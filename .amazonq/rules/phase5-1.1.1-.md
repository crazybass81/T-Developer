# Phase 5: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ - Tasks 5.1~5.3 SubTask êµ¬ì¡°

## ğŸ“‹ Task 5.1~5.3 SubTask ë¦¬ìŠ¤íŠ¸

### Task 5.1: ì¤‘ì•™ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì„¤ê³„ ë° êµ¬í˜„

- **SubTask 5.1.1**: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì•„í‚¤í…ì²˜ ì„¤ê³„
- **SubTask 5.1.2**: ì—ì´ì „íŠ¸ í†µí•© ì¸í„°í˜ì´ìŠ¤
- **SubTask 5.1.3**: ì›Œí¬í”Œë¡œìš° ìƒíƒœ ê´€ë¦¬
- **SubTask 5.1.4**: ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹  ì‹œìŠ¤í…œ

### Task 5.2: ì›Œí¬í”Œë¡œìš° ì—”ì§„ êµ¬ì¶•

- **SubTask 5.2.1**: ì›Œí¬í”Œë¡œìš° ì •ì˜ ëª¨ë¸
- **SubTask 5.2.2**: ì›Œí¬í”Œë¡œìš° íŒŒì„œ ë° ê²€ì¦ê¸°
- **SubTask 5.2.3**: ì‹¤í–‰ ìŠ¤ì¼€ì¤„ëŸ¬
- **SubTask 5.2.4**: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ëª¨ë‹ˆí„°

### Task 5.3: ì—ì´ì „íŠ¸ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬

- **SubTask 5.3.1**: ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
- **SubTask 5.3.2**: ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬ ì‹œìŠ¤í…œ
- **SubTask 5.3.3**: ë™ì  ì—ì´ì „íŠ¸ ìŠ¤ì¼€ì¼ë§
- **SubTask 5.3.4**: ì—ì´ì „íŠ¸ ë²„ì „ ê´€ë¦¬

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 5.1: ì¤‘ì•™ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì„¤ê³„ ë° êµ¬í˜„

#### SubTask 5.1.1: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì•„í‚¤í…ì²˜ ì„¤ê³„

**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/core/orchestrator.py
from typing import Dict, List, Optional, Any, AsyncIterator
from dataclasses import dataclass, field
from enum import Enum
import asyncio
from datetime import datetime
import uuid

@dataclass
class OrchestratorConfig:
    max_concurrent_workflows: int = 100
    max_concurrent_tasks: int = 500
    task_timeout_seconds: int = 300
    workflow_timeout_seconds: int = 3600
    enable_auto_recovery: bool = True
    enable_metrics: bool = True
    state_storage_type: str = "dynamodb"
    message_queue_type: str = "sqs"

@dataclass
class WorkflowState(Enum):
    PENDING = "pending"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class TaskState(Enum):
    PENDING = "pending"
    QUEUED = "queued"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    TIMEOUT = "timeout"

class CentralOrchestrator:
    """T-Developer ì¤‘ì•™ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ"""

    def __init__(self, config: OrchestratorConfig):
        self.config = config

        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸
        self.agent_registry: AgentRegistry = None
        self.workflow_engine: WorkflowEngine = None
        self.task_scheduler: TaskScheduler = None
        self.state_manager: StateManager = None
        self.event_bus: EventBus = None
        self.metrics_collector: MetricsCollector = None
        self.resource_manager: ResourceManager = None

        # ì‹¤í–‰ ìƒíƒœ ì¶”ì 
        self.active_workflows: Dict[str, WorkflowExecution] = {}
        self.active_tasks: Dict[str, AgentTask] = {}
        self.workflow_semaphore = asyncio.Semaphore(config.max_concurrent_workflows)
        self.task_semaphore = asyncio.Semaphore(config.max_concurrent_tasks)

        # ë™ê¸°í™” í”„ë¦¬ë¯¸í‹°ë¸Œ
        self.workflow_lock = asyncio.Lock()
        self.task_lock = asyncio.Lock()
        self.shutdown_event = asyncio.Event()

    async def initialize(self):
        """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”"""
        logger.info("Initializing Central Orchestrator...")

        # 1. ìƒíƒœ ì €ì¥ì†Œ ì´ˆê¸°í™”
        self.state_manager = await self._initialize_state_manager()

        # 2. ì´ë²¤íŠ¸ ë²„ìŠ¤ ì´ˆê¸°í™”
        self.event_bus = EventBus()
        await self.event_bus.start()

        # 3. ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”
        self.agent_registry = AgentRegistry(self.event_bus)
        await self.agent_registry.initialize()

        # 4. ì›Œí¬í”Œë¡œìš° ì—”ì§„ ì´ˆê¸°í™”
        self.workflow_engine = WorkflowEngine(self)

        # 5. íƒœìŠ¤í¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”
        self.task_scheduler = TaskScheduler(
            self.agent_registry,
            self.task_semaphore
        )

        # 6. ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì ì´ˆê¸°í™”
        self.resource_manager = ResourceManager(self.config)

        # 7. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        if self.config.enable_metrics:
            self.metrics_collector = MetricsCollector(self)
            await self.metrics_collector.start()

        # 8. ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
        self._register_event_handlers()

        # 9. ì¤‘ë‹¨ëœ ì›Œí¬í”Œë¡œìš° ë³µêµ¬
        if self.config.enable_auto_recovery:
            await self._recover_interrupted_workflows()

        logger.info("Central Orchestrator initialized successfully")

    async def submit_workflow(
        self,
        workflow_id: str,
        input_data: Dict[str, Any],
        options: Optional[Dict[str, Any]] = None
    ) -> str:
        """ì›Œí¬í”Œë¡œìš° ì œì¶œ"""
        async with self.workflow_semaphore:
            # ì›Œí¬í”Œë¡œìš° ì •ì˜ ë¡œë“œ
            workflow_def = await self._load_workflow_definition(workflow_id)

            # ì…ë ¥ ê²€ì¦
            await self._validate_workflow_input(workflow_def, input_data)

            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ìƒì„±
            execution = await self.workflow_engine.create_execution(
                workflow_def,
                input_data,
                options or {}
            )

            # í™œì„± ì›Œí¬í”Œë¡œìš° ì¶”ê°€
            async with self.workflow_lock:
                self.active_workflows[execution.id] = execution

            # ì‹¤í–‰ ì‹œì‘
            asyncio.create_task(
                self._execute_workflow(execution)
            )

            # ì›Œí¬í”Œë¡œìš° ì‹œì‘ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="workflow.started",
                    workflow_id=execution.id,
                    timestamp=datetime.utcnow(),
                    data={"workflow_def_id": workflow_id}
                )
            )

            return execution.id

    async def _execute_workflow(self, execution: WorkflowExecution):
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ë‚´ë¶€)"""
        try:
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            result = await self.workflow_engine.execute(execution)

            # ì™„ë£Œ ì²˜ë¦¬
            execution.state = WorkflowState.COMPLETED
            execution.completed_at = datetime.utcnow()
            execution.result = result

            # ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="workflow.completed",
                    workflow_id=execution.id,
                    timestamp=datetime.utcnow(),
                    data={"result": result}
                )
            )

        except Exception as e:
            # ì‹¤íŒ¨ ì²˜ë¦¬
            execution.state = WorkflowState.FAILED
            execution.completed_at = datetime.utcnow()
            execution.error = str(e)

            # ì‹¤íŒ¨ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="workflow.failed",
                    workflow_id=execution.id,
                    timestamp=datetime.utcnow(),
                    data={"error": str(e)}
                )
            )

        finally:
            # ìƒíƒœ ì €ì¥
            await self.state_manager.save_workflow_state(
                execution.id,
                execution
            )

            # í™œì„± ì›Œí¬í”Œë¡œìš°ì—ì„œ ì œê±°
            async with self.workflow_lock:
                self.active_workflows.pop(execution.id, None)
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í•µì‹¬ ì•„í‚¤í…ì²˜ êµ¬í˜„
- [ ] ë™ì‹œì„± ì œì–´ ë©”ì»¤ë‹ˆì¦˜
- [ ] ìƒíƒœ ê´€ë¦¬ í†µí•©
- [ ] ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹ 

#### SubTask 5.1.2: ì—ì´ì „íŠ¸ í†µí•© ì¸í„°í˜ì´ìŠ¤

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/core/agent_interface.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List, Callable
import httpx
import asyncio
from datetime import datetime, timedelta

@dataclass
class AgentCapability:
    name: str
    version: str
    input_schema: Dict[str, Any]
    output_schema: Dict[str, Any]
    timeout_seconds: int = 300
    max_retries: int = 3

@dataclass
class AgentInfo:
    id: str
    type: str
    name: str
    version: str
    endpoint: str
    capabilities: List[AgentCapability]
    health_check_endpoint: str
    status: str = "unknown"
    last_health_check: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

class AgentInterface(ABC):
    """ì—ì´ì „íŠ¸ í†µí•©ì„ ìœ„í•œ í‘œì¤€ ì¸í„°í˜ì´ìŠ¤"""

    @abstractmethod
    async def execute(self, task: AgentTask) -> Dict[str, Any]:
        """íƒœìŠ¤í¬ ì‹¤í–‰"""
        pass

    @abstractmethod
    async def get_status(self, task_id: str) -> Dict[str, Any]:
        """íƒœìŠ¤í¬ ìƒíƒœ ì¡°íšŒ"""
        pass

    @abstractmethod
    async def cancel(self, task_id: str) -> bool:
        """íƒœìŠ¤í¬ ì·¨ì†Œ"""
        pass

    @abstractmethod
    async def health_check(self) -> Dict[str, Any]:
        """í—¬ìŠ¤ ì²´í¬"""
        pass

class HTTPAgentProxy(AgentInterface):
    """HTTP ê¸°ë°˜ ì—ì´ì „íŠ¸ í”„ë¡ì‹œ"""

    def __init__(self, agent_info: AgentInfo):
        self.agent_info = agent_info
        self.client = httpx.AsyncClient(
            timeout=httpx.Timeout(
                connect=5.0,
                read=300.0,
                write=30.0,
                pool=5.0
            ),
            limits=httpx.Limits(
                max_keepalive_connections=5,
                max_connections=10
            )
        )
        self._circuit_breaker = CircuitBreaker(
            failure_threshold=5,
            recovery_timeout=60,
            expected_exception=httpx.HTTPError
        )

    async def execute(self, task: AgentTask) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ íƒœìŠ¤í¬ ì‹¤í–‰"""
        @self._circuit_breaker
        async def _execute():
            # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
            request_data = {
                "task_id": task.id,
                "input": task.input_data,
                "context": task.context,
                "timeout": task.timeout
            }

            # ì—ì´ì „íŠ¸ í˜¸ì¶œ
            response = await self.client.post(
                f"{self.agent_info.endpoint}/execute",
                json=request_data,
                headers={
                    "X-Task-ID": task.id,
                    "X-Workflow-ID": task.workflow_id,
                    "X-Request-ID": str(uuid.uuid4())
                }
            )

            # ì‘ë‹µ ì²˜ë¦¬
            if response.status_code == 202:  # Accepted
                # ë¹„ë™ê¸° ì‹¤í–‰ - í´ë§ í•„ìš”
                return {
                    "status": "accepted",
                    "task_id": task.id,
                    "poll_url": response.headers.get("Location")
                }
            elif response.status_code == 200:
                # ë™ê¸° ì‹¤í–‰ ì™„ë£Œ
                return response.json()
            else:
                raise AgentExecutionError(
                    f"Agent returned {response.status_code}: {response.text}"
                )

        return await _execute()

    async def get_status(self, task_id: str) -> Dict[str, Any]:
        """íƒœìŠ¤í¬ ìƒíƒœ ì¡°íšŒ"""
        response = await self.client.get(
            f"{self.agent_info.endpoint}/tasks/{task_id}/status"
        )

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 404:
            return {"status": "not_found"}
        else:
            raise AgentStatusError(
                f"Failed to get status: {response.status_code}"
            )

    async def cancel(self, task_id: str) -> bool:
        """íƒœìŠ¤í¬ ì·¨ì†Œ"""
        try:
            response = await self.client.post(
                f"{self.agent_info.endpoint}/tasks/{task_id}/cancel"
            )
            return response.status_code in [200, 202]
        except Exception as e:
            logger.error(f"Failed to cancel task {task_id}: {e}")
            return False

    async def health_check(self) -> Dict[str, Any]:
        """í—¬ìŠ¤ ì²´í¬"""
        try:
            response = await self.client.get(
                self.agent_info.health_check_endpoint,
                timeout=5.0
            )

            if response.status_code == 200:
                return {
                    "status": "healthy",
                    "timestamp": datetime.utcnow(),
                    "details": response.json()
                }
            else:
                return {
                    "status": "unhealthy",
                    "timestamp": datetime.utcnow(),
                    "error": f"HTTP {response.status_code}"
                }
        except Exception as e:
            return {
                "status": "unhealthy",
                "timestamp": datetime.utcnow(),
                "error": str(e)
            }

class AgentProxyFactory:
    """ì—ì´ì „íŠ¸ í”„ë¡ì‹œ íŒ©í† ë¦¬"""

    @staticmethod
    def create_proxy(agent_info: AgentInfo) -> AgentInterface:
        """ì—ì´ì „íŠ¸ íƒ€ì…ì— ë”°ë¥¸ í”„ë¡ì‹œ ìƒì„±"""
        if agent_info.endpoint.startswith("http"):
            return HTTPAgentProxy(agent_info)
        elif agent_info.endpoint.startswith("grpc"):
            return GRPCAgentProxy(agent_info)
        elif agent_info.endpoint.startswith("lambda"):
            return LambdaAgentProxy(agent_info)
        else:
            raise ValueError(f"Unknown agent type: {agent_info.endpoint}")
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í‘œì¤€ ì—ì´ì „íŠ¸ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- [ ] HTTP/gRPC/Lambda í”„ë¡ì‹œ êµ¬í˜„
- [ ] Circuit Breaker íŒ¨í„´ ì ìš©
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§

#### SubTask 5.1.3: ì›Œí¬í”Œë¡œìš° ìƒíƒœ ê´€ë¦¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/core/state_manager.py
from typing import Dict, List, Optional, Any
import asyncio
from datetime import datetime
import json

class StateStorage(ABC):
    """ìƒíƒœ ì €ì¥ì†Œ ì¶”ìƒ í´ë˜ìŠ¤"""

    @abstractmethod
    async def save(self, key: str, data: Dict[str, Any]) -> None:
        pass

    @abstractmethod
    async def load(self, key: str) -> Optional[Dict[str, Any]]:
        pass

    @abstractmethod
    async def delete(self, key: str) -> None:
        pass

    @abstractmethod
    async def list_keys(self, prefix: str) -> List[str]:
        pass

class DynamoDBStateStorage(StateStorage):
    """DynamoDB ê¸°ë°˜ ìƒíƒœ ì €ì¥ì†Œ"""

    def __init__(self, table_name: str):
        self.table_name = table_name
        self.dynamodb = boto3.resource('dynamodb')
        self.table = self.dynamodb.Table(table_name)

    async def save(self, key: str, data: Dict[str, Any]) -> None:
        """ìƒíƒœ ì €ì¥"""
        item = {
            'id': key,
            'data': json.dumps(data, default=str),
            'timestamp': datetime.utcnow().isoformat(),
            'ttl': int((datetime.utcnow() + timedelta(days=30)).timestamp())
        }

        await asyncio.to_thread(
            self.table.put_item,
            Item=item
        )

    async def load(self, key: str) -> Optional[Dict[str, Any]]:
        """ìƒíƒœ ë¡œë“œ"""
        response = await asyncio.to_thread(
            self.table.get_item,
            Key={'id': key}
        )

        if 'Item' in response:
            return json.loads(response['Item']['data'])
        return None

class StateManager:
    """ì›Œí¬í”Œë¡œìš° ë° íƒœìŠ¤í¬ ìƒíƒœ ê´€ë¦¬ì"""

    def __init__(self, storage: StateStorage):
        self.storage = storage
        self.state_cache = TTLCache(maxsize=1000, ttl=300)
        self.cache_lock = asyncio.Lock()
        self.write_buffer = asyncio.Queue(maxsize=1000)
        self.writer_task = None

    async def start(self):
        """ìƒíƒœ ê´€ë¦¬ì ì‹œì‘"""
        self.writer_task = asyncio.create_task(self._write_worker())

    async def stop(self):
        """ìƒíƒœ ê´€ë¦¬ì ì¤‘ì§€"""
        if self.writer_task:
            self.writer_task.cancel()

    async def save_workflow_state(
        self,
        workflow_id: str,
        execution: WorkflowExecution
    ) -> None:
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì €ì¥"""
        state_data = {
            "workflow_id": execution.workflow_id,
            "execution_id": execution.id,
            "state": execution.state.value,
            "started_at": execution.started_at.isoformat(),
            "completed_at": execution.completed_at.isoformat()
                if execution.completed_at else None,
            "tasks": {
                task_id: self._serialize_task(task)
                for task_id, task in execution.tasks.items()
            },
            "context": execution.context,
            "result": execution.result,
            "error": execution.error,
            "metadata": execution.metadata
        }

        # ìºì‹œ ì—…ë°ì´íŠ¸
        async with self.cache_lock:
            self.state_cache[workflow_id] = state_data

        # ë¹„ë™ê¸° ì €ì¥ íì— ì¶”ê°€
        await self.write_buffer.put((
            f"workflow:{workflow_id}",
            state_data
        ))

    async def load_workflow_state(
        self,
        workflow_id: str
    ) -> Optional[WorkflowExecution]:
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë¡œë“œ"""
        # ìºì‹œ í™•ì¸
        async with self.cache_lock:
            if workflow_id in self.state_cache:
                state_data = self.state_cache[workflow_id]
                return self._deserialize_workflow(state_data)

        # ì €ì¥ì†Œì—ì„œ ë¡œë“œ
        state_data = await self.storage.load(f"workflow:{workflow_id}")
        if state_data:
            # ìºì‹œ ì—…ë°ì´íŠ¸
            async with self.cache_lock:
                self.state_cache[workflow_id] = state_data
            return self._deserialize_workflow(state_data)

        return None

    async def update_task_state(
        self,
        workflow_id: str,
        task_id: str,
        updates: Dict[str, Any]
    ) -> None:
        """íƒœìŠ¤í¬ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        # ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë¡œë“œ
        execution = await self.load_workflow_state(workflow_id)
        if not execution:
            raise ValueError(f"Workflow {workflow_id} not found")

        # íƒœìŠ¤í¬ ì—…ë°ì´íŠ¸
        if task_id not in execution.tasks:
            raise ValueError(f"Task {task_id} not found")

        task = execution.tasks[task_id]
        for key, value in updates.items():
            setattr(task, key, value)

        # íƒ€ì„ìŠ¤íƒ¬í”„ ì—…ë°ì´íŠ¸
        if updates.get("status") == "completed":
            task.completed_at = datetime.utcnow()
        elif updates.get("status") == "running":
            task.started_at = datetime.utcnow()

        # ìƒíƒœ ì €ì¥
        await self.save_workflow_state(workflow_id, execution)

    async def list_active_workflows(self) -> List[str]:
        """í™œì„± ì›Œí¬í”Œë¡œìš° ëª©ë¡ ì¡°íšŒ"""
        keys = await self.storage.list_keys("workflow:")
        workflows = []

        for key in keys:
            workflow_id = key.replace("workflow:", "")
            execution = await self.load_workflow_state(workflow_id)

            if execution and execution.state in [
                WorkflowState.PENDING,
                WorkflowState.RUNNING
            ]:
                workflows.append(workflow_id)

        return workflows

    async def _write_worker(self):
        """ë¹„ë™ê¸° ì“°ê¸° ì›Œì»¤"""
        batch = []

        while True:
            try:
                # ë°°ì¹˜ ìˆ˜ì§‘ (ìµœëŒ€ 100ê°œ ë˜ëŠ” 1ì´ˆ)
                deadline = asyncio.create_task(asyncio.sleep(1.0))

                while len(batch) < 100:
                    get_task = asyncio.create_task(self.write_buffer.get())

                    done, pending = await asyncio.wait(
                        [get_task, deadline],
                        return_when=asyncio.FIRST_COMPLETED
                    )

                    if get_task in done:
                        batch.append(get_task.result())
                    else:
                        get_task.cancel()
                        break

                # ë°°ì¹˜ ì €ì¥
                if batch:
                    await self._save_batch(batch)
                    batch.clear()

            except asyncio.CancelledError:
                # ë‚¨ì€ ë°ì´í„° ì €ì¥
                if batch:
                    await self._save_batch(batch)
                break
            except Exception as e:
                logger.error(f"Write worker error: {e}")
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ìƒíƒœ ì €ì¥/ë¡œë“œ ë©”ì»¤ë‹ˆì¦˜
- [ ] ìºì‹± ì „ëµ êµ¬í˜„
- [ ] ë°°ì¹˜ ì“°ê¸° ìµœì í™”
- [ ] ìƒíƒœ ë³µêµ¬ ê¸°ëŠ¥

#### SubTask 5.1.4: ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹  ì‹œìŠ¤í…œ

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/core/event_bus.py
from typing import Dict, List, Callable, Optional, Any
import asyncio
from datetime import datetime
from dataclasses import dataclass
import json

@dataclass
class OrchestratorEvent:
    event_id: str
    event_type: str
    source: str
    workflow_id: Optional[str]
    task_id: Optional[str]
    timestamp: datetime
    data: Dict[str, Any]
    correlation_id: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "event_id": self.event_id,
            "event_type": self.event_type,
            "source": self.source,
            "workflow_id": self.workflow_id,
            "task_id": self.task_id,
            "timestamp": self.timestamp.isoformat(),
            "data": self.data,
            "correlation_id": self.correlation_id
        }

class EventHandler:
    """ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë˜í¼"""

    def __init__(
        self,
        handler: Callable,
        filter_func: Optional[Callable] = None,
        priority: int = 0
    ):
        self.handler = handler
        self.filter_func = filter_func
        self.priority = priority
        self.is_async = asyncio.iscoroutinefunction(handler)

    async def handle(self, event: OrchestratorEvent) -> Any:
        """ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        # í•„í„° í™•ì¸
        if self.filter_func and not self.filter_func(event):
            return None

        # í•¸ë“¤ëŸ¬ ì‹¤í–‰
        if self.is_async:
            return await self.handler(event)
        else:
            return self.handler(event)

class EventBus:
    """ì¤‘ì•™ ì´ë²¤íŠ¸ ë²„ìŠ¤"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.subscribers: Dict[str, List[EventHandler]] = {}
        self.event_queue = asyncio.Queue(
            maxsize=self.config.get("queue_size", 10000)
        )
        self.event_store: Optional[EventStore] = None
        self.running = False
        self.workers = []
        self.stats = EventBusStats()

    async def start(self):
        """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œì‘"""
        self.running = True

        # ì´ë²¤íŠ¸ ì €ì¥ì†Œ ì´ˆê¸°í™”
        if self.config.get("enable_event_store", True):
            self.event_store = EventStore(
                self.config.get("event_store_config", {})
            )
            await self.event_store.initialize()

        # ì›Œì»¤ ì‹œì‘
        num_workers = self.config.get("num_workers", 4)
        for i in range(num_workers):
            worker = asyncio.create_task(
                self._event_worker(f"worker-{i}")
            )
            self.workers.append(worker)

        logger.info(f"Event bus started with {num_workers} workers")

    async def stop(self):
        """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì¤‘ì§€"""
        self.running = False

        # ì›Œì»¤ ì¤‘ì§€
        for worker in self.workers:
            worker.cancel()

        # ë‚¨ì€ ì´ë²¤íŠ¸ ì²˜ë¦¬
        await self._flush_events()

        # ì´ë²¤íŠ¸ ì €ì¥ì†Œ ì¢…ë£Œ
        if self.event_store:
            await self.event_store.close()

    async def publish(
        self,
        event: OrchestratorEvent,
        priority: int = 0
    ) -> None:
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        # ì´ë²¤íŠ¸ ID ìƒì„±
        if not event.event_id:
            event.event_id = str(uuid.uuid4())

        # í†µê³„ ì—…ë°ì´íŠ¸
        self.stats.increment_published(event.event_type)

        # ì´ë²¤íŠ¸ ì €ì¥
        if self.event_store:
            await self.event_store.save(event)

        # íì— ì¶”ê°€
        try:
            await asyncio.wait_for(
                self.event_queue.put((priority, event)),
                timeout=1.0
            )
        except asyncio.TimeoutError:
            logger.error(f"Event queue full, dropping event: {event.event_id}")
            self.stats.increment_dropped()

    def subscribe(
        self,
        event_type: str,
        handler: Callable,
        filter_func: Optional[Callable] = None,
        priority: int = 0
    ) -> str:
        """ì´ë²¤íŠ¸ êµ¬ë…"""
        if event_type not in self.subscribers:
            self.subscribers[event_type] = []

        event_handler = EventHandler(handler, filter_func, priority)
        self.subscribers[event_type].append(event_handler)

        # ìš°ì„ ìˆœìœ„ ì •ë ¬
        self.subscribers[event_type].sort(
            key=lambda h: h.priority,
            reverse=True
        )

        subscription_id = f"{event_type}:{id(handler)}"
        logger.info(f"Subscribed to {event_type}: {subscription_id}")

        return subscription_id

    def unsubscribe(self, subscription_id: str) -> bool:
        """êµ¬ë… ì·¨ì†Œ"""
        event_type, handler_id = subscription_id.split(":")

        if event_type in self.subscribers:
            self.subscribers[event_type] = [
                h for h in self.subscribers[event_type]
                if id(h.handler) != int(handler_id)
            ]
            return True

        return False

    async def _event_worker(self, worker_id: str):
        """ì´ë²¤íŠ¸ ì²˜ë¦¬ ì›Œì»¤"""
        logger.info(f"Event worker {worker_id} started")

        while self.running:
            try:
                # ì´ë²¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                priority, event = await asyncio.wait_for(
                    self.event_queue.get(),
                    timeout=1.0
                )

                # ì´ë²¤íŠ¸ ì²˜ë¦¬
                await self._process_event(event)

            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"Event worker {worker_id} error: {e}")

        logger.info(f"Event worker {worker_id} stopped")

    async def _process_event(self, event: OrchestratorEvent):
        """ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        start_time = datetime.utcnow()

        try:
            # ì „ì—­ í•¸ë“¤ëŸ¬ (*) ì‹¤í–‰
            if "*" in self.subscribers:
                for handler in self.subscribers["*"]:
                    await self._execute_handler(handler, event)

            # íŠ¹ì • ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì‹¤í–‰
            if event.event_type in self.subscribers:
                handlers = self.subscribers[event.event_type]

                # ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ í•¸ë“¤ëŸ¬ ê·¸ë£¹í™”
                async_tasks = []

                for handler in handlers:
                    if handler.is_async:
                        task = asyncio.create_task(
                            self._execute_handler(handler, event)
                        )
                        async_tasks.append(task)
                    else:
                        # ë™ê¸° í•¸ë“¤ëŸ¬ëŠ” ìˆœì°¨ ì‹¤í–‰
                        await self._execute_handler(handler, event)

                # ë¹„ë™ê¸° í•¸ë“¤ëŸ¬ ëŒ€ê¸°
                if async_tasks:
                    await asyncio.gather(*async_tasks, return_exceptions=True)

            # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
            duration = (datetime.utcnow() - start_time).total_seconds()
            self.stats.record_processing_time(event.event_type, duration)

        except Exception as e:
            logger.error(f"Error processing event {event.event_id}: {e}")
            self.stats.increment_errors(event.event_type)

    async def _execute_handler(
        self,
        handler: EventHandler,
        event: OrchestratorEvent
    ):
        """ê°œë³„ í•¸ë“¤ëŸ¬ ì‹¤í–‰"""
        try:
            await handler.handle(event)
        except Exception as e:
            logger.error(
                f"Handler error for event {event.event_id}: {e}",
                exc_info=True
            )
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì´ë²¤íŠ¸ ë°œí–‰/êµ¬ë… ë©”ì»¤ë‹ˆì¦˜
- [ ] ë¹„ë™ê¸° ì´ë²¤íŠ¸ ì²˜ë¦¬
- [ ] ì´ë²¤íŠ¸ ìš°ì„ ìˆœìœ„ ê´€ë¦¬
- [ ] ì´ë²¤íŠ¸ ì €ì¥ ë° ì¬ìƒ

### Task 5.2: ì›Œí¬í”Œë¡œìš° ì—”ì§„ êµ¬ì¶•

#### SubTask 5.2.1: ì›Œí¬í”Œë¡œìš° ì •ì˜ ëª¨ë¸

**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/workflow/workflow_definition.py
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, field
from enum import Enum
import yaml
import json

@dataclass
class TaskDependency:
    task_id: str
    condition: Optional[str] = None
    wait_for_completion: bool = True

@dataclass
class RetryPolicy:
    max_attempts: int = 3
    initial_delay: int = 1
    max_delay: int = 60
    multiplier: float = 2.0
    retry_on: List[str] = field(default_factory=lambda: ["error", "timeout"])

@dataclass
class WorkflowTask:
    id: str
    name: str
    agent_type: str
    description: Optional[str] = None

    # ì…ì¶œë ¥ ë§¤í•‘
    input_mapping: Dict[str, str] = field(default_factory=dict)
    output_mapping: Dict[str, str] = field(default_factory=dict)

    # ì˜ì¡´ì„±
    dependencies: List[TaskDependency] = field(default_factory=list)

    # ì‹¤í–‰ ì„¤ì •
    timeout_seconds: int = 300
    retry_policy: RetryPolicy = field(default_factory=RetryPolicy)

    # ì¡°ê±´ë¶€ ì‹¤í–‰
    conditions: List[str] = field(default_factory=list)
    skip_on_failure: bool = False

    # ì—ëŸ¬ í•¸ë“¤ë§
    error_handler: Optional[str] = None
    compensation_task: Optional[str] = None

@dataclass
class ParallelBlock:
    """ë³‘ë ¬ ì‹¤í–‰ ë¸”ë¡"""
    id: str
    tasks: List[Union[WorkflowTask, 'ConditionalBlock']]
    max_concurrency: Optional[int] = None
    fail_fast: bool = True

@dataclass
class ConditionalBlock:
    """ì¡°ê±´ë¶€ ì‹¤í–‰ ë¸”ë¡"""
    id: str
    condition: str
    if_tasks: List[Union[WorkflowTask, ParallelBlock]]
    else_tasks: Optional[List[Union[WorkflowTask, ParallelBlock]]] = None

@dataclass
class LoopBlock:
    """ë°˜ë³µ ì‹¤í–‰ ë¸”ë¡"""
    id: str
    iterator: str  # ë°˜ë³µí•  ë°ì´í„° ê²½ë¡œ
    variable: str  # ë°˜ë³µ ë³€ìˆ˜ ì´ë¦„
    tasks: List[Union[WorkflowTask, ParallelBlock, ConditionalBlock]]
    max_iterations: Optional[int] = None
    parallel: bool = False

@dataclass
class WorkflowDefinition:
    """ì›Œí¬í”Œë¡œìš° ì •ì˜"""
    id: str
    name: str
    version: str
    description: str

    # ì…ì¶œë ¥ ìŠ¤í‚¤ë§ˆ
    input_schema: Dict[str, Any]
    output_schema: Dict[str, Any]

    # ì›Œí¬í”Œë¡œìš° êµ¬ì¡°
    tasks: List[Union[WorkflowTask, ParallelBlock, ConditionalBlock, LoopBlock]]

    # ì „ì—­ ì„¤ì •
    timeout_seconds: int = 3600
    max_retries: int = 1

    # ì—ëŸ¬ í•¸ë“¤ëŸ¬
    error_handlers: Dict[str, str] = field(default_factory=dict)

    # ë©”íƒ€ë°ì´í„°
    tags: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

class WorkflowLoader:
    """ì›Œí¬í”Œë¡œìš° ì •ì˜ ë¡œë”"""

    def __init__(self):
        self.validators = {
            'yaml': self._validate_yaml,
            'json': self._validate_json,
            'dsl': self._validate_dsl
        }

    async def load_from_file(self, file_path: str) -> WorkflowDefinition:
        """íŒŒì¼ì—ì„œ ì›Œí¬í”Œë¡œìš° ë¡œë“œ"""
        with open(file_path, 'r') as f:
            content = f.read()

        if file_path.endswith('.yaml') or file_path.endswith('.yml'):
            return await self.load_from_yaml(content)
        elif file_path.endswith('.json'):
            return await self.load_from_json(content)
        else:
            raise ValueError(f"Unsupported file format: {file_path}")

    async def load_from_yaml(self, yaml_content: str) -> WorkflowDefinition:
        """YAMLì—ì„œ ì›Œí¬í”Œë¡œìš° ë¡œë“œ"""
        data = yaml.safe_load(yaml_content)
        await self._validate_yaml(data)
        return self._parse_workflow_data(data)

    async def load_from_json(self, json_content: str) -> WorkflowDefinition:
        """JSONì—ì„œ ì›Œí¬í”Œë¡œìš° ë¡œë“œ"""
        data = json.loads(json_content)
        await self._validate_json(data)
        return self._parse_workflow_data(data)

    def _parse_workflow_data(self, data: Dict[str, Any]) -> WorkflowDefinition:
        """ì›Œí¬í”Œë¡œìš° ë°ì´í„° íŒŒì‹±"""
        # ê¸°ë³¸ ì •ë³´
        workflow = WorkflowDefinition(
            id=data['id'],
            name=data['name'],
            version=data['version'],
            description=data.get('description', ''),
            input_schema=data.get('input_schema', {}),
            output_schema=data.get('output_schema', {}),
            timeout_seconds=data.get('timeout_seconds', 3600),
            max_retries=data.get('max_retries', 1),
            error_handlers=data.get('error_handlers', {}),
            tags=data.get('tags', []),
            metadata=data.get('metadata', {})
        )

        # íƒœìŠ¤í¬ íŒŒì‹±
        workflow.tasks = self._parse_tasks(data.get('tasks', []))

        return workflow

    def _parse_tasks(
        self,
        tasks_data: List[Dict[str, Any]]
    ) -> List[Union[WorkflowTask, ParallelBlock, ConditionalBlock, LoopBlock]]:
        """íƒœìŠ¤í¬ ë¦¬ìŠ¤íŠ¸ íŒŒì‹±"""
        tasks = []

        for task_data in tasks_data:
            task_type = task_data.get('type', 'task')

            if task_type == 'task':
                task = self._parse_workflow_task(task_data)
            elif task_type == 'parallel':
                task = self._parse_parallel_block(task_data)
            elif task_type == 'conditional':
                task = self._parse_conditional_block(task_data)
            elif task_type == 'loop':
                task = self._parse_loop_block(task_data)
            else:
                raise ValueError(f"Unknown task type: {task_type}")

            tasks.append(task)

        return tasks
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í¬ê´„ì ì¸ ì›Œí¬í”Œë¡œìš° ëª¨ë¸
- [ ] YAML/JSON ë¡œë” êµ¬í˜„
- [ ] íƒœìŠ¤í¬ íƒ€ì… ì§€ì› (ìˆœì°¨/ë³‘ë ¬/ì¡°ê±´/ë°˜ë³µ)
- [ ] ì…ì¶œë ¥ ë§¤í•‘ ë° ì˜ì¡´ì„± ê´€ë¦¬

#### SubTask 5.2.2: ì›Œí¬í”Œë¡œìš° íŒŒì„œ ë° ê²€ì¦ê¸°

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/workflow/workflow_validator.py
from typing import Dict, List, Set, Optional, Any
import networkx as nx
from jsonschema import validate, ValidationError

class WorkflowValidator:
    """ì›Œí¬í”Œë¡œìš° ì •ì˜ ê²€ì¦ê¸°"""

    def __init__(self):
        self.schema_validator = SchemaValidator()
        self.dependency_validator = DependencyValidator()
        self.expression_validator = ExpressionValidator()

    async def validate(
        self,
        workflow: WorkflowDefinition
    ) -> ValidationResult:
        """ì›Œí¬í”Œë¡œìš° ì „ì²´ ê²€ì¦"""
        errors = []
        warnings = []

        # 1. ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
        structural_errors = await self._validate_structure(workflow)
        errors.extend(structural_errors)

        # 2. íƒœìŠ¤í¬ ê²€ì¦
        task_errors = await self._validate_tasks(workflow)
        errors.extend(task_errors)

        # 3. ì˜ì¡´ì„± ê²€ì¦
        dependency_result = await self.dependency_validator.validate(workflow)
        errors.extend(dependency_result.errors)
        warnings.extend(dependency_result.warnings)

        # 4. ì…ì¶œë ¥ ë§¤í•‘ ê²€ì¦
        mapping_errors = await self._validate_mappings(workflow)
        errors.extend(mapping_errors)

        # 5. ì¡°ê±´ì‹ ê²€ì¦
        expression_errors = await self._validate_expressions(workflow)
        errors.extend(expression_errors)

        # 6. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶”ì •
        resource_warnings = await self._estimate_resources(workflow)
        warnings.extend(resource_warnings)

        return ValidationResult(
            is_valid=len(errors) == 0,
            errors=errors,
            warnings=warnings
        )

    async def _validate_structure(
        self,
        workflow: WorkflowDefinition
    ) -> List[ValidationError]:
        """ê¸°ë³¸ êµ¬ì¡° ê²€ì¦"""
        errors = []

        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        if not workflow.id:
            errors.append(ValidationError("Workflow ID is required"))
        if not workflow.name:
            errors.append(ValidationError("Workflow name is required"))
        if not workflow.version:
            errors.append(ValidationError("Workflow version is required"))

        # ë²„ì „ í˜•ì‹ ê²€ì¦
        if not self._is_valid_version(workflow.version):
            errors.append(
                ValidationError(f"Invalid version format: {workflow.version}")
            )

        # íƒœìŠ¤í¬ ì¡´ì¬ í™•ì¸
        if not workflow.tasks:
            errors.append(ValidationError("Workflow must have at least one task"))

        return errors

    async def _validate_tasks(
        self,
        workflow: WorkflowDefinition
    ) -> List[ValidationError]:
        """íƒœìŠ¤í¬ ê²€ì¦"""
        errors = []
        task_ids = set()

        for task in self._flatten_tasks(workflow.tasks):
            # ID ì¤‘ë³µ í™•ì¸
            if task.id in task_ids:
                errors.append(
                    ValidationError(f"Duplicate task ID: {task.id}")
                )
            task_ids.add(task.id)

            # ì—ì´ì „íŠ¸ íƒ€ì… ê²€ì¦
            if not await self._is_valid_agent_type(task.agent_type):
                errors.append(
                    ValidationError(
                        f"Unknown agent type: {task.agent_type} in task {task.id}"
                    )
                )

            # íƒ€ì„ì•„ì›ƒ ê²€ì¦
            if task.timeout_seconds <= 0:
                errors.append(
                    ValidationError(
                        f"Invalid timeout for task {task.id}: {task.timeout_seconds}"
                    )
                )

        return errors

class DependencyValidator:
    """ì˜ì¡´ì„± ê²€ì¦ê¸°"""

    async def validate(
        self,
        workflow: WorkflowDefinition
    ) -> DependencyValidationResult:
        """ì˜ì¡´ì„± ê²€ì¦"""
        errors = []
        warnings = []

        # ì˜ì¡´ì„± ê·¸ë˜í”„ ìƒì„±
        dep_graph = self._build_dependency_graph(workflow)

        # 1. ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
        cycles = list(nx.simple_cycles(dep_graph))
        if cycles:
            for cycle in cycles:
                errors.append(
                    ValidationError(
                        f"Circular dependency detected: {' -> '.join(cycle)}"
                    )
                )

        # 2. ë¯¸í•´ê²° ì˜ì¡´ì„± ê²€ì‚¬
        all_task_ids = set(dep_graph.nodes())

        for task_id, task_data in dep_graph.nodes(data=True):
            task = task_data['task']

            for dep in task.dependencies:
                if dep.task_id not in all_task_ids:
                    errors.append(
                        ValidationError(
                            f"Task {task_id} depends on unknown task: {dep.task_id}"
                        )
                    )

        # 3. ë„ë‹¬ ë¶ˆê°€ëŠ¥í•œ íƒœìŠ¤í¬ ê²€ì‚¬
        if dep_graph.number_of_nodes() > 0:
            # ì‹œì‘ ë…¸ë“œ ì°¾ê¸° (ì˜ì¡´ì„±ì´ ì—†ëŠ” ë…¸ë“œ)
            start_nodes = [
                n for n in dep_graph.nodes()
                if dep_graph.in_degree(n) == 0
            ]

            if not start_nodes:
                warnings.append(
                    ValidationWarning(
                        "No start tasks found (all tasks have dependencies)"
                    )
                )
            else:
                # ë„ë‹¬ ê°€ëŠ¥í•œ ë…¸ë“œ ì°¾ê¸°
                reachable = set()
                for start in start_nodes:
                    reachable.update(
                        nx.descendants(dep_graph, start)
                    )
                reachable.update(start_nodes)

                # ë„ë‹¬ ë¶ˆê°€ëŠ¥í•œ ë…¸ë“œ
                unreachable = all_task_ids - reachable
                if unreachable:
                    warnings.append(
                        ValidationWarning(
                            f"Unreachable tasks: {unreachable}"
                        )
                    )

        return DependencyValidationResult(errors, warnings)
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] êµ¬ì¡°ì  ê²€ì¦ (í•„ìˆ˜ í•„ë“œ, í˜•ì‹)
- [ ] íƒœìŠ¤í¬ ê²€ì¦ (ID ì¤‘ë³µ, íƒ€ì…)
- [ ] ì˜ì¡´ì„± ê²€ì¦ (ìˆœí™˜, ë¯¸í•´ê²°)
- [ ] í‘œí˜„ì‹ ë° ë§¤í•‘ ê²€ì¦

#### SubTask 5.2.3: ì‹¤í–‰ ìŠ¤ì¼€ì¤„ëŸ¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/workflow/task_scheduler.py
from typing import Dict, List, Set, Optional, Any
import asyncio
from datetime import datetime
from collections import deque

class TaskScheduler:
    """íƒœìŠ¤í¬ ì‹¤í–‰ ìŠ¤ì¼€ì¤„ëŸ¬"""

    def __init__(
        self,
        agent_registry: AgentRegistry,
        max_concurrent_tasks: int = 100
    ):
        self.agent_registry = agent_registry
        self.max_concurrent_tasks = max_concurrent_tasks

        # ì‹¤í–‰ í
        self.ready_queue = asyncio.Queue()
        self.running_tasks: Dict[str, asyncio.Task] = {}
        self.completed_tasks: Set[str] = set()

        # ë™ê¸°í™”
        self.task_semaphore = asyncio.Semaphore(max_concurrent_tasks)
        self.scheduler_lock = asyncio.Lock()

    async def schedule_workflow(
        self,
        execution: WorkflowExecution,
        workflow_def: WorkflowDefinition
    ) -> None:
        """ì›Œí¬í”Œë¡œìš° ìŠ¤ì¼€ì¤„ë§"""
        # íƒœìŠ¤í¬ ì˜ì¡´ì„± ë¶„ì„
        task_graph = self._build_task_graph(workflow_def.tasks)

        # ì´ˆê¸° ì‹¤í–‰ ê°€ëŠ¥ íƒœìŠ¤í¬ ì°¾ê¸°
        ready_tasks = self._find_ready_tasks(
            task_graph,
            set(),
            execution.context
        )

        # ì¤€ë¹„ëœ íƒœìŠ¤í¬ íì— ì¶”ê°€
        for task_id in ready_tasks:
            await self.ready_queue.put(task_id)

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
        await self._run_scheduler(execution, task_graph)

    async def _run_scheduler(
        self,
        execution: WorkflowExecution,
        task_graph: TaskGraph
    ) -> None:
        """ìŠ¤ì¼€ì¤„ëŸ¬ ë©”ì¸ ë£¨í”„"""
        while True:
            # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
            if self._is_workflow_complete(execution, task_graph):
                break

            # ì¤€ë¹„ëœ íƒœìŠ¤í¬ ê°€ì ¸ì˜¤ê¸°
            try:
                task_id = await asyncio.wait_for(
                    self.ready_queue.get(),
                    timeout=1.0
                )
            except asyncio.TimeoutError:
                # ë°ë“œë½ ê°ì§€
                if self._detect_deadlock(execution, task_graph):
                    raise WorkflowDeadlockError("Workflow deadlock detected")
                continue

            # íƒœìŠ¤í¬ ì‹¤í–‰
            await self._execute_task(task_id, execution, task_graph)

    async def _execute_task(
        self,
        task_id: str,
        execution: WorkflowExecution,
        task_graph: TaskGraph
    ) -> None:
        """ê°œë³„ íƒœìŠ¤í¬ ì‹¤í–‰"""
        task = execution.tasks[task_id]

        async with self.task_semaphore:
            try:
                # íƒœìŠ¤í¬ ìƒíƒœ ì—…ë°ì´íŠ¸
                task.status = TaskState.RUNNING
                task.started_at = datetime.utcnow()

                # ì—ì´ì „íŠ¸ í”„ë¡ì‹œ ê°€ì ¸ì˜¤ê¸°
                agent_proxy = await self.agent_registry.get_agent(
                    task.agent_type
                )

                # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
                input_data = self._prepare_task_input(
                    task,
                    execution.context
                )

                # íƒœìŠ¤í¬ ì‹¤í–‰
                execution_task = asyncio.create_task(
                    self._run_task_with_timeout(
                        agent_proxy,
                        task,
                        input_data
                    )
                )

                async with self.scheduler_lock:
                    self.running_tasks[task_id] = execution_task

                # ê²°ê³¼ ëŒ€ê¸°
                result = await execution_task

                # ì„±ê³µ ì²˜ë¦¬
                await self._handle_task_success(
                    task_id,
                    result,
                    execution,
                    task_graph
                )

            except asyncio.TimeoutError:
                await self._handle_task_timeout(task_id, execution)
            except Exception as e:
                await self._handle_task_failure(task_id, e, execution)
            finally:
                async with self.scheduler_lock:
                    self.running_tasks.pop(task_id, None)

    async def _run_task_with_timeout(
        self,
        agent_proxy: AgentInterface,
        task: AgentTask,
        input_data: Dict[str, Any]
    ) -> Any:
        """íƒ€ì„ì•„ì›ƒì´ ìˆëŠ” íƒœìŠ¤í¬ ì‹¤í–‰"""
        return await asyncio.wait_for(
            agent_proxy.execute(task),
            timeout=task.timeout_seconds
        )

    async def _handle_task_success(
        self,
        task_id: str,
        result: Any,
        execution: WorkflowExecution,
        task_graph: TaskGraph
    ) -> None:
        """íƒœìŠ¤í¬ ì„±ê³µ ì²˜ë¦¬"""
        task = execution.tasks[task_id]

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        task.status = TaskState.COMPLETED
        task.completed_at = datetime.utcnow()
        task.result = result

        # ì¶œë ¥ ë§¤í•‘
        self._apply_output_mapping(task, result, execution.context)

        # ì™„ë£Œ íƒœìŠ¤í¬ ì¶”ê°€
        async with self.scheduler_lock:
            self.completed_tasks.add(task_id)

        # ë‹¤ìŒ ì‹¤í–‰ ê°€ëŠ¥ íƒœìŠ¤í¬ ì°¾ê¸°
        next_tasks = self._find_ready_tasks(
            task_graph,
            self.completed_tasks,
            execution.context
        )

        # ì¤€ë¹„ëœ íƒœìŠ¤í¬ íì— ì¶”ê°€
        for next_task_id in next_tasks:
            await self.ready_queue.put(next_task_id)

    def _prepare_task_input(
        self,
        task: WorkflowTask,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """íƒœìŠ¤í¬ ì…ë ¥ ë°ì´í„° ì¤€ë¹„"""
        input_data = {}

        for target_key, source_path in task.input_mapping.items():
            # JSONPath ë˜ëŠ” ë‹¨ìˆœ í‚¤ë¡œ ê°’ ì¶”ì¶œ
            value = self._extract_value(context, source_path)
            input_data[target_key] = value

        return input_data

    def _apply_output_mapping(
        self,
        task: WorkflowTask,
        result: Any,
        context: Dict[str, Any]
    ) -> None:
        """íƒœìŠ¤í¬ ì¶œë ¥ ë§¤í•‘ ì ìš©"""
        for source_key, target_path in task.output_mapping.items():
            # ê²°ê³¼ì—ì„œ ê°’ ì¶”ì¶œ
            if isinstance(result, dict):
                value = result.get(source_key)
            else:
                value = result

            # ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
            self._set_value(context, target_path, value)
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] íƒœìŠ¤í¬ ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜
- [ ] ë™ì‹œ ì‹¤í–‰ ì œì–´
- [ ] ì˜ì¡´ì„± ê¸°ë°˜ ì‹¤í–‰ ìˆœì„œ
- [ ] ë°ë“œë½ ê°ì§€ ë° ì²˜ë¦¬

#### SubTask 5.2.4: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ëª¨ë‹ˆí„°

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/workflow/execution_monitor.py
from typing import Dict, List, Optional, Any
import asyncio
from datetime import datetime, timedelta

@dataclass
class WorkflowMetrics:
    workflow_id: str
    execution_id: str
    start_time: datetime
    end_time: Optional[datetime]
    total_tasks: int
    completed_tasks: int
    failed_tasks: int
    running_tasks: int
    average_task_duration: float
    total_duration: Optional[float]
    resource_usage: Dict[str, Any]

class ExecutionMonitor:
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ëª¨ë‹ˆí„°"""

    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        self.active_executions: Dict[str, WorkflowMetrics] = {}
        self.metrics_store = MetricsStore()
        self.alert_manager = AlertManager()

        # ëª¨ë‹ˆí„°ë§ ì„¤ì •
        self.monitoring_interval = 5  # seconds
        self.monitoring_task = None

    async def start(self):
        """ëª¨ë‹ˆí„° ì‹œì‘"""
        # ì´ë²¤íŠ¸ êµ¬ë…
        self.event_bus.subscribe("workflow.started", self._on_workflow_started)
        self.event_bus.subscribe("workflow.completed", self._on_workflow_completed)
        self.event_bus.subscribe("workflow.failed", self._on_workflow_failed)
        self.event_bus.subscribe("task.started", self._on_task_started)
        self.event_bus.subscribe("task.completed", self._on_task_completed)
        self.event_bus.subscribe("task.failed", self._on_task_failed)

        # ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì‹œì‘
        self.monitoring_task = asyncio.create_task(self._monitoring_loop())

    async def stop(self):
        """ëª¨ë‹ˆí„° ì¤‘ì§€"""
        if self.monitoring_task:
            self.monitoring_task.cancel()

    async def get_execution_status(
        self,
        execution_id: str
    ) -> Optional[WorkflowMetrics]:
        """ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ"""
        return self.active_executions.get(execution_id)

    async def get_execution_history(
        self,
        workflow_id: str,
        limit: int = 10
    ) -> List[WorkflowMetrics]:
        """ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ"""
        return await self.metrics_store.get_workflow_history(
            workflow_id,
            limit
        )

    async def _monitoring_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while True:
            try:
                await asyncio.sleep(self.monitoring_interval)

                # í™œì„± ì‹¤í–‰ ëª¨ë‹ˆí„°ë§
                for execution_id, metrics in self.active_executions.items():
                    await self._monitor_execution(execution_id, metrics)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Monitoring error: {e}")

    async def _monitor_execution(
        self,
        execution_id: str,
        metrics: WorkflowMetrics
    ):
        """ê°œë³„ ì‹¤í–‰ ëª¨ë‹ˆí„°ë§"""
        # ì‹¤í–‰ ì‹œê°„ í™•ì¸
        elapsed_time = (datetime.utcnow() - metrics.start_time).total_seconds()

        # SLA ìœ„ë°˜ í™•ì¸
        sla_config = await self._get_sla_config(metrics.workflow_id)
        if sla_config:
            if elapsed_time > sla_config.max_duration:
                await self.alert_manager.send_alert(
                    AlertType.SLA_VIOLATION,
                    {
                        "execution_id": execution_id,
                        "elapsed_time": elapsed_time,
                        "max_duration": sla_config.max_duration
                    }
                )

        # ì •ì²´ íƒœìŠ¤í¬ í™•ì¸
        stalled_tasks = await self._find_stalled_tasks(execution_id)
        if stalled_tasks:
            await self.alert_manager.send_alert(
                AlertType.STALLED_TASKS,
                {
                    "execution_id": execution_id,
                    "stalled_tasks": stalled_tasks
                }
            )

        # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
        resource_usage = await self._get_resource_usage(execution_id)
        metrics.resource_usage = resource_usage

        # ë©”íŠ¸ë¦­ ì €ì¥
        await self.metrics_store.save_metrics(metrics)

    async def _on_workflow_started(self, event: OrchestratorEvent):
        """ì›Œí¬í”Œë¡œìš° ì‹œì‘ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        metrics = WorkflowMetrics(
            workflow_id=event.data["workflow_def_id"],
            execution_id=event.workflow_id,
            start_time=event.timestamp,
            end_time=None,
            total_tasks=event.data.get("total_tasks", 0),
            completed_tasks=0,
            failed_tasks=0,
            running_tasks=0,
            average_task_duration=0.0,
            total_duration=None,
            resource_usage={}
        )

        self.active_executions[event.workflow_id] = metrics

    async def _on_workflow_completed(self, event: OrchestratorEvent):
        """ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        if event.workflow_id in self.active_executions:
            metrics = self.active_executions[event.workflow_id]
            metrics.end_time = event.timestamp
            metrics.total_duration = (
                metrics.end_time - metrics.start_time
            ).total_seconds()

            # ìµœì¢… ë©”íŠ¸ë¦­ ì €ì¥
            await self.metrics_store.save_final_metrics(metrics)

            # í™œì„± ì‹¤í–‰ì—ì„œ ì œê±°
            del self.active_executions[event.workflow_id]
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì‹¤ì‹œê°„ ì‹¤í–‰ ëª¨ë‹ˆí„°ë§
- [ ] ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥
- [ ] SLA ëª¨ë‹ˆí„°ë§
- [ ] ì•Œë¦¼ ì‹œìŠ¤í…œ í†µí•©

### Task 5.3: ì—ì´ì „íŠ¸ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬

#### SubTask 5.3.1: ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/agent/agent_registry.py
from typing import Dict, List, Optional, Set
import asyncio
from datetime import datetime

class AgentRegistry:
    """ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬"""

    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        self.agents: Dict[str, AgentInfo] = {}
        self.agent_proxies: Dict[str, AgentInterface] = {}
        self.agent_capabilities: Dict[str, List[AgentCapability]] = {}

        # ë™ê¸°í™”
        self.registry_lock = asyncio.Lock()

        # ë””ìŠ¤ì»¤ë²„ë¦¬
        self.discovery_service = AgentDiscoveryService()
        self.discovery_interval = 30  # seconds
        self.discovery_task = None

    async def initialize(self):
        """ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”"""
        # ê¸°ì¡´ ì—ì´ì „íŠ¸ ë¡œë“œ
        await self._load_registered_agents()

        # ë””ìŠ¤ì»¤ë²„ë¦¬ ì‹œì‘
        self.discovery_task = asyncio.create_task(
            self._discovery_loop()
        )

        # ì´ë²¤íŠ¸ êµ¬ë…
        self.event_bus.subscribe(
            "agent.registered",
            self._on_agent_registered
        )
        self.event_bus.subscribe(
            "agent.unregistered",
            self._on_agent_unregistered
        )

    async def register_agent(
        self,
        agent_info: AgentInfo
    ) -> str:
        """ì—ì´ì „íŠ¸ ë“±ë¡"""
        async with self.registry_lock:
            # ì¤‘ë³µ í™•ì¸
            if agent_info.id in self.agents:
                raise ValueError(f"Agent {agent_info.id} already registered")

            # ì—ì´ì „íŠ¸ ì •ë³´ ì €ì¥
            self.agents[agent_info.id] = agent_info

            # í”„ë¡ì‹œ ìƒì„±
            proxy = AgentProxyFactory.create_proxy(agent_info)
            self.agent_proxies[agent_info.id] = proxy

            # ëŠ¥ë ¥ ì¸ë±ì‹±
            self._index_capabilities(agent_info)

            # ì˜êµ¬ ì €ì¥
            await self._persist_agent(agent_info)

            # ë“±ë¡ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="agent.registered",
                    source="agent_registry",
                    timestamp=datetime.utcnow(),
                    data={"agent": agent_info.to_dict()}
                )
            )

            logger.info(f"Agent registered: {agent_info.id} ({agent_info.type})")

        return agent_info.id

    async def unregister_agent(self, agent_id: str) -> bool:
        """ì—ì´ì „íŠ¸ ë“±ë¡ í•´ì œ"""
        async with self.registry_lock:
            if agent_id not in self.agents:
                return False

            agent_info = self.agents[agent_id]

            # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ì œê±°
            del self.agents[agent_id]
            del self.agent_proxies[agent_id]

            # ëŠ¥ë ¥ ì¸ë±ìŠ¤ì—ì„œ ì œê±°
            self._remove_from_capabilities(agent_id)

            # ì˜êµ¬ ì €ì¥ì†Œì—ì„œ ì œê±°
            await self._remove_persisted_agent(agent_id)

            # ë“±ë¡ í•´ì œ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="agent.unregistered",
                    source="agent_registry",
                    timestamp=datetime.utcnow(),
                    data={"agent_id": agent_id}
                )
            )

            logger.info(f"Agent unregistered: {agent_id}")

        return True

    async def get_agent(
        self,
        agent_type: str,
        version: Optional[str] = None
    ) -> AgentInterface:
        """ì—ì´ì „íŠ¸ í”„ë¡ì‹œ ê°€ì ¸ì˜¤ê¸°"""
        candidates = []

        async with self.registry_lock:
            for agent_id, agent_info in self.agents.items():
                if agent_info.type == agent_type:
                    if version is None or agent_info.version == version:
                        if agent_info.status == "healthy":
                            candidates.append(agent_id)

        if not candidates:
            raise AgentNotFoundError(
                f"No healthy agent found for type: {agent_type}"
            )

        # ë¡œë“œ ë°¸ëŸ°ì‹± (ë¼ìš´ë“œ ë¡œë¹ˆ)
        selected_id = await self._select_agent(candidates)

        return self.agent_proxies[selected_id]

    async def find_agents_by_capability(
        self,
        capability_name: str
    ) -> List[AgentInfo]:
        """ëŠ¥ë ¥ìœ¼ë¡œ ì—ì´ì „íŠ¸ ì°¾ê¸°"""
        agent_ids = self.agent_capabilities.get(capability_name, [])

        agents = []
        async with self.registry_lock:
            for agent_id in agent_ids:
                if agent_id in self.agents:
                    agents.append(self.agents[agent_id])

        return agents

    async def get_all_agents(
        self,
        agent_type: Optional[str] = None,
        status: Optional[str] = None
    ) -> List[AgentInfo]:
        """ì „ì²´ ì—ì´ì „íŠ¸ ëª©ë¡"""
        agents = []

        async with self.registry_lock:
            for agent_info in self.agents.values():
                if agent_type and agent_info.type != agent_type:
                    continue
                if status and agent_info.status != status:
                    continue
                agents.append(agent_info)

        return agents

    def _index_capabilities(self, agent_info: AgentInfo):
        """ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ì¸ë±ì‹±"""
        for capability in agent_info.capabilities:
            if capability.name not in self.agent_capabilities:
                self.agent_capabilities[capability.name] = []
            self.agent_capabilities[capability.name].append(agent_info.id)

    async def _discovery_loop(self):
        """ì—ì´ì „íŠ¸ ë””ìŠ¤ì»¤ë²„ë¦¬ ë£¨í”„"""
        while True:
            try:
                await asyncio.sleep(self.discovery_interval)

                # ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ íƒìƒ‰
                discovered = await self.discovery_service.discover_agents()

                for agent_info in discovered:
                    if agent_info.id not in self.agents:
                        await self.register_agent(agent_info)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Discovery error: {e}")
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì—ì´ì „íŠ¸ ë“±ë¡/í•´ì œ
- [ ] ëŠ¥ë ¥ ê¸°ë°˜ ê²€ìƒ‰
- [ ] ìë™ ë””ìŠ¤ì»¤ë²„ë¦¬
- [ ] ë¡œë“œ ë°¸ëŸ°ì‹±

#### SubTask 5.3.2: ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬ ì‹œìŠ¤í…œ

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/agent/health_check.py
from typing import Dict, List, Optional
import asyncio
from datetime import datetime, timedelta

@dataclass
class HealthStatus:
    agent_id: str
    status: str  # healthy, unhealthy, degraded
    last_check: datetime
    response_time: float
    error_count: int
    consecutive_failures: int
    details: Dict[str, Any]

class HealthCheckManager:
    """ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬ ê´€ë¦¬ì"""

    def __init__(
        self,
        registry: AgentRegistry,
        event_bus: EventBus
    ):
        self.registry = registry
        self.event_bus = event_bus

        # í—¬ìŠ¤ ì²´í¬ ì„¤ì •
        self.check_interval = 10  # seconds
        self.timeout = 5  # seconds
        self.failure_threshold = 3
        self.recovery_threshold = 2

        # ìƒíƒœ ì¶”ì 
        self.health_status: Dict[str, HealthStatus] = {}
        self.check_tasks: Dict[str, asyncio.Task] = {}

    async def start(self):
        """í—¬ìŠ¤ ì²´í¬ ì‹œì‘"""
        # ëª¨ë“  ì—ì´ì „íŠ¸ì— ëŒ€í•´ í—¬ìŠ¤ ì²´í¬ ì‹œì‘
        agents = await self.registry.get_all_agents()

        for agent in agents:
            await self.start_health_check(agent.id)

    async def stop(self):
        """í—¬ìŠ¤ ì²´í¬ ì¤‘ì§€"""
        # ëª¨ë“  í—¬ìŠ¤ ì²´í¬ íƒœìŠ¤í¬ ì·¨ì†Œ
        for task in self.check_tasks.values():
            task.cancel()

    async def start_health_check(self, agent_id: str):
        """íŠ¹ì • ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬ ì‹œì‘"""
        if agent_id in self.check_tasks:
            return

        # ì´ˆê¸° ìƒíƒœ
        self.health_status[agent_id] = HealthStatus(
            agent_id=agent_id,
            status="unknown",
            last_check=datetime.utcnow(),
            response_time=0.0,
            error_count=0,
            consecutive_failures=0,
            details={}
        )

        # í—¬ìŠ¤ ì²´í¬ íƒœìŠ¤í¬ ì‹œì‘
        task = asyncio.create_task(
            self._health_check_loop(agent_id)
        )
        self.check_tasks[agent_id] = task

    async def stop_health_check(self, agent_id: str):
        """íŠ¹ì • ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬ ì¤‘ì§€"""
        if agent_id in self.check_tasks:
            self.check_tasks[agent_id].cancel()
            del self.check_tasks[agent_id]
            del self.health_status[agent_id]

    async def _health_check_loop(self, agent_id: str):
        """í—¬ìŠ¤ ì²´í¬ ë£¨í”„"""
        while True:
            try:
                await asyncio.sleep(self.check_interval)
                await self._perform_health_check(agent_id)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Health check loop error for {agent_id}: {e}")

    async def _perform_health_check(self, agent_id: str):
        """í—¬ìŠ¤ ì²´í¬ ìˆ˜í–‰"""
        agent_info = self.registry.agents.get(agent_id)
        if not agent_info:
            return

        proxy = self.registry.agent_proxies.get(agent_id)
        if not proxy:
            return

        status = self.health_status[agent_id]
        start_time = datetime.utcnow()

        try:
            # í—¬ìŠ¤ ì²´í¬ í˜¸ì¶œ
            result = await asyncio.wait_for(
                proxy.health_check(),
                timeout=self.timeout
            )

            # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
            response_time = (datetime.utcnow() - start_time).total_seconds()

            # ìƒíƒœ ì—…ë°ì´íŠ¸
            status.last_check = datetime.utcnow()
            status.response_time = response_time
            status.details = result

            # í—¬ìŠ¤ ìƒíƒœ ê²°ì •
            if result.get("status") == "healthy":
                await self._handle_healthy_response(agent_id, status)
            else:
                await self._handle_unhealthy_response(agent_id, status, result)

        except asyncio.TimeoutError:
            await self._handle_timeout(agent_id, status)
        except Exception as e:
            await self._handle_error(agent_id, status, e)

    async def _handle_healthy_response(
        self,
        agent_id: str,
        status: HealthStatus
    ):
        """ì •ìƒ ì‘ë‹µ ì²˜ë¦¬"""
        previous_status = status.status

        if status.consecutive_failures > 0:
            # ë³µêµ¬ ì¤‘
            status.consecutive_failures = 0
            status.error_count = max(0, status.error_count - 1)

            if status.error_count <= self.recovery_threshold:
                status.status = "healthy"

                # ë³µêµ¬ ì´ë²¤íŠ¸
                if previous_status != "healthy":
                    await self._emit_health_event(
                        agent_id,
                        "agent.recovered",
                        status
                    )
        else:
            status.status = "healthy"

        # ì—ì´ì „íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
        await self._update_agent_status(agent_id, "healthy")

    async def _handle_unhealthy_response(
        self,
        agent_id: str,
        status: HealthStatus,
        result: Dict[str, Any]
    ):
        """ë¹„ì •ìƒ ì‘ë‹µ ì²˜ë¦¬"""
        status.consecutive_failures += 1
        status.error_count += 1

        if status.consecutive_failures >= self.failure_threshold:
            status.status = "unhealthy"
            await self._update_agent_status(agent_id, "unhealthy")

            # ì¥ì•  ì´ë²¤íŠ¸
            await self._emit_health_event(
                agent_id,
                "agent.unhealthy",
                status
            )
        else:
            status.status = "degraded"
            await self._update_agent_status(agent_id, "degraded")
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì£¼ê¸°ì  í—¬ìŠ¤ ì²´í¬
- [ ] ì¥ì•  ê°ì§€ ë° ë³µêµ¬
- [ ] ìƒíƒœ ì „ì´ ê´€ë¦¬
- [ ] ì´ë²¤íŠ¸ ë°œí–‰

#### SubTask 5.3.3: ë™ì  ì—ì´ì „íŠ¸ ìŠ¤ì¼€ì¼ë§

**ë‹´ë‹¹ì**: ì¸í”„ë¼ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/agent/auto_scaling.py
from typing import Dict, List, Optional
import asyncio
from datetime import datetime, timedelta

@dataclass
class ScalingPolicy:
    agent_type: str
    min_instances: int
    max_instances: int
    target_cpu_percent: float
    target_memory_percent: float
    target_queue_depth: int
    scale_up_threshold: float
    scale_down_threshold: float
    cooldown_seconds: int

@dataclass
class ScalingDecision:
    agent_type: str
    current_instances: int
    desired_instances: int
    reason: str
    metrics: Dict[str, float]

class AutoScaler:
    """ì—ì´ì „íŠ¸ ìë™ ìŠ¤ì¼€ì¼ë§"""

    def __init__(
        self,
        registry: AgentRegistry,
        metrics_collector: MetricsCollector,
        infrastructure_manager: InfrastructureManager
    ):
        self.registry = registry
        self.metrics_collector = metrics_collector
        self.infrastructure = infrastructure_manager

        # ìŠ¤ì¼€ì¼ë§ ì •ì±…
        self.policies: Dict[str, ScalingPolicy] = {}

        # ìŠ¤ì¼€ì¼ë§ ìƒíƒœ
        self.last_scaling: Dict[str, datetime] = {}
        self.scaling_lock = asyncio.Lock()

        # ëª¨ë‹ˆí„°ë§
        self.check_interval = 30  # seconds
        self.monitoring_task = None

    async def start(self):
        """ìë™ ìŠ¤ì¼€ì¼ë§ ì‹œì‘"""
        # ì •ì±… ë¡œë“œ
        await self._load_scaling_policies()

        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self.monitoring_task = asyncio.create_task(
            self._scaling_loop()
        )

    async def stop(self):
        """ìë™ ìŠ¤ì¼€ì¼ë§ ì¤‘ì§€"""
        if self.monitoring_task:
            self.monitoring_task.cancel()

    async def set_policy(
        self,
        agent_type: str,
        policy: ScalingPolicy
    ):
        """ìŠ¤ì¼€ì¼ë§ ì •ì±… ì„¤ì •"""
        self.policies[agent_type] = policy
        await self._persist_policy(agent_type, policy)

    async def _scaling_loop(self):
        """ìŠ¤ì¼€ì¼ë§ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while True:
            try:
                await asyncio.sleep(self.check_interval)

                # ê° ì—ì´ì „íŠ¸ íƒ€ì…ë³„ í™•ì¸
                for agent_type, policy in self.policies.items():
                    await self._check_and_scale(agent_type, policy)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Scaling loop error: {e}")

    async def _check_and_scale(
        self,
        agent_type: str,
        policy: ScalingPolicy
    ):
        """ìŠ¤ì¼€ì¼ë§ í•„ìš”ì„± í™•ì¸ ë° ì‹¤í–‰"""
        # ì¿¨ë‹¤ìš´ í™•ì¸
        if not self._is_cooldown_expired(agent_type, policy):
            return

        # í˜„ì¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        metrics = await self._collect_metrics(agent_type)

        # í˜„ì¬ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜
        current_instances = await self._count_instances(agent_type)

        # ìŠ¤ì¼€ì¼ë§ ê²°ì •
        decision = self._make_scaling_decision(
            policy,
            current_instances,
            metrics
        )

        # ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰
        if decision.desired_instances != current_instances:
            await self._execute_scaling(decision)

    async def _collect_metrics(
        self,
        agent_type: str
    ) -> Dict[str, float]:
        """ì—ì´ì „íŠ¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        agents = await self.registry.get_all_agents(
            agent_type=agent_type,
            status="healthy"
        )

        if not agents:
            return {}

        # ì§‘ê³„ ë©”íŠ¸ë¦­
        total_cpu = 0.0
        total_memory = 0.0
        total_queue_depth = 0

        for agent in agents:
            agent_metrics = await self.metrics_collector.get_agent_metrics(
                agent.id
            )

            total_cpu += agent_metrics.get("cpu_percent", 0)
            total_memory += agent_metrics.get("memory_percent", 0)
            total_queue_depth += agent_metrics.get("queue_depth", 0)

        # í‰ê·  ê³„ì‚°
        avg_cpu = total_cpu / len(agents)
        avg_memory = total_memory / len(agents)

        return {
            "cpu_percent": avg_cpu,
            "memory_percent": avg_memory,
            "queue_depth": total_queue_depth,
            "instance_count": len(agents)
        }

    def _make_scaling_decision(
        self,
        policy: ScalingPolicy,
        current_instances: int,
        metrics: Dict[str, float]
    ) -> ScalingDecision:
        """ìŠ¤ì¼€ì¼ë§ ê²°ì •"""
        desired_instances = current_instances
        reason = "No scaling needed"

        # CPU ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
        if metrics.get("cpu_percent", 0) > policy.scale_up_threshold:
            desired_instances = min(
                current_instances + 1,
                policy.max_instances
            )
            reason = f"High CPU usage: {metrics['cpu_percent']:.1f}%"

        elif metrics.get("cpu_percent", 100) < policy.scale_down_threshold:
            if current_instances > policy.min_instances:
                desired_instances = current_instances - 1
                reason = f"Low CPU usage: {metrics['cpu_percent']:.1f}%"

        # í ê¹Šì´ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
        queue_depth = metrics.get("queue_depth", 0)
        if queue_depth > policy.target_queue_depth * 1.5:
            desired_instances = min(
                current_instances + 1,
                policy.max_instances
            )
            reason = f"High queue depth: {queue_depth}"

        return ScalingDecision(
            agent_type=policy.agent_type,
            current_instances=current_instances,
            desired_instances=desired_instances,
            reason=reason,
            metrics=metrics
        )

    async def _execute_scaling(self, decision: ScalingDecision):
        """ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰"""
        async with self.scaling_lock:
            diff = decision.desired_instances - decision.current_instances

            if diff > 0:
                # ìŠ¤ì¼€ì¼ ì—…
                await self._scale_up(decision.agent_type, diff)
            else:
                # ìŠ¤ì¼€ì¼ ë‹¤ìš´
                await self._scale_down(decision.agent_type, abs(diff))

            # ë§ˆì§€ë§‰ ìŠ¤ì¼€ì¼ë§ ì‹œê°„ ê¸°ë¡
            self.last_scaling[decision.agent_type] = datetime.utcnow()

            # ìŠ¤ì¼€ì¼ë§ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="agent.scaled",
                    source="auto_scaler",
                    timestamp=datetime.utcnow(),
                    data={
                        "agent_type": decision.agent_type,
                        "from_instances": decision.current_instances,
                        "to_instances": decision.desired_instances,
                        "reason": decision.reason
                    }
                )
            )
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ë©”íŠ¸ë¦­ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
- [ ] ì •ì±… ê´€ë¦¬
- [ ] ì¿¨ë‹¤ìš´ ë©”ì»¤ë‹ˆì¦˜
- [ ] ì¸í”„ë¼ í†µí•©

#### SubTask 5.3.4: ì—ì´ì „íŠ¸ ë²„ì „ ê´€ë¦¬

**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/agent/version_manager.py
from typing import Dict, List, Optional, Tuple
import asyncio
from datetime import datetime
import semver

@dataclass
class AgentVersion:
    agent_type: str
    version: str
    release_date: datetime
    changelog: str
    compatibility: Dict[str, str]  # dependency -> version
    deprecated: bool = False
    end_of_life: Optional[datetime] = None

@dataclass
class DeploymentStrategy:
    strategy_type: str  # canary, blue-green, rolling
    canary_percent: Optional[int] = None
    rollback_threshold: Optional[float] = None
    health_check_interval: int = 30

class VersionManager:
    """ì—ì´ì „íŠ¸ ë²„ì „ ê´€ë¦¬"""

    def __init__(
        self,
        registry: AgentRegistry,
        deployment_manager: DeploymentManager
    ):
        self.registry = registry
        self.deployment_manager = deployment_manager

        # ë²„ì „ ì •ë³´
        self.versions: Dict[str, List[AgentVersion]] = {}
        self.active_deployments: Dict[str, DeploymentStatus] = {}

        # ë™ê¸°í™”
        self.deployment_lock = asyncio.Lock()

    async def register_version(
        self,
        agent_type: str,
        version: AgentVersion
    ):
        """ìƒˆ ë²„ì „ ë“±ë¡"""
        if agent_type not in self.versions:
            self.versions[agent_type] = []

        # ë²„ì „ ìœ íš¨ì„± ê²€ì¦
        self._validate_version(version)

        # í˜¸í™˜ì„± í™•ì¸
        await self._check_compatibility(agent_type, version)

        # ë²„ì „ ì¶”ê°€
        self.versions[agent_type].append(version)
        self.versions[agent_type].sort(
            key=lambda v: semver.VersionInfo.parse(v.version),
            reverse=True
        )

        logger.info(
            f"Registered version {version.version} for {agent_type}"
        )

    async def deploy_version(
        self,
        agent_type: str,
        target_version: str,
        strategy: DeploymentStrategy
    ) -> str:
        """ë²„ì „ ë°°í¬"""
        async with self.deployment_lock:
            # í˜„ì¬ ë²„ì „ í™•ì¸
            current_version = await self._get_current_version(agent_type)

            if current_version == target_version:
                raise ValueError("Target version is already deployed")

            # ë°°í¬ ê³„íš ìƒì„±
            deployment_plan = await self._create_deployment_plan(
                agent_type,
                current_version,
                target_version,
                strategy
            )

            # ë°°í¬ ì‹¤í–‰
            deployment_id = await self._execute_deployment(
                deployment_plan
            )

            return deployment_id

    async def rollback_version(
        self,
        agent_type: str,
        target_version: Optional[str] = None
    ):
        """ë²„ì „ ë¡¤ë°±"""
        async with self.deployment_lock:
            # ì´ì „ ì•ˆì • ë²„ì „ ì°¾ê¸°
            if not target_version:
                target_version = await self._find_last_stable_version(
                    agent_type
                )

            if not target_version:
                raise ValueError("No stable version found for rollback")

            # ë¡¤ë°± ì‹¤í–‰
            await self._execute_rollback(agent_type, target_version)

    async def _create_deployment_plan(
        self,
        agent_type: str,
        current_version: str,
        target_version: str,
        strategy: DeploymentStrategy
    ) -> DeploymentPlan:
        """ë°°í¬ ê³„íš ìƒì„±"""
        plan = DeploymentPlan(
            agent_type=agent_type,
            from_version=current_version,
            to_version=target_version,
            strategy=strategy,
            steps=[]
        )

        if strategy.strategy_type == "canary":
            plan.steps = self._create_canary_steps(
                agent_type,
                target_version,
                strategy.canary_percent
            )
        elif strategy.strategy_type == "blue-green":
            plan.steps = self._create_blue_green_steps(
                agent_type,
                target_version
            )
        elif strategy.strategy_type == "rolling":
            plan.steps = self._create_rolling_steps(
                agent_type,
                target_version
            )

        return plan

    def _create_canary_steps(
        self,
        agent_type: str,
        target_version: str,
        canary_percent: int
    ) -> List[DeploymentStep]:
        """ì¹´ë‚˜ë¦¬ ë°°í¬ ë‹¨ê³„ ìƒì„±"""
        return [
            DeploymentStep(
                name="Deploy canary instances",
                action="deploy_percent",
                parameters={
                    "version": target_version,
                    "percent": canary_percent
                }
            ),
            DeploymentStep(
                name="Monitor canary health",
                action="monitor",
                parameters={
                    "duration_seconds": 300,
                    "metrics": ["error_rate", "response_time"]
                }
            ),
            DeploymentStep(
                name="Evaluate canary",
                action="evaluate",
                parameters={
                    "threshold": 0.95,
                    "rollback_on_failure": True
                }
            ),
            DeploymentStep(
                name="Promote canary",
                action="promote",
                parameters={
                    "version": target_version
                }
            )
        ]

    async def _check_version_health(
        self,
        agent_type: str,
        version: str
    ) -> VersionHealth:
        """ë²„ì „ ê±´ê°• ìƒíƒœ í™•ì¸"""
        agents = await self.registry.get_all_agents(
            agent_type=agent_type
        )

        version_agents = [
            a for a in agents
            if a.version == version
        ]

        if not version_agents:
            return VersionHealth(
                version=version,
                healthy_count=0,
                total_count=0,
                error_rate=0.0,
                avg_response_time=0.0
            )

        # ê±´ê°•í•œ ì—ì´ì „íŠ¸ ìˆ˜
        healthy_count = len([
            a for a in version_agents
            if a.status == "healthy"
        ])

        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        total_errors = 0
        total_requests = 0
        total_response_time = 0

        for agent in version_agents:
            metrics = await self.metrics_collector.get_agent_metrics(
                agent.id,
                time_range=timedelta(minutes=5)
            )

            total_errors += metrics.get("error_count", 0)
            total_requests += metrics.get("request_count", 0)
            total_response_time += metrics.get("total_response_time", 0)

        error_rate = total_errors / total_requests if total_requests > 0 else 0
        avg_response_time = total_response_time / total_requests if total_requests > 0 else 0

        return VersionHealth(
            version=version,
            healthy_count=healthy_count,
            total_count=len(version_agents),
            error_rate=error_rate,
            avg_response_time=avg_response_time
        )
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ë²„ì „ ë“±ë¡ ë° ê´€ë¦¬
- [ ] ë°°í¬ ì „ëµ êµ¬í˜„ (Canary/Blue-Green/Rolling)
- [ ] ë²„ì „ í˜¸í™˜ì„± ê²€ì¦
- [ ] ë¡¤ë°± ë©”ì»¤ë‹ˆì¦˜

---

# Phase 5: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ - Tasks 5.4~5.6 SubTask êµ¬ì¡°

## ğŸ“‹ Task 5.4~5.6 SubTask ë¦¬ìŠ¤íŠ¸

### Task 5.4: ì›Œí¬í”Œë¡œìš° ì •ì˜ ì–¸ì–´ (DSL) êµ¬í˜„

- **SubTask 5.4.1**: DSL ë¬¸ë²• ì„¤ê³„ ë° ëª…ì„¸
- **SubTask 5.4.2**: DSL íŒŒì„œ ë° ì»´íŒŒì¼ëŸ¬ êµ¬í˜„
- **SubTask 5.4.3**: DSL ê²€ì¦ê¸° ë° íƒ€ì… ì‹œìŠ¤í…œ
- **SubTask 5.4.4**: DSL IDE ì§€ì› ë° ë„êµ¬

### Task 5.5: ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ìˆ˜ì •

- **SubTask 5.5.1**: ëŸ°íƒ€ì„ ì›Œí¬í”Œë¡œìš° ë¹Œë”
- **SubTask 5.5.2**: ì›Œí¬í”Œë¡œìš° ìˆ˜ì • API
- **SubTask 5.5.3**: ë™ì  ë¶„ê¸° ë° ì¡°ê±´ë¶€ ì‹¤í–‰
- **SubTask 5.5.4**: ì›Œí¬í”Œë¡œìš° ë²„ì „ ê´€ë¦¬

### Task 5.6: ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ë° ì¬ì‚¬ìš© ì‹œìŠ¤í…œ

- **SubTask 5.6.1**: í…œí”Œë¦¿ ì €ì¥ì†Œ êµ¬ì¶•
- **SubTask 5.6.2**: í…œí”Œë¦¿ íŒŒë¼ë¯¸í„°í™” ì‹œìŠ¤í…œ
- **SubTask 5.6.3**: í…œí”Œë¦¿ ìƒì† ë° í™•ì¥ ë©”ì»¤ë‹ˆì¦˜
- **SubTask 5.6.4**: í…œí”Œë¦¿ ê³µìœ  ë§ˆì¼“í”Œë ˆì´ìŠ¤

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 5.4: ì›Œí¬í”Œë¡œìš° ì •ì˜ ì–¸ì–´ (DSL) êµ¬í˜„

#### SubTask 5.4.1: DSL ë¬¸ë²• ì„¤ê³„ ë° ëª…ì„¸

**ë‹´ë‹¹ì**: ì–¸ì–´ ì„¤ê³„ ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dsl/grammar.ts
export interface DSLGrammar {
  version: string;
  keywords: string[];
  operators: string[];
  types: string[];
  builtins: string[];
}

// T-Developer Workflow DSL (TWDSL) ë¬¸ë²• ì •ì˜
export const TWDSLGrammar: DSLGrammar = {
  version: "1.0.0",
  keywords: [
    "workflow",
    "task",
    "parallel",
    "sequence",
    "if",
    "else",
    "while",
    "foreach",
    "input",
    "output",
    "depends",
    "timeout",
    "retry",
    "on_error",
    "on_success",
    "import",
    "export",
    "template",
  ],
  operators: [
    "->",
    "=>",
    "==",
    "!=",
    ">",
    "<",
    ">=",
    "<=",
    "&&",
    "||",
    "!",
    "+",
    "-",
    "*",
    "/",
    "%",
    "=",
    ".",
  ],
  types: [
    "string",
    "number",
    "boolean",
    "object",
    "array",
    "any",
    "datetime",
    "duration",
    "file",
    "url",
  ],
  builtins: [
    "env",
    "context",
    "result",
    "error",
    "retry_count",
    "current_time",
    "workflow_id",
    "task_id",
  ],
};

// DSL ì˜ˆì œ
const dslExample = `
workflow CreateFullStackApp {
  version: "1.0.0"
  description: "Full-stack application generation workflow"
  
  input {
    project_name: string
    tech_stack: {
      frontend: string
      backend: string
      database: string
    }
    features: array<string>
  }
  
  output {
    project_url: string
    documentation_url: string
    deployment_status: string
  }
  
  // ë³‘ë ¬ ì‹¤í–‰ ë¸”ë¡
  parallel {
    // Frontend ìƒì„±
    task generateFrontend {
      agent: "UISelectionAgent"
      input: {
        framework: tech_stack.frontend
        features: features.filter(f => f.startsWith("ui_"))
      }
      timeout: 5m
      retry: 3
    }
    
    // Backend ìƒì„±
    task generateBackend {
      agent: "BackendAgent"
      input: {
        framework: tech_stack.backend
        database: tech_stack.database
        features: features.filter(f => f.startsWith("api_"))
      }
      timeout: 10m
    }
  }
  
  // ìˆœì°¨ ì‹¤í–‰
  sequence {
    // í†µí•© í…ŒìŠ¤íŠ¸
    task runIntegrationTests {
      agent: "TestAgent"
      depends: [generateFrontend, generateBackend]
      input: {
        frontend_output: generateFrontend.result
        backend_output: generateBackend.result
      }
      on_error: {
        retry: 2
        fallback: skipTests
      }
    }
    
    // ì¡°ê±´ë¶€ ë°°í¬
    if (runIntegrationTests.result.passed) {
      task deployApplication {
        agent: "DeploymentAgent"
        input: {
          frontend: generateFrontend.result.build_path
          backend: generateBackend.result.build_path
        }
      }
    } else {
      task notifyFailure {
        agent: "NotificationAgent"
        input: {
          message: "Integration tests failed"
          details: runIntegrationTests.result.errors
        }
      }
    }
  }
  
  // ë°˜ë³µ ì‹¤í–‰
  foreach feature in features {
    task generateFeatureTests {
      agent: "TestGenerationAgent"
      input: {
        feature_name: feature
        project_context: context
      }
    }
  }
}
`;

// DSL ì–¸ì–´ ëª…ì„¸
export class DSLSpecification {
  // êµ¬ë¬¸ ê·œì¹™
  syntaxRules = {
    workflow: {
      pattern: /workflow\s+(\w+)\s*{/,
      required: ["version", "input", "output"],
      optional: ["description", "timeout", "on_error"],
    },
    task: {
      pattern: /task\s+(\w+)\s*{/,
      required: ["agent"],
      optional: [
        "input",
        "depends",
        "timeout",
        "retry",
        "on_error",
        "on_success",
      ],
    },
    parallel: {
      pattern: /parallel\s*{/,
      children: ["task", "sequence", "if", "foreach"],
    },
    sequence: {
      pattern: /sequence\s*{/,
      children: ["task", "parallel", "if", "foreach", "while"],
    },
    conditional: {
      pattern: /if\s*\((.*?)\)\s*{/,
      elseBranch: /else\s*{/,
    },
    loop: {
      foreach: /foreach\s+(\w+)\s+in\s+(.*?)\s*{/,
      while: /while\s*\((.*?)\)\s*{/,
    },
  };

  // íƒ€ì… ì‹œìŠ¤í…œ
  typeSystem = {
    primitives: ["string", "number", "boolean", "null"],
    complex: ["object", "array"],
    custom: ["datetime", "duration", "file", "url"],

    typeInference: {
      string: /^["'].*["']$/,
      number: /^-?\d+(\.\d+)?$/,
      boolean: /^(true|false)$/,
      null: /^null$/,
      array: /^\[.*\]$/,
      object: /^{.*}$/,
    },
  };

  // í‘œí˜„ì‹ í‰ê°€ ê·œì¹™
  expressionRules = {
    // ë³€ìˆ˜ ì°¸ì¡°
    variableRef: /(\w+)\.(\w+)/,

    // í•¨ìˆ˜ í˜¸ì¶œ
    functionCall: /(\w+)\((.*?)\)/,

    // ì—°ì‚°ì ìš°ì„ ìˆœìœ„
    operatorPrecedence: {
      "||": 1,
      "&&": 2,
      "==": 3,
      "!=": 3,
      ">": 4,
      "<": 4,
      ">=": 4,
      "<=": 4,
      "+": 5,
      "-": 5,
      "*": 6,
      "/": 6,
      "%": 6,
      "!": 7,
      ".": 8,
    },
  };
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì™„ì „í•œ DSL ë¬¸ë²• ëª…ì„¸
- [ ] íƒ€ì… ì‹œìŠ¤í…œ ì •ì˜
- [ ] í‘œí˜„ì‹ í‰ê°€ ê·œì¹™
- [ ] ì˜ˆì œ ë° ë¬¸ì„œí™”

#### SubTask 5.4.2: DSL íŒŒì„œ ë° ì»´íŒŒì¼ëŸ¬ êµ¬í˜„

**ë‹´ë‹¹ì**: ì»´íŒŒì¼ëŸ¬ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 20ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dsl/parser.ts
import { Lexer, Token } from "./lexer";
import { ASTNode, WorkflowAST } from "./ast";

export class DSLParser {
  private lexer: Lexer;
  private currentToken: Token;
  private position: number = 0;

  constructor(private source: string) {
    this.lexer = new Lexer(source);
  }

  // ë©”ì¸ íŒŒì‹± í•¨ìˆ˜
  parse(): WorkflowAST {
    const tokens = this.lexer.tokenize();
    this.position = 0;
    this.currentToken = tokens[0];

    const workflow = this.parseWorkflow();

    if (this.position < tokens.length - 1) {
      throw new ParseError(
        `Unexpected token: ${this.currentToken.value}`,
        this.currentToken.line,
        this.currentToken.column
      );
    }

    return workflow;
  }

  // ì›Œí¬í”Œë¡œìš° íŒŒì‹±
  private parseWorkflow(): WorkflowAST {
    this.expect("workflow");
    const name = this.expectIdentifier();
    this.expect("{");

    const workflow: WorkflowAST = {
      type: "workflow",
      name,
      version: "",
      description: "",
      input: {},
      output: {},
      body: [],
    };

    while (!this.check("}")) {
      if (this.match("version")) {
        this.expect(":");
        workflow.version = this.expectString();
      } else if (this.match("description")) {
        this.expect(":");
        workflow.description = this.expectString();
      } else if (this.match("input")) {
        workflow.input = this.parseInputOutput();
      } else if (this.match("output")) {
        workflow.output = this.parseInputOutput();
      } else {
        // ì›Œí¬í”Œë¡œìš° ë°”ë”” íŒŒì‹±
        workflow.body.push(this.parseStatement());
      }
    }

    this.expect("}");
    return workflow;
  }

  // ë¬¸ì¥ íŒŒì‹±
  private parseStatement(): ASTNode {
    if (this.match("task")) {
      return this.parseTask();
    } else if (this.match("parallel")) {
      return this.parseParallel();
    } else if (this.match("sequence")) {
      return this.parseSequence();
    } else if (this.match("if")) {
      return this.parseConditional();
    } else if (this.match("foreach")) {
      return this.parseForeach();
    } else if (this.match("while")) {
      return this.parseWhile();
    } else {
      throw new ParseError(
        `Unexpected statement: ${this.currentToken.value}`,
        this.currentToken.line,
        this.currentToken.column
      );
    }
  }

  // íƒœìŠ¤í¬ íŒŒì‹±
  private parseTask(): ASTNode {
    const name = this.expectIdentifier();
    this.expect("{");

    const task: TaskAST = {
      type: "task",
      name,
      agent: "",
      input: {},
      depends: [],
      timeout: null,
      retry: null,
      onError: null,
      onSuccess: null,
    };

    while (!this.check("}")) {
      if (this.match("agent")) {
        this.expect(":");
        task.agent = this.expectString();
      } else if (this.match("input")) {
        this.expect(":");
        task.input = this.parseExpression();
      } else if (this.match("depends")) {
        this.expect(":");
        task.depends = this.parseArray();
      } else if (this.match("timeout")) {
        this.expect(":");
        task.timeout = this.parseDuration();
      } else if (this.match("retry")) {
        this.expect(":");
        task.retry = this.expectNumber();
      } else if (this.match("on_error")) {
        task.onError = this.parseErrorHandler();
      } else if (this.match("on_success")) {
        task.onSuccess = this.parseSuccessHandler();
      }
    }

    this.expect("}");
    return task;
  }

  // í‘œí˜„ì‹ íŒŒì‹±
  private parseExpression(): ASTNode {
    return this.parseOrExpression();
  }

  private parseOrExpression(): ASTNode {
    let left = this.parseAndExpression();

    while (this.match("||")) {
      const operator = this.previous();
      const right = this.parseAndExpression();
      left = {
        type: "binary",
        operator: operator.value,
        left,
        right,
      };
    }

    return left;
  }

  // ... ì¶”ê°€ íŒŒì‹± ë©”ì„œë“œë“¤
}

// DSL ì»´íŒŒì¼ëŸ¬
export class DSLCompiler {
  constructor(private optimizer: DSLOptimizer) {}

  // ASTë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°ë¡œ ì»´íŒŒì¼
  compile(ast: WorkflowAST): CompiledWorkflow {
    // 1. ì˜ë¯¸ ë¶„ì„
    const analyzed = this.semanticAnalysis(ast);

    // 2. ìµœì í™”
    const optimized = this.optimizer.optimize(analyzed);

    // 3. ì¤‘ê°„ í‘œí˜„(IR) ìƒì„±
    const ir = this.generateIR(optimized);

    // 4. ì½”ë“œ ìƒì„±
    const code = this.generateCode(ir);

    return {
      id: this.generateWorkflowId(ast.name),
      name: ast.name,
      version: ast.version,
      compiledAt: new Date(),
      code,
      metadata: this.extractMetadata(ast),
    };
  }

  // ì˜ë¯¸ ë¶„ì„
  private semanticAnalysis(ast: WorkflowAST): AnalyzedAST {
    const analyzer = new SemanticAnalyzer();

    // íƒ€ì… ê²€ì‚¬
    analyzer.checkTypes(ast);

    // ë³€ìˆ˜ ìŠ¤ì½”í”„ ë¶„ì„
    analyzer.analyzeScopes(ast);

    // ì˜ì¡´ì„± ë¶„ì„
    analyzer.analyzeDependencies(ast);

    // ë„ë‹¬ ê°€ëŠ¥ì„± ë¶„ì„
    analyzer.checkReachability(ast);

    return analyzer.getAnalyzedAST();
  }

  // ì¤‘ê°„ í‘œí˜„ ìƒì„±
  private generateIR(ast: AnalyzedAST): IntermediateRepresentation {
    const irGenerator = new IRGenerator();

    // ê¸°ë³¸ ë¸”ë¡ ìƒì„±
    const blocks = irGenerator.createBasicBlocks(ast);

    // ì œì–´ íë¦„ ê·¸ë˜í”„ ìƒì„±
    const cfg = irGenerator.createControlFlowGraph(blocks);

    // ë°ì´í„° íë¦„ ë¶„ì„
    const dataFlow = irGenerator.analyzeDataFlow(cfg);

    return {
      blocks,
      cfg,
      dataFlow,
      symbols: irGenerator.getSymbolTable(),
    };
  }

  // ì‹¤í–‰ ì½”ë“œ ìƒì„±
  private generateCode(ir: IntermediateRepresentation): ExecutableCode {
    const codeGen = new CodeGenerator();

    // ì›Œí¬í”Œë¡œìš° ì •ì˜ ìƒì„±
    const workflowDef = codeGen.generateWorkflowDefinition(ir);

    // íƒœìŠ¤í¬ ì •ì˜ ìƒì„±
    const taskDefs = codeGen.generateTaskDefinitions(ir);

    // ëŸ°íƒ€ì„ í—¬í¼ ìƒì„±
    const helpers = codeGen.generateHelpers(ir);

    return {
      workflow: workflowDef,
      tasks: taskDefs,
      helpers,
      entryPoint: codeGen.getEntryPoint(),
    };
  }
}

// DSL ìµœì í™”ê¸°
export class DSLOptimizer {
  optimize(ast: AnalyzedAST): OptimizedAST {
    // 1. ì£½ì€ ì½”ë“œ ì œê±°
    this.removeDeadCode(ast);

    // 2. ìƒìˆ˜ í´ë”©
    this.constantFolding(ast);

    // 3. ê³µí†µ ë¶€ë¶„ì‹ ì œê±°
    this.commonSubexpressionElimination(ast);

    // 4. ë³‘ë ¬í™” ê¸°íšŒ ì‹ë³„
    this.identifyParallelization(ast);

    // 5. íƒœìŠ¤í¬ ë³‘í•©
    this.mergeCompatibleTasks(ast);

    return ast as OptimizedAST;
  }

  private removeDeadCode(ast: AnalyzedAST): void {
    // ë„ë‹¬ ë¶ˆê°€ëŠ¥í•œ íƒœìŠ¤í¬ ì œê±°
    const visitor = new ASTVisitor();

    visitor.visitWorkflow(ast, (node) => {
      if (node.type === "task" && !node.reachable) {
        // ë¶€ëª¨ ë…¸ë“œì—ì„œ ì œê±°
        this.removeNode(ast, node);
      }
    });
  }

  private identifyParallelization(ast: AnalyzedAST): void {
    // ë…ë¦½ì ì¸ íƒœìŠ¤í¬ ì°¾ê¸°
    const dependencyGraph = this.buildDependencyGraph(ast);
    const independentTasks = this.findIndependentTasks(dependencyGraph);

    // ë³‘ë ¬ ë¸”ë¡ìœ¼ë¡œ ê·¸ë£¹í™”
    for (const group of independentTasks) {
      if (group.length > 1) {
        this.wrapInParallelBlock(ast, group);
      }
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì™„ì „í•œ íŒŒì„œ êµ¬í˜„
- [ ] AST ìƒì„± ë° ë³€í™˜
- [ ] ì˜ë¯¸ ë¶„ì„ ë° íƒ€ì… ê²€ì‚¬
- [ ] ì½”ë“œ ìƒì„± ë° ìµœì í™”

#### SubTask 5.4.3: DSL ê²€ì¦ê¸° ë° íƒ€ì… ì‹œìŠ¤í…œ

**ë‹´ë‹¹ì**: íƒ€ì… ì‹œìŠ¤í…œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dsl/validator.ts
export interface ValidationResult {
  valid: boolean;
  errors: ValidationError[];
  warnings: ValidationWarning[];
  hints: ValidationHint[];
}

export class DSLValidator {
  private typeChecker: TypeChecker;
  private dependencyChecker: DependencyChecker;
  private semanticChecker: SemanticChecker;

  constructor() {
    this.typeChecker = new TypeChecker();
    this.dependencyChecker = new DependencyChecker();
    this.semanticChecker = new SemanticChecker();
  }

  async validate(source: string): Promise<ValidationResult> {
    const errors: ValidationError[] = [];
    const warnings: ValidationWarning[] = [];
    const hints: ValidationHint[] = [];

    try {
      // 1. ë ‰ì‹± ê²€ì¦
      const lexer = new Lexer(source);
      const tokens = lexer.tokenize();

      // 2. íŒŒì‹± ê²€ì¦
      const parser = new DSLParser(source);
      const ast = parser.parse();

      // 3. íƒ€ì… ê²€ì¦
      const typeErrors = await this.typeChecker.check(ast);
      errors.push(...typeErrors);

      // 4. ì˜ì¡´ì„± ê²€ì¦
      const depResult = await this.dependencyChecker.check(ast);
      errors.push(...depResult.errors);
      warnings.push(...depResult.warnings);

      // 5. ì˜ë¯¸ì  ê²€ì¦
      const semanticResult = await this.semanticChecker.check(ast);
      errors.push(...semanticResult.errors);
      warnings.push(...semanticResult.warnings);
      hints.push(...semanticResult.hints);

      // 6. ëª¨ë²” ì‚¬ë¡€ ê²€ì¦
      const bestPractices = await this.checkBestPractices(ast);
      hints.push(...bestPractices);
    } catch (e) {
      if (e instanceof ParseError) {
        errors.push({
          type: "parse_error",
          message: e.message,
          line: e.line,
          column: e.column,
          severity: "error",
        });
      } else {
        errors.push({
          type: "unknown_error",
          message: e.message,
          severity: "error",
        });
      }
    }

    return {
      valid: errors.length === 0,
      errors,
      warnings,
      hints,
    };
  }

  private async checkBestPractices(
    ast: WorkflowAST
  ): Promise<ValidationHint[]> {
    const hints: ValidationHint[] = [];

    // íƒœìŠ¤í¬ ìˆ˜ í™•ì¸
    const taskCount = this.countTasks(ast);
    if (taskCount > 50) {
      hints.push({
        type: "complexity",
        message:
          "Consider breaking down the workflow into smaller sub-workflows",
        severity: "hint",
      });
    }

    // ì¤‘ë³µ ì½”ë“œ ê°ì§€
    const duplicates = this.findDuplicatePatterns(ast);
    for (const dup of duplicates) {
      hints.push({
        type: "duplication",
        message: `Consider extracting repeated pattern into a template: ${dup.pattern}`,
        severity: "hint",
      });
    }

    return hints;
  }
}

// íƒ€ì… ì²´ì»¤
export class TypeChecker {
  private typeEnvironment: TypeEnvironment;
  private inferenceEngine: TypeInferenceEngine;

  constructor() {
    this.typeEnvironment = new TypeEnvironment();
    this.inferenceEngine = new TypeInferenceEngine();
  }

  async check(ast: WorkflowAST): Promise<ValidationError[]> {
    const errors: ValidationError[] = [];

    // ê¸€ë¡œë²Œ íƒ€ì… í™˜ê²½ ì´ˆê¸°í™”
    this.initializeGlobalTypes();

    // ì…ì¶œë ¥ íƒ€ì… ë“±ë¡
    this.registerIOTypes(ast);

    // AST ìˆœíšŒí•˜ë©° íƒ€ì… ê²€ì‚¬
    const visitor = new TypeCheckVisitor(this.typeEnvironment);

    visitor.on("type_error", (error) => {
      errors.push(error);
    });

    visitor.visit(ast);

    return errors;
  }

  private initializeGlobalTypes(): void {
    // ë‚´ì¥ íƒ€ì… ë“±ë¡
    this.typeEnvironment.registerType("string", PrimitiveType.String);
    this.typeEnvironment.registerType("number", PrimitiveType.Number);
    this.typeEnvironment.registerType("boolean", PrimitiveType.Boolean);

    // ë³µí•© íƒ€ì…
    this.typeEnvironment.registerType("array", new ArrayType());
    this.typeEnvironment.registerType("object", new ObjectType());

    // ì»¤ìŠ¤í…€ íƒ€ì…
    this.typeEnvironment.registerType("datetime", new DateTimeType());
    this.typeEnvironment.registerType("duration", new DurationType());
  }
}

// íƒ€ì… ì¶”ë¡  ì—”ì§„
export class TypeInferenceEngine {
  infer(expression: ASTNode, context: TypeContext): Type {
    switch (expression.type) {
      case "literal":
        return this.inferLiteralType(expression);

      case "identifier":
        return this.inferIdentifierType(expression, context);

      case "binary":
        return this.inferBinaryType(expression, context);

      case "function_call":
        return this.inferFunctionType(expression, context);

      case "member_access":
        return this.inferMemberType(expression, context);

      default:
        return new AnyType();
    }
  }

  private inferLiteralType(literal: LiteralNode): Type {
    if (typeof literal.value === "string") {
      return PrimitiveType.String;
    } else if (typeof literal.value === "number") {
      return PrimitiveType.Number;
    } else if (typeof literal.value === "boolean") {
      return PrimitiveType.Boolean;
    } else if (literal.value === null) {
      return new NullType();
    } else if (Array.isArray(literal.value)) {
      return new ArrayType(this.inferArrayElementType(literal.value));
    } else if (typeof literal.value === "object") {
      return this.inferObjectType(literal.value);
    }

    return new AnyType();
  }
}

// ì˜ì¡´ì„± ê²€ì‚¬ê¸°
export class DependencyChecker {
  async check(ast: WorkflowAST): Promise<DependencyCheckResult> {
    const errors: ValidationError[] = [];
    const warnings: ValidationWarning[] = [];

    // ì˜ì¡´ì„± ê·¸ë˜í”„ êµ¬ì¶•
    const depGraph = this.buildDependencyGraph(ast);

    // 1. ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
    const cycles = this.findCycles(depGraph);
    for (const cycle of cycles) {
      errors.push({
        type: "circular_dependency",
        message: `Circular dependency detected: ${cycle.join(" -> ")}`,
        severity: "error",
      });
    }

    // 2. ë¯¸í•´ê²° ì˜ì¡´ì„± ê²€ì‚¬
    const unresolved = this.findUnresolvedDependencies(ast, depGraph);
    for (const dep of unresolved) {
      errors.push({
        type: "unresolved_dependency",
        message: `Task '${dep.from}' depends on unknown task '${dep.to}'`,
        severity: "error",
      });
    }

    // 3. ë„ë‹¬ ë¶ˆê°€ëŠ¥í•œ íƒœìŠ¤í¬
    const unreachable = this.findUnreachableTasks(depGraph);
    for (const task of unreachable) {
      warnings.push({
        type: "unreachable_task",
        message: `Task '${task}' is unreachable`,
        severity: "warning",
      });
    }

    return { errors, warnings };
  }

  private buildDependencyGraph(ast: WorkflowAST): DependencyGraph {
    const graph = new DependencyGraph();

    const visitor = new DependencyVisitor();
    visitor.visit(ast, (task) => {
      graph.addNode(task.name);

      if (task.depends) {
        for (const dep of task.depends) {
          graph.addEdge(task.name, dep);
        }
      }
    });

    return graph;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì¢…í•©ì ì¸ ê²€ì¦ ì‹œìŠ¤í…œ
- [ ] íƒ€ì… ê²€ì‚¬ ë° ì¶”ë¡ 
- [ ] ì˜ì¡´ì„± ë¶„ì„
- [ ] ëª¨ë²” ì‚¬ë¡€ ê²€ì¦

#### SubTask 5.4.4: DSL IDE ì§€ì› ë° ë„êµ¬

**ë‹´ë‹¹ì**: ë„êµ¬ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dsl/language-server.ts
import {
  createConnection,
  TextDocuments,
  ProposedFeatures,
  InitializeParams,
  CompletionItem,
  CompletionItemKind,
  TextDocumentPositionParams,
  Hover,
  Definition,
} from "vscode-languageserver/node";

export class TWDSLLanguageServer {
  private connection = createConnection(ProposedFeatures.all);
  private documents = new TextDocuments(TextDocument);
  private validator = new DSLValidator();
  private completionProvider = new CompletionProvider();
  private hoverProvider = new HoverProvider();

  constructor() {
    this.setupHandlers();
  }

  private setupHandlers(): void {
    // ì´ˆê¸°í™”
    this.connection.onInitialize((params: InitializeParams) => {
      return {
        capabilities: {
          textDocumentSync: TextDocumentSyncKind.Incremental,
          completionProvider: {
            resolveProvider: true,
            triggerCharacters: [".", ":"],
          },
          hoverProvider: true,
          definitionProvider: true,
          documentFormattingProvider: true,
          codeActionProvider: true,
          signatureHelpProvider: {
            triggerCharacters: ["(", ","],
          },
        },
      };
    });

    // ìë™ ì™„ì„±
    this.connection.onCompletion(
      async (params: TextDocumentPositionParams): Promise<CompletionItem[]> => {
        const document = this.documents.get(params.textDocument.uri);
        if (!document) return [];

        return this.completionProvider.provideCompletions(
          document,
          params.position
        );
      }
    );

    // í˜¸ë²„ ì •ë³´
    this.connection.onHover(
      async (params: TextDocumentPositionParams): Promise<Hover | null> => {
        const document = this.documents.get(params.textDocument.uri);
        if (!document) return null;

        return this.hoverProvider.provideHover(document, params.position);
      }
    );

    // ë¬¸ì„œ ê²€ì¦
    this.documents.onDidChangeContent(async (change) => {
      await this.validateDocument(change.document);
    });
  }

  private async validateDocument(document: TextDocument): Promise<void> {
    const text = document.getText();
    const result = await this.validator.validate(text);

    // ì§„ë‹¨ ì •ë³´ ìƒì„±
    const diagnostics: Diagnostic[] = [];

    // ì˜¤ë¥˜
    for (const error of result.errors) {
      diagnostics.push({
        severity: DiagnosticSeverity.Error,
        range: {
          start: { line: error.line - 1, character: error.column - 1 },
          end: { line: error.line - 1, character: error.column },
        },
        message: error.message,
        source: "twdsl",
      });
    }

    // ê²½ê³ 
    for (const warning of result.warnings) {
      diagnostics.push({
        severity: DiagnosticSeverity.Warning,
        range: {
          start: { line: warning.line - 1, character: warning.column - 1 },
          end: { line: warning.line - 1, character: warning.column },
        },
        message: warning.message,
        source: "twdsl",
      });
    }

    // íŒíŠ¸
    for (const hint of result.hints) {
      diagnostics.push({
        severity: DiagnosticSeverity.Hint,
        range: {
          start: { line: hint.line - 1, character: hint.column - 1 },
          end: { line: hint.line - 1, character: hint.column },
        },
        message: hint.message,
        source: "twdsl",
      });
    }

    this.connection.sendDiagnostics({ uri: document.uri, diagnostics });
  }

  start(): void {
    this.documents.listen(this.connection);
    this.connection.listen();
  }
}

// ìë™ ì™„ì„± ì œê³µì
export class CompletionProvider {
  private keywords = TWDSLGrammar.keywords;
  private builtins = TWDSLGrammar.builtins;
  private agentTypes = [
    "NLInputAgent",
    "UISelectionAgent",
    "ParserAgent",
    "ComponentDecisionAgent",
    "MatchRateAgent",
    "SearchAgent",
    "GenerationAgent",
    "AssemblyAgent",
    "DownloadAgent",
  ];

  async provideCompletions(
    document: TextDocument,
    position: Position
  ): Promise<CompletionItem[]> {
    const context = this.getCompletionContext(document, position);
    const completions: CompletionItem[] = [];

    // ì»¨í…ìŠ¤íŠ¸ë³„ ì™„ì„± í•­ëª©
    switch (context.type) {
      case "workflow_body":
        completions.push(...this.getWorkflowBodyCompletions());
        break;

      case "task_body":
        completions.push(...this.getTaskBodyCompletions());
        break;

      case "agent_value":
        completions.push(...this.getAgentCompletions());
        break;

      case "expression":
        completions.push(...this.getExpressionCompletions(context));
        break;

      default:
        completions.push(...this.getGeneralCompletions());
    }

    return completions;
  }

  private getWorkflowBodyCompletions(): CompletionItem[] {
    return [
      {
        label: "task",
        kind: CompletionItemKind.Keyword,
        insertText: 'task ${1:taskName} {\n  agent: "${2:agentType}"\n  $0\n}',
        insertTextFormat: InsertTextFormat.Snippet,
        documentation: "Define a new task",
      },
      {
        label: "parallel",
        kind: CompletionItemKind.Keyword,
        insertText: "parallel {\n  $0\n}",
        insertTextFormat: InsertTextFormat.Snippet,
        documentation: "Execute tasks in parallel",
      },
      {
        label: "sequence",
        kind: CompletionItemKind.Keyword,
        insertText: "sequence {\n  $0\n}",
        insertTextFormat: InsertTextFormat.Snippet,
        documentation: "Execute tasks in sequence",
      },
      {
        label: "if",
        kind: CompletionItemKind.Keyword,
        insertText: "if (${1:condition}) {\n  $0\n}",
        insertTextFormat: InsertTextFormat.Snippet,
        documentation: "Conditional execution",
      },
    ];
  }

  private getAgentCompletions(): CompletionItem[] {
    return this.agentTypes.map((agent) => ({
      label: agent,
      kind: CompletionItemKind.Value,
      detail: `Agent type: ${agent}`,
      documentation: this.getAgentDocumentation(agent),
    }));
  }
}

// í¬ë§¤í„°
export class DSLFormatter {
  private indentSize: number = 2;
  private indentChar: string = " ";

  format(source: string): string {
    const parser = new DSLParser(source);
    const ast = parser.parse();

    return this.formatAST(ast, 0);
  }

  private formatAST(node: ASTNode, indent: number): string {
    const indentStr = this.indentChar.repeat(indent * this.indentSize);

    switch (node.type) {
      case "workflow":
        return this.formatWorkflow(node as WorkflowAST, indent);

      case "task":
        return this.formatTask(node as TaskAST, indent);

      case "parallel":
        return this.formatParallel(node as ParallelAST, indent);

      // ... ê¸°íƒ€ ë…¸ë“œ íƒ€ì…

      default:
        return "";
    }
  }

  private formatWorkflow(workflow: WorkflowAST, indent: number): string {
    const ind = this.getIndent(indent);
    let result = `workflow ${workflow.name} {\n`;

    result += `${ind}  version: "${workflow.version}"\n`;

    if (workflow.description) {
      result += `${ind}  description: "${workflow.description}"\n`;
    }

    result += "\n";
    result += this.formatInputOutput("input", workflow.input, indent + 1);
    result += "\n";
    result += this.formatInputOutput("output", workflow.output, indent + 1);
    result += "\n";

    for (const stmt of workflow.body) {
      result += this.formatAST(stmt, indent + 1) + "\n";
    }

    result += `${ind}}`;
    return result;
  }
}

// ë””ë²„ê±° ì§€ì›
export class DSLDebugAdapter {
  private breakpoints: Map<string, Breakpoint[]> = new Map();
  private runtime: DSLRuntime;

  async attach(workflowId: string): Promise<void> {
    this.runtime = await this.getRuntimeInstance(workflowId);

    this.runtime.on("taskStart", this.handleTaskStart.bind(this));
    this.runtime.on("taskComplete", this.handleTaskComplete.bind(this));
    this.runtime.on("breakpoint", this.handleBreakpoint.bind(this));
  }

  setBreakpoint(file: string, line: number): Breakpoint {
    const bp = new Breakpoint(file, line);

    if (!this.breakpoints.has(file)) {
      this.breakpoints.set(file, []);
    }

    this.breakpoints.get(file)!.push(bp);
    return bp;
  }

  async stepOver(): Promise<void> {
    await this.runtime.stepOver();
  }

  async stepInto(): Promise<void> {
    await this.runtime.stepInto();
  }

  async continue(): Promise<void> {
    await this.runtime.continue();
  }

  async evaluate(expression: string): Promise<any> {
    return this.runtime.evaluate(expression);
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] Language Server Protocol êµ¬í˜„
- [ ] ìë™ ì™„ì„± ê¸°ëŠ¥
- [ ] êµ¬ë¬¸ ê°•ì¡° ë° í¬ë§¤íŒ…
- [ ] ë””ë²„ê¹… ì§€ì›

### Task 5.5: ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ìˆ˜ì •

#### SubTask 5.5.1: ëŸ°íƒ€ì„ ì›Œí¬í”Œë¡œìš° ë¹Œë”

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dynamic/workflow_builder.ts
export class DynamicWorkflowBuilder {
  private workflow: WorkflowDefinition;
  private validators: WorkflowValidator[] = [];
  private optimizers: WorkflowOptimizer[] = [];

  constructor(name: string, version: string = "1.0.0") {
    this.workflow = {
      id: this.generateId(name),
      name,
      version,
      description: "",
      input_schema: {},
      output_schema: {},
      tasks: [],
      timeout_seconds: 3600,
      max_retries: 1,
      error_handlers: {},
      tags: [],
      metadata: {},
    };
  }

  // í”Œë£¨ì–¸íŠ¸ API
  description(desc: string): this {
    this.workflow.description = desc;
    return this;
  }

  input(schema: Record<string, any>): this {
    this.workflow.input_schema = schema;
    return this;
  }

  output(schema: Record<string, any>): this {
    this.workflow.output_schema = schema;
    return this;
  }

  timeout(seconds: number): this {
    this.workflow.timeout_seconds = seconds;
    return this;
  }

  // íƒœìŠ¤í¬ ì¶”ê°€
  addTask(task: WorkflowTask | TaskBuilder): this {
    if (task instanceof TaskBuilder) {
      this.workflow.tasks.push(task.build());
    } else {
      this.workflow.tasks.push(task);
    }
    return this;
  }

  // ë³‘ë ¬ ë¸”ë¡ ì¶”ê°€
  parallel(configure: (builder: ParallelBuilder) => void): this {
    const parallelBuilder = new ParallelBuilder();
    configure(parallelBuilder);
    this.workflow.tasks.push(parallelBuilder.build());
    return this;
  }

  // ì¡°ê±´ë¶€ ë¸”ë¡ ì¶”ê°€
  conditional(
    condition: string,
    configure: (builder: ConditionalBuilder) => void
  ): this {
    const conditionalBuilder = new ConditionalBuilder(condition);
    configure(conditionalBuilder);
    this.workflow.tasks.push(conditionalBuilder.build());
    return this;
  }

  // ë°˜ë³µ ë¸”ë¡ ì¶”ê°€
  foreach(
    iterator: string,
    variable: string,
    configure: (builder: LoopBuilder) => void
  ): this {
    const loopBuilder = new LoopBuilder("foreach", iterator, variable);
    configure(loopBuilder);
    this.workflow.tasks.push(loopBuilder.build());
    return this;
  }

  // ê²€ì¦ ë° ë¹Œë“œ
  async build(): Promise<WorkflowDefinition> {
    // ê²€ì¦
    for (const validator of this.validators) {
      const result = await validator.validate(this.workflow);
      if (!result.valid) {
        throw new WorkflowValidationError(result.errors);
      }
    }

    // ìµœì í™”
    let optimized = this.workflow;
    for (const optimizer of this.optimizers) {
      optimized = await optimizer.optimize(optimized);
    }

    return optimized;
  }

  // ê²€ì¦ê¸° ì¶”ê°€
  withValidator(validator: WorkflowValidator): this {
    this.validators.push(validator);
    return this;
  }

  // ìµœì í™”ê¸° ì¶”ê°€
  withOptimizer(optimizer: WorkflowOptimizer): this {
    this.optimizers.push(optimizer);
    return this;
  }
}

// íƒœìŠ¤í¬ ë¹Œë”
export class TaskBuilder {
  private task: Partial<WorkflowTask>;

  constructor(id: string, name: string, agentType: string) {
    this.task = {
      id,
      name,
      agent_type: agentType,
      input_mapping: {},
      output_mapping: {},
      dependencies: [],
      timeout_seconds: 300,
      retry_policy: new RetryPolicy(),
      conditions: [],
    };
  }

  input(mapping: Record<string, string>): this {
    this.task.input_mapping = mapping;
    return this;
  }

  output(mapping: Record<string, string>): this {
    this.task.output_mapping = mapping;
    return this;
  }

  dependsOn(...taskIds: string[]): this {
    this.task.dependencies = taskIds.map((id) => ({
      task_id: id,
      wait_for_completion: true,
    }));
    return this;
  }

  conditionalDependsOn(taskId: string, condition: string): this {
    this.task.dependencies!.push({
      task_id: taskId,
      condition,
      wait_for_completion: true,
    });
    return this;
  }

  timeout(seconds: number): this {
    this.task.timeout_seconds = seconds;
    return this;
  }

  retry(policy: Partial<RetryPolicy>): this {
    this.task.retry_policy = { ...new RetryPolicy(), ...policy };
    return this;
  }

  condition(expr: string): this {
    this.task.conditions!.push(expr);
    return this;
  }

  onError(handler: string): this {
    this.task.error_handler = handler;
    return this;
  }

  build(): WorkflowTask {
    if (!this.task.id || !this.task.name || !this.task.agent_type) {
      throw new Error("Task requires id, name, and agent_type");
    }
    return this.task as WorkflowTask;
  }
}

// ë³‘ë ¬ ë¹Œë”
export class ParallelBuilder {
  private tasks: (WorkflowTask | ConditionalBlock)[] = [];
  private maxConcurrency?: number;
  private failFast: boolean = true;

  task(configure: (builder: TaskBuilder) => TaskBuilder): this {
    const taskBuilder = new TaskBuilder(`task_${Date.now()}`, "unnamed", "");
    const configured = configure(taskBuilder);
    this.tasks.push(configured.build());
    return this;
  }

  conditional(
    condition: string,
    configure: (builder: ConditionalBuilder) => void
  ): this {
    const conditionalBuilder = new ConditionalBuilder(condition);
    configure(conditionalBuilder);
    this.tasks.push(conditionalBuilder.build());
    return this;
  }

  concurrency(max: number): this {
    this.maxConcurrency = max;
    return this;
  }

  continueOnFailure(): this {
    this.failFast = false;
    return this;
  }

  build(): ParallelBlock {
    return {
      id: `parallel_${Date.now()}`,
      tasks: this.tasks,
      max_concurrency: this.maxConcurrency,
      fail_fast: this.failFast,
    };
  }
}

// ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„± ì˜ˆì œ
export class WorkflowFactory {
  static createDataProcessingWorkflow(
    config: DataProcessingConfig
  ): DynamicWorkflowBuilder {
    const builder = new DynamicWorkflowBuilder("data-processing", "1.0.0")
      .description("Dynamic data processing workflow")
      .input({
        source: { type: "string", required: true },
        format: { type: "string", enum: ["csv", "json", "xml"] },
        transformations: { type: "array", items: { type: "string" } },
      })
      .output({
        processed_data: { type: "object" },
        statistics: { type: "object" },
      });

    // ë°ì´í„° ì†ŒìŠ¤ì— ë”°ë¥¸ ë™ì  íƒœìŠ¤í¬ ì¶”ê°€
    if (config.source.type === "database") {
      builder.addTask(
        new TaskBuilder("fetch_db", "Fetch from Database", "DataFetchAgent")
          .input({
            connection_string: "input.source",
            query: `"${config.source.query}"`,
          })
          .output({
            raw_data: "context.raw_data",
          })
      );
    } else if (config.source.type === "api") {
      builder.addTask(
        new TaskBuilder("fetch_api", "Fetch from API", "APIFetchAgent")
          .input({
            url: "input.source",
            headers: JSON.stringify(config.source.headers || {}),
          })
          .output({
            raw_data: "context.raw_data",
          })
      );
    }

    // ë³€í™˜ íƒœìŠ¤í¬ ë™ì  ì¶”ê°€
    config.transformations.forEach((transform, index) => {
      const prevTaskId =
        index === 0
          ? config.source.type === "database"
            ? "fetch_db"
            : "fetch_api"
          : `transform_${index - 1}`;

      builder.addTask(
        new TaskBuilder(
          `transform_${index}`,
          `Transform: ${transform.type}`,
          "DataTransformAgent"
        )
          .dependsOn(prevTaskId)
          .input({
            data:
              index === 0
                ? "context.raw_data"
                : `transform_${index - 1}.result`,
            transformation: JSON.stringify(transform),
          })
          .output({
            result: `context.transform_${index}_result`,
          })
      );
    });

    // ìµœì¢… ì§‘ê³„
    builder.addTask(
      new TaskBuilder("aggregate", "Aggregate Results", "AggregationAgent")
        .dependsOn(`transform_${config.transformations.length - 1}`)
        .input({
          data: `transform_${config.transformations.length - 1}.result`,
        })
        .output({
          processed_data: "output.processed_data",
          statistics: "output.statistics",
        })
    );

    return builder;
  }
}

// ëŸ°íƒ€ì„ ì›Œí¬í”Œë¡œìš° ìˆ˜ì •
export class RuntimeWorkflowModifier {
  constructor(
    private orchestrator: CentralOrchestrator,
    private validator: WorkflowValidator
  ) {}

  async modifyRunningWorkflow(
    executionId: string,
    modifications: WorkflowModification[]
  ): Promise<ModificationResult> {
    // í˜„ì¬ ì‹¤í–‰ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
    const execution = await this.orchestrator.getExecution(executionId);

    if (!execution) {
      throw new Error(`Workflow execution ${executionId} not found`);
    }

    if (execution.state !== WorkflowState.RUNNING) {
      throw new Error(`Workflow is not running: ${execution.state}`);
    }

    // ìˆ˜ì • ê°€ëŠ¥ì„± ê²€ì¦
    const canModify = await this.validateModifications(
      execution,
      modifications
    );

    if (!canModify.valid) {
      return {
        success: false,
        errors: canModify.errors,
      };
    }

    // ìˆ˜ì • ì ìš©
    const results = [];
    for (const mod of modifications) {
      const result = await this.applyModification(execution, mod);
      results.push(result);
    }

    return {
      success: true,
      results,
    };
  }

  private async applyModification(
    execution: WorkflowExecution,
    modification: WorkflowModification
  ): Promise<any> {
    switch (modification.type) {
      case "add_task":
        return this.addTaskToRunning(execution, modification);

      case "skip_task":
        return this.skipTask(execution, modification);

      case "modify_timeout":
        return this.modifyTimeout(execution, modification);

      case "inject_data":
        return this.injectData(execution, modification);

      default:
        throw new Error(`Unknown modification type: ${modification.type}`);
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í”Œë£¨ì–¸íŠ¸ API ì„¤ê³„
- [ ] ë™ì  íƒœìŠ¤í¬ ìƒì„±
- [ ] ëŸ°íƒ€ì„ ìˆ˜ì • ì§€ì›
- [ ] ê²€ì¦ ë° ìµœì í™”

#### SubTask 5.5.2: ì›Œí¬í”Œë¡œìš° ìˆ˜ì • API

**ë‹´ë‹¹ì**: API ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dynamic/modification_api.ts
import { Router } from "express";
import { body, param, validationResult } from "express-validator";

export class WorkflowModificationAPI {
  private router: Router;
  private modificationService: WorkflowModificationService;
  private authMiddleware: AuthMiddleware;

  constructor(orchestrator: CentralOrchestrator) {
    this.router = Router();
    this.modificationService = new WorkflowModificationService(orchestrator);
    this.authMiddleware = new AuthMiddleware();
    this.setupRoutes();
  }

  private setupRoutes(): void {
    // ì‹¤í–‰ ì¤‘ì¸ ì›Œí¬í”Œë¡œìš° ìˆ˜ì •
    this.router.patch(
      "/workflows/:workflowId/executions/:executionId",
      this.authMiddleware.requirePermission("workflow:modify"),
      [
        param("workflowId").isString(),
        param("executionId").isUUID(),
        body("modifications").isArray(),
        body("modifications.*.type").isIn([
          "add_task",
          "remove_task",
          "skip_task",
          "modify_task",
          "inject_data",
          "modify_timeout",
        ]),
      ],
      this.modifyExecution.bind(this)
    );

    // íƒœìŠ¤í¬ ì¶”ê°€
    this.router.post(
      "/workflows/:workflowId/executions/:executionId/tasks",
      this.authMiddleware.requirePermission("workflow:modify"),
      [
        param("executionId").isUUID(),
        body("task").isObject(),
        body("position").optional().isString(),
      ],
      this.addTask.bind(this)
    );

    // íƒœìŠ¤í¬ ìŠ¤í‚µ
    this.router.post(
      "/workflows/:workflowId/executions/:executionId/tasks/:taskId/skip",
      this.authMiddleware.requirePermission("workflow:modify"),
      [
        param("executionId").isUUID(),
        param("taskId").isString(),
        body("reason").optional().isString(),
      ],
      this.skipTask.bind(this)
    );

    // ë°ì´í„° ì£¼ì…
    this.router.post(
      "/workflows/:workflowId/executions/:executionId/data",
      this.authMiddleware.requirePermission("workflow:modify"),
      [
        param("executionId").isUUID(),
        body("path").isString(),
        body("value").exists(),
      ],
      this.injectData.bind(this)
    );

    // ì¡°ê±´ë¶€ ë¶„ê¸° ê°•ì œ
    this.router.post(
      "/workflows/:workflowId/executions/:executionId/force-branch",
      this.authMiddleware.requirePermission("workflow:modify"),
      [
        param("executionId").isUUID(),
        body("branchId").isString(),
        body("condition").isString(),
      ],
      this.forceBranch.bind(this)
    );
  }

  private async modifyExecution(req: Request, res: Response): Promise<void> {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { executionId } = req.params;
    const { modifications } = req.body;

    try {
      // ìˆ˜ì • ê¶Œí•œ í™•ì¸
      const canModify = await this.checkModificationPermissions(
        req.user,
        executionId
      );

      if (!canModify) {
        return res.status(403).json({
          error: "Insufficient permissions to modify workflow",
        });
      }

      // ìˆ˜ì • ì‚¬í•­ ê²€ì¦
      const validation = await this.modificationService.validateModifications(
        executionId,
        modifications
      );

      if (!validation.valid) {
        return res.status(400).json({
          error: "Invalid modifications",
          details: validation.errors,
        });
      }

      // ìˆ˜ì • ì ìš©
      const result = await this.modificationService.applyModifications(
        executionId,
        modifications
      );

      // ê°ì‚¬ ë¡œê·¸
      await this.auditLog.log({
        action: "workflow_modified",
        executionId,
        userId: req.user.id,
        modifications,
        result,
      });

      res.json({
        success: true,
        result,
      });
    } catch (error) {
      logger.error("Failed to modify workflow", { error, executionId });
      res.status(500).json({
        error: "Failed to modify workflow",
        message: error.message,
      });
    }
  }

  private async addTask(req: Request, res: Response): Promise<void> {
    const { executionId } = req.params;
    const { task, position } = req.body;

    try {
      // íƒœìŠ¤í¬ ë¹Œë”ë¡œ ê²€ì¦
      const taskBuilder = new TaskBuilder(
        task.id || `dynamic_${Date.now()}`,
        task.name,
        task.agent_type
      );

      // íƒœìŠ¤í¬ êµ¬ì„±
      if (task.input) taskBuilder.input(task.input);
      if (task.output) taskBuilder.output(task.output);
      if (task.dependencies) taskBuilder.dependsOn(...task.dependencies);
      if (task.timeout) taskBuilder.timeout(task.timeout);

      const builtTask = taskBuilder.build();

      // ì¶”ê°€ ìœ„ì¹˜ ê²°ì •
      const insertPosition = position || "end";

      // íƒœìŠ¤í¬ ì¶”ê°€
      const result = await this.modificationService.addTaskToExecution(
        executionId,
        builtTask,
        insertPosition
      );

      res.json({
        success: true,
        taskId: result.taskId,
        position: result.position,
      });
    } catch (error) {
      logger.error("Failed to add task", { error, executionId });
      res.status(500).json({
        error: "Failed to add task",
        message: error.message,
      });
    }
  }
}

// ì›Œí¬í”Œë¡œìš° ìˆ˜ì • ì„œë¹„ìŠ¤
export class WorkflowModificationService {
  private modificationQueue: Queue<ModificationRequest>;
  private modificationHandlers: Map<string, ModificationHandler>;

  constructor(private orchestrator: CentralOrchestrator) {
    this.modificationQueue = new Queue();
    this.registerHandlers();
    this.startModificationProcessor();
  }

  private registerHandlers(): void {
    this.modificationHandlers = new Map([
      ["add_task", new AddTaskHandler()],
      ["remove_task", new RemoveTaskHandler()],
      ["skip_task", new SkipTaskHandler()],
      ["modify_task", new ModifyTaskHandler()],
      ["inject_data", new InjectDataHandler()],
      ["modify_timeout", new ModifyTimeoutHandler()],
      ["force_branch", new ForceBranchHandler()],
    ]);
  }

  async validateModifications(
    executionId: string,
    modifications: WorkflowModification[]
  ): Promise<ValidationResult> {
    const execution = await this.orchestrator.getExecution(executionId);

    if (!execution) {
      return {
        valid: false,
        errors: ["Execution not found"],
      };
    }

    const errors: string[] = [];

    for (const mod of modifications) {
      const handler = this.modificationHandlers.get(mod.type);

      if (!handler) {
        errors.push(`Unknown modification type: ${mod.type}`);
        continue;
      }

      const validation = await handler.validate(execution, mod);
      if (!validation.valid) {
        errors.push(...validation.errors);
      }
    }

    return {
      valid: errors.length === 0,
      errors,
    };
  }

  async applyModifications(
    executionId: string,
    modifications: WorkflowModification[]
  ): Promise<ModificationResult[]> {
    const results: ModificationResult[] = [];

    // ìˆ˜ì • ìš”ì²­ì„ íì— ì¶”ê°€
    for (const mod of modifications) {
      const request: ModificationRequest = {
        id: uuid(),
        executionId,
        modification: mod,
        timestamp: new Date(),
        status: "pending",
      };

      await this.modificationQueue.enqueue(request);

      // ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬ ëŒ€ê¸°
      const result = await this.waitForModification(request.id);
      results.push(result);
    }

    return results;
  }

  private async processModification(
    request: ModificationRequest
  ): Promise<ModificationResult> {
    const handler = this.modificationHandlers.get(request.modification.type);

    if (!handler) {
      return {
        requestId: request.id,
        success: false,
        error: `Unknown modification type: ${request.modification.type}`,
      };
    }

    try {
      // ì‹¤í–‰ ìƒíƒœ ì ê¸ˆ
      await this.orchestrator.lockExecution(request.executionId);

      // ìˆ˜ì • ì ìš©
      const result = await handler.apply(
        this.orchestrator,
        request.executionId,
        request.modification
      );

      // ì´ë²¤íŠ¸ ë°œí–‰
      await this.orchestrator.eventBus.publish({
        event_type: "workflow.modified",
        workflow_id: request.executionId,
        timestamp: new Date(),
        data: {
          modification: request.modification,
          result,
        },
      });

      return {
        requestId: request.id,
        success: true,
        result,
      };
    } catch (error) {
      return {
        requestId: request.id,
        success: false,
        error: error.message,
      };
    } finally {
      // ì ê¸ˆ í•´ì œ
      await this.orchestrator.unlockExecution(request.executionId);
    }
  }
}

// ìˆ˜ì • í•¸ë“¤ëŸ¬ ì¸í„°í˜ì´ìŠ¤
abstract class ModificationHandler {
  abstract validate(
    execution: WorkflowExecution,
    modification: WorkflowModification
  ): Promise<ValidationResult>;

  abstract apply(
    orchestrator: CentralOrchestrator,
    executionId: string,
    modification: WorkflowModification
  ): Promise<any>;
}

// íƒœìŠ¤í¬ ì¶”ê°€ í•¸ë“¤ëŸ¬
class AddTaskHandler extends ModificationHandler {
  async validate(
    execution: WorkflowExecution,
    modification: WorkflowModification
  ): Promise<ValidationResult> {
    const { task, position } = modification.data;

    // íƒœìŠ¤í¬ ê²€ì¦
    if (!task.agent_type) {
      return {
        valid: false,
        errors: ["Task must specify agent_type"],
      };
    }

    // ìœ„ì¹˜ ê²€ì¦
    if (position && position !== "end") {
      const targetTask = execution.tasks[position];
      if (!targetTask) {
        return {
          valid: false,
          errors: [`Invalid position: ${position}`],
        };
      }

      // ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜ ì™„ë£Œëœ íƒœìŠ¤í¬ ë’¤ì—ëŠ” ì¶”ê°€ ë¶ˆê°€
      if (targetTask.status !== "pending") {
        return {
          valid: false,
          errors: ["Cannot add task after running/completed task"],
        };
      }
    }

    return { valid: true, errors: [] };
  }

  async apply(
    orchestrator: CentralOrchestrator,
    executionId: string,
    modification: WorkflowModification
  ): Promise<any> {
    const { task, position } = modification.data;

    // íƒœìŠ¤í¬ ìƒì„±
    const newTask = new AgentTask({
      id: task.id || `dynamic_${Date.now()}`,
      ...task,
      workflow_id: executionId,
      status: "pending",
      created_at: new Date(),
    });

    // ì‹¤í–‰ì— ì¶”ê°€
    await orchestrator.addTaskToExecution(executionId, newTask, position);

    return {
      taskId: newTask.id,
      position: position || "end",
    };
  }
}

// ë™ì  ì›Œí¬í”Œë¡œìš° ë¹Œë” UI ì§€ì›
export class WorkflowBuilderUISupport {
  async getAvailableAgents(): Promise<AgentInfo[]> {
    return this.orchestrator.registry.getAllAgents();
  }

  async getTaskTemplates(): Promise<TaskTemplate[]> {
    return [
      {
        id: "data_fetch",
        name: "Data Fetch",
        description: "Fetch data from various sources",
        agent_type: "DataFetchAgent",
        default_config: {
          timeout: 300,
          retry: 2,
        },
      },
      {
        id: "data_transform",
        name: "Data Transform",
        description: "Transform data using various operations",
        agent_type: "DataTransformAgent",
        default_config: {
          timeout: 600,
          retry: 1,
        },
      },
      // ... ë” ë§ì€ í…œí”Œë¦¿
    ];
  }

  async validateWorkflowDraft(draft: WorkflowDraft): Promise<ValidationResult> {
    const builder = new DynamicWorkflowBuilder(draft.name, draft.version);

    // ë“œë˜í”„íŠ¸ë¥¼ ë¹Œë”ë¡œ ë³€í™˜
    builder
      .description(draft.description)
      .input(draft.input_schema)
      .output(draft.output_schema);

    for (const task of draft.tasks) {
      builder.addTask(task);
    }

    // ê²€ì¦
    try {
      await builder.build();
      return { valid: true, errors: [] };
    } catch (error) {
      return {
        valid: false,
        errors: [error.message],
      };
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] RESTful API ì„¤ê³„
- [ ] ìˆ˜ì • ê²€ì¦ ë¡œì§
- [ ] ê¶Œí•œ ê´€ë¦¬
- [ ] ì‹¤ì‹œê°„ ìˆ˜ì • ì§€ì›

#### SubTask 5.5.3: ë™ì  ë¶„ê¸° ë° ì¡°ê±´ë¶€ ì‹¤í–‰

**ë‹´ë‹¹ì**: ì›Œí¬í”Œë¡œìš° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dynamic/conditional_execution.ts
export class ConditionalExecutor {
  private expressionEvaluator: ExpressionEvaluator;
  private branchPredictor: BranchPredictor;

  constructor() {
    this.expressionEvaluator = new ExpressionEvaluator();
    this.branchPredictor = new BranchPredictor();
  }

  async evaluateCondition(
    condition: string,
    context: ExecutionContext
  ): Promise<boolean> {
    try {
      // í‘œí˜„ì‹ íŒŒì‹±
      const expression = this.expressionEvaluator.parse(condition);

      // ì»¨í…ìŠ¤íŠ¸ ê°’ í•´ê²°
      const resolvedContext = await this.resolveContextValues(
        expression,
        context
      );

      // í‰ê°€
      const result = await this.expressionEvaluator.evaluate(
        expression,
        resolvedContext
      );

      // ê²°ê³¼ íƒ€ì… ê²€ì¦
      if (typeof result !== "boolean") {
        throw new Error(
          `Condition must evaluate to boolean, got ${typeof result}`
        );
      }

      return result;
    } catch (error) {
      logger.error("Failed to evaluate condition", {
        condition,
        error: error.message,
      });
      throw new ConditionEvaluationError(
        `Failed to evaluate condition: ${error.message}`
      );
    }
  }

  async executeDynamicBranch(
    branchConfig: DynamicBranchConfig,
    context: ExecutionContext
  ): Promise<BranchExecutionResult> {
    const startTime = Date.now();
    const results: TaskExecutionResult[] = [];

    try {
      // ë¶„ê¸° ì˜ˆì¸¡
      const prediction = await this.branchPredictor.predict(
        branchConfig,
        context
      );

      // ì˜ˆì¸¡ ê¸°ë°˜ ë¦¬ì†ŒìŠ¤ ì‚¬ì „ í• ë‹¹
      if (prediction.confidence > 0.8) {
        await this.preAllocateResources(prediction.predictedBranch);
      }

      // ì¡°ê±´ í‰ê°€
      const branchDecision = await this.decideBranch(branchConfig, context);

      // ì„ íƒëœ ë¶„ê¸° ì‹¤í–‰
      const selectedBranch = branchConfig.branches[branchDecision.branchIndex];

      logger.info("Executing dynamic branch", {
        branchId: selectedBranch.id,
        condition: branchDecision.condition,
        evaluated: branchDecision.evaluated,
      });

      // íƒœìŠ¤í¬ ì‹¤í–‰
      for (const task of selectedBranch.tasks) {
        const result = await this.executeTask(task, context);
        results.push(result);

        // ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ë°˜ì˜
        this.updateContext(context, task, result);
      }

      return {
        branchId: selectedBranch.id,
        executed: true,
        results,
        duration: Date.now() - startTime,
      };
    } catch (error) {
      return {
        branchId: null,
        executed: false,
        error: error.message,
        duration: Date.now() - startTime,
      };
    }
  }

  private async decideBranch(
    config: DynamicBranchConfig,
    context: ExecutionContext
  ): Promise<BranchDecision> {
    // switch ìŠ¤íƒ€ì¼ ë¶„ê¸°
    if (config.type === "switch") {
      const switchValue = await this.evaluateExpression(
        config.switchExpression!,
        context
      );

      for (let i = 0; i < config.branches.length; i++) {
        const branch = config.branches[i];

        if (branch.caseValue === switchValue) {
          return {
            branchIndex: i,
            condition: `${config.switchExpression} == ${branch.caseValue}`,
            evaluated: true,
          };
        }
      }

      // default ë¶„ê¸°
      const defaultIndex = config.branches.findIndex((b) => b.isDefault);
      if (defaultIndex >= 0) {
        return {
          branchIndex: defaultIndex,
          condition: "default",
          evaluated: true,
        };
      }
    } else {
      // if-else ìŠ¤íƒ€ì¼ ë¶„ê¸°
      for (let i = 0; i < config.branches.length; i++) {
        const branch = config.branches[i];

        if (!branch.condition) {
          // else ë¶„ê¸°
          return {
            branchIndex: i,
            condition: "else",
            evaluated: true,
          };
        }

        const conditionMet = await this.evaluateCondition(
          branch.condition,
          context
        );

        if (conditionMet) {
          return {
            branchIndex: i,
            condition: branch.condition,
            evaluated: conditionMet,
          };
        }
      }
    }

    throw new Error("No branch condition met");
  }
}

// ë™ì  ë°˜ë³µ ì‹¤í–‰
export class DynamicLoopExecutor {
  constructor(
    private taskExecutor: TaskExecutor,
    private conditionEvaluator: ConditionalExecutor
  ) {}

  async executeLoop(
    loopConfig: LoopConfig,
    context: ExecutionContext
  ): Promise<LoopExecutionResult> {
    const results: TaskExecutionResult[] = [];
    let iterations = 0;
    const maxIterations = loopConfig.maxIterations || 1000;

    try {
      if (loopConfig.type === "foreach") {
        // ForEach ë£¨í”„
        results.push(...(await this.executeForeach(loopConfig, context)));
      } else if (loopConfig.type === "while") {
        // While ë£¨í”„
        results.push(
          ...(await this.executeWhile(loopConfig, context, maxIterations))
        );
      } else if (loopConfig.type === "do-while") {
        // Do-While ë£¨í”„
        results.push(
          ...(await this.executeDoWhile(loopConfig, context, maxIterations))
        );
      } else if (loopConfig.type === "for") {
        // For ë£¨í”„
        results.push(...(await this.executeFor(loopConfig, context)));
      }

      return {
        completed: true,
        iterations: results.length,
        results,
      };
    } catch (error) {
      return {
        completed: false,
        iterations,
        results,
        error: error.message,
      };
    }
  }

  private async executeForeach(
    config: LoopConfig,
    context: ExecutionContext
  ): Promise<TaskExecutionResult[]> {
    const results: TaskExecutionResult[] = [];

    // ë°˜ë³µ ëŒ€ìƒ ê°€ì ¸ì˜¤ê¸°
    const iterable = await this.resolveIterable(config.iterator!, context);

    if (!Array.isArray(iterable)) {
      throw new Error(`Iterator must be an array, got ${typeof iterable}`);
    }

    // ë³‘ë ¬ ì‹¤í–‰ ì—¬ë¶€
    if (config.parallel) {
      const promises = iterable.map((item, index) =>
        this.executeLoopIteration(config, context, item, index)
      );

      const parallelResults = await Promise.allSettled(promises);

      for (const result of parallelResults) {
        if (result.status === "fulfilled") {
          results.push(...result.value);
        } else {
          logger.error("Parallel loop iteration failed", result.reason);
        }
      }
    } else {
      // ìˆœì°¨ ì‹¤í–‰
      for (let i = 0; i < iterable.length; i++) {
        const item = iterable[i];
        const iterationResults = await this.executeLoopIteration(
          config,
          context,
          item,
          i
        );
        results.push(...iterationResults);

        // early break ì¡°ê±´ í™•ì¸
        if (config.breakCondition) {
          const shouldBreak = await this.conditionEvaluator.evaluateCondition(
            config.breakCondition,
            context
          );
          if (shouldBreak) break;
        }
      }
    }

    return results;
  }

  private async executeLoopIteration(
    config: LoopConfig,
    baseContext: ExecutionContext,
    item: any,
    index: number
  ): Promise<TaskExecutionResult[]> {
    // ë°˜ë³µ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    const iterationContext = this.createIterationContext(
      baseContext,
      config.variable!,
      item,
      index
    );

    const results: TaskExecutionResult[] = [];

    for (const task of config.tasks) {
      const result = await this.taskExecutor.execute(task, iterationContext);
      results.push(result);

      // ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ë°˜ì˜
      this.updateIterationContext(iterationContext, task, result);
    }

    return results;
  }

  private createIterationContext(
    baseContext: ExecutionContext,
    variableName: string,
    item: any,
    index: number
  ): ExecutionContext {
    return {
      ...baseContext,
      loop: {
        ...baseContext.loop,
        [variableName]: item,
        [`${variableName}_index`]: index,
      },
    };
  }
}

// ë™ì  ì—ëŸ¬ ì²˜ë¦¬
export class DynamicErrorHandler {
  private errorPatterns: Map<string, ErrorPattern>;
  private recoveryStrategies: Map<string, RecoveryStrategy>;

  constructor() {
    this.errorPatterns = new Map();
    this.recoveryStrategies = new Map();
    this.registerDefaultPatterns();
  }

  async handleError(
    error: Error,
    task: WorkflowTask,
    context: ExecutionContext
  ): Promise<ErrorHandlingResult> {
    // ì—ëŸ¬ íŒ¨í„´ ë§¤ì¹­
    const pattern = this.matchErrorPattern(error);

    // ë³µêµ¬ ì „ëµ ì„ íƒ
    const strategy = this.selectRecoveryStrategy(pattern, task, context);

    // ì „ëµ ì‹¤í–‰
    return await this.executeRecoveryStrategy(strategy, error, task, context);
  }

  private matchErrorPattern(error: Error): ErrorPattern | null {
    for (const [name, pattern] of this.errorPatterns) {
      if (pattern.matches(error)) {
        return pattern;
      }
    }
    return null;
  }

  private selectRecoveryStrategy(
    pattern: ErrorPattern | null,
    task: WorkflowTask,
    context: ExecutionContext
  ): RecoveryStrategy {
    // íƒœìŠ¤í¬ë³„ ì—ëŸ¬ í•¸ë“¤ëŸ¬ í™•ì¸
    if (task.error_handler) {
      const customStrategy = this.recoveryStrategies.get(task.error_handler);
      if (customStrategy) return customStrategy;
    }

    // íŒ¨í„´ ê¸°ë°˜ ì „ëµ
    if (pattern && pattern.recoveryStrategy) {
      const patternStrategy = this.recoveryStrategies.get(
        pattern.recoveryStrategy
      );
      if (patternStrategy) return patternStrategy;
    }

    // ê¸°ë³¸ ì „ëµ
    return this.recoveryStrategies.get("default")!;
  }

  private async executeRecoveryStrategy(
    strategy: RecoveryStrategy,
    error: Error,
    task: WorkflowTask,
    context: ExecutionContext
  ): Promise<ErrorHandlingResult> {
    try {
      const result = await strategy.execute(error, task, context);

      if (result.recovered) {
        logger.info("Error recovered", {
          taskId: task.id,
          strategy: strategy.name,
          action: result.action,
        });
      }

      return result;
    } catch (recoveryError) {
      logger.error("Recovery strategy failed", {
        taskId: task.id,
        strategy: strategy.name,
        error: recoveryError.message,
      });

      return {
        recovered: false,
        action: "fail",
        error: recoveryError,
      };
    }
  }

  registerErrorPattern(name: string, pattern: ErrorPattern): void {
    this.errorPatterns.set(name, pattern);
  }

  registerRecoveryStrategy(name: string, strategy: RecoveryStrategy): void {
    this.recoveryStrategies.set(name, strategy);
  }

  private registerDefaultPatterns(): void {
    // ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜
    this.registerErrorPattern("network", {
      name: "network",
      matches: (error) => {
        return (
          error.message.includes("ECONNREFUSED") ||
          error.message.includes("ETIMEDOUT") ||
          error.message.includes("ENOTFOUND")
        );
      },
      recoveryStrategy: "retry_with_backoff",
    });

    // ë¦¬ì†ŒìŠ¤ ë¶€ì¡±
    this.registerErrorPattern("resource_exhausted", {
      name: "resource_exhausted",
      matches: (error) => {
        return (
          error.message.includes("insufficient resources") ||
          error.message.includes("quota exceeded")
        );
      },
      recoveryStrategy: "wait_and_retry",
    });

    // ê¶Œí•œ ì˜¤ë¥˜
    this.registerErrorPattern("permission_denied", {
      name: "permission_denied",
      matches: (error) => {
        return (
          error.message.includes("permission denied") ||
          error.message.includes("unauthorized")
        );
      },
      recoveryStrategy: "escalate",
    });
  }
}

// ë¶„ê¸° ì˜ˆì¸¡ê¸°
class BranchPredictor {
  private history: Map<string, BranchHistory>;

  constructor() {
    this.history = new Map();
  }

  async predict(
    config: DynamicBranchConfig,
    context: ExecutionContext
  ): Promise<BranchPrediction> {
    const historyKey = this.generateHistoryKey(config, context);
    const branchHistory = this.history.get(historyKey);

    if (!branchHistory || branchHistory.samples < 10) {
      // íˆìŠ¤í† ë¦¬ê°€ ë¶€ì¡±í•˜ë©´ ì˜ˆì¸¡í•˜ì§€ ì•ŠìŒ
      return {
        predictedBranch: null,
        confidence: 0,
      };
    }

    // ê°€ì¥ ìì£¼ ì‹¤í–‰ëœ ë¶„ê¸° ì°¾ê¸°
    const mostFrequent = branchHistory.getMostFrequentBranch();

    return {
      predictedBranch: mostFrequent.branchId,
      confidence: mostFrequent.frequency / branchHistory.samples,
    };
  }

  recordExecution(
    config: DynamicBranchConfig,
    context: ExecutionContext,
    executedBranch: string
  ): void {
    const historyKey = this.generateHistoryKey(config, context);

    if (!this.history.has(historyKey)) {
      this.history.set(historyKey, new BranchHistory());
    }

    this.history.get(historyKey)!.record(executedBranch);
  }

  private generateHistoryKey(
    config: DynamicBranchConfig,
    context: ExecutionContext
  ): string {
    // ì»¨í…ìŠ¤íŠ¸ì˜ ì£¼ìš” ê°’ë“¤ë¡œ í‚¤ ìƒì„±
    const relevantContext = this.extractRelevantContext(config, context);
    return `${config.id}:${JSON.stringify(relevantContext)}`;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì¡°ê±´ë¶€ ì‹¤í–‰ ì—”ì§„
- [ ] ë™ì  ë°˜ë³µ ì²˜ë¦¬
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬
- [ ] ë¶„ê¸° ì˜ˆì¸¡ ìµœì í™”

#### SubTask 5.5.4: ì›Œí¬í”Œë¡œìš° ë²„ì „ ê´€ë¦¬

**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dynamic/version_control.ts
export class WorkflowVersionControl {
  private versionStore: VersionStore;
  private diffEngine: DiffEngine;
  private mergeEngine: MergeEngine;

  constructor(storage: StorageBackend) {
    this.versionStore = new VersionStore(storage);
    this.diffEngine = new DiffEngine();
    this.mergeEngine = new MergeEngine();
  }

  async createVersion(
    workflow: WorkflowDefinition,
    metadata: VersionMetadata
  ): Promise<WorkflowVersion> {
    // ë²„ì „ ë²ˆí˜¸ ìƒì„±
    const versionNumber = await this.generateVersionNumber(
      workflow.id,
      metadata.versionType
    );

    // ì´ì „ ë²„ì „ê³¼ì˜ ì°¨ì´ ê³„ì‚°
    const previousVersion = await this.getLatestVersion(workflow.id);
    const diff = previousVersion
      ? await this.diffEngine.calculateDiff(
          previousVersion.definition,
          workflow
        )
      : null;

    // ë²„ì „ ìƒì„±
    const version: WorkflowVersion = {
      id: uuid(),
      workflowId: workflow.id,
      version: versionNumber,
      definition: workflow,
      diff,
      metadata: {
        ...metadata,
        createdAt: new Date(),
        createdBy: metadata.userId,
        changeLog: await this.generateChangeLog(diff),
      },
      status: "draft",
    };

    // ì €ì¥
    await this.versionStore.save(version);

    return version;
  }

  async promoteVersion(
    workflowId: string,
    versionId: string,
    environment: string
  ): Promise<PromotionResult> {
    const version = await this.versionStore.get(versionId);

    if (!version) {
      throw new Error(`Version ${versionId} not found`);
    }

    // ê²€ì¦
    const validation = await this.validatePromotion(version, environment);

    if (!validation.valid) {
      return {
        success: false,
        errors: validation.errors,
      };
    }

    // í”„ë¡œëª¨ì…˜ ì‹¤í–‰
    const promotion = await this.executePromotion(version, environment);

    // í”„ë¡œëª¨ì…˜ ê¸°ë¡
    await this.recordPromotion(version, environment, promotion);

    return promotion;
  }

  async compareVersions(
    versionId1: string,
    versionId2: string
  ): Promise<VersionComparison> {
    const [version1, version2] = await Promise.all([
      this.versionStore.get(versionId1),
      this.versionStore.get(versionId2),
    ]);

    if (!version1 || !version2) {
      throw new Error("One or both versions not found");
    }

    const diff = await this.diffEngine.calculateDiff(
      version1.definition,
      version2.definition
    );

    return {
      version1: {
        id: version1.id,
        version: version1.version,
        createdAt: version1.metadata.createdAt,
      },
      version2: {
        id: version2.id,
        version: version2.version,
        createdAt: version2.metadata.createdAt,
      },
      diff,
      summary: this.summarizeDiff(diff),
    };
  }

  async mergeVersions(
    baseVersionId: string,
    sourceVersionId: string,
    targetVersionId: string,
    strategy: MergeStrategy = "three-way"
  ): Promise<MergeResult> {
    const [base, source, target] = await Promise.all([
      this.versionStore.get(baseVersionId),
      this.versionStore.get(sourceVersionId),
      this.versionStore.get(targetVersionId),
    ]);

    if (!base || !source || !target) {
      throw new Error("One or more versions not found");
    }

    // ë³‘í•© ì‹¤í–‰
    const mergeResult = await this.mergeEngine.merge(
      base.definition,
      source.definition,
      target.definition,
      strategy
    );

    if (mergeResult.conflicts.length > 0) {
      return {
        success: false,
        conflicts: mergeResult.conflicts,
        merged: null,
      };
    }

    // ë³‘í•©ëœ ë²„ì „ ìƒì„±
    const mergedVersion = await this.createVersion(mergeResult.merged, {
      versionType: "merge",
      description: `Merge of ${source.version} into ${target.version}`,
      userId: "system",
      mergeInfo: {
        base: baseVersionId,
        source: sourceVersionId,
        target: targetVersionId,
      },
    });

    return {
      success: true,
      conflicts: [],
      merged: mergedVersion,
    };
  }

  async rollbackVersion(
    workflowId: string,
    targetVersionId: string,
    reason: string
  ): Promise<RollbackResult> {
    const currentVersion = await this.getCurrentVersion(workflowId);
    const targetVersion = await this.versionStore.get(targetVersionId);

    if (!targetVersion) {
      throw new Error(`Target version ${targetVersionId} not found`);
    }

    // ë¡¤ë°± ê°€ëŠ¥ì„± í™•ì¸
    const canRollback = await this.validateRollback(
      currentVersion,
      targetVersion
    );

    if (!canRollback.valid) {
      return {
        success: false,
        errors: canRollback.errors,
      };
    }

    // ë¡¤ë°± ì‹¤í–‰
    const rollbackVersion = await this.createVersion(targetVersion.definition, {
      versionType: "rollback",
      description: `Rollback to ${targetVersion.version}: ${reason}`,
      userId: "system",
      rollbackInfo: {
        from: currentVersion.id,
        to: targetVersionId,
        reason,
      },
    });

    // ì¦‰ì‹œ í™œì„±í™”
    await this.activateVersion(rollbackVersion.id);

    return {
      success: true,
      rollbackVersion,
    };
  }

  private async generateVersionNumber(
    workflowId: string,
    versionType: VersionType
  ): Promise<string> {
    const latestVersion = await this.getLatestVersion(workflowId);

    if (!latestVersion) {
      return "1.0.0";
    }

    const current = semver.parse(latestVersion.version);

    switch (versionType) {
      case "major":
        return semver.inc(current, "major");
      case "minor":
        return semver.inc(current, "minor");
      case "patch":
        return semver.inc(current, "patch");
      case "prerelease":
        return semver.inc(current, "prerelease", "beta");
      default:
        return semver.inc(current, "patch");
    }
  }
}

// ë²„ì „ ì°¨ì´ ì—”ì§„
export class DiffEngine {
  async calculateDiff(
    oldDef: WorkflowDefinition,
    newDef: WorkflowDefinition
  ): Promise<WorkflowDiff> {
    const diff: WorkflowDiff = {
      metadata: this.diffMetadata(oldDef, newDef),
      tasks: await this.diffTasks(oldDef.tasks, newDef.tasks),
      structure: this.diffStructure(oldDef, newDef),
      inputs: this.diffSchema(oldDef.input_schema, newDef.input_schema),
      outputs: this.diffSchema(oldDef.output_schema, newDef.output_schema),
    };

    return diff;
  }

  private async diffTasks(
    oldTasks: WorkflowTask[],
    newTasks: WorkflowTask[]
  ): Promise<TaskDiff[]> {
    const diffs: TaskDiff[] = [];
    const oldTaskMap = new Map(oldTasks.map((t) => [t.id, t]));
    const newTaskMap = new Map(newTasks.map((t) => [t.id, t]));

    // ì¶”ê°€ëœ íƒœìŠ¤í¬
    for (const [id, task] of newTaskMap) {
      if (!oldTaskMap.has(id)) {
        diffs.push({
          type: "added",
          taskId: id,
          task,
        });
      }
    }

    // ì‚­ì œëœ íƒœìŠ¤í¬
    for (const [id, task] of oldTaskMap) {
      if (!newTaskMap.has(id)) {
        diffs.push({
          type: "removed",
          taskId: id,
          task,
        });
      }
    }

    // ìˆ˜ì •ëœ íƒœìŠ¤í¬
    for (const [id, newTask] of newTaskMap) {
      const oldTask = oldTaskMap.get(id);
      if (oldTask) {
        const changes = this.compareTask(oldTask, newTask);
        if (changes.length > 0) {
          diffs.push({
            type: "modified",
            taskId: id,
            changes,
          });
        }
      }
    }

    return diffs;
  }

  private compareTask(
    oldTask: WorkflowTask,
    newTask: WorkflowTask
  ): TaskChange[] {
    const changes: TaskChange[] = [];

    // ì†ì„±ë³„ ë¹„êµ
    const properties = [
      "agent_type",
      "timeout_seconds",
      "retry_policy",
      "input_mapping",
      "output_mapping",
      "dependencies",
    ];

    for (const prop of properties) {
      if (!_.isEqual(oldTask[prop], newTask[prop])) {
        changes.push({
          property: prop,
          oldValue: oldTask[prop],
          newValue: newTask[prop],
        });
      }
    }

    return changes;
  }
}

// ë²„ì „ ë³‘í•© ì—”ì§„
export class MergeEngine {
  async merge(
    base: WorkflowDefinition,
    source: WorkflowDefinition,
    target: WorkflowDefinition,
    strategy: MergeStrategy
  ): Promise<MergeResult> {
    if (strategy === "three-way") {
      return this.threeWayMerge(base, source, target);
    } else if (strategy === "ours") {
      return { merged: target, conflicts: [] };
    } else if (strategy === "theirs") {
      return { merged: source, conflicts: [] };
    } else {
      throw new Error(`Unknown merge strategy: ${strategy}`);
    }
  }

  private async threeWayMerge(
    base: WorkflowDefinition,
    source: WorkflowDefinition,
    target: WorkflowDefinition
  ): Promise<MergeResult> {
    const conflicts: MergeConflict[] = [];
    const merged = _.cloneDeep(target);

    // ë©”íƒ€ë°ì´í„° ë³‘í•©
    const metadataConflicts = this.mergeMetadata(base, source, target, merged);
    conflicts.push(...metadataConflicts);

    // íƒœìŠ¤í¬ ë³‘í•©
    const taskConflicts = await this.mergeTasks(
      base.tasks,
      source.tasks,
      target.tasks,
      merged
    );
    conflicts.push(...taskConflicts);

    // ìŠ¤í‚¤ë§ˆ ë³‘í•©
    const schemaConflicts = this.mergeSchemas(base, source, target, merged);
    conflicts.push(...schemaConflicts);

    return {
      merged: conflicts.length === 0 ? merged : null,
      conflicts,
    };
  }

  private async mergeTasks(
    baseTasks: WorkflowTask[],
    sourceTasks: WorkflowTask[],
    targetTasks: WorkflowTask[],
    merged: WorkflowDefinition
  ): Promise<MergeConflict[]> {
    const conflicts: MergeConflict[] = [];
    const baseMap = new Map(baseTasks.map((t) => [t.id, t]));
    const sourceMap = new Map(sourceTasks.map((t) => [t.id, t]));
    const targetMap = new Map(targetTasks.map((t) => [t.id, t]));

    const allTaskIds = new Set([
      ...baseMap.keys(),
      ...sourceMap.keys(),
      ...targetMap.keys(),
    ]);

    const mergedTasks: WorkflowTask[] = [];

    for (const taskId of allTaskIds) {
      const baseTask = baseMap.get(taskId);
      const sourceTask = sourceMap.get(taskId);
      const targetTask = targetMap.get(taskId);

      if (!baseTask && sourceTask && !targetTask) {
        // Sourceì—ë§Œ ì¶”ê°€ë¨
        mergedTasks.push(sourceTask);
      } else if (!baseTask && !sourceTask && targetTask) {
        // Targetì—ë§Œ ì¶”ê°€ë¨
        mergedTasks.push(targetTask);
      } else if (baseTask && !sourceTask && targetTask) {
        // Sourceì—ì„œ ì‚­ì œë¨
        if (_.isEqual(baseTask, targetTask)) {
          // Targetì—ì„œ ë³€ê²½ ì—†ìŒ - ì‚­ì œ ì ìš©
          continue;
        } else {
          // ì¶©ëŒ: Sourceì—ì„œ ì‚­ì œ, Targetì—ì„œ ìˆ˜ì •
          conflicts.push({
            type: "delete-modify",
            path: `tasks.${taskId}`,
            base: baseTask,
            source: null,
            target: targetTask,
          });
        }
      } else if (baseTask && sourceTask && !targetTask) {
        // Targetì—ì„œ ì‚­ì œë¨
        if (_.isEqual(baseTask, sourceTask)) {
          // Sourceì—ì„œ ë³€ê²½ ì—†ìŒ - ì‚­ì œ ì ìš©
          continue;
        } else {
          // ì¶©ëŒ: Sourceì—ì„œ ìˆ˜ì •, Targetì—ì„œ ì‚­ì œ
          conflicts.push({
            type: "modify-delete",
            path: `tasks.${taskId}`,
            base: baseTask,
            source: sourceTask,
            target: null,
          });
        }
      } else if (baseTask && sourceTask && targetTask) {
        // ëª¨ë‘ì— ì¡´ì¬ - 3-way ë³‘í•©
        const mergedTask = await this.mergeTask(
          baseTask,
          sourceTask,
          targetTask
        );

        if (mergedTask.conflicts.length > 0) {
          conflicts.push(...mergedTask.conflicts);
        } else {
          mergedTasks.push(mergedTask.task);
        }
      }
    }

    if (conflicts.length === 0) {
      merged.tasks = mergedTasks;
    }

    return conflicts;
  }
}

// ë²„ì „ ì´ë ¥ ì¶”ì 
export class VersionHistory {
  private timeline: VersionTimeline;

  constructor(private versionStore: VersionStore) {
    this.timeline = new VersionTimeline();
  }

  async getHistory(
    workflowId: string,
    options: HistoryOptions = {}
  ): Promise<VersionHistoryEntry[]> {
    const versions = await this.versionStore.listVersions(workflowId, options);

    const history: VersionHistoryEntry[] = [];

    for (const version of versions) {
      const entry: VersionHistoryEntry = {
        version: version.version,
        createdAt: version.metadata.createdAt,
        createdBy: version.metadata.createdBy,
        type: version.metadata.versionType,
        description: version.metadata.description,
        changes: await this.summarizeChanges(version),
        promotions: await this.getPromotions(version.id),
      };

      history.push(entry);
    }

    return history;
  }

  async getVersionGraph(workflowId: string): Promise<VersionGraph> {
    const versions = await this.versionStore.listVersions(workflowId);
    const graph = new VersionGraph();

    // ë…¸ë“œ ì¶”ê°€
    for (const version of versions) {
      graph.addNode({
        id: version.id,
        version: version.version,
        metadata: version.metadata,
      });
    }

    // ì—£ì§€ ì¶”ê°€ (ë¶€ëª¨-ìì‹ ê´€ê³„)
    for (const version of versions) {
      if (version.metadata.parentVersion) {
        graph.addEdge(
          version.metadata.parentVersion,
          version.id,
          version.metadata.versionType
        );
      }
    }

    return graph;
  }

  async getBranches(workflowId: string): Promise<VersionBranch[]> {
    const graph = await this.getVersionGraph(workflowId);
    return graph.identifyBranches();
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ë²„ì „ ìƒì„± ë° ê´€ë¦¬
- [ ] ë²„ì „ ë¹„êµ ë° ë³‘í•©
- [ ] í”„ë¡œëª¨ì…˜ ë° ë¡¤ë°±
- [ ] ë²„ì „ ì´ë ¥ ì¶”ì 

### Task 5.6: ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ë° ì¬ì‚¬ìš© ì‹œìŠ¤í…œ

#### SubTask 5.6.1: í…œí”Œë¦¿ ì €ì¥ì†Œ êµ¬ì¶•

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/templates/template_repository.ts
export interface WorkflowTemplate {
  id: string;
  name: string;
  version: string;
  description: string;
  category: string;
  tags: string[];
  author: string;
  organization?: string;
  visibility: "public" | "private" | "organization";

  // í…œí”Œë¦¿ ë‚´ìš©
  definition: TemplateDefinition;
  parameters: TemplateParameter[];
  examples: TemplateExample[];

  // ë©”íƒ€ë°ì´í„°
  created_at: Date;
  updated_at: Date;
  downloads: number;
  rating: number;
  verified: boolean;
}

export class TemplateRepository {
  private storage: TemplateStorage;
  private validator: TemplateValidator;
  private indexer: TemplateIndexer;

  constructor(config: RepositoryConfig) {
    this.storage = new TemplateStorage(config.storage);
    this.validator = new TemplateValidator();
    this.indexer = new TemplateIndexer(config.search);
  }

  async createTemplate(
    template: Omit<
      WorkflowTemplate,
      "id" | "created_at" | "updated_at" | "downloads" | "rating"
    >
  ): Promise<WorkflowTemplate> {
    // ê²€ì¦
    const validation = await this.validator.validate(template);
    if (!validation.valid) {
      throw new TemplateValidationError(validation.errors);
    }

    // ID ìƒì„±
    const id = this.generateTemplateId(template.name, template.version);

    // í…œí”Œë¦¿ ìƒì„±
    const fullTemplate: WorkflowTemplate = {
      ...template,
      id,
      created_at: new Date(),
      updated_at: new Date(),
      downloads: 0,
      rating: 0,
    };

    // ì €ì¥
    await this.storage.save(fullTemplate);

    // ì¸ë±ì‹±
    await this.indexer.index(fullTemplate);

    // ì´ë²¤íŠ¸ ë°œí–‰
    await this.publishEvent("template.created", fullTemplate);

    return fullTemplate;
  }

  async searchTemplates(
    query: TemplateSearchQuery
  ): Promise<TemplateSearchResult> {
    // ê²€ìƒ‰ ì‹¤í–‰
    const searchResults = await this.indexer.search(query);

    // í…œí”Œë¦¿ ë¡œë“œ
    const templates = await Promise.all(
      searchResults.hits.map((hit) => this.storage.get(hit.id))
    );

    // í•„í„°ë§ ì ìš©
    const filtered = this.applyFilters(templates, query.filters);

    // ì •ë ¬
    const sorted = this.sortTemplates(filtered, query.sort);

    // í˜ì´ì§•
    const paginated = this.paginate(sorted, query.page, query.limit);

    return {
      templates: paginated,
      total: filtered.length,
      page: query.page,
      limit: query.limit,
      facets: await this.calculateFacets(filtered),
    };
  }

  async getTemplate(
    templateId: string,
    options: GetTemplateOptions = {}
  ): Promise<WorkflowTemplate | null> {
    const template = await this.storage.get(templateId);

    if (!template) {
      return null;
    }

    // ì ‘ê·¼ ê¶Œí•œ í™•ì¸
    if (!(await this.checkAccess(template, options.userId))) {
      throw new TemplateAccessError("Access denied");
    }

    // ë‹¤ìš´ë¡œë“œ ì¹´ìš´íŠ¸ ì¦ê°€
    if (options.incrementDownload) {
      await this.incrementDownloadCount(templateId);
    }

    // ê´€ë ¨ í…œí”Œë¦¿ ë¡œë“œ
    if (options.includeRelated) {
      template.related = await this.findRelatedTemplates(template);
    }

    return template;
  }

  async updateTemplate(
    templateId: string,
    updates: Partial<WorkflowTemplate>,
    userId: string
  ): Promise<WorkflowTemplate> {
    const existing = await this.getTemplate(templateId);

    if (!existing) {
      throw new TemplateNotFoundError(templateId);
    }

    // ê¶Œí•œ í™•ì¸
    if (existing.author !== userId && !(await this.isAdmin(userId))) {
      throw new TemplateAccessError("Only author can update template");
    }

    // ì—…ë°ì´íŠ¸ ì ìš©
    const updated = {
      ...existing,
      ...updates,
      updated_at: new Date(),
    };

    // ë²„ì „ ê´€ë¦¬
    if (updates.definition && !updates.version) {
      updated.version = this.incrementVersion(existing.version);
    }

    // ê²€ì¦
    const validation = await this.validator.validate(updated);
    if (!validation.valid) {
      throw new TemplateValidationError(validation.errors);
    }

    // ì €ì¥
    await this.storage.save(updated);

    // ì¬ì¸ë±ì‹±
    await this.indexer.reindex(updated);

    // ì´ë²¤íŠ¸ ë°œí–‰
    await this.publishEvent("template.updated", updated);

    return updated;
  }

  async forkTemplate(
    templateId: string,
    userId: string,
    modifications: Partial<WorkflowTemplate> = {}
  ): Promise<WorkflowTemplate> {
    const original = await this.getTemplate(templateId);

    if (!original) {
      throw new TemplateNotFoundError(templateId);
    }

    // í¬í¬ ìƒì„±
    const forked = {
      ...original,
      ...modifications,
      id: undefined as any,
      name: modifications.name || `${original.name} (Fork)`,
      author: userId,
      visibility: "private" as const,
      downloads: 0,
      rating: 0,
      verified: false,
      forked_from: templateId,
      created_at: new Date(),
      updated_at: new Date(),
    };

    // ìƒˆ í…œí”Œë¦¿ìœ¼ë¡œ ìƒì„±
    return this.createTemplate(forked);
  }

  async rateTemplate(
    templateId: string,
    userId: string,
    rating: number
  ): Promise<void> {
    if (rating < 1 || rating > 5) {
      throw new Error("Rating must be between 1 and 5");
    }

    // ì¤‘ë³µ í‰ê°€ ë°©ì§€
    const existingRating = await this.storage.getRating(templateId, userId);
    if (existingRating) {
      throw new Error("User has already rated this template");
    }

    // í‰ê°€ ì €ì¥
    await this.storage.saveRating(templateId, userId, rating);

    // í‰ê·  í‰ì  ì¬ê³„ì‚°
    const newAverage = await this.storage.calculateAverageRating(templateId);

    // í…œí”Œë¦¿ ì—…ë°ì´íŠ¸
    await this.storage.updateRating(templateId, newAverage);
  }

  private async checkAccess(
    template: WorkflowTemplate,
    userId?: string
  ): Promise<boolean> {
    if (template.visibility === "public") {
      return true;
    }

    if (!userId) {
      return false;
    }

    if (template.author === userId) {
      return true;
    }

    if (template.visibility === "organization" && template.organization) {
      return await this.userBelongsToOrganization(
        userId,
        template.organization
      );
    }

    return false;
  }
}

// í…œí”Œë¦¿ ì €ì¥ì†Œ
export class TemplateStorage {
  private db: Database;
  private s3: S3Client;

  constructor(config: StorageConfig) {
    this.db = new Database(config.database);
    this.s3 = new S3Client(config.s3);
  }

  async save(template: WorkflowTemplate): Promise<void> {
    // ë©”íƒ€ë°ì´í„°ëŠ” DBì— ì €ì¥
    await this.db.templates.upsert({
      id: template.id,
      name: template.name,
      version: template.version,
      description: template.description,
      category: template.category,
      tags: template.tags,
      author: template.author,
      organization: template.organization,
      visibility: template.visibility,
      created_at: template.created_at,
      updated_at: template.updated_at,
      downloads: template.downloads,
      rating: template.rating,
      verified: template.verified,
    });

    // í…œí”Œë¦¿ ì •ì˜ëŠ” S3ì— ì €ì¥
    const definitionKey = `templates/${template.id}/definition.json`;
    await this.s3.putObject({
      Bucket: "workflow-templates",
      Key: definitionKey,
      Body: JSON.stringify(template.definition),
      ContentType: "application/json",
    });

    // íŒŒë¼ë¯¸í„° ì €ì¥
    const parametersKey = `templates/${template.id}/parameters.json`;
    await this.s3.putObject({
      Bucket: "workflow-templates",
      Key: parametersKey,
      Body: JSON.stringify(template.parameters),
      ContentType: "application/json",
    });

    // ì˜ˆì œ ì €ì¥
    for (let i = 0; i < template.examples.length; i++) {
      const exampleKey = `templates/${template.id}/examples/${i}.json`;
      await this.s3.putObject({
        Bucket: "workflow-templates",
        Key: exampleKey,
        Body: JSON.stringify(template.examples[i]),
        ContentType: "application/json",
      });
    }
  }

  async get(templateId: string): Promise<WorkflowTemplate | null> {
    // ë©”íƒ€ë°ì´í„° ë¡œë“œ
    const metadata = await this.db.templates.findById(templateId);
    if (!metadata) {
      return null;
    }

    // í…œí”Œë¦¿ ì •ì˜ ë¡œë“œ
    const definitionKey = `templates/${templateId}/definition.json`;
    const definitionObj = await this.s3.getObject({
      Bucket: "workflow-templates",
      Key: definitionKey,
    });
    const definition = JSON.parse(definitionObj.Body.toString());

    // íŒŒë¼ë¯¸í„° ë¡œë“œ
    const parametersKey = `templates/${templateId}/parameters.json`;
    const parametersObj = await this.s3.getObject({
      Bucket: "workflow-templates",
      Key: parametersKey,
    });
    const parameters = JSON.parse(parametersObj.Body.toString());

    // ì˜ˆì œ ë¡œë“œ
    const examples = await this.loadExamples(templateId);

    return {
      ...metadata,
      definition,
      parameters,
      examples,
    };
  }

  private async loadExamples(templateId: string): Promise<TemplateExample[]> {
    const examples: TemplateExample[] = [];
    let i = 0;

    while (true) {
      try {
        const exampleKey = `templates/${templateId}/examples/${i}.json`;
        const exampleObj = await this.s3.getObject({
          Bucket: "workflow-templates",
          Key: exampleKey,
        });
        examples.push(JSON.parse(exampleObj.Body.toString()));
        i++;
      } catch (error) {
        if (error.Code === "NoSuchKey") {
          break;
        }
        throw error;
      }
    }

    return examples;
  }
}

// í…œí”Œë¦¿ ì¸ë±ì„œ
export class TemplateIndexer {
  private searchClient: ElasticsearchClient;

  constructor(config: SearchConfig) {
    this.searchClient = new ElasticsearchClient(config);
  }

  async index(template: WorkflowTemplate): Promise<void> {
    const document = {
      id: template.id,
      name: template.name,
      description: template.description,
      category: template.category,
      tags: template.tags,
      author: template.author,
      organization: template.organization,
      visibility: template.visibility,
      downloads: template.downloads,
      rating: template.rating,
      verified: template.verified,
      created_at: template.created_at,

      // ê²€ìƒ‰ìš© í•„ë“œ
      search_text: `${template.name} ${template.description} ${template.tags.join(" ")}`,

      // íŒ¨ì‹¯ìš© í•„ë“œ
      category_facet: template.category,
      tags_facet: template.tags,
      author_facet: template.author,
      visibility_facet: template.visibility,
    };

    await this.searchClient.index({
      index: "workflow-templates",
      id: template.id,
      body: document,
    });
  }

  async search(query: TemplateSearchQuery): Promise<SearchResult> {
    const searchBody = {
      query: this.buildQuery(query),
      aggs: this.buildAggregations(),
      from: (query.page - 1) * query.limit,
      size: query.limit,
      sort: this.buildSort(query.sort),
    };

    const response = await this.searchClient.search({
      index: "workflow-templates",
      body: searchBody,
    });

    return {
      hits: response.hits.hits.map((hit) => ({
        id: hit._id,
        score: hit._score,
        ...hit._source,
      })),
      total: response.hits.total.value,
      aggregations: response.aggregations,
    };
  }

  private buildQuery(query: TemplateSearchQuery): any {
    const must = [];
    const filter = [];

    // í…ìŠ¤íŠ¸ ê²€ìƒ‰
    if (query.text) {
      must.push({
        multi_match: {
          query: query.text,
          fields: ["name^3", "description^2", "tags", "search_text"],
          type: "best_fields",
          fuzziness: "AUTO",
        },
      });
    }

    // í•„í„°
    if (query.filters) {
      if (query.filters.category) {
        filter.push({
          term: { category_facet: query.filters.category },
        });
      }

      if (query.filters.tags && query.filters.tags.length > 0) {
        filter.push({
          terms: { tags_facet: query.filters.tags },
        });
      }

      if (query.filters.author) {
        filter.push({
          term: { author_facet: query.filters.author },
        });
      }

      if (query.filters.visibility) {
        filter.push({
          term: { visibility_facet: query.filters.visibility },
        });
      }

      if (query.filters.verified !== undefined) {
        filter.push({
          term: { verified: query.filters.verified },
        });
      }

      if (query.filters.minRating) {
        filter.push({
          range: { rating: { gte: query.filters.minRating } },
        });
      }
    }

    return {
      bool: {
        must,
        filter,
      },
    };
  }

  private buildAggregations(): any {
    return {
      categories: {
        terms: {
          field: "category_facet",
          size: 20,
        },
      },
      tags: {
        terms: {
          field: "tags_facet",
          size: 50,
        },
      },
      authors: {
        terms: {
          field: "author_facet",
          size: 20,
        },
      },
      visibility: {
        terms: {
          field: "visibility_facet",
        },
      },
      rating_ranges: {
        range: {
          field: "rating",
          ranges: [
            { from: 4, to: 5, key: "4-5 stars" },
            { from: 3, to: 4, key: "3-4 stars" },
            { from: 2, to: 3, key: "2-3 stars" },
            { from: 1, to: 2, key: "1-2 stars" },
          ],
        },
      },
    };
  }

  private buildSort(sort?: TemplateSort): any {
    if (!sort) {
      return [{ downloads: "desc" }, { rating: "desc" }];
    }

    switch (sort.field) {
      case "downloads":
        return [{ downloads: sort.order }];
      case "rating":
        return [{ rating: sort.order }];
      case "created_at":
        return [{ created_at: sort.order }];
      case "name":
        return [{ "name.keyword": sort.order }];
      default:
        return [{ _score: "desc" }];
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í…œí”Œë¦¿ CRUD ì‘ì—…
- [ ] ê²€ìƒ‰ ë° í•„í„°ë§
- [ ] ë²„ì „ ê´€ë¦¬
- [ ] ê¶Œí•œ ë° ê³µìœ 

#### SubTask 5.6.2: í…œí”Œë¦¿ íŒŒë¼ë¯¸í„°í™” ì‹œìŠ¤í…œ

**ë‹´ë‹¹ì**: í…œí”Œë¦¿ ì—”ì§„ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/templates/parameterization.ts
export interface TemplateParameter {
  name: string;
  type: ParameterType;
  description?: string;
  required: boolean;
  default?: any;
  validation?: ParameterValidation;
  ui_hints?: UIHints;
}

export enum ParameterType {
  STRING = "string",
  NUMBER = "number",
  BOOLEAN = "boolean",
  ARRAY = "array",
  OBJECT = "object",
  CHOICE = "choice",
  FILE = "file",
  SECRET = "secret",
  TEMPLATE_REF = "template_ref",
}

export interface ParameterValidation {
  // String validations
  minLength?: number;
  maxLength?: number;
  pattern?: string;

  // Number validations
  min?: number;
  max?: number;
  step?: number;

  // Array validations
  minItems?: number;
  maxItems?: number;
  uniqueItems?: boolean;

  // Choice validations
  choices?: any[];

  // Custom validation
  custom?: string; // JavaScript expression
}

export class TemplateParameterizer {
  private validator: ParameterValidator;
  private resolver: ParameterResolver;
  private transformer: ParameterTransformer;

  constructor() {
    this.validator = new ParameterValidator();
    this.resolver = new ParameterResolver();
    this.transformer = new ParameterTransformer();
  }

  async instantiateTemplate(
    template: WorkflowTemplate,
    parameters: Record<string, any>
  ): Promise<WorkflowDefinition> {
    // 1. íŒŒë¼ë¯¸í„° ê²€ì¦
    const validation = await this.validator.validateParameters(
      template.parameters,
      parameters
    );

    if (!validation.valid) {
      throw new ParameterValidationError(validation.errors);
    }

    // 2. ê¸°ë³¸ê°’ ì ìš©
    const resolvedParams = this.applyDefaults(template.parameters, parameters);

    // 3. í…œí”Œë¦¿ ë³€í™˜
    const transformed = await this.transformer.transform(
      template.definition,
      resolvedParams
    );

    // 4. í›„ì²˜ë¦¬
    const postProcessed = await this.postProcess(transformed, resolvedParams);

    return postProcessed;
  }

  private applyDefaults(
    paramDefs: TemplateParameter[],
    provided: Record<string, any>
  ): Record<string, any> {
    const result = { ...provided };

    for (const paramDef of paramDefs) {
      if (!(paramDef.name in result) && paramDef.default !== undefined) {
        result[paramDef.name] = paramDef.default;
      }
    }

    return result;
  }

  async generateParameterForm(
    template: WorkflowTemplate
  ): Promise<ParameterForm> {
    const form: ParameterForm = {
      sections: [],
      validation: {},
      dependencies: {},
    };

    // íŒŒë¼ë¯¸í„°ë¥¼ ì„¹ì…˜ë³„ë¡œ ê·¸ë£¹í™”
    const sections = this.groupParameters(template.parameters);

    for (const [sectionName, params] of sections) {
      const section: FormSection = {
        name: sectionName,
        title: this.humanize(sectionName),
        fields: [],
      };

      for (const param of params) {
        const field = await this.generateField(param);
        section.fields.push(field);

        // ê²€ì¦ ê·œì¹™ ì¶”ê°€
        if (param.validation) {
          form.validation[param.name] = param.validation;
        }
      }

      form.sections.push(section);
    }

    // íŒŒë¼ë¯¸í„° ê°„ ì˜ì¡´ì„± ë¶„ì„
    form.dependencies = this.analyzeDependencies(template.parameters);

    return form;
  }

  private async generateField(param: TemplateParameter): Promise<FormField> {
    const field: FormField = {
      name: param.name,
      label: param.ui_hints?.label || this.humanize(param.name),
      type: this.mapParameterTypeToFieldType(param.type),
      required: param.required,
      description: param.description,
      placeholder: param.ui_hints?.placeholder,
      help: param.ui_hints?.help,
    };

    // íƒ€ì…ë³„ íŠ¹ìˆ˜ ì²˜ë¦¬
    switch (param.type) {
      case ParameterType.CHOICE:
        field.options = param.validation?.choices?.map((choice) => ({
          value: choice.value || choice,
          label: choice.label || choice,
        }));
        break;

      case ParameterType.FILE:
        field.accept = param.ui_hints?.accept;
        field.maxSize = param.validation?.maxSize;
        break;

      case ParameterType.SECRET:
        field.type = "password";
        field.autocomplete = "off";
        break;

      case ParameterType.TEMPLATE_REF:
        field.type = "template-selector";
        field.templateFilter = param.ui_hints?.templateFilter;
        break;
    }

    return field;
  }
}

// íŒŒë¼ë¯¸í„° ë³€í™˜ê¸°
export class ParameterTransformer {
  private templateEngine: TemplateEngine;
  private expressionEvaluator: ExpressionEvaluator;

  constructor() {
    this.templateEngine = new TemplateEngine();
    this.expressionEvaluator = new ExpressionEvaluator();
  }

  async transform(
    definition: TemplateDefinition,
    parameters: Record<string, any>
  ): Promise<WorkflowDefinition> {
    // ê¹Šì€ ë³µì‚¬
    const result = _.cloneDeep(definition);

    // ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    const context = this.createTransformContext(parameters);

    // ì¬ê·€ì  ë³€í™˜
    await this.transformNode(result, context);

    return result as WorkflowDefinition;
  }

  private async transformNode(
    node: any,
    context: TransformContext
  ): Promise<void> {
    if (typeof node === "string") {
      // ë¬¸ìì—´ í…œí”Œë¦¿ ì²˜ë¦¬
      return this.transformString(node, context);
    } else if (Array.isArray(node)) {
      // ë°°ì—´ ì²˜ë¦¬
      for (let i = 0; i < node.length; i++) {
        node[i] = await this.transformNode(node[i], context);
      }
    } else if (typeof node === "object" && node !== null) {
      // ê°ì²´ ì²˜ë¦¬
      for (const key of Object.keys(node)) {
        // íŠ¹ìˆ˜ í‚¤ ì²˜ë¦¬
        if (key === "$if") {
          await this.handleConditional(node, context);
        } else if (key === "$foreach") {
          await this.handleLoop(node, context);
        } else if (key === "$include") {
          await this.handleInclude(node, context);
        } else {
          // ì¼ë°˜ ì†ì„± ë³€í™˜
          node[key] = await this.transformNode(node[key], context);
        }
      }
    }

    return node;
  }

  private async transformString(
    str: string,
    context: TransformContext
  ): Promise<any> {
    // í…œí”Œë¦¿ ë³€ìˆ˜ íŒ¨í„´: ${variable}
    const templatePattern = /\$\{([^}]+)\}/g;

    // í‘œí˜„ì‹ íŒ¨í„´: ${{expression}}
    const expressionPattern = /\$\{\{([^}]+)\}\}/g;

    let result = str;

    // late{s} ì²˜ë¦¬
    result = await this.templateEngine.render(result, context.parameters);

    // í‘œí˜„ì‹ ì²˜ë¦¬
    const expressions = result.matchAll(expressionPattern);
    for (const match of expressions) {
      const expression = match[1];
      const value = await this.expressionEvaluator.evaluate(
        expression,
        context
      );
      result = result.replace(match[0], value);
    }

    // íƒ€ì… ë³€í™˜ ì‹œë„
    if (result === str) {
      // ë³€í™˜ë˜ì§€ ì•Šì€ ê²½ìš° ì›ë³¸ ë°˜í™˜
      return str;
    } else if (result === "true" || result === "false") {
      return result === "true";
    } else if (!isNaN(Number(result))) {
      return Number(result);
    }

    return result;
  }

  private async handleConditional(
    node: any,
    context: TransformContext
  ): Promise<void> {
    const condition = node.$if;
    const thenBlock = node.$then;
    const elseBlock = node.$else;

    const conditionResult = await this.expressionEvaluator.evaluate(
      condition,
      context
    );

    if (conditionResult) {
      // then ë¸”ë¡ ì ìš©
      Object.assign(node, thenBlock);
    } else if (elseBlock) {
      // else ë¸”ë¡ ì ìš©
      Object.assign(node, elseBlock);
    }

    // íŠ¹ìˆ˜ í‚¤ ì œê±°
    delete node.$if;
    delete node.$then;
    delete node.$else;
  }

  private async handleLoop(
    node: any,
    context: TransformContext
  ): Promise<void> {
    const loopSpec = node.$foreach;
    const itemVar = loopSpec.item || "item";
    const indexVar = loopSpec.index || "index";
    const collection = await this.resolveValue(loopSpec.in, context);
    const template = node.$body;

    if (!Array.isArray(collection)) {
      throw new Error(`$foreach requires an array, got ${typeof collection}`);
    }

    const results = [];

    for (let i = 0; i < collection.length; i++) {
      // ë£¨í”„ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
      const loopContext = {
        ...context,
        [itemVar]: collection[i],
        [indexVar]: i,
      };

      // í…œí”Œë¦¿ ì¸ìŠ¤í„´ìŠ¤í™”
      const instance = _.cloneDeep(template);
      await this.transformNode(instance, loopContext);
      results.push(instance);
    }

    // ê²°ê³¼ë¡œ ëŒ€ì²´
    if (node.$target) {
      node[node.$target] = results;
      delete node.$foreach;
      delete node.$body;
      delete node.$target;
    } else {
      // ë¶€ëª¨ ë…¸ë“œë¥¼ ë°°ì—´ë¡œ ëŒ€ì²´
      return results;
    }
  }
}

// íŒŒë¼ë¯¸í„° ê²€ì¦ê¸°
export class ParameterValidator {
  async validateParameters(
    definitions: TemplateParameter[],
    provided: Record<string, any>
  ): Promise<ValidationResult> {
    const errors: ValidationError[] = [];

    for (const def of definitions) {
      const value = provided[def.name];

      // í•„ìˆ˜ íŒŒë¼ë¯¸í„° ê²€ì‚¬
      if (def.required && value === undefined) {
        errors.push({
          parameter: def.name,
          message: `Required parameter '${def.name}' is missing`,
          type: "required",
        });
        continue;
      }

      if (value !== undefined) {
        // íƒ€ì… ê²€ì¦
        const typeErrors = this.validateType(def, value);
        errors.push(...typeErrors);

        // ì œì•½ ì¡°ê±´ ê²€ì¦
        if (def.validation) {
          const constraintErrors = await this.validateConstraints(def, value);
          errors.push(...constraintErrors);
        }
      }
    }

    // ì¶”ê°€ íŒŒë¼ë¯¸í„° ê²€ì‚¬
    const definedNames = new Set(definitions.map((d) => d.name));
    for (const providedName of Object.keys(provided)) {
      if (!definedNames.has(providedName)) {
        errors.push({
          parameter: providedName,
          message: `Unknown parameter '${providedName}'`,
          type: "unknown",
        });
      }
    }

    return {
      valid: errors.length === 0,
      errors,
    };
  }

  private validateType(def: TemplateParameter, value: any): ValidationError[] {
    const errors: ValidationError[] = [];

    switch (def.type) {
      case ParameterType.STRING:
        if (typeof value !== "string") {
          errors.push({
            parameter: def.name,
            message: `Expected string, got ${typeof value}`,
            type: "type_mismatch",
          });
        }
        break;

      case ParameterType.NUMBER:
        if (typeof value !== "number") {
          errors.push({
            parameter: def.name,
            message: `Expected number, got ${typeof value}`,
            type: "type_mismatch",
          });
        }
        break;

      case ParameterType.BOOLEAN:
        if (typeof value !== "boolean") {
          errors.push({
            parameter: def.name,
            message: `Expected boolean, got ${typeof value}`,
            type: "type_mismatch",
          });
        }
        break;

      case ParameterType.ARRAY:
        if (!Array.isArray(value)) {
          errors.push({
            parameter: def.name,
            message: `Expected array, got ${typeof value}`,
            type: "type_mismatch",
          });
        }
        break;

      case ParameterType.OBJECT:
        if (typeof value !== "object" || value === null) {
          errors.push({
            parameter: def.name,
            message: `Expected object, got ${typeof value}`,
            type: "type_mismatch",
          });
        }
        break;
    }

    return errors;
  }

  private async validateConstraints(
    def: TemplateParameter,
    value: any
  ): Promise<ValidationError[]> {
    const errors: ValidationError[] = [];
    const validation = def.validation!;

    // String constraints
    if (def.type === ParameterType.STRING) {
      if (validation.minLength && value.length < validation.minLength) {
        errors.push({
          parameter: def.name,
          message: `Minimum length is ${validation.minLength}`,
          type: "constraint_violation",
        });
      }

      if (validation.maxLength && value.length > validation.maxLength) {
        errors.push({
          parameter: def.name,
          message: `Maximum length is ${validation.maxLength}`,
          type: "constraint_violation",
        });
      }

      if (validation.pattern) {
        const regex = new RegExp(validation.pattern);
        if (!regex.test(value)) {
          errors.push({
            parameter: def.name,
            message: `Does not match pattern: ${validation.pattern}`,
            type: "constraint_violation",
          });
        }
      }
    }

    // Number constraints
    if (def.type === ParameterType.NUMBER) {
      if (validation.min !== undefined && value < validation.min) {
        errors.push({
          parameter: def.name,
          message: `Minimum value is ${validation.min}`,
          type: "constraint_violation",
        });
      }

      if (validation.max !== undefined && value > validation.max) {
        errors.push({
          parameter: def.name,
          message: `Maximum value is ${validation.max}`,
          type: "constraint_violation",
        });
      }
    }

    // Choice constraints
    if (def.type === ParameterType.CHOICE && validation.choices) {
      const validChoices = validation.choices.map((c) => c.value || c);
      if (!validChoices.includes(value)) {
        errors.push({
          parameter: def.name,
          message: `Invalid choice. Must be one of: ${validChoices.join(", ")}`,
          type: "constraint_violation",
        });
      }
    }

    // Custom validation
    if (validation.custom) {
      try {
        const customResult = await this.evaluateCustomValidation(
          validation.custom,
          value,
          def
        );
        if (!customResult.valid) {
          errors.push({
            parameter: def.name,
            message: customResult.message || "Custom validation failed",
            type: "custom_validation",
          });
        }
      } catch (e) {
        errors.push({
          parameter: def.name,
          message: `Custom validation error: ${e.message}`,
          type: "validation_error",
        });
      }
    }

    return errors;
  }

  private async evaluateCustomValidation(
    expression: string,
    value: any,
    parameter: TemplateParameter
  ): Promise<{ valid: boolean; message?: string }> {
    // ì•ˆì „í•œ ì»¨í…ìŠ¤íŠ¸ì—ì„œ í‘œí˜„ì‹ í‰ê°€
    const sandbox = {
      value,
      parameter,
      // ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
      isEmail: (v: string) => /^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(v),
      isURL: (v: string) => {
        try {
          new URL(v);
          return true;
        } catch {
          return false;
        }
      },
      isUUID: (v: string) =>
        /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(
          v
        ),
    };

    // í‘œí˜„ì‹ ì‹¤í–‰
    const fn = new Function(...Object.keys(sandbox), `return ${expression}`);
    const result = fn(...Object.values(sandbox));

    if (typeof result === "boolean") {
      return { valid: result };
    } else if (typeof result === "object" && result !== null) {
      return result;
    } else {
      return {
        valid: false,
        message: "Validation must return boolean or {valid, message}",
      };
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] íŒŒë¼ë¯¸í„° ì •ì˜ ì‹œìŠ¤í…œ
- [ ] í…œí”Œë¦¿ ë³€í™˜ ì—”ì§„
- [ ] ë™ì  í¼ ìƒì„±
- [ ] ê²€ì¦ ë° íƒ€ì… ì²´í¬

#### SubTask 5.6.3: í…œí”Œë¦¿ ìƒì† ë° í™•ì¥ ë©”ì»¤ë‹ˆì¦˜

**ë‹´ë‹¹ì**: í…œí”Œë¦¿ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/templates/inheritance.ts
export interface TemplateInheritance {
  extends?: string; // ë¶€ëª¨ í…œí”Œë¦¿ ID
  abstract?: boolean; // ì¶”ìƒ í…œí”Œë¦¿ ì—¬ë¶€
  overrides?: string[]; // ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥í•œ ì„¹ì…˜
  final?: string[]; // ì˜¤ë²„ë¼ì´ë“œ ë¶ˆê°€ëŠ¥í•œ ì„¹ì…˜
  mixins?: string[]; // ë¯¹ìŠ¤ì¸ í…œí”Œë¦¿ IDë“¤
}

export class TemplateInheritanceEngine {
  private templateRepo: TemplateRepository;
  private mergeEngine: TemplateMergeEngine;
  private overrideValidator: OverrideValidator;

  constructor(repo: TemplateRepository) {
    this.templateRepo = repo;
    this.mergeEngine = new TemplateMergeEngine();
    this.overrideValidator = new OverrideValidator();
  }

  async resolveTemplate(
    templateId: string,
    visited: Set<string> = new Set()
  ): Promise<ResolvedTemplate> {
    // ìˆœí™˜ ì°¸ì¡° ë°©ì§€
    if (visited.has(templateId)) {
      throw new CircularInheritanceError(
        `Circular inheritance detected: ${Array.from(visited).join(" -> ")} -> ${templateId}`
      );
    }
    visited.add(templateId);

    // í…œí”Œë¦¿ ë¡œë“œ
    const template = await this.templateRepo.getTemplate(templateId);
    if (!template) {
      throw new TemplateNotFoundError(templateId);
    }

    // ìƒì† ì •ë³´ í™•ì¸
    const inheritance = template.definition.inheritance;
    if (!inheritance || !inheritance.extends) {
      // ê¸°ë³¸ í…œí”Œë¦¿ì¸ ê²½ìš°
      return this.applyMixins(template, inheritance);
    }

    // ë¶€ëª¨ í…œí”Œë¦¿ í•´ê²°
    const parent = await this.resolveTemplate(
      inheritance.extends,
      new Set(visited)
    );

    // ìƒì† ê²€ì¦
    await this.validateInheritance(parent, template);

    // í…œí”Œë¦¿ ë³‘í•©
    const merged = await this.mergeTemplates(parent, template);

    // ë¯¹ìŠ¤ì¸ ì ìš©
    return this.applyMixins(merged, inheritance);
  }

  private async validateInheritance(
    parent: ResolvedTemplate,
    child: WorkflowTemplate
  ): Promise<void> {
    const parentDef = parent.definition;
    const childDef = child.definition;

    // ì¶”ìƒ í…œí”Œë¦¿ì€ ì§ì ‘ ì‚¬ìš© ë¶ˆê°€
    if (parentDef.inheritance?.abstract) {
      // ìì‹ë„ ì¶”ìƒì´ì–´ì•¼ í•¨
      if (!childDef.inheritance?.abstract) {
        throw new InheritanceError(
          "Cannot extend abstract template unless child is also abstract"
        );
      }
    }

    // final ì„¹ì…˜ ì˜¤ë²„ë¼ì´ë“œ ê²€ì‚¬
    if (parentDef.inheritance?.final) {
      const overrides = this.findOverrides(parentDef, childDef);
      const violations = overrides.filter((o) =>
        parentDef.inheritance!.final!.includes(o)
      );

      if (violations.length > 0) {
        throw new InheritanceError(
          `Cannot override final sections: ${violations.join(", ")}`
        );
      }
    }

    // í•„ìˆ˜ ì˜¤ë²„ë¼ì´ë“œ ê²€ì‚¬
    if (parentDef.inheritance?.overrides) {
      const required = parentDef.inheritance.overrides
        .filter((o) => o.startsWith("required:"))
        .map((o) => o.substring(9));

      const implemented = this.findOverrides(parentDef, childDef);
      const missing = required.filter((r) => !implemented.includes(r));

      if (missing.length > 0) {
        throw new InheritanceError(
          `Missing required overrides: ${missing.join(", ")}`
        );
      }
    }
  }

  private async mergeTemplates(
    parent: ResolvedTemplate,
    child: WorkflowTemplate
  ): Promise<ResolvedTemplate> {
    const merged = _.cloneDeep(parent);

    // ë©”íƒ€ë°ì´í„° ë³‘í•©
    merged.name = child.name;
    merged.version = child.version;
    merged.description = child.description;
    merged.author = child.author;

    // íŒŒë¼ë¯¸í„° ë³‘í•©
    merged.parameters = this.mergeParameters(
      parent.parameters,
      child.parameters
    );

    // ì •ì˜ ë³‘í•©
    merged.definition = await this.mergeEngine.merge(
      parent.definition,
      child.definition,
      {
        strategy: "override",
        preservePaths: parent.definition.inheritance?.final || [],
      }
    );

    // ìƒì† ì²´ì¸ ì—…ë°ì´íŠ¸
    merged.inheritanceChain = [
      ...(parent.inheritanceChain || []),
      {
        templateId: child.id,
        templateName: child.name,
        version: child.version,
      },
    ];

    return merged;
  }

  private mergeParameters(
    parentParams: TemplateParameter[],
    childParams: TemplateParameter[]
  ): TemplateParameter[] {
    const merged = [...parentParams];
    const parentNames = new Set(parentParams.map((p) => p.name));

    for (const childParam of childParams) {
      const existingIndex = merged.findIndex((p) => p.name === childParam.name);

      if (existingIndex >= 0) {
        // ì˜¤ë²„ë¼ì´ë“œ
        merged[existingIndex] = this.mergeParameter(
          merged[existingIndex],
          childParam
        );
      } else {
        // ìƒˆ íŒŒë¼ë¯¸í„°
        merged.push(childParam);
      }
    }

    return merged;
  }

  private mergeParameter(
    parent: TemplateParameter,
    child: TemplateParameter
  ): TemplateParameter {
    return {
      ...parent,
      ...child,
      // ê²€ì¦ ê·œì¹™ì€ ë³‘í•©
      validation: {
        ...parent.validation,
        ...child.validation,
      },
      // UI íŒíŠ¸ë„ ë³‘í•©
      ui_hints: {
        ...parent.ui_hints,
        ...child.ui_hints,
      },
    };
  }

  private async applyMixins(
    template: ResolvedTemplate,
    inheritance?: TemplateInheritance
  ): Promise<ResolvedTemplate> {
    if (!inheritance?.mixins || inheritance.mixins.length === 0) {
      return template;
    }

    let result = template;

    for (const mixinId of inheritance.mixins) {
      const mixin = await this.templateRepo.getTemplate(mixinId);

      if (!mixin) {
        throw new TemplateNotFoundError(`Mixin ${mixinId} not found`);
      }

      // ë¯¹ìŠ¤ì¸ì€ íŠ¹ì • ì„¹ì…˜ë§Œ ì œê³µ
      result = await this.applyMixin(result, mixin);
    }

    return result;
  }

  private async applyMixin(
    target: ResolvedTemplate,
    mixin: WorkflowTemplate
  ): Promise<ResolvedTemplate> {
    const mixinDef = mixin.definition;

    // ë¯¹ìŠ¤ì¸ì—ì„œ ì œê³µí•˜ëŠ” ì„¹ì…˜ ì‹ë³„
    const providedSections = mixinDef.mixin?.provides || [];

    for (const section of providedSections) {
      const sectionData = _.get(mixinDef, section);

      if (sectionData) {
        // íƒ€ê²Ÿì— ì„¹ì…˜ ì¶”ê°€/ë³‘í•©
        const existing = _.get(target.definition, section);

        if (existing && Array.isArray(existing) && Array.isArray(sectionData)) {
          // ë°°ì—´ ë³‘í•©
          _.set(target.definition, section, [...existing, ...sectionData]);
        } else if (
          existing &&
          typeof existing === "object" &&
          typeof sectionData === "object"
        ) {
          // ê°ì²´ ë³‘í•©
          _.set(target.definition, section, _.merge({}, existing, sectionData));
        } else {
          // ë®ì–´ì“°ê¸°
          _.set(target.definition, section, sectionData);
        }
      }
    }

    // ë¯¹ìŠ¤ì¸ ì²´ì¸ì— ì¶”ê°€
    target.mixinChain = [
      ...(target.mixinChain || []),
      {
        templateId: mixin.id,
        templateName: mixin.name,
        sections: providedSections,
      },
    ];

    return target;
  }
}

// í…œí”Œë¦¿ í™•ì¥ ë¹Œë”
export class TemplateExtensionBuilder {
  private baseTemplate: WorkflowTemplate;
  private extensions: TemplateExtension[] = [];

  constructor(baseTemplate: WorkflowTemplate) {
    this.baseTemplate = baseTemplate;
  }

  extend(extension: TemplateExtension): this {
    this.extensions.push(extension);
    return this;
  }

  override(path: string, value: any): this {
    this.extensions.push({
      type: "override",
      path,
      value,
    });
    return this;
  }

  addTask(position: string, task: WorkflowTask): this {
    this.extensions.push({
      type: "add_task",
      position,
      task,
    });
    return this;
  }

  removeTask(taskId: string): this {
    this.extensions.push({
      type: "remove_task",
      taskId,
    });
    return this;
  }

  modifyTask(taskId: string, modifications: Partial<WorkflowTask>): this {
    this.extensions.push({
      type: "modify_task",
      taskId,
      modifications,
    });
    return this;
  }

  addParameter(parameter: TemplateParameter): this {
    this.extensions.push({
      type: "add_parameter",
      parameter,
    });
    return this;
  }

  build(): ExtendedTemplate {
    const extended = _.cloneDeep(this.baseTemplate);

    // í™•ì¥ ì ìš©
    for (const extension of this.extensions) {
      this.applyExtension(extended, extension);
    }

    // ìƒì† ì •ë³´ ì¶”ê°€
    extended.definition.inheritance = {
      extends: this.baseTemplate.id,
      overrides: this.collectOverrides(),
    };

    return extended;
  }

  private applyExtension(
    template: WorkflowTemplate,
    extension: TemplateExtension
  ): void {
    switch (extension.type) {
      case "override":
        _.set(template.definition, extension.path, extension.value);
        break;

      case "add_task":
        const tasks = template.definition.tasks || [];
        const position = this.findPosition(tasks, extension.position);
        tasks.splice(position, 0, extension.task);
        break;

      case "remove_task":
        template.definition.tasks = template.definition.tasks?.filter(
          (t) => t.id !== extension.taskId
        );
        break;

      case "modify_task":
        const task = template.definition.tasks?.find(
          (t) => t.id === extension.taskId
        );
        if (task) {
          Object.assign(task, extension.modifications);
        }
        break;

      case "add_parameter":
        template.parameters.push(extension.parameter);
        break;
    }
  }

  private collectOverrides(): string[] {
    return this.extensions
      .filter((e) => e.type === "override")
      .map((e) => e.path);
  }
}

// í…œí”Œë¦¿ ì¡°í•©ê¸°
export class TemplateComposer {
  async composeTemplate(
    composition: TemplateComposition
  ): Promise<WorkflowTemplate> {
    const templates: WorkflowTemplate[] = [];

    // ëª¨ë“  í…œí”Œë¦¿ ë¡œë“œ
    for (const ref of composition.templates) {
      const template = await this.loadTemplateRef(ref);
      templates.push(template);
    }

    // ì¡°í•© ì „ëµì— ë”°ë¼ ë³‘í•©
    let composed: WorkflowTemplate;

    switch (composition.strategy) {
      case "sequential":
        composed = this.composeSequential(templates);
        break;

      case "parallel":
        composed = this.composeParallel(templates);
        break;

      case "conditional":
        composed = this.composeConditional(templates, composition.conditions!);
        break;

      case "pipeline":
        composed = this.composePipeline(templates);
        break;

      default:
        throw new Error(
          `Unknown composition strategy: ${composition.strategy}`
        );
    }

    // ë©”íƒ€ë°ì´í„° ì„¤ì •
    composed.name = composition.name;
    composed.description = composition.description;
    composed.composition = composition;

    return composed;
  }

  private composeSequential(templates: WorkflowTemplate[]): WorkflowTemplate {
    const composed = this.createEmptyTemplate();

    // ìˆœì°¨ì ìœ¼ë¡œ íƒœìŠ¤í¬ ì—°ê²°
    let lastTasks: string[] = [];

    for (const template of templates) {
      const offset = composed.definition.tasks.length;

      // íƒœìŠ¤í¬ ë³µì‚¬ (ID ì¡°ì •)
      const adjustedTasks = template.definition.tasks.map((task, index) => ({
        ...task,
        id: `${template.id}_${task.id}`,
        dependencies: [
          ...task.dependencies.map((d) => ({
            ...d,
            task_id: `${template.id}_${d.task_id}`,
          })),
          // ì´ì „ í…œí”Œë¦¿ì˜ ë§ˆì§€ë§‰ íƒœìŠ¤í¬ë“¤ì— ì˜ì¡´
          ...lastTasks.map((taskId) => ({
            task_id: taskId,
            wait_for_completion: true,
          })),
        ],
      }));

      composed.definition.tasks.push(...adjustedTasks);

      // ì´ í…œí”Œë¦¿ì˜ ë§ˆì§€ë§‰ íƒœìŠ¤í¬ë“¤ ì°¾ê¸°
      lastTasks = this.findTerminalTasks(adjustedTasks);

      // íŒŒë¼ë¯¸í„° ë³‘í•©
      composed.parameters.push(...template.parameters);
    }

    return composed;
  }

  private composeParallel(templates: WorkflowTemplate[]): WorkflowTemplate {
    const composed = this.createEmptyTemplate();

    // ë³‘ë ¬ ë¸”ë¡ ìƒì„±
    const parallelBlock: ParallelBlock = {
      id: "parallel_composition",
      tasks: [],
      max_concurrency: templates.length,
    };

    for (const template of templates) {
      // ê° í…œí”Œë¦¿ì„ ì„œë¸Œì›Œí¬í”Œë¡œìš°ë¡œ ë³€í™˜
      const subWorkflow = {
        id: `sub_${template.id}`,
        type: "subworkflow",
        workflow_id: template.id,
        input_mapping: this.createInputMapping(template),
        output_mapping: this.createOutputMapping(template),
      };

      parallelBlock.tasks.push(subWorkflow);
    }

    composed.definition.tasks.push(parallelBlock);

    // ëª¨ë“  íŒŒë¼ë¯¸í„° ë³‘í•© (ì¤‘ë³µ ì œê±°)
    const paramMap = new Map<string, TemplateParameter>();

    for (const template of templates) {
      for (const param of template.parameters) {
        if (!paramMap.has(param.name)) {
          paramMap.set(param.name, param);
        }
      }
    }

    composed.parameters = Array.from(paramMap.values());

    return composed;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í…œí”Œë¦¿ ìƒì† ì‹œìŠ¤í…œ
- [ ] ë¯¹ìŠ¤ì¸ ì§€ì›
- [ ] í™•ì¥ ë¹Œë” API
- [ ] í…œí”Œë¦¿ ì¡°í•© ì „ëµ

#### SubTask 5.6.4: í…œí”Œë¦¿ ê³µìœ  ë§ˆì¼“í”Œë ˆì´ìŠ¤

**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/templates/marketplace.ts
export class TemplateMarketplace {
  private repository: TemplateRepository;
  private reviewService: TemplateReviewService;
  private analyticsService: TemplateAnalyticsService;
  private paymentService: PaymentService;

  constructor(config: MarketplaceConfig) {
    this.repository = new TemplateRepository(config.repository);
    this.reviewService = new TemplateReviewService();
    this.analyticsService = new TemplateAnalyticsService();
    this.paymentService = new PaymentService(config.payment);
  }

  async publishTemplate(
    template: WorkflowTemplate,
    publishOptions: PublishOptions
  ): Promise<PublishedTemplate> {
    // 1. í’ˆì§ˆ ê²€ì‚¬
    const qualityCheck = await this.performQualityCheck(template);

    if (!qualityCheck.passed) {
      throw new QualityCheckError(qualityCheck.issues);
    }

    // 2. ë¼ì´ì„ ìŠ¤ ì„¤ì •
    template.license = publishOptions.license || "MIT";
    template.pricing = publishOptions.pricing || { type: "free" };

    // 3. ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜
    if (!template.category) {
      template.category = await this.categorizeTemplate(template);
    }

    // 4. íƒœê·¸ ìë™ ìƒì„±
    const autoTags = await this.generateTags(template);
    template.tags = [...new Set([...template.tags, ...autoTags])];

    // 5. ê²€ì¦ ë§ˆí¬ ë¶€ì—¬ (ì¡°ê±´ ì¶©ì¡± ì‹œ)
    if (await this.qualifiesForVerification(template)) {
      template.verified = true;
    }

    // 6. ì €ì¥ ë° ë°œí–‰
    const published = await this.repository.createTemplate(template);

    // 7. ê²€ìƒ‰ ì¸ë±ì‹±
    await this.indexForSearch(published);

    // 8. ì•Œë¦¼ ë°œì†¡
    await this.notifyFollowers(published);

    return {
      ...published,
      publishedAt: new Date(),
      status: "published",
    };
  }

  async purchaseTemplate(
    templateId: string,
    userId: string,
    paymentMethod: PaymentMethod
  ): Promise<PurchaseResult> {
    const template = await this.repository.getTemplate(templateId);

    if (!template) {
      throw new TemplateNotFoundError(templateId);
    }

    // ë¬´ë£Œ í…œí”Œë¦¿ ì²˜ë¦¬
    if (template.pricing.type === "free") {
      return {
        success: true,
        templateId,
        transactionId: null,
        accessGranted: true,
      };
    }

    // ì´ë¯¸ êµ¬ë§¤í•œ ê²½ìš°
    if (await this.hasAccess(userId, templateId)) {
      return {
        success: true,
        templateId,
        transactionId: "existing",
        accessGranted: true,
      };
    }

    // ê²°ì œ ì²˜ë¦¬
    const payment = await this.paymentService.processPayment({
      amount: template.pricing.amount,
      currency: template.pricing.currency,
      userId,
      templateId,
      paymentMethod,
    });

    if (payment.success) {
      // ì ‘ê·¼ ê¶Œí•œ ë¶€ì—¬
      await this.grantAccess(userId, templateId);

      // íŒë§¤ìì—ê²Œ ìˆ˜ìµ ë¶„ë°°
      await this.distributeRevenue(
        template.author,
        payment.amount,
        template.pricing.revenueShare || 0.7
      );

      // íŒë§¤ í†µê³„ ì—…ë°ì´íŠ¸
      await this.analyticsService.recordPurchase(templateId, userId);
    }

    return {
      success: payment.success,
      templateId,
      transactionId: payment.transactionId,
      accessGranted: payment.success,
    };
  }

  async getMarketplaceStats(): Promise<MarketplaceStats> {
    const stats = await this.analyticsService.getGlobalStats();

    return {
      totalTemplates: stats.templateCount,
      totalAuthors: stats.authorCount,
      totalDownloads: stats.downloadCount,
      totalRevenue: stats.totalRevenue,
      topCategories: await this.getTopCategories(),
      trendingTemplates: await this.getTrendingTemplates(),
      featuredTemplates: await this.getFeaturedTemplates(),
    };
  }

  async reviewTemplate(
    templateId: string,
    userId: string,
    review: TemplateReview
  ): Promise<void> {
    // êµ¬ë§¤/ì‚¬ìš© í™•ì¸
    if (!(await this.hasUsedTemplate(userId, templateId))) {
      throw new Error("You must use the template before reviewing");
    }

    // ë¦¬ë·° ì €ì¥
    await this.reviewService.addReview({
      templateId,
      userId,
      rating: review.rating,
      title: review.title,
      content: review.content,
      pros: review.pros,
      cons: review.cons,
      createdAt: new Date(),
    });

    // í‰ê·  í‰ì  ì¬ê³„ì‚°
    const avgRating =
      await this.reviewService.calculateAverageRating(templateId);
    await this.repository.updateTemplate(
      templateId,
      { rating: avgRating },
      "system"
    );

    // ì‘ì„±ìì—ê²Œ ì•Œë¦¼
    const template = await this.repository.getTemplate(templateId);
    if (template) {
      await this.notifyAuthor(template.author, "new_review", {
        templateId,
        reviewId: review.id,
        rating: review.rating,
      });
    }
  }

  private async performQualityCheck(
    template: WorkflowTemplate
  ): Promise<QualityCheckResult> {
    const issues: QualityIssue[] = [];

    // 1. ë¬¸ì„œí™” ê²€ì‚¬
    if (!template.description || template.description.length < 100) {
      issues.push({
        severity: "error",
        category: "documentation",
        message: "Description must be at least 100 characters",
      });
    }

    if (!template.examples || template.examples.length === 0) {
      issues.push({
        severity: "error",
        category: "documentation",
        message: "At least one example is required",
      });
    }

    // 2. íŒŒë¼ë¯¸í„° ê²€ì‚¬
    for (const param of template.parameters) {
      if (!param.description) {
        issues.push({
          severity: "warning",
          category: "parameters",
          message: `Parameter '${param.name}' lacks description`,
        });
      }
    }

    // 3. ë³´ì•ˆ ê²€ì‚¬
    const securityIssues = await this.checkSecurity(template);
    issues.push(...securityIssues);

    // 4. ì„±ëŠ¥ ê²€ì‚¬
    const performanceIssues = await this.checkPerformance(template);
    issues.push(...performanceIssues);

    // 5. ëª¨ë²” ì‚¬ë¡€ ê²€ì‚¬
    const bestPracticeIssues = await this.checkBestPractices(template);
    issues.push(...bestPracticeIssues);

    return {
      passed: issues.filter((i) => i.severity === "error").length === 0,
      issues,
      score: this.calculateQualityScore(issues),
    };
  }

  private async checkSecurity(
    template: WorkflowTemplate
  ): Promise<QualityIssue[]> {
    const issues: QualityIssue[] = [];
    const securityScanner = new TemplateSecurityScanner();

    // ë¯¼ê°í•œ ë°ì´í„° ë…¸ì¶œ ê²€ì‚¬
    const exposures = await securityScanner.findDataExposures(template);
    for (const exposure of exposures) {
      issues.push({
        severity: "error",
        category: "security",
        message: `Potential data exposure: ${exposure.description}`,
        location: exposure.location,
      });
    }

    // ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ê²€ì‚¬
    const escalations =
      await securityScanner.findPrivilegeEscalations(template);
    for (const escalation of escalations) {
      issues.push({
        severity: "warning",
        category: "security",
        message: `Potential privilege escalation: ${escalation.description}`,
        location: escalation.location,
      });
    }

    // ì¸ì ì…˜ ì·¨ì•½ì  ê²€ì‚¬
    const injections =
      await securityScanner.findInjectionVulnerabilities(template);
    for (const injection of injections) {
      issues.push({
        severity: "error",
        category: "security",
        message: `Potential injection vulnerability: ${injection.description}`,
        location: injection.location,
      });
    }

    return issues;
  }

  private async categorizeTemplate(
    template: WorkflowTemplate
  ): Promise<string> {
    const classifier = new TemplateCategorizer();

    // í…œí”Œë¦¿ ë‚´ìš© ë¶„ì„
    const features = await classifier.extractFeatures(template);

    // ML ëª¨ë¸ë¡œ ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡
    const predictions = await classifier.predict(features);

    // ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ì¹´í…Œê³ ë¦¬ ì„ íƒ
    return predictions[0].category;
  }

  private async generateTags(template: WorkflowTemplate): Promise<string[]> {
    const tagger = new TemplateAutoTagger();

    // ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ íƒœê·¸ ì¶”ì¶œ
    const tags = new Set<string>();

    // 1. ì—ì´ì „íŠ¸ íƒ€ì…ì—ì„œ ì¶”ì¶œ
    const agentTypes = this.extractAgentTypes(template);
    agentTypes.forEach((type) => tags.add(type.toLowerCase()));

    // 2. ê¸°ìˆ  ìŠ¤íƒì—ì„œ ì¶”ì¶œ
    const techStack = await tagger.detectTechnologyStack(template);
    techStack.forEach((tech) => tags.add(tech.toLowerCase()));

    // 3. ë„ë©”ì¸ í‚¤ì›Œë“œ ì¶”ì¶œ
    const domainKeywords = await tagger.extractDomainKeywords(template);
    domainKeywords.forEach((keyword) => tags.add(keyword.toLowerCase()));

    // 4. íŒ¨í„´ ì¸ì‹
    const patterns = await tagger.recognizePatterns(template);
    patterns.forEach((pattern) => tags.add(pattern.toLowerCase()));

    return Array.from(tags);
  }
}

// í…œí”Œë¦¿ ë¦¬ë·° ì„œë¹„ìŠ¤
export class TemplateReviewService {
  private reviewStore: ReviewStore;
  private sentimentAnalyzer: SentimentAnalyzer;
  private spamDetector: SpamDetector;

  async addReview(review: TemplateReview): Promise<void> {
    // ìŠ¤íŒ¸ ê²€ì‚¬
    if (await this.spamDetector.isSpam(review.content)) {
      throw new Error("Review appears to be spam");
    }

    // ê°ì • ë¶„ì„
    review.sentiment = await this.sentimentAnalyzer.analyze(review.content);

    // ìœ ìš©ì„± ì ìˆ˜ ì´ˆê¸°í™”
    review.helpfulCount = 0;
    review.totalVotes = 0;

    // ì €ì¥
    await this.reviewStore.save(review);

    // ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
    await this.extractInsights(review);
  }

  async voteReview(
    reviewId: string,
    userId: string,
    helpful: boolean
  ): Promise<void> {
    // ì¤‘ë³µ íˆ¬í‘œ ë°©ì§€
    if (await this.hasVoted(userId, reviewId)) {
      throw new Error("Already voted on this review");
    }

    // íˆ¬í‘œ ê¸°ë¡
    await this.reviewStore.recordVote(reviewId, userId, helpful);

    // ìœ ìš©ì„± ì—…ë°ì´íŠ¸
    const review = await this.reviewStore.get(reviewId);
    if (review) {
      if (helpful) {
        review.helpfulCount++;
      }
      review.totalVotes++;
      await this.reviewStore.update(review);
    }
  }

  private async extractInsights(review: TemplateReview): Promise<void> {
    const insights = new InsightExtractor();

    // ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
    const keywords = await insights.extractKeywords(review.content);

    // ê°œì„  ì œì•ˆ ì¶”ì¶œ
    const suggestions = await insights.extractSuggestions(review.content);

    // ê°ì • íŠ¸ë Œë“œ ë¶„ì„
    const sentimentTrend = await insights.analyzeSentimentTrend(
      review.templateId
    );

    // ì¸ì‚¬ì´íŠ¸ ì €ì¥
    await this.storeInsights({
      templateId: review.templateId,
      reviewId: review.id,
      keywords,
      suggestions,
      sentimentTrend,
    });
  }
}

// í…œí”Œë¦¿ ë¶„ì„ ì„œë¹„ìŠ¤
export class TemplateAnalyticsService {
  private metricsCollector: MetricsCollector;
  private trendAnalyzer: TrendAnalyzer;

  async recordUsage(
    templateId: string,
    userId: string,
    usage: TemplateUsage
  ): Promise<void> {
    await this.metricsCollector.record({
      type: "template_usage",
      templateId,
      userId,
      timestamp: new Date(),
      duration: usage.duration,
      success: usage.success,
      errors: usage.errors,
    });

    // ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ì—…ë°ì´íŠ¸
    await this.trendAnalyzer.updateTrend(templateId);
  }

  async getTemplateAnalytics(
    templateId: string,
    timeRange: TimeRange
  ): Promise<TemplateAnalytics> {
    const metrics = await this.metricsCollector.query({
      templateId,
      startTime: timeRange.start,
      endTime: timeRange.end,
    });

    return {
      downloads: metrics.downloads,
      uniqueUsers: metrics.uniqueUsers,
      successRate: metrics.successRate,
      averageDuration: metrics.averageDuration,
      errorRate: metrics.errorRate,
      userRetention: await this.calculateRetention(templateId, timeRange),
      geographicDistribution: await this.getGeographicDistribution(templateId),
      usagePatterns: await this.analyzeUsagePatterns(templateId),
      performanceTrends: await this.getPerformanceTrends(templateId, timeRange),
    };
  }

  async getTrendingTemplates(
    category?: string,
    limit: number = 10
  ): Promise<TrendingTemplate[]> {
    const trends = await this.trendAnalyzer.getTopTrends({
      category,
      metric: "composite", // ë‹¤ìš´ë¡œë“œ, í‰ì , ìµœê·¼ í™œë™ ì¢…í•©
      timeWindow: "7d",
      limit,
    });

    return trends.map((trend) => ({
      templateId: trend.entityId,
      score: trend.score,
      momentum: trend.momentum,
      rank: trend.rank,
      previousRank: trend.previousRank,
      metrics: {
        downloads: trend.metrics.downloads,
        rating: trend.metrics.rating,
        reviews: trend.metrics.reviews,
      },
    }));
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í…œí”Œë¦¿ ë°œí–‰ ì‹œìŠ¤í…œ
- [ ] í’ˆì§ˆ ê²€ì‚¬ ë° ê²€ì¦
- [ ] ë¦¬ë·° ë° í‰ì  ì‹œìŠ¤í…œ
- [ ] ë¶„ì„ ë° íŠ¸ë Œë“œ ì¶”ì 

---
