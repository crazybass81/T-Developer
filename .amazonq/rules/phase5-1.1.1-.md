# Phase 5: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ - Tasks 5.1~5.3 SubTask êµ¬ì¡°

## ğŸ“‹ Task 5.1~5.3 SubTask ë¦¬ìŠ¤íŠ¸

### Task 5.1: ì¤‘ì•™ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì„¤ê³„ ë° êµ¬í˜„

- **SubTask 5.1.1**: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì•„í‚¤í…ì²˜ ì„¤ê³„
- **SubTask 5.1.2**: ì—ì´ì „íŠ¸ í†µí•© ì¸í„°í˜ì´ìŠ¤
- **SubTask 5.1.3**: ì›Œí¬í”Œë¡œìš° ìƒíƒœ ê´€ë¦¬
- **SubTask 5.1.4**: ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹  ì‹œìŠ¤í…œ

### Task 5.2: ì›Œí¬í”Œë¡œìš° ì—”ì§„ êµ¬ì¶•

- **SubTask 5.2.1**: ì›Œí¬í”Œë¡œìš° ì •ì˜ ëª¨ë¸
- **SubTask 5.2.2**: ì›Œí¬í”Œë¡œìš° íŒŒì„œ ë° ê²€ì¦ê¸°
- **SubTask 5.2.3**: ì‹¤í–‰ ìŠ¤ì¼€ì¤„ëŸ¬
- **SubTask 5.2.4**: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ëª¨ë‹ˆí„°

### Task 5.3: ì—ì´ì „íŠ¸ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬

- **SubTask 5.3.1**: ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
- **SubTask 5.3.2**: ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬ ì‹œìŠ¤í…œ
- **SubTask 5.3.3**: ë™ì  ì—ì´ì „íŠ¸ ìŠ¤ì¼€ì¼ë§
- **SubTask 5.3.4**: ì—ì´ì „íŠ¸ ë²„ì „ ê´€ë¦¬

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 5.1: ì¤‘ì•™ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì„¤ê³„ ë° êµ¬í˜„

#### SubTask 5.1.1: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì•„í‚¤í…ì²˜ ì„¤ê³„

**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/core/orchestrator.py
from typing import Dict, List, Optional, Any, AsyncIterator
from dataclasses import dataclass, field
from enum import Enum
import asyncio
from datetime import datetime
import uuid

@dataclass
class OrchestratorConfig:
    max_concurrent_workflows: int = 100
    max_concurrent_tasks: int = 500
    task_timeout_seconds: int = 300
    workflow_timeout_seconds: int = 3600
    enable_auto_recovery: bool = True
    enable_metrics: bool = True
    state_storage_type: str = "dynamodb"
    message_queue_type: str = "sqs"

@dataclass
class WorkflowState(Enum):
    PENDING = "pending"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class TaskState(Enum):
    PENDING = "pending"
    QUEUED = "queued"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    TIMEOUT = "timeout"

class CentralOrchestrator:
    """T-Developer ì¤‘ì•™ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ"""

    def __init__(self, config: OrchestratorConfig):
        self.config = config

        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸
        self.agent_registry: AgentRegistry = None
        self.workflow_engine: WorkflowEngine = None
        self.task_scheduler: TaskScheduler = None
        self.state_manager: StateManager = None
        self.event_bus: EventBus = None
        self.metrics_collector: MetricsCollector = None
        self.resource_manager: ResourceManager = None

        # ì‹¤í–‰ ìƒíƒœ ì¶”ì 
        self.active_workflows: Dict[str, WorkflowExecution] = {}
        self.active_tasks: Dict[str, AgentTask] = {}
        self.workflow_semaphore = asyncio.Semaphore(config.max_concurrent_workflows)
        self.task_semaphore = asyncio.Semaphore(config.max_concurrent_tasks)

        # ë™ê¸°í™” í”„ë¦¬ë¯¸í‹°ë¸Œ
        self.workflow_lock = asyncio.Lock()
        self.task_lock = asyncio.Lock()
        self.shutdown_event = asyncio.Event()

    async def initialize(self):
        """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”"""
        logger.info("Initializing Central Orchestrator...")

        # 1. ìƒíƒœ ì €ì¥ì†Œ ì´ˆê¸°í™”
        self.state_manager = await self._initialize_state_manager()

        # 2. ì´ë²¤íŠ¸ ë²„ìŠ¤ ì´ˆê¸°í™”
        self.event_bus = EventBus()
        await self.event_bus.start()

        # 3. ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”
        self.agent_registry = AgentRegistry(self.event_bus)
        await self.agent_registry.initialize()

        # 4. ì›Œí¬í”Œë¡œìš° ì—”ì§„ ì´ˆê¸°í™”
        self.workflow_engine = WorkflowEngine(self)

        # 5. íƒœìŠ¤í¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”
        self.task_scheduler = TaskScheduler(
            self.agent_registry,
            self.task_semaphore
        )

        # 6. ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì ì´ˆê¸°í™”
        self.resource_manager = ResourceManager(self.config)

        # 7. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        if self.config.enable_metrics:
            self.metrics_collector = MetricsCollector(self)
            await self.metrics_collector.start()

        # 8. ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
        self._register_event_handlers()

        # 9. ì¤‘ë‹¨ëœ ì›Œí¬í”Œë¡œìš° ë³µêµ¬
        if self.config.enable_auto_recovery:
            await self._recover_interrupted_workflows()

        logger.info("Central Orchestrator initialized successfully")

    async def submit_workflow(
        self,
        workflow_id: str,
        input_data: Dict[str, Any],
        options: Optional[Dict[str, Any]] = None
    ) -> str:
        """ì›Œí¬í”Œë¡œìš° ì œì¶œ"""
        async with self.workflow_semaphore:
            # ì›Œí¬í”Œë¡œìš° ì •ì˜ ë¡œë“œ
            workflow_def = await self._load_workflow_definition(workflow_id)

            # ì…ë ¥ ê²€ì¦
            await self._validate_workflow_input(workflow_def, input_data)

            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ìƒì„±
            execution = await self.workflow_engine.create_execution(
                workflow_def,
                input_data,
                options or {}
            )

            # í™œì„± ì›Œí¬í”Œë¡œìš° ì¶”ê°€
            async with self.workflow_lock:
                self.active_workflows[execution.id] = execution

            # ì‹¤í–‰ ì‹œì‘
            asyncio.create_task(
                self._execute_workflow(execution)
            )

            # ì›Œí¬í”Œë¡œìš° ì‹œì‘ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="workflow.started",
                    workflow_id=execution.id,
                    timestamp=datetime.utcnow(),
                    data={"workflow_def_id": workflow_id}
                )
            )

            return execution.id

    async def _execute_workflow(self, execution: WorkflowExecution):
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ë‚´ë¶€)"""
        try:
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            result = await self.workflow_engine.execute(execution)

            # ì™„ë£Œ ì²˜ë¦¬
            execution.state = WorkflowState.COMPLETED
            execution.completed_at = datetime.utcnow()
            execution.result = result

            # ì™„ë£Œ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="workflow.completed",
                    workflow_id=execution.id,
                    timestamp=datetime.utcnow(),
                    data={"result": result}
                )
            )

        except Exception as e:
            # ì‹¤íŒ¨ ì²˜ë¦¬
            execution.state = WorkflowState.FAILED
            execution.completed_at = datetime.utcnow()
            execution.error = str(e)

            # ì‹¤íŒ¨ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="workflow.failed",
                    workflow_id=execution.id,
                    timestamp=datetime.utcnow(),
                    data={"error": str(e)}
                )
            )

        finally:
            # ìƒíƒœ ì €ì¥
            await self.state_manager.save_workflow_state(
                execution.id,
                execution
            )

            # í™œì„± ì›Œí¬í”Œë¡œìš°ì—ì„œ ì œê±°
            async with self.workflow_lock:
                self.active_workflows.pop(execution.id, None)
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í•µì‹¬ ì•„í‚¤í…ì²˜ êµ¬í˜„
- [ ] ë™ì‹œì„± ì œì–´ ë©”ì»¤ë‹ˆì¦˜
- [ ] ìƒíƒœ ê´€ë¦¬ í†µí•©
- [ ] ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹ 

#### SubTask 5.1.2: ì—ì´ì „íŠ¸ í†µí•© ì¸í„°í˜ì´ìŠ¤

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/core/agent_interface.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List, Callable
import httpx
import asyncio
from datetime import datetime, timedelta

@dataclass
class AgentCapability:
    name: str
    version: str
    input_schema: Dict[str, Any]
    output_schema: Dict[str, Any]
    timeout_seconds: int = 300
    max_retries: int = 3

@dataclass
class AgentInfo:
    id: str
    type: str
    name: str
    version: str
    endpoint: str
    capabilities: List[AgentCapability]
    health_check_endpoint: str
    status: str = "unknown"
    last_health_check: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

class AgentInterface(ABC):
    """ì—ì´ì „íŠ¸ í†µí•©ì„ ìœ„í•œ í‘œì¤€ ì¸í„°í˜ì´ìŠ¤"""

    @abstractmethod
    async def execute(self, task: AgentTask) -> Dict[str, Any]:
        """íƒœìŠ¤í¬ ì‹¤í–‰"""
        pass

    @abstractmethod
    async def get_status(self, task_id: str) -> Dict[str, Any]:
        """íƒœìŠ¤í¬ ìƒíƒœ ì¡°íšŒ"""
        pass

    @abstractmethod
    async def cancel(self, task_id: str) -> bool:
        """íƒœìŠ¤í¬ ì·¨ì†Œ"""
        pass

    @abstractmethod
    async def health_check(self) -> Dict[str, Any]:
        """í—¬ìŠ¤ ì²´í¬"""
        pass

class HTTPAgentProxy(AgentInterface):
    """HTTP ê¸°ë°˜ ì—ì´ì „íŠ¸ í”„ë¡ì‹œ"""

    def __init__(self, agent_info: AgentInfo):
        self.agent_info = agent_info
        self.client = httpx.AsyncClient(
            timeout=httpx.Timeout(
                connect=5.0,
                read=300.0,
                write=30.0,
                pool=5.0
            ),
            limits=httpx.Limits(
                max_keepalive_connections=5,
                max_connections=10
            )
        )
        self._circuit_breaker = CircuitBreaker(
            failure_threshold=5,
            recovery_timeout=60,
            expected_exception=httpx.HTTPError
        )

    async def execute(self, task: AgentTask) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ íƒœìŠ¤í¬ ì‹¤í–‰"""
        @self._circuit_breaker
        async def _execute():
            # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
            request_data = {
                "task_id": task.id,
                "input": task.input_data,
                "context": task.context,
                "timeout": task.timeout
            }

            # ì—ì´ì „íŠ¸ í˜¸ì¶œ
            response = await self.client.post(
                f"{self.agent_info.endpoint}/execute",
                json=request_data,
                headers={
                    "X-Task-ID": task.id,
                    "X-Workflow-ID": task.workflow_id,
                    "X-Request-ID": str(uuid.uuid4())
                }
            )

            # ì‘ë‹µ ì²˜ë¦¬
            if response.status_code == 202:  # Accepted
                # ë¹„ë™ê¸° ì‹¤í–‰ - í´ë§ í•„ìš”
                return {
                    "status": "accepted",
                    "task_id": task.id,
                    "poll_url": response.headers.get("Location")
                }
            elif response.status_code == 200:
                # ë™ê¸° ì‹¤í–‰ ì™„ë£Œ
                return response.json()
            else:
                raise AgentExecutionError(
                    f"Agent returned {response.status_code}: {response.text}"
                )

        return await _execute()

    async def get_status(self, task_id: str) -> Dict[str, Any]:
        """íƒœìŠ¤í¬ ìƒíƒœ ì¡°íšŒ"""
        response = await self.client.get(
            f"{self.agent_info.endpoint}/tasks/{task_id}/status"
        )

        if response.status_code == 200:
            return response.json()
        elif response.status_code == 404:
            return {"status": "not_found"}
        else:
            raise AgentStatusError(
                f"Failed to get status: {response.status_code}"
            )

    async def cancel(self, task_id: str) -> bool:
        """íƒœìŠ¤í¬ ì·¨ì†Œ"""
        try:
            response = await self.client.post(
                f"{self.agent_info.endpoint}/tasks/{task_id}/cancel"
            )
            return response.status_code in [200, 202]
        except Exception as e:
            logger.error(f"Failed to cancel task {task_id}: {e}")
            return False

    async def health_check(self) -> Dict[str, Any]:
        """í—¬ìŠ¤ ì²´í¬"""
        try:
            response = await self.client.get(
                self.agent_info.health_check_endpoint,
                timeout=5.0
            )

            if response.status_code == 200:
                return {
                    "status": "healthy",
                    "timestamp": datetime.utcnow(),
                    "details": response.json()
                }
            else:
                return {
                    "status": "unhealthy",
                    "timestamp": datetime.utcnow(),
                    "error": f"HTTP {response.status_code}"
                }
        except Exception as e:
            return {
                "status": "unhealthy",
                "timestamp": datetime.utcnow(),
                "error": str(e)
            }

class AgentProxyFactory:
    """ì—ì´ì „íŠ¸ í”„ë¡ì‹œ íŒ©í† ë¦¬"""

    @staticmethod
    def create_proxy(agent_info: AgentInfo) -> AgentInterface:
        """ì—ì´ì „íŠ¸ íƒ€ì…ì— ë”°ë¥¸ í”„ë¡ì‹œ ìƒì„±"""
        if agent_info.endpoint.startswith("http"):
            return HTTPAgentProxy(agent_info)
        elif agent_info.endpoint.startswith("grpc"):
            return GRPCAgentProxy(agent_info)
        elif agent_info.endpoint.startswith("lambda"):
            return LambdaAgentProxy(agent_info)
        else:
            raise ValueError(f"Unknown agent type: {agent_info.endpoint}")
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í‘œì¤€ ì—ì´ì „íŠ¸ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- [ ] HTTP/gRPC/Lambda í”„ë¡ì‹œ êµ¬í˜„
- [ ] Circuit Breaker íŒ¨í„´ ì ìš©
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§

#### SubTask 5.1.3: ì›Œí¬í”Œë¡œìš° ìƒíƒœ ê´€ë¦¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/core/state_manager.py
from typing import Dict, List, Optional, Any
import asyncio
from datetime import datetime
import json

class StateStorage(ABC):
    """ìƒíƒœ ì €ì¥ì†Œ ì¶”ìƒ í´ë˜ìŠ¤"""

    @abstractmethod
    async def save(self, key: str, data: Dict[str, Any]) -> None:
        pass

    @abstractmethod
    async def load(self, key: str) -> Optional[Dict[str, Any]]:
        pass

    @abstractmethod
    async def delete(self, key: str) -> None:
        pass

    @abstractmethod
    async def list_keys(self, prefix: str) -> List[str]:
        pass

class DynamoDBStateStorage(StateStorage):
    """DynamoDB ê¸°ë°˜ ìƒíƒœ ì €ì¥ì†Œ"""

    def __init__(self, table_name: str):
        self.table_name = table_name
        self.dynamodb = boto3.resource('dynamodb')
        self.table = self.dynamodb.Table(table_name)

    async def save(self, key: str, data: Dict[str, Any]) -> None:
        """ìƒíƒœ ì €ì¥"""
        item = {
            'id': key,
            'data': json.dumps(data, default=str),
            'timestamp': datetime.utcnow().isoformat(),
            'ttl': int((datetime.utcnow() + timedelta(days=30)).timestamp())
        }

        await asyncio.to_thread(
            self.table.put_item,
            Item=item
        )

    async def load(self, key: str) -> Optional[Dict[str, Any]]:
        """ìƒíƒœ ë¡œë“œ"""
        response = await asyncio.to_thread(
            self.table.get_item,
            Key={'id': key}
        )

        if 'Item' in response:
            return json.loads(response['Item']['data'])
        return None

class StateManager:
    """ì›Œí¬í”Œë¡œìš° ë° íƒœìŠ¤í¬ ìƒíƒœ ê´€ë¦¬ì"""

    def __init__(self, storage: StateStorage):
        self.storage = storage
        self.state_cache = TTLCache(maxsize=1000, ttl=300)
        self.cache_lock = asyncio.Lock()
        self.write_buffer = asyncio.Queue(maxsize=1000)
        self.writer_task = None

    async def start(self):
        """ìƒíƒœ ê´€ë¦¬ì ì‹œì‘"""
        self.writer_task = asyncio.create_task(self._write_worker())

    async def stop(self):
        """ìƒíƒœ ê´€ë¦¬ì ì¤‘ì§€"""
        if self.writer_task:
            self.writer_task.cancel()

    async def save_workflow_state(
        self,
        workflow_id: str,
        execution: WorkflowExecution
    ) -> None:
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì €ì¥"""
        state_data = {
            "workflow_id": execution.workflow_id,
            "execution_id": execution.id,
            "state": execution.state.value,
            "started_at": execution.started_at.isoformat(),
            "completed_at": execution.completed_at.isoformat()
                if execution.completed_at else None,
            "tasks": {
                task_id: self._serialize_task(task)
                for task_id, task in execution.tasks.items()
            },
            "context": execution.context,
            "result": execution.result,
            "error": execution.error,
            "metadata": execution.metadata
        }

        # ìºì‹œ ì—…ë°ì´íŠ¸
        async with self.cache_lock:
            self.state_cache[workflow_id] = state_data

        # ë¹„ë™ê¸° ì €ì¥ íì— ì¶”ê°€
        await self.write_buffer.put((
            f"workflow:{workflow_id}",
            state_data
        ))

    async def load_workflow_state(
        self,
        workflow_id: str
    ) -> Optional[WorkflowExecution]:
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë¡œë“œ"""
        # ìºì‹œ í™•ì¸
        async with self.cache_lock:
            if workflow_id in self.state_cache:
                state_data = self.state_cache[workflow_id]
                return self._deserialize_workflow(state_data)

        # ì €ì¥ì†Œì—ì„œ ë¡œë“œ
        state_data = await self.storage.load(f"workflow:{workflow_id}")
        if state_data:
            # ìºì‹œ ì—…ë°ì´íŠ¸
            async with self.cache_lock:
                self.state_cache[workflow_id] = state_data
            return self._deserialize_workflow(state_data)

        return None

    async def update_task_state(
        self,
        workflow_id: str,
        task_id: str,
        updates: Dict[str, Any]
    ) -> None:
        """íƒœìŠ¤í¬ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        # ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë¡œë“œ
        execution = await self.load_workflow_state(workflow_id)
        if not execution:
            raise ValueError(f"Workflow {workflow_id} not found")

        # íƒœìŠ¤í¬ ì—…ë°ì´íŠ¸
        if task_id not in execution.tasks:
            raise ValueError(f"Task {task_id} not found")

        task = execution.tasks[task_id]
        for key, value in updates.items():
            setattr(task, key, value)

        # íƒ€ì„ìŠ¤íƒ¬í”„ ì—…ë°ì´íŠ¸
        if updates.get("status") == "completed":
            task.completed_at = datetime.utcnow()
        elif updates.get("status") == "running":
            task.started_at = datetime.utcnow()

        # ìƒíƒœ ì €ì¥
        await self.save_workflow_state(workflow_id, execution)

    async def list_active_workflows(self) -> List[str]:
        """í™œì„± ì›Œí¬í”Œë¡œìš° ëª©ë¡ ì¡°íšŒ"""
        keys = await self.storage.list_keys("workflow:")
        workflows = []

        for key in keys:
            workflow_id = key.replace("workflow:", "")
            execution = await self.load_workflow_state(workflow_id)

            if execution and execution.state in [
                WorkflowState.PENDING,
                WorkflowState.RUNNING
            ]:
                workflows.append(workflow_id)

        return workflows

    async def _write_worker(self):
        """ë¹„ë™ê¸° ì“°ê¸° ì›Œì»¤"""
        batch = []

        while True:
            try:
                # ë°°ì¹˜ ìˆ˜ì§‘ (ìµœëŒ€ 100ê°œ ë˜ëŠ” 1ì´ˆ)
                deadline = asyncio.create_task(asyncio.sleep(1.0))

                while len(batch) < 100:
                    get_task = asyncio.create_task(self.write_buffer.get())

                    done, pending = await asyncio.wait(
                        [get_task, deadline],
                        return_when=asyncio.FIRST_COMPLETED
                    )

                    if get_task in done:
                        batch.append(get_task.result())
                    else:
                        get_task.cancel()
                        break

                # ë°°ì¹˜ ì €ì¥
                if batch:
                    await self._save_batch(batch)
                    batch.clear()

            except asyncio.CancelledError:
                # ë‚¨ì€ ë°ì´í„° ì €ì¥
                if batch:
                    await self._save_batch(batch)
                break
            except Exception as e:
                logger.error(f"Write worker error: {e}")
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ìƒíƒœ ì €ì¥/ë¡œë“œ ë©”ì»¤ë‹ˆì¦˜
- [ ] ìºì‹± ì „ëµ êµ¬í˜„
- [ ] ë°°ì¹˜ ì“°ê¸° ìµœì í™”
- [ ] ìƒíƒœ ë³µêµ¬ ê¸°ëŠ¥

#### SubTask 5.1.4: ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹  ì‹œìŠ¤í…œ

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/core/event_bus.py
from typing import Dict, List, Callable, Optional, Any
import asyncio
from datetime import datetime
from dataclasses import dataclass
import json

@dataclass
class OrchestratorEvent:
    event_id: str
    event_type: str
    source: str
    workflow_id: Optional[str]
    task_id: Optional[str]
    timestamp: datetime
    data: Dict[str, Any]
    correlation_id: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "event_id": self.event_id,
            "event_type": self.event_type,
            "source": self.source,
            "workflow_id": self.workflow_id,
            "task_id": self.task_id,
            "timestamp": self.timestamp.isoformat(),
            "data": self.data,
            "correlation_id": self.correlation_id
        }

class EventHandler:
    """ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë˜í¼"""

    def __init__(
        self,
        handler: Callable,
        filter_func: Optional[Callable] = None,
        priority: int = 0
    ):
        self.handler = handler
        self.filter_func = filter_func
        self.priority = priority
        self.is_async = asyncio.iscoroutinefunction(handler)

    async def handle(self, event: OrchestratorEvent) -> Any:
        """ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        # í•„í„° í™•ì¸
        if self.filter_func and not self.filter_func(event):
            return None

        # í•¸ë“¤ëŸ¬ ì‹¤í–‰
        if self.is_async:
            return await self.handler(event)
        else:
            return self.handler(event)

class EventBus:
    """ì¤‘ì•™ ì´ë²¤íŠ¸ ë²„ìŠ¤"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.subscribers: Dict[str, List[EventHandler]] = {}
        self.event_queue = asyncio.Queue(
            maxsize=self.config.get("queue_size", 10000)
        )
        self.event_store: Optional[EventStore] = None
        self.running = False
        self.workers = []
        self.stats = EventBusStats()

    async def start(self):
        """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹œì‘"""
        self.running = True

        # ì´ë²¤íŠ¸ ì €ì¥ì†Œ ì´ˆê¸°í™”
        if self.config.get("enable_event_store", True):
            self.event_store = EventStore(
                self.config.get("event_store_config", {})
            )
            await self.event_store.initialize()

        # ì›Œì»¤ ì‹œì‘
        num_workers = self.config.get("num_workers", 4)
        for i in range(num_workers):
            worker = asyncio.create_task(
                self._event_worker(f"worker-{i}")
            )
            self.workers.append(worker)

        logger.info(f"Event bus started with {num_workers} workers")

    async def stop(self):
        """ì´ë²¤íŠ¸ ë²„ìŠ¤ ì¤‘ì§€"""
        self.running = False

        # ì›Œì»¤ ì¤‘ì§€
        for worker in self.workers:
            worker.cancel()

        # ë‚¨ì€ ì´ë²¤íŠ¸ ì²˜ë¦¬
        await self._flush_events()

        # ì´ë²¤íŠ¸ ì €ì¥ì†Œ ì¢…ë£Œ
        if self.event_store:
            await self.event_store.close()

    async def publish(
        self,
        event: OrchestratorEvent,
        priority: int = 0
    ) -> None:
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        # ì´ë²¤íŠ¸ ID ìƒì„±
        if not event.event_id:
            event.event_id = str(uuid.uuid4())

        # í†µê³„ ì—…ë°ì´íŠ¸
        self.stats.increment_published(event.event_type)

        # ì´ë²¤íŠ¸ ì €ì¥
        if self.event_store:
            await self.event_store.save(event)

        # íì— ì¶”ê°€
        try:
            await asyncio.wait_for(
                self.event_queue.put((priority, event)),
                timeout=1.0
            )
        except asyncio.TimeoutError:
            logger.error(f"Event queue full, dropping event: {event.event_id}")
            self.stats.increment_dropped()

    def subscribe(
        self,
        event_type: str,
        handler: Callable,
        filter_func: Optional[Callable] = None,
        priority: int = 0
    ) -> str:
        """ì´ë²¤íŠ¸ êµ¬ë…"""
        if event_type not in self.subscribers:
            self.subscribers[event_type] = []

        event_handler = EventHandler(handler, filter_func, priority)
        self.subscribers[event_type].append(event_handler)

        # ìš°ì„ ìˆœìœ„ ì •ë ¬
        self.subscribers[event_type].sort(
            key=lambda h: h.priority,
            reverse=True
        )

        subscription_id = f"{event_type}:{id(handler)}"
        logger.info(f"Subscribed to {event_type}: {subscription_id}")

        return subscription_id

    def unsubscribe(self, subscription_id: str) -> bool:
        """êµ¬ë… ì·¨ì†Œ"""
        event_type, handler_id = subscription_id.split(":")

        if event_type in self.subscribers:
            self.subscribers[event_type] = [
                h for h in self.subscribers[event_type]
                if id(h.handler) != int(handler_id)
            ]
            return True

        return False

    async def _event_worker(self, worker_id: str):
        """ì´ë²¤íŠ¸ ì²˜ë¦¬ ì›Œì»¤"""
        logger.info(f"Event worker {worker_id} started")

        while self.running:
            try:
                # ì´ë²¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                priority, event = await asyncio.wait_for(
                    self.event_queue.get(),
                    timeout=1.0
                )

                # ì´ë²¤íŠ¸ ì²˜ë¦¬
                await self._process_event(event)

            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"Event worker {worker_id} error: {e}")

        logger.info(f"Event worker {worker_id} stopped")

    async def _process_event(self, event: OrchestratorEvent):
        """ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        start_time = datetime.utcnow()

        try:
            # ì „ì—­ í•¸ë“¤ëŸ¬ (*) ì‹¤í–‰
            if "*" in self.subscribers:
                for handler in self.subscribers["*"]:
                    await self._execute_handler(handler, event)

            # íŠ¹ì • ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì‹¤í–‰
            if event.event_type in self.subscribers:
                handlers = self.subscribers[event.event_type]

                # ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ í•¸ë“¤ëŸ¬ ê·¸ë£¹í™”
                async_tasks = []

                for handler in handlers:
                    if handler.is_async:
                        task = asyncio.create_task(
                            self._execute_handler(handler, event)
                        )
                        async_tasks.append(task)
                    else:
                        # ë™ê¸° í•¸ë“¤ëŸ¬ëŠ” ìˆœì°¨ ì‹¤í–‰
                        await self._execute_handler(handler, event)

                # ë¹„ë™ê¸° í•¸ë“¤ëŸ¬ ëŒ€ê¸°
                if async_tasks:
                    await asyncio.gather(*async_tasks, return_exceptions=True)

            # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
            duration = (datetime.utcnow() - start_time).total_seconds()
            self.stats.record_processing_time(event.event_type, duration)

        except Exception as e:
            logger.error(f"Error processing event {event.event_id}: {e}")
            self.stats.increment_errors(event.event_type)

    async def _execute_handler(
        self,
        handler: EventHandler,
        event: OrchestratorEvent
    ):
        """ê°œë³„ í•¸ë“¤ëŸ¬ ì‹¤í–‰"""
        try:
            await handler.handle(event)
        except Exception as e:
            logger.error(
                f"Handler error for event {event.event_id}: {e}",
                exc_info=True
            )
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì´ë²¤íŠ¸ ë°œí–‰/êµ¬ë… ë©”ì»¤ë‹ˆì¦˜
- [ ] ë¹„ë™ê¸° ì´ë²¤íŠ¸ ì²˜ë¦¬
- [ ] ì´ë²¤íŠ¸ ìš°ì„ ìˆœìœ„ ê´€ë¦¬
- [ ] ì´ë²¤íŠ¸ ì €ì¥ ë° ì¬ìƒ

### Task 5.2: ì›Œí¬í”Œë¡œìš° ì—”ì§„ êµ¬ì¶•

#### SubTask 5.2.1: ì›Œí¬í”Œë¡œìš° ì •ì˜ ëª¨ë¸

**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/workflow/workflow_definition.py
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, field
from enum import Enum
import yaml
import json

@dataclass
class TaskDependency:
    task_id: str
    condition: Optional[str] = None
    wait_for_completion: bool = True

@dataclass
class RetryPolicy:
    max_attempts: int = 3
    initial_delay: int = 1
    max_delay: int = 60
    multiplier: float = 2.0
    retry_on: List[str] = field(default_factory=lambda: ["error", "timeout"])

@dataclass
class WorkflowTask:
    id: str
    name: str
    agent_type: str
    description: Optional[str] = None

    # ì…ì¶œë ¥ ë§¤í•‘
    input_mapping: Dict[str, str] = field(default_factory=dict)
    output_mapping: Dict[str, str] = field(default_factory=dict)

    # ì˜ì¡´ì„±
    dependencies: List[TaskDependency] = field(default_factory=list)

    # ì‹¤í–‰ ì„¤ì •
    timeout_seconds: int = 300
    retry_policy: RetryPolicy = field(default_factory=RetryPolicy)

    # ì¡°ê±´ë¶€ ì‹¤í–‰
    conditions: List[str] = field(default_factory=list)
    skip_on_failure: bool = False

    # ì—ëŸ¬ í•¸ë“¤ë§
    error_handler: Optional[str] = None
    compensation_task: Optional[str] = None

@dataclass
class ParallelBlock:
    """ë³‘ë ¬ ì‹¤í–‰ ë¸”ë¡"""
    id: str
    tasks: List[Union[WorkflowTask, 'ConditionalBlock']]
    max_concurrency: Optional[int] = None
    fail_fast: bool = True

@dataclass
class ConditionalBlock:
    """ì¡°ê±´ë¶€ ì‹¤í–‰ ë¸”ë¡"""
    id: str
    condition: str
    if_tasks: List[Union[WorkflowTask, ParallelBlock]]
    else_tasks: Optional[List[Union[WorkflowTask, ParallelBlock]]] = None

@dataclass
class LoopBlock:
    """ë°˜ë³µ ì‹¤í–‰ ë¸”ë¡"""
    id: str
    iterator: str  # ë°˜ë³µí•  ë°ì´í„° ê²½ë¡œ
    variable: str  # ë°˜ë³µ ë³€ìˆ˜ ì´ë¦„
    tasks: List[Union[WorkflowTask, ParallelBlock, ConditionalBlock]]
    max_iterations: Optional[int] = None
    parallel: bool = False

@dataclass
class WorkflowDefinition:
    """ì›Œí¬í”Œë¡œìš° ì •ì˜"""
    id: str
    name: str
    version: str
    description: str

    # ì…ì¶œë ¥ ìŠ¤í‚¤ë§ˆ
    input_schema: Dict[str, Any]
    output_schema: Dict[str, Any]

    # ì›Œí¬í”Œë¡œìš° êµ¬ì¡°
    tasks: List[Union[WorkflowTask, ParallelBlock, ConditionalBlock, LoopBlock]]

    # ì „ì—­ ì„¤ì •
    timeout_seconds: int = 3600
    max_retries: int = 1

    # ì—ëŸ¬ í•¸ë“¤ëŸ¬
    error_handlers: Dict[str, str] = field(default_factory=dict)

    # ë©”íƒ€ë°ì´í„°
    tags: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

class WorkflowLoader:
    """ì›Œí¬í”Œë¡œìš° ì •ì˜ ë¡œë”"""

    def __init__(self):
        self.validators = {
            'yaml': self._validate_yaml,
            'json': self._validate_json,
            'dsl': self._validate_dsl
        }

    async def load_from_file(self, file_path: str) -> WorkflowDefinition:
        """íŒŒì¼ì—ì„œ ì›Œí¬í”Œë¡œìš° ë¡œë“œ"""
        with open(file_path, 'r') as f:
            content = f.read()

        if file_path.endswith('.yaml') or file_path.endswith('.yml'):
            return await self.load_from_yaml(content)
        elif file_path.endswith('.json'):
            return await self.load_from_json(content)
        else:
            raise ValueError(f"Unsupported file format: {file_path}")

    async def load_from_yaml(self, yaml_content: str) -> WorkflowDefinition:
        """YAMLì—ì„œ ì›Œí¬í”Œë¡œìš° ë¡œë“œ"""
        data = yaml.safe_load(yaml_content)
        await self._validate_yaml(data)
        return self._parse_workflow_data(data)

    async def load_from_json(self, json_content: str) -> WorkflowDefinition:
        """JSONì—ì„œ ì›Œí¬í”Œë¡œìš° ë¡œë“œ"""
        data = json.loads(json_content)
        await self._validate_json(data)
        return self._parse_workflow_data(data)

    def _parse_workflow_data(self, data: Dict[str, Any]) -> WorkflowDefinition:
        """ì›Œí¬í”Œë¡œìš° ë°ì´í„° íŒŒì‹±"""
        # ê¸°ë³¸ ì •ë³´
        workflow = WorkflowDefinition(
            id=data['id'],
            name=data['name'],
            version=data['version'],
            description=data.get('description', ''),
            input_schema=data.get('input_schema', {}),
            output_schema=data.get('output_schema', {}),
            timeout_seconds=data.get('timeout_seconds', 3600),
            max_retries=data.get('max_retries', 1),
            error_handlers=data.get('error_handlers', {}),
            tags=data.get('tags', []),
            metadata=data.get('metadata', {})
        )

        # íƒœìŠ¤í¬ íŒŒì‹±
        workflow.tasks = self._parse_tasks(data.get('tasks', []))

        return workflow

    def _parse_tasks(
        self,
        tasks_data: List[Dict[str, Any]]
    ) -> List[Union[WorkflowTask, ParallelBlock, ConditionalBlock, LoopBlock]]:
        """íƒœìŠ¤í¬ ë¦¬ìŠ¤íŠ¸ íŒŒì‹±"""
        tasks = []

        for task_data in tasks_data:
            task_type = task_data.get('type', 'task')

            if task_type == 'task':
                task = self._parse_workflow_task(task_data)
            elif task_type == 'parallel':
                task = self._parse_parallel_block(task_data)
            elif task_type == 'conditional':
                task = self._parse_conditional_block(task_data)
            elif task_type == 'loop':
                task = self._parse_loop_block(task_data)
            else:
                raise ValueError(f"Unknown task type: {task_type}")

            tasks.append(task)

        return tasks
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í¬ê´„ì ì¸ ì›Œí¬í”Œë¡œìš° ëª¨ë¸
- [ ] YAML/JSON ë¡œë” êµ¬í˜„
- [ ] íƒœìŠ¤í¬ íƒ€ì… ì§€ì› (ìˆœì°¨/ë³‘ë ¬/ì¡°ê±´/ë°˜ë³µ)
- [ ] ì…ì¶œë ¥ ë§¤í•‘ ë° ì˜ì¡´ì„± ê´€ë¦¬

#### SubTask 5.2.2: ì›Œí¬í”Œë¡œìš° íŒŒì„œ ë° ê²€ì¦ê¸°

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/workflow/workflow_validator.py
from typing import Dict, List, Set, Optional, Any
import networkx as nx
from jsonschema import validate, ValidationError

class WorkflowValidator:
    """ì›Œí¬í”Œë¡œìš° ì •ì˜ ê²€ì¦ê¸°"""

    def __init__(self):
        self.schema_validator = SchemaValidator()
        self.dependency_validator = DependencyValidator()
        self.expression_validator = ExpressionValidator()

    async def validate(
        self,
        workflow: WorkflowDefinition
    ) -> ValidationResult:
        """ì›Œí¬í”Œë¡œìš° ì „ì²´ ê²€ì¦"""
        errors = []
        warnings = []

        # 1. ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
        structural_errors = await self._validate_structure(workflow)
        errors.extend(structural_errors)

        # 2. íƒœìŠ¤í¬ ê²€ì¦
        task_errors = await self._validate_tasks(workflow)
        errors.extend(task_errors)

        # 3. ì˜ì¡´ì„± ê²€ì¦
        dependency_result = await self.dependency_validator.validate(workflow)
        errors.extend(dependency_result.errors)
        warnings.extend(dependency_result.warnings)

        # 4. ì…ì¶œë ¥ ë§¤í•‘ ê²€ì¦
        mapping_errors = await self._validate_mappings(workflow)
        errors.extend(mapping_errors)

        # 5. ì¡°ê±´ì‹ ê²€ì¦
        expression_errors = await self._validate_expressions(workflow)
        errors.extend(expression_errors)

        # 6. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶”ì •
        resource_warnings = await self._estimate_resources(workflow)
        warnings.extend(resource_warnings)

        return ValidationResult(
            is_valid=len(errors) == 0,
            errors=errors,
            warnings=warnings
        )

    async def _validate_structure(
        self,
        workflow: WorkflowDefinition
    ) -> List[ValidationError]:
        """ê¸°ë³¸ êµ¬ì¡° ê²€ì¦"""
        errors = []

        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        if not workflow.id:
            errors.append(ValidationError("Workflow ID is required"))
        if not workflow.name:
            errors.append(ValidationError("Workflow name is required"))
        if not workflow.version:
            errors.append(ValidationError("Workflow version is required"))

        # ë²„ì „ í˜•ì‹ ê²€ì¦
        if not self._is_valid_version(workflow.version):
            errors.append(
                ValidationError(f"Invalid version format: {workflow.version}")
            )

        # íƒœìŠ¤í¬ ì¡´ì¬ í™•ì¸
        if not workflow.tasks:
            errors.append(ValidationError("Workflow must have at least one task"))

        return errors

    async def _validate_tasks(
        self,
        workflow: WorkflowDefinition
    ) -> List[ValidationError]:
        """íƒœìŠ¤í¬ ê²€ì¦"""
        errors = []
        task_ids = set()

        for task in self._flatten_tasks(workflow.tasks):
            # ID ì¤‘ë³µ í™•ì¸
            if task.id in task_ids:
                errors.append(
                    ValidationError(f"Duplicate task ID: {task.id}")
                )
            task_ids.add(task.id)

            # ì—ì´ì „íŠ¸ íƒ€ì… ê²€ì¦
            if not await self._is_valid_agent_type(task.agent_type):
                errors.append(
                    ValidationError(
                        f"Unknown agent type: {task.agent_type} in task {task.id}"
                    )
                )

            # íƒ€ì„ì•„ì›ƒ ê²€ì¦
            if task.timeout_seconds <= 0:
                errors.append(
                    ValidationError(
                        f"Invalid timeout for task {task.id}: {task.timeout_seconds}"
                    )
                )

        return errors

class DependencyValidator:
    """ì˜ì¡´ì„± ê²€ì¦ê¸°"""

    async def validate(
        self,
        workflow: WorkflowDefinition
    ) -> DependencyValidationResult:
        """ì˜ì¡´ì„± ê²€ì¦"""
        errors = []
        warnings = []

        # ì˜ì¡´ì„± ê·¸ë˜í”„ ìƒì„±
        dep_graph = self._build_dependency_graph(workflow)

        # 1. ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
        cycles = list(nx.simple_cycles(dep_graph))
        if cycles:
            for cycle in cycles:
                errors.append(
                    ValidationError(
                        f"Circular dependency detected: {' -> '.join(cycle)}"
                    )
                )

        # 2. ë¯¸í•´ê²° ì˜ì¡´ì„± ê²€ì‚¬
        all_task_ids = set(dep_graph.nodes())

        for task_id, task_data in dep_graph.nodes(data=True):
            task = task_data['task']

            for dep in task.dependencies:
                if dep.task_id not in all_task_ids:
                    errors.append(
                        ValidationError(
                            f"Task {task_id} depends on unknown task: {dep.task_id}"
                        )
                    )

        # 3. ë„ë‹¬ ë¶ˆê°€ëŠ¥í•œ íƒœìŠ¤í¬ ê²€ì‚¬
        if dep_graph.number_of_nodes() > 0:
            # ì‹œì‘ ë…¸ë“œ ì°¾ê¸° (ì˜ì¡´ì„±ì´ ì—†ëŠ” ë…¸ë“œ)
            start_nodes = [
                n for n in dep_graph.nodes()
                if dep_graph.in_degree(n) == 0
            ]

            if not start_nodes:
                warnings.append(
                    ValidationWarning(
                        "No start tasks found (all tasks have dependencies)"
                    )
                )
            else:
                # ë„ë‹¬ ê°€ëŠ¥í•œ ë…¸ë“œ ì°¾ê¸°
                reachable = set()
                for start in start_nodes:
                    reachable.update(
                        nx.descendants(dep_graph, start)
                    )
                reachable.update(start_nodes)

                # ë„ë‹¬ ë¶ˆê°€ëŠ¥í•œ ë…¸ë“œ
                unreachable = all_task_ids - reachable
                if unreachable:
                    warnings.append(
                        ValidationWarning(
                            f"Unreachable tasks: {unreachable}"
                        )
                    )

        return DependencyValidationResult(errors, warnings)
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] êµ¬ì¡°ì  ê²€ì¦ (í•„ìˆ˜ í•„ë“œ, í˜•ì‹)
- [ ] íƒœìŠ¤í¬ ê²€ì¦ (ID ì¤‘ë³µ, íƒ€ì…)
- [ ] ì˜ì¡´ì„± ê²€ì¦ (ìˆœí™˜, ë¯¸í•´ê²°)
- [ ] í‘œí˜„ì‹ ë° ë§¤í•‘ ê²€ì¦

#### SubTask 5.2.3: ì‹¤í–‰ ìŠ¤ì¼€ì¤„ëŸ¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/workflow/task_scheduler.py
from typing import Dict, List, Set, Optional, Any
import asyncio
from datetime import datetime
from collections import deque

class TaskScheduler:
    """íƒœìŠ¤í¬ ì‹¤í–‰ ìŠ¤ì¼€ì¤„ëŸ¬"""

    def __init__(
        self,
        agent_registry: AgentRegistry,
        max_concurrent_tasks: int = 100
    ):
        self.agent_registry = agent_registry
        self.max_concurrent_tasks = max_concurrent_tasks

        # ì‹¤í–‰ í
        self.ready_queue = asyncio.Queue()
        self.running_tasks: Dict[str, asyncio.Task] = {}
        self.completed_tasks: Set[str] = set()

        # ë™ê¸°í™”
        self.task_semaphore = asyncio.Semaphore(max_concurrent_tasks)
        self.scheduler_lock = asyncio.Lock()

    async def schedule_workflow(
        self,
        execution: WorkflowExecution,
        workflow_def: WorkflowDefinition
    ) -> None:
        """ì›Œí¬í”Œë¡œìš° ìŠ¤ì¼€ì¤„ë§"""
        # íƒœìŠ¤í¬ ì˜ì¡´ì„± ë¶„ì„
        task_graph = self._build_task_graph(workflow_def.tasks)

        # ì´ˆê¸° ì‹¤í–‰ ê°€ëŠ¥ íƒœìŠ¤í¬ ì°¾ê¸°
        ready_tasks = self._find_ready_tasks(
            task_graph,
            set(),
            execution.context
        )

        # ì¤€ë¹„ëœ íƒœìŠ¤í¬ íì— ì¶”ê°€
        for task_id in ready_tasks:
            await self.ready_queue.put(task_id)

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
        await self._run_scheduler(execution, task_graph)

    async def _run_scheduler(
        self,
        execution: WorkflowExecution,
        task_graph: TaskGraph
    ) -> None:
        """ìŠ¤ì¼€ì¤„ëŸ¬ ë©”ì¸ ë£¨í”„"""
        while True:
            # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
            if self._is_workflow_complete(execution, task_graph):
                break

            # ì¤€ë¹„ëœ íƒœìŠ¤í¬ ê°€ì ¸ì˜¤ê¸°
            try:
                task_id = await asyncio.wait_for(
                    self.ready_queue.get(),
                    timeout=1.0
                )
            except asyncio.TimeoutError:
                # ë°ë“œë½ ê°ì§€
                if self._detect_deadlock(execution, task_graph):
                    raise WorkflowDeadlockError("Workflow deadlock detected")
                continue

            # íƒœìŠ¤í¬ ì‹¤í–‰
            await self._execute_task(task_id, execution, task_graph)

    async def _execute_task(
        self,
        task_id: str,
        execution: WorkflowExecution,
        task_graph: TaskGraph
    ) -> None:
        """ê°œë³„ íƒœìŠ¤í¬ ì‹¤í–‰"""
        task = execution.tasks[task_id]

        async with self.task_semaphore:
            try:
                # íƒœìŠ¤í¬ ìƒíƒœ ì—…ë°ì´íŠ¸
                task.status = TaskState.RUNNING
                task.started_at = datetime.utcnow()

                # ì—ì´ì „íŠ¸ í”„ë¡ì‹œ ê°€ì ¸ì˜¤ê¸°
                agent_proxy = await self.agent_registry.get_agent(
                    task.agent_type
                )

                # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
                input_data = self._prepare_task_input(
                    task,
                    execution.context
                )

                # íƒœìŠ¤í¬ ì‹¤í–‰
                execution_task = asyncio.create_task(
                    self._run_task_with_timeout(
                        agent_proxy,
                        task,
                        input_data
                    )
                )

                async with self.scheduler_lock:
                    self.running_tasks[task_id] = execution_task

                # ê²°ê³¼ ëŒ€ê¸°
                result = await execution_task

                # ì„±ê³µ ì²˜ë¦¬
                await self._handle_task_success(
                    task_id,
                    result,
                    execution,
                    task_graph
                )

            except asyncio.TimeoutError:
                await self._handle_task_timeout(task_id, execution)
            except Exception as e:
                await self._handle_task_failure(task_id, e, execution)
            finally:
                async with self.scheduler_lock:
                    self.running_tasks.pop(task_id, None)

    async def _run_task_with_timeout(
        self,
        agent_proxy: AgentInterface,
        task: AgentTask,
        input_data: Dict[str, Any]
    ) -> Any:
        """íƒ€ì„ì•„ì›ƒì´ ìˆëŠ” íƒœìŠ¤í¬ ì‹¤í–‰"""
        return await asyncio.wait_for(
            agent_proxy.execute(task),
            timeout=task.timeout_seconds
        )

    async def _handle_task_success(
        self,
        task_id: str,
        result: Any,
        execution: WorkflowExecution,
        task_graph: TaskGraph
    ) -> None:
        """íƒœìŠ¤í¬ ì„±ê³µ ì²˜ë¦¬"""
        task = execution.tasks[task_id]

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        task.status = TaskState.COMPLETED
        task.completed_at = datetime.utcnow()
        task.result = result

        # ì¶œë ¥ ë§¤í•‘
        self._apply_output_mapping(task, result, execution.context)

        # ì™„ë£Œ íƒœìŠ¤í¬ ì¶”ê°€
        async with self.scheduler_lock:
            self.completed_tasks.add(task_id)

        # ë‹¤ìŒ ì‹¤í–‰ ê°€ëŠ¥ íƒœìŠ¤í¬ ì°¾ê¸°
        next_tasks = self._find_ready_tasks(
            task_graph,
            self.completed_tasks,
            execution.context
        )

        # ì¤€ë¹„ëœ íƒœìŠ¤í¬ íì— ì¶”ê°€
        for next_task_id in next_tasks:
            await self.ready_queue.put(next_task_id)

    def _prepare_task_input(
        self,
        task: WorkflowTask,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """íƒœìŠ¤í¬ ì…ë ¥ ë°ì´í„° ì¤€ë¹„"""
        input_data = {}

        for target_key, source_path in task.input_mapping.items():
            # JSONPath ë˜ëŠ” ë‹¨ìˆœ í‚¤ë¡œ ê°’ ì¶”ì¶œ
            value = self._extract_value(context, source_path)
            input_data[target_key] = value

        return input_data

    def _apply_output_mapping(
        self,
        task: WorkflowTask,
        result: Any,
        context: Dict[str, Any]
    ) -> None:
        """íƒœìŠ¤í¬ ì¶œë ¥ ë§¤í•‘ ì ìš©"""
        for source_key, target_path in task.output_mapping.items():
            # ê²°ê³¼ì—ì„œ ê°’ ì¶”ì¶œ
            if isinstance(result, dict):
                value = result.get(source_key)
            else:
                value = result

            # ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
            self._set_value(context, target_path, value)
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] íƒœìŠ¤í¬ ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜
- [ ] ë™ì‹œ ì‹¤í–‰ ì œì–´
- [ ] ì˜ì¡´ì„± ê¸°ë°˜ ì‹¤í–‰ ìˆœì„œ
- [ ] ë°ë“œë½ ê°ì§€ ë° ì²˜ë¦¬

#### SubTask 5.2.4: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ëª¨ë‹ˆí„°

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/workflow/execution_monitor.py
from typing import Dict, List, Optional, Any
import asyncio
from datetime import datetime, timedelta

@dataclass
class WorkflowMetrics:
    workflow_id: str
    execution_id: str
    start_time: datetime
    end_time: Optional[datetime]
    total_tasks: int
    completed_tasks: int
    failed_tasks: int
    running_tasks: int
    average_task_duration: float
    total_duration: Optional[float]
    resource_usage: Dict[str, Any]

class ExecutionMonitor:
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ëª¨ë‹ˆí„°"""

    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        self.active_executions: Dict[str, WorkflowMetrics] = {}
        self.metrics_store = MetricsStore()
        self.alert_manager = AlertManager()

        # ëª¨ë‹ˆí„°ë§ ì„¤ì •
        self.monitoring_interval = 5  # seconds
        self.monitoring_task = None

    async def start(self):
        """ëª¨ë‹ˆí„° ì‹œì‘"""
        # ì´ë²¤íŠ¸ êµ¬ë…
        self.event_bus.subscribe("workflow.started", self._on_workflow_started)
        self.event_bus.subscribe("workflow.completed", self._on_workflow_completed)
        self.event_bus.subscribe("workflow.failed", self._on_workflow_failed)
        self.event_bus.subscribe("task.started", self._on_task_started)
        self.event_bus.subscribe("task.completed", self._on_task_completed)
        self.event_bus.subscribe("task.failed", self._on_task_failed)

        # ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì‹œì‘
        self.monitoring_task = asyncio.create_task(self._monitoring_loop())

    async def stop(self):
        """ëª¨ë‹ˆí„° ì¤‘ì§€"""
        if self.monitoring_task:
            self.monitoring_task.cancel()

    async def get_execution_status(
        self,
        execution_id: str
    ) -> Optional[WorkflowMetrics]:
        """ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ"""
        return self.active_executions.get(execution_id)

    async def get_execution_history(
        self,
        workflow_id: str,
        limit: int = 10
    ) -> List[WorkflowMetrics]:
        """ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ"""
        return await self.metrics_store.get_workflow_history(
            workflow_id,
            limit
        )

    async def _monitoring_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while True:
            try:
                await asyncio.sleep(self.monitoring_interval)

                # í™œì„± ì‹¤í–‰ ëª¨ë‹ˆí„°ë§
                for execution_id, metrics in self.active_executions.items():
                    await self._monitor_execution(execution_id, metrics)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Monitoring error: {e}")

    async def _monitor_execution(
        self,
        execution_id: str,
        metrics: WorkflowMetrics
    ):
        """ê°œë³„ ì‹¤í–‰ ëª¨ë‹ˆí„°ë§"""
        # ì‹¤í–‰ ì‹œê°„ í™•ì¸
        elapsed_time = (datetime.utcnow() - metrics.start_time).total_seconds()

        # SLA ìœ„ë°˜ í™•ì¸
        sla_config = await self._get_sla_config(metrics.workflow_id)
        if sla_config:
            if elapsed_time > sla_config.max_duration:
                await self.alert_manager.send_alert(
                    AlertType.SLA_VIOLATION,
                    {
                        "execution_id": execution_id,
                        "elapsed_time": elapsed_time,
                        "max_duration": sla_config.max_duration
                    }
                )

        # ì •ì²´ íƒœìŠ¤í¬ í™•ì¸
        stalled_tasks = await self._find_stalled_tasks(execution_id)
        if stalled_tasks:
            await self.alert_manager.send_alert(
                AlertType.STALLED_TASKS,
                {
                    "execution_id": execution_id,
                    "stalled_tasks": stalled_tasks
                }
            )

        # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
        resource_usage = await self._get_resource_usage(execution_id)
        metrics.resource_usage = resource_usage

        # ë©”íŠ¸ë¦­ ì €ì¥
        await self.metrics_store.save_metrics(metrics)

    async def _on_workflow_started(self, event: OrchestratorEvent):
        """ì›Œí¬í”Œë¡œìš° ì‹œì‘ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        metrics = WorkflowMetrics(
            workflow_id=event.data["workflow_def_id"],
            execution_id=event.workflow_id,
            start_time=event.timestamp,
            end_time=None,
            total_tasks=event.data.get("total_tasks", 0),
            completed_tasks=0,
            failed_tasks=0,
            running_tasks=0,
            average_task_duration=0.0,
            total_duration=None,
            resource_usage={}
        )

        self.active_executions[event.workflow_id] = metrics

    async def _on_workflow_completed(self, event: OrchestratorEvent):
        """ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        if event.workflow_id in self.active_executions:
            metrics = self.active_executions[event.workflow_id]
            metrics.end_time = event.timestamp
            metrics.total_duration = (
                metrics.end_time - metrics.start_time
            ).total_seconds()

            # ìµœì¢… ë©”íŠ¸ë¦­ ì €ì¥
            await self.metrics_store.save_final_metrics(metrics)

            # í™œì„± ì‹¤í–‰ì—ì„œ ì œê±°
            del self.active_executions[event.workflow_id]
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì‹¤ì‹œê°„ ì‹¤í–‰ ëª¨ë‹ˆí„°ë§
- [ ] ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥
- [ ] SLA ëª¨ë‹ˆí„°ë§
- [ ] ì•Œë¦¼ ì‹œìŠ¤í…œ í†µí•©

### Task 5.3: ì—ì´ì „íŠ¸ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬

#### SubTask 5.3.1: ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/agent/agent_registry.py
from typing import Dict, List, Optional, Set
import asyncio
from datetime import datetime

class AgentRegistry:
    """ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬"""

    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        self.agents: Dict[str, AgentInfo] = {}
        self.agent_proxies: Dict[str, AgentInterface] = {}
        self.agent_capabilities: Dict[str, List[AgentCapability]] = {}

        # ë™ê¸°í™”
        self.registry_lock = asyncio.Lock()

        # ë””ìŠ¤ì»¤ë²„ë¦¬
        self.discovery_service = AgentDiscoveryService()
        self.discovery_interval = 30  # seconds
        self.discovery_task = None

    async def initialize(self):
        """ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”"""
        # ê¸°ì¡´ ì—ì´ì „íŠ¸ ë¡œë“œ
        await self._load_registered_agents()

        # ë””ìŠ¤ì»¤ë²„ë¦¬ ì‹œì‘
        self.discovery_task = asyncio.create_task(
            self._discovery_loop()
        )

        # ì´ë²¤íŠ¸ êµ¬ë…
        self.event_bus.subscribe(
            "agent.registered",
            self._on_agent_registered
        )
        self.event_bus.subscribe(
            "agent.unregistered",
            self._on_agent_unregistered
        )

    async def register_agent(
        self,
        agent_info: AgentInfo
    ) -> str:
        """ì—ì´ì „íŠ¸ ë“±ë¡"""
        async with self.registry_lock:
            # ì¤‘ë³µ í™•ì¸
            if agent_info.id in self.agents:
                raise ValueError(f"Agent {agent_info.id} already registered")

            # ì—ì´ì „íŠ¸ ì •ë³´ ì €ì¥
            self.agents[agent_info.id] = agent_info

            # í”„ë¡ì‹œ ìƒì„±
            proxy = AgentProxyFactory.create_proxy(agent_info)
            self.agent_proxies[agent_info.id] = proxy

            # ëŠ¥ë ¥ ì¸ë±ì‹±
            self._index_capabilities(agent_info)

            # ì˜êµ¬ ì €ì¥
            await self._persist_agent(agent_info)

            # ë“±ë¡ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="agent.registered",
                    source="agent_registry",
                    timestamp=datetime.utcnow(),
                    data={"agent": agent_info.to_dict()}
                )
            )

            logger.info(f"Agent registered: {agent_info.id} ({agent_info.type})")

        return agent_info.id

    async def unregister_agent(self, agent_id: str) -> bool:
        """ì—ì´ì „íŠ¸ ë“±ë¡ í•´ì œ"""
        async with self.registry_lock:
            if agent_id not in self.agents:
                return False

            agent_info = self.agents[agent_id]

            # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ì œê±°
            del self.agents[agent_id]
            del self.agent_proxies[agent_id]

            # ëŠ¥ë ¥ ì¸ë±ìŠ¤ì—ì„œ ì œê±°
            self._remove_from_capabilities(agent_id)

            # ì˜êµ¬ ì €ì¥ì†Œì—ì„œ ì œê±°
            await self._remove_persisted_agent(agent_id)

            # ë“±ë¡ í•´ì œ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="agent.unregistered",
                    source="agent_registry",
                    timestamp=datetime.utcnow(),
                    data={"agent_id": agent_id}
                )
            )

            logger.info(f"Agent unregistered: {agent_id}")

        return True

    async def get_agent(
        self,
        agent_type: str,
        version: Optional[str] = None
    ) -> AgentInterface:
        """ì—ì´ì „íŠ¸ í”„ë¡ì‹œ ê°€ì ¸ì˜¤ê¸°"""
        candidates = []

        async with self.registry_lock:
            for agent_id, agent_info in self.agents.items():
                if agent_info.type == agent_type:
                    if version is None or agent_info.version == version:
                        if agent_info.status == "healthy":
                            candidates.append(agent_id)

        if not candidates:
            raise AgentNotFoundError(
                f"No healthy agent found for type: {agent_type}"
            )

        # ë¡œë“œ ë°¸ëŸ°ì‹± (ë¼ìš´ë“œ ë¡œë¹ˆ)
        selected_id = await self._select_agent(candidates)

        return self.agent_proxies[selected_id]

    async def find_agents_by_capability(
        self,
        capability_name: str
    ) -> List[AgentInfo]:
        """ëŠ¥ë ¥ìœ¼ë¡œ ì—ì´ì „íŠ¸ ì°¾ê¸°"""
        agent_ids = self.agent_capabilities.get(capability_name, [])

        agents = []
        async with self.registry_lock:
            for agent_id in agent_ids:
                if agent_id in self.agents:
                    agents.append(self.agents[agent_id])

        return agents

    async def get_all_agents(
        self,
        agent_type: Optional[str] = None,
        status: Optional[str] = None
    ) -> List[AgentInfo]:
        """ì „ì²´ ì—ì´ì „íŠ¸ ëª©ë¡"""
        agents = []

        async with self.registry_lock:
            for agent_info in self.agents.values():
                if agent_type and agent_info.type != agent_type:
                    continue
                if status and agent_info.status != status:
                    continue
                agents.append(agent_info)

        return agents

    def _index_capabilities(self, agent_info: AgentInfo):
        """ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ì¸ë±ì‹±"""
        for capability in agent_info.capabilities:
            if capability.name not in self.agent_capabilities:
                self.agent_capabilities[capability.name] = []
            self.agent_capabilities[capability.name].append(agent_info.id)

    async def _discovery_loop(self):
        """ì—ì´ì „íŠ¸ ë””ìŠ¤ì»¤ë²„ë¦¬ ë£¨í”„"""
        while True:
            try:
                await asyncio.sleep(self.discovery_interval)

                # ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ íƒìƒ‰
                discovered = await self.discovery_service.discover_agents()

                for agent_info in discovered:
                    if agent_info.id not in self.agents:
                        await self.register_agent(agent_info)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Discovery error: {e}")
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì—ì´ì „íŠ¸ ë“±ë¡/í•´ì œ
- [ ] ëŠ¥ë ¥ ê¸°ë°˜ ê²€ìƒ‰
- [ ] ìë™ ë””ìŠ¤ì»¤ë²„ë¦¬
- [ ] ë¡œë“œ ë°¸ëŸ°ì‹±

#### SubTask 5.3.2: ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬ ì‹œìŠ¤í…œ

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/agent/health_check.py
from typing import Dict, List, Optional
import asyncio
from datetime import datetime, timedelta

@dataclass
class HealthStatus:
    agent_id: str
    status: str  # healthy, unhealthy, degraded
    last_check: datetime
    response_time: float
    error_count: int
    consecutive_failures: int
    details: Dict[str, Any]

class HealthCheckManager:
    """ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬ ê´€ë¦¬ì"""

    def __init__(
        self,
        registry: AgentRegistry,
        event_bus: EventBus
    ):
        self.registry = registry
        self.event_bus = event_bus

        # í—¬ìŠ¤ ì²´í¬ ì„¤ì •
        self.check_interval = 10  # seconds
        self.timeout = 5  # seconds
        self.failure_threshold = 3
        self.recovery_threshold = 2

        # ìƒíƒœ ì¶”ì 
        self.health_status: Dict[str, HealthStatus] = {}
        self.check_tasks: Dict[str, asyncio.Task] = {}

    async def start(self):
        """í—¬ìŠ¤ ì²´í¬ ì‹œì‘"""
        # ëª¨ë“  ì—ì´ì „íŠ¸ì— ëŒ€í•´ í—¬ìŠ¤ ì²´í¬ ì‹œì‘
        agents = await self.registry.get_all_agents()

        for agent in agents:
            await self.start_health_check(agent.id)

    async def stop(self):
        """í—¬ìŠ¤ ì²´í¬ ì¤‘ì§€"""
        # ëª¨ë“  í—¬ìŠ¤ ì²´í¬ íƒœìŠ¤í¬ ì·¨ì†Œ
        for task in self.check_tasks.values():
            task.cancel()

    async def start_health_check(self, agent_id: str):
        """íŠ¹ì • ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬ ì‹œì‘"""
        if agent_id in self.check_tasks:
            return

        # ì´ˆê¸° ìƒíƒœ
        self.health_status[agent_id] = HealthStatus(
            agent_id=agent_id,
            status="unknown",
            last_check=datetime.utcnow(),
            response_time=0.0,
            error_count=0,
            consecutive_failures=0,
            details={}
        )

        # í—¬ìŠ¤ ì²´í¬ íƒœìŠ¤í¬ ì‹œì‘
        task = asyncio.create_task(
            self._health_check_loop(agent_id)
        )
        self.check_tasks[agent_id] = task

    async def stop_health_check(self, agent_id: str):
        """íŠ¹ì • ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬ ì¤‘ì§€"""
        if agent_id in self.check_tasks:
            self.check_tasks[agent_id].cancel()
            del self.check_tasks[agent_id]
            del self.health_status[agent_id]

    async def _health_check_loop(self, agent_id: str):
        """í—¬ìŠ¤ ì²´í¬ ë£¨í”„"""
        while True:
            try:
                await asyncio.sleep(self.check_interval)
                await self._perform_health_check(agent_id)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Health check loop error for {agent_id}: {e}")

    async def _perform_health_check(self, agent_id: str):
        """í—¬ìŠ¤ ì²´í¬ ìˆ˜í–‰"""
        agent_info = self.registry.agents.get(agent_id)
        if not agent_info:
            return

        proxy = self.registry.agent_proxies.get(agent_id)
        if not proxy:
            return

        status = self.health_status[agent_id]
        start_time = datetime.utcnow()

        try:
            # í—¬ìŠ¤ ì²´í¬ í˜¸ì¶œ
            result = await asyncio.wait_for(
                proxy.health_check(),
                timeout=self.timeout
            )

            # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
            response_time = (datetime.utcnow() - start_time).total_seconds()

            # ìƒíƒœ ì—…ë°ì´íŠ¸
            status.last_check = datetime.utcnow()
            status.response_time = response_time
            status.details = result

            # í—¬ìŠ¤ ìƒíƒœ ê²°ì •
            if result.get("status") == "healthy":
                await self._handle_healthy_response(agent_id, status)
            else:
                await self._handle_unhealthy_response(agent_id, status, result)

        except asyncio.TimeoutError:
            await self._handle_timeout(agent_id, status)
        except Exception as e:
            await self._handle_error(agent_id, status, e)

    async def _handle_healthy_response(
        self,
        agent_id: str,
        status: HealthStatus
    ):
        """ì •ìƒ ì‘ë‹µ ì²˜ë¦¬"""
        previous_status = status.status

        if status.consecutive_failures > 0:
            # ë³µêµ¬ ì¤‘
            status.consecutive_failures = 0
            status.error_count = max(0, status.error_count - 1)

            if status.error_count <= self.recovery_threshold:
                status.status = "healthy"

                # ë³µêµ¬ ì´ë²¤íŠ¸
                if previous_status != "healthy":
                    await self._emit_health_event(
                        agent_id,
                        "agent.recovered",
                        status
                    )
        else:
            status.status = "healthy"

        # ì—ì´ì „íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
        await self._update_agent_status(agent_id, "healthy")

    async def _handle_unhealthy_response(
        self,
        agent_id: str,
        status: HealthStatus,
        result: Dict[str, Any]
    ):
        """ë¹„ì •ìƒ ì‘ë‹µ ì²˜ë¦¬"""
        status.consecutive_failures += 1
        status.error_count += 1

        if status.consecutive_failures >= self.failure_threshold:
            status.status = "unhealthy"
            await self._update_agent_status(agent_id, "unhealthy")

            # ì¥ì•  ì´ë²¤íŠ¸
            await self._emit_health_event(
                agent_id,
                "agent.unhealthy",
                status
            )
        else:
            status.status = "degraded"
            await self._update_agent_status(agent_id, "degraded")
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì£¼ê¸°ì  í—¬ìŠ¤ ì²´í¬
- [ ] ì¥ì•  ê°ì§€ ë° ë³µêµ¬
- [ ] ìƒíƒœ ì „ì´ ê´€ë¦¬
- [ ] ì´ë²¤íŠ¸ ë°œí–‰

#### SubTask 5.3.3: ë™ì  ì—ì´ì „íŠ¸ ìŠ¤ì¼€ì¼ë§

**ë‹´ë‹¹ì**: ì¸í”„ë¼ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/agent/auto_scaling.py
from typing import Dict, List, Optional
import asyncio
from datetime import datetime, timedelta

@dataclass
class ScalingPolicy:
    agent_type: str
    min_instances: int
    max_instances: int
    target_cpu_percent: float
    target_memory_percent: float
    target_queue_depth: int
    scale_up_threshold: float
    scale_down_threshold: float
    cooldown_seconds: int

@dataclass
class ScalingDecision:
    agent_type: str
    current_instances: int
    desired_instances: int
    reason: str
    metrics: Dict[str, float]

class AutoScaler:
    """ì—ì´ì „íŠ¸ ìë™ ìŠ¤ì¼€ì¼ë§"""

    def __init__(
        self,
        registry: AgentRegistry,
        metrics_collector: MetricsCollector,
        infrastructure_manager: InfrastructureManager
    ):
        self.registry = registry
        self.metrics_collector = metrics_collector
        self.infrastructure = infrastructure_manager

        # ìŠ¤ì¼€ì¼ë§ ì •ì±…
        self.policies: Dict[str, ScalingPolicy] = {}

        # ìŠ¤ì¼€ì¼ë§ ìƒíƒœ
        self.last_scaling: Dict[str, datetime] = {}
        self.scaling_lock = asyncio.Lock()

        # ëª¨ë‹ˆí„°ë§
        self.check_interval = 30  # seconds
        self.monitoring_task = None

    async def start(self):
        """ìë™ ìŠ¤ì¼€ì¼ë§ ì‹œì‘"""
        # ì •ì±… ë¡œë“œ
        await self._load_scaling_policies()

        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self.monitoring_task = asyncio.create_task(
            self._scaling_loop()
        )

    async def stop(self):
        """ìë™ ìŠ¤ì¼€ì¼ë§ ì¤‘ì§€"""
        if self.monitoring_task:
            self.monitoring_task.cancel()

    async def set_policy(
        self,
        agent_type: str,
        policy: ScalingPolicy
    ):
        """ìŠ¤ì¼€ì¼ë§ ì •ì±… ì„¤ì •"""
        self.policies[agent_type] = policy
        await self._persist_policy(agent_type, policy)

    async def _scaling_loop(self):
        """ìŠ¤ì¼€ì¼ë§ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while True:
            try:
                await asyncio.sleep(self.check_interval)

                # ê° ì—ì´ì „íŠ¸ íƒ€ì…ë³„ í™•ì¸
                for agent_type, policy in self.policies.items():
                    await self._check_and_scale(agent_type, policy)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Scaling loop error: {e}")

    async def _check_and_scale(
        self,
        agent_type: str,
        policy: ScalingPolicy
    ):
        """ìŠ¤ì¼€ì¼ë§ í•„ìš”ì„± í™•ì¸ ë° ì‹¤í–‰"""
        # ì¿¨ë‹¤ìš´ í™•ì¸
        if not self._is_cooldown_expired(agent_type, policy):
            return

        # í˜„ì¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        metrics = await self._collect_metrics(agent_type)

        # í˜„ì¬ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜
        current_instances = await self._count_instances(agent_type)

        # ìŠ¤ì¼€ì¼ë§ ê²°ì •
        decision = self._make_scaling_decision(
            policy,
            current_instances,
            metrics
        )

        # ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰
        if decision.desired_instances != current_instances:
            await self._execute_scaling(decision)

    async def _collect_metrics(
        self,
        agent_type: str
    ) -> Dict[str, float]:
        """ì—ì´ì „íŠ¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        agents = await self.registry.get_all_agents(
            agent_type=agent_type,
            status="healthy"
        )

        if not agents:
            return {}

        # ì§‘ê³„ ë©”íŠ¸ë¦­
        total_cpu = 0.0
        total_memory = 0.0
        total_queue_depth = 0

        for agent in agents:
            agent_metrics = await self.metrics_collector.get_agent_metrics(
                agent.id
            )

            total_cpu += agent_metrics.get("cpu_percent", 0)
            total_memory += agent_metrics.get("memory_percent", 0)
            total_queue_depth += agent_metrics.get("queue_depth", 0)

        # í‰ê·  ê³„ì‚°
        avg_cpu = total_cpu / len(agents)
        avg_memory = total_memory / len(agents)

        return {
            "cpu_percent": avg_cpu,
            "memory_percent": avg_memory,
            "queue_depth": total_queue_depth,
            "instance_count": len(agents)
        }

    def _make_scaling_decision(
        self,
        policy: ScalingPolicy,
        current_instances: int,
        metrics: Dict[str, float]
    ) -> ScalingDecision:
        """ìŠ¤ì¼€ì¼ë§ ê²°ì •"""
        desired_instances = current_instances
        reason = "No scaling needed"

        # CPU ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
        if metrics.get("cpu_percent", 0) > policy.scale_up_threshold:
            desired_instances = min(
                current_instances + 1,
                policy.max_instances
            )
            reason = f"High CPU usage: {metrics['cpu_percent']:.1f}%"

        elif metrics.get("cpu_percent", 100) < policy.scale_down_threshold:
            if current_instances > policy.min_instances:
                desired_instances = current_instances - 1
                reason = f"Low CPU usage: {metrics['cpu_percent']:.1f}%"

        # í ê¹Šì´ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
        queue_depth = metrics.get("queue_depth", 0)
        if queue_depth > policy.target_queue_depth * 1.5:
            desired_instances = min(
                current_instances + 1,
                policy.max_instances
            )
            reason = f"High queue depth: {queue_depth}"

        return ScalingDecision(
            agent_type=policy.agent_type,
            current_instances=current_instances,
            desired_instances=desired_instances,
            reason=reason,
            metrics=metrics
        )

    async def _execute_scaling(self, decision: ScalingDecision):
        """ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰"""
        async with self.scaling_lock:
            diff = decision.desired_instances - decision.current_instances

            if diff > 0:
                # ìŠ¤ì¼€ì¼ ì—…
                await self._scale_up(decision.agent_type, diff)
            else:
                # ìŠ¤ì¼€ì¼ ë‹¤ìš´
                await self._scale_down(decision.agent_type, abs(diff))

            # ë§ˆì§€ë§‰ ìŠ¤ì¼€ì¼ë§ ì‹œê°„ ê¸°ë¡
            self.last_scaling[decision.agent_type] = datetime.utcnow()

            # ìŠ¤ì¼€ì¼ë§ ì´ë²¤íŠ¸ ë°œí–‰
            await self.event_bus.publish(
                OrchestratorEvent(
                    event_type="agent.scaled",
                    source="auto_scaler",
                    timestamp=datetime.utcnow(),
                    data={
                        "agent_type": decision.agent_type,
                        "from_instances": decision.current_instances,
                        "to_instances": decision.desired_instances,
                        "reason": decision.reason
                    }
                )
            )
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ë©”íŠ¸ë¦­ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
- [ ] ì •ì±… ê´€ë¦¬
- [ ] ì¿¨ë‹¤ìš´ ë©”ì»¤ë‹ˆì¦˜
- [ ] ì¸í”„ë¼ í†µí•©

#### SubTask 5.3.4: ì—ì´ì „íŠ¸ ë²„ì „ ê´€ë¦¬

**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/orchestration/agent/version_manager.py
from typing import Dict, List, Optional, Tuple
import asyncio
from datetime import datetime
import semver

@dataclass
class AgentVersion:
    agent_type: str
    version: str
    release_date: datetime
    changelog: str
    compatibility: Dict[str, str]  # dependency -> version
    deprecated: bool = False
    end_of_life: Optional[datetime] = None

@dataclass
class DeploymentStrategy:
    strategy_type: str  # canary, blue-green, rolling
    canary_percent: Optional[int] = None
    rollback_threshold: Optional[float] = None
    health_check_interval: int = 30

class VersionManager:
    """ì—ì´ì „íŠ¸ ë²„ì „ ê´€ë¦¬"""

    def __init__(
        self,
        registry: AgentRegistry,
        deployment_manager: DeploymentManager
    ):
        self.registry = registry
        self.deployment_manager = deployment_manager

        # ë²„ì „ ì •ë³´
        self.versions: Dict[str, List[AgentVersion]] = {}
        self.active_deployments: Dict[str, DeploymentStatus] = {}

        # ë™ê¸°í™”
        self.deployment_lock = asyncio.Lock()

    async def register_version(
        self,
        agent_type: str,
        version: AgentVersion
    ):
        """ìƒˆ ë²„ì „ ë“±ë¡"""
        if agent_type not in self.versions:
            self.versions[agent_type] = []

        # ë²„ì „ ìœ íš¨ì„± ê²€ì¦
        self._validate_version(version)

        # í˜¸í™˜ì„± í™•ì¸
        await self._check_compatibility(agent_type, version)

        # ë²„ì „ ì¶”ê°€
        self.versions[agent_type].append(version)
        self.versions[agent_type].sort(
            key=lambda v: semver.VersionInfo.parse(v.version),
            reverse=True
        )

        logger.info(
            f"Registered version {version.version} for {agent_type}"
        )

    async def deploy_version(
        self,
        agent_type: str,
        target_version: str,
        strategy: DeploymentStrategy
    ) -> str:
        """ë²„ì „ ë°°í¬"""
        async with self.deployment_lock:
            # í˜„ì¬ ë²„ì „ í™•ì¸
            current_version = await self._get_current_version(agent_type)

            if current_version == target_version:
                raise ValueError("Target version is already deployed")

            # ë°°í¬ ê³„íš ìƒì„±
            deployment_plan = await self._create_deployment_plan(
                agent_type,
                current_version,
                target_version,
                strategy
            )

            # ë°°í¬ ì‹¤í–‰
            deployment_id = await self._execute_deployment(
                deployment_plan
            )

            return deployment_id

    async def rollback_version(
        self,
        agent_type: str,
        target_version: Optional[str] = None
    ):
        """ë²„ì „ ë¡¤ë°±"""
        async with self.deployment_lock:
            # ì´ì „ ì•ˆì • ë²„ì „ ì°¾ê¸°
            if not target_version:
                target_version = await self._find_last_stable_version(
                    agent_type
                )

            if not target_version:
                raise ValueError("No stable version found for rollback")

            # ë¡¤ë°± ì‹¤í–‰
            await self._execute_rollback(agent_type, target_version)

    async def _create_deployment_plan(
        self,
        agent_type: str,
        current_version: str,
        target_version: str,
        strategy: DeploymentStrategy
    ) -> DeploymentPlan:
        """ë°°í¬ ê³„íš ìƒì„±"""
        plan = DeploymentPlan(
            agent_type=agent_type,
            from_version=current_version,
            to_version=target_version,
            strategy=strategy,
            steps=[]
        )

        if strategy.strategy_type == "canary":
            plan.steps = self._create_canary_steps(
                agent_type,
                target_version,
                strategy.canary_percent
            )
        elif strategy.strategy_type == "blue-green":
            plan.steps = self._create_blue_green_steps(
                agent_type,
                target_version
            )
        elif strategy.strategy_type == "rolling":
            plan.steps = self._create_rolling_steps(
                agent_type,
                target_version
            )

        return plan

    def _create_canary_steps(
        self,
        agent_type: str,
        target_version: str,
        canary_percent: int
    ) -> List[DeploymentStep]:
        """ì¹´ë‚˜ë¦¬ ë°°í¬ ë‹¨ê³„ ìƒì„±"""
        return [
            DeploymentStep(
                name="Deploy canary instances",
                action="deploy_percent",
                parameters={
                    "version": target_version,
                    "percent": canary_percent
                }
            ),
            DeploymentStep(
                name="Monitor canary health",
                action="monitor",
                parameters={
                    "duration_seconds": 300,
                    "metrics": ["error_rate", "response_time"]
                }
            ),
            DeploymentStep(
                name="Evaluate canary",
                action="evaluate",
                parameters={
                    "threshold": 0.95,
                    "rollback_on_failure": True
                }
            ),
            DeploymentStep(
                name="Promote canary",
                action="promote",
                parameters={
                    "version": target_version
                }
            )
        ]

    async def _check_version_health(
        self,
        agent_type: str,
        version: str
    ) -> VersionHealth:
        """ë²„ì „ ê±´ê°• ìƒíƒœ í™•ì¸"""
        agents = await self.registry.get_all_agents(
            agent_type=agent_type
        )

        version_agents = [
            a for a in agents
            if a.version == version
        ]

        if not version_agents:
            return VersionHealth(
                version=version,
                healthy_count=0,
                total_count=0,
                error_rate=0.0,
                avg_response_time=0.0
            )

        # ê±´ê°•í•œ ì—ì´ì „íŠ¸ ìˆ˜
        healthy_count = len([
            a for a in version_agents
            if a.status == "healthy"
        ])

        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        total_errors = 0
        total_requests = 0
        total_response_time = 0

        for agent in version_agents:
            metrics = await self.metrics_collector.get_agent_metrics(
                agent.id,
                time_range=timedelta(minutes=5)
            )

            total_errors += metrics.get("error_count", 0)
            total_requests += metrics.get("request_count", 0)
            total_response_time += metrics.get("total_response_time", 0)

        error_rate = total_errors / total_requests if total_requests > 0 else 0
        avg_response_time = total_response_time / total_requests if total_requests > 0 else 0

        return VersionHealth(
            version=version,
            healthy_count=healthy_count,
            total_count=len(version_agents),
            error_rate=error_rate,
            avg_response_time=avg_response_time
        )
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ë²„ì „ ë“±ë¡ ë° ê´€ë¦¬
- [ ] ë°°í¬ ì „ëµ êµ¬í˜„ (Canary/Blue-Green/Rolling)
- [ ] ë²„ì „ í˜¸í™˜ì„± ê²€ì¦
- [ ] ë¡¤ë°± ë©”ì»¤ë‹ˆì¦˜

---

# Phase 5: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ - Tasks 5.4~5.6 SubTask êµ¬ì¡°

## ğŸ“‹ Task 5.4~5.6 SubTask ë¦¬ìŠ¤íŠ¸

### Task 5.4: ì›Œí¬í”Œë¡œìš° ì •ì˜ ì–¸ì–´ (DSL) êµ¬í˜„

- **SubTask 5.4.1**: DSL ë¬¸ë²• ì„¤ê³„ ë° ëª…ì„¸
- **SubTask 5.4.2**: DSL íŒŒì„œ ë° ì»´íŒŒì¼ëŸ¬ êµ¬í˜„
- **SubTask 5.4.3**: DSL ê²€ì¦ê¸° ë° íƒ€ì… ì‹œìŠ¤í…œ
- **SubTask 5.4.4**: DSL IDE ì§€ì› ë° ë„êµ¬

### Task 5.5: ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ìˆ˜ì •

- **SubTask 5.5.1**: ëŸ°íƒ€ì„ ì›Œí¬í”Œë¡œìš° ë¹Œë”
- **SubTask 5.5.2**: ì›Œí¬í”Œë¡œìš° ìˆ˜ì • API
- **SubTask 5.5.3**: ë™ì  ë¶„ê¸° ë° ì¡°ê±´ë¶€ ì‹¤í–‰
- **SubTask 5.5.4**: ì›Œí¬í”Œë¡œìš° ë²„ì „ ê´€ë¦¬

### Task 5.6: ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ë° ì¬ì‚¬ìš© ì‹œìŠ¤í…œ

- **SubTask 5.6.1**: í…œí”Œë¦¿ ì €ì¥ì†Œ êµ¬ì¶•
- **SubTask 5.6.2**: í…œí”Œë¦¿ íŒŒë¼ë¯¸í„°í™” ì‹œìŠ¤í…œ
- **SubTask 5.6.3**: í…œí”Œë¦¿ ìƒì† ë° í™•ì¥ ë©”ì»¤ë‹ˆì¦˜
- **SubTask 5.6.4**: í…œí”Œë¦¿ ê³µìœ  ë§ˆì¼“í”Œë ˆì´ìŠ¤

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 5.4: ì›Œí¬í”Œë¡œìš° ì •ì˜ ì–¸ì–´ (DSL) êµ¬í˜„

#### SubTask 5.4.1: DSL ë¬¸ë²• ì„¤ê³„ ë° ëª…ì„¸

**ë‹´ë‹¹ì**: ì–¸ì–´ ì„¤ê³„ ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dsl/grammar.ts
export interface DSLGrammar {
  version: string;
  keywords: string[];
  operators: string[];
  types: string[];
  builtins: string[];
}

// T-Developer Workflow DSL (TWDSL) ë¬¸ë²• ì •ì˜
export const TWDSLGrammar: DSLGrammar = {
  version: "1.0.0",
  keywords: [
    "workflow",
    "task",
    "parallel",
    "sequence",
    "if",
    "else",
    "while",
    "foreach",
    "input",
    "output",
    "depends",
    "timeout",
    "retry",
    "on_error",
    "on_success",
    "import",
    "export",
    "template",
  ],
  operators: [
    "->",
    "=>",
    "==",
    "!=",
    ">",
    "<",
    ">=",
    "<=",
    "&&",
    "||",
    "!",
    "+",
    "-",
    "*",
    "/",
    "%",
    "=",
    ".",
  ],
  types: [
    "string",
    "number",
    "boolean",
    "object",
    "array",
    "any",
    "datetime",
    "duration",
    "file",
    "url",
  ],
  builtins: [
    "env",
    "context",
    "result",
    "error",
    "retry_count",
    "current_time",
    "workflow_id",
    "task_id",
  ],
};

// DSL ì˜ˆì œ
const dslExample = `
workflow CreateFullStackApp {
  version: "1.0.0"
  description: "Full-stack application generation workflow"
  
  input {
    project_name: string
    tech_stack: {
      frontend: string
      backend: string
      database: string
    }
    features: array<string>
  }
  
  output {
    project_url: string
    documentation_url: string
    deployment_status: string
  }
  
  // ë³‘ë ¬ ì‹¤í–‰ ë¸”ë¡
  parallel {
    // Frontend ìƒì„±
    task generateFrontend {
      agent: "UISelectionAgent"
      input: {
        framework: tech_stack.frontend
        features: features.filter(f => f.startsWith("ui_"))
      }
      timeout: 5m
      retry: 3
    }
    
    // Backend ìƒì„±
    task generateBackend {
      agent: "BackendAgent"
      input: {
        framework: tech_stack.backend
        database: tech_stack.database
        features: features.filter(f => f.startsWith("api_"))
      }
      timeout: 10m
    }
  }
  
  // ìˆœì°¨ ì‹¤í–‰
  sequence {
    // í†µí•© í…ŒìŠ¤íŠ¸
    task runIntegrationTests {
      agent: "TestAgent"
      depends: [generateFrontend, generateBackend]
      input: {
        frontend_output: generateFrontend.result
        backend_output: generateBackend.result
      }
      on_error: {
        retry: 2
        fallback: skipTests
      }
    }
    
    // ì¡°ê±´ë¶€ ë°°í¬
    if (runIntegrationTests.result.passed) {
      task deployApplication {
        agent: "DeploymentAgent"
        input: {
          frontend: generateFrontend.result.build_path
          backend: generateBackend.result.build_path
        }
      }
    } else {
      task notifyFailure {
        agent: "NotificationAgent"
        input: {
          message: "Integration tests failed"
          details: runIntegrationTests.result.errors
        }
      }
    }
  }
  
  // ë°˜ë³µ ì‹¤í–‰
  foreach feature in features {
    task generateFeatureTests {
      agent: "TestGenerationAgent"
      input: {
        feature_name: feature
        project_context: context
      }
    }
  }
}
`;

// DSL ì–¸ì–´ ëª…ì„¸
export class DSLSpecification {
  // êµ¬ë¬¸ ê·œì¹™
  syntaxRules = {
    workflow: {
      pattern: /workflow\s+(\w+)\s*{/,
      required: ["version", "input", "output"],
      optional: ["description", "timeout", "on_error"],
    },
    task: {
      pattern: /task\s+(\w+)\s*{/,
      required: ["agent"],
      optional: [
        "input",
        "depends",
        "timeout",
        "retry",
        "on_error",
        "on_success",
      ],
    },
    parallel: {
      pattern: /parallel\s*{/,
      children: ["task", "sequence", "if", "foreach"],
    },
    sequence: {
      pattern: /sequence\s*{/,
      children: ["task", "parallel", "if", "foreach", "while"],
    },
    conditional: {
      pattern: /if\s*\((.*?)\)\s*{/,
      elseBranch: /else\s*{/,
    },
    loop: {
      foreach: /foreach\s+(\w+)\s+in\s+(.*?)\s*{/,
      while: /while\s*\((.*?)\)\s*{/,
    },
  };

  // íƒ€ì… ì‹œìŠ¤í…œ
  typeSystem = {
    primitives: ["string", "number", "boolean", "null"],
    complex: ["object", "array"],
    custom: ["datetime", "duration", "file", "url"],

    typeInference: {
      string: /^["'].*["']$/,
      number: /^-?\d+(\.\d+)?$/,
      boolean: /^(true|false)$/,
      null: /^null$/,
      array: /^\[.*\]$/,
      object: /^{.*}$/,
    },
  };

  // í‘œí˜„ì‹ í‰ê°€ ê·œì¹™
  expressionRules = {
    // ë³€ìˆ˜ ì°¸ì¡°
    variableRef: /(\w+)\.(\w+)/,

    // í•¨ìˆ˜ í˜¸ì¶œ
    functionCall: /(\w+)\((.*?)\)/,

    // ì—°ì‚°ì ìš°ì„ ìˆœìœ„
    operatorPrecedence: {
      "||": 1,
      "&&": 2,
      "==": 3,
      "!=": 3,
      ">": 4,
      "<": 4,
      ">=": 4,
      "<=": 4,
      "+": 5,
      "-": 5,
      "*": 6,
      "/": 6,
      "%": 6,
      "!": 7,
      ".": 8,
    },
  };
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì™„ì „í•œ DSL ë¬¸ë²• ëª…ì„¸
- [ ] íƒ€ì… ì‹œìŠ¤í…œ ì •ì˜
- [ ] í‘œí˜„ì‹ í‰ê°€ ê·œì¹™
- [ ] ì˜ˆì œ ë° ë¬¸ì„œí™”

#### SubTask 5.4.2: DSL íŒŒì„œ ë° ì»´íŒŒì¼ëŸ¬ êµ¬í˜„

**ë‹´ë‹¹ì**: ì»´íŒŒì¼ëŸ¬ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 20ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dsl/parser.ts
import { Lexer, Token } from "./lexer";
import { ASTNode, WorkflowAST } from "./ast";

export class DSLParser {
  private lexer: Lexer;
  private currentToken: Token;
  private position: number = 0;

  constructor(private source: string) {
    this.lexer = new Lexer(source);
  }

  // ë©”ì¸ íŒŒì‹± í•¨ìˆ˜
  parse(): WorkflowAST {
    const tokens = this.lexer.tokenize();
    this.position = 0;
    this.currentToken = tokens[0];

    const workflow = this.parseWorkflow();

    if (this.position < tokens.length - 1) {
      throw new ParseError(
        `Unexpected token: ${this.currentToken.value}`,
        this.currentToken.line,
        this.currentToken.column
      );
    }

    return workflow;
  }

  // ì›Œí¬í”Œë¡œìš° íŒŒì‹±
  private parseWorkflow(): WorkflowAST {
    this.expect("workflow");
    const name = this.expectIdentifier();
    this.expect("{");

    const workflow: WorkflowAST = {
      type: "workflow",
      name,
      version: "",
      description: "",
      input: {},
      output: {},
      body: [],
    };

    while (!this.check("}")) {
      if (this.match("version")) {
        this.expect(":");
        workflow.version = this.expectString();
      } else if (this.match("description")) {
        this.expect(":");
        workflow.description = this.expectString();
      } else if (this.match("input")) {
        workflow.input = this.parseInputOutput();
      } else if (this.match("output")) {
        workflow.output = this.parseInputOutput();
      } else {
        // ì›Œí¬í”Œë¡œìš° ë°”ë”” íŒŒì‹±
        workflow.body.push(this.parseStatement());
      }
    }

    this.expect("}");
    return workflow;
  }

  // ë¬¸ì¥ íŒŒì‹±
  private parseStatement(): ASTNode {
    if (this.match("task")) {
      return this.parseTask();
    } else if (this.match("parallel")) {
      return this.parseParallel();
    } else if (this.match("sequence")) {
      return this.parseSequence();
    } else if (this.match("if")) {
      return this.parseConditional();
    } else if (this.match("foreach")) {
      return this.parseForeach();
    } else if (this.match("while")) {
      return this.parseWhile();
    } else {
      throw new ParseError(
        `Unexpected statement: ${this.currentToken.value}`,
        this.currentToken.line,
        this.currentToken.column
      );
    }
  }

  // íƒœìŠ¤í¬ íŒŒì‹±
  private parseTask(): ASTNode {
    const name = this.expectIdentifier();
    this.expect("{");

    const task: TaskAST = {
      type: "task",
      name,
      agent: "",
      input: {},
      depends: [],
      timeout: null,
      retry: null,
      onError: null,
      onSuccess: null,
    };

    while (!this.check("}")) {
      if (this.match("agent")) {
        this.expect(":");
        task.agent = this.expectString();
      } else if (this.match("input")) {
        this.expect(":");
        task.input = this.parseExpression();
      } else if (this.match("depends")) {
        this.expect(":");
        task.depends = this.parseArray();
      } else if (this.match("timeout")) {
        this.expect(":");
        task.timeout = this.parseDuration();
      } else if (this.match("retry")) {
        this.expect(":");
        task.retry = this.expectNumber();
      } else if (this.match("on_error")) {
        task.onError = this.parseErrorHandler();
      } else if (this.match("on_success")) {
        task.onSuccess = this.parseSuccessHandler();
      }
    }

    this.expect("}");
    return task;
  }

  // í‘œí˜„ì‹ íŒŒì‹±
  private parseExpression(): ASTNode {
    return this.parseOrExpression();
  }

  private parseOrExpression(): ASTNode {
    let left = this.parseAndExpression();

    while (this.match("||")) {
      const operator = this.previous();
      const right = this.parseAndExpression();
      left = {
        type: "binary",
        operator: operator.value,
        left,
        right,
      };
    }

    return left;
  }

  // ... ì¶”ê°€ íŒŒì‹± ë©”ì„œë“œë“¤
}

// DSL ì»´íŒŒì¼ëŸ¬
export class DSLCompiler {
  constructor(private optimizer: DSLOptimizer) {}

  // ASTë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°ë¡œ ì»´íŒŒì¼
  compile(ast: WorkflowAST): CompiledWorkflow {
    // 1. ì˜ë¯¸ ë¶„ì„
    const analyzed = this.semanticAnalysis(ast);

    // 2. ìµœì í™”
    const optimized = this.optimizer.optimize(analyzed);

    // 3. ì¤‘ê°„ í‘œí˜„(IR) ìƒì„±
    const ir = this.generateIR(optimized);

    // 4. ì½”ë“œ ìƒì„±
    const code = this.generateCode(ir);

    return {
      id: this.generateWorkflowId(ast.name),
      name: ast.name,
      version: ast.version,
      compiledAt: new Date(),
      code,
      metadata: this.extractMetadata(ast),
    };
  }

  // ì˜ë¯¸ ë¶„ì„
  private semanticAnalysis(ast: WorkflowAST): AnalyzedAST {
    const analyzer = new SemanticAnalyzer();

    // íƒ€ì… ê²€ì‚¬
    analyzer.checkTypes(ast);

    // ë³€ìˆ˜ ìŠ¤ì½”í”„ ë¶„ì„
    analyzer.analyzeScopes(ast);

    // ì˜ì¡´ì„± ë¶„ì„
    analyzer.analyzeDependencies(ast);

    // ë„ë‹¬ ê°€ëŠ¥ì„± ë¶„ì„
    analyzer.checkReachability(ast);

    return analyzer.getAnalyzedAST();
  }

  // ì¤‘ê°„ í‘œí˜„ ìƒì„±
  private generateIR(ast: AnalyzedAST): IntermediateRepresentation {
    const irGenerator = new IRGenerator();

    // ê¸°ë³¸ ë¸”ë¡ ìƒì„±
    const blocks = irGenerator.createBasicBlocks(ast);

    // ì œì–´ íë¦„ ê·¸ë˜í”„ ìƒì„±
    const cfg = irGenerator.createControlFlowGraph(blocks);

    // ë°ì´í„° íë¦„ ë¶„ì„
    const dataFlow = irGenerator.analyzeDataFlow(cfg);

    return {
      blocks,
      cfg,
      dataFlow,
      symbols: irGenerator.getSymbolTable(),
    };
  }

  // ì‹¤í–‰ ì½”ë“œ ìƒì„±
  private generateCode(ir: IntermediateRepresentation): ExecutableCode {
    const codeGen = new CodeGenerator();

    // ì›Œí¬í”Œë¡œìš° ì •ì˜ ìƒì„±
    const workflowDef = codeGen.generateWorkflowDefinition(ir);

    // íƒœìŠ¤í¬ ì •ì˜ ìƒì„±
    const taskDefs = codeGen.generateTaskDefinitions(ir);

    // ëŸ°íƒ€ì„ í—¬í¼ ìƒì„±
    const helpers = codeGen.generateHelpers(ir);

    return {
      workflow: workflowDef,
      tasks: taskDefs,
      helpers,
      entryPoint: codeGen.getEntryPoint(),
    };
  }
}

// DSL ìµœì í™”ê¸°
export class DSLOptimizer {
  optimize(ast: AnalyzedAST): OptimizedAST {
    // 1. ì£½ì€ ì½”ë“œ ì œê±°
    this.removeDeadCode(ast);

    // 2. ìƒìˆ˜ í´ë”©
    this.constantFolding(ast);

    // 3. ê³µí†µ ë¶€ë¶„ì‹ ì œê±°
    this.commonSubexpressionElimination(ast);

    // 4. ë³‘ë ¬í™” ê¸°íšŒ ì‹ë³„
    this.identifyParallelization(ast);

    // 5. íƒœìŠ¤í¬ ë³‘í•©
    this.mergeCompatibleTasks(ast);

    return ast as OptimizedAST;
  }

  private removeDeadCode(ast: AnalyzedAST): void {
    // ë„ë‹¬ ë¶ˆê°€ëŠ¥í•œ íƒœìŠ¤í¬ ì œê±°
    const visitor = new ASTVisitor();

    visitor.visitWorkflow(ast, (node) => {
      if (node.type === "task" && !node.reachable) {
        // ë¶€ëª¨ ë…¸ë“œì—ì„œ ì œê±°
        this.removeNode(ast, node);
      }
    });
  }

  private identifyParallelization(ast: AnalyzedAST): void {
    // ë…ë¦½ì ì¸ íƒœìŠ¤í¬ ì°¾ê¸°
    const dependencyGraph = this.buildDependencyGraph(ast);
    const independentTasks = this.findIndependentTasks(dependencyGraph);

    // ë³‘ë ¬ ë¸”ë¡ìœ¼ë¡œ ê·¸ë£¹í™”
    for (const group of independentTasks) {
      if (group.length > 1) {
        this.wrapInParallelBlock(ast, group);
      }
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì™„ì „í•œ íŒŒì„œ êµ¬í˜„
- [ ] AST ìƒì„± ë° ë³€í™˜
- [ ] ì˜ë¯¸ ë¶„ì„ ë° íƒ€ì… ê²€ì‚¬
- [ ] ì½”ë“œ ìƒì„± ë° ìµœì í™”

#### SubTask 5.4.3: DSL ê²€ì¦ê¸° ë° íƒ€ì… ì‹œìŠ¤í…œ

**ë‹´ë‹¹ì**: íƒ€ì… ì‹œìŠ¤í…œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dsl/validator.ts
export interface ValidationResult {
  valid: boolean;
  errors: ValidationError[];
  warnings: ValidationWarning[];
  hints: ValidationHint[];
}

export class DSLValidator {
  private typeChecker: TypeChecker;
  private dependencyChecker: DependencyChecker;
  private semanticChecker: SemanticChecker;

  constructor() {
    this.typeChecker = new TypeChecker();
    this.dependencyChecker = new DependencyChecker();
    this.semanticChecker = new SemanticChecker();
  }

  async validate(source: string): Promise<ValidationResult> {
    const errors: ValidationError[] = [];
    const warnings: ValidationWarning[] = [];
    const hints: ValidationHint[] = [];

    try {
      // 1. ë ‰ì‹± ê²€ì¦
      const lexer = new Lexer(source);
      const tokens = lexer.tokenize();

      // 2. íŒŒì‹± ê²€ì¦
      const parser = new DSLParser(source);
      const ast = parser.parse();

      // 3. íƒ€ì… ê²€ì¦
      const typeErrors = await this.typeChecker.check(ast);
      errors.push(...typeErrors);

      // 4. ì˜ì¡´ì„± ê²€ì¦
      const depResult = await this.dependencyChecker.check(ast);
      errors.push(...depResult.errors);
      warnings.push(...depResult.warnings);

      // 5. ì˜ë¯¸ì  ê²€ì¦
      const semanticResult = await this.semanticChecker.check(ast);
      errors.push(...semanticResult.errors);
      warnings.push(...semanticResult.warnings);
      hints.push(...semanticResult.hints);

      // 6. ëª¨ë²” ì‚¬ë¡€ ê²€ì¦
      const bestPractices = await this.checkBestPractices(ast);
      hints.push(...bestPractices);
    } catch (e) {
      if (e instanceof ParseError) {
        errors.push({
          type: "parse_error",
          message: e.message,
          line: e.line,
          column: e.column,
          severity: "error",
        });
      } else {
        errors.push({
          type: "unknown_error",
          message: e.message,
          severity: "error",
        });
      }
    }

    return {
      valid: errors.length === 0,
      errors,
      warnings,
      hints,
    };
  }

  private async checkBestPractices(
    ast: WorkflowAST
  ): Promise<ValidationHint[]> {
    const hints: ValidationHint[] = [];

    // íƒœìŠ¤í¬ ìˆ˜ í™•ì¸
    const taskCount = this.countTasks(ast);
    if (taskCount > 50) {
      hints.push({
        type: "complexity",
        message:
          "Consider breaking down the workflow into smaller sub-workflows",
        severity: "hint",
      });
    }

    // ì¤‘ë³µ ì½”ë“œ ê°ì§€
    const duplicates = this.findDuplicatePatterns(ast);
    for (const dup of duplicates) {
      hints.push({
        type: "duplication",
        message: `Consider extracting repeated pattern into a template: ${dup.pattern}`,
        severity: "hint",
      });
    }

    return hints;
  }
}

// íƒ€ì… ì²´ì»¤
export class TypeChecker {
  private typeEnvironment: TypeEnvironment;
  private inferenceEngine: TypeInferenceEngine;

  constructor() {
    this.typeEnvironment = new TypeEnvironment();
    this.inferenceEngine = new TypeInferenceEngine();
  }

  async check(ast: WorkflowAST): Promise<ValidationError[]> {
    const errors: ValidationError[] = [];

    // ê¸€ë¡œë²Œ íƒ€ì… í™˜ê²½ ì´ˆê¸°í™”
    this.initializeGlobalTypes();

    // ì…ì¶œë ¥ íƒ€ì… ë“±ë¡
    this.registerIOTypes(ast);

    // AST ìˆœíšŒí•˜ë©° íƒ€ì… ê²€ì‚¬
    const visitor = new TypeCheckVisitor(this.typeEnvironment);

    visitor.on("type_error", (error) => {
      errors.push(error);
    });

    visitor.visit(ast);

    return errors;
  }

  private initializeGlobalTypes(): void {
    // ë‚´ì¥ íƒ€ì… ë“±ë¡
    this.typeEnvironment.registerType("string", PrimitiveType.String);
    this.typeEnvironment.registerType("number", PrimitiveType.Number);
    this.typeEnvironment.registerType("boolean", PrimitiveType.Boolean);

    // ë³µí•© íƒ€ì…
    this.typeEnvironment.registerType("array", new ArrayType());
    this.typeEnvironment.registerType("object", new ObjectType());

    // ì»¤ìŠ¤í…€ íƒ€ì…
    this.typeEnvironment.registerType("datetime", new DateTimeType());
    this.typeEnvironment.registerType("duration", new DurationType());
  }
}

// íƒ€ì… ì¶”ë¡  ì—”ì§„
export class TypeInferenceEngine {
  infer(expression: ASTNode, context: TypeContext): Type {
    switch (expression.type) {
      case "literal":
        return this.inferLiteralType(expression);

      case "identifier":
        return this.inferIdentifierType(expression, context);

      case "binary":
        return this.inferBinaryType(expression, context);

      case "function_call":
        return this.inferFunctionType(expression, context);

      case "member_access":
        return this.inferMemberType(expression, context);

      default:
        return new AnyType();
    }
  }

  private inferLiteralType(literal: LiteralNode): Type {
    if (typeof literal.value === "string") {
      return PrimitiveType.String;
    } else if (typeof literal.value === "number") {
      return PrimitiveType.Number;
    } else if (typeof literal.value === "boolean") {
      return PrimitiveType.Boolean;
    } else if (literal.value === null) {
      return new NullType();
    } else if (Array.isArray(literal.value)) {
      return new ArrayType(this.inferArrayElementType(literal.value));
    } else if (typeof literal.value === "object") {
      return this.inferObjectType(literal.value);
    }

    return new AnyType();
  }
}

// ì˜ì¡´ì„± ê²€ì‚¬ê¸°
export class DependencyChecker {
  async check(ast: WorkflowAST): Promise<DependencyCheckResult> {
    const errors: ValidationError[] = [];
    const warnings: ValidationWarning[] = [];

    // ì˜ì¡´ì„± ê·¸ë˜í”„ êµ¬ì¶•
    const depGraph = this.buildDependencyGraph(ast);

    // 1. ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
    const cycles = this.findCycles(depGraph);
    for (const cycle of cycles) {
      errors.push({
        type: "circular_dependency",
        message: `Circular dependency detected: ${cycle.join(" -> ")}`,
        severity: "error",
      });
    }

    // 2. ë¯¸í•´ê²° ì˜ì¡´ì„± ê²€ì‚¬
    const unresolved = this.findUnresolvedDependencies(ast, depGraph);
    for (const dep of unresolved) {
      errors.push({
        type: "unresolved_dependency",
        message: `Task '${dep.from}' depends on unknown task '${dep.to}'`,
        severity: "error",
      });
    }

    // 3. ë„ë‹¬ ë¶ˆê°€ëŠ¥í•œ íƒœìŠ¤í¬
    const unreachable = this.findUnreachableTasks(depGraph);
    for (const task of unreachable) {
      warnings.push({
        type: "unreachable_task",
        message: `Task '${task}' is unreachable`,
        severity: "warning",
      });
    }

    return { errors, warnings };
  }

  private buildDependencyGraph(ast: WorkflowAST): DependencyGraph {
    const graph = new DependencyGraph();

    const visitor = new DependencyVisitor();
    visitor.visit(ast, (task) => {
      graph.addNode(task.name);

      if (task.depends) {
        for (const dep of task.depends) {
          graph.addEdge(task.name, dep);
        }
      }
    });

    return graph;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì¢…í•©ì ì¸ ê²€ì¦ ì‹œìŠ¤í…œ
- [ ] íƒ€ì… ê²€ì‚¬ ë° ì¶”ë¡ 
- [ ] ì˜ì¡´ì„± ë¶„ì„
- [ ] ëª¨ë²” ì‚¬ë¡€ ê²€ì¦

#### SubTask 5.4.4: DSL IDE ì§€ì› ë° ë„êµ¬

**ë‹´ë‹¹ì**: ë„êµ¬ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dsl/language-server.ts
import {
  createConnection,
  TextDocuments,
  ProposedFeatures,
  InitializeParams,
  CompletionItem,
  CompletionItemKind,
  TextDocumentPositionParams,
  Hover,
  Definition,
} from "vscode-languageserver/node";

export class TWDSLLanguageServer {
  private connection = createConnection(ProposedFeatures.all);
  private documents = new TextDocuments(TextDocument);
  private validator = new DSLValidator();
  private completionProvider = new CompletionProvider();
  private hoverProvider = new HoverProvider();

  constructor() {
    this.setupHandlers();
  }

  private setupHandlers(): void {
    // ì´ˆê¸°í™”
    this.connection.onInitialize((params: InitializeParams) => {
      return {
        capabilities: {
          textDocumentSync: TextDocumentSyncKind.Incremental,
          completionProvider: {
            resolveProvider: true,
            triggerCharacters: [".", ":"],
          },
          hoverProvider: true,
          definitionProvider: true,
          documentFormattingProvider: true,
          codeActionProvider: true,
          signatureHelpProvider: {
            triggerCharacters: ["(", ","],
          },
        },
      };
    });

    // ìë™ ì™„ì„±
    this.connection.onCompletion(
      async (params: TextDocumentPositionParams): Promise<CompletionItem[]> => {
        const document = this.documents.get(params.textDocument.uri);
        if (!document) return [];

        return this.completionProvider.provideCompletions(
          document,
          params.position
        );
      }
    );

    // í˜¸ë²„ ì •ë³´
    this.connection.onHover(
      async (params: TextDocumentPositionParams): Promise<Hover | null> => {
        const document = this.documents.get(params.textDocument.uri);
        if (!document) return null;

        return this.hoverProvider.provideHover(document, params.position);
      }
    );

    // ë¬¸ì„œ ê²€ì¦
    this.documents.onDidChangeContent(async (change) => {
      await this.validateDocument(change.document);
    });
  }

  private async validateDocument(document: TextDocument): Promise<void> {
    const text = document.getText();
    const result = await this.validator.validate(text);

    // ì§„ë‹¨ ì •ë³´ ìƒì„±
    const diagnostics: Diagnostic[] = [];

    // ì˜¤ë¥˜
    for (const error of result.errors) {
      diagnostics.push({
        severity: DiagnosticSeverity.Error,
        range: {
          start: { line: error.line - 1, character: error.column - 1 },
          end: { line: error.line - 1, character: error.column },
        },
        message: error.message,
        source: "twdsl",
      });
    }

    // ê²½ê³ 
    for (const warning of result.warnings) {
      diagnostics.push({
        severity: DiagnosticSeverity.Warning,
        range: {
          start: { line: warning.line - 1, character: warning.column - 1 },
          end: { line: warning.line - 1, character: warning.column },
        },
        message: warning.message,
        source: "twdsl",
      });
    }

    // íŒíŠ¸
    for (const hint of result.hints) {
      diagnostics.push({
        severity: DiagnosticSeverity.Hint,
        range: {
          start: { line: hint.line - 1, character: hint.column - 1 },
          end: { line: hint.line - 1, character: hint.column },
        },
        message: hint.message,
        source: "twdsl",
      });
    }

    this.connection.sendDiagnostics({ uri: document.uri, diagnostics });
  }

  start(): void {
    this.documents.listen(this.connection);
    this.connection.listen();
  }
}

// ìë™ ì™„ì„± ì œê³µì
export class CompletionProvider {
  private keywords = TWDSLGrammar.keywords;
  private builtins = TWDSLGrammar.builtins;
  private agentTypes = [
    "NLInputAgent",
    "UISelectionAgent",
    "ParserAgent",
    "ComponentDecisionAgent",
    "MatchRateAgent",
    "SearchAgent",
    "GenerationAgent",
    "AssemblyAgent",
    "DownloadAgent",
  ];

  async provideCompletions(
    document: TextDocument,
    position: Position
  ): Promise<CompletionItem[]> {
    const context = this.getCompletionContext(document, position);
    const completions: CompletionItem[] = [];

    // ì»¨í…ìŠ¤íŠ¸ë³„ ì™„ì„± í•­ëª©
    switch (context.type) {
      case "workflow_body":
        completions.push(...this.getWorkflowBodyCompletions());
        break;

      case "task_body":
        completions.push(...this.getTaskBodyCompletions());
        break;

      case "agent_value":
        completions.push(...this.getAgentCompletions());
        break;

      case "expression":
        completions.push(...this.getExpressionCompletions(context));
        break;

      default:
        completions.push(...this.getGeneralCompletions());
    }

    return completions;
  }

  private getWorkflowBodyCompletions(): CompletionItem[] {
    return [
      {
        label: "task",
        kind: CompletionItemKind.Keyword,
        insertText: 'task ${1:taskName} {\n  agent: "${2:agentType}"\n  $0\n}',
        insertTextFormat: InsertTextFormat.Snippet,
        documentation: "Define a new task",
      },
      {
        label: "parallel",
        kind: CompletionItemKind.Keyword,
        insertText: "parallel {\n  $0\n}",
        insertTextFormat: InsertTextFormat.Snippet,
        documentation: "Execute tasks in parallel",
      },
      {
        label: "sequence",
        kind: CompletionItemKind.Keyword,
        insertText: "sequence {\n  $0\n}",
        insertTextFormat: InsertTextFormat.Snippet,
        documentation: "Execute tasks in sequence",
      },
      {
        label: "if",
        kind: CompletionItemKind.Keyword,
        insertText: "if (${1:condition}) {\n  $0\n}",
        insertTextFormat: InsertTextFormat.Snippet,
        documentation: "Conditional execution",
      },
    ];
  }

  private getAgentCompletions(): CompletionItem[] {
    return this.agentTypes.map((agent) => ({
      label: agent,
      kind: CompletionItemKind.Value,
      detail: `Agent type: ${agent}`,
      documentation: this.getAgentDocumentation(agent),
    }));
  }
}

// í¬ë§¤í„°
export class DSLFormatter {
  private indentSize: number = 2;
  private indentChar: string = " ";

  format(source: string): string {
    const parser = new DSLParser(source);
    const ast = parser.parse();

    return this.formatAST(ast, 0);
  }

  private formatAST(node: ASTNode, indent: number): string {
    const indentStr = this.indentChar.repeat(indent * this.indentSize);

    switch (node.type) {
      case "workflow":
        return this.formatWorkflow(node as WorkflowAST, indent);

      case "task":
        return this.formatTask(node as TaskAST, indent);

      case "parallel":
        return this.formatParallel(node as ParallelAST, indent);

      // ... ê¸°íƒ€ ë…¸ë“œ íƒ€ì…

      default:
        return "";
    }
  }

  private formatWorkflow(workflow: WorkflowAST, indent: number): string {
    const ind = this.getIndent(indent);
    let result = `workflow ${workflow.name} {\n`;

    result += `${ind}  version: "${workflow.version}"\n`;

    if (workflow.description) {
      result += `${ind}  description: "${workflow.description}"\n`;
    }

    result += "\n";
    result += this.formatInputOutput("input", workflow.input, indent + 1);
    result += "\n";
    result += this.formatInputOutput("output", workflow.output, indent + 1);
    result += "\n";

    for (const stmt of workflow.body) {
      result += this.formatAST(stmt, indent + 1) + "\n";
    }

    result += `${ind}}`;
    return result;
  }
}

// ë””ë²„ê±° ì§€ì›
export class DSLDebugAdapter {
  private breakpoints: Map<string, Breakpoint[]> = new Map();
  private runtime: DSLRuntime;

  async attach(workflowId: string): Promise<void> {
    this.runtime = await this.getRuntimeInstance(workflowId);

    this.runtime.on("taskStart", this.handleTaskStart.bind(this));
    this.runtime.on("taskComplete", this.handleTaskComplete.bind(this));
    this.runtime.on("breakpoint", this.handleBreakpoint.bind(this));
  }

  setBreakpoint(file: string, line: number): Breakpoint {
    const bp = new Breakpoint(file, line);

    if (!this.breakpoints.has(file)) {
      this.breakpoints.set(file, []);
    }

    this.breakpoints.get(file)!.push(bp);
    return bp;
  }

  async stepOver(): Promise<void> {
    await this.runtime.stepOver();
  }

  async stepInto(): Promise<void> {
    await this.runtime.stepInto();
  }

  async continue(): Promise<void> {
    await this.runtime.continue();
  }

  async evaluate(expression: string): Promise<any> {
    return this.runtime.evaluate(expression);
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] Language Server Protocol êµ¬í˜„
- [ ] ìë™ ì™„ì„± ê¸°ëŠ¥
- [ ] êµ¬ë¬¸ ê°•ì¡° ë° í¬ë§¤íŒ…
- [ ] ë””ë²„ê¹… ì§€ì›

### Task 5.5: ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ìˆ˜ì •

#### SubTask 5.5.1: ëŸ°íƒ€ì„ ì›Œí¬í”Œë¡œìš° ë¹Œë”

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dynamic/workflow_builder.ts
export class DynamicWorkflowBuilder {
  private workflow: WorkflowDefinition;
  private validators: WorkflowValidator[] = [];
  private optimizers: WorkflowOptimizer[] = [];

  constructor(name: string, version: string = "1.0.0") {
    this.workflow = {
      id: this.generateId(name),
      name,
      version,
      description: "",
      input_schema: {},
      output_schema: {},
      tasks: [],
      timeout_seconds: 3600,
      max_retries: 1,
      error_handlers: {},
      tags: [],
      metadata: {},
    };
  }

  // í”Œë£¨ì–¸íŠ¸ API
  description(desc: string): this {
    this.workflow.description = desc;
    return this;
  }

  input(schema: Record<string, any>): this {
    this.workflow.input_schema = schema;
    return this;
  }

  output(schema: Record<string, any>): this {
    this.workflow.output_schema = schema;
    return this;
  }

  timeout(seconds: number): this {
    this.workflow.timeout_seconds = seconds;
    return this;
  }

  // íƒœìŠ¤í¬ ì¶”ê°€
  addTask(task: WorkflowTask | TaskBuilder): this {
    if (task instanceof TaskBuilder) {
      this.workflow.tasks.push(task.build());
    } else {
      this.workflow.tasks.push(task);
    }
    return this;
  }

  // ë³‘ë ¬ ë¸”ë¡ ì¶”ê°€
  parallel(configure: (builder: ParallelBuilder) => void): this {
    const parallelBuilder = new ParallelBuilder();
    configure(parallelBuilder);
    this.workflow.tasks.push(parallelBuilder.build());
    return this;
  }

  // ì¡°ê±´ë¶€ ë¸”ë¡ ì¶”ê°€
  conditional(
    condition: string,
    configure: (builder: ConditionalBuilder) => void
  ): this {
    const conditionalBuilder = new ConditionalBuilder(condition);
    configure(conditionalBuilder);
    this.workflow.tasks.push(conditionalBuilder.build());
    return this;
  }

  // ë°˜ë³µ ë¸”ë¡ ì¶”ê°€
  foreach(
    iterator: string,
    variable: string,
    configure: (builder: LoopBuilder) => void
  ): this {
    const loopBuilder = new LoopBuilder("foreach", iterator, variable);
    configure(loopBuilder);
    this.workflow.tasks.push(loopBuilder.build());
    return this;
  }

  // ê²€ì¦ ë° ë¹Œë“œ
  async build(): Promise<WorkflowDefinition> {
    // ê²€ì¦
    for (const validator of this.validators) {
      const result = await validator.validate(this.workflow);
      if (!result.valid) {
        throw new WorkflowValidationError(result.errors);
      }
    }

    // ìµœì í™”
    let optimized = this.workflow;
    for (const optimizer of this.optimizers) {
      optimized = await optimizer.optimize(optimized);
    }

    return optimized;
  }

  // ê²€ì¦ê¸° ì¶”ê°€
  withValidator(validator: WorkflowValidator): this {
    this.validators.push(validator);
    return this;
  }

  // ìµœì í™”ê¸° ì¶”ê°€
  withOptimizer(optimizer: WorkflowOptimizer): this {
    this.optimizers.push(optimizer);
    return this;
  }
}

// íƒœìŠ¤í¬ ë¹Œë”
export class TaskBuilder {
  private task: Partial<WorkflowTask>;

  constructor(id: string, name: string, agentType: string) {
    this.task = {
      id,
      name,
      agent_type: agentType,
      input_mapping: {},
      output_mapping: {},
      dependencies: [],
      timeout_seconds: 300,
      retry_policy: new RetryPolicy(),
      conditions: [],
    };
  }

  input(mapping: Record<string, string>): this {
    this.task.input_mapping = mapping;
    return this;
  }

  output(mapping: Record<string, string>): this {
    this.task.output_mapping = mapping;
    return this;
  }

  dependsOn(...taskIds: string[]): this {
    this.task.dependencies = taskIds.map((id) => ({
      task_id: id,
      wait_for_completion: true,
    }));
    return this;
  }

  conditionalDependsOn(taskId: string, condition: string): this {
    this.task.dependencies!.push({
      task_id: taskId,
      condition,
      wait_for_completion: true,
    });
    return this;
  }

  timeout(seconds: number): this {
    this.task.timeout_seconds = seconds;
    return this;
  }

  retry(policy: Partial<RetryPolicy>): this {
    this.task.retry_policy = { ...new RetryPolicy(), ...policy };
    return this;
  }

  condition(expr: string): this {
    this.task.conditions!.push(expr);
    return this;
  }

  onError(handler: string): this {
    this.task.error_handler = handler;
    return this;
  }

  build(): WorkflowTask {
    if (!this.task.id || !this.task.name || !this.task.agent_type) {
      throw new Error("Task requires id, name, and agent_type");
    }
    return this.task as WorkflowTask;
  }
}

// ë³‘ë ¬ ë¹Œë”
export class ParallelBuilder {
  private tasks: (WorkflowTask | ConditionalBlock)[] = [];
  private maxConcurrency?: number;
  private failFast: boolean = true;

  task(configure: (builder: TaskBuilder) => TaskBuilder): this {
    const taskBuilder = new TaskBuilder(`task_${Date.now()}`, "unnamed", "");
    const configured = configure(taskBuilder);
    this.tasks.push(configured.build());
    return this;
  }

  conditional(
    condition: string,
    configure: (builder: ConditionalBuilder) => void
  ): this {
    const conditionalBuilder = new ConditionalBuilder(condition);
    configure(conditionalBuilder);
    this.tasks.push(conditionalBuilder.build());
    return this;
  }

  concurrency(max: number): this {
    this.maxConcurrency = max;
    return this;
  }

  continueOnFailure(): this {
    this.failFast = false;
    return this;
  }

  build(): ParallelBlock {
    return {
      id: `parallel_${Date.now()}`,
      tasks: this.tasks,
      max_concurrency: this.maxConcurrency,
      fail_fast: this.failFast,
    };
  }
}

// ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„± ì˜ˆì œ
export class WorkflowFactory {
  static createDataProcessingWorkflow(
    config: DataProcessingConfig
  ): DynamicWorkflowBuilder {
    const builder = new DynamicWorkflowBuilder("data-processing", "1.0.0")
      .description("Dynamic data processing workflow")
      .input({
        source: { type: "string", required: true },
        format: { type: "string", enum: ["csv", "json", "xml"] },
        transformations: { type: "array", items: { type: "string" } },
      })
      .output({
        processed_data: { type: "object" },
        statistics: { type: "object" },
      });

    // ë°ì´í„° ì†ŒìŠ¤ì— ë”°ë¥¸ ë™ì  íƒœìŠ¤í¬ ì¶”ê°€
    if (config.source.type === "database") {
      builder.addTask(
        new TaskBuilder("fetch_db", "Fetch from Database", "DataFetchAgent")
          .input({
            connection_string: "input.source",
            query: `"${config.source.query}"`,
          })
          .output({
            raw_data: "context.raw_data",
          })
      );
    } else if (config.source.type === "api") {
      builder.addTask(
        new TaskBuilder("fetch_api", "Fetch from API", "APIFetchAgent")
          .input({
            url: "input.source",
            headers: JSON.stringify(config.source.headers || {}),
          })
          .output({
            raw_data: "context.raw_data",
          })
      );
    }

    // ë³€í™˜ íƒœìŠ¤í¬ ë™ì  ì¶”ê°€
    config.transformations.forEach((transform, index) => {
      const prevTaskId =
        index === 0
          ? config.source.type === "database"
            ? "fetch_db"
            : "fetch_api"
          : `transform_${index - 1}`;

      builder.addTask(
        new TaskBuilder(
          `transform_${index}`,
          `Transform: ${transform.type}`,
          "DataTransformAgent"
        )
          .dependsOn(prevTaskId)
          .input({
            data:
              index === 0
                ? "context.raw_data"
                : `transform_${index - 1}.result`,
            transformation: JSON.stringify(transform),
          })
          .output({
            result: `context.transform_${index}_result`,
          })
      );
    });

    // ìµœì¢… ì§‘ê³„
    builder.addTask(
      new TaskBuilder("aggregate", "Aggregate Results", "AggregationAgent")
        .dependsOn(`transform_${config.transformations.length - 1}`)
        .input({
          data: `transform_${config.transformations.length - 1}.result`,
        })
        .output({
          processed_data: "output.processed_data",
          statistics: "output.statistics",
        })
    );

    return builder;
  }
}

// ëŸ°íƒ€ì„ ì›Œí¬í”Œë¡œìš° ìˆ˜ì •
export class RuntimeWorkflowModifier {
  constructor(
    private orchestrator: CentralOrchestrator,
    private validator: WorkflowValidator
  ) {}

  async modifyRunningWorkflow(
    executionId: string,
    modifications: WorkflowModification[]
  ): Promise<ModificationResult> {
    // í˜„ì¬ ì‹¤í–‰ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
    const execution = await this.orchestrator.getExecution(executionId);

    if (!execution) {
      throw new Error(`Workflow execution ${executionId} not found`);
    }

    if (execution.state !== WorkflowState.RUNNING) {
      throw new Error(`Workflow is not running: ${execution.state}`);
    }

    // ìˆ˜ì • ê°€ëŠ¥ì„± ê²€ì¦
    const canModify = await this.validateModifications(
      execution,
      modifications
    );

    if (!canModify.valid) {
      return {
        success: false,
        errors: canModify.errors,
      };
    }

    // ìˆ˜ì • ì ìš©
    const results = [];
    for (const mod of modifications) {
      const result = await this.applyModification(execution, mod);
      results.push(result);
    }

    return {
      success: true,
      results,
    };
  }

  private async applyModification(
    execution: WorkflowExecution,
    modification: WorkflowModification
  ): Promise<any> {
    switch (modification.type) {
      case "add_task":
        return this.addTaskToRunning(execution, modification);

      case "skip_task":
        return this.skipTask(execution, modification);

      case "modify_timeout":
        return this.modifyTimeout(execution, modification);

      case "inject_data":
        return this.injectData(execution, modification);

      default:
        throw new Error(`Unknown modification type: ${modification.type}`);
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í”Œë£¨ì–¸íŠ¸ API ì„¤ê³„
- [ ] ë™ì  íƒœìŠ¤í¬ ìƒì„±
- [ ] ëŸ°íƒ€ì„ ìˆ˜ì • ì§€ì›
- [ ] ê²€ì¦ ë° ìµœì í™”

#### SubTask 5.5.2: ì›Œí¬í”Œë¡œìš° ìˆ˜ì • API

**ë‹´ë‹¹ì**: API ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dynamic/modification_api.ts
import { Router } from "express";
import { body, param, validationResult } from "express-validator";

export class WorkflowModificationAPI {
  private router: Router;
  private modificationService: WorkflowModificationService;
  private authMiddleware: AuthMiddleware;

  constructor(orchestrator: CentralOrchestrator) {
    this.router = Router();
    this.modificationService = new WorkflowModificationService(orchestrator);
    this.authMiddleware = new AuthMiddleware();
    this.setupRoutes();
  }

  private setupRoutes(): void {
    // ì‹¤í–‰ ì¤‘ì¸ ì›Œí¬í”Œë¡œìš° ìˆ˜ì •
    this.router.patch(
      "/workflows/:workflowId/executions/:executionId",
      this.authMiddleware.requirePermission("workflow:modify"),
      [
        param("workflowId").isString(),
        param("executionId").isUUID(),
        body("modifications").isArray(),
        body("modifications.*.type").isIn([
          "add_task",
          "remove_task",
          "skip_task",
          "modify_task",
          "inject_data",
          "modify_timeout",
        ]),
      ],
      this.modifyExecution.bind(this)
    );

    // íƒœìŠ¤í¬ ì¶”ê°€
    this.router.post(
      "/workflows/:workflowId/executions/:executionId/tasks",
      this.authMiddleware.requirePermission("workflow:modify"),
      [
        param("executionId").isUUID(),
        body("task").isObject(),
        body("position").optional().isString(),
      ],
      this.addTask.bind(this)
    );

    // íƒœìŠ¤í¬ ìŠ¤í‚µ
    this.router.post(
      "/workflows/:workflowId/executions/:executionId/tasks/:taskId/skip",
      this.authMiddleware.requirePermission("workflow:modify"),
      [
        param("executionId").isUUID(),
        param("taskId").isString(),
        body("reason").optional().isString(),
      ],
      this.skipTask.bind(this)
    );

    // ë°ì´í„° ì£¼ì…
    this.router.post(
      "/workflows/:workflowId/executions/:executionId/data",
      this.authMiddleware.requirePermission("workflow:modify"),
      [
        param("executionId").isUUID(),
        body("path").isString(),
        body("value").exists(),
      ],
      this.injectData.bind(this)
    );

    // ì¡°ê±´ë¶€ ë¶„ê¸° ê°•ì œ
    this.router.post(
      "/workflows/:workflowId/executions/:executionId/force-branch",
      this.authMiddleware.requirePermission("workflow:modify"),
      [
        param("executionId").isUUID(),
        body("branchId").isString(),
        body("condition").isString(),
      ],
      this.forceBranch.bind(this)
    );
  }

  private async modifyExecution(req: Request, res: Response): Promise<void> {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { executionId } = req.params;
    const { modifications } = req.body;

    try {
      // ìˆ˜ì • ê¶Œí•œ í™•ì¸
      const canModify = await this.checkModificationPermissions(
        req.user,
        executionId
      );

      if (!canModify) {
        return res.status(403).json({
          error: "Insufficient permissions to modify workflow",
        });
      }

      // ìˆ˜ì • ì‚¬í•­ ê²€ì¦
      const validation = await this.modificationService.validateModifications(
        executionId,
        modifications
      );

      if (!validation.valid) {
        return res.status(400).json({
          error: "Invalid modifications",
          details: validation.errors,
        });
      }

      // ìˆ˜ì • ì ìš©
      const result = await this.modificationService.applyModifications(
        executionId,
        modifications
      );

      // ê°ì‚¬ ë¡œê·¸
      await this.auditLog.log({
        action: "workflow_modified",
        executionId,
        userId: req.user.id,
        modifications,
        result,
      });

      res.json({
        success: true,
        result,
      });
    } catch (error) {
      logger.error("Failed to modify workflow", { error, executionId });
      res.status(500).json({
        error: "Failed to modify workflow",
        message: error.message,
      });
    }
  }

  private async addTask(req: Request, res: Response): Promise<void> {
    const { executionId } = req.params;
    const { task, position } = req.body;

    try {
      // íƒœìŠ¤í¬ ë¹Œë”ë¡œ ê²€ì¦
      const taskBuilder = new TaskBuilder(
        task.id || `dynamic_${Date.now()}`,
        task.name,
        task.agent_type
      );

      // íƒœìŠ¤í¬ êµ¬ì„±
      if (task.input) taskBuilder.input(task.input);
      if (task.output) taskBuilder.output(task.output);
      if (task.dependencies) taskBuilder.dependsOn(...task.dependencies);
      if (task.timeout) taskBuilder.timeout(task.timeout);

      const builtTask = taskBuilder.build();

      // ì¶”ê°€ ìœ„ì¹˜ ê²°ì •
      const insertPosition = position || "end";

      // íƒœìŠ¤í¬ ì¶”ê°€
      const result = await this.modificationService.addTaskToExecution(
        executionId,
        builtTask,
        insertPosition
      );

      res.json({
        success: true,
        taskId: result.taskId,
        position: result.position,
      });
    } catch (error) {
      logger.error("Failed to add task", { error, executionId });
      res.status(500).json({
        error: "Failed to add task",
        message: error.message,
      });
    }
  }
}

// ì›Œí¬í”Œë¡œìš° ìˆ˜ì • ì„œë¹„ìŠ¤
export class WorkflowModificationService {
  private modificationQueue: Queue<ModificationRequest>;
  private modificationHandlers: Map<string, ModificationHandler>;

  constructor(private orchestrator: CentralOrchestrator) {
    this.modificationQueue = new Queue();
    this.registerHandlers();
    this.startModificationProcessor();
  }

  private registerHandlers(): void {
    this.modificationHandlers = new Map([
      ["add_task", new AddTaskHandler()],
      ["remove_task", new RemoveTaskHandler()],
      ["skip_task", new SkipTaskHandler()],
      ["modify_task", new ModifyTaskHandler()],
      ["inject_data", new InjectDataHandler()],
      ["modify_timeout", new ModifyTimeoutHandler()],
      ["force_branch", new ForceBranchHandler()],
    ]);
  }

  async validateModifications(
    executionId: string,
    modifications: WorkflowModification[]
  ): Promise<ValidationResult> {
    const execution = await this.orchestrator.getExecution(executionId);

    if (!execution) {
      return {
        valid: false,
        errors: ["Execution not found"],
      };
    }

    const errors: string[] = [];

    for (const mod of modifications) {
      const handler = this.modificationHandlers.get(mod.type);

      if (!handler) {
        errors.push(`Unknown modification type: ${mod.type}`);
        continue;
      }

      const validation = await handler.validate(execution, mod);
      if (!validation.valid) {
        errors.push(...validation.errors);
      }
    }

    return {
      valid: errors.length === 0,
      errors,
    };
  }

  async applyModifications(
    executionId: string,
    modifications: WorkflowModification[]
  ): Promise<ModificationResult[]> {
    const results: ModificationResult[] = [];

    // ìˆ˜ì • ìš”ì²­ì„ íì— ì¶”ê°€
    for (const mod of modifications) {
      const request: ModificationRequest = {
        id: uuid(),
        executionId,
        modification: mod,
        timestamp: new Date(),
        status: "pending",
      };

      await this.modificationQueue.enqueue(request);

      // ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬ ëŒ€ê¸°
      const result = await this.waitForModification(request.id);
      results.push(result);
    }

    return results;
  }

  private async processModification(
    request: ModificationRequest
  ): Promise<ModificationResult> {
    const handler = this.modificationHandlers.get(request.modification.type);

    if (!handler) {
      return {
        requestId: request.id,
        success: false,
        error: `Unknown modification type: ${request.modification.type}`,
      };
    }

    try {
      // ì‹¤í–‰ ìƒíƒœ ì ê¸ˆ
      await this.orchestrator.lockExecution(request.executionId);

      // ìˆ˜ì • ì ìš©
      const result = await handler.apply(
        this.orchestrator,
        request.executionId,
        request.modification
      );

      // ì´ë²¤íŠ¸ ë°œí–‰
      await this.orchestrator.eventBus.publish({
        event_type: "workflow.modified",
        workflow_id: request.executionId,
        timestamp: new Date(),
        data: {
          modification: request.modification,
          result,
        },
      });

      return {
        requestId: request.id,
        success: true,
        result,
      };
    } catch (error) {
      return {
        requestId: request.id,
        success: false,
        error: error.message,
      };
    } finally {
      // ì ê¸ˆ í•´ì œ
      await this.orchestrator.unlockExecution(request.executionId);
    }
  }
}

// ìˆ˜ì • í•¸ë“¤ëŸ¬ ì¸í„°í˜ì´ìŠ¤
abstract class ModificationHandler {
  abstract validate(
    execution: WorkflowExecution,
    modification: WorkflowModification
  ): Promise<ValidationResult>;

  abstract apply(
    orchestrator: CentralOrchestrator,
    executionId: string,
    modification: WorkflowModification
  ): Promise<any>;
}

// íƒœìŠ¤í¬ ì¶”ê°€ í•¸ë“¤ëŸ¬
class AddTaskHandler extends ModificationHandler {
  async validate(
    execution: WorkflowExecution,
    modification: WorkflowModification
  ): Promise<ValidationResult> {
    const { task, position } = modification.data;

    // íƒœìŠ¤í¬ ê²€ì¦
    if (!task.agent_type) {
      return {
        valid: false,
        errors: ["Task must specify agent_type"],
      };
    }

    // ìœ„ì¹˜ ê²€ì¦
    if (position && position !== "end") {
      const targetTask = execution.tasks[position];
      if (!targetTask) {
        return {
          valid: false,
          errors: [`Invalid position: ${position}`],
        };
      }

      // ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜ ì™„ë£Œëœ íƒœìŠ¤í¬ ë’¤ì—ëŠ” ì¶”ê°€ ë¶ˆê°€
      if (targetTask.status !== "pending") {
        return {
          valid: false,
          errors: ["Cannot add task after running/completed task"],
        };
      }
    }

    return { valid: true, errors: [] };
  }

  async apply(
    orchestrator: CentralOrchestrator,
    executionId: string,
    modification: WorkflowModification
  ): Promise<any> {
    const { task, position } = modification.data;

    // íƒœìŠ¤í¬ ìƒì„±
    const newTask = new AgentTask({
      id: task.id || `dynamic_${Date.now()}`,
      ...task,
      workflow_id: executionId,
      status: "pending",
      created_at: new Date(),
    });

    // ì‹¤í–‰ì— ì¶”ê°€
    await orchestrator.addTaskToExecution(executionId, newTask, position);

    return {
      taskId: newTask.id,
      position: position || "end",
    };
  }
}

// ë™ì  ì›Œí¬í”Œë¡œìš° ë¹Œë” UI ì§€ì›
export class WorkflowBuilderUISupport {
  async getAvailableAgents(): Promise<AgentInfo[]> {
    return this.orchestrator.registry.getAllAgents();
  }

  async getTaskTemplates(): Promise<TaskTemplate[]> {
    return [
      {
        id: "data_fetch",
        name: "Data Fetch",
        description: "Fetch data from various sources",
        agent_type: "DataFetchAgent",
        default_config: {
          timeout: 300,
          retry: 2,
        },
      },
      {
        id: "data_transform",
        name: "Data Transform",
        description: "Transform data using various operations",
        agent_type: "DataTransformAgent",
        default_config: {
          timeout: 600,
          retry: 1,
        },
      },
      // ... ë” ë§ì€ í…œí”Œë¦¿
    ];
  }

  async validateWorkflowDraft(draft: WorkflowDraft): Promise<ValidationResult> {
    const builder = new DynamicWorkflowBuilder(draft.name, draft.version);

    // ë“œë˜í”„íŠ¸ë¥¼ ë¹Œë”ë¡œ ë³€í™˜
    builder
      .description(draft.description)
      .input(draft.input_schema)
      .output(draft.output_schema);

    for (const task of draft.tasks) {
      builder.addTask(task);
    }

    // ê²€ì¦
    try {
      await builder.build();
      return { valid: true, errors: [] };
    } catch (error) {
      return {
        valid: false,
        errors: [error.message],
      };
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] RESTful API ì„¤ê³„
- [ ] ìˆ˜ì • ê²€ì¦ ë¡œì§
- [ ] ê¶Œí•œ ê´€ë¦¬
- [ ] ì‹¤ì‹œê°„ ìˆ˜ì • ì§€ì›

#### SubTask 5.5.3: ë™ì  ë¶„ê¸° ë° ì¡°ê±´ë¶€ ì‹¤í–‰

**ë‹´ë‹¹ì**: ì›Œí¬í”Œë¡œìš° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dynamic/conditional_execution.ts
export class ConditionalExecutor {
  private expressionEvaluator: ExpressionEvaluator;
  private branchPredictor: BranchPredictor;

  constructor() {
    this.expressionEvaluator = new ExpressionEvaluator();
    this.branchPredictor = new BranchPredictor();
  }

  async evaluateCondition(
    condition: string,
    context: ExecutionContext
  ): Promise<boolean> {
    try {
      // í‘œí˜„ì‹ íŒŒì‹±
      const expression = this.expressionEvaluator.parse(condition);

      // ì»¨í…ìŠ¤íŠ¸ ê°’ í•´ê²°
      const resolvedContext = await this.resolveContextValues(
        expression,
        context
      );

      // í‰ê°€
      const result = await this.expressionEvaluator.evaluate(
        expression,
        resolvedContext
      );

      // ê²°ê³¼ íƒ€ì… ê²€ì¦
      if (typeof result !== "boolean") {
        throw new Error(
          `Condition must evaluate to boolean, got ${typeof result}`
        );
      }

      return result;
    } catch (error) {
      logger.error("Failed to evaluate condition", {
        condition,
        error: error.message,
      });
      throw new ConditionEvaluationError(
        `Failed to evaluate condition: ${error.message}`
      );
    }
  }

  async executeDynamicBranch(
    branchConfig: DynamicBranchConfig,
    context: ExecutionContext
  ): Promise<BranchExecutionResult> {
    const startTime = Date.now();
    const results: TaskExecutionResult[] = [];

    try {
      // ë¶„ê¸° ì˜ˆì¸¡
      const prediction = await this.branchPredictor.predict(
        branchConfig,
        context
      );

      // ì˜ˆì¸¡ ê¸°ë°˜ ë¦¬ì†ŒìŠ¤ ì‚¬ì „ í• ë‹¹
      if (prediction.confidence > 0.8) {
        await this.preAllocateResources(prediction.predictedBranch);
      }

      // ì¡°ê±´ í‰ê°€
      const branchDecision = await this.decideBranch(branchConfig, context);

      // ì„ íƒëœ ë¶„ê¸° ì‹¤í–‰
      const selectedBranch = branchConfig.branches[branchDecision.branchIndex];

      logger.info("Executing dynamic branch", {
        branchId: selectedBranch.id,
        condition: branchDecision.condition,
        evaluated: branchDecision.evaluated,
      });

      // íƒœìŠ¤í¬ ì‹¤í–‰
      for (const task of selectedBranch.tasks) {
        const result = await this.executeTask(task, context);
        results.push(result);

        // ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ë°˜ì˜
        this.updateContext(context, task, result);
      }

      return {
        branchId: selectedBranch.id,
        executed: true,
        results,
        duration: Date.now() - startTime,
      };
    } catch (error) {
      return {
        branchId: null,
        executed: false,
        error: error.message,
        duration: Date.now() - startTime,
      };
    }
  }

  private async decideBranch(
    config: DynamicBranchConfig,
    context: ExecutionContext
  ): Promise<BranchDecision> {
    // switch ìŠ¤íƒ€ì¼ ë¶„ê¸°
    if (config.type === "switch") {
      const switchValue = await this.evaluateExpression(
        config.switchExpression!,
        context
      );

      for (let i = 0; i < config.branches.length; i++) {
        const branch = config.branches[i];

        if (branch.caseValue === switchValue) {
          return {
            branchIndex: i,
            condition: `${config.switchExpression} == ${branch.caseValue}`,
            evaluated: true,
          };
        }
      }

      // default ë¶„ê¸°
      const defaultIndex = config.branches.findIndex((b) => b.isDefault);
      if (defaultIndex >= 0) {
        return {
          branchIndex: defaultIndex,
          condition: "default",
          evaluated: true,
        };
      }
    } else {
      // if-else ìŠ¤íƒ€ì¼ ë¶„ê¸°
      for (let i = 0; i < config.branches.length; i++) {
        const branch = config.branches[i];

        if (!branch.condition) {
          // else ë¶„ê¸°
          return {
            branchIndex: i,
            condition: "else",
            evaluated: true,
          };
        }

        const conditionMet = await this.evaluateCondition(
          branch.condition,
          context
        );

        if (conditionMet) {
          return {
            branchIndex: i,
            condition: branch.condition,
            evaluated: conditionMet,
          };
        }
      }
    }

    throw new Error("No branch condition met");
  }
}

// ë™ì  ë°˜ë³µ ì‹¤í–‰
export class DynamicLoopExecutor {
  constructor(
    private taskExecutor: TaskExecutor,
    private conditionEvaluator: ConditionalExecutor
  ) {}

  async executeLoop(
    loopConfig: LoopConfig,
    context: ExecutionContext
  ): Promise<LoopExecutionResult> {
    const results: TaskExecutionResult[] = [];
    let iterations = 0;
    const maxIterations = loopConfig.maxIterations || 1000;

    try {
      if (loopConfig.type === "foreach") {
        // ForEach ë£¨í”„
        results.push(...(await this.executeForeach(loopConfig, context)));
      } else if (loopConfig.type === "while") {
        // While ë£¨í”„
        results.push(
          ...(await this.executeWhile(loopConfig, context, maxIterations))
        );
      } else if (loopConfig.type === "do-while") {
        // Do-While ë£¨í”„
        results.push(
          ...(await this.executeDoWhile(loopConfig, context, maxIterations))
        );
      } else if (loopConfig.type === "for") {
        // For ë£¨í”„
        results.push(...(await this.executeFor(loopConfig, context)));
      }

      return {
        completed: true,
        iterations: results.length,
        results,
      };
    } catch (error) {
      return {
        completed: false,
        iterations,
        results,
        error: error.message,
      };
    }
  }

  private async executeForeach(
    config: LoopConfig,
    context: ExecutionContext
  ): Promise<TaskExecutionResult[]> {
    const results: TaskExecutionResult[] = [];

    // ë°˜ë³µ ëŒ€ìƒ ê°€ì ¸ì˜¤ê¸°
    const iterable = await this.resolveIterable(config.iterator!, context);

    if (!Array.isArray(iterable)) {
      throw new Error(`Iterator must be an array, got ${typeof iterable}`);
    }

    // ë³‘ë ¬ ì‹¤í–‰ ì—¬ë¶€
    if (config.parallel) {
      const promises = iterable.map((item, index) =>
        this.executeLoopIteration(config, context, item, index)
      );

      const parallelResults = await Promise.allSettled(promises);

      for (const result of parallelResults) {
        if (result.status === "fulfilled") {
          results.push(...result.value);
        } else {
          logger.error("Parallel loop iteration failed", result.reason);
        }
      }
    } else {
      // ìˆœì°¨ ì‹¤í–‰
      for (let i = 0; i < iterable.length; i++) {
        const item = iterable[i];
        const iterationResults = await this.executeLoopIteration(
          config,
          context,
          item,
          i
        );
        results.push(...iterationResults);

        // early break ì¡°ê±´ í™•ì¸
        if (config.breakCondition) {
          const shouldBreak = await this.conditionEvaluator.evaluateCondition(
            config.breakCondition,
            context
          );
          if (shouldBreak) break;
        }
      }
    }

    return results;
  }

  private async executeLoopIteration(
    config: LoopConfig,
    baseContext: ExecutionContext,
    item: any,
    index: number
  ): Promise<TaskExecutionResult[]> {
    // ë°˜ë³µ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    const iterationContext = this.createIterationContext(
      baseContext,
      config.variable!,
      item,
      index
    );

    const results: TaskExecutionResult[] = [];

    for (const task of config.tasks) {
      const result = await this.taskExecutor.execute(task, iterationContext);
      results.push(result);

      // ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ë°˜ì˜
      this.updateIterationContext(iterationContext, task, result);
    }

    return results;
  }

  private createIterationContext(
    baseContext: ExecutionContext,
    variableName: string,
    item: any,
    index: number
  ): ExecutionContext {
    return {
      ...baseContext,
      loop: {
        ...baseContext.loop,
        [variableName]: item,
        [`${variableName}_index`]: index,
      },
    };
  }
}

// ë™ì  ì—ëŸ¬ ì²˜ë¦¬
export class DynamicErrorHandler {
  private errorPatterns: Map<string, ErrorPattern>;
  private recoveryStrategies: Map<string, RecoveryStrategy>;

  constructor() {
    this.errorPatterns = new Map();
    this.recoveryStrategies = new Map();
    this.registerDefaultPatterns();
  }

  async handleError(
    error: Error,
    task: WorkflowTask,
    context: ExecutionContext
  ): Promise<ErrorHandlingResult> {
    // ì—ëŸ¬ íŒ¨í„´ ë§¤ì¹­
    const pattern = this.matchErrorPattern(error);

    // ë³µêµ¬ ì „ëµ ì„ íƒ
    const strategy = this.selectRecoveryStrategy(pattern, task, context);

    // ì „ëµ ì‹¤í–‰
    return await this.executeRecoveryStrategy(strategy, error, task, context);
  }

  private matchErrorPattern(error: Error): ErrorPattern | null {
    for (const [name, pattern] of this.errorPatterns) {
      if (pattern.matches(error)) {
        return pattern;
      }
    }
    return null;
  }

  private selectRecoveryStrategy(
    pattern: ErrorPattern | null,
    task: WorkflowTask,
    context: ExecutionContext
  ): RecoveryStrategy {
    // íƒœìŠ¤í¬ë³„ ì—ëŸ¬ í•¸ë“¤ëŸ¬ í™•ì¸
    if (task.error_handler) {
      const customStrategy = this.recoveryStrategies.get(task.error_handler);
      if (customStrategy) return customStrategy;
    }

    // íŒ¨í„´ ê¸°ë°˜ ì „ëµ
    if (pattern && pattern.recoveryStrategy) {
      const patternStrategy = this.recoveryStrategies.get(
        pattern.recoveryStrategy
      );
      if (patternStrategy) return patternStrategy;
    }

    // ê¸°ë³¸ ì „ëµ
    return this.recoveryStrategies.get("default")!;
  }

  private async executeRecoveryStrategy(
    strategy: RecoveryStrategy,
    error: Error,
    task: WorkflowTask,
    context: ExecutionContext
  ): Promise<ErrorHandlingResult> {
    try {
      const result = await strategy.execute(error, task, context);

      if (result.recovered) {
        logger.info("Error recovered", {
          taskId: task.id,
          strategy: strategy.name,
          action: result.action,
        });
      }

      return result;
    } catch (recoveryError) {
      logger.error("Recovery strategy failed", {
        taskId: task.id,
        strategy: strategy.name,
        error: recoveryError.message,
      });

      return {
        recovered: false,
        action: "fail",
        error: recoveryError,
      };
    }
  }

  registerErrorPattern(name: string, pattern: ErrorPattern): void {
    this.errorPatterns.set(name, pattern);
  }

  registerRecoveryStrategy(name: string, strategy: RecoveryStrategy): void {
    this.recoveryStrategies.set(name, strategy);
  }

  private registerDefaultPatterns(): void {
    // ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜
    this.registerErrorPattern("network", {
      name: "network",
      matches: (error) => {
        return (
          error.message.includes("ECONNREFUSED") ||
          error.message.includes("ETIMEDOUT") ||
          error.message.includes("ENOTFOUND")
        );
      },
      recoveryStrategy: "retry_with_backoff",
    });

    // ë¦¬ì†ŒìŠ¤ ë¶€ì¡±
    this.registerErrorPattern("resource_exhausted", {
      name: "resource_exhausted",
      matches: (error) => {
        return (
          error.message.includes("insufficient resources") ||
          error.message.includes("quota exceeded")
        );
      },
      recoveryStrategy: "wait_and_retry",
    });

    // ê¶Œí•œ ì˜¤ë¥˜
    this.registerErrorPattern("permission_denied", {
      name: "permission_denied",
      matches: (error) => {
        return (
          error.message.includes("permission denied") ||
          error.message.includes("unauthorized")
        );
      },
      recoveryStrategy: "escalate",
    });
  }
}

// ë¶„ê¸° ì˜ˆì¸¡ê¸°
class BranchPredictor {
  private history: Map<string, BranchHistory>;

  constructor() {
    this.history = new Map();
  }

  async predict(
    config: DynamicBranchConfig,
    context: ExecutionContext
  ): Promise<BranchPrediction> {
    const historyKey = this.generateHistoryKey(config, context);
    const branchHistory = this.history.get(historyKey);

    if (!branchHistory || branchHistory.samples < 10) {
      // íˆìŠ¤í† ë¦¬ê°€ ë¶€ì¡±í•˜ë©´ ì˜ˆì¸¡í•˜ì§€ ì•ŠìŒ
      return {
        predictedBranch: null,
        confidence: 0,
      };
    }

    // ê°€ì¥ ìì£¼ ì‹¤í–‰ëœ ë¶„ê¸° ì°¾ê¸°
    const mostFrequent = branchHistory.getMostFrequentBranch();

    return {
      predictedBranch: mostFrequent.branchId,
      confidence: mostFrequent.frequency / branchHistory.samples,
    };
  }

  recordExecution(
    config: DynamicBranchConfig,
    context: ExecutionContext,
    executedBranch: string
  ): void {
    const historyKey = this.generateHistoryKey(config, context);

    if (!this.history.has(historyKey)) {
      this.history.set(historyKey, new BranchHistory());
    }

    this.history.get(historyKey)!.record(executedBranch);
  }

  private generateHistoryKey(
    config: DynamicBranchConfig,
    context: ExecutionContext
  ): string {
    // ì»¨í…ìŠ¤íŠ¸ì˜ ì£¼ìš” ê°’ë“¤ë¡œ í‚¤ ìƒì„±
    const relevantContext = this.extractRelevantContext(config, context);
    return `${config.id}:${JSON.stringify(relevantContext)}`;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ì¡°ê±´ë¶€ ì‹¤í–‰ ì—”ì§„
- [ ] ë™ì  ë°˜ë³µ ì²˜ë¦¬
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬
- [ ] ë¶„ê¸° ì˜ˆì¸¡ ìµœì í™”

#### SubTask 5.5.4: ì›Œí¬í”Œë¡œìš° ë²„ì „ ê´€ë¦¬

**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/dynamic/version_control.ts
export class WorkflowVersionControl {
  private versionStore: VersionStore;
  private diffEngine: DiffEngine;
  private mergeEngine: MergeEngine;

  constructor(storage: StorageBackend) {
    this.versionStore = new VersionStore(storage);
    this.diffEngine = new DiffEngine();
    this.mergeEngine = new MergeEngine();
  }

  async createVersion(
    workflow: WorkflowDefinition,
    metadata: VersionMetadata
  ): Promise<WorkflowVersion> {
    // ë²„ì „ ë²ˆí˜¸ ìƒì„±
    const versionNumber = await this.generateVersionNumber(
      workflow.id,
      metadata.versionType
    );

    // ì´ì „ ë²„ì „ê³¼ì˜ ì°¨ì´ ê³„ì‚°
    const previousVersion = await this.getLatestVersion(workflow.id);
    const diff = previousVersion
      ? await this.diffEngine.calculateDiff(
          previousVersion.definition,
          workflow
        )
      : null;

    // ë²„ì „ ìƒì„±
    const version: WorkflowVersion = {
      id: uuid(),
      workflowId: workflow.id,
      version: versionNumber,
      definition: workflow,
      diff,
      metadata: {
        ...metadata,
        createdAt: new Date(),
        createdBy: metadata.userId,
        changeLog: await this.generateChangeLog(diff),
      },
      status: "draft",
    };

    // ì €ì¥
    await this.versionStore.save(version);

    return version;
  }

  async promoteVersion(
    workflowId: string,
    versionId: string,
    environment: string
  ): Promise<PromotionResult> {
    const version = await this.versionStore.get(versionId);

    if (!version) {
      throw new Error(`Version ${versionId} not found`);
    }

    // ê²€ì¦
    const validation = await this.validatePromotion(version, environment);

    if (!validation.valid) {
      return {
        success: false,
        errors: validation.errors,
      };
    }

    // í”„ë¡œëª¨ì…˜ ì‹¤í–‰
    const promotion = await this.executePromotion(version, environment);

    // í”„ë¡œëª¨ì…˜ ê¸°ë¡
    await this.recordPromotion(version, environment, promotion);

    return promotion;
  }

  async compareVersions(
    versionId1: string,
    versionId2: string
  ): Promise<VersionComparison> {
    const [version1, version2] = await Promise.all([
      this.versionStore.get(versionId1),
      this.versionStore.get(versionId2),
    ]);

    if (!version1 || !version2) {
      throw new Error("One or both versions not found");
    }

    const diff = await this.diffEngine.calculateDiff(
      version1.definition,
      version2.definition
    );

    return {
      version1: {
        id: version1.id,
        version: version1.version,
        createdAt: version1.metadata.createdAt,
      },
      version2: {
        id: version2.id,
        version: version2.version,
        createdAt: version2.metadata.createdAt,
      },
      diff,
      summary: this.summarizeDiff(diff),
    };
  }

  async mergeVersions(
    baseVersionId: string,
    sourceVersionId: string,
    targetVersionId: string,
    strategy: MergeStrategy = "three-way"
  ): Promise<MergeResult> {
    const [base, source, target] = await Promise.all([
      this.versionStore.get(baseVersionId),
      this.versionStore.get(sourceVersionId),
      this.versionStore.get(targetVersionId),
    ]);

    if (!base || !source || !target) {
      throw new Error("One or more versions not found");
    }

    // ë³‘í•© ì‹¤í–‰
    const mergeResult = await this.mergeEngine.merge(
      base.definition,
      source.definition,
      target.definition,
      strategy
    );

    if (mergeResult.conflicts.length > 0) {
      return {
        success: false,
        conflicts: mergeResult.conflicts,
        merged: null,
      };
    }

    // ë³‘í•©ëœ ë²„ì „ ìƒì„±
    const mergedVersion = await this.createVersion(mergeResult.merged, {
      versionType: "merge",
      description: `Merge of ${source.version} into ${target.version}`,
      userId: "system",
      mergeInfo: {
        base: baseVersionId,
        source: sourceVersionId,
        target: targetVersionId,
      },
    });

    return {
      success: true,
      conflicts: [],
      merged: mergedVersion,
    };
  }

  async rollbackVersion(
    workflowId: string,
    targetVersionId: string,
    reason: string
  ): Promise<RollbackResult> {
    const currentVersion = await this.getCurrentVersion(workflowId);
    const targetVersion = await this.versionStore.get(targetVersionId);

    if (!targetVersion) {
      throw new Error(`Target version ${targetVersionId} not found`);
    }

    // ë¡¤ë°± ê°€ëŠ¥ì„± í™•ì¸
    const canRollback = await this.validateRollback(
      currentVersion,
      targetVersion
    );

    if (!canRollback.valid) {
      return {
        success: false,
        errors: canRollback.errors,
      };
    }

    // ë¡¤ë°± ì‹¤í–‰
    const rollbackVersion = await this.createVersion(targetVersion.definition, {
      versionType: "rollback",
      description: `Rollback to ${targetVersion.version}: ${reason}`,
      userId: "system",
      rollbackInfo: {
        from: currentVersion.id,
        to: targetVersionId,
        reason,
      },
    });

    // ì¦‰ì‹œ í™œì„±í™”
    await this.activateVersion(rollbackVersion.id);

    return {
      success: true,
      rollbackVersion,
    };
  }

  private async generateVersionNumber(
    workflowId: string,
    versionType: VersionType
  ): Promise<string> {
    const latestVersion = await this.getLatestVersion(workflowId);

    if (!latestVersion) {
      return "1.0.0";
    }

    const current = semver.parse(latestVersion.version);

    switch (versionType) {
      case "major":
        return semver.inc(current, "major");
      case "minor":
        return semver.inc(current, "minor");
      case "patch":
        return semver.inc(current, "patch");
      case "prerelease":
        return semver.inc(current, "prerelease", "beta");
      default:
        return semver.inc(current, "patch");
    }
  }
}

// ë²„ì „ ì°¨ì´ ì—”ì§„
export class DiffEngine {
  async calculateDiff(
    oldDef: WorkflowDefinition,
    newDef: WorkflowDefinition
  ): Promise<WorkflowDiff> {
    const diff: WorkflowDiff = {
      metadata: this.diffMetadata(oldDef, newDef),
      tasks: await this.diffTasks(oldDef.tasks, newDef.tasks),
      structure: this.diffStructure(oldDef, newDef),
      inputs: this.diffSchema(oldDef.input_schema, newDef.input_schema),
      outputs: this.diffSchema(oldDef.output_schema, newDef.output_schema),
    };

    return diff;
  }

  private async diffTasks(
    oldTasks: WorkflowTask[],
    newTasks: WorkflowTask[]
  ): Promise<TaskDiff[]> {
    const diffs: TaskDiff[] = [];
    const oldTaskMap = new Map(oldTasks.map((t) => [t.id, t]));
    const newTaskMap = new Map(newTasks.map((t) => [t.id, t]));

    // ì¶”ê°€ëœ íƒœìŠ¤í¬
    for (const [id, task] of newTaskMap) {
      if (!oldTaskMap.has(id)) {
        diffs.push({
          type: "added",
          taskId: id,
          task,
        });
      }
    }

    // ì‚­ì œëœ íƒœìŠ¤í¬
    for (const [id, task] of oldTaskMap) {
      if (!newTaskMap.has(id)) {
        diffs.push({
          type: "removed",
          taskId: id,
          task,
        });
      }
    }

    // ìˆ˜ì •ëœ íƒœìŠ¤í¬
    for (const [id, newTask] of newTaskMap) {
      const oldTask = oldTaskMap.get(id);
      if (oldTask) {
        const changes = this.compareTask(oldTask, newTask);
        if (changes.length > 0) {
          diffs.push({
            type: "modified",
            taskId: id,
            changes,
          });
        }
      }
    }

    return diffs;
  }

  private compareTask(
    oldTask: WorkflowTask,
    newTask: WorkflowTask
  ): TaskChange[] {
    const changes: TaskChange[] = [];

    // ì†ì„±ë³„ ë¹„êµ
    const properties = [
      "agent_type",
      "timeout_seconds",
      "retry_policy",
      "input_mapping",
      "output_mapping",
      "dependencies",
    ];

    for (const prop of properties) {
      if (!_.isEqual(oldTask[prop], newTask[prop])) {
        changes.push({
          property: prop,
          oldValue: oldTask[prop],
          newValue: newTask[prop],
        });
      }
    }

    return changes;
  }
}

// ë²„ì „ ë³‘í•© ì—”ì§„
export class MergeEngine {
  async merge(
    base: WorkflowDefinition,
    source: WorkflowDefinition,
    target: WorkflowDefinition,
    strategy: MergeStrategy
  ): Promise<MergeResult> {
    if (strategy === "three-way") {
      return this.threeWayMerge(base, source, target);
    } else if (strategy === "ours") {
      return { merged: target, conflicts: [] };
    } else if (strategy === "theirs") {
      return { merged: source, conflicts: [] };
    } else {
      throw new Error(`Unknown merge strategy: ${strategy}`);
    }
  }

  private async threeWayMerge(
    base: WorkflowDefinition,
    source: WorkflowDefinition,
    target: WorkflowDefinition
  ): Promise<MergeResult> {
    const conflicts: MergeConflict[] = [];
    const merged = _.cloneDeep(target);

    // ë©”íƒ€ë°ì´í„° ë³‘í•©
    const metadataConflicts = this.mergeMetadata(base, source, target, merged);
    conflicts.push(...metadataConflicts);

    // íƒœìŠ¤í¬ ë³‘í•©
    const taskConflicts = await this.mergeTasks(
      base.tasks,
      source.tasks,
      target.tasks,
      merged
    );
    conflicts.push(...taskConflicts);

    // ìŠ¤í‚¤ë§ˆ ë³‘í•©
    const schemaConflicts = this.mergeSchemas(base, source, target, merged);
    conflicts.push(...schemaConflicts);

    return {
      merged: conflicts.length === 0 ? merged : null,
      conflicts,
    };
  }

  private async mergeTasks(
    baseTasks: WorkflowTask[],
    sourceTasks: WorkflowTask[],
    targetTasks: WorkflowTask[],
    merged: WorkflowDefinition
  ): Promise<MergeConflict[]> {
    const conflicts: MergeConflict[] = [];
    const baseMap = new Map(baseTasks.map((t) => [t.id, t]));
    const sourceMap = new Map(sourceTasks.map((t) => [t.id, t]));
    const targetMap = new Map(targetTasks.map((t) => [t.id, t]));

    const allTaskIds = new Set([
      ...baseMap.keys(),
      ...sourceMap.keys(),
      ...targetMap.keys(),
    ]);

    const mergedTasks: WorkflowTask[] = [];

    for (const taskId of allTaskIds) {
      const baseTask = baseMap.get(taskId);
      const sourceTask = sourceMap.get(taskId);
      const targetTask = targetMap.get(taskId);

      if (!baseTask && sourceTask && !targetTask) {
        // Sourceì—ë§Œ ì¶”ê°€ë¨
        mergedTasks.push(sourceTask);
      } else if (!baseTask && !sourceTask && targetTask) {
        // Targetì—ë§Œ ì¶”ê°€ë¨
        mergedTasks.push(targetTask);
      } else if (baseTask && !sourceTask && targetTask) {
        // Sourceì—ì„œ ì‚­ì œë¨
        if (_.isEqual(baseTask, targetTask)) {
          // Targetì—ì„œ ë³€ê²½ ì—†ìŒ - ì‚­ì œ ì ìš©
          continue;
        } else {
          // ì¶©ëŒ: Sourceì—ì„œ ì‚­ì œ, Targetì—ì„œ ìˆ˜ì •
          conflicts.push({
            type: "delete-modify",
            path: `tasks.${taskId}`,
            base: baseTask,
            source: null,
            target: targetTask,
          });
        }
      } else if (baseTask && sourceTask && !targetTask) {
        // Targetì—ì„œ ì‚­ì œë¨
        if (_.isEqual(baseTask, sourceTask)) {
          // Sourceì—ì„œ ë³€ê²½ ì—†ìŒ - ì‚­ì œ ì ìš©
          continue;
        } else {
          // ì¶©ëŒ: Sourceì—ì„œ ìˆ˜ì •, Targetì—ì„œ ì‚­ì œ
          conflicts.push({
            type: "modify-delete",
            path: `tasks.${taskId}`,
            base: baseTask,
            source: sourceTask,
            target: null,
          });
        }
      } else if (baseTask && sourceTask && targetTask) {
        // ëª¨ë‘ì— ì¡´ì¬ - 3-way ë³‘í•©
        const mergedTask = await this.mergeTask(
          baseTask,
          sourceTask,
          targetTask
        );

        if (mergedTask.conflicts.length > 0) {
          conflicts.push(...mergedTask.conflicts);
        } else {
          mergedTasks.push(mergedTask.task);
        }
      }
    }

    if (conflicts.length === 0) {
      merged.tasks = mergedTasks;
    }

    return conflicts;
  }
}

// ë²„ì „ ì´ë ¥ ì¶”ì 
export class VersionHistory {
  private timeline: VersionTimeline;

  constructor(private versionStore: VersionStore) {
    this.timeline = new VersionTimeline();
  }

  async getHistory(
    workflowId: string,
    options: HistoryOptions = {}
  ): Promise<VersionHistoryEntry[]> {
    const versions = await this.versionStore.listVersions(workflowId, options);

    const history: VersionHistoryEntry[] = [];

    for (const version of versions) {
      const entry: VersionHistoryEntry = {
        version: version.version,
        createdAt: version.metadata.createdAt,
        createdBy: version.metadata.createdBy,
        type: version.metadata.versionType,
        description: version.metadata.description,
        changes: await this.summarizeChanges(version),
        promotions: await this.getPromotions(version.id),
      };

      history.push(entry);
    }

    return history;
  }

  async getVersionGraph(workflowId: string): Promise<VersionGraph> {
    const versions = await this.versionStore.listVersions(workflowId);
    const graph = new VersionGraph();

    // ë…¸ë“œ ì¶”ê°€
    for (const version of versions) {
      graph.addNode({
        id: version.id,
        version: version.version,
        metadata: version.metadata,
      });
    }

    // ì—£ì§€ ì¶”ê°€ (ë¶€ëª¨-ìì‹ ê´€ê³„)
    for (const version of versions) {
      if (version.metadata.parentVersion) {
        graph.addEdge(
          version.metadata.parentVersion,
          version.id,
          version.metadata.versionType
        );
      }
    }

    return graph;
  }

  async getBranches(workflowId: string): Promise<VersionBranch[]> {
    const graph = await this.getVersionGraph(workflowId);
    return graph.identifyBranches();
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] ë²„ì „ ìƒì„± ë° ê´€ë¦¬
- [ ] ë²„ì „ ë¹„êµ ë° ë³‘í•©
- [ ] í”„ë¡œëª¨ì…˜ ë° ë¡¤ë°±
- [ ] ë²„ì „ ì´ë ¥ ì¶”ì 

### Task 5.6: ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ë° ì¬ì‚¬ìš© ì‹œìŠ¤í…œ

#### SubTask 5.6.1: í…œí”Œë¦¿ ì €ì¥ì†Œ êµ¬ì¶•

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/templates/template_repository.ts
export interface WorkflowTemplate {
  id: string;
  name: string;
  version: string;
  description: string;
  category: string;
  tags: string[];
  author: string;
  organization?: string;
  visibility: "public" | "private" | "organization";

  // í…œí”Œë¦¿ ë‚´ìš©
  definition: TemplateDefinition;
  parameters: TemplateParameter[];
  examples: TemplateExample[];

  // ë©”íƒ€ë°ì´í„°
  created_at: Date;
  updated_at: Date;
  downloads: number;
  rating: number;
  verified: boolean;
}

export class TemplateRepository {
  private storage: TemplateStorage;
  private validator: TemplateValidator;
  private indexer: TemplateIndexer;

  constructor(config: RepositoryConfig) {
    this.storage = new TemplateStorage(config.storage);
    this.validator = new TemplateValidator();
    this.indexer = new TemplateIndexer(config.search);
  }

  async createTemplate(
    template: Omit<
      WorkflowTemplate,
      "id" | "created_at" | "updated_at" | "downloads" | "rating"
    >
  ): Promise<WorkflowTemplate> {
    // ê²€ì¦
    const validation = await this.validator.validate(template);
    if (!validation.valid) {
      throw new TemplateValidationError(validation.errors);
    }

    // ID ìƒì„±
    const id = this.generateTemplateId(template.name, template.version);

    // í…œí”Œë¦¿ ìƒì„±
    const fullTemplate: WorkflowTemplate = {
      ...template,
      id,
      created_at: new Date(),
      updated_at: new Date(),
      downloads: 0,
      rating: 0,
    };

    // ì €ì¥
    await this.storage.save(fullTemplate);

    // ì¸ë±ì‹±
    await this.indexer.index(fullTemplate);

    // ì´ë²¤íŠ¸ ë°œí–‰
    await this.publishEvent("template.created", fullTemplate);

    return fullTemplate;
  }

  async searchTemplates(
    query: TemplateSearchQuery
  ): Promise<TemplateSearchResult> {
    // ê²€ìƒ‰ ì‹¤í–‰
    const searchResults = await this.indexer.search(query);

    // í…œí”Œë¦¿ ë¡œë“œ
    const templates = await Promise.all(
      searchResults.hits.map((hit) => this.storage.get(hit.id))
    );

    // í•„í„°ë§ ì ìš©
    const filtered = this.applyFilters(templates, query.filters);

    // ì •ë ¬
    const sorted = this.sortTemplates(filtered, query.sort);

    // í˜ì´ì§•
    const paginated = this.paginate(sorted, query.page, query.limit);

    return {
      templates: paginated,
      total: filtered.length,
      page: query.page,
      limit: query.limit,
      facets: await this.calculateFacets(filtered),
    };
  }

  async getTemplate(
    templateId: string,
    options: GetTemplateOptions = {}
  ): Promise<WorkflowTemplate | null> {
    const template = await this.storage.get(templateId);

    if (!template) {
      return null;
    }

    // ì ‘ê·¼ ê¶Œí•œ í™•ì¸
    if (!(await this.checkAccess(template, options.userId))) {
      throw new TemplateAccessError("Access denied");
    }

    // ë‹¤ìš´ë¡œë“œ ì¹´ìš´íŠ¸ ì¦ê°€
    if (options.incrementDownload) {
      await this.incrementDownloadCount(templateId);
    }

    // ê´€ë ¨ í…œí”Œë¦¿ ë¡œë“œ
    if (options.includeRelated) {
      template.related = await this.findRelatedTemplates(template);
    }

    return template;
  }

  async updateTemplate(
    templateId: string,
    updates: Partial<WorkflowTemplate>,
    userId: string
  ): Promise<WorkflowTemplate> {
    const existing = await this.getTemplate(templateId);

    if (!existing) {
      throw new TemplateNotFoundError(templateId);
    }

    // ê¶Œí•œ í™•ì¸
    if (existing.author !== userId && !(await this.isAdmin(userId))) {
      throw new TemplateAccessError("Only author can update template");
    }

    // ì—…ë°ì´íŠ¸ ì ìš©
    const updated = {
      ...existing,
      ...updates,
      updated_at: new Date(),
    };

    // ë²„ì „ ê´€ë¦¬
    if (updates.definition && !updates.version) {
      updated.version = this.incrementVersion(existing.version);
    }

    // ê²€ì¦
    const validation = await this.validator.validate(updated);
    if (!validation.valid) {
      throw new TemplateValidationError(validation.errors);
    }

    // ì €ì¥
    await this.storage.save(updated);

    // ì¬ì¸ë±ì‹±
    await this.indexer.reindex(updated);

    // ì´ë²¤íŠ¸ ë°œí–‰
    await this.publishEvent("template.updated", updated);

    return updated;
  }

  async forkTemplate(
    templateId: string,
    userId: string,
    modifications: Partial<WorkflowTemplate> = {}
  ): Promise<WorkflowTemplate> {
    const original = await this.getTemplate(templateId);

    if (!original) {
      throw new TemplateNotFoundError(templateId);
    }

    // í¬í¬ ìƒì„±
    const forked = {
      ...original,
      ...modifications,
      id: undefined as any,
      name: modifications.name || `${original.name} (Fork)`,
      author: userId,
      visibility: "private" as const,
      downloads: 0,
      rating: 0,
      verified: false,
      forked_from: templateId,
      created_at: new Date(),
      updated_at: new Date(),
    };

    // ìƒˆ í…œí”Œë¦¿ìœ¼ë¡œ ìƒì„±
    return this.createTemplate(forked);
  }

  async rateTemplate(
    templateId: string,
    userId: string,
    rating: number
  ): Promise<void> {
    if (rating < 1 || rating > 5) {
      throw new Error("Rating must be between 1 and 5");
    }

    // ì¤‘ë³µ í‰ê°€ ë°©ì§€
    const existingRating = await this.storage.getRating(templateId, userId);
    if (existingRating) {
      throw new Error("User has already rated this template");
    }

    // í‰ê°€ ì €ì¥
    await this.storage.saveRating(templateId, userId, rating);

    // í‰ê·  í‰ì  ì¬ê³„ì‚°
    const newAverage = await this.storage.calculateAverageRating(templateId);

    // í…œí”Œë¦¿ ì—…ë°ì´íŠ¸
    await this.storage.updateRating(templateId, newAverage);
  }

  private async checkAccess(
    template: WorkflowTemplate,
    userId?: string
  ): Promise<boolean> {
    if (template.visibility === "public") {
      return true;
    }

    if (!userId) {
      return false;
    }

    if (template.author === userId) {
      return true;
    }

    if (template.visibility === "organization" && template.organization) {
      return await this.userBelongsToOrganization(
        userId,
        template.organization
      );
    }

    return false;
  }
}

// í…œí”Œë¦¿ ì €ì¥ì†Œ
export class TemplateStorage {
  private db: Database;
  private s3: S3Client;

  constructor(config: StorageConfig) {
    this.db = new Database(config.database);
    this.s3 = new S3Client(config.s3);
  }

  async save(template: WorkflowTemplate): Promise<void> {
    // ë©”íƒ€ë°ì´í„°ëŠ” DBì— ì €ì¥
    await this.db.templates.upsert({
      id: template.id,
      name: template.name,
      version: template.version,
      description: template.description,
      category: template.category,
      tags: template.tags,
      author: template.author,
      organization: template.organization,
      visibility: template.visibility,
      created_at: template.created_at,
      updated_at: template.updated_at,
      downloads: template.downloads,
      rating: template.rating,
      verified: template.verified,
    });

    // í…œí”Œë¦¿ ì •ì˜ëŠ” S3ì— ì €ì¥
    const definitionKey = `templates/${template.id}/definition.json`;
    await this.s3.putObject({
      Bucket: "workflow-templates",
      Key: definitionKey,
      Body: JSON.stringify(template.definition),
      ContentType: "application/json",
    });

    // íŒŒë¼ë¯¸í„° ì €ì¥
    const parametersKey = `templates/${template.id}/parameters.json`;
    await this.s3.putObject({
      Bucket: "workflow-templates",
      Key: parametersKey,
      Body: JSON.stringify(template.parameters),
      ContentType: "application/json",
    });

    // ì˜ˆì œ ì €ì¥
    for (let i = 0; i < template.examples.length; i++) {
      const exampleKey = `templates/${template.id}/examples/${i}.json`;
      await this.s3.putObject({
        Bucket: "workflow-templates",
        Key: exampleKey,
        Body: JSON.stringify(template.examples[i]),
        ContentType: "application/json",
      });
    }
  }

  async get(templateId: string): Promise<WorkflowTemplate | null> {
    // ë©”íƒ€ë°ì´í„° ë¡œë“œ
    const metadata = await this.db.templates.findById(templateId);
    if (!metadata) {
      return null;
    }

    // í…œí”Œë¦¿ ì •ì˜ ë¡œë“œ
    const definitionKey = `templates/${templateId}/definition.json`;
    const definitionObj = await this.s3.getObject({
      Bucket: "workflow-templates",
      Key: definitionKey,
    });
    const definition = JSON.parse(definitionObj.Body.toString());

    // íŒŒë¼ë¯¸í„° ë¡œë“œ
    const parametersKey = `templates/${templateId}/parameters.json`;
    const parametersObj = await this.s3.getObject({
      Bucket: "workflow-templates",
      Key: parametersKey,
    });
    const parameters = JSON.parse(parametersObj.Body.toString());

    // ì˜ˆì œ ë¡œë“œ
    const examples = await this.loadExamples(templateId);

    return {
      ...metadata,
      definition,
      parameters,
      examples,
    };
  }

  private async loadExamples(templateId: string): Promise<TemplateExample[]> {
    const examples: TemplateExample[] = [];
    let i = 0;

    while (true) {
      try {
        const exampleKey = `templates/${templateId}/examples/${i}.json`;
        const exampleObj = await this.s3.getObject({
          Bucket: "workflow-templates",
          Key: exampleKey,
        });
        examples.push(JSON.parse(exampleObj.Body.toString()));
        i++;
      } catch (error) {
        if (error.Code === "NoSuchKey") {
          break;
        }
        throw error;
      }
    }

    return examples;
  }
}

// í…œí”Œë¦¿ ì¸ë±ì„œ
export class TemplateIndexer {
  private searchClient: ElasticsearchClient;

  constructor(config: SearchConfig) {
    this.searchClient = new ElasticsearchClient(config);
  }

  async index(template: WorkflowTemplate): Promise<void> {
    const document = {
      id: template.id,
      name: template.name,
      description: template.description,
      category: template.category,
      tags: template.tags,
      author: template.author,
      organization: template.organization,
      visibility: template.visibility,
      downloads: template.downloads,
      rating: template.rating,
      verified: template.verified,
      created_at: template.created_at,

      // ê²€ìƒ‰ìš© í•„ë“œ
      search_text: `${template.name} ${template.description} ${template.tags.join(" ")}`,

      // íŒ¨ì‹¯ìš© í•„ë“œ
      category_facet: template.category,
      tags_facet: template.tags,
      author_facet: template.author,
      visibility_facet: template.visibility,
    };

    await this.searchClient.index({
      index: "workflow-templates",
      id: template.id,
      body: document,
    });
  }

  async search(query: TemplateSearchQuery): Promise<SearchResult> {
    const searchBody = {
      query: this.buildQuery(query),
      aggs: this.buildAggregations(),
      from: (query.page - 1) * query.limit,
      size: query.limit,
      sort: this.buildSort(query.sort),
    };

    const response = await this.searchClient.search({
      index: "workflow-templates",
      body: searchBody,
    });

    return {
      hits: response.hits.hits.map((hit) => ({
        id: hit._id,
        score: hit._score,
        ...hit._source,
      })),
      total: response.hits.total.value,
      aggregations: response.aggregations,
    };
  }

  private buildQuery(query: TemplateSearchQuery): any {
    const must = [];
    const filter = [];

    // í…ìŠ¤íŠ¸ ê²€ìƒ‰
    if (query.text) {
      must.push({
        multi_match: {
          query: query.text,
          fields: ["name^3", "description^2", "tags", "search_text"],
          type: "best_fields",
          fuzziness: "AUTO",
        },
      });
    }

    // í•„í„°
    if (query.filters) {
      if (query.filters.category) {
        filter.push({
          term: { category_facet: query.filters.category },
        });
      }

      if (query.filters.tags && query.filters.tags.length > 0) {
        filter.push({
          terms: { tags_facet: query.filters.tags },
        });
      }

      if (query.filters.author) {
        filter.push({
          term: { author_facet: query.filters.author },
        });
      }

      if (query.filters.visibility) {
        filter.push({
          term: { visibility_facet: query.filters.visibility },
        });
      }

      if (query.filters.verified !== undefined) {
        filter.push({
          term: { verified: query.filters.verified },
        });
      }

      if (query.filters.minRating) {
        filter.push({
          range: { rating: { gte: query.filters.minRating } },
        });
      }
    }

    return {
      bool: {
        must,
        filter,
      },
    };
  }

  private buildAggregations(): any {
    return {
      categories: {
        terms: {
          field: "category_facet",
          size: 20,
        },
      },
      tags: {
        terms: {
          field: "tags_facet",
          size: 50,
        },
      },
      authors: {
        terms: {
          field: "author_facet",
          size: 20,
        },
      },
      visibility: {
        terms: {
          field: "visibility_facet",
        },
      },
      rating_ranges: {
        range: {
          field: "rating",
          ranges: [
            { from: 4, to: 5, key: "4-5 stars" },
            { from: 3, to: 4, key: "3-4 stars" },
            { from: 2, to: 3, key: "2-3 stars" },
            { from: 1, to: 2, key: "1-2 stars" },
          ],
        },
      },
    };
  }

  private buildSort(sort?: TemplateSort): any {
    if (!sort) {
      return [{ downloads: "desc" }, { rating: "desc" }];
    }

    switch (sort.field) {
      case "downloads":
        return [{ downloads: sort.order }];
      case "rating":
        return [{ rating: sort.order }];
      case "created_at":
        return [{ created_at: sort.order }];
      case "name":
        return [{ "name.keyword": sort.order }];
      default:
        return [{ _score: "desc" }];
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í…œí”Œë¦¿ CRUD ì‘ì—…
- [ ] ê²€ìƒ‰ ë° í•„í„°ë§
- [ ] ë²„ì „ ê´€ë¦¬
- [ ] ê¶Œí•œ ë° ê³µìœ 

#### SubTask 5.6.2: í…œí”Œë¦¿ íŒŒë¼ë¯¸í„°í™” ì‹œìŠ¤í…œ

**ë‹´ë‹¹ì**: í…œí”Œë¦¿ ì—”ì§„ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/templates/parameterization.ts
export interface TemplateParameter {
  name: string;
  type: ParameterType;
  description?: string;
  required: boolean;
  default?: any;
  validation?: ParameterValidation;
  ui_hints?: UIHints;
}

export enum ParameterType {
  STRING = "string",
  NUMBER = "number",
  BOOLEAN = "boolean",
  ARRAY = "array",
  OBJECT = "object",
  CHOICE = "choice",
  FILE = "file",
  SECRET = "secret",
  TEMPLATE_REF = "template_ref",
}

export interface ParameterValidation {
  // String validations
  minLength?: number;
  maxLength?: number;
  pattern?: string;

  // Number validations
  min?: number;
  max?: number;
  step?: number;

  // Array validations
  minItems?: number;
  maxItems?: number;
  uniqueItems?: boolean;

  // Choice validations
  choices?: any[];

  // Custom validation
  custom?: string; // JavaScript expression
}

export class TemplateParameterizer {
  private validator: ParameterValidator;
  private resolver: ParameterResolver;
  private transformer: ParameterTransformer;

  constructor() {
    this.validator = new ParameterValidator();
    this.resolver = new ParameterResolver();
    this.transformer = new ParameterTransformer();
  }

  async instantiateTemplate(
    template: WorkflowTemplate,
    parameters: Record<string, any>
  ): Promise<WorkflowDefinition> {
    // 1. íŒŒë¼ë¯¸í„° ê²€ì¦
    const validation = await this.validator.validateParameters(
      template.parameters,
      parameters
    );

    if (!validation.valid) {
      throw new ParameterValidationError(validation.errors);
    }

    // 2. ê¸°ë³¸ê°’ ì ìš©
    const resolvedParams = this.applyDefaults(template.parameters, parameters);

    // 3. í…œí”Œë¦¿ ë³€í™˜
    const transformed = await this.transformer.transform(
      template.definition,
      resolvedParams
    );

    // 4. í›„ì²˜ë¦¬
    const postProcessed = await this.postProcess(transformed, resolvedParams);

    return postProcessed;
  }

  private applyDefaults(
    paramDefs: TemplateParameter[],
    provided: Record<string, any>
  ): Record<string, any> {
    const result = { ...provided };

    for (const paramDef of paramDefs) {
      if (!(paramDef.name in result) && paramDef.default !== undefined) {
        result[paramDef.name] = paramDef.default;
      }
    }

    return result;
  }

  async generateParameterForm(
    template: WorkflowTemplate
  ): Promise<ParameterForm> {
    const form: ParameterForm = {
      sections: [],
      validation: {},
      dependencies: {},
    };

    // íŒŒë¼ë¯¸í„°ë¥¼ ì„¹ì…˜ë³„ë¡œ ê·¸ë£¹í™”
    const sections = this.groupParameters(template.parameters);

    for (const [sectionName, params] of sections) {
      const section: FormSection = {
        name: sectionName,
        title: this.humanize(sectionName),
        fields: [],
      };

      for (const param of params) {
        const field = await this.generateField(param);
        section.fields.push(field);

        // ê²€ì¦ ê·œì¹™ ì¶”ê°€
        if (param.validation) {
          form.validation[param.name] = param.validation;
        }
      }

      form.sections.push(section);
    }

    // íŒŒë¼ë¯¸í„° ê°„ ì˜ì¡´ì„± ë¶„ì„
    form.dependencies = this.analyzeDependencies(template.parameters);

    return form;
  }

  private async generateField(param: TemplateParameter): Promise<FormField> {
    const field: FormField = {
      name: param.name,
      label: param.ui_hints?.label || this.humanize(param.name),
      type: this.mapParameterTypeToFieldType(param.type),
      required: param.required,
      description: param.description,
      placeholder: param.ui_hints?.placeholder,
      help: param.ui_hints?.help,
    };

    // íƒ€ì…ë³„ íŠ¹ìˆ˜ ì²˜ë¦¬
    switch (param.type) {
      case ParameterType.CHOICE:
        field.options = param.validation?.choices?.map((choice) => ({
          value: choice.value || choice,
          label: choice.label || choice,
        }));
        break;

      case ParameterType.FILE:
        field.accept = param.ui_hints?.accept;
        field.maxSize = param.validation?.maxSize;
        break;

      case ParameterType.SECRET:
        field.type = "password";
        field.autocomplete = "off";
        break;

      case ParameterType.TEMPLATE_REF:
        field.type = "template-selector";
        field.templateFilter = param.ui_hints?.templateFilter;
        break;
    }

    return field;
  }
}

// íŒŒë¼ë¯¸í„° ë³€í™˜ê¸°
export class ParameterTransformer {
  private templateEngine: TemplateEngine;
  private expressionEvaluator: ExpressionEvaluator;

  constructor() {
    this.templateEngine = new TemplateEngine();
    this.expressionEvaluator = new ExpressionEvaluator();
  }

  async transform(
    definition: TemplateDefinition,
    parameters: Record<string, any>
  ): Promise<WorkflowDefinition> {
    // ê¹Šì€ ë³µì‚¬
    const result = _.cloneDeep(definition);

    // ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    const context = this.createTransformContext(parameters);

    // ì¬ê·€ì  ë³€í™˜
    await this.transformNode(result, context);

    return result as WorkflowDefinition;
  }

  private async transformNode(
    node: any,
    context: TransformContext
  ): Promise<void> {
    if (typeof node === "string") {
      // ë¬¸ìì—´ í…œí”Œë¦¿ ì²˜ë¦¬
      return this.transformString(node, context);
    } else if (Array.isArray(node)) {
      // ë°°ì—´ ì²˜ë¦¬
      for (let i = 0; i < node.length; i++) {
        node[i] = await this.transformNode(node[i], context);
      }
    } else if (typeof node === "object" && node !== null) {
      // ê°ì²´ ì²˜ë¦¬
      for (const key of Object.keys(node)) {
        // íŠ¹ìˆ˜ í‚¤ ì²˜ë¦¬
        if (key === "$if") {
          await this.handleConditional(node, context);
        } else if (key === "$foreach") {
          await this.handleLoop(node, context);
        } else if (key === "$include") {
          await this.handleInclude(node, context);
        } else {
          // ì¼ë°˜ ì†ì„± ë³€í™˜
          node[key] = await this.transformNode(node[key], context);
        }
      }
    }

    return node;
  }

  private async transformString(
    str: string,
    context: TransformContext
  ): Promise<any> {
    // í…œí”Œë¦¿ ë³€ìˆ˜ íŒ¨í„´: ${variable}
    const templatePattern = /\$\{([^}]+)\}/g;

    // í‘œí˜„ì‹ íŒ¨í„´: ${{expression}}
    const expressionPattern = /\$\{\{([^}]+)\}\}/g;

    let result = str;

    // late{s} ì²˜ë¦¬
    result = await this.templateEngine.render(result, context.parameters);

    // í‘œí˜„ì‹ ì²˜ë¦¬
    const expressions = result.matchAll(expressionPattern);
    for (const match of expressions) {
      const expression = match[1];
      const value = await this.expressionEvaluator.evaluate(
        expression,
        context
      );
      result = result.replace(match[0], value);
    }

    // íƒ€ì… ë³€í™˜ ì‹œë„
    if (result === str) {
      // ë³€í™˜ë˜ì§€ ì•Šì€ ê²½ìš° ì›ë³¸ ë°˜í™˜
      return str;
    } else if (result === "true" || result === "false") {
      return result === "true";
    } else if (!isNaN(Number(result))) {
      return Number(result);
    }

    return result;
  }

  private async handleConditional(
    node: any,
    context: TransformContext
  ): Promise<void> {
    const condition = node.$if;
    const thenBlock = node.$then;
    const elseBlock = node.$else;

    const conditionResult = await this.expressionEvaluator.evaluate(
      condition,
      context
    );

    if (conditionResult) {
      // then ë¸”ë¡ ì ìš©
      Object.assign(node, thenBlock);
    } else if (elseBlock) {
      // else ë¸”ë¡ ì ìš©
      Object.assign(node, elseBlock);
    }

    // íŠ¹ìˆ˜ í‚¤ ì œê±°
    delete node.$if;
    delete node.$then;
    delete node.$else;
  }

  private async handleLoop(
    node: any,
    context: TransformContext
  ): Promise<void> {
    const loopSpec = node.$foreach;
    const itemVar = loopSpec.item || "item";
    const indexVar = loopSpec.index || "index";
    const collection = await this.resolveValue(loopSpec.in, context);
    const template = node.$body;

    if (!Array.isArray(collection)) {
      throw new Error(`$foreach requires an array, got ${typeof collection}`);
    }

    const results = [];

    for (let i = 0; i < collection.length; i++) {
      // ë£¨í”„ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
      const loopContext = {
        ...context,
        [itemVar]: collection[i],
        [indexVar]: i,
      };

      // í…œí”Œë¦¿ ì¸ìŠ¤í„´ìŠ¤í™”
      const instance = _.cloneDeep(template);
      await this.transformNode(instance, loopContext);
      results.push(instance);
    }

    // ê²°ê³¼ë¡œ ëŒ€ì²´
    if (node.$target) {
      node[node.$target] = results;
      delete node.$foreach;
      delete node.$body;
      delete node.$target;
    } else {
      // ë¶€ëª¨ ë…¸ë“œë¥¼ ë°°ì—´ë¡œ ëŒ€ì²´
      return results;
    }
  }
}

// íŒŒë¼ë¯¸í„° ê²€ì¦ê¸°
export class ParameterValidator {
  async validateParameters(
    definitions: TemplateParameter[],
    provided: Record<string, any>
  ): Promise<ValidationResult> {
    const errors: ValidationError[] = [];

    for (const def of definitions) {
      const value = provided[def.name];

      // í•„ìˆ˜ íŒŒë¼ë¯¸í„° ê²€ì‚¬
      if (def.required && value === undefined) {
        errors.push({
          parameter: def.name,
          message: `Required parameter '${def.name}' is missing`,
          type: "required",
        });
        continue;
      }

      if (value !== undefined) {
        // íƒ€ì… ê²€ì¦
        const typeErrors = this.validateType(def, value);
        errors.push(...typeErrors);

        // ì œì•½ ì¡°ê±´ ê²€ì¦
        if (def.validation) {
          const constraintErrors = await this.validateConstraints(def, value);
          errors.push(...constraintErrors);
        }
      }
    }

    // ì¶”ê°€ íŒŒë¼ë¯¸í„° ê²€ì‚¬
    const definedNames = new Set(definitions.map((d) => d.name));
    for (const providedName of Object.keys(provided)) {
      if (!definedNames.has(providedName)) {
        errors.push({
          parameter: providedName,
          message: `Unknown parameter '${providedName}'`,
          type: "unknown",
        });
      }
    }

    return {
      valid: errors.length === 0,
      errors,
    };
  }

  private validateType(def: TemplateParameter, value: any): ValidationError[] {
    const errors: ValidationError[] = [];

    switch (def.type) {
      case ParameterType.STRING:
        if (typeof value !== "string") {
          errors.push({
            parameter: def.name,
            message: `Expected string, got ${typeof value}`,
            type: "type_mismatch",
          });
        }
        break;

      case ParameterType.NUMBER:
        if (typeof value !== "number") {
          errors.push({
            parameter: def.name,
            message: `Expected number, got ${typeof value}`,
            type: "type_mismatch",
          });
        }
        break;

      case ParameterType.BOOLEAN:
        if (typeof value !== "boolean") {
          errors.push({
            parameter: def.name,
            message: `Expected boolean, got ${typeof value}`,
            type: "type_mismatch",
          });
        }
        break;

      case ParameterType.ARRAY:
        if (!Array.isArray(value)) {
          errors.push({
            parameter: def.name,
            message: `Expected array, got ${typeof value}`,
            type: "type_mismatch",
          });
        }
        break;

      case ParameterType.OBJECT:
        if (typeof value !== "object" || value === null) {
          errors.push({
            parameter: def.name,
            message: `Expected object, got ${typeof value}`,
            type: "type_mismatch",
          });
        }
        break;
    }

    return errors;
  }

  private async validateConstraints(
    def: TemplateParameter,
    value: any
  ): Promise<ValidationError[]> {
    const errors: ValidationError[] = [];
    const validation = def.validation!;

    // String constraints
    if (def.type === ParameterType.STRING) {
      if (validation.minLength && value.length < validation.minLength) {
        errors.push({
          parameter: def.name,
          message: `Minimum length is ${validation.minLength}`,
          type: "constraint_violation",
        });
      }

      if (validation.maxLength && value.length > validation.maxLength) {
        errors.push({
          parameter: def.name,
          message: `Maximum length is ${validation.maxLength}`,
          type: "constraint_violation",
        });
      }

      if (validation.pattern) {
        const regex = new RegExp(validation.pattern);
        if (!regex.test(value)) {
          errors.push({
            parameter: def.name,
            message: `Does not match pattern: ${validation.pattern}`,
            type: "constraint_violation",
          });
        }
      }
    }

    // Number constraints
    if (def.type === ParameterType.NUMBER) {
      if (validation.min !== undefined && value < validation.min) {
        errors.push({
          parameter: def.name,
          message: `Minimum value is ${validation.min}`,
          type: "constraint_violation",
        });
      }

      if (validation.max !== undefined && value > validation.max) {
        errors.push({
          parameter: def.name,
          message: `Maximum value is ${validation.max}`,
          type: "constraint_violation",
        });
      }
    }

    // Choice constraints
    if (def.type === ParameterType.CHOICE && validation.choices) {
      const validChoices = validation.choices.map((c) => c.value || c);
      if (!validChoices.includes(value)) {
        errors.push({
          parameter: def.name,
          message: `Invalid choice. Must be one of: ${validChoices.join(", ")}`,
          type: "constraint_violation",
        });
      }
    }

    // Custom validation
    if (validation.custom) {
      try {
        const customResult = await this.evaluateCustomValidation(
          validation.custom,
          value,
          def
        );
        if (!customResult.valid) {
          errors.push({
            parameter: def.name,
            message: customResult.message || "Custom validation failed",
            type: "custom_validation",
          });
        }
      } catch (e) {
        errors.push({
          parameter: def.name,
          message: `Custom validation error: ${e.message}`,
          type: "validation_error",
        });
      }
    }

    return errors;
  }

  private async evaluateCustomValidation(
    expression: string,
    value: any,
    parameter: TemplateParameter
  ): Promise<{ valid: boolean; message?: string }> {
    // ì•ˆì „í•œ ì»¨í…ìŠ¤íŠ¸ì—ì„œ í‘œí˜„ì‹ í‰ê°€
    const sandbox = {
      value,
      parameter,
      // ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
      isEmail: (v: string) => /^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(v),
      isURL: (v: string) => {
        try {
          new URL(v);
          return true;
        } catch {
          return false;
        }
      },
      isUUID: (v: string) =>
        /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(
          v
        ),
    };

    // í‘œí˜„ì‹ ì‹¤í–‰
    const fn = new Function(...Object.keys(sandbox), `return ${expression}`);
    const result = fn(...Object.values(sandbox));

    if (typeof result === "boolean") {
      return { valid: result };
    } else if (typeof result === "object" && result !== null) {
      return result;
    } else {
      return {
        valid: false,
        message: "Validation must return boolean or {valid, message}",
      };
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] íŒŒë¼ë¯¸í„° ì •ì˜ ì‹œìŠ¤í…œ
- [ ] í…œí”Œë¦¿ ë³€í™˜ ì—”ì§„
- [ ] ë™ì  í¼ ìƒì„±
- [ ] ê²€ì¦ ë° íƒ€ì… ì²´í¬

#### SubTask 5.6.3: í…œí”Œë¦¿ ìƒì† ë° í™•ì¥ ë©”ì»¤ë‹ˆì¦˜

**ë‹´ë‹¹ì**: í…œí”Œë¦¿ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/templates/inheritance.ts
export interface TemplateInheritance {
  extends?: string; // ë¶€ëª¨ í…œí”Œë¦¿ ID
  abstract?: boolean; // ì¶”ìƒ í…œí”Œë¦¿ ì—¬ë¶€
  overrides?: string[]; // ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥í•œ ì„¹ì…˜
  final?: string[]; // ì˜¤ë²„ë¼ì´ë“œ ë¶ˆê°€ëŠ¥í•œ ì„¹ì…˜
  mixins?: string[]; // ë¯¹ìŠ¤ì¸ í…œí”Œë¦¿ IDë“¤
}

export class TemplateInheritanceEngine {
  private templateRepo: TemplateRepository;
  private mergeEngine: TemplateMergeEngine;
  private overrideValidator: OverrideValidator;

  constructor(repo: TemplateRepository) {
    this.templateRepo = repo;
    this.mergeEngine = new TemplateMergeEngine();
    this.overrideValidator = new OverrideValidator();
  }

  async resolveTemplate(
    templateId: string,
    visited: Set<string> = new Set()
  ): Promise<ResolvedTemplate> {
    // ìˆœí™˜ ì°¸ì¡° ë°©ì§€
    if (visited.has(templateId)) {
      throw new CircularInheritanceError(
        `Circular inheritance detected: ${Array.from(visited).join(" -> ")} -> ${templateId}`
      );
    }
    visited.add(templateId);

    // í…œí”Œë¦¿ ë¡œë“œ
    const template = await this.templateRepo.getTemplate(templateId);
    if (!template) {
      throw new TemplateNotFoundError(templateId);
    }

    // ìƒì† ì •ë³´ í™•ì¸
    const inheritance = template.definition.inheritance;
    if (!inheritance || !inheritance.extends) {
      // ê¸°ë³¸ í…œí”Œë¦¿ì¸ ê²½ìš°
      return this.applyMixins(template, inheritance);
    }

    // ë¶€ëª¨ í…œí”Œë¦¿ í•´ê²°
    const parent = await this.resolveTemplate(
      inheritance.extends,
      new Set(visited)
    );

    // ìƒì† ê²€ì¦
    await this.validateInheritance(parent, template);

    // í…œí”Œë¦¿ ë³‘í•©
    const merged = await this.mergeTemplates(parent, template);

    // ë¯¹ìŠ¤ì¸ ì ìš©
    return this.applyMixins(merged, inheritance);
  }

  private async validateInheritance(
    parent: ResolvedTemplate,
    child: WorkflowTemplate
  ): Promise<void> {
    const parentDef = parent.definition;
    const childDef = child.definition;

    // ì¶”ìƒ í…œí”Œë¦¿ì€ ì§ì ‘ ì‚¬ìš© ë¶ˆê°€
    if (parentDef.inheritance?.abstract) {
      // ìì‹ë„ ì¶”ìƒì´ì–´ì•¼ í•¨
      if (!childDef.inheritance?.abstract) {
        throw new InheritanceError(
          "Cannot extend abstract template unless child is also abstract"
        );
      }
    }

    // final ì„¹ì…˜ ì˜¤ë²„ë¼ì´ë“œ ê²€ì‚¬
    if (parentDef.inheritance?.final) {
      const overrides = this.findOverrides(parentDef, childDef);
      const violations = overrides.filter((o) =>
        parentDef.inheritance!.final!.includes(o)
      );

      if (violations.length > 0) {
        throw new InheritanceError(
          `Cannot override final sections: ${violations.join(", ")}`
        );
      }
    }

    // í•„ìˆ˜ ì˜¤ë²„ë¼ì´ë“œ ê²€ì‚¬
    if (parentDef.inheritance?.overrides) {
      const required = parentDef.inheritance.overrides
        .filter((o) => o.startsWith("required:"))
        .map((o) => o.substring(9));

      const implemented = this.findOverrides(parentDef, childDef);
      const missing = required.filter((r) => !implemented.includes(r));

      if (missing.length > 0) {
        throw new InheritanceError(
          `Missing required overrides: ${missing.join(", ")}`
        );
      }
    }
  }

  private async mergeTemplates(
    parent: ResolvedTemplate,
    child: WorkflowTemplate
  ): Promise<ResolvedTemplate> {
    const merged = _.cloneDeep(parent);

    // ë©”íƒ€ë°ì´í„° ë³‘í•©
    merged.name = child.name;
    merged.version = child.version;
    merged.description = child.description;
    merged.author = child.author;

    // íŒŒë¼ë¯¸í„° ë³‘í•©
    merged.parameters = this.mergeParameters(
      parent.parameters,
      child.parameters
    );

    // ì •ì˜ ë³‘í•©
    merged.definition = await this.mergeEngine.merge(
      parent.definition,
      child.definition,
      {
        strategy: "override",
        preservePaths: parent.definition.inheritance?.final || [],
      }
    );

    // ìƒì† ì²´ì¸ ì—…ë°ì´íŠ¸
    merged.inheritanceChain = [
      ...(parent.inheritanceChain || []),
      {
        templateId: child.id,
        templateName: child.name,
        version: child.version,
      },
    ];

    return merged;
  }

  private mergeParameters(
    parentParams: TemplateParameter[],
    childParams: TemplateParameter[]
  ): TemplateParameter[] {
    const merged = [...parentParams];
    const parentNames = new Set(parentParams.map((p) => p.name));

    for (const childParam of childParams) {
      const existingIndex = merged.findIndex((p) => p.name === childParam.name);

      if (existingIndex >= 0) {
        // ì˜¤ë²„ë¼ì´ë“œ
        merged[existingIndex] = this.mergeParameter(
          merged[existingIndex],
          childParam
        );
      } else {
        // ìƒˆ íŒŒë¼ë¯¸í„°
        merged.push(childParam);
      }
    }

    return merged;
  }

  private mergeParameter(
    parent: TemplateParameter,
    child: TemplateParameter
  ): TemplateParameter {
    return {
      ...parent,
      ...child,
      // ê²€ì¦ ê·œì¹™ì€ ë³‘í•©
      validation: {
        ...parent.validation,
        ...child.validation,
      },
      // UI íŒíŠ¸ë„ ë³‘í•©
      ui_hints: {
        ...parent.ui_hints,
        ...child.ui_hints,
      },
    };
  }

  private async applyMixins(
    template: ResolvedTemplate,
    inheritance?: TemplateInheritance
  ): Promise<ResolvedTemplate> {
    if (!inheritance?.mixins || inheritance.mixins.length === 0) {
      return template;
    }

    let result = template;

    for (const mixinId of inheritance.mixins) {
      const mixin = await this.templateRepo.getTemplate(mixinId);

      if (!mixin) {
        throw new TemplateNotFoundError(`Mixin ${mixinId} not found`);
      }

      // ë¯¹ìŠ¤ì¸ì€ íŠ¹ì • ì„¹ì…˜ë§Œ ì œê³µ
      result = await this.applyMixin(result, mixin);
    }

    return result;
  }

  private async applyMixin(
    target: ResolvedTemplate,
    mixin: WorkflowTemplate
  ): Promise<ResolvedTemplate> {
    const mixinDef = mixin.definition;

    // ë¯¹ìŠ¤ì¸ì—ì„œ ì œê³µí•˜ëŠ” ì„¹ì…˜ ì‹ë³„
    const providedSections = mixinDef.mixin?.provides || [];

    for (const section of providedSections) {
      const sectionData = _.get(mixinDef, section);

      if (sectionData) {
        // íƒ€ê²Ÿì— ì„¹ì…˜ ì¶”ê°€/ë³‘í•©
        const existing = _.get(target.definition, section);

        if (existing && Array.isArray(existing) && Array.isArray(sectionData)) {
          // ë°°ì—´ ë³‘í•©
          _.set(target.definition, section, [...existing, ...sectionData]);
        } else if (
          existing &&
          typeof existing === "object" &&
          typeof sectionData === "object"
        ) {
          // ê°ì²´ ë³‘í•©
          _.set(target.definition, section, _.merge({}, existing, sectionData));
        } else {
          // ë®ì–´ì“°ê¸°
          _.set(target.definition, section, sectionData);
        }
      }
    }

    // ë¯¹ìŠ¤ì¸ ì²´ì¸ì— ì¶”ê°€
    target.mixinChain = [
      ...(target.mixinChain || []),
      {
        templateId: mixin.id,
        templateName: mixin.name,
        sections: providedSections,
      },
    ];

    return target;
  }
}

// í…œí”Œë¦¿ í™•ì¥ ë¹Œë”
export class TemplateExtensionBuilder {
  private baseTemplate: WorkflowTemplate;
  private extensions: TemplateExtension[] = [];

  constructor(baseTemplate: WorkflowTemplate) {
    this.baseTemplate = baseTemplate;
  }

  extend(extension: TemplateExtension): this {
    this.extensions.push(extension);
    return this;
  }

  override(path: string, value: any): this {
    this.extensions.push({
      type: "override",
      path,
      value,
    });
    return this;
  }

  addTask(position: string, task: WorkflowTask): this {
    this.extensions.push({
      type: "add_task",
      position,
      task,
    });
    return this;
  }

  removeTask(taskId: string): this {
    this.extensions.push({
      type: "remove_task",
      taskId,
    });
    return this;
  }

  modifyTask(taskId: string, modifications: Partial<WorkflowTask>): this {
    this.extensions.push({
      type: "modify_task",
      taskId,
      modifications,
    });
    return this;
  }

  addParameter(parameter: TemplateParameter): this {
    this.extensions.push({
      type: "add_parameter",
      parameter,
    });
    return this;
  }

  build(): ExtendedTemplate {
    const extended = _.cloneDeep(this.baseTemplate);

    // í™•ì¥ ì ìš©
    for (const extension of this.extensions) {
      this.applyExtension(extended, extension);
    }

    // ìƒì† ì •ë³´ ì¶”ê°€
    extended.definition.inheritance = {
      extends: this.baseTemplate.id,
      overrides: this.collectOverrides(),
    };

    return extended;
  }

  private applyExtension(
    template: WorkflowTemplate,
    extension: TemplateExtension
  ): void {
    switch (extension.type) {
      case "override":
        _.set(template.definition, extension.path, extension.value);
        break;

      case "add_task":
        const tasks = template.definition.tasks || [];
        const position = this.findPosition(tasks, extension.position);
        tasks.splice(position, 0, extension.task);
        break;

      case "remove_task":
        template.definition.tasks = template.definition.tasks?.filter(
          (t) => t.id !== extension.taskId
        );
        break;

      case "modify_task":
        const task = template.definition.tasks?.find(
          (t) => t.id === extension.taskId
        );
        if (task) {
          Object.assign(task, extension.modifications);
        }
        break;

      case "add_parameter":
        template.parameters.push(extension.parameter);
        break;
    }
  }

  private collectOverrides(): string[] {
    return this.extensions
      .filter((e) => e.type === "override")
      .map((e) => e.path);
  }
}

// í…œí”Œë¦¿ ì¡°í•©ê¸°
export class TemplateComposer {
  async composeTemplate(
    composition: TemplateComposition
  ): Promise<WorkflowTemplate> {
    const templates: WorkflowTemplate[] = [];

    // ëª¨ë“  í…œí”Œë¦¿ ë¡œë“œ
    for (const ref of composition.templates) {
      const template = await this.loadTemplateRef(ref);
      templates.push(template);
    }

    // ì¡°í•© ì „ëµì— ë”°ë¼ ë³‘í•©
    let composed: WorkflowTemplate;

    switch (composition.strategy) {
      case "sequential":
        composed = this.composeSequential(templates);
        break;

      case "parallel":
        composed = this.composeParallel(templates);
        break;

      case "conditional":
        composed = this.composeConditional(templates, composition.conditions!);
        break;

      case "pipeline":
        composed = this.composePipeline(templates);
        break;

      default:
        throw new Error(
          `Unknown composition strategy: ${composition.strategy}`
        );
    }

    // ë©”íƒ€ë°ì´í„° ì„¤ì •
    composed.name = composition.name;
    composed.description = composition.description;
    composed.composition = composition;

    return composed;
  }

  private composeSequential(templates: WorkflowTemplate[]): WorkflowTemplate {
    const composed = this.createEmptyTemplate();

    // ìˆœì°¨ì ìœ¼ë¡œ íƒœìŠ¤í¬ ì—°ê²°
    let lastTasks: string[] = [];

    for (const template of templates) {
      const offset = composed.definition.tasks.length;

      // íƒœìŠ¤í¬ ë³µì‚¬ (ID ì¡°ì •)
      const adjustedTasks = template.definition.tasks.map((task, index) => ({
        ...task,
        id: `${template.id}_${task.id}`,
        dependencies: [
          ...task.dependencies.map((d) => ({
            ...d,
            task_id: `${template.id}_${d.task_id}`,
          })),
          // ì´ì „ í…œí”Œë¦¿ì˜ ë§ˆì§€ë§‰ íƒœìŠ¤í¬ë“¤ì— ì˜ì¡´
          ...lastTasks.map((taskId) => ({
            task_id: taskId,
            wait_for_completion: true,
          })),
        ],
      }));

      composed.definition.tasks.push(...adjustedTasks);

      // ì´ í…œí”Œë¦¿ì˜ ë§ˆì§€ë§‰ íƒœìŠ¤í¬ë“¤ ì°¾ê¸°
      lastTasks = this.findTerminalTasks(adjustedTasks);

      // íŒŒë¼ë¯¸í„° ë³‘í•©
      composed.parameters.push(...template.parameters);
    }

    return composed;
  }

  private composeParallel(templates: WorkflowTemplate[]): WorkflowTemplate {
    const composed = this.createEmptyTemplate();

    // ë³‘ë ¬ ë¸”ë¡ ìƒì„±
    const parallelBlock: ParallelBlock = {
      id: "parallel_composition",
      tasks: [],
      max_concurrency: templates.length,
    };

    for (const template of templates) {
      // ê° í…œí”Œë¦¿ì„ ì„œë¸Œì›Œí¬í”Œë¡œìš°ë¡œ ë³€í™˜
      const subWorkflow = {
        id: `sub_${template.id}`,
        type: "subworkflow",
        workflow_id: template.id,
        input_mapping: this.createInputMapping(template),
        output_mapping: this.createOutputMapping(template),
      };

      parallelBlock.tasks.push(subWorkflow);
    }

    composed.definition.tasks.push(parallelBlock);

    // ëª¨ë“  íŒŒë¼ë¯¸í„° ë³‘í•© (ì¤‘ë³µ ì œê±°)
    const paramMap = new Map<string, TemplateParameter>();

    for (const template of templates) {
      for (const param of template.parameters) {
        if (!paramMap.has(param.name)) {
          paramMap.set(param.name, param);
        }
      }
    }

    composed.parameters = Array.from(paramMap.values());

    return composed;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í…œí”Œë¦¿ ìƒì† ì‹œìŠ¤í…œ
- [ ] ë¯¹ìŠ¤ì¸ ì§€ì›
- [ ] í™•ì¥ ë¹Œë” API
- [ ] í…œí”Œë¦¿ ì¡°í•© ì „ëµ

#### SubTask 5.6.4: í…œí”Œë¦¿ ê³µìœ  ë§ˆì¼“í”Œë ˆì´ìŠ¤

**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/orchestration/templates/marketplace.ts
export class TemplateMarketplace {
  private repository: TemplateRepository;
  private reviewService: TemplateReviewService;
  private analyticsService: TemplateAnalyticsService;
  private paymentService: PaymentService;

  constructor(config: MarketplaceConfig) {
    this.repository = new TemplateRepository(config.repository);
    this.reviewService = new TemplateReviewService();
    this.analyticsService = new TemplateAnalyticsService();
    this.paymentService = new PaymentService(config.payment);
  }

  async publishTemplate(
    template: WorkflowTemplate,
    publishOptions: PublishOptions
  ): Promise<PublishedTemplate> {
    // 1. í’ˆì§ˆ ê²€ì‚¬
    const qualityCheck = await this.performQualityCheck(template);

    if (!qualityCheck.passed) {
      throw new QualityCheckError(qualityCheck.issues);
    }

    // 2. ë¼ì´ì„ ìŠ¤ ì„¤ì •
    template.license = publishOptions.license || "MIT";
    template.pricing = publishOptions.pricing || { type: "free" };

    // 3. ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜
    if (!template.category) {
      template.category = await this.categorizeTemplate(template);
    }

    // 4. íƒœê·¸ ìë™ ìƒì„±
    const autoTags = await this.generateTags(template);
    template.tags = [...new Set([...template.tags, ...autoTags])];

    // 5. ê²€ì¦ ë§ˆí¬ ë¶€ì—¬ (ì¡°ê±´ ì¶©ì¡± ì‹œ)
    if (await this.qualifiesForVerification(template)) {
      template.verified = true;
    }

    // 6. ì €ì¥ ë° ë°œí–‰
    const published = await this.repository.createTemplate(template);

    // 7. ê²€ìƒ‰ ì¸ë±ì‹±
    await this.indexForSearch(published);

    // 8. ì•Œë¦¼ ë°œì†¡
    await this.notifyFollowers(published);

    return {
      ...published,
      publishedAt: new Date(),
      status: "published",
    };
  }

  async purchaseTemplate(
    templateId: string,
    userId: string,
    paymentMethod: PaymentMethod
  ): Promise<PurchaseResult> {
    const template = await this.repository.getTemplate(templateId);

    if (!template) {
      throw new TemplateNotFoundError(templateId);
    }

    // ë¬´ë£Œ í…œí”Œë¦¿ ì²˜ë¦¬
    if (template.pricing.type === "free") {
      return {
        success: true,
        templateId,
        transactionId: null,
        accessGranted: true,
      };
    }

    // ì´ë¯¸ êµ¬ë§¤í•œ ê²½ìš°
    if (await this.hasAccess(userId, templateId)) {
      return {
        success: true,
        templateId,
        transactionId: "existing",
        accessGranted: true,
      };
    }

    // ê²°ì œ ì²˜ë¦¬
    const payment = await this.paymentService.processPayment({
      amount: template.pricing.amount,
      currency: template.pricing.currency,
      userId,
      templateId,
      paymentMethod,
    });

    if (payment.success) {
      // ì ‘ê·¼ ê¶Œí•œ ë¶€ì—¬
      await this.grantAccess(userId, templateId);

      // íŒë§¤ìì—ê²Œ ìˆ˜ìµ ë¶„ë°°
      await this.distributeRevenue(
        template.author,
        payment.amount,
        template.pricing.revenueShare || 0.7
      );

      // íŒë§¤ í†µê³„ ì—…ë°ì´íŠ¸
      await this.analyticsService.recordPurchase(templateId, userId);
    }

    return {
      success: payment.success,
      templateId,
      transactionId: payment.transactionId,
      accessGranted: payment.success,
    };
  }

  async getMarketplaceStats(): Promise<MarketplaceStats> {
    const stats = await this.analyticsService.getGlobalStats();

    return {
      totalTemplates: stats.templateCount,
      totalAuthors: stats.authorCount,
      totalDownloads: stats.downloadCount,
      totalRevenue: stats.totalRevenue,
      topCategories: await this.getTopCategories(),
      trendingTemplates: await this.getTrendingTemplates(),
      featuredTemplates: await this.getFeaturedTemplates(),
    };
  }

  async reviewTemplate(
    templateId: string,
    userId: string,
    review: TemplateReview
  ): Promise<void> {
    // êµ¬ë§¤/ì‚¬ìš© í™•ì¸
    if (!(await this.hasUsedTemplate(userId, templateId))) {
      throw new Error("You must use the template before reviewing");
    }

    // ë¦¬ë·° ì €ì¥
    await this.reviewService.addReview({
      templateId,
      userId,
      rating: review.rating,
      title: review.title,
      content: review.content,
      pros: review.pros,
      cons: review.cons,
      createdAt: new Date(),
    });

    // í‰ê·  í‰ì  ì¬ê³„ì‚°
    const avgRating =
      await this.reviewService.calculateAverageRating(templateId);
    await this.repository.updateTemplate(
      templateId,
      { rating: avgRating },
      "system"
    );

    // ì‘ì„±ìì—ê²Œ ì•Œë¦¼
    const template = await this.repository.getTemplate(templateId);
    if (template) {
      await this.notifyAuthor(template.author, "new_review", {
        templateId,
        reviewId: review.id,
        rating: review.rating,
      });
    }
  }

  private async performQualityCheck(
    template: WorkflowTemplate
  ): Promise<QualityCheckResult> {
    const issues: QualityIssue[] = [];

    // 1. ë¬¸ì„œí™” ê²€ì‚¬
    if (!template.description || template.description.length < 100) {
      issues.push({
        severity: "error",
        category: "documentation",
        message: "Description must be at least 100 characters",
      });
    }

    if (!template.examples || template.examples.length === 0) {
      issues.push({
        severity: "error",
        category: "documentation",
        message: "At least one example is required",
      });
    }

    // 2. íŒŒë¼ë¯¸í„° ê²€ì‚¬
    for (const param of template.parameters) {
      if (!param.description) {
        issues.push({
          severity: "warning",
          category: "parameters",
          message: `Parameter '${param.name}' lacks description`,
        });
      }
    }

    // 3. ë³´ì•ˆ ê²€ì‚¬
    const securityIssues = await this.checkSecurity(template);
    issues.push(...securityIssues);

    // 4. ì„±ëŠ¥ ê²€ì‚¬
    const performanceIssues = await this.checkPerformance(template);
    issues.push(...performanceIssues);

    // 5. ëª¨ë²” ì‚¬ë¡€ ê²€ì‚¬
    const bestPracticeIssues = await this.checkBestPractices(template);
    issues.push(...bestPracticeIssues);

    return {
      passed: issues.filter((i) => i.severity === "error").length === 0,
      issues,
      score: this.calculateQualityScore(issues),
    };
  }

  private async checkSecurity(
    template: WorkflowTemplate
  ): Promise<QualityIssue[]> {
    const issues: QualityIssue[] = [];
    const securityScanner = new TemplateSecurityScanner();

    // ë¯¼ê°í•œ ë°ì´í„° ë…¸ì¶œ ê²€ì‚¬
    const exposures = await securityScanner.findDataExposures(template);
    for (const exposure of exposures) {
      issues.push({
        severity: "error",
        category: "security",
        message: `Potential data exposure: ${exposure.description}`,
        location: exposure.location,
      });
    }

    // ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ê²€ì‚¬
    const escalations =
      await securityScanner.findPrivilegeEscalations(template);
    for (const escalation of escalations) {
      issues.push({
        severity: "warning",
        category: "security",
        message: `Potential privilege escalation: ${escalation.description}`,
        location: escalation.location,
      });
    }

    // ì¸ì ì…˜ ì·¨ì•½ì  ê²€ì‚¬
    const injections =
      await securityScanner.findInjectionVulnerabilities(template);
    for (const injection of injections) {
      issues.push({
        severity: "error",
        category: "security",
        message: `Potential injection vulnerability: ${injection.description}`,
        location: injection.location,
      });
    }

    return issues;
  }

  private async categorizeTemplate(
    template: WorkflowTemplate
  ): Promise<string> {
    const classifier = new TemplateCategorizer();

    // í…œí”Œë¦¿ ë‚´ìš© ë¶„ì„
    const features = await classifier.extractFeatures(template);

    // ML ëª¨ë¸ë¡œ ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡
    const predictions = await classifier.predict(features);

    // ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ì¹´í…Œê³ ë¦¬ ì„ íƒ
    return predictions[0].category;
  }

  private async generateTags(template: WorkflowTemplate): Promise<string[]> {
    const tagger = new TemplateAutoTagger();

    // ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ íƒœê·¸ ì¶”ì¶œ
    const tags = new Set<string>();

    // 1. ì—ì´ì „íŠ¸ íƒ€ì…ì—ì„œ ì¶”ì¶œ
    const agentTypes = this.extractAgentTypes(template);
    agentTypes.forEach((type) => tags.add(type.toLowerCase()));

    // 2. ê¸°ìˆ  ìŠ¤íƒì—ì„œ ì¶”ì¶œ
    const techStack = await tagger.detectTechnologyStack(template);
    techStack.forEach((tech) => tags.add(tech.toLowerCase()));

    // 3. ë„ë©”ì¸ í‚¤ì›Œë“œ ì¶”ì¶œ
    const domainKeywords = await tagger.extractDomainKeywords(template);
    domainKeywords.forEach((keyword) => tags.add(keyword.toLowerCase()));

    // 4. íŒ¨í„´ ì¸ì‹
    const patterns = await tagger.recognizePatterns(template);
    patterns.forEach((pattern) => tags.add(pattern.toLowerCase()));

    return Array.from(tags);
  }
}

// í…œí”Œë¦¿ ë¦¬ë·° ì„œë¹„ìŠ¤
export class TemplateReviewService {
  private reviewStore: ReviewStore;
  private sentimentAnalyzer: SentimentAnalyzer;
  private spamDetector: SpamDetector;

  async addReview(review: TemplateReview): Promise<void> {
    // ìŠ¤íŒ¸ ê²€ì‚¬
    if (await this.spamDetector.isSpam(review.content)) {
      throw new Error("Review appears to be spam");
    }

    // ê°ì • ë¶„ì„
    review.sentiment = await this.sentimentAnalyzer.analyze(review.content);

    // ìœ ìš©ì„± ì ìˆ˜ ì´ˆê¸°í™”
    review.helpfulCount = 0;
    review.totalVotes = 0;

    // ì €ì¥
    await this.reviewStore.save(review);

    // ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
    await this.extractInsights(review);
  }

  async voteReview(
    reviewId: string,
    userId: string,
    helpful: boolean
  ): Promise<void> {
    // ì¤‘ë³µ íˆ¬í‘œ ë°©ì§€
    if (await this.hasVoted(userId, reviewId)) {
      throw new Error("Already voted on this review");
    }

    // íˆ¬í‘œ ê¸°ë¡
    await this.reviewStore.recordVote(reviewId, userId, helpful);

    // ìœ ìš©ì„± ì—…ë°ì´íŠ¸
    const review = await this.reviewStore.get(reviewId);
    if (review) {
      if (helpful) {
        review.helpfulCount++;
      }
      review.totalVotes++;
      await this.reviewStore.update(review);
    }
  }

  private async extractInsights(review: TemplateReview): Promise<void> {
    const insights = new InsightExtractor();

    // ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
    const keywords = await insights.extractKeywords(review.content);

    // ê°œì„  ì œì•ˆ ì¶”ì¶œ
    const suggestions = await insights.extractSuggestions(review.content);

    // ê°ì • íŠ¸ë Œë“œ ë¶„ì„
    const sentimentTrend = await insights.analyzeSentimentTrend(
      review.templateId
    );

    // ì¸ì‚¬ì´íŠ¸ ì €ì¥
    await this.storeInsights({
      templateId: review.templateId,
      reviewId: review.id,
      keywords,
      suggestions,
      sentimentTrend,
    });
  }
}

// í…œí”Œë¦¿ ë¶„ì„ ì„œë¹„ìŠ¤
export class TemplateAnalyticsService {
  private metricsCollector: MetricsCollector;
  private trendAnalyzer: TrendAnalyzer;

  async recordUsage(
    templateId: string,
    userId: string,
    usage: TemplateUsage
  ): Promise<void> {
    await this.metricsCollector.record({
      type: "template_usage",
      templateId,
      userId,
      timestamp: new Date(),
      duration: usage.duration,
      success: usage.success,
      errors: usage.errors,
    });

    // ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ì—…ë°ì´íŠ¸
    await this.trendAnalyzer.updateTrend(templateId);
  }

  async getTemplateAnalytics(
    templateId: string,
    timeRange: TimeRange
  ): Promise<TemplateAnalytics> {
    const metrics = await this.metricsCollector.query({
      templateId,
      startTime: timeRange.start,
      endTime: timeRange.end,
    });

    return {
      downloads: metrics.downloads,
      uniqueUsers: metrics.uniqueUsers,
      successRate: metrics.successRate,
      averageDuration: metrics.averageDuration,
      errorRate: metrics.errorRate,
      userRetention: await this.calculateRetention(templateId, timeRange),
      geographicDistribution: await this.getGeographicDistribution(templateId),
      usagePatterns: await this.analyzeUsagePatterns(templateId),
      performanceTrends: await this.getPerformanceTrends(templateId, timeRange),
    };
  }

  async getTrendingTemplates(
    category?: string,
    limit: number = 10
  ): Promise<TrendingTemplate[]> {
    const trends = await this.trendAnalyzer.getTopTrends({
      category,
      metric: "composite", // ë‹¤ìš´ë¡œë“œ, í‰ì , ìµœê·¼ í™œë™ ì¢…í•©
      timeWindow: "7d",
      limit,
    });

    return trends.map((trend) => ({
      templateId: trend.entityId,
      score: trend.score,
      momentum: trend.momentum,
      rank: trend.rank,
      previousRank: trend.previousRank,
      metrics: {
        downloads: trend.metrics.downloads,
        rating: trend.metrics.rating,
        reviews: trend.metrics.reviews,
      },
    }));
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:

- [ ] í…œí”Œë¦¿ ë°œí–‰ ì‹œìŠ¤í…œ
- [ ] í’ˆì§ˆ ê²€ì‚¬ ë° ê²€ì¦
- [ ] ë¦¬ë·° ë° í‰ì  ì‹œìŠ¤í…œ
- [ ] ë¶„ì„ ë° íŠ¸ë Œë“œ ì¶”ì 

---
# Phase 5: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ - Tasks 5.7~5.9 SubTask êµ¬ì¡°

## ğŸ“‹ Task 5.7~5.9 SubTask ë¦¬ìŠ¤íŠ¸

### Task 5.7: ë¦¬ì†ŒìŠ¤ í’€ ê´€ë¦¬ ì‹œìŠ¤í…œ
- **SubTask 5.7.1**: ë¦¬ì†ŒìŠ¤ í’€ ì•„í‚¤í…ì²˜ ì„¤ê³„
- **SubTask 5.7.2**: ë¦¬ì†ŒìŠ¤ í• ë‹¹ ë° í•´ì œ ë©”ì»¤ë‹ˆì¦˜
- **SubTask 5.7.3**: ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ë° ì¶”ì 
- **SubTask 5.7.4**: ë¦¬ì†ŒìŠ¤ ìµœì í™” ë° ì¬ì¡°ì •

### Task 5.8: ì§€ëŠ¥í˜• ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
- **SubTask 5.8.1**: ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
- **SubTask 5.8.2**: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ í ì‹œìŠ¤í…œ
- **SubTask 5.8.3**: ì˜ˆì¸¡ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§
- **SubTask 5.8.4**: ìŠ¤ì¼€ì¤„ëŸ¬ ì„±ëŠ¥ ìµœì í™”

### Task 5.9: ë¶€í•˜ ë¶„ì‚° ë° ìë™ ìŠ¤ì¼€ì¼ë§
- **SubTask 5.9.1**: ë¶€í•˜ ë¶„ì‚° ì „ëµ êµ¬í˜„
- **SubTask 5.9.2**: ìë™ ìŠ¤ì¼€ì¼ë§ ì •ì±… ì—”ì§„
- **SubTask 5.9.3**: ë¦¬ì†ŒìŠ¤ ì˜ˆì¸¡ ë° ì‚¬ì „ í”„ë¡œë¹„ì €ë‹
- **SubTask 5.9.4**: ë©€í‹° ë¦¬ì „ ë¶„ì‚° ì²˜ë¦¬

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 5.7: ë¦¬ì†ŒìŠ¤ í’€ ê´€ë¦¬ ì‹œìŠ¤í…œ

#### SubTask 5.7.1: ë¦¬ì†ŒìŠ¤ í’€ ì•„í‚¤í…ì²˜ ì„¤ê³„
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/resources/resource_pool.ts
export enum ResourceType {
  CPU = 'cpu',
  MEMORY = 'memory',
  GPU = 'gpu',
  STORAGE = 'storage',
  NETWORK = 'network',
  AGENT = 'agent',
  CONTAINER = 'container',
  LAMBDA = 'lambda'
}

export interface ResourceUnit {
  id: string;
  type: ResourceType;
  capacity: number;
  unit: string; // 'cores', 'GB', 'Mbps', etc.
  available: number;
  allocated: number;
  metadata: Record<string, any>;
}

export interface ResourcePool {
  id: string;
  name: string;
  region: string;
  resources: Map<ResourceType, ResourceUnit[]>;
  policies: ResourcePolicy[];
  constraints: ResourceConstraint[];
  status: PoolStatus;
  metrics: PoolMetrics;
}

export class ResourcePoolManager {
  private pools: Map<string, ResourcePool> = new Map();
  private allocator: ResourceAllocator;
  private monitor: ResourceMonitor;
  private optimizer: ResourceOptimizer;
  
  constructor(config: ResourcePoolConfig) {
    this.allocator = new ResourceAllocator(config.allocation);
    this.monitor = new ResourceMonitor(config.monitoring);
    this.optimizer = new ResourceOptimizer(config.optimization);
  }

  async createPool(poolConfig: PoolConfiguration): Promise<ResourcePool> {
    const pool: ResourcePool = {
      id: this.generatePoolId(poolConfig.name),
      name: poolConfig.name,
      region: poolConfig.region,
      resources: new Map(),
      policies: poolConfig.policies || [],
      constraints: poolConfig.constraints || [],
      status: PoolStatus.INITIALIZING,
      metrics: {
        totalCapacity: {},
        currentUsage: {},
        peakUsage: {},
        efficiency: 0,
        lastUpdated: new Date()
      }
    };

    // ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”
    for (const resourceDef of poolConfig.resources) {
      await this.initializeResource(pool, resourceDef);
    }

    // ì •ì±… ê²€ì¦
    await this.validatePolicies(pool);

    // ëª¨ë‹ˆí„°ë§ ì‹œì‘
    await this.monitor.startMonitoring(pool);

    // í’€ ë“±ë¡
    this.pools.set(pool.id, pool);
    pool.status = PoolStatus.ACTIVE;

    logger.info(`Resource pool created: ${pool.id}`);
    return pool;
  }

  private async initializeResource(
    pool: ResourcePool,
    resourceDef: ResourceDefinition
  ): Promise<void> {
    const resources: ResourceUnit[] = [];

    switch (resourceDef.type) {
      case ResourceType.CPU:
        resources.push(...await this.initializeCPUResources(resourceDef));
        break;
      
      case ResourceType.MEMORY:
        resources.push(...await this.initializeMemoryResources(resourceDef));
        break;
      
      case ResourceType.GPU:
        resources.push(...await this.initializeGPUResources(resourceDef));
        break;
      
      case ResourceType.AGENT:
        resources.push(...await this.initializeAgentResources(resourceDef));
        break;
      
      case ResourceType.CONTAINER:
        resources.push(...await this.initializeContainerResources(resourceDef));
        break;
      
      case ResourceType.LAMBDA:
        resources.push(...await this.initializeLambdaResources(resourceDef));
        break;
    }

    pool.resources.set(resourceDef.type, resources);
  }

  private async initializeCPUResources(
    def: ResourceDefinition
  ): Promise<ResourceUnit[]> {
    const cpuResources: ResourceUnit[] = [];
    const nodeInfo = await this.getNodeInformation();

    for (const node of nodeInfo) {
      const cpuResource: ResourceUnit = {
        id: `cpu-${node.id}`,
        type: ResourceType.CPU,
        capacity: node.cpuCores * def.overcommitRatio,
        unit: 'cores',
        available: node.cpuCores * def.overcommitRatio,
        allocated: 0,
        metadata: {
          nodeId: node.id,
          architecture: node.cpuArchitecture,
          model: node.cpuModel,
          frequency: node.cpuFrequency,
          numa: node.numaNodes,
          hyperthreading: node.hyperthreadingEnabled
        }
      };

      cpuResources.push(cpuResource);
    }

    return cpuResources;
  }

  async allocateResources(
    request: ResourceRequest
  ): Promise<ResourceAllocation> {
    const startTime = Date.now();

    try {
      // 1. ìš”ì²­ ê²€ì¦
      const validation = await this.validateRequest(request);
      if (!validation.valid) {
        throw new ResourceValidationError(validation.errors);
      }

      // 2. ì í•©í•œ í’€ ì°¾ê¸°
      const candidatePools = await this.findCandidatePools(request);
      if (candidatePools.length === 0) {
        throw new NoResourceAvailableError('No suitable resource pool found');
      }

      // 3. ìµœì  í’€ ì„ íƒ
      const selectedPool = await this.selectOptimalPool(
        candidatePools,
        request
      );

      // 4. ë¦¬ì†ŒìŠ¤ í• ë‹¹
      const allocation = await this.allocator.allocate(
        selectedPool,
        request
      );

      // 5. í• ë‹¹ ê¸°ë¡
      await this.recordAllocation(allocation);

      // 6. ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
      await this.updateMetrics(selectedPool, allocation);

      logger.info(`Resources allocated: ${allocation.id}`, {
        poolId: selectedPool.id,
        duration: Date.now() - startTime
      });

      return allocation;

    } catch (error) {
      logger.error('Resource allocation failed', { error, request });
      throw error;
    }
  }

  private async findCandidatePools(
    request: ResourceRequest
  ): Promise<ResourcePool[]> {
    const candidates: ResourcePool[] = [];

    for (const pool of this.pools.values()) {
      // ìƒíƒœ í™•ì¸
      if (pool.status !== PoolStatus.ACTIVE) {
        continue;
      }

      // ë¦¬ì „ í™•ì¸
      if (request.regionPreference && 
          !this.matchesRegion(pool.region, request.regionPreference)) {
        continue;
      }

      // ë¦¬ì†ŒìŠ¤ ê°€ìš©ì„± í™•ì¸
      if (await this.hasAvailableResources(pool, request)) {
        candidates.push(pool);
      }
    }

    return candidates;
  }

  private async hasAvailableResources(
    pool: ResourcePool,
    request: ResourceRequest
  ): Promise<boolean> {
    for (const requirement of request.requirements) {
      const resources = pool.resources.get(requirement.type);
      
      if (!resources) {
        return false;
      }

      const availableCapacity = resources.reduce(
        (sum, resource) => sum + resource.available,
        0
      );

      if (availableCapacity < requirement.amount) {
        return false;
      }
    }

    return true;
  }

  private async selectOptimalPool(
    candidates: ResourcePool[],
    request: ResourceRequest
  ): Promise<ResourcePool> {
    const scores = new Map<string, number>();

    for (const pool of candidates) {
      const score = await this.calculatePoolScore(pool, request);
      scores.set(pool.id, score);
    }

    // ìµœê³  ì ìˆ˜ í’€ ì„ íƒ
    const sorted = Array.from(scores.entries())
      .sort((a, b) => b[1] - a[1]);

    const selectedId = sorted[0][0];
    return candidates.find(p => p.id === selectedId)!;
  }

  private async calculatePoolScore(
    pool: ResourcePool,
    request: ResourceRequest
  ): Promise<number> {
    let score = 100;

    // 1. í™œìš©ë¥  (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
    const utilization = this.calculateUtilization(pool);
    score -= utilization * 0.3;

    // 2. ì§€ì—­ì„± (ê°™ì€ ë¦¬ì „ì´ë©´ ê°€ì‚°ì )
    if (request.regionPreference === pool.region) {
      score += 20;
    }

    // 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­
    const performanceScore = await this.getPerformanceScore(pool);
    score += performanceScore * 0.2;

    // 4. ë¹„ìš© (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
    const costScore = await this.calculateCostScore(pool, request);
    score += costScore * 0.3;

    // 5. ì¹œí™”ì„± ê·œì¹™
    const affinityScore = this.calculateAffinityScore(pool, request);
    score += affinityScore * 0.2;

    return Math.max(0, Math.min(100, score));
  }
}

// ë¦¬ì†ŒìŠ¤ ì •ì±…
export interface ResourcePolicy {
  id: string;
  name: string;
  type: PolicyType;
  rules: PolicyRule[];
  priority: number;
  enabled: boolean;
}

export enum PolicyType {
  ALLOCATION = 'allocation',
  SCALING = 'scaling',
  EVICTION = 'eviction',
  RESERVATION = 'reservation',
  QUOTA = 'quota'
}

export class ResourcePolicyEngine {
  private policies: Map<string, ResourcePolicy[]> = new Map();

  async evaluateAllocationPolicy(
    pool: ResourcePool,
    request: ResourceRequest
  ): Promise<PolicyDecision> {
    const poolPolicies = this.policies.get(pool.id) || [];
    const applicablePolicies = poolPolicies
      .filter(p => p.type === PolicyType.ALLOCATION && p.enabled)
      .sort((a, b) => b.priority - a.priority);

    for (const policy of applicablePolicies) {
      const decision = await this.evaluatePolicy(policy, {
        pool,
        request,
        currentState: await this.getCurrentState(pool)
      });

      if (decision.action === 'deny') {
        return decision;
      }

      if (decision.modifications) {
        this.applyModifications(request, decision.modifications);
      }
    }

    return { action: 'allow', reason: 'All policies passed' };
  }

  private async evaluatePolicy(
    policy: ResourcePolicy,
    context: PolicyContext
  ): Promise<PolicyDecision> {
    const results: RuleResult[] = [];

    for (const rule of policy.rules) {
      const result = await this.evaluateRule(rule, context);
      results.push(result);

      if (rule.stopOnMatch && result.matched) {
        break;
      }
    }

    // ì •ì±… ê²°ì • ë¡œì§
    return this.makeDecision(policy, results);
  }

  private async evaluateRule(
    rule: PolicyRule,
    context: PolicyContext
  ): Promise<RuleResult> {
    const evaluator = new RuleEvaluator();
    
    try {
      const matched = await evaluator.evaluate(rule.condition, context);
      
      if (matched) {
        return {
          matched: true,
          action: rule.action,
          modifications: rule.modifications,
          message: rule.message
        };
      }

      return { matched: false };

    } catch (error) {
      logger.error('Rule evaluation failed', { rule, error });
      return { 
        matched: false, 
        error: error.message 
      };
    }
  }
}

// ë¦¬ì†ŒìŠ¤ ì œì•½
export interface ResourceConstraint {
  id: string;
  type: ConstraintType;
  target: ConstraintTarget;
  operator: ConstraintOperator;
  value: any;
  enforcement: 'soft' | 'hard';
}

export enum ConstraintType {
  AFFINITY = 'affinity',
  ANTI_AFFINITY = 'anti_affinity',
  LOCATION = 'location',
  CAPABILITY = 'capability',
  ISOLATION = 'isolation'
}

export class ResourceConstraintEvaluator {
  async evaluate(
    constraints: ResourceConstraint[],
    allocation: CandidateAllocation
  ): Promise<ConstraintResult> {
    const violations: ConstraintViolation[] = [];
    let score = 100;

    for (const constraint of constraints) {
      const result = await this.evaluateConstraint(constraint, allocation);
      
      if (!result.satisfied) {
        if (constraint.enforcement === 'hard') {
          violations.push({
            constraint,
            reason: result.reason,
            severity: 'error'
          });
        } else {
          violations.push({
            constraint,
            reason: result.reason,
            severity: 'warning'
          });
          score -= result.penalty || 10;
        }
      } else if (result.bonus) {
        score += result.bonus;
      }
    }

    return {
      satisfied: violations.filter(v => v.severity === 'error').length === 0,
      violations,
      score: Math.max(0, Math.min(100, score))
    };
  }

  private async evaluateConstraint(
    constraint: ResourceConstraint,
    allocation: CandidateAllocation
  ): Promise<SingleConstraintResult> {
    switch (constraint.type) {
      case ConstraintType.AFFINITY:
        return this.evaluateAffinity(constraint, allocation);
      
      case ConstraintType.ANTI_AFFINITY:
        return this.evaluateAntiAffinity(constraint, allocation);
      
      case ConstraintType.LOCATION:
        return this.evaluateLocation(constraint, allocation);
      
      case ConstraintType.CAPABILITY:
        return this.evaluateCapability(constraint, allocation);
      
      case ConstraintType.ISOLATION:
        return this.evaluateIsolation(constraint, allocation);
      
      default:
        return { satisfied: true };
    }
  }

  private async evaluateAffinity(
    constraint: ResourceConstraint,
    allocation: CandidateAllocation
  ): Promise<SingleConstraintResult> {
    // ì¹œí™”ì„± ê·œì¹™: íŠ¹ì • ë¦¬ì†ŒìŠ¤ì™€ í•¨ê»˜ ë°°ì¹˜
    const targetResources = await this.findTargetResources(
      constraint.target
    );

    for (const resource of allocation.resources) {
      const colocated = this.isColocated(resource, targetResources);
      
      if (!colocated && constraint.enforcement === 'hard') {
        return {
          satisfied: false,
          reason: `Resource ${resource.id} not colocated with target`
        };
      }
    }

    return { satisfied: true };
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë¦¬ì†ŒìŠ¤ í’€ ìƒì„± ë° ê´€ë¦¬
- [ ] ë‹¤ì–‘í•œ ë¦¬ì†ŒìŠ¤ íƒ€ì… ì§€ì›
- [ ] ì •ì±… ë° ì œì•½ ì‹œìŠ¤í…œ
- [ ] ìµœì  í’€ ì„ íƒ ì•Œê³ ë¦¬ì¦˜

#### SubTask 5.7.2: ë¦¬ì†ŒìŠ¤ í• ë‹¹ ë° í•´ì œ ë©”ì»¤ë‹ˆì¦˜
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/resources/resource_allocator.ts
export interface AllocationStrategy {
  name: string;
  allocate(
    pool: ResourcePool,
    request: ResourceRequest
  ): Promise<ResourceAllocation>;
  deallocate(
    pool: ResourcePool,
    allocation: ResourceAllocation
  ): Promise<void>;
}

export class ResourceAllocator {
  private strategies: Map<string, AllocationStrategy>;
  private lockManager: ResourceLockManager;
  private allocationTracker: AllocationTracker;
  
  constructor(config: AllocatorConfig) {
    this.strategies = new Map();
    this.lockManager = new ResourceLockManager();
    this.allocationTracker = new AllocationTracker();
    
    // ì „ëµ ë“±ë¡
    this.registerStrategy('first-fit', new FirstFitStrategy());
    this.registerStrategy('best-fit', new BestFitStrategy());
    this.registerStrategy('worst-fit', new WorstFitStrategy());
    this.registerStrategy('round-robin', new RoundRobinStrategy());
    this.registerStrategy('bin-packing', new BinPackingStrategy());
  }

  async allocate(
    pool: ResourcePool,
    request: ResourceRequest
  ): Promise<ResourceAllocation> {
    // 1. ì „ëµ ì„ íƒ
    const strategy = this.selectStrategy(request);
    
    // 2. ë¦¬ì†ŒìŠ¤ ì ê¸ˆ
    const locks = await this.acquireLocks(pool, request);
    
    try {
      // 3. í• ë‹¹ ìˆ˜í–‰
      const allocation = await strategy.allocate(pool, request);
      
      // 4. í• ë‹¹ ì¶”ì 
      await this.allocationTracker.track(allocation);
      
      // 5. ë¦¬ì†ŒìŠ¤ ìƒíƒœ ì—…ë°ì´íŠ¸
      await this.updateResourceStates(pool, allocation);
      
      // 6. ì´ë²¤íŠ¸ ë°œí–‰
      await this.publishAllocationEvent(allocation);
      
      return allocation;
      
    } catch (error) {
      // ë¡¤ë°±
      await this.rollbackAllocation(pool, request);
      throw error;
      
    } finally {
      // ì ê¸ˆ í•´ì œ
      await this.releaseLocks(locks);
    }
  }

  async deallocate(
    allocationId: string
  ): Promise<void> {
    const allocation = await this.allocationTracker.get(allocationId);
    
    if (!allocation) {
      throw new AllocationNotFoundError(allocationId);
    }

    const pool = await this.getPool(allocation.poolId);
    const strategy = this.strategies.get(allocation.strategy)!;
    
    // 1. ë¦¬ì†ŒìŠ¤ ì ê¸ˆ
    const locks = await this.acquireDeallocationLocks(allocation);
    
    try {
      // 2. í•´ì œ ì „ ê²€ì¦
      await this.validateDeallocation(allocation);
      
      // 3. í•´ì œ ìˆ˜í–‰
      await strategy.deallocate(pool, allocation);
      
      // 4. ë¦¬ì†ŒìŠ¤ ìƒíƒœ ì—…ë°ì´íŠ¸
      await this.releaseResourceStates(pool, allocation);
      
      // 5. ì¶”ì  ì œê±°
      await this.allocationTracker.remove(allocationId);
      
      // 6. ì´ë²¤íŠ¸ ë°œí–‰
      await this.publishDeallocationEvent(allocation);
      
    } finally {
      await this.releaseLocks(locks);
    }
  }

  private async acquireLocks(
    pool: ResourcePool,
    request: ResourceRequest
  ): Promise<ResourceLock[]> {
    const locks: ResourceLock[] = [];
    
    for (const requirement of request.requirements) {
      const resources = pool.resources.get(requirement.type);
      
      if (!resources) continue;
      
      // í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì ê¸ˆ íšë“
      const resourceLocks = await this.lockManager.acquireMultiple(
        resources.map(r => ({
          resourceId: r.id,
          lockType: 'write',
          timeout: 30000
        }))
      );
      
      locks.push(...resourceLocks);
    }
    
    return locks;
  }

  private async updateResourceStates(
    pool: ResourcePool,
    allocation: ResourceAllocation
  ): Promise<void> {
    for (const allocated of allocation.allocatedResources) {
      const resources = pool.resources.get(allocated.type);
      const resource = resources?.find(r => r.id === allocated.resourceId);
      
      if (resource) {
        resource.allocated += allocated.amount;
        resource.available = resource.capacity - resource.allocated;
        
        // ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        resource.metadata.lastAllocation = {
          allocationId: allocation.id,
          timestamp: new Date(),
          amount: allocated.amount
        };
      }
    }
    
    // í’€ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    pool.metrics.currentUsage = this.calculateCurrentUsage(pool);
    pool.metrics.lastUpdated = new Date();
  }
}

// First-Fit ì „ëµ
export class FirstFitStrategy implements AllocationStrategy {
  name = 'first-fit';

  async allocate(
    pool: ResourcePool,
    request: ResourceRequest
  ): Promise<ResourceAllocation> {
    const allocation: ResourceAllocation = {
      id: uuid(),
      requestId: request.id,
      poolId: pool.id,
      strategy: this.name,
      allocatedResources: [],
      status: 'allocated',
      createdAt: new Date(),
      expiresAt: request.duration 
        ? new Date(Date.now() + request.duration) 
        : undefined
    };

    for (const requirement of request.requirements) {
      const allocated = await this.allocateRequirement(
        pool,
        requirement
      );
      
      if (!allocated) {
        throw new InsufficientResourceError(
          `Cannot allocate ${requirement.amount} ${requirement.type}`
        );
      }
      
      allocation.allocatedResources.push(...allocated);
    }

    return allocation;
  }

  private async allocateRequirement(
    pool: ResourcePool,
    requirement: ResourceRequirement
  ): Promise<AllocatedResource[] | null> {
    const resources = pool.resources.get(requirement.type);
    if (!resources) return null;

    const allocated: AllocatedResource[] = [];
    let remaining = requirement.amount;

    // First-fit: ì²« ë²ˆì§¸ ê°€ìš© ë¦¬ì†ŒìŠ¤ë¶€í„° í• ë‹¹
    for (const resource of resources) {
      if (remaining <= 0) break;
      
      if (resource.available > 0) {
        const toAllocate = Math.min(resource.available, remaining);
        
        allocated.push({
          resourceId: resource.id,
          type: requirement.type,
          amount: toAllocate,
          metadata: requirement.metadata
        });
        
        remaining -= toAllocate;
      }
    }

    return remaining === 0 ? allocated : null;
  }

  async deallocate(
    pool: ResourcePool,
    allocation: ResourceAllocation
  ): Promise<void> {
    for (const allocated of allocation.allocatedResources) {
      const resources = pool.resources.get(allocated.type);
      const resource = resources?.find(r => r.id === allocated.resourceId);
      
      if (resource) {
        resource.allocated -= allocated.amount;
        resource.available += allocated.amount;
      }
    }
  }
}

// Best-Fit ì „ëµ
export class BestFitStrategy implements AllocationStrategy {
  name = 'best-fit';

  async allocate(
    pool: ResourcePool,
    request: ResourceRequest
  ): Promise<ResourceAllocation> {
    const allocation: ResourceAllocation = {
      id: uuid(),
      requestId: request.id,
      poolId: pool.id,
      strategy: this.name,
      allocatedResources: [],
      status: 'allocated',
      createdAt: new Date()
    };

    for (const requirement of request.requirements) {
      const allocated = await this.allocateBestFit(
        pool,
        requirement
      );
      
      if (!allocated) {
        throw new InsufficientResourceError(
          `Cannot allocate ${requirement.amount} ${requirement.type}`
        );
      }
      
      allocation.allocatedResources.push(...allocated);
    }

    return allocation;
  }

  private async allocateBestFit(
    pool: ResourcePool,
    requirement: ResourceRequirement
  ): Promise<AllocatedResource[] | null> {
    const resources = pool.resources.get(requirement.type);
    if (!resources) return null;

    // Best-fit: ê°€ì¥ ì í•©í•œ í¬ê¸°ì˜ ë¦¬ì†ŒìŠ¤ ì°¾ê¸°
    const candidates = resources
      .filter(r => r.available >= requirement.amount)
      .sort((a, b) => a.available - b.available);

    if (candidates.length === 0) {
      // ë‹¨ì¼ ë¦¬ì†ŒìŠ¤ë¡œ ì¶©ì¡± ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ë¶„í•  í• ë‹¹
      return this.allocateFragmented(resources, requirement);
    }

    const bestFit = candidates[0];
    
    return [{
      resourceId: bestFit.id,
      type: requirement.type,
      amount: requirement.amount,
      metadata: requirement.metadata
    }];
  }

  private allocateFragmented(
    resources: ResourceUnit[],
    requirement: ResourceRequirement
  ): AllocatedResource[] | null {
    // ê°€ìš© ë¦¬ì†ŒìŠ¤ë¥¼ í¬ê¸° ìˆœìœ¼ë¡œ ì •ë ¬
    const sorted = resources
      .filter(r => r.available > 0)
      .sort((a, b) => b.available - a.available);

    const allocated: AllocatedResource[] = [];
    let remaining = requirement.amount;

    for (const resource of sorted) {
      if (remaining <= 0) break;
      
      const toAllocate = Math.min(resource.available, remaining);
      
      allocated.push({
        resourceId: resource.id,
        type: requirement.type,
        amount: toAllocate,
        metadata: requirement.metadata
      });
      
      remaining -= toAllocate;
    }

    return remaining === 0 ? allocated : null;
  }

  async deallocate(
    pool: ResourcePool,
    allocation: ResourceAllocation
  ): Promise<void> {
    // First-Fitê³¼ ë™ì¼í•œ í•´ì œ ë¡œì§
    for (const allocated of allocation.allocatedResources) {
      const resources = pool.resources.get(allocated.type);
      const resource = resources?.find(r => r.id === allocated.resourceId);
      
      if (resource) {
        resource.allocated -= allocated.amount;
        resource.available += allocated.amount;
      }
    }
  }
}

// ë¦¬ì†ŒìŠ¤ ì˜ˆì•½ ì‹œìŠ¤í…œ
export class ResourceReservationSystem {
  private reservations: Map<string, ResourceReservation> = new Map();
  private scheduler: ReservationScheduler;

  constructor() {
    this.scheduler = new ReservationScheduler();
  }

  async reserve(
    request: ReservationRequest
  ): Promise<ResourceReservation> {
    // 1. ì˜ˆì•½ ê°€ëŠ¥ì„± í™•ì¸
    const availability = await this.checkAvailability(request);
    
    if (!availability.available) {
      throw new ReservationUnavailableError(availability.reason);
    }

    // 2. ì˜ˆì•½ ìƒì„±
    const reservation: ResourceReservation = {
      id: uuid(),
      requestId: request.id,
      poolId: request.poolId,
      resources: request.resources,
      startTime: request.startTime,
      endTime: request.endTime,
      status: 'pending',
      createdAt: new Date(),
      createdBy: request.userId
    };

    // 3. ì˜ˆì•½ ë“±ë¡
    this.reservations.set(reservation.id, reservation);

    // 4. ìŠ¤ì¼€ì¤„ë§
    await this.scheduler.schedule(reservation);

    // 5. ì•Œë¦¼ ì„¤ì •
    this.setupNotifications(reservation);

    return reservation;
  }

  async cancel(
    reservationId: string,
    reason?: string
  ): Promise<void> {
    const reservation = this.reservations.get(reservationId);
    
    if (!reservation) {
      throw new ReservationNotFoundError(reservationId);
    }

    // 1. ì·¨ì†Œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if (reservation.status === 'active') {
      throw new Error('Cannot cancel active reservation');
    }

    // 2. ì˜ˆì•½ ì·¨ì†Œ
    reservation.status = 'cancelled';
    reservation.cancelledAt = new Date();
    reservation.cancellationReason = reason;

    // 3. ìŠ¤ì¼€ì¤„ ì œê±°
    await this.scheduler.unschedule(reservationId);

    // 4. ë¦¬ì†ŒìŠ¤ í•´ì œ
    if (reservation.allocatedResources) {
      await this.releaseReservedResources(reservation);
    }

    // 5. ì•Œë¦¼ ë°œì†¡
    await this.notifyCancellation(reservation);
  }

  private async checkAvailability(
    request: ReservationRequest
  ): Promise<AvailabilityResult> {
    const pool = await this.getPool(request.poolId);
    
    // ì‹œê°„ëŒ€ë³„ ê°€ìš©ì„± í™•ì¸
    const timeline = await this.buildAvailabilityTimeline(
      pool,
      request.startTime,
      request.endTime
    );

    for (const requirement of request.resources) {
      const available = this.checkResourceAvailability(
        timeline,
        requirement
      );
      
      if (!available) {
        return {
          available: false,
          reason: `Insufficient ${requirement.type} during requested period`
        };
      }
    }

    return { available: true };
  }

  private async buildAvailabilityTimeline(
    pool: ResourcePool,
    startTime: Date,
    endTime: Date
  ): Promise<AvailabilityTimeline> {
    const timeline = new AvailabilityTimeline();

    // í˜„ì¬ í• ë‹¹ ìƒíƒœ
    timeline.addSnapshot(new Date(), pool.resources);

    // ê¸°ì¡´ ì˜ˆì•½ ë°˜ì˜
    const existingReservations = await this.getReservationsInPeriod(
      pool.id,
      startTime,
      endTime
    );

    for (const reservation of existingReservations) {
      timeline.addReservation(reservation);
    }

    // ì˜ˆì¸¡ëœ í•´ì œ ë°˜ì˜
    const predictedReleases = await this.predictReleases(
      pool.id,
      startTime,
      endTime
    );

    for (const release of predictedReleases) {
      timeline.addRelease(release);
    }

    return timeline;
  }
}

// í• ë‹¹ ì¶”ì ê¸°
export class AllocationTracker {
  private allocations: Map<string, TrackedAllocation> = new Map();
  private expirationQueue: PriorityQueue<string>;
  private metricsCollector: MetricsCollector;

  constructor() {
    this.expirationQueue = new PriorityQueue((a, b) => {
      const allocationA = this.allocations.get(a)!;
      const allocationB = this.allocations.get(b)!;
      return allocationA.expiresAt!.getTime() - allocationB.expiresAt!.getTime();
    });
    
    this.metricsCollector = new MetricsCollector();
    this.startExpirationMonitor();
  }

  async track(allocation: ResourceAllocation): Promise<void> {
    const tracked: TrackedAllocation = {
      ...allocation,
      trackingStarted: new Date(),
      lastHeartbeat: new Date(),
      metrics: {
        cpuUsage: [],
        memoryUsage: [],
        networkIO: [],
        diskIO: []
      }
    };

    this.allocations.set(allocation.id, tracked);

    if (allocation.expiresAt) {
      this.expirationQueue.enqueue(allocation.id);
    }

    // ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘
    this.metricsCollector.startCollecting(allocation.id);
  }

  async remove(allocationId: string): Promise<void> {
    const allocation = this.allocations.get(allocationId);
    
    if (allocation) {
      // ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ì§€
      this.metricsCollector.stopCollecting(allocationId);
      
      // ìµœì¢… ë©”íŠ¸ë¦­ ì €ì¥
      await this.saveMetrics(allocation);
      
      // ì¶”ì  ì œê±°
      this.allocations.delete(allocationId);
    }
  }

  private startExpirationMonitor(): void {
    setInterval(async () => {
      await this.checkExpirations();
    }, 10000); // 10ì´ˆë§ˆë‹¤ í™•ì¸
  }

  private async checkExpirations(): Promise<void> {
    const now = new Date();

    while (!this.expirationQueue.isEmpty()) {
      const allocationId = this.expirationQueue.peek()!;
      const allocation = this.allocations.get(allocationId);

      if (!allocation || !allocation.expiresAt) {
        this.expirationQueue.dequeue();
        continue;
      }

      if (allocation.expiresAt > now) {
        break; // ì•„ì§ ë§Œë£Œë˜ì§€ ì•ŠìŒ
      }

      // ë§Œë£Œëœ í• ë‹¹ ì²˜ë¦¬
      this.expirationQueue.dequeue();
      await this.handleExpiration(allocation);
    }
  }

  private async handleExpiration(
    allocation: TrackedAllocation
  ): Promise<void> {
    logger.info(`Allocation expired: ${allocation.id}`);

    // ìë™ í•´ì œ ì—¬ë¶€ í™•ì¸
    if (allocation.autoRelease) {
      await this.releaseAllocation(allocation.id);
    } else {
      // ë§Œë£Œ ì•Œë¦¼
      await this.notifyExpiration(allocation);
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ í• ë‹¹ ì „ëµ êµ¬í˜„
- [ ] ë¦¬ì†ŒìŠ¤ ì ê¸ˆ ë©”ì»¤ë‹ˆì¦˜
- [ ] ì˜ˆì•½ ì‹œìŠ¤í…œ
- [ ] í• ë‹¹ ì¶”ì  ë° ë§Œë£Œ ì²˜ë¦¬

#### SubTask 5.7.3: ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ë° ì¶”ì 
**ë‹´ë‹¹ì**: ëª¨ë‹ˆí„°ë§ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/resources/resource_monitor.ts
export class ResourceMonitor {
  private collectors: Map<ResourceType, MetricCollector> = new Map();
  private aggregator: MetricAggregator;
  private alertManager: AlertManager;
  private dashboardUpdater: DashboardUpdater;

  constructor(config: MonitorConfig) {
    this.aggregator = new MetricAggregator(config.aggregation);
    this.alertManager = new AlertManager(config.alerts);
    this.dashboardUpdater = new DashboardUpdater(config.dashboard);
    
    this.initializeCollectors();
  }

  private initializeCollectors(): void {
    this.collectors.set(ResourceType.CPU, new CPUCollector());
    this.collectors.set(ResourceType.MEMORY, new MemoryCollector());
    this.collectors.set(ResourceType.GPU, new GPUCollector());
    this.collectors.set(ResourceType.NETWORK, new NetworkCollector());
    this.collectors.set(ResourceType.STORAGE, new StorageCollector());
    this.collectors.set(ResourceType.AGENT, new AgentCollector());
  }

  async startMonitoring(pool: ResourcePool): Promise<void> {
    logger.info(`Starting monitoring for pool: ${pool.id}`);

    // ê° ë¦¬ì†ŒìŠ¤ íƒ€ì…ë³„ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    for (const [type, resources] of pool.resources) {
      const collector = this.collectors.get(type);
      
      if (collector) {
        for (const resource of resources) {
          await collector.startCollecting(resource);
        }
      }
    }

    // ì£¼ê¸°ì  ì§‘ê³„ ì‹œì‘
    this.scheduleAggregation(pool);

    // ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
    this.startRealtimeStream(pool);

    // ì•Œë¦¼ ê·œì¹™ ë“±ë¡
    await this.registerAlertRules(pool);
  }

  private scheduleAggregation(pool: ResourcePool): void {
    // 1ë¶„ ë‹¨ìœ„ ì§‘ê³„
    setInterval(async () => {
      await this.aggregateMetrics(pool, '1m');
    }, 60 * 1000);

    // 5ë¶„ ë‹¨ìœ„ ì§‘ê³„
    setInterval(async () => {
      await this.aggregateMetrics(pool, '5m');
    }, 5 * 60 * 1000);

    // 1ì‹œê°„ ë‹¨ìœ„ ì§‘ê³„
    setInterval(async () => {
      await this.aggregateMetrics(pool, '1h');
    }, 60 * 60 * 1000);
  }

  private async aggregateMetrics(
    pool: ResourcePool,
    interval: string
  ): Promise<void> {
    const metrics: PoolMetrics = {
      timestamp: new Date(),
      interval,
      resources: {}
    };

    for (const [type, resources] of pool.resources) {
      const collector = this.collectors.get(type);
      
      if (!collector) continue;

      const typeMetrics: ResourceTypeMetrics = {
        total: 0,
        used: 0,
        available: 0,
        utilization: 0,
        details: []
      };

      for (const resource of resources) {
        const resourceMetrics = await collector.getMetrics(
          resource.id,
          interval
        );

        typeMetrics.total += resource.capacity;
        typeMetrics.used += resource.allocated;
        typeMetrics.available += resource.available;
        
        typeMetrics.details.push({
          resourceId: resource.id,
          metrics: resourceMetrics
        });
      }

      typeMetrics.utilization = (typeMetrics.used / typeMetrics.total) * 100;
      metrics.resources[type] = typeMetrics;
    }

    // ì§‘ê³„ëœ ë©”íŠ¸ë¦­ ì €ì¥
    await this.aggregator.save(pool.id, metrics);

    // ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸
    await this.dashboardUpdater.update(pool.id, metrics);

    // ì•Œë¦¼ í™•ì¸
    await this.checkAlerts(pool, metrics);
  }

  private async checkAlerts(
    pool: ResourcePool,
    metrics: PoolMetrics
  ): Promise<void> {
    const rules = await this.alertManager.getRules(pool.id);

    for (const rule of rules) {
      const triggered = await this.evaluateAlertRule(rule, metrics);
      
      if (triggered) {
        await this.alertManager.trigger({
          ruleId: rule.id,
          poolId: pool.id,
          severity: rule.severity,
          message: rule.message,
          metrics: this.extractRelevantMetrics(metrics, rule),
          timestamp: new Date()
        });
      }
    }
  }

  private async evaluateAlertRule(
    rule: AlertRule,
    metrics: PoolMetrics
  ): Promise<boolean> {
    switch (rule.condition.type) {
      case 'threshold':
        return this.evaluateThreshold(rule.condition, metrics);
      
      case 'rate':
        return this.evaluateRate(rule.condition, metrics);
      
      case 'anomaly':
        return this.evaluateAnomaly(rule.condition, metrics);
      
      case 'composite':
        return this.evaluateComposite(rule.condition, metrics);
      
      default:
        return false;
    }
  }

  private startRealtimeStream(pool: ResourcePool): void {
    const stream = new RealtimeMetricStream(pool.id);

    // ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    for (const [type, resources] of pool.resources) {
      const collector = this.collectors.get(type);
      
      if (!collector) continue;

      for (const resource of resources) {
        collector.onMetricUpdate(resource.id, (metric) => {
          stream.publish({
            resourceId: resource.id,
            type,
            metric,
            timestamp: new Date()
          });
        });
      }
    }

    // WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì „ì†¡
    stream.onSubscribe((client) => {
      logger.info(`Client subscribed to pool ${pool.id} metrics`);
    });
  }
}

// CPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
export class CPUCollector implements MetricCollector {
  private intervals: Map<string, NodeJS.Timer> = new Map();

  async startCollecting(resource: ResourceUnit): Promise<void> {
    const interval = setInterval(async () => {
      const metrics = await this.collectCPUMetrics(resource);
      await this.store(resource.id, metrics);
    }, 5000); // 5ì´ˆë§ˆë‹¤

    this.intervals.set(resource.id, interval);
  }

  async stopCollecting(resourceId: string): Promise<void> {
    const interval = this.intervals.get(resourceId);
    if (interval) {
      clearInterval(interval);
      this.intervals.delete(resourceId);
    }
  }

  private async collectCPUMetrics(
    resource: ResourceUnit
  ): Promise<CPUMetrics> {
    const nodeId = resource.metadata.nodeId;
    
    // ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    const usage = await this.getCPUUsage(nodeId);
    const temperature = await this.getCPUTemperature(nodeId);
    const frequency = await this.getCPUFrequency(nodeId);
    
    return {
      usage: {
        user: usage.user,
        system: usage.system,
        idle: usage.idle,
        iowait: usage.iowait,
        steal: usage.steal
      },
      temperature,
      frequency: {
        current: frequency.current,
        min: frequency.min,
        max: frequency.max
      },
      cores: {
        allocated: resource.allocated,
        available: resource.available,
        total: resource.capacity
      },
      processes: await this.getProcessCount(nodeId),
      loadAverage: await this.getLoadAverage(nodeId)
    };
  }

  async getMetrics(
    resourceId: string,
    interval: string
  ): Promise<AggregatedMetrics> {
    const raw = await this.getRawMetrics(resourceId, interval);
    
    return {
      avg: this.calculateAverage(raw),
      min: this.calculateMin(raw),
      max: this.calculateMax(raw),
      p50: this.calculatePercentile(raw, 50),
      p90: this.calculatePercentile(raw, 90),
      p99: this.calculatePercentile(raw, 99),
      stdDev: this.calculateStdDev(raw)
    };
  }
}

// ë¦¬ì†ŒìŠ¤ ì¶”ì  ì‹œìŠ¤í…œ
export class ResourceTracker {
  private history: Map<string, ResourceHistory> = new Map();
  private changeDetector: ChangeDetector;
  private predictiveAnalyzer: PredictiveAnalyzer;

  constructor() {
    this.changeDetector = new ChangeDetector();
    this.predictiveAnalyzer = new PredictiveAnalyzer();
  }

  async trackChange(
    poolId: string,
    change: ResourceChange
  ): Promise<void> {
    let history = this.history.get(poolId);
    
    if (!history) {
      history = {
        poolId,
        changes: [],
        snapshots: []
      };
      this.history.set(poolId, history);
    }

    // ë³€ê²½ ì‚¬í•­ ê¸°ë¡
    history.changes.push({
      ...change,
      timestamp: new Date()
    });

    // ìŠ¤ëƒ…ìƒ· ìƒì„± (ì£¼ìš” ë³€ê²½ ì‹œ)
    if (this.isSignificantChange(change)) {
      const snapshot = await this.createSnapshot(poolId);
      history.snapshots.push(snapshot);
    }

    // ì´ìƒ íƒì§€
    const anomaly = await this.changeDetector.detect(change, history);
    if (anomaly) {
      await this.handleAnomaly(anomaly);
    }

    // ì˜ˆì¸¡ ëª¨ë¸ ì—…ë°ì´íŠ¸
    await this.predictiveAnalyzer.updateModel(poolId, history);
  }

  async getHistory(
    poolId: string,
    options: HistoryOptions
  ): Promise<ResourceHistory> {
    const history = this.history.get(poolId);
    
    if (!history) {
      return { poolId, changes: [], snapshots: [] };
    }

    // ì‹œê°„ ë²”ìœ„ í•„í„°ë§
    let filtered = history;
    
    if (options.startTime || options.endTime) {
      filtered = this.filterByTimeRange(
        history,
        options.startTime,
        options.endTime
      );
    }

    // ë³€ê²½ íƒ€ì… í•„í„°ë§
    if (options.changeTypes) {
      filtered = this.filterByChangeType(
        filtered,
        options.changeTypes
      );
    }

    return filtered;
  }

  async predictUsage(
    poolId: string,
    timeframe: number
  ): Promise<UsagePrediction> {
    const history = this.history.get(poolId);
    
    if (!history || history.changes.length < 100) {
      return {
        confidence: 0,
        predictions: [],
        reasoning: 'Insufficient historical data'
      };
    }

    return this.predictiveAnalyzer.predict(
      history,
      timeframe
    );
  }

  private isSignificantChange(change: ResourceChange): boolean {
    // ì£¼ìš” ë³€ê²½ ì‚¬í•­ íŒë‹¨ ë¡œì§
    if (change.type === 'allocation' && change.amount > 100) {
      return true;
    }
    
    if (change.type === 'pool_resize') {
      return true;
    }
    
    if (change.type === 'failure') {
      return true;
    }
    
    return false;
  }

  private async createSnapshot(poolId: string): Promise<ResourceSnapshot> {
    const pool = await this.getPool(poolId);
    
    return {
      timestamp: new Date(),
      poolId,
      resources: this.serializeResources(pool.resources),
      metrics: { ...pool.metrics },
      allocations: await this.getCurrentAllocations(poolId)
    };
  }
}

// ëŒ€ì‹œë³´ë“œ ì—…ë°ì´í„°
export class DashboardUpdater {
  private websocketServer: WebSocketServer;
  private dashboardCache: Map<string, DashboardData> = new Map();

  constructor(config: DashboardConfig) {
    this.websocketServer = new WebSocketServer(config.wsPort);
  }

  async update(
    poolId: string,
    metrics: PoolMetrics
  ): Promise<void> {
    // ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¤€ë¹„
    const dashboardData = this.prepareDashboardData(poolId, metrics);
    
    // ìºì‹œ ì—…ë°ì´íŠ¸
    this.dashboardCache.set(poolId, dashboardData);
    
    // ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
    this.broadcast(poolId, dashboardData);
    
    // ì˜êµ¬ ì €ì¥ (íˆìŠ¤í† ë¦¬)
    await this.saveToDashboardHistory(poolId, dashboardData);
  }

  private prepareDashboardData(
    poolId: string,
    metrics: PoolMetrics
  ): DashboardData {
    return {
      poolId,
      timestamp: metrics.timestamp,
      summary: {
        totalResources: this.countTotalResources(metrics),
        utilization: this.calculateOverallUtilization(metrics),
        efficiency: this.calculateEfficiency(metrics),
        health: this.assessHealth(metrics)
      },
      resourceBreakdown: this.createResourceBreakdown(metrics),
      trends: this.calculateTrends(poolId, metrics),
      alerts: this.getActiveAlerts(poolId),
      recommendations: this.generateRecommendations(metrics)
    };
  }

  private createResourceBreakdown(
    metrics: PoolMetrics
  ): ResourceBreakdown[] {
    const breakdown: ResourceBreakdown[] = [];

    for (const [type, typeMetrics] of Object.entries(metrics.resources)) {
      breakdown.push({
        type: type as ResourceType,
        total: typeMetrics.total,
        used: typeMetrics.used,
        available: typeMetrics.available,
        utilization: typeMetrics.utilization,
        trend: this.calculateResourceTrend(type, typeMetrics),
        topConsumers: this.getTopConsumers(typeMetrics)
      });
    }

    return breakdown;
  }

  private calculateTrends(
    poolId: string,
    currentMetrics: PoolMetrics
  ): TrendData {
    const history = this.getHistoricalData(poolId);
    
    return {
      utilization: {
        current: currentMetrics.utilization,
        change1h: this.calculateChange(history, '1h', 'utilization'),
        change24h: this.calculateChange(history, '24h', 'utilization'),
        change7d: this.calculateChange(history, '7d', 'utilization'),
        forecast: this.forecastMetric(history, 'utilization', '24h')
      },
      allocations: {
        current: currentMetrics.activeAllocations,
        change1h: this.calculateChange(history, '1h', 'allocations'),
        change24h: this.calculateChange(history, '24h', 'allocations'),
        peak24h: this.findPeak(history, '24h', 'allocations')
      }
    };
  }

  private generateRecommendations(
    metrics: PoolMetrics
  ): Recommendation[] {
    const recommendations: Recommendation[] = [];

    // ê³ ì‚¬ìš©ë¥  ê²½ê³ 
    if (metrics.utilization > 80) {
      recommendations.push({
        type: 'scaling',
        priority: 'high',
        message: 'Resource utilization is high. Consider scaling up.',
        action: {
          type: 'scale_up',
          amount: Math.ceil(metrics.total * 0.3)
        }
      });
    }

    // ì €ì‚¬ìš©ë¥  ìµœì í™”
    if (metrics.utilization < 20 && metrics.age > 24 * 60 * 60 * 1000) {
      recommendations.push({
        type: 'optimization',
        priority: 'medium',
        message: 'Resource utilization is low. Consider scaling down.',
        action: {
          type: 'scale_down',
          amount: Math.floor(metrics.total * 0.3)
        }
      });
    }

    // ë¶ˆê· í˜• ê°ì§€
    const imbalance = this.detectImbalance(metrics);
    if (imbalance) {
      recommendations.push({
        type: 'rebalancing',
        priority: 'medium',
        message: `Resource imbalance detected: ${imbalance.description}`,
        action: {
          type: 'rebalance',
          target: imbalance.target
        }
      });
    }

    return recommendations;
  }

  private broadcast(poolId: string, data: DashboardData): void {
    const message = JSON.stringify({
      type: 'dashboard_update',
      poolId,
      data
    });

    this.websocketServer.broadcast(
      `/pools/${poolId}/dashboard`,
      message
    );
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
- [ ] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ìŠ¤íŠ¸ë¦¼
- [ ] ì´ìƒ íƒì§€ ë° ì•Œë¦¼
- [ ] ëŒ€ì‹œë³´ë“œ í†µí•©

#### SubTask 5.7.4: ë¦¬ì†ŒìŠ¤ ìµœì í™” ë° ì¬ì¡°ì •
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ìµœì í™” ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/resources/resource_optimizer.ts
export class ResourceOptimizer {
  private analyzer: ResourceAnalyzer;
  private rebalancer: ResourceRebalancer;
  private predictor: ResourcePredictor;
  private optimizer: OptimizationEngine;

  constructor(config: OptimizerConfig) {
    this.analyzer = new ResourceAnalyzer();
    this.rebalancer = new ResourceRebalancer();
    this.predictor = new ResourcePredictor();
    this.optimizer = new OptimizationEngine(config);
  }

  async optimizePool(
    pool: ResourcePool,
    objectives: OptimizationObjective[]
  ): Promise<OptimizationResult> {
    const startTime = Date.now();

    // 1. í˜„ì¬ ìƒíƒœ ë¶„ì„
    const analysis = await this.analyzer.analyze(pool);

    // 2. ìµœì í™” ê¸°íšŒ ì‹ë³„
    const opportunities = await this.identifyOpportunities(
      pool,
      analysis
    );

    // 3. ìµœì í™” ê³„íš ìˆ˜ë¦½
    const plan = await this.optimizer.createPlan(
      pool,
      opportunities,
      objectives
    );

    // 4. ê³„íš ì‹¤í–‰
    const result = await this.executePlan(pool, plan);

    // 5. ê²°ê³¼ í‰ê°€
    const evaluation = await this.evaluateResult(
      pool,
      result,
      objectives
    );

    return {
      poolId: pool.id,
      duration: Date.now() - startTime,
      plan,
      result,
      evaluation,
      improvements: this.calculateImprovements(analysis, evaluation)
    };
  }

  private async identifyOpportunities(
    pool: ResourcePool,
    analysis: PoolAnalysis
  ): Promise<OptimizationOpportunity[]> {
    const opportunities: OptimizationOpportunity[] = [];

    // 1. ì¡°ê°í™” ê°ì†Œ
    if (analysis.fragmentation > 0.3) {
      opportunities.push({
        type: 'defragmentation',
        priority: 'high',
        estimatedBenefit: {
          efficiency: 0.2,
          capacity: analysis.fragmentedCapacity
        },
        cost: {
          migrations: this.estimateMigrations(pool),
          downtime: 0
        }
      });
    }

    // 2. ë¶€í•˜ ì¬ë¶„ë°°
    const imbalance = analysis.loadImbalance;
    if (imbalance.score > 0.4) {
      opportunities.push({
        type: 'rebalancing',
        priority: 'medium',
        estimatedBenefit: {
          performance: 0.15,
          reliability: 0.1
        },
        cost: {
          migrations: imbalance.requiredMigrations,
          networkTraffic: imbalance.estimatedTraffic
        }
      });
    }

    // 3. ë¯¸ì‚¬ìš© ë¦¬ì†ŒìŠ¤ íšŒìˆ˜
    if (analysis.idleResources.length > 0) {
      opportunities.push({
        type: 'reclamation',
        priority: 'low',
        estimatedBenefit: {
          capacity: analysis.idleCapacity,
          cost: analysis.idleCost
        },
        cost: {
          processing: 'minimal'
        }
      });
    }

    // 4. ì˜ˆì¸¡ ê¸°ë°˜ ì‚¬ì „ ìŠ¤ì¼€ì¼ë§
    const prediction = await this.predictor.predictDemand(pool, 24);
    if (prediction.peakDemand > pool.capacity * 0.9) {
      opportunities.push({
        type: 'predictive_scaling',
        priority: 'high',
        estimatedBenefit: {
          availability: 0.99,
          performanceSLA: 0.95
        },
        cost: {
          additionalResources: prediction.requiredCapacity
        }
      });
    }

    return opportunities;
  }

  private async executePlan(
    pool: ResourcePool,
    plan: OptimizationPlan
  ): Promise<ExecutionResult> {
    const executor = new PlanExecutor(pool);
    const result: ExecutionResult = {
      steps: [],
      success: true,
      rollbacks: []
    };

    for (const step of plan.steps) {
      try {
        // ë‹¨ê³„ ì‹¤í–‰
        const stepResult = await executor.executeStep(step);
        result.steps.push(stepResult);

        // ê²€ì¦
        if (!await this.validateStep(pool, stepResult)) {
          throw new ValidationError(`Step ${step.id} validation failed`);
        }

      } catch (error) {
        // ë¡¤ë°±
        result.success = false;
        result.error = error;
        
        // ì´ì „ ë‹¨ê³„ë“¤ ë¡¤ë°±
        for (let i = result.steps.length - 1; i >= 0; i--) {
          const rollback = await executor.rollbackStep(result.steps[i]);
          result.rollbacks.push(rollback);
        }
        
        break;
      }
    }

    return result;
  }
}

// ë¦¬ì†ŒìŠ¤ ì¬ì¡°ì •ê¸°
export class ResourceRebalancer {
  async rebalance(
    pool: ResourcePool,
    strategy: RebalanceStrategy
  ): Promise<RebalanceResult> {
    switch (strategy) {
      case 'round-robin':
        return this.roundRobinRebalance(pool);
      
      case 'least-loaded':
        return this.leastLoadedRebalance(pool);
      
      case 'affinity-aware':
        return this.affinityAwareRebalance(pool);
      
      case 'cost-optimized':
        return this.costOptimizedRebalance(pool);
      
      default:
        throw new Error(`Unknown rebalance strategy: ${strategy}`);
    }
  }

  private async leastLoadedRebalance(
    pool: ResourcePool
  ): Promise<RebalanceResult> {
    const allocations = await this.getAllocations(pool);
    const migrations: Migration[] = [];

    // ë¦¬ì†ŒìŠ¤ë³„ ë¶€í•˜ ê³„ì‚°
    const loads = this.calculateResourceLoads(pool);
    
    // ë¶€í•˜ê°€ ë†’ì€ ë¦¬ì†ŒìŠ¤ì—ì„œ ë‚®ì€ ë¦¬ì†ŒìŠ¤ë¡œ ì´ë™
    const overloaded = loads.filter(l => l.utilization > 0.8);
    const underloaded = loads.filter(l => l.utilization < 0.4);

    for (const source of overloaded) {
      const candidates = allocations.filter(
        a => a.resourceId === source.resourceId
      );

      for (const allocation of candidates) {
        // ì í•©í•œ ëŒ€ìƒ ì°¾ê¸°
        const target = this.findBestTarget(
          allocation,
          underloaded,
          pool
        );

        if (target) {
          migrations.push({
            allocationId: allocation.id,
            from: source.resourceId,
            to: target.resourceId,
            size: allocation.amount,
            estimatedDuration: this.estimateMigrationTime(allocation)
          });

          // ë¶€í•˜ ì—…ë°ì´íŠ¸
          source.utilization -= allocation.amount / source.capacity;
          target.utilization += allocation.amount / target.capacity;

          if (source.utilization <= 0.7) break;
        }
      }
    }

    // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    return this.executeMigrations(migrations);
  }

  private async executeMigrations(
    migrations: Migration[]
  ): Promise<RebalanceResult> {
    const results: MigrationResult[] = [];
    const startTime = Date.now();

    // ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì´ê·¸ë ˆì´ì…˜ ê·¸ë£¹í™”
    const groups = this.groupMigrations(migrations);

    for (const group of groups) {
      const groupResults = await Promise.all(
        group.map(m => this.executeMigration(m))
      );
      results.push(...groupResults);
    }

    return {
      totalMigrations: migrations.length,
      successfulMigrations: results.filter(r => r.success).length,
      failedMigrations: results.filter(r => !r.success).length,
      duration: Date.now() - startTime,
      details: results
    };
  }

  private groupMigrations(
    migrations: Migration[]
  ): Migration[][] {
    // ì˜ì¡´ì„±ì´ ì—†ëŠ” ë§ˆì´ê·¸ë ˆì´ì…˜ë¼ë¦¬ ê·¸ë£¹í™”
    const groups: Migration[][] = [];
    const processed = new Set<string>();

    while (processed.size < migrations.length) {
      const group: Migration[] = [];

      for (const migration of migrations) {
        if (processed.has(migration.allocationId)) continue;

        // ê°™ì€ ë¦¬ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ë‹¤ë¥¸ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì—†ëŠ”ì§€ í™•ì¸
        const hasConflict = group.some(
          g => g.from === migration.from || 
               g.to === migration.to ||
               g.from === migration.to ||
               g.to === migration.from
        );

        if (!hasConflict) {
          group.push(migration);
          processed.add(migration.allocationId);
        }
      }

      if (group.length > 0) {
        groups.push(group);
      }
    }

    return groups;
  }
}

// ì¡°ê°í™” ì œê±°ê¸°
export class DefragmentationEngine {
  async defragment(
    pool: ResourcePool,
    options: DefragOptions = {}
  ): Promise<DefragResult> {
    const startTime = Date.now();

    // 1. ì¡°ê°í™” ë¶„ì„
    const fragmentation = await this.analyzeFragmentation(pool);

    if (fragmentation.score < (options.threshold || 0.2)) {
      return {
        needed: false,
        fragmentationBefore: fragmentation.score,
        message: 'Fragmentation below threshold'
      };
    }

    // 2. ì¡°ê°í™” ì œê±° ê³„íš
    const plan = this.createDefragPlan(pool, fragmentation);

    // 3. ì‹¤í–‰
    const result = await this.executeDefragPlan(plan, options);

    // 4. ê²°ê³¼ ë¶„ì„
    const newFragmentation = await this.analyzeFragmentation(pool);

    return {
      needed: true,
      fragmentationBefore: fragmentation.score,
      fragmentationAfter: newFragmentation.score,
      duration: Date.now() - startTime,
      compactedAllocations: result.compacted,
      freedCapacity: result.freedCapacity
    };
  }

  private async analyzeFragmentation(
    pool: ResourcePool
  ): Promise<FragmentationAnalysis> {
    const analysis: FragmentationAnalysis = {
      score: 0,
      fragments: [],
      largestFreeBlock: 0,
      totalFreeSpace: 0
    };

    for (const [type, resources] of pool.resources) {
      for (const resource of resources) {
        const fragments = this.findFragments(resource);
        analysis.fragments.push(...fragments);

        // ì¡°ê°í™” ì ìˆ˜ ê³„ì‚°
        if (resource.available > 0) {
          const fragScore = 1 - (fragments[0]?.size || 0) / resource.available;
          analysis.score += fragScore * (resource.available / pool.totalCapacity);
        }
      }
    }

    return analysis;
  }

  private findFragments(resource: ResourceUnit): Fragment[] {
    const allocations = this.getAllocationsForResource(resource.id);
    const fragments: Fragment[] = [];

    // í• ë‹¹ëœ ì˜ì—­ ì •ë ¬
    allocations.sort((a, b) => a.offset - b.offset);

    let currentOffset = 0;

    for (const allocation of allocations) {
      if (allocation.offset > currentOffset) {
        // ë¹ˆ ê³µê°„ ë°œê²¬
        fragments.push({
          offset: currentOffset,
          size: allocation.offset - currentOffset,
          resourceId: resource.id
        });
      }
      currentOffset = allocation.offset + allocation.size;
    }

    // ë§ˆì§€ë§‰ ë¹ˆ ê³µê°„
    if (currentOffset < resource.capacity) {
      fragments.push({
        offset: currentOffset,
        size: resource.capacity - currentOffset,
        resourceId: resource.id
      });
    }

    return fragments.sort((a, b) => b.size - a.size);
  }

  private createDefragPlan(
    pool: ResourcePool,
    fragmentation: FragmentationAnalysis
  ): DefragPlan {
    const moves: AllocationMove[] = [];

    // ê° ë¦¬ì†ŒìŠ¤ë³„ë¡œ ì••ì¶• ê³„íš
    for (const [type, resources] of pool.resources) {
      for (const resource of resources) {
        const resourceMoves = this.planResourceCompaction(resource);
        moves.push(...resourceMoves);
      }
    }

    return {
      moves,
      estimatedDuration: this.estimateDuration(moves),
      requiredSpace: this.calculateRequiredSpace(moves)
    };
  }

  private planResourceCompaction(
    resource: ResourceUnit
  ): AllocationMove[] {
    const allocations = this.getAllocationsForResource(resource.id);
    const moves: AllocationMove[] = [];

    // ì™¼ìª½ìœ¼ë¡œ ì••ì¶•
    let targetOffset = 0;

    for (const allocation of allocations) {
      if (allocation.offset > targetOffset) {
        moves.push({
          allocationId: allocation.id,
          fromOffset: allocation.offset,
          toOffset: targetOffset,
          size: allocation.size
        });
      }
      targetOffset += allocation.size;
    }

    return moves;
  }
}

// ë¹„ìš© ìµœì í™” ì—”ì§„
export class CostOptimizer {
  private pricingModel: PricingModel;
  private usageAnalyzer: UsageAnalyzer;

  constructor() {
    this.pricingModel = new PricingModel();
    this.usageAnalyzer = new UsageAnalyzer();
  }

  async optimizeCost(
    pool: ResourcePool,
    constraints: CostConstraints
  ): Promise<CostOptimizationResult> {
    // 1. í˜„ì¬ ë¹„ìš© ë¶„ì„
    const currentCost = await this.calculateCurrentCost(pool);

    // 2. ì‚¬ìš© íŒ¨í„´ ë¶„ì„
    const usagePattern = await this.usageAnalyzer.analyze(pool);

    // 3. ìµœì í™” ì „ëµ ìˆ˜ë¦½
    const strategies = this.generateStrategies(
      pool,
      usagePattern,
      constraints
    );

    // 4. ìµœì  ì „ëµ ì„ íƒ
    const optimalStrategy = this.selectOptimalStrategy(
      strategies,
      constraints
    );

    // 5. ì˜ˆìƒ ì ˆê°ì•¡ ê³„ì‚°
    const projectedCost = await this.projectCost(
      pool,
      optimalStrategy
    );

    return {
      currentCost,
      projectedCost,
      savings: currentCost - projectedCost,
      savingsPercentage: ((currentCost - projectedCost) / currentCost) * 100,
      strategy: optimalStrategy,
      implementation: this.createImplementationPlan(optimalStrategy)
    };
  }

  private generateStrategies(
    pool: ResourcePool,
    usage: UsagePattern,
    constraints: CostConstraints
  ): CostStrategy[] {
    const strategies: CostStrategy[] = [];

    // 1. ì˜ˆì•½ ì¸ìŠ¤í„´ìŠ¤ ì „ëµ
    if (usage.predictability > 0.8) {
      strategies.push({
        type: 'reserved_instances',
        description: 'Convert to reserved instances for predictable workloads',
        estimatedSavings: 0.3,
        requiredCommitment: '1year',
        risk: 'low'
      });
    }

    // 2. ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ í™œìš©
    if (constraints.allowSpot && usage.interruptibilityTolerance > 0.7) {
      strategies.push({
        type: 'spot_instances',
        description: 'Use spot instances for interruptible workloads',
        estimatedSavings: 0.7,
        requiredChanges: ['implement_checkpointing', 'add_retry_logic'],
        risk: 'medium'
      });
    }

    // 3. ìë™ ìŠ¤ì¼€ì¼ë§ ìµœì í™”
    if (usage.variability > 0.5) {
      strategies.push({
        type: 'auto_scaling',
        description: 'Optimize auto-scaling policies',
        estimatedSavings: 0.25,
        requiredChanges: ['tune_scaling_policies', 'implement_predictive_scaling'],
        risk: 'low'
      });
    }

    // 4. ë¦¬ì†ŒìŠ¤ ì ì • í¬ê¸° ì¡°ì •
    const rightsizing = this.analyzeRightsizing(pool, usage);
    if (rightsizing.opportunities.length > 0) {
      strategies.push({
        type: 'rightsizing',
        description: 'Adjust resource sizes based on actual usage',
        estimatedSavings: rightsizing.estimatedSavings,
        changes: rightsizing.opportunities,
        risk: 'low'
      });
    }

    return strategies;
  }

  private analyzeRightsizing(
    pool: ResourcePool,
    usage: UsagePattern
  ): RightsizingAnalysis {
    const opportunities: RightsizingOpportunity[] = [];
    let totalSavings = 0;

    for (const [type, resources] of pool.resources) {
      for (const resource of resources) {
        const utilization = usage.resourceUtilization.get(resource.id);
        
        if (!utilization) continue;

        // ê³¼ì†Œ ì‚¬ìš© ë¦¬ì†ŒìŠ¤
        if (utilization.average < 0.3 && utilization.peak < 0.5) {
          const recommendedSize = resource.capacity * 0.6;
          const savings = this.calculateSizingSavings(
            resource,
            recommendedSize
          );

          opportunities.push({
            resourceId: resource.id,
            currentSize: resource.capacity,
            recommendedSize,
            estimatedSavings: savings,
            reason: 'Underutilized resource'
          });

          totalSavings += savings;
        }

        // ê³¼ë‹¤ ì‚¬ìš© ë¦¬ì†ŒìŠ¤ (ë¹„ìš© ì¦ê°€í•  ìˆ˜ ìˆì§€ë§Œ ì„±ëŠ¥ í–¥ìƒ)
        if (utilization.average > 0.8 || utilization.peak > 0.95) {
          const recommendedSize = resource.capacity * 1.5;
          
          opportunities.push({
            resourceId: resource.id,
            currentSize: resource.capacity,
            recommendedSize,
            estimatedSavings: -this.calculateSizingSavings(
              resource,
              recommendedSize
            ),
            reason: 'Overutilized resource - performance risk'
          });
        }
      }
    }

    return {
      opportunities,
      estimatedSavings: totalSavings / this.calculateCurrentCost(pool)
    };
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ìµœì í™” ì „ëµ
- [ ] ë¦¬ì†ŒìŠ¤ ì¬ì¡°ì • ë©”ì»¤ë‹ˆì¦˜
- [ ] ì¡°ê°í™” ì œê±°
- [ ] ë¹„ìš© ìµœì í™”

### Task 5.8: ì§€ëŠ¥í˜• ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬

#### SubTask 5.8.1: ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
**ë‹´ë‹¹ì**: ì•Œê³ ë¦¬ì¦˜ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/scheduler/scheduling_algorithms.ts
export interface SchedulingAlgorithm {
  name: string;
  schedule(
    tasks: Task[],
    resources: ResourcePool[],
    constraints: SchedulingConstraints
  ): Promise<Schedule>;
}

export class IntelligentScheduler {
  private algorithms: Map<string, SchedulingAlgorithm>;
  private mlPredictor: MLTaskPredictor;
  private constraintSolver: ConstraintSolver;
  
  constructor(config: SchedulerConfig) {
    this.algorithms = new Map();
    this.mlPredictor = new MLTaskPredictor(config.mlModel);
    this.constraintSolver = new ConstraintSolver();
    
    // ì•Œê³ ë¦¬ì¦˜ ë“±ë¡
    this.registerAlgorithm('fifo', new FIFOAlgorithm());
    this.registerAlgorithm('sjf', new ShortestJobFirst());
    this.registerAlgorithm('priority', new PriorityScheduling());
    this.registerAlgorithm('round-robin', new RoundRobinScheduling());
    this.registerAlgorithm('edf', new EarliestDeadlineFirst());
    this.registerAlgorithm('genetic', new GeneticAlgorithm());
    this.registerAlgorithm('ml-optimized', new MLOptimizedScheduling(this.mlPredictor));
  }

  async schedule(
    request: SchedulingRequest
  ): Promise<SchedulingResult> {
    const startTime = Date.now();

    // 1. íƒœìŠ¤í¬ ë¶„ì„ ë° ì˜ˆì¸¡
    const analyzedTasks = await this.analyzeTasks(request.tasks);

    // 2. ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸
    const resourceState = await this.getResourceState(request.resources);

    // 3. ì œì•½ ì¡°ê±´ ì „ì²˜ë¦¬
    const constraints = await this.preprocessConstraints(
      request.constraints,
      analyzedTasks,
      resourceState
    );

    // 4. ìµœì  ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
    const algorithm = await this.selectAlgorithm(
      analyzedTasks,
      resourceState,
      constraints
    );

    // 5. ìŠ¤ì¼€ì¤„ ìƒì„±
    const schedule = await algorithm.schedule(
      analyzedTasks,
      resourceState,
      constraints
    );

    // 6. ìŠ¤ì¼€ì¤„ ìµœì í™”
    const optimized = await this.optimizeSchedule(schedule);

    // 7. ê²€ì¦
    const validation = await this.validateSchedule(optimized);
    
    if (!validation.valid) {
      throw new SchedulingError(validation.errors);
    }

    return {
      schedule: optimized,
      algorithm: algorithm.name,
      metrics: {
        makespan: this.calculateMakespan(optimized),
        utilization: this.calculateUtilization(optimized),
        waitTime: this.calculateAverageWaitTime(optimized),
        throughput: this.calculateThroughput(optimized)
      },
      duration: Date.now() - startTime
    };
  }

  private async analyzeTasks(tasks: Task[]): Promise<AnalyzedTask[]> {
    return Promise.all(tasks.map(async task => {
      // ML ê¸°ë°˜ ì˜ˆì¸¡
      const prediction = await this.mlPredictor.predict(task);

      return {
        ...task,
        predictedDuration: prediction.duration,
        predictedResources: prediction.resources,
        predictedSuccess: prediction.successProbability,
        complexity: this.calculateComplexity(task),
        dependencies: await this.resolveDependencies(task),
        criticalPath: await this.calculateCriticalPath(task)
      };
    }));
  }

  private async selectAlgorithm(
    tasks: AnalyzedTask[],
    resources: ResourceState,
    constraints: ProcessedConstraints
  ): Promise<SchedulingAlgorithm> {
    // íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
    const characteristics = this.analyzeWorkloadCharacteristics(tasks);

    if (characteristics.isRealTime) {
      return this.algorithms.get('edf')!;
    }

    if (characteristics.hasPriorities && characteristics.priorityVariance > 0.5) {
      return this.algorithms.get('priority')!;
    }

    if (characteristics.taskCount > 1000 && characteristics.hasComplexConstraints) {
      return this.algorithms.get('genetic')!;
    }

    if (characteristics.isPredictable && this.mlPredictor.isReady()) {
      return this.algorithms.get('ml-optimized')!;
    }

    // ê¸°ë³¸ê°’
    return this.algorithms.get('sjf')!;
  }
}

// Shortest Job First ì•Œê³ ë¦¬ì¦˜
export class ShortestJobFirst implements SchedulingAlgorithm {
  name = 'shortest-job-first';

  async schedule(
    tasks: AnalyzedTask[],
    resources: ResourcePool[],
    constraints: SchedulingConstraints
  ): Promise<Schedule> {
    // ì˜ˆì¸¡ ì‹¤í–‰ ì‹œê°„ ê¸°ì¤€ ì •ë ¬
    const sortedTasks = [...tasks].sort(
      (a, b) => a.predictedDuration - b.predictedDuration
    );

    const schedule = new Schedule();
    const resourceQueues = new Map<string, TaskQueue>();

    // ê° ë¦¬ì†ŒìŠ¤ë³„ í ì´ˆê¸°í™”
    for (const resource of resources) {
      resourceQueues.set(resource.id, new TaskQueue());
    }

    // íƒœìŠ¤í¬ ìŠ¤ì¼€ì¤„ë§
    for (const task of sortedTasks) {
      // ê°€ì¥ ë¹¨ë¦¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤ ì°¾ê¸°
      const bestResource = this.findBestResource(
        task,
        resources,
        resourceQueues,
        constraints
      );

      if (!bestResource) {
        throw new NoResourceAvailableError(`No resource for task ${task.id}`);
      }

      // ìŠ¤ì¼€ì¤„ì— ì¶”ê°€
      const startTime = this.calculateStartTime(
        task,
        bestResource,
        resourceQueues.get(bestResource.id)!
      );

      schedule.addTask({
        taskId: task.id,
        resourceId: bestResource.id,
        startTime,
        endTime: new Date(startTime.getTime() + task.predictedDuration),
        allocatedResources: task.predictedResources
      });

      // ë¦¬ì†ŒìŠ¤ í ì—…ë°ì´íŠ¸
      resourceQueues.get(bestResource.id)!.enqueue(task);
    }

    return schedule;
  }

  private findBestResource(
    task: AnalyzedTask,
    resources: ResourcePool[],
    queues: Map<string, TaskQueue>,
    constraints: SchedulingConstraints
  ): ResourcePool | null {
    let bestResource: ResourcePool | null = null;
    let earliestAvailable = Infinity;

    for (const resource of resources) {
      // ë¦¬ì†ŒìŠ¤ ì œì•½ í™•ì¸
      if (!this.meetsResourceRequirements(task, resource)) {
        continue;
      }

      // ì œì•½ ì¡°ê±´ í™•ì¸
      if (!this.meetsConstraints(task, resource, constraints)) {
        continue;
      }

      // ê°€ìš© ì‹œê°„ ê³„ì‚°
      const queue = queues.get(resource.id)!;
      const availableTime = queue.getNextAvailableTime();

      if (availableTime < earliestAvailable) {
        earliestAvailable = availableTime;
        bestResource = resource;
      }
    }

    return bestResource;
  }
}

// ML ìµœì í™” ìŠ¤ì¼€ì¤„ë§
export class MLOptimizedScheduling implements SchedulingAlgorithm {
  name = 'ml-optimized';

  constructor(private predictor: MLTaskPredictor) {}

  async schedule(
    tasks: AnalyzedTask[],
    resources: ResourcePool[],
    constraints: SchedulingConstraints
  ): Promise<Schedule> {
    // 1. íŠ¹ì§• ì¶”ì¶œ
    const features = await this.extractFeatures(tasks, resources);

    // 2. ML ëª¨ë¸ë¡œ ìµœì  ìŠ¤ì¼€ì¤„ ì˜ˆì¸¡
    const mlSchedule = await this.predictor.predictOptimalSchedule(features);

    // 3. ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹¤ì œ ìŠ¤ì¼€ì¤„ë¡œ ë³€í™˜
    const schedule = new Schedule();

    for (const prediction of mlSchedule.assignments) {
      const task = tasks.find(t => t.id === prediction.taskId);
      const resource = resources.find(r => r.id === prediction.resourceId);

      if (!task || !resource) continue;

      // ì œì•½ ì¡°ê±´ ê²€ì¦
      if (this.validateAssignment(task, resource, constraints)) {
        schedule.addTask({
          taskId: task.id,
          resourceId: resource.id,
          startTime: prediction.startTime,
          endTime: prediction.endTime,
          allocatedResources: prediction.resources,
          confidence: prediction.confidence
        });
      } else {
        // ëŒ€ì²´ ìŠ¤ì¼€ì¤„ë§
        await this.handleInvalidPrediction(
          task,
          resources,
          schedule,
          constraints
        );
      }
    }

    // 4. í›„ì²˜ë¦¬ ìµœì í™”
    return this.postProcessOptimization(schedule);
  }

  private async extractFeatures(
    tasks: AnalyzedTask[],
    resources: ResourcePool[]
  ): Promise<SchedulingFeatures> {
    return {
      taskFeatures: tasks.map(t => ({
        duration: t.predictedDuration,
        priority: t.priority,
        dependencies: t.dependencies.length,
        resourceRequirements: this.encodeResources(t.predictedResources),
        complexity: t.complexity,
        historicalSuccess: t.historicalMetrics?.successRate || 1.0
      })),
      resourceFeatures: resources.map(r => ({
        capacity: r.capacity,
        currentUtilization: r.utilization,
        reliability: r.metrics.reliability,
        cost: r.cost,
        location: this.encodeLocation(r.location)
      })),
      globalFeatures: {
        totalTasks: tasks.length,
        totalResources: resources.length,
        averageComplexity: this.average(tasks.map(t => t.complexity)),
        timeOfDay: new Date().getHours(),
        dayOfWeek: new Date().getDay()
      }
    };
  }
}

// ìœ ì „ì ì•Œê³ ë¦¬ì¦˜ ìŠ¤ì¼€ì¤„ë§
export class GeneticAlgorithm implements SchedulingAlgorithm {
  name = 'genetic';
  
  private populationSize = 100;
  private generations = 500;
  private mutationRate = 0.1;
  private eliteSize = 10;

  async schedule(
    tasks: AnalyzedTask[],
    resources: ResourcePool[],
    constraints: SchedulingConstraints
  ): Promise<Schedule> {
    // 1. ì´ˆê¸° population ìƒì„±
    let population = this.initializePopulation(
      tasks,
      resources,
      this.populationSize
    );

    // 2. ì§„í™” ì‹œì‘
    for (let gen = 0; gen < this.generations; gen++) {
      // ì í•©ë„ í‰ê°€
      const fitness = population.map(individual => ({
        individual,
        fitness: this.evaluateFitness(individual, constraints)
      }));

      // ì •ë ¬
      fitness.sort((a, b) => b.fitness - a.fitness);

      // ìˆ˜ë ´ í™•ì¸
      if (this.hasConverged(fitness)) {
        break;
      }

      // ì„ íƒ ë° êµë°°
      const nextPopulation: Individual[] = [];

      // ì—˜ë¦¬íŠ¸ ë³´ì¡´
      for (let i = 0; i < this.eliteSize; i++) {
        nextPopulation.push(fitness[i].individual);
      }

      // êµë°°ë¡œ ìƒˆë¡œìš´ ê°œì²´ ìƒì„±
      while (nextPopulation.length < this.populationSize) {
        const parent1 = this.tournamentSelection(fitness);
        const parent2 = this.tournamentSelection(fitness);
        
        const offspring = this.crossover(parent1, parent2);
        
        // ë³€ì´
        if (Math.random() < this.mutationRate) {
          this.mutate(offspring, tasks, resources);
        }

        nextPopulation.push(offspring);
      }

      population = nextPopulation;
    }

    // ìµœì  ê°œì²´ë¥¼ ìŠ¤ì¼€ì¤„ë¡œ ë³€í™˜
    const best = population.reduce((a, b) => 
      this.evaluateFitness(a, constraints) > this.evaluateFitness(b, constraints) ? a : b
    );

    return this.individualToSchedule(best);
  }

  private initializePopulation(
    tasks: AnalyzedTask[],
    resources: ResourcePool[],
    size: number
  ): Individual[] {
    const population: Individual[] = [];

    for (let i = 0; i < size; i++) {
      const individual: Individual = {
        genes: []
      };

      // ë¬´ì‘ìœ„ í• ë‹¹
      for (const task of tasks) {
        const validResources = resources.filter(r => 
          this.canAllocate(task, r)
        );

        if (validResources.length > 0) {
          const resource = validResources[
            Math.floor(Math.random() * validResources.length)
          ];

          individual.genes.push({
            taskId: task.id,
            resourceId: resource.id,
            startTime: this.randomStartTime(task)
          });
        }
      }

      population.push(individual);
    }

    return population;
  }

  private evaluateFitness(
    individual: Individual,
    constraints: SchedulingConstraints
  ): number {
    let fitness = 0;

    // 1. Makespan (ìµœì†Œí™”)
    const makespan = this.calculateMakespan(individual);
    fitness += 1000 / (1 + makespan);

    // 2. ë¦¬ì†ŒìŠ¤ í™œìš©ë¥  (ìµœëŒ€í™”)
    const utilization = this.calculateUtilization(individual);
    fitness += utilization * 100;

    // 3. ì œì•½ ìœ„ë°˜ í˜ë„í‹°
    const violations = this.countConstraintViolations(individual, constraints);
    fitness -= violations * 50;

    // 4. ë¡œë“œ ë°¸ëŸ°ì‹±
    const balance = this.calculateLoadBalance(individual);
    fitness += balance * 50;

    // 5. ë¹„ìš© (ìµœì†Œí™”)
    const cost = this.calculateCost(individual);
    fitness += 100 / (1 + cost);

    return fitness;
  }

  private crossover(parent1: Individual, parent2: Individual): Individual {
    const offspring: Individual = { genes: [] };
    
    // ë‹¨ì¼ì  êµì°¨
    const crossoverPoint = Math.floor(Math.random() * parent1.genes.length);
    
    for (let i = 0; i < parent1.genes.length; i++) {
      if (i < crossoverPoint) {
        offspring.genes.push({ ...parent1.genes[i] });
      } else if (i < parent2.genes.length) {
        offspring.genes.push({ ...parent2.genes[i] });
      }
    }

    return offspring;
  }

  private mutate(
    individual: Individual,
    tasks: AnalyzedTask[],
    resources: ResourcePool[]
  ): void {
    // ë¬´ì‘ìœ„ ìœ ì „ì ì„ íƒ
    const geneIndex = Math.floor(Math.random() * individual.genes.length);
    const gene = individual.genes[geneIndex];
    
    // ë³€ì´ íƒ€ì… ì„ íƒ
    const mutationType = Math.random();
    
    if (mutationType < 0.5) {
      // ë¦¬ì†ŒìŠ¤ ë³€ê²½
      const task = tasks.find(t => t.id === gene.taskId)!;
      const validResources = resources.filter(r => 
        this.canAllocate(task, r) && r.id !== gene.resourceId
      );
      
      if (validResources.length > 0) {
        gene.resourceId = validResources[
          Math.floor(Math.random() * validResources.length)
        ].id;
      }
    } else {
      // ì‹œì‘ ì‹œê°„ ë³€ê²½
      gene.startTime = this.mutateStartTime(gene.startTime);
    }
  }
}

// ì œì•½ í•´ê²°ê¸°
export class ConstraintSolver {
  async solve(
    tasks: AnalyzedTask[],
    resources: ResourcePool[],
    constraints: SchedulingConstraints
  ): Promise<ConstraintSolution> {
    // CSP (Constraint Satisfaction Problem) í•´ê²°
    const problem = this.formulateProblem(tasks, resources, constraints);
    
    // ë°±íŠ¸ë˜í‚¹ + ì œì•½ ì „íŒŒ
    const solution = await this.backtrackingSearch(problem);
    
    if (!solution) {
      // ì œì•½ ì™„í™”
      const relaxed = await this.relaxConstraints(problem);
      return this.backtrackingSearch(relaxed);
    }
    
    return solution;
  }

  private formulateProblem(
    tasks: AnalyzedTask[],
    resources: ResourcePool[],
    constraints: SchedulingConstraints
  ): CSPProblem {
    return {
      variables: tasks.map(t => ({
        id: t.id,
        domain: this.generateDomain(t, resources)
      })),
      constraints: [
        ...this.generateResourceConstraints(resources),
        ...this.generateDependencyConstraints(tasks),
        ...this.generateCustomConstraints(constraints)
      ]
    };
  }

  private async backtrackingSearch(
    problem: CSPProblem
  ): Promise<ConstraintSolution | null> {
    const assignment: Map<string, Assignment> = new Map();
    
    return this.backtrack(problem, assignment);
  }

  private async backtrack(
    problem: CSPProblem,
    assignment: Map<string, Assignment>
  ): Promise<ConstraintSolution | null> {
    // ëª¨ë“  ë³€ìˆ˜ê°€ í• ë‹¹ë¨
    if (assignment.size === problem.variables.length) {
      return this.assignmentToSolution(assignment);
    }

    // ë‹¤ìŒ ë³€ìˆ˜ ì„ íƒ (MRV íœ´ë¦¬ìŠ¤í‹±)
    const variable = this.selectUnassignedVariable(problem, assignment);
    
    // ë„ë©”ì¸ ê°’ ìˆœì„œí™” (LCV íœ´ë¦¬ìŠ¤í‹±)
    const orderedDomain = this.orderDomainValues(variable, assignment, problem);
    
    for (const value of orderedDomain) {
      if (this.isConsistent(variable, value, assignment, problem)) {
        // í• ë‹¹
        assignment.set(variable.id, value);
        
        // ì œì•½ ì „íŒŒ
        const inferences = await this.inference(
          variable,
          value,
          assignment,
          problem
        );
        
        if (inferences !== null) {
          // ì¬ê·€ í˜¸ì¶œ
          const result = await this.backtrack(problem, assignment);
          
          if (result !== null) {
            return result;
          }
        }
        
        // ë°±íŠ¸ë™
        assignment.delete(variable.id);
        this.removeInferences(inferences);
      }
    }
    
    return null;
  }

  private selectUnassignedVariable(
    problem: CSPProblem,
    assignment: Map<string, Assignment>
  ): Variable {
    // Minimum Remaining Values (MRV) íœ´ë¦¬ìŠ¤í‹±
    let minVariable: Variable | null = null;
    let minDomainSize = Infinity;
    
    for (const variable of problem.variables) {
      if (!assignment.has(variable.id)) {
        const domainSize = this.getDomainSize(variable, assignment, problem);
        
        if (domainSize < minDomainSize) {
          minDomainSize = domainSize;
          minVariable = variable;
        }
      }
    }
    
    return minVariable!;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜
- [ ] ML ê¸°ë°˜ ìµœì í™”
- [ ] ìœ ì „ì ì•Œê³ ë¦¬ì¦˜
- [ ] ì œì•½ í•´ê²°ê¸°

#### SubTask 5.8.2: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ í ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/scheduler/priority_queue_system.ts
export class PriorityQueueSystem {
  private queues: Map<string, PriorityQueue<ScheduledTask>>;
  private queueManager: QueueManager;
  private priorityEngine: PriorityEngine;
  private fairnessController: FairnessController;

  constructor(config: QueueSystemConfig) {
    this.queues = new Map();
    this.queueManager = new QueueManager(config);
    this.priorityEngine = new PriorityEngine(config.priority);
    this.fairnessController = new FairnessController(config.fairness);
  }

  async enqueue(task: Task): Promise<void> {
    // 1. ìš°ì„ ìˆœìœ„ ê³„ì‚°
    const priority = await this.priorityEngine.calculatePriority(task);

    // 2. í ì„ íƒ
    const queueId = this.selectQueue(task, priority);

    // 3. ìŠ¤ì¼€ì¤„ëœ íƒœìŠ¤í¬ ìƒì„±
    const scheduledTask: ScheduledTask = {
      ...task,
      priority,
      enqueuedAt: new Date(),
      attempts: 0,
      queueId
    };

    // 4. íì— ì¶”ê°€
    const queue = this.getOrCreateQueue(queueId);
    await queue.enqueue(scheduledTask, priority);

    // 5. ì´ë²¤íŠ¸ ë°œí–‰
    await this.publishEnqueueEvent(scheduledTask);
  }

  async dequeue(resourceType: ResourceType): Promise<ScheduledTask | null> {
    // 1. ì í•©í•œ íë“¤ ì°¾ê¸°
    const eligibleQueues = this.findEligibleQueues(resourceType);

    if (eligibleQueues.length === 0) {
      return null;
    }

    // 2. ê³µì •ì„± ê³ ë ¤í•œ í ì„ íƒ
    const selectedQueue = await this.fairnessController.selectQueue(
      eligibleQueues
    );

    // 3. íƒœìŠ¤í¬ ì¶”ì¶œ
    const task = await selectedQueue.dequeue();

    if (task) {
      // 4. í†µê³„ ì—…ë°ì´íŠ¸
      await this.updateDequeueStats(task);

      // 5. ì´ë²¤íŠ¸ ë°œí–‰
      await this.publishDequeueEvent(task);
    }

    return task;
  }

  private getOrCreateQueue(queueId: string): PriorityQueue<ScheduledTask> {
    if (!this.queues.has(queueId)) {
      const queue = new AdaptivePriorityQueue<ScheduledTask>({
        comparator: (a, b) => {
          // ìš°ì„ ìˆœìœ„ê°€ ë†’ì„ìˆ˜ë¡ ë¨¼ì €
          if (a.priority !== b.priority) {
            return b.priority - a.priority;
          }
          // ê°™ì€ ìš°ì„ ìˆœìœ„ë©´ ë¨¼ì € ë“¤ì–´ì˜¨ ê²ƒ ë¨¼ì € (FIFO)
          return a.enqueuedAt.getTime() - b.enqueuedAt.getTime();
        },
        capacity: this.queueManager.getQueueCapacity(queueId)
      });

      this.queues.set(queueId, queue);
    }

    return this.queues.get(queueId)!;
  }
}

// ìš°ì„ ìˆœìœ„ ê³„ì‚° ì—”ì§„
export class PriorityEngine {
  private rules: PriorityRule[];
  private mlPriorityModel: MLPriorityModel;

  constructor(config: PriorityConfig) {
    this.rules = config.rules || [];
    this.mlPriorityModel = new MLPriorityModel(config.mlModel);
  }

  async calculatePriority(task: Task): Promise<number> {
    let basePriority = task.priority || 50;

    // 1. ê·œì¹™ ê¸°ë°˜ ì¡°ì •
    for (const rule of this.rules) {
      if (await rule.applies(task)) {
        basePriority = rule.adjust(basePriority, task);
      }
    }

    // 2. ML ê¸°ë°˜ ì¡°ì •
    if (this.mlPriorityModel.isReady()) {
      const mlAdjustment = await this.mlPriorityModel.predictPriorityAdjustment(task);
      basePriority += mlAdjustment;
    }

    // 3. ë™ì  ì¡°ì • ìš”ì†Œ
    const dynamicFactors = await this.calculateDynamicFactors(task);
    basePriority = this.applyDynamicFactors(basePriority, dynamicFactors);

    // ë²”ìœ„ ì œí•œ (0-100)
    return Math.max(0, Math.min(100, basePriority));
  }

  private async calculateDynamicFactors(task: Task): Promise<DynamicFactors> {
    return {
      // ëŒ€ê¸° ì‹œê°„ ìš”ì†Œ
      waitTime: task.createdAt 
        ? Date.now() - task.createdAt.getTime() 
        : 0,
      
      // ë°ë“œë¼ì¸ ê¸´ê¸‰ë„
      urgency: task.deadline 
        ? this.calculateUrgency(task.deadline) 
        : 0,
      
      // ì˜ì¡´ì„± ì„ê³„ë„
      dependencyCriticality: await this.calculateDependencyCriticality(task),
      
      // ì‚¬ìš©ì ì¤‘ìš”ë„
      userImportance: await this.getUserImportance(task.userId),
      
      // ë¦¬ì†ŒìŠ¤ ê°€ìš©ì„±
      resourceAvailability: await this.checkResourceAvailability(task)
    };
  }

  private calculateUrgency(deadline: Date): number {
    const timeUntilDeadline = deadline.getTime() - Date.now();
    
    if (timeUntilDeadline < 0) {
      return 100; // ì´ë¯¸ ì§€ë‚¬ìŒ
    }
    
    // ì§€ìˆ˜ í•¨ìˆ˜ë¡œ ê¸´ê¸‰ë„ ê³„ì‚°
    const hoursUntilDeadline = timeUntilDeadline / (1000 * 60 * 60);
    return Math.min(100, 100 * Math.exp(-hoursUntilDeadline / 24));
  }

  private applyDynamicFactors(
    basePriority: number,
    factors: DynamicFactors
  ): number {
    let priority = basePriority;

    // ëŒ€ê¸° ì‹œê°„ ë³´ë„ˆìŠ¤ (Aging)
    const waitHours = factors.waitTime / (1000 * 60 * 60);
    priority += Math.min(20, waitHours * 2);

    // ê¸´ê¸‰ë„ ë³´ë„ˆìŠ¤
    priority += factors.urgency * 0.3;

    // ì˜ì¡´ì„± ì„ê³„ë„
    priority += factors.dependencyCriticality * 0.2;

    // ì‚¬ìš©ì ì¤‘ìš”ë„
    priority *= (1 + factors.userImportance * 0.1);

    // ë¦¬ì†ŒìŠ¤ ê°€ìš©ì„± í˜ë„í‹°
    if (factors.resourceAvailability < 0.3) {
      priority *= 0.8; // ë¦¬ì†ŒìŠ¤ ë¶€ì¡± ì‹œ ìš°ì„ ìˆœìœ„ ê°ì†Œ
    }

    return priority;
  }
}

// ê³µì •ì„± ì»¨íŠ¸ë¡¤ëŸ¬
export class FairnessController {
  private queueStats: Map<string, QueueStatistics>;
  private fairnessPolicy: FairnessPolicy;

  constructor(config: FairnessConfig) {
    this.queueStats = new Map();
    this.fairnessPolicy = config.policy || 'weighted-round-robin';
  }

  async selectQueue(
    queues: PriorityQueue<ScheduledTask>[]
  ): Promise<PriorityQueue<ScheduledTask>> {
    switch (this.fairnessPolicy) {
      case 'strict-priority':
        return this.selectStrictPriority(queues);
      
      case 'weighted-round-robin':
        return this.selectWeightedRoundRobin(queues);
      
      case 'fair-share':
        return this.selectFairShare(queues);
      
      case 'lottery':
        return this.selectLottery(queues);
      
      default:
        return queues[0];
    }
  }

  private async selectWeightedRoundRobin(
    queues: PriorityQueue<ScheduledTask>[]
  ): Promise<PriorityQueue<ScheduledTask>> {
    // ê° íì˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
    const weights = await Promise.all(
      queues.map(q => this.calculateQueueWeight(q))
    );

    // ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì„ íƒ
    const totalWeight = weights.reduce((sum, w) => sum + w, 0);
    let random = Math.random() * totalWeight;

    for (let i = 0; i < queues.length; i++) {
      random -= weights[i];
      if (random <= 0) {
        // ì„ íƒëœ íì˜ í†µê³„ ì—…ë°ì´íŠ¸
        this.updateQueueStats(queues[i].id, 'selected');
        return queues[i];
      }
    }

    return queues[queues.length - 1];
  }

  private async calculateQueueWeight(
    queue: PriorityQueue<ScheduledTask>
  ): Promise<number> {
    const stats = this.getQueueStats(queue.id);
    
    // ê¸°ë³¸ ê°€ì¤‘ì¹˜
    let weight = queue.size();

    // ê¸°ì•„ ë°©ì§€: ì˜¤ë˜ ê¸°ë‹¤ë¦° íì— ë³´ë„ˆìŠ¤
    const timeSinceLastService = Date.now() - stats.lastServiceTime.getTime();
    weight *= (1 + timeSinceLastService / (1000 * 60 * 60)); // ì‹œê°„ë‹¹ ë³´ë„ˆìŠ¤

    // ìš°ì„ ìˆœìœ„ ê³ ë ¤
    const avgPriority = await this.getAveragePriority(queue);
    weight *= (avgPriority / 50); // 50ì„ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •

    // ê³µì •ì„± íŒ©í„°
    const fairnessFactor = 1 / (1 + stats.totalServiced / 1000);
    weight *= fairnessFactor;

    return weight;
  }

  private getQueueStats(queueId: string): QueueStatistics {
    if (!this.queueStats.has(queueId)) {
      this.queueStats.set(queueId, {
        queueId,
        totalEnqueued: 0,
        totalServiced: 0,
        totalDropped: 0,
        avgWaitTime: 0,
        lastServiceTime: new Date(0),
        lastUpdateTime: new Date()
      });
    }

    return this.queueStats.get(queueId)!;
  }
}

// ì ì‘í˜• ìš°ì„ ìˆœìœ„ í
export class AdaptivePriorityQueue<T> implements PriorityQueue<T> {
  private heap: Heap<T>;
  private indexMap: Map<string, number>;
  private config: AdaptiveQueueConfig;
  private adaptiveController: AdaptiveController;

  constructor(config: AdaptiveQueueConfig) {
    this.config = config;
    this.heap = new Heap(config.comparator);
    this.indexMap = new Map();
    this.adaptiveController = new AdaptiveController();
  }

  async enqueue(item: T, priority: number): Promise<void> {
    // ìš©ëŸ‰ í™•ì¸
    if (this.heap.size() >= this.config.capacity) {
      await this.handleOverflow(item, priority);
      return;
    }

    // í™ì— ì¶”ê°€
    this.heap.insert(item);

    // ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
    if (this.hasId(item)) {
      this.indexMap.set(this.getId(item), this.heap.size() - 1);
    }

    // ì ì‘í˜• ì¡°ì •
    await this.adaptiveController.onEnqueue(this);
  }

  async dequeue(): Promise<T | null> {
    if (this.heap.isEmpty()) {
      return null;
    }

    const item = this.heap.extractMin();

    // ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
    if (this.hasId(item)) {
      this.indexMap.delete(this.getId(item));
    }

    // í™ ì¬êµ¬ì„±
    this.rebuild();

    // ì ì‘í˜• ì¡°ì •
    await this.adaptiveController.onDequeue(this);

    return item;
  }

  private async handleOverflow(item: T, priority: number): Promise<void> {
    switch (this.config.overflowPolicy) {
      case 'drop-lowest':
        // ê°€ì¥ ë‚®ì€ ìš°ì„ ìˆœìœ„ ì œê±°
        const lowest = this.findLowestPriority();
        if (lowest && this.comparePriority(item, lowest) > 0) {
          await this.remove(lowest);
          await this.enqueue(item, priority);
        }
        break;

      case 'drop-oldest':
        // ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
        const oldest = this.findOldest();
        if (oldest) {
          await this.remove(oldest);
          await this.enqueue(item, priority);
        }
        break;

      case 'reject':
        // ìƒˆ í•­ëª© ê±°ë¶€
        throw new QueueOverflowError('Queue is full');

      case 'expand':
        // ë™ì  í™•ì¥
        this.config.capacity *= 1.5;
        await this.enqueue(item, priority);
        break;
    }
  }

  async reprioritize(
    itemId: string,
    newPriority: number
  ): Promise<void> {
    const index = this.indexMap.get(itemId);
    
    if (index === undefined) {
      throw new Error(`Item ${itemId} not found in queue`);
    }

    // ìš°ì„ ìˆœìœ„ ì—…ë°ì´íŠ¸
    const item = this.heap.get(index);
    if (this.hasUpdatePriority(item)) {
      this.updatePriority(item, newPriority);
    }

    // í™ ì†ì„± ë³µêµ¬
    this.heap.updateAt(index);

    // ì¸ë±ìŠ¤ ì¬ê³„ì‚°
    this.rebuildIndex();
  }

  peek(): T | null {
    return this.heap.peek();
  }

  size(): number {
    return this.heap.size();
  }

  isEmpty(): boolean {
    return this.heap.isEmpty();
  }

  private rebuild(): void {
    this.indexMap.clear();
    
    const items = this.heap.toArray();
    for (let i = 0; i < items.length; i++) {
      if (this.hasId(items[i])) {
        this.indexMap.set(this.getId(items[i]), i);
      }
    }
  }

  private hasId(item: any): boolean {
    return item && typeof item.id === 'string';
  }

  private getId(item: any): string {
    return item.id;
  }
}

// ë‹¤ë‹¨ê³„ í ìŠ¤ì¼€ì¤„ëŸ¬
export class MultiLevelQueueScheduler {
  private levels: QueueLevel[];
  private migrationPolicy: MigrationPolicy;
  private quantumCalculator: QuantumCalculator;

  constructor(config: MultiLevelConfig) {
    this.levels = this.initializeLevels(config.levels);
    this.migrationPolicy = new MigrationPolicy(config.migration);
    this.quantumCalculator = new QuantumCalculator();
  }

  private initializeLevels(levelConfigs: LevelConfig[]): QueueLevel[] {
    return levelConfigs.map((config, index) => ({
      id: `level-${index}`,
      priority: config.priority,
      queue: new AdaptivePriorityQueue({
        comparator: config.comparator || defaultComparator,
        capacity: config.capacity || 1000,
        overflowPolicy: 'drop-lowest'
      }),
      quantum: config.quantum || 100,
      policy: config.policy || 'round-robin'
    }));
  }

  async schedule(): Promise<ScheduledTask | null> {
    // ìµœìƒìœ„ ë ˆë²¨ë¶€í„° í™•ì¸
    for (const level of this.levels) {
      if (!level.queue.isEmpty()) {
        const task = await level.queue.dequeue();
        
        if (task) {
          // í€€í…€ í• ë‹¹
          task.quantum = this.quantumCalculator.calculate(task, level);
          
          // ë ˆë²¨ ì •ë³´ ì¶”ê°€
          task.currentLevel = level.id;
          
          return task;
        }
      }
    }

    return null;
  }

  async feedback(
    task: ScheduledTask,
    execution: ExecutionResult
  ): Promise<void> {
    const currentLevel = this.findLevel(task.currentLevel);
    
    if (!currentLevel) return;

    // ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ì •
    const migration = await this.migrationPolicy.decide(
      task,
      execution,
      currentLevel
    );

    if (migration.shouldMigrate) {
      const targetLevel = this.findLevel(migration.targetLevel);
      
      if (targetLevel) {
        // ìš°ì„ ìˆœìœ„ ì¡°ì •
        if (migration.adjustPriority) {
          task.priority = migration.newPriority;
        }

        // ë ˆë²¨ ì´ë™
        await targetLevel.queue.enqueue(task, task.priority);
        
        // í†µê³„ ì—…ë°ì´íŠ¸
        this.updateMigrationStats(task, currentLevel, targetLevel);
      }
    } else {
      // ê°™ì€ ë ˆë²¨ì— ì¬ì§„ì…
      await currentLevel.queue.enqueue(task, task.priority);
    }
  }

  private findLevel(levelId: string): QueueLevel | undefined {
    return this.levels.find(l => l.id === levelId);
  }
}

// ì§€ëŠ¥í˜• ë°±í”„ë ˆì…” ì‹œìŠ¤í…œ
export class BackpressureSystem {
  private thresholds: BackpressureThresholds;
  private currentPressure: Map<string, PressureMetrics>;
  private adaptiveController: AdaptiveBackpressureController;

  constructor(config: BackpressureConfig) {
    this.thresholds = config.thresholds;
    this.currentPressure = new Map();
    this.adaptiveController = new AdaptiveBackpressureController(config);
  }

  async checkPressure(queueId: string): Promise<PressureLevel> {
    const metrics = await this.collectMetrics(queueId);
    const pressure = this.calculatePressure(metrics);

    // ì••ë ¥ ë ˆë²¨ ê²°ì •
    if (pressure > this.thresholds.critical) {
      return PressureLevel.CRITICAL;
    } else if (pressure > this.thresholds.high) {
      return PressureLevel.HIGH;
    } else if (pressure > this.thresholds.medium) {
      return PressureLevel.MEDIUM;
    } else {
      return PressureLevel.LOW;
    }
  }

  async applyBackpressure(
    queueId: string,
    level: PressureLevel
  ): Promise<BackpressureAction> {
    switch (level) {
      case PressureLevel.CRITICAL:
        return {
          action: 'reject',
          throttleRate: 0,
          message: 'System overloaded, rejecting new tasks'
        };

      case PressureLevel.HIGH:
        return {
          action: 'throttle',
          throttleRate: 0.2, // 20% ì²˜ë¦¬ìœ¨
          delayMs: 1000
        };

      case PressureLevel.MEDIUM:
        return {
          action: 'throttle',
          throttleRate: 0.6, // 60% ì²˜ë¦¬ìœ¨
          delayMs: 100
        };

      case PressureLevel.LOW:
        return {
          action: 'accept',
          throttleRate: 1.0
        };
    }
  }

  private calculatePressure(metrics: QueueMetrics): number {
    // ë³µí•© ì••ë ¥ ì§€í‘œ ê³„ì‚°
    const queuePressure = metrics.queueDepth / metrics.queueCapacity;
    const latencyPressure = metrics.avgLatency / metrics.targetLatency;
    const errorPressure = metrics.errorRate / metrics.errorThreshold;
    const resourcePressure = metrics.resourceUtilization / 100;

    // ê°€ì¤‘ í‰ê· 
    return (
      queuePressure * 0.3 +
      latencyPressure * 0.3 +
      errorPressure * 0.2 +
      resourcePressure * 0.2
    );
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ìš°ì„ ìˆœìœ„ ê³„ì‚° ì—”ì§„
- [ ] ê³µì •ì„± ì œì–´
- [ ] ë‹¤ë‹¨ê³„ í ì‹œìŠ¤í…œ
- [ ] ë°±í”„ë ˆì…” ë©”ì»¤ë‹ˆì¦˜

#### SubTask 5.8.3: ì˜ˆì¸¡ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§
**ë‹´ë‹¹ì**: ML ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/scheduler/predictive_scheduling.ts
export class PredictiveScheduler {
  private predictor: TaskPredictor;
  private workloadAnalyzer: WorkloadAnalyzer;
  private resourceForecaster: ResourceForecaster;
  private optimizationEngine: ScheduleOptimizer;

  constructor(config: PredictiveConfig) {
    this.predictor = new TaskPredictor(config.model);
    this.workloadAnalyzer = new WorkloadAnalyzer();
    this.resourceForecaster = new ResourceForecaster();
    this.optimizationEngine = new ScheduleOptimizer();
  }

  async generatePredictiveSchedule(
    upcomingTasks: Task[],
    currentState: SystemState,
    horizon: TimeHorizon
  ): Promise<PredictiveSchedule> {
    // 1. ì›Œí¬ë¡œë“œ ë¶„ì„ ë° ì˜ˆì¸¡
    const workloadPrediction = await this.workloadAnalyzer.predictWorkload(
      upcomingTasks,
      horizon
    );

    // 2. ë¦¬ì†ŒìŠ¤ ê°€ìš©ì„± ì˜ˆì¸¡
    const resourcePrediction = await this.resourceForecaster.forecast(
      currentState.resources,
      horizon
    );

    // 3. íƒœìŠ¤í¬ë³„ ì˜ˆì¸¡
    const taskPredictions = await this.predictTaskMetrics(upcomingTasks);

    // 4. ìµœì  ìŠ¤ì¼€ì¤„ ìƒì„±
    const schedule = await this.optimizationEngine.optimize({
      tasks: taskPredictions,
      resources: resourcePrediction,
      workload: workloadPrediction,
      objectives: ['minimize_makespan', 'maximize_utilization'],
      constraints: currentState.constraints
    });

    // 5. ì‹ ë¢°ë„ í‰ê°€
    const confidence = await this.evaluateConfidence(schedule);

    return {
      schedule,
      predictions: taskPredictions,
      confidence,
      recommendations: this.generateRecommendations(schedule, confidence)
    };
  }

  private async predictTaskMetrics(
    tasks: Task[]
  ): Promise<TaskPrediction[]> {
    return Promise.all(tasks.map(async task => {
      const features = await this.extractTaskFeatures(task);
      const prediction = await this.predictor.predict(features);

      return {
        taskId: task.id,
        estimatedDuration: prediction.duration,
        confidenceInterval: prediction.confidenceInterval,
        resourceRequirements: prediction.resources,
        successProbability: prediction.successRate,
        potentialBottlenecks: prediction.bottlenecks,
        optimalStartTime: prediction.optimalStart
      };
    }));
  }

  private async extractTaskFeatures(task: Task): Promise<TaskFeatures> {
    const historicalData = await this.getHistoricalData(task.type);
    const contextualFeatures = await this.extractContextualFeatures(task);

    return {
      // Task intrinsic features
      taskType: task.type,
      priority: task.priority,
      complexity: this.estimateComplexity(task),
      dataSize: task.inputSize || 0,
      
      // Historical features
      avgDuration: historicalData.avgDuration,
      stdDevDuration: historicalData.stdDev,
      failureRate: historicalData.failureRate,
      
      // Contextual features
      timeOfDay: new Date().getHours(),
      dayOfWeek: new Date().getDay(),
      currentLoad: contextualFeatures.systemLoad,
      queueDepth: contextualFeatures.queueDepth,
      
      // Dependencies
      dependencyCount: task.dependencies?.length || 0,
      criticalPathLength: await this.calculateCriticalPath(task)
    };
  }
}

// íƒœìŠ¤í¬ ì˜ˆì¸¡ ëª¨ë¸
export class TaskPredictor {
  private model: TensorFlowModel;
  private featureEncoder: FeatureEncoder;
  private confidenceEstimator: ConfidenceEstimator;

  constructor(modelConfig: ModelConfig) {
    this.model = new TensorFlowModel(modelConfig);
    this.featureEncoder = new FeatureEncoder();
    this.confidenceEstimator = new ConfidenceEstimator();
  }

  async predict(features: TaskFeatures): Promise<TaskPrediction> {
    // íŠ¹ì§• ì¸ì½”ë”©
    const encoded = await this.featureEncoder.encode(features);

    // ëª¨ë¸ ì˜ˆì¸¡
    const prediction = await this.model.predict(encoded);

    // ì‹ ë¢° êµ¬ê°„ ê³„ì‚°
    const confidence = await this.confidenceEstimator.estimate(
      prediction,
      features
    );

    return {
      duration: prediction.duration,
      confidenceInterval: {
        lower: prediction.duration * (1 - confidence.margin),
        upper: prediction.duration * (1 + confidence.margin)
      },
      resources: {
        cpu: prediction.cpuRequirement,
        memory: prediction.memoryRequirement,
        io: prediction.ioRequirement
      },
      successRate: prediction.successProbability,
      bottlenecks: await this.identifyBottlenecks(prediction, features),
      optimalStart: await this.calculateOptimalStart(prediction, features)
    };
  }

  async train(trainingData: TrainingDataset): Promise<void> {
    // ë°ì´í„° ì „ì²˜ë¦¬
    const processed = await this.preprocessTrainingData(trainingData);

    // ëª¨ë¸ í›ˆë ¨
    await this.model.train(processed, {
      epochs: 100,
      batchSize: 32,
      validationSplit: 0.2,
      callbacks: {
        onEpochEnd: (epoch, logs) => {
          logger.info(`Epoch ${epoch}: loss=${logs.loss}`);
        }
      }
    });

    // ëª¨ë¸ í‰ê°€
    const evaluation = await this.evaluate(processed.validation);
    logger.info('Model evaluation:', evaluation);
  }

  private async identifyBottlenecks(
    prediction: ModelPrediction,
    features: TaskFeatures
  ): Promise<Bottleneck[]> {
    const bottlenecks: Bottleneck[] = [];

    // CPU ë³‘ëª©
    if (prediction.cpuRequirement > 0.8) {
      bottlenecks.push({
        type: 'cpu',
        severity: 'high',
        impact: 0.3,
        mitigation: 'Consider CPU-optimized instance or parallel processing'
      });
    }

    // ë©”ëª¨ë¦¬ ë³‘ëª©
    if (prediction.memoryRequirement > 0.7) {
      bottlenecks.push({
        type: 'memory',
        severity: 'medium',
        impact: 0.2,
        mitigation: 'Increase memory allocation or optimize memory usage'
      });
    }

    // I/O ë³‘ëª©
    if (prediction.ioRequirement > 0.6 && features.dataSize > 1000000) {
      bottlenecks.push({
        type: 'io',
        severity: 'medium',
        impact: 0.25,
        mitigation: 'Use SSD storage or implement caching strategy'
      });
    }

    // ì˜ì¡´ì„± ë³‘ëª©
    if (features.dependencyCount > 5) {
      bottlenecks.push({
        type: 'dependency',
        severity: 'low',
        impact: 0.15,
        mitigation: 'Consider dependency optimization or parallelization'
      });
    }

    return bottlenecks;
  }
}

// ì›Œí¬ë¡œë“œ ë¶„ì„ê¸°
export class WorkloadAnalyzer {
  private patternDetector: PatternDetector;
  private seasonalityAnalyzer: SeasonalityAnalyzer;
  private anomalyDetector: AnomalyDetector;

  constructor() {
    this.patternDetector = new PatternDetector();
    this.seasonalityAnalyzer = new SeasonalityAnalyzer();
    this.anomalyDetector = new AnomalyDetector();
  }

  async predictWorkload(
    tasks: Task[],
    horizon: TimeHorizon
  ): Promise<WorkloadPrediction> {
    // 1. ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘
    const historicalData = await this.collectHistoricalData(horizon.start);

    // 2. íŒ¨í„´ ê°ì§€
    const patterns = await this.patternDetector.detect(historicalData);

    // 3. ê³„ì ˆì„± ë¶„ì„
    const seasonality = await this.seasonalityAnalyzer.analyze(historicalData);

    // 4. íŠ¸ë Œë“œ ë¶„ì„
    const trend = this.analyzeTrend(historicalData);

    // 5. ì˜ˆì¸¡ ëª¨ë¸ ì ìš©
    const forecast = await this.forecastWorkload(
      historicalData,
      patterns,
      seasonality,
      trend,
      horizon
    );

    // 6. ì´ìƒì¹˜ ê°ì§€
    const anomalies = await this.anomalyDetector.detect(forecast);

    return {
      forecast,
      patterns,
      seasonality,
      trend,
      anomalies,
      confidence: this.calculateConfidence(forecast, historicalData)
    };
  }

  private async forecastWorkload(
    historical: WorkloadData[],
    patterns: Pattern[],
    seasonality: Seasonality,
    trend: Trend,
    horizon: TimeHorizon
  ): Promise<WorkloadForecast[]> {
    const forecasts: WorkloadForecast[] = [];
    
    // ARIMA ëª¨ë¸ ì ìš©
    const arimaModel = new ARIMAModel(historical);
    const arimaForecast = await arimaModel.forecast(horizon);

    // ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡
    const timeSlots = this.generateTimeSlots(horizon);
    
    for (const slot of timeSlots) {
      const baseLoad = arimaForecast.getValueAt(slot.start);
      
      // íŒ¨í„´ ì ìš©
      let adjustedLoad = baseLoad;
      for (const pattern of patterns) {
        if (pattern.matches(slot)) {
          adjustedLoad *= pattern.multiplier;
        }
      }

      // ê³„ì ˆì„± ì ìš©
      adjustedLoad *= seasonality.getFactorAt(slot.start);

      // íŠ¸ë Œë“œ ì ìš©
      adjustedLoad += trend.getValueAt(slot.start);

      forecasts.push({
        timeSlot: slot,
        expectedTasks: Math.round(adjustedLoad),
        confidence: this.calculateSlotConfidence(slot, historical),
        resourceDemand: this.estimateResourceDemand(adjustedLoad)
      });
    }

    return forecasts;
  }

  private estimateResourceDemand(taskCount: number): ResourceDemand {
    // ê³¼ê±° ë°ì´í„° ê¸°ë°˜ ë¦¬ì†ŒìŠ¤ ìˆ˜ìš” ì˜ˆì¸¡
    return {
      cpu: taskCount * 0.3, // í‰ê·  CPU ì‚¬ìš©ëŸ‰
      memory: taskCount * 512, // MB
      io: taskCount * 10, // IOPS
      network: taskCount * 1 // Mbps
    };
  }
}

// ë¦¬ì†ŒìŠ¤ ì˜ˆì¸¡ê¸°
export class ResourceForecaster {
  private availabilityPredictor: AvailabilityPredictor;
  private capacityPlanner: CapacityPlanner;
  private failurePredictor: FailurePredictor;

  async forecast(
    resources: ResourcePool[],
    horizon: TimeHorizon
  ): Promise<ResourceForecast> {
    const forecasts: ResourcePrediction[] = [];

    for (const resource of resources) {
      // ê°€ìš©ì„± ì˜ˆì¸¡
      const availability = await this.availabilityPredictor.predict(
        resource,
        horizon
      );

      // ìš©ëŸ‰ ê³„íš
      const capacity = await this.capacityPlanner.plan(
        resource,
        horizon
      );

      // ì¥ì•  ì˜ˆì¸¡
      const failureProbability = await this.failurePredictor.predict(
        resource,
        horizon
      );

      forecasts.push({
        resourceId: resource.id,
        availability,
        capacity,
        failureProbability,
        maintenanceWindows: await this.getMaintenanceWindows(resource, horizon),
        costProjection: await this.projectCost(resource, capacity, horizon)
      });
    }

    return {
      resources: forecasts,
      aggregateCapacity: this.calculateAggregateCapacity(forecasts),
      recommendations: await this.generateCapacityRecommendations(forecasts)
    };
  }

  private async generateCapacityRecommendations(
    forecasts: ResourcePrediction[]
  ): Promise<CapacityRecommendation[]> {
    const recommendations: CapacityRecommendation[] = [];

    for (const forecast of forecasts) {
      // ìš©ëŸ‰ ë¶€ì¡± ì˜ˆì¸¡
      if (forecast.capacity.utilization > 0.8) {
        recommendations.push({
          resourceId: forecast.resourceId,
          type: 'scale-up',
          urgency: forecast.capacity.utilization > 0.9 ? 'high' : 'medium',
          recommendation: `Scale up by ${Math.ceil((forecast.capacity.utilization - 0.7) * 100)}%`,
          estimatedCost: forecast.costProjection.scaleUpCost
        });
      }

      // ê³¼ì‰ ìš©ëŸ‰
      if (forecast.capacity.utilization < 0.3) {
        recommendations.push({
          resourceId: forecast.resourceId,
          type: 'scale-down',
          urgency: 'low',
          recommendation: `Consider scaling down by ${Math.floor((0.5 - forecast.capacity.utilization) * 100)}%`,
          estimatedSavings: forecast.costProjection.scaleDownSavings
        });
      }

      // ì¥ì•  ìœ„í—˜
      if (forecast.failureProbability > 0.1) {
        recommendations.push({
          resourceId: forecast.resourceId,
          type: 'maintenance',
          urgency: 'high',
          recommendation: 'Schedule preventive maintenance',
          risk: forecast.failureProbability
        });
      }
    }

    return recommendations;
  }
}

// ìŠ¤ì¼€ì¤„ ìµœì í™” ì—”ì§„
export class ScheduleOptimizer {
  private solver: OptimizationSolver;
  private evaluator: ScheduleEvaluator;

  constructor() {
    this.solver = new GeneticOptimizationSolver();
    this.evaluator = new ScheduleEvaluator();
  }

  async optimize(params: OptimizationParams): Promise<OptimizedSchedule> {
    // 1. ì´ˆê¸° ìŠ¤ì¼€ì¤„ ìƒì„±
    const initialSchedule = this.generateInitialSchedule(
      params.tasks,
      params.resources
    );

    // 2. ìµœì í™” ë¬¸ì œ ì •ì˜
    const problem = this.formulateOptimizationProblem(params);

    // 3. ìµœì í™” ì‹¤í–‰
    const solution = await this.solver.solve(problem, {
      initialSolution: initialSchedule,
      maxIterations: 1000,
      timeLimit: 30000 // 30ì´ˆ
    });

    // 4. ìŠ¤ì¼€ì¤„ í‰ê°€
    const evaluation = await this.evaluator.evaluate(
      solution.schedule,
      params.objectives
    );

    return {
      schedule: solution.schedule,
      objectives: evaluation,
      improvements: this.calculateImprovements(initialSchedule, solution.schedule),
      confidence: solution.confidence
    };
  }

  private formulateOptimizationProblem(
    params: OptimizationParams
  ): OptimizationProblem {
    return {
      variables: this.createDecisionVariables(params.tasks, params.resources),
      objectives: params.objectives.map(obj => this.createObjectiveFunction(obj)),
      constraints: [
        ...this.createResourceConstraints(params.resources),
        ...this.createDependencyConstraints(params.tasks),
        ...this.createCustomConstraints(params.constraints)
      ]
    };
  }

  private createObjectiveFunction(objective: string): ObjectiveFunction {
    switch (objective) {
      case 'minimize_makespan':
        return {
          type: 'minimize',
          function: (schedule: Schedule) => this.calculateMakespan(schedule)
        };

      case 'maximize_utilization':
        return {
          type: 'maximize',
          function: (schedule: Schedule) => this.calculateUtilization(schedule)
        };

      case 'minimize_cost':
        return {
          type: 'minimize',
          function: (schedule: Schedule) => this.calculateCost(schedule)
        };

      case 'balance_load':
        return {
          type: 'minimize',
          function: (schedule: Schedule) => this.calculateLoadImbalance(schedule)
        };

      default:
        throw new Error(`Unknown objective: ${objective}`);
    }
  }
}

// ì˜ˆì¸¡ ì‹ ë¢°ë„ í‰ê°€ê¸°
export class ConfidenceEstimator {
  private uncertaintyQuantifier: UncertaintyQuantifier;
  private validationMetrics: ValidationMetrics;

  async estimate(
    prediction: any,
    features: any
  ): Promise<ConfidenceEstimate> {
    // 1. ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
    const uncertainty = await this.uncertaintyQuantifier.quantify(
      prediction,
      features
    );

    // 2. ê³¼ê±° ì •í™•ë„ ë¶„ì„
    const historicalAccuracy = await this.getHistoricalAccuracy(
      features.taskType
    );

    // 3. íŠ¹ì§• ì‹ ë¢°ë„
    const featureConfidence = this.assessFeatureQuality(features);

    // 4. ëª¨ë¸ ì‹ ë¢°ë„
    const modelConfidence = await this.assessModelConfidence(prediction);

    // ì¢…í•© ì‹ ë¢°ë„ ê³„ì‚°
    const overallConfidence = this.combineConfidenceScores({
      uncertainty: 1 - uncertainty.epistemic,
      accuracy: historicalAccuracy,
      features: featureConfidence,
      model: modelConfidence
    });

    return {
      overall: overallConfidence,
      components: {
        dataQuality: featureConfidence,
        modelCertainty: modelConfidence,
        historicalPerformance: historicalAccuracy
      },
      margin: uncertainty.aleatoric,
      recommendation: this.getConfidenceRecommendation(overallConfidence)
    };
  }

  private combineConfidenceScores(scores: ConfidenceComponents): number {
    // ê°€ì¤‘ ì¡°í™” í‰ê· 
    const weights = {
      uncertainty: 0.3,
      accuracy: 0.3,
      features: 0.2,
      model: 0.2
    };

    let weightedSum = 0;
    let totalWeight = 0;

    for (const [key, value] of Object.entries(scores)) {
      const weight = weights[key] || 0.1;
      weightedSum += weight / value;
      totalWeight += weight;
    }

    return totalWeight / weightedSum;
  }

  private getConfidenceRecommendation(confidence: number): string {
    if (confidence > 0.9) {
      return 'High confidence - proceed with predicted schedule';
    } else if (confidence > 0.7) {
      return 'Moderate confidence - monitor closely';
    } else if (confidence > 0.5) {
      return 'Low confidence - consider fallback options';
    } else {
      return 'Very low confidence - use conservative estimates';
    }
  }
}

// ì ì‘í˜• ìŠ¤ì¼€ì¤„ëŸ¬
export class AdaptiveScheduler {
  private baseScheduler: PredictiveScheduler;
  private performanceMonitor: PerformanceMonitor;
  private adaptationEngine: AdaptationEngine;

  async scheduleWithAdaptation(
    request: SchedulingRequest
  ): Promise<AdaptiveSchedule> {
    // 1. ì´ˆê¸° ì˜ˆì¸¡ ìŠ¤ì¼€ì¤„
    const predictiveSchedule = await this.baseScheduler.generatePredictiveSchedule(
      request.tasks,
      request.currentState,
      request.horizon
    );

    // 2. ì ì‘í˜• ì¡°ì •
    const adaptedSchedule = await this.adaptationEngine.adapt(
      predictiveSchedule,
      await this.performanceMonitor.getCurrentPerformance()
    );

    // 3. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì„¤ì •
    const monitoringPlan = this.setupMonitoring(adaptedSchedule);

    // 4. í”¼ë“œë°± ë£¨í”„ ì„¤ì •
    this.setupFeedbackLoop(adaptedSchedule);

    return {
      schedule: adaptedSchedule,
      monitoringPlan,
      adaptationRules: this.generateAdaptationRules(adaptedSchedule),
      fallbackOptions: await this.generateFallbacks(adaptedSchedule)
    };
  }

  private setupFeedbackLoop(schedule: Schedule): void {
    // ì‹¤í–‰ ê²°ê³¼ ìˆ˜ì§‘
    schedule.onTaskComplete((task, result) => {
      this.performanceMonitor.recordExecution(task, result);
      
      // ì˜ˆì¸¡ ì •í™•ë„ ì—…ë°ì´íŠ¸
      this.updatePredictionAccuracy(task, result);
      
      // í•„ìš”ì‹œ ì¬ìŠ¤ì¼€ì¤„ë§
      if (this.needsRescheduling(result)) {
        this.triggerRescheduling(schedule, task);
      }
    });

    // ì£¼ê¸°ì  ì„±ëŠ¥ í‰ê°€
    setInterval(() => {
      this.evaluateSchedulePerformance(schedule);
    }, 60000); // 1ë¶„ë§ˆë‹¤
  }

  private generateAdaptationRules(
    schedule: Schedule
  ): AdaptationRule[] {
    return [
      {
        condition: 'task_duration_deviation > 20%',
        action: 'reschedule_dependent_tasks',
        priority: 'high'
      },
      {
        condition: 'resource_failure',
        action: 'migrate_to_backup_resource',
        priority: 'critical'
      },
      {
        condition: 'queue_depth > threshold',
        action: 'enable_burst_capacity',
        priority: 'medium'
      },
      {
        condition: 'success_rate < 0.8',
        action: 'increase_retry_budget',
        priority: 'medium'
      }
    ];
  }

  async triggerRescheduling(
    currentSchedule: Schedule,
    triggerTask: Task
  ): Promise<void> {
    // ì˜í–¥ë°›ëŠ” íƒœìŠ¤í¬ ì‹ë³„
    const affectedTasks = this.identifyAffectedTasks(
      currentSchedule,
      triggerTask
    );

    // ë¶€ë¶„ ì¬ìŠ¤ì¼€ì¤„ë§
    const partialSchedule = await this.baseScheduler.reschedulePartial(
      affectedTasks,
      currentSchedule
    );

    // ìŠ¤ì¼€ì¤„ ì—…ë°ì´íŠ¸
    await this.applyScheduleUpdate(currentSchedule, partialSchedule);
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ML ê¸°ë°˜ íƒœìŠ¤í¬ ì˜ˆì¸¡
- [ ] ì›Œí¬ë¡œë“œ íŒ¨í„´ ë¶„ì„
- [ ] ë¦¬ì†ŒìŠ¤ ê°€ìš©ì„± ì˜ˆì¸¡
- [ ] ì ì‘í˜• ìŠ¤ì¼€ì¤„ë§

#### SubTask 5.8.4: ìŠ¤ì¼€ì¤„ëŸ¬ ì„±ëŠ¥ ìµœì í™”
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/scheduler/performance_optimization.ts
export class SchedulerPerformanceOptimizer {
  private profiler: SchedulerProfiler;
  private cacheManager: ScheduleCacheManager;
  private parallelizer: ScheduleParallelizer;
  private indexOptimizer: IndexOptimizer;

  constructor(config: OptimizerConfig) {
    this.profiler = new SchedulerProfiler();
    this.cacheManager = new ScheduleCacheManager(config.cache);
    this.parallelizer = new ScheduleParallelizer(config.parallelism);
    this.indexOptimizer = new IndexOptimizer();
  }

  async optimizeScheduler(
    scheduler: IntelligentScheduler
  ): Promise<OptimizationResult> {
    // 1. ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
    const profile = await this.profiler.profile(scheduler);

    // 2. ë³‘ëª© ì§€ì  ì‹ë³„
    const bottlenecks = this.identifyBottlenecks(profile);

    // 3. ìµœì í™” ì „ëµ ì ìš©
    const optimizations = await this.applyOptimizations(
      scheduler,
      bottlenecks
    );

    // 4. ì„±ëŠ¥ ê²€ì¦
    const validation = await this.validateOptimizations(
      scheduler,
      optimizations
    );

    return {
      originalPerformance: profile,
      optimizations,
      improvement: validation.improvement,
      recommendations: this.generateRecommendations(validation)
    };
  }

  private async applyOptimizations(
    scheduler: IntelligentScheduler,
    bottlenecks: Bottleneck[]
  ): Promise<AppliedOptimization[]> {
    const optimizations: AppliedOptimization[] = [];

    for (const bottleneck of bottlenecks) {
      switch (bottleneck.type) {
        case 'algorithm_complexity':
          optimizations.push(
            await this.optimizeAlgorithmComplexity(scheduler, bottleneck)
          );
          break;

        case 'data_structure':
          optimizations.push(
            await this.optimizeDataStructures(scheduler, bottleneck)
          );
          break;

        case 'io_bound':
          optimizations.push(
            await this.optimizeIO(scheduler, bottleneck)
          );
          break;

        case 'cache_miss':
          optimizations.push(
            await this.optimizeCaching(scheduler, bottleneck)
          );
          break;

        case 'lock_contention':
          optimizations.push(
            await this.optimizeLocking(scheduler, bottleneck)
          );
          break;
      }
    }

    return optimizations;
  }

  private async optimizeAlgorithmComplexity(
    scheduler: IntelligentScheduler,
    bottleneck: Bottleneck
  ): Promise<AppliedOptimization> {
    // íœ´ë¦¬ìŠ¤í‹± ê°œì„ 
    if (bottleneck.location === 'task_sorting') {
      // í™ ê¸°ë°˜ ì •ë ¬ë¡œ ë³€ê²½
      return {
        type: 'algorithm',
        description: 'Replace quicksort with heap-based sorting',
        implementation: async () => {
          scheduler.setSortingAlgorithm(new HeapSort());
        },
        expectedImprovement: 0.3
      };
    }

    // ë™ì  í”„ë¡œê·¸ë˜ë° ì ìš©
    if (bottleneck.location === 'dependency_resolution') {
      return {
        type: 'algorithm',
        description: 'Apply dynamic programming to dependency resolution',
        implementation: async () => {
          scheduler.setDependencyResolver(new DPDependencyResolver());
        },
        expectedImprovement: 0.4
      };
    }

    return null;
  }

  private async optimizeCaching(
    scheduler: IntelligentScheduler,
    bottleneck: Bottleneck
  ): Promise<AppliedOptimization> {
    const cacheConfig = await this.cacheManager.analyzeAndConfigure(
      bottleneck
    );

    return {
      type: 'caching',
      description: 'Implement multi-level caching strategy',
      implementation: async () => {
        // L1 ìºì‹œ - ìì£¼ ì‚¬ìš©ë˜ëŠ” ìŠ¤ì¼€ì¤„ ê²°ì •
        scheduler.addCache('l1', new LRUCache({
          maxSize: 1000,
          ttl: 60000 // 1ë¶„
        }));

        // L2 ìºì‹œ - íƒœìŠ¤í¬ ì˜ˆì¸¡ ê²°ê³¼
        scheduler.addCache('l2', new RedisCache({
          maxSize: 10000,
          ttl: 300000 // 5ë¶„
        }));

        // ìºì‹œ ì›Œë°
        await this.warmCache(scheduler);
      },
      expectedImprovement: 0.5
    };
  }

  private async warmCache(scheduler: IntelligentScheduler): Promise<void> {
    // ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒ¨í„´ ì‚¬ì „ ê³„ì‚°
    const commonPatterns = await this.identifyCommonPatterns();

    for (const pattern of commonPatterns) {
      const result = await scheduler.computeSchedule(pattern);
      await scheduler.cache.set(pattern.key, result);
    }
  }
}

// ìŠ¤ì¼€ì¤„ ìºì‹œ ê´€ë¦¬ì
export class ScheduleCacheManager {
  private caches: Map<string, ICache>;
  private hitRateMonitor: HitRateMonitor;
  private evictionPolicy: EvictionPolicy;

  constructor(config: CacheConfig) {
    this.caches = new Map();
    this.hitRateMonitor = new HitRateMonitor();
    this.evictionPolicy = new AdaptiveEvictionPolicy(config);
  }

  async get(
    key: string,
    compute: () => Promise<any>
  ): Promise<CacheResult> {
    const startTime = Date.now();
    
    // ë‹¤ë‹¨ê³„ ìºì‹œ í™•ì¸
    for (const [name, cache] of this.caches) {
      const value = await cache.get(key);
      
      if (value !== undefined) {
        this.hitRateMonitor.recordHit(name);
        
        return {
          value,
          cached: true,
          cacheLevel: name,
          latency: Date.now() - startTime
        };
      }
    }

    // ìºì‹œ ë¯¸ìŠ¤ - ê³„ì‚° ìˆ˜í–‰
    this.hitRateMonitor.recordMiss();
    const value = await compute();

    // ìºì‹œì— ì €ì¥
    await this.store(key, value);

    return {
      value,
      cached: false,
      latency: Date.now() - startTime
    };
  }

  private async store(key: string, value: any): Promise<void> {
    // ì ì‘í˜• ìºì‹± - ê°’ì˜ ì¤‘ìš”ë„ì— ë”°ë¼ ìºì‹œ ë ˆë²¨ ê²°ì •
    const importance = await this.calculateImportance(key, value);
    
    if (importance > 0.8) {
      // ëª¨ë“  ë ˆë²¨ì— ì €ì¥
      for (const [name, cache] of this.caches) {
        await cache.set(key, value);
      }
    } else if (importance > 0.5) {
      // L1, L2ì—ë§Œ ì €ì¥
      await this.caches.get('l1')?.set(key, value);
      await this.caches.get('l2')?.set(key, value);
    } else {
      // L1ì—ë§Œ ì €ì¥
      await this.caches.get('l1')?.set(key, value);
    }
  }

  async invalidate(pattern: string): Promise<void> {
    const tasks = [];
    
    for (const [name, cache] of this.caches) {
      tasks.push(cache.invalidate(pattern));
    }

    await Promise.all(tasks);
  }

  getStats(): CacheStatistics {
    return {
      hitRate: this.hitRateMonitor.getOverallHitRate(),
      levelStats: this.hitRateMonitor.getLevelStats(),
      memoryUsage: this.calculateMemoryUsage(),
      evictionStats: this.evictionPolicy.getStats()
    };
  }
}

// ë³‘ë ¬ ìŠ¤ì¼€ì¤„ë§ ìµœì í™”
export class ScheduleParallelizer {
  private workerPool: WorkerPool;
  private taskPartitioner: TaskPartitioner;
  private resultAggregator: ResultAggregator;

  constructor(config: ParallelismConfig) {
    this.workerPool = new WorkerPool(config.workers);
    this.taskPartitioner = new TaskPartitioner();
    this.resultAggregator = new ResultAggregator();
  }

  async parallelSchedule(
    tasks: Task[],
    resources: ResourcePool[]
  ): Promise<Schedule> {
    // 1. íƒœìŠ¤í¬ ë¶„í• 
    const partitions = await this.taskPartitioner.partition(
      tasks,
      this.workerPool.size
    );

    // 2. ë³‘ë ¬ ìŠ¤ì¼€ì¤„ë§
    const partialSchedules = await Promise.all(
      partitions.map((partition, index) => 
        this.workerPool.execute(index, {
          type: 'schedule',
          tasks: partition,
          resources: resources
        })
      )
    );

    // 3. ê²°ê³¼ ë³‘í•©
    const mergedSchedule = await this.resultAggregator.merge(
      partialSchedules
    );

    // 4. ì¶©ëŒ í•´ê²°
    const resolved = await this.resolveConflicts(mergedSchedule);

    return resolved;
  }

  private async resolveConflicts(
    schedule: Schedule
  ): Promise<Schedule> {
    const conflicts = this.detectConflicts(schedule);
    
    if (conflicts.length === 0) {
      return schedule;
    }

    // ì¶©ëŒ í•´ê²° ì „ëµ
    const resolver = new ConflictResolver();
    
    for (const conflict of conflicts) {
      const resolution = await resolver.resolve(conflict);
      this.applyResolution(schedule, resolution);
    }

    // ì¬ê·€ì ìœ¼ë¡œ í™•ì¸
    return this.resolveConflicts(schedule);
  }
}

// ì¸ë±ìŠ¤ ìµœì í™”
export class IndexOptimizer {
  private indexAnalyzer: IndexAnalyzer;
  private indexBuilder: IndexBuilder;

  async optimizeIndices(
    scheduler: IntelligentScheduler
  ): Promise<IndexOptimization[]> {
    // 1. ì¿¼ë¦¬ íŒ¨í„´ ë¶„ì„
    const queryPatterns = await this.indexAnalyzer.analyzeQueries(
      scheduler.getQueryLog()
    );

    // 2. ì¸ë±ìŠ¤ ì¶”ì²œ
    const recommendations = this.recommendIndices(queryPatterns);

    // 3. ì¸ë±ìŠ¤ êµ¬ì¶•
    const optimizations: IndexOptimization[] = [];

    for (const rec of recommendations) {
      const index = await this.indexBuilder.build(rec);
      
      optimizations.push({
        name: rec.name,
        type: rec.type,
        fields: rec.fields,
        improvement: await this.measureImprovement(scheduler, index)
      });

      // ìŠ¤ì¼€ì¤„ëŸ¬ì— ì¸ë±ìŠ¤ ì ìš©
      scheduler.addIndex(index);
    }

    return optimizations;
  }

  private recommendIndices(
    patterns: QueryPattern[]
  ): IndexRecommendation[] {
    const recommendations: IndexRecommendation[] = [];

    // ë¹ˆë„ê°€ ë†’ì€ ì¿¼ë¦¬ íŒ¨í„´ì— ëŒ€í•œ ì¸ë±ìŠ¤
    const frequentPatterns = patterns.filter(p => p.frequency > 100);
    
    for (const pattern of frequentPatterns) {
      if (pattern.type === 'task_by_priority') {
        recommendations.push({
          name: 'idx_task_priority',
          type: 'btree',
          fields: ['priority', 'created_at'],
          unique: false
        });
      }

      if (pattern.type === 'resource_availability') {
        recommendations.push({
          name: 'idx_resource_availability',
          type: 'bitmap',
          fields: ['resource_id', 'available'],
          unique: false
        });
      }

      if (pattern.type === 'dependency_lookup') {
        recommendations.push({
          name: 'idx_task_dependencies',
          type: 'hash',
          fields: ['task_id', 'depends_on'],
          unique: false
        });
      }
    }

    return recommendations;
  }
}

// JIT ì»´íŒŒì¼ ìµœì í™”
export class JITOptimizer {
  private compiler: JITCompiler;
  private hotspotDetector: HotspotDetector;

  async optimize(scheduler: IntelligentScheduler): Promise<void> {
    // 1. í•«ìŠ¤íŒŸ ê°ì§€
    const hotspots = await this.hotspotDetector.detect(scheduler);

    // 2. í•« ê²½ë¡œ ì»´íŒŒì¼
    for (const hotspot of hotspots) {
      if (hotspot.invocations > 10000) {
        const optimizedCode = await this.compiler.compile(
          hotspot.function,
          {
            level: 'aggressive',
            inlining: true,
            vectorization: true
          }
        );

        // ì›ë³¸ í•¨ìˆ˜ êµì²´
        scheduler.replaceFunction(
          hotspot.functionName,
          optimizedCode
        );
      }
    }

    // 3. ì¸ë¼ì¸ ìºì‹±
    this.enableInlineCaching(scheduler);
  }

  private enableInlineCaching(scheduler: IntelligentScheduler): void {
    // ë‹¤í˜•ì„± í˜¸ì¶œ ì‚¬ì´íŠ¸ ìµœì í™”
    scheduler.enableFeature('inline_caching', {
      maxCacheSize: 8,
      monomorphicThreshold: 0.95,
      polymorphicThreshold: 0.8
    });
  }
}

// ë©”ëª¨ë¦¬ ìµœì í™”
export class MemoryOptimizer {
  private memoryProfiler: MemoryProfiler;
  private objectPoolManager: ObjectPoolManager;
  private gcTuner: GCTuner;

  async optimizeMemory(scheduler: IntelligentScheduler): Promise<void> {
    // 1. ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§
    const profile = await this.memoryProfiler.profile(scheduler);

    // 2. ê°ì²´ í’€ ì ìš©
    if (profile.allocationRate > 1000) { // ì´ˆë‹¹ 1000ê°œ ì´ìƒ í• ë‹¹
      await this.applyObjectPooling(scheduler, profile);
    }

    // 3. GC íŠœë‹
    await this.gcTuner.tune({
      heapSize: profile.heapSize,
      allocationRate: profile.allocationRate,
      gcPauseTarget: 10 // 10ms
    });

    // 4. ë©”ëª¨ë¦¬ ì••ì¶•
    if (profile.fragmentation > 0.3) {
      await this.compactMemory(scheduler);
    }
  }

  private async applyObjectPooling(
    scheduler: IntelligentScheduler,
    profile: MemoryProfile
  ): Promise<void> {
    // ìì£¼ í• ë‹¹ë˜ëŠ” ê°ì²´ íƒ€ì… ì‹ë³„
    const hotTypes = profile.hotAllocationTypes;

    for (const type of hotTypes) {
      const pool = this.objectPoolManager.createPool({
        type,
        initialSize: 100,
        maxSize: 1000,
        factory: () => new type(),
        reset: (obj) => obj.reset()
      });

      // ìŠ¤ì¼€ì¤„ëŸ¬ì— í’€ ë“±ë¡
      scheduler.registerObjectPool(type, pool);
    }
  }

  private async compactMemory(
    scheduler: IntelligentScheduler
  ): Promise<void> {
    // ë©”ëª¨ë¦¬ ì••ì¶• ì „ëµ
    await scheduler.pauseScheduling();
    
    // 1. ë¶ˆí•„ìš”í•œ ì°¸ì¡° ì œê±°
    scheduler.cleanupReferences();
    
    // 2. ê°•ì œ GC
    if (global.gc) {
      global.gc();
    }
    
    // 3. ë©”ëª¨ë¦¬ ì¬êµ¬ì„±
    await scheduler.reorganizeMemory();
    
    await scheduler.resumeScheduling();
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ì‹œìŠ¤í…œ
- [ ] ìºì‹± ì „ëµ êµ¬í˜„
- [ ] ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
- [ ] ë©”ëª¨ë¦¬ ë° GC ìµœì í™”

### Task 5.9: ë¶€í•˜ ë¶„ì‚° ë° ìë™ ìŠ¤ì¼€ì¼ë§

#### SubTask 5.9.1: ë¶€í•˜ ë¶„ì‚° ì „ëµ êµ¬í˜„
**ë‹´ë‹¹ì**: ì¸í”„ë¼ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/loadbalancing/load_balancer.ts
export interface LoadBalancingStrategy {
  name: string;
  selectTarget(
    request: WorkloadRequest,
    targets: Target[],
    metrics: TargetMetrics[]
  ): Promise<Target | null>;
}

export class IntelligentLoadBalancer {
  private strategies: Map<string, LoadBalancingStrategy>;
  private metricsCollector: MetricsCollector;
  private healthChecker: HealthChecker;
  private circuitBreaker: CircuitBreaker;

  constructor(config: LoadBalancerConfig) {
    this.strategies = new Map();
    this.metricsCollector = new MetricsCollector(config.metrics);
    this.healthChecker = new HealthChecker(config.health);
    this.circuitBreaker = new CircuitBreaker(config.circuitBreaker);
    
    this.registerStrategies();
  }

  private registerStrategies(): void {
    this.strategies.set('round-robin', new RoundRobinStrategy());
    this.strategies.set('least-connections', new LeastConnectionsStrategy());
    this.strategies.set('weighted-round-robin', new WeightedRoundRobinStrategy());
    this.strategies.set('least-response-time', new LeastResponseTimeStrategy());
    this.strategies.set('hash-based', new HashBasedStrategy());
    this.strategies.set('adaptive', new AdaptiveStrategy());
    this.strategies.set('ml-optimized', new MLOptimizedStrategy());
  }

  async route(request: WorkloadRequest): Promise<RoutingResult> {
    const startTime = Date.now();

    try {
      // 1. ê±´ê°•í•œ íƒ€ê²Ÿ í•„í„°ë§
      const healthyTargets = await this.getHealthyTargets();

      if (healthyTargets.length === 0) {
        throw new NoHealthyTargetsError('No healthy targets available');
      }

      // 2. íƒ€ê²Ÿ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
      const metrics = await this.collectTargetMetrics(healthyTargets);

      // 3. ì „ëµ ì„ íƒ
      const strategy = await this.selectStrategy(request, metrics);

      // 4. íƒ€ê²Ÿ ì„ íƒ
      const target = await strategy.selectTarget(
        request,
        healthyTargets,
        metrics
      );

      if (!target) {
        throw new NoSuitableTargetError('No suitable target found');
      }

      // 5. ì„œí‚· ë¸Œë ˆì´ì»¤ í™•ì¸
      if (await this.circuitBreaker.isOpen(target.id)) {
        return this.handleCircuitOpen(request, target);
      }

      // 6. ë¼ìš°íŒ… ì‹¤í–‰
      const result = await this.executeRouting(request, target);

      // 7. ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
      await this.updateMetrics(target, result, Date.now() - startTime);

      return result;

    } catch (error) {
      logger.error('Load balancing failed', { error, request });
      throw error;
    }
  }

  private async getHealthyTargets(): Promise<Target[]> {
    const allTargets = await this.getAllTargets();
    const healthChecks = await Promise.all(
      allTargets.map(target => this.healthChecker.check(target))
    );

    return allTargets.filter((target, index) => healthChecks[index].healthy);
  }

  private async selectStrategy(
    request: WorkloadRequest,
    metrics: TargetMetrics[]
  ): Promise<LoadBalancingStrategy> {
    // ìš”ì²­ íŠ¹ì„±ì— ë”°ë¥¸ ì „ëµ ì„ íƒ
    if (request.requiresAffinity) {
      return this.strategies.get('hash-based')!;
    }

    if (request.priority === 'high') {
      return this.strategies.get('least-response-time')!;
    }

    // ì‹œìŠ¤í…œ ìƒíƒœì— ë”°ë¥¸ ì ì‘í˜• ì„ íƒ
    const systemLoad = this.calculateSystemLoad(metrics);
    if (systemLoad.variance > 0.3) {
      return this.strategies.get('adaptive')!;
    }

    // ê¸°ë³¸ ì „ëµ
    return this.strategies.get('weighted-round-robin')!;
  }

  private async executeRouting(
    request: WorkloadRequest,
    target: Target
  ): Promise<RoutingResult> {
    try {
      // ì—°ê²° ìˆ˜ ì¦ê°€
      await this.incrementConnections(target);

      // ì‹¤ì œ ë¼ìš°íŒ…
      const response = await this.forwardRequest(request, target);

      return {
        success: true,
        target,
        response,
        latency: response.latency
      };

    } catch (error) {
      // ì‹¤íŒ¨ ì²˜ë¦¬
      await this.handleRoutingFailure(target, error);
      throw error;

    } finally {
      // ì—°ê²° ìˆ˜ ê°ì†Œ
      await this.decrementConnections(target);
    }
  }
}

// ì ì‘í˜• ë¶€í•˜ ë¶„ì‚° ì „ëµ
export class AdaptiveStrategy implements LoadBalancingStrategy {
  name = 'adaptive';
  
  private predictor: LoadPredictor;
  private optimizer: TargetOptimizer;

  constructor() {
    this.predictor = new LoadPredictor();
    this.optimizer = new TargetOptimizer();
  }

  async selectTarget(
    request: WorkloadRequest,
    targets: Target[],
    metrics: TargetMetrics[]
  ): Promise<Target | null> {
    // 1. ë¯¸ë˜ ë¶€í•˜ ì˜ˆì¸¡
    const predictions = await this.predictor.predictLoad(targets, metrics);

    // 2. ìµœì í™” ì ìˆ˜ ê³„ì‚°
    const scores = await this.calculateOptimizationScores(
      request,
      targets,
      metrics,
      predictions
    );

    // 3. ìµœì  íƒ€ê²Ÿ ì„ íƒ
    const optimal = this.selectOptimalTarget(scores);

    return optimal;
  }

  private async calculateOptimizationScores(
    request: WorkloadRequest,
    targets: Target[],
    metrics: TargetMetrics[],
    predictions: LoadPrediction[]
  ): Promise<TargetScore[]> {
    const scores: TargetScore[] = [];

    for (let i = 0; i < targets.length; i++) {
      const target = targets[i];
      const metric = metrics[i];
      const prediction = predictions[i];

      const score = await this.optimizer.calculateScore({
        target,
        currentMetrics: metric,
        predictedLoad: prediction,
        requestCharacteristics: request,
        weights: {
          responseTime: 0.3,
          throughput: 0.2,
          errorRate: 0.2,
          resourceUtilization: 0.2,
          predictedAvailability: 0.1
        }
      });

      scores.push({ target, score });
    }

    return scores;
  }

  private selectOptimalTarget(scores: TargetScore[]): Target | null {
    if (scores.length === 0) return null;

    // ì ìˆ˜ ê¸°ë°˜ í™•ë¥ ì  ì„ íƒ (ë†’ì€ ì ìˆ˜ì¼ìˆ˜ë¡ ì„ íƒ í™•ë¥  ì¦ê°€)
    const totalScore = scores.reduce((sum, s) => sum + s.score, 0);
    
    if (totalScore === 0) {
      // ëª¨ë“  ì ìˆ˜ê°€ 0ì¸ ê²½ìš° ê· ë“± ì„ íƒ
      return scores[Math.floor(Math.random() * scores.length)].target;
    }

    let random = Math.random() * totalScore;
    
    for (const { target, score } of scores) {
      random -= score;
      if (random <= 0) {
        return target;
      }
    }

    return scores[scores.length - 1].target;
  }
}

// ML ìµœì í™” ë¶€í•˜ ë¶„ì‚°
export class MLOptimizedStrategy implements LoadBalancingStrategy {
  name = 'ml-optimized';
  
  private model: LoadBalancingModel;
  private featureExtractor: FeatureExtractor;

  constructor() {
    this.model = new LoadBalancingModel();
    this.featureExtractor = new FeatureExtractor();
  }

  async selectTarget(
    request: WorkloadRequest,
    targets: Target[],
    metrics: TargetMetrics[]
  ): Promise<Target | null> {
    // 1. íŠ¹ì§• ì¶”ì¶œ
    const features = await this.featureExtractor.extract({
      request,
      targets,
      metrics,
      timestamp: new Date()
    });

    // 2. ML ëª¨ë¸ ì˜ˆì¸¡
    const predictions = await this.model.predict(features);

    // 3. ìµœì  íƒ€ê²Ÿ ì„ íƒ
    const targetIndex = predictions.optimalTargetIndex;
    
    if (targetIndex >= 0 && targetIndex < targets.length) {
      return targets[targetIndex];
    }

    // í´ë°±: ìµœì†Œ ì‘ë‹µ ì‹œê°„
    return this.fallbackSelection(targets, metrics);
  }

  private fallbackSelection(
    targets: Target[],
    metrics: TargetMetrics[]
  ): Target | null {
    let minResponseTime = Infinity;
    let selectedTarget: Target | null = null;

    for (let i = 0; i < targets.length; i++) {
      if (metrics[i].avgResponseTime < minResponseTime) {
        minResponseTime = metrics[i].avgResponseTime;
        selectedTarget = targets[i];
      }
    }

    return selectedTarget;
  }
}

// ì§€ì—­ ì¸ì‹ ë¶€í•˜ ë¶„ì‚°
export class GeoAwareLoadBalancer {
  private geoResolver: GeoResolver;
  private latencyPredictor: LatencyPredictor;
  private complianceChecker: ComplianceChecker;

  async route(request: WorkloadRequest): Promise<RoutingResult> {
    // 1. ìš”ì²­ ì§€ì—­ í™•ì¸
    const requestLocation = await this.geoResolver.resolve(request.clientIP);

    // 2. ê·œì • ì¤€ìˆ˜ í™•ì¸
    const complianceRequirements = await this.complianceChecker.check(
      requestLocation,
      request.dataType
    );

    // 3. ì í•©í•œ íƒ€ê²Ÿ í•„í„°ë§
    const eligibleTargets = await this.filterByCompliance(
      await this.getAllTargets(),
      complianceRequirements
    );

    // 4. ì§€ì—° ì‹œê°„ ì˜ˆì¸¡
    const latencyPredictions = await this.latencyPredictor.predict(
      requestLocation,
      eligibleTargets
    );

    // 5. ìµœì  íƒ€ê²Ÿ ì„ íƒ
    const optimal = this.selectOptimalByLatency(
      eligibleTargets,
      latencyPredictions
    );

    return this.executeRouting(request, optimal);
  }

  private async filterByCompliance(
    targets: Target[],
    requirements: ComplianceRequirements
  ): Promise<Target[]> {
    return targets.filter(target => {
      // ë°ì´í„° ìƒì£¼ ìš”êµ¬ì‚¬í•­
      if (requirements.dataResidency) {
        if (!requirements.allowedRegions.includes(target.region)) {
          return false;
        }
      }

      // GDPR ì¤€ìˆ˜
      if (requirements.gdprCompliant && !target.gdprCertified) {
        return false;
      }

      // ê¸°íƒ€ ê·œì •
      return true;
    });
  }

  private selectOptimalByLatency(
    targets: Target[],
    predictions: LatencyPrediction[]
  ): Target {
    // P95 ì§€ì—°ì‹œê°„ ê¸°ì¤€ ì„ íƒ
    let minP95 = Infinity;
    let optimalTarget = targets[0];

    for (let i = 0; i < targets.length; i++) {
      if (predictions[i].p95 < minP95) {
        minP95 = predictions[i].p95;
        optimalTarget = targets[i];
      }
    }

    return optimalTarget;
  }
}

// ì„¸ì…˜ ì¹œí™”ì„± ê´€ë¦¬
export class SessionAffinityManager {
  private sessionStore: SessionStore;
  private affinityRules: AffinityRule[];

  async getTargetForSession(
    sessionId: string,
    availableTargets: Target[]
  ): Promise<Target | null> {
    // 1. ê¸°ì¡´ ì„¸ì…˜ í™•ì¸
    const existingAffinity = await this.sessionStore.get(sessionId);
    
    if (existingAffinity) {
      const target = availableTargets.find(
        t => t.id === existingAffinity.targetId
      );
      
      if (target) {
        // ì„¸ì…˜ ê°±ì‹ 
        await this.sessionStore.refresh(sessionId);
        return target;
      }
    }

    // 2. ìƒˆ íƒ€ê²Ÿ í• ë‹¹
    const newTarget = await this.assignNewTarget(
      sessionId,
      availableTargets
    );

    // 3. ì„¸ì…˜ ì €ì¥
    await this.sessionStore.set(sessionId, {
      targetId: newTarget.id,
      createdAt: new Date(),
      lastAccessed: new Date()
    });

    return newTarget;
  }

  private async assignNewTarget(
    sessionId: string,
    targets: Target[]
  ): Promise<Target> {
    // ì„¸ì…˜ ê¸°ë°˜ ì¼ê´€ëœ í•´ì‹±
    const hash = this.hashSession(sessionId);
    const index = hash % targets.length;
    
    return targets[index];
  }

  private hashSession(sessionId: string): number {
    let hash = 0;
    for (let i = 0; i < sessionId.length; i++) {
      const char = sessionId.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // Convert to 32-bit integer
    }
    return Math.abs(hash);
  }
}

// ë™ì  ê°€ì¤‘ì¹˜ ê´€ë¦¬
export class DynamicWeightManager {
  private weights: Map<string, number>;
  private performanceTracker: PerformanceTracker;
  private adjustmentPolicy: WeightAdjustmentPolicy;

  async updateWeights(
    targets: Target[],
    metrics: TargetMetrics[]
  ): Promise<void> {
    for (let i = 0; i < targets.length; i++) {
      const target = targets[i];
      const metric = metrics[i];

      // ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
      const performanceScore = await this.calculatePerformanceScore(metric);

      // ê°€ì¤‘ì¹˜ ì¡°ì •
      const currentWeight = this.weights.get(target.id) || 1.0;
      const newWeight = await this.adjustmentPolicy.adjust(
        currentWeight,
        performanceScore,
        metric
      );

      this.weights.set(target.id, newWeight);
    }

    // ì •ê·œí™”
    this.normalizeWeights();
  }

  private async calculatePerformanceScore(
    metrics: TargetMetrics
  ): Promise<number> {
    // ë³µí•© ì„±ëŠ¥ ì§€í‘œ
    const responseTimeScore = 1 / (1 + metrics.avgResponseTime / 100);
    const errorRateScore = 1 - metrics.errorRate;
    const throughputScore = metrics.throughput / 1000;
    const availabilityScore = metrics.availability;

    return (
      responseTimeScore * 0.3 +
      errorRateScore * 0.3 +
      throughputScore * 0.2 +
      availabilityScore * 0.2
    );
  }

  private normalizeWeights(): void {
    const total = Array.from(this.weights.values()).reduce(
      (sum, w) => sum + w,
      0
    );

    if (total > 0) {
      for (const [targetId, weight] of this.weights.entries()) {
        this.weights.set(targetId, weight / total);
      }
    }
  }

  getWeight(targetId: string): number {
    return this.weights.get(targetId) || 0;
  }
}

// ë¶€í•˜ ë¶„ì‚° ìƒíƒœ ëª¨ë‹ˆí„°
export class LoadBalancerMonitor {
  private metricsCollector: MetricsCollector;
  private anomalyDetector: AnomalyDetector;
  private dashboardReporter: DashboardReporter;

  async monitor(loadBalancer: IntelligentLoadBalancer): Promise<void> {
    // ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    setInterval(async () => {
      const metrics = await this.collectMetrics(loadBalancer);
      
      // ì´ìƒ ê°ì§€
      const anomalies = await this.anomalyDetector.detect(metrics);
      
      if (anomalies.length > 0) {
        await this.handleAnomalies(anomalies);
      }

      // ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸
      await this.dashboardReporter.update(metrics);
      
    }, 5000); // 5ì´ˆë§ˆë‹¤
  }

  private async collectMetrics(
    loadBalancer: IntelligentLoadBalancer
  ): Promise<LoadBalancerMetrics> {
    return {
      timestamp: new Date(),
      requestRate: await this.metricsCollector.getRequestRate(),
      avgResponseTime: await this.metricsCollector.getAvgResponseTime(),
      errorRate: await this.metricsCollector.getErrorRate(),
      targetDistribution: await this.getTargetDistribution(loadBalancer),
      activeConnections: await this.getActiveConnections(),
      queueDepth: await this.getQueueDepth()
    };
  }

  private async handleAnomalies(anomalies: Anomaly[]): Promise<void> {
    for (const anomaly of anomalies) {
      logger.warn('Load balancer anomaly detected', anomaly);

      switch (anomaly.type) {
        case 'uneven_distribution':
          // ì¬ë¶„ë°° íŠ¸ë¦¬ê±°
          await this.triggerRebalancing();
          break;

        case 'high_error_rate':
          // ì„œí‚· ë¸Œë ˆì´ì»¤ í™œì„±í™”
          await this.activateCircuitBreaker(anomaly.targetId);
          break;

        case 'response_time_spike':
          // ë°±í”„ë ˆì…” ì ìš©
          await this.applyBackpressure(anomaly.targetId);
          break;
      }
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ë¶€í•˜ ë¶„ì‚° ì „ëµ
- [ ] ì ì‘í˜• ë° ML ê¸°ë°˜ ë¼ìš°íŒ…
- [ ] ì§€ì—­ ì¸ì‹ ë° ê·œì • ì¤€ìˆ˜
- [ ] ì„¸ì…˜ ì¹œí™”ì„± ë° ëª¨ë‹ˆí„°ë§

#### SubTask 5.9.2: ìë™ ìŠ¤ì¼€ì¼ë§ ì •ì±… ì—”ì§„
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/autoscaling/scaling_engine.ts
export interface ScalingPolicy {
  id: string;
  name: string;
  type: ScalingPolicyType;
  triggers: ScalingTrigger[];
  actions: ScalingAction[];
  cooldown: number;
  enabled: boolean;
}

export class AutoScalingEngine {
  private policies: Map<string, ScalingPolicy>;
  private metricsEvaluator: MetricsEvaluator;
  private scaler: ResourceScaler;
  private policyEvaluator: PolicyEvaluator;
  private cooldownManager: CooldownManager;

  constructor(config: AutoScalingConfig) {
    this.policies = new Map();
    this.metricsEvaluator = new MetricsEvaluator(config.metrics);
    this.scaler = new ResourceScaler(config.scaling);
    this.policyEvaluator = new PolicyEvaluator();
    this.cooldownManager = new CooldownManager();
  }

  async evaluateAndScale(): Promise<ScalingResult> {
    const results: ScalingDecision[] = [];

    // 1. í˜„ì¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    const currentMetrics = await this.metricsEvaluator.collectMetrics();

    // 2. ê° ì •ì±… í‰ê°€
    for (const policy of this.policies.values()) {
      if (!policy.enabled) continue;

      // ì¿¨ë‹¤ìš´ í™•ì¸
      if (await this.cooldownManager.isInCooldown(policy.id)) {
        continue;
      }

      // ì •ì±… í‰ê°€
      const decision = await this.policyEvaluator.evaluate(
        policy,
        currentMetrics
      );

      if (decision.shouldScale) {
        results.push(decision);
      }
    }

    // 3. ì¶©ëŒ í•´ê²°
    const resolvedDecisions = await this.resolveConflicts(results);

    // 4. ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰
    const scalingResults = await this.executeScaling(resolvedDecisions);

    // 5. ì¿¨ë‹¤ìš´ ì„¤ì •
    for (const result of scalingResults) {
      if (result.success) {
        await this.cooldownManager.setCooldown(
          result.policyId,
          result.policy.cooldown
        );
      }
    }

    return {
      decisions: resolvedDecisions,
      results: scalingResults,
      metrics: currentMetrics
    };
  }

  private async resolveConflicts(
    decisions: ScalingDecision[]
  ): Promise<ScalingDecision[]> {
    // ë¦¬ì†ŒìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
    const resourceGroups = new Map<string, ScalingDecision[]>();

    for (const decision of decisions) {
      const resourceId = decision.targetResource;
      if (!resourceGroups.has(resourceId)) {
        resourceGroups.set(resourceId, []);
      }
      resourceGroups.get(resourceId)!.push(decision);
    }

    // ê° ë¦¬ì†ŒìŠ¤ë³„ ìµœì¢… ê²°ì •
    const resolved: ScalingDecision[] = [];

    for (const [resourceId, group] of resourceGroups) {
      if (group.length === 1) {
        resolved.push(group[0]);
      } else {
        // ì¶©ëŒ í•´ê²°: ê°€ì¥ ê³µê²©ì ì¸ ìŠ¤ì¼€ì¼ë§ ì„ íƒ
        const winner = this.selectMostAggressiveScaling(group);
        resolved.push(winner);
      }
    }

    return resolved;
  }

  private selectMostAggressiveScaling(
    decisions: ScalingDecision[]
  ): ScalingDecision {
    // Scale outì´ scale inë³´ë‹¤ ìš°ì„ 
    const scaleOutDecisions = decisions.filter(d => d.direction === 'out');
    if (scaleOutDecisions.length > 0) {
      // ê°€ì¥ í° ì¦ê°€ëŸ‰ ì„ íƒ
      return scaleOutDecisions.reduce((max, d) => 
        d.scalingAmount > max.scalingAmount ? d : max
      );
    }

    // Scale in ì¤‘ ê°€ì¥ ì‘ì€ ê°ì†ŒëŸ‰ ì„ íƒ (ì•ˆì „í•˜ê²Œ)
    return decisions.reduce((min, d) => 
      Math.abs(d.scalingAmount) < Math.abs(min.scalingAmount) ? d : min
    );
  }

  private async executeScaling(
    decisions: ScalingDecision[]
  ): Promise<ScalingExecutionResult[]> {
    const results: ScalingExecutionResult[] = [];

    for (const decision of decisions) {
      try {
        const result = await this.scaler.scale(decision);
        results.push({
          ...result,
          policyId: decision.policyId,
          policy: this.policies.get(decision.policyId)!
        });

        // ì„±ê³µ ì´ë²¤íŠ¸
        await this.publishScalingEvent({
          type: 'scaling_success',
          decision,
          result
        });

      } catch (error) {
        results.push({
          success: false,
          policyId: decision.policyId,
          policy: this.policies.get(decision.policyId)!,
          error: error.message
        });

        // ì‹¤íŒ¨ ì´ë²¤íŠ¸
        await this.publishScalingEvent({
          type: 'scaling_failed',
          decision,
          error
        });
      }
    }

    return results;
  }
}

// ë©”íŠ¸ë¦­ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§ ì •ì±…
export class MetricBasedScalingPolicy implements ScalingPolicy {
  id: string;
  name: string;
  type = ScalingPolicyType.METRIC_BASED;
  triggers: MetricTrigger[];
  actions: ScalingAction[];
  cooldown: number;
  enabled: boolean;

  async evaluate(metrics: SystemMetrics): Promise<boolean> {
    for (const trigger of this.triggers) {
      const metricValue = this.getMetricValue(metrics, trigger.metric);
      
      if (this.checkThreshold(metricValue, trigger)) {
        return true;
      }
    }

    return false;
  }

  private checkThreshold(value: number, trigger: MetricTrigger): boolean {
    switch (trigger.comparison) {
      case 'greater_than':
        return value > trigger.threshold;
      case 'less_than':
        return value < trigger.threshold;
      case 'greater_than_or_equal':
        return value >= trigger.threshold;
      case 'less_than_or_equal':
        return value <= trigger.threshold;
      default:
        return false;
    }
  }

  calculateScalingAmount(currentCapacity: number): number {
    const action = this.actions[0]; // ì²« ë²ˆì§¸ ì•¡ì…˜ ì‚¬ìš©

    switch (action.type) {
      case 'change_capacity':
        return action.value;
      case 'percent_change':
        return Math.ceil(currentCapacity * (action.value / 100));
      case 'exact_capacity':
        return action.value - currentCapacity;
      default:
        return 0;
    }
  }
}

// ì˜ˆì¸¡ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
export class PredictiveScalingPolicy implements ScalingPolicy {
  id: string;
  name: string;
  type = ScalingPolicyType.PREDICTIVE;
  triggers: PredictiveTrigger[];
  actions: ScalingAction[];
  cooldown: number;
  enabled: boolean;

  private predictor: WorkloadPredictor;
  private confidenceThreshold: number = 0.8;

  constructor(config: PredictivePolicyConfig) {
    this.predictor = new WorkloadPredictor(config.model);
    this.confidenceThreshold = config.confidenceThreshold || 0.8;
  }

  async evaluate(metrics: SystemMetrics): Promise<ScalingDecision | null> {
    // 1. ì›Œí¬ë¡œë“œ ì˜ˆì¸¡
    const prediction = await this.predictor.predict({
      historicalMetrics: metrics.history,
      timeHorizon: this.triggers[0].lookahead || 300 // 5ë¶„
    });

    // 2. ì‹ ë¢°ë„ í™•ì¸
    if (prediction.confidence < this.confidenceThreshold) {
      return null;
    }

    // 3. ì˜ˆì¸¡ëœ ìˆ˜ìš”ì™€ í˜„ì¬ ìš©ëŸ‰ ë¹„êµ
    const currentCapacity = metrics.current.capacity;
    const predictedDemand = prediction.expectedLoad;
    const buffer = 1.2; // 20% ë²„í¼

    if (predictedDemand * buffer > currentCapacity) {
      // Scale out í•„ìš”
      return {
        shouldScale: true,
        direction: 'out',
        scalingAmount: Math.ceil(predictedDemand * buffer - currentCapacity),
        reason: `Predicted demand (${predictedDemand}) exceeds capacity`,
        confidence: prediction.confidence
      };
    } else if (predictedDemand < currentCapacity * 0.4) {
      // Scale in ê°€ëŠ¥
      return {
        shouldScale: true,
        direction: 'in',
        scalingAmount: Math.floor(currentCapacity * 0.3),
        reason: `Predicted demand (${predictedDemand}) is low`,
        confidence: prediction.confidence
      };
    }

    return null;
  }
}

// ìŠ¤ì¼€ì¤„ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
export class ScheduleBasedScalingPolicy implements ScalingPolicy {
  id: string;
  name: string;
  type = ScalingPolicyType.SCHEDULED;
  triggers: ScheduleTrigger[];
  actions: ScalingAction[];
  cooldown: number;
  enabled: boolean;

  private scheduler: CronScheduler;

  constructor() {
    this.scheduler = new CronScheduler();
  }

  async initialize(): Promise<void> {
    for (const trigger of this.triggers) {
      await this.scheduler.schedule(
        trigger.cronExpression,
        async () => {
          await this.executeScheduledScaling(trigger);
        }
      );
    }
  }

  private async executeScheduledScaling(
    trigger: ScheduleTrigger
  ): Promise<void> {
    const action = this.actions.find(a => a.id === trigger.actionId);
    
    if (!action) {
      logger.error(`Action ${trigger.actionId} not found for trigger`);
      return;
    }

    // ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰
    await this.scaler.scale({
      targetResource: trigger.targetResource,
      scalingAction: action,
      reason: `Scheduled scaling: ${trigger.description}`
    });
  }
}

// ë³µí•© ìŠ¤ì¼€ì¼ë§ ì •ì±…
export class CompositeScalingPolicy implements ScalingPolicy {
  id: string;
  name: string;
  type = ScalingPolicyType.COMPOSITE;
  triggers: CompositeTrigger[];
  actions: ScalingAction[];
  cooldown: number;
  enabled: boolean;

  private subPolicies: ScalingPolicy[];
  private aggregationRule: AggregationRule;

  async evaluate(metrics: SystemMetrics): Promise<ScalingDecision | null> {
    const subDecisions: ScalingDecision[] = [];

    // ëª¨ë“  í•˜ìœ„ ì •ì±… í‰ê°€
    for (const policy of this.subPolicies) {
      const decision = await policy.evaluate(metrics);
      if (decision) {
        subDecisions.push(decision);
      }
    }

    // ì§‘ê³„ ê·œì¹™ ì ìš©
    return this.aggregate(subDecisions);
  }

  private aggregate(decisions: ScalingDecision[]): ScalingDecision | null {
    if (decisions.length === 0) return null;

    switch (this.aggregationRule) {
      case 'all':
        // ëª¨ë“  ì •ì±…ì´ ë™ì˜í•´ì•¼ í•¨
        if (decisions.length !== this.subPolicies.length) {
          return null;
        }
        break;

      case 'any':
        // í•˜ë‚˜ë¼ë„ íŠ¸ë¦¬ê±°ë˜ë©´ ì‹¤í–‰
        if (decisions.length > 0) {
          return decisions[0];
        }
        break;

      case 'majority':
        // ê³¼ë°˜ìˆ˜ ë™ì˜
        if (decisions.length > this.subPolicies.length / 2) {
          return this.mergeDecisions(decisions);
        }
        break;
    }

    return null;
  }

  private mergeDecisions(decisions: ScalingDecision[]): ScalingDecision {
    // í‰ê· ê°’ ì‚¬ìš©
    const avgScaling = decisions.reduce((sum, d) => sum + d.scalingAmount, 0) / decisions.length;
    
    return {
      shouldScale: true,
      direction: avgScaling > 0 ? 'out' : 'in',
      scalingAmount: Math.round(avgScaling),
      reason: `Composite policy: ${decisions.length} sub-policies triggered`,
      confidence: decisions.reduce((sum, d) => sum + (d.confidence || 1), 0) / decisions.length
    };
  }
}

// ë¦¬ì†ŒìŠ¤ ìŠ¤ì¼€ì¼ëŸ¬
export class ResourceScaler {
  private providers: Map<string, ScalingProvider>;
  private validator: ScalingValidator;
  private rollbackManager: RollbackManager;

  async scale(decision: ScalingDecision): Promise<ScalingResult> {
    // 1. ê²€ì¦
    const validation = await this.validator.validate(decision);
    if (!validation.valid) {
      throw new ScalingValidationError(validation.errors);
    }

    // 2. í”„ë¡œë°”ì´ë” ì„ íƒ
    const provider = this.selectProvider(decision.targetResource);

    // 3. ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰
    try {
      const result = await provider.scale({
        resourceId: decision.targetResource,
        direction: decision.direction,
        amount: decision.scalingAmount,
        metadata: decision.metadata
      });

      // 4. í—¬ìŠ¤ ì²´í¬
      await this.waitForHealthy(result.instances);

      return {
        success: true,
        scaledInstances: result.instances,
        previousCapacity: result.previousCapacity,
        newCapacity: result.newCapacity,
        duration: result.duration
      };

    } catch (error) {
      // 5. ë¡¤ë°±
      await this.rollbackManager.rollback(decision, error);
      throw error;
    }
  }

  private async waitForHealthy(
    instances: Instance[],
    timeout: number = 300000 // 5ë¶„
  ): Promise<void> {
    const startTime = Date.now();

    while (Date.now() - startTime < timeout) {
      const healthChecks = await Promise.all(
        instances.map(i => this.checkHealth(i))
      );

      if (healthChecks.every(h => h.healthy)) {
        return;
      }

      await this.sleep(5000); // 5ì´ˆ ëŒ€ê¸°
    }

    throw new ScalingTimeoutError('Instances did not become healthy in time');
  }
}

// ìŠ¤ì¼€ì¼ë§ ì •ì±… ìµœì í™”
export class ScalingPolicyOptimizer {
  private performanceAnalyzer: ScalingPerformanceAnalyzer;
  private costAnalyzer: ScalingCostAnalyzer;
  private mlOptimizer: MLPolicyOptimizer;

  async optimizePolicies(
    policies: ScalingPolicy[],
    historicalData: ScalingHistory
  ): Promise<OptimizedPolicies> {
    const optimizations: PolicyOptimization[] = [];

    for (const policy of policies) {
      // 1. ì„±ëŠ¥ ë¶„ì„
      const performance = await this.performanceAnalyzer.analyze(
        policy,
        historicalData
      );

      // 2. ë¹„ìš© ë¶„ì„
      const cost = await this.costAnalyzer.analyze(
        policy,
        historicalData
      );

      // 3. ML ê¸°ë°˜ ìµœì í™”
      const mlSuggestions = await this.mlOptimizer.optimize(
        policy,
        performance,
        cost
      );

      optimizations.push({
        policyId: policy.id,
        currentPerformance: performance,
        currentCost: cost,
        suggestions: mlSuggestions,
        estimatedImprovement: this.calculateImprovement(
          performance,
          cost,
          mlSuggestions
        )
      });
    }

    return {
      optimizations,
      recommendations: this.generateRecommendations(optimizations)
    };
  }

  private generateRecommendations(
    optimizations: PolicyOptimization[]
  ): PolicyRecommendation[] {
    const recommendations: PolicyRecommendation[] = [];

    for (const opt of optimizations) {
      // ì„ê³„ê°’ ì¡°ì • ì¶”ì²œ
      if (opt.currentPerformance.falsePositiveRate > 0.3) {
        recommendations.push({
          policyId: opt.policyId,
          type: 'adjust_threshold',
          description: 'Increase threshold to reduce false positives',
          impact: 'high',
          implementation: {
            threshold: opt.suggestions.optimalThreshold
          }
        });
      }

      // ì¿¨ë‹¤ìš´ ì¡°ì • ì¶”ì²œ
      if (opt.currentPerformance.thrashing > 0.2) {
        recommendations.push({
          policyId: opt.policyId,
          type: 'increase_cooldown',
          description: 'Increase cooldown to prevent thrashing',
          impact: 'medium',
          implementation: {
            cooldown: opt.suggestions.optimalCooldown
          }
        });
      }

      // ì˜ˆì¸¡ ëª¨ë¸ ì¶”ê°€ ì¶”ì²œ
      if (opt.currentPerformance.reactionTime > 180) { // 3ë¶„ ì´ìƒ
        recommendations.push({
          policyId: opt.policyId,
          type: 'add_predictive',
          description: 'Add predictive scaling to improve reaction time',
          impact: 'high',
          implementation: {
            model: 'arima',
            lookahead: 300
          }
        });
      }
    }

    return recommendations;
  }
}

// ë‹¤ì¤‘ í´ë¼ìš°ë“œ ìŠ¤ì¼€ì¼ë§
export class MultiCloudScaler {
  private cloudProviders: Map<string, CloudProvider>;
  private costOptimizer: MultiCloudCostOptimizer;
  private loadDistributor: MultiCloudLoadDistributor;

  async scaleAcrossClouds(
    demand: number,
    constraints: MultiCloudConstraints
  ): Promise<MultiCloudScalingResult> {
    // 1. ê° í´ë¼ìš°ë“œì˜ í˜„ì¬ ìƒíƒœ í™•ì¸
    const cloudStates = await this.getCloudStates();

    // 2. ë¹„ìš© ìµœì í™” ë¶„ì„
    const costAnalysis = await this.costOptimizer.analyze(
      demand,
      cloudStates,
      constraints
    );

    // 3. ìµœì  ë¶„ë°° ê³„ì‚°
    const distribution = await this.loadDistributor.calculate(
      demand,
      cloudStates,
      costAnalysis,
      constraints
    );

    // 4. ê° í´ë¼ìš°ë“œì—ì„œ ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰
    const results = await this.executeMultiCloudScaling(distribution);

    return {
      distribution,
      results,
      totalCost: this.calculateTotalCost(results),
      estimatedSavings: costAnalysis.savings
    };
  }

  private async executeMultiCloudScaling(
    distribution: CloudDistribution
  ): Promise<CloudScalingResult[]> {
    const tasks = [];

    for (const [cloudId, allocation] of distribution.allocations) {
      const provider = this.cloudProviders.get(cloudId);
      
      if (!provider) continue;

      tasks.push(
        provider.scale({
          targetCapacity: allocation.capacity,
          instanceType: allocation.instanceType,
          region: allocation.region
        })
      );
    }

    return Promise.all(tasks);
  }
}

// ìŠ¤ì¼€ì¼ë§ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
export class ScalingEventHandler {
  private eventBus: EventBus;
  private notificationService: NotificationService;
  private auditLogger: AuditLogger;

  async handleScalingEvent(event: ScalingEvent): Promise<void> {
    // 1. ê°ì‚¬ ë¡œê¹…
    await this.auditLogger.log({
      type: 'scaling_event',
      event,
      timestamp: new Date(),
      user: event.triggeredBy || 'system'
    });

    // 2. ì•Œë¦¼ ë°œì†¡
    if (this.shouldNotify(event)) {
      await this.notificationService.send({
        type: 'scaling',
        severity: this.getSeverity(event),
        message: this.formatMessage(event),
        recipients: await this.getRecipients(event)
      });
    }

    // 3. ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    await this.updateMetrics(event);

    // 4. í›„ì† ì•¡ì…˜ íŠ¸ë¦¬ê±°
    if (event.type === 'scaling_failed') {
      await this.handleScalingFailure(event);
    }
  }

  private shouldNotify(event: ScalingEvent): boolean {
    // ì¤‘ìš” ì´ë²¤íŠ¸ë§Œ ì•Œë¦¼
    return event.type === 'scaling_failed' ||
           event.type === 'scaling_completed' && event.scalingAmount > 10 ||
           event.type === 'cost_threshold_exceeded';
  }

  private async handleScalingFailure(event: ScalingEvent): Promise<void> {
    // ì¬ì‹œë„ ì •ì±… í™•ì¸
    const policy = await this.getRetryPolicy(event.policyId);
    
    if (policy && event.attemptNumber < policy.maxRetries) {
      // ì¬ì‹œë„ ìŠ¤ì¼€ì¤„ë§
      setTimeout(() => {
        this.retryScaling(event);
      }, policy.retryDelay * Math.pow(2, event.attemptNumber)); // ì§€ìˆ˜ ë°±ì˜¤í”„
    } else {
      // ìµœì¢… ì‹¤íŒ¨ ì²˜ë¦¬
      await this.handleFinalFailure(event);
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ë§ ì •ì±… êµ¬í˜„
- [ ] ì˜ˆì¸¡ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
- [ ] ì •ì±… ì¶©ëŒ í•´ê²°
- [ ] ë‹¤ì¤‘ í´ë¼ìš°ë“œ ì§€ì›

#### SubTask 5.9.3: ë¦¬ì†ŒìŠ¤ ì˜ˆì¸¡ ë° ì‚¬ì „ í”„ë¡œë¹„ì €ë‹
**ë‹´ë‹¹ì**: ML ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/autoscaling/resource_prediction.ts
export class ResourcePredictor {
  private timeSeriesAnalyzer: TimeSeriesAnalyzer;
  private patternRecognizer: PatternRecognizer;
  private anomalyDetector: AnomalyDetector;
  private mlModels: Map<string, PredictionModel>;

  constructor(config: PredictorConfig) {
    this.timeSeriesAnalyzer = new TimeSeriesAnalyzer();
    this.patternRecognizer = new PatternRecognizer();
    this.anomalyDetector = new AnomalyDetector();
    this.mlModels = this.initializeModels(config);
  }

  async predictResourceDemand(
    historicalData: ResourceUsageHistory,
    horizon: TimeHorizon
  ): Promise<ResourceDemandForecast> {
    // 1. ë°ì´í„° ì „ì²˜ë¦¬
    const preprocessed = await this.preprocessData(historicalData);

    // 2. íŒ¨í„´ ì¸ì‹
    const patterns = await this.patternRecognizer.identify(preprocessed);

    // 3. ì‹œê³„ì—´ ë¶„ì„
    const timeSeriesAnalysis = await this.timeSeriesAnalyzer.analyze(
      preprocessed,
      {
        seasonality: patterns.seasonality,
        trend: patterns.trend,
        cyclic: patterns.cyclic
      }
    );

    // 4. ML ì˜ˆì¸¡
    const predictions = await this.generatePredictions(
      preprocessed,
      timeSeriesAnalysis,
      horizon
    );

    // 5. ì´ìƒì¹˜ ë³´ì •
    const corrected = await this.correctForAnomalies(predictions);

    // 6. ì‹ ë¢° êµ¬ê°„ ê³„ì‚°
    const confidence = await this.calculateConfidenceIntervals(corrected);

    return {
      predictions: corrected,
      confidence,
      patterns,
      recommendations: await this.generateRecommendations(corrected)
    };
  }

  private async generatePredictions(
    data: ProcessedData,
    analysis: TimeSeriesAnalysis,
    horizon: TimeHorizon
  ): Promise<ResourcePrediction[]> {
    const predictions: ResourcePrediction[] = [];

    // ê° ë¦¬ì†ŒìŠ¤ íƒ€ì…ë³„ ì˜ˆì¸¡
    for (const resourceType of ['cpu', 'memory', 'disk', 'network']) {
      const model = this.mlModels.get(resourceType)!;
      
      // íŠ¹ì§• ì¶”ì¶œ
      const features = await this.extractFeatures(data, analysis, resourceType);
      
      // ëª¨ë¸ ì˜ˆì¸¡
      const forecast = await model.predict(features, horizon);
      
      predictions.push({
        resourceType,
        timeSeries: forecast.values,
        peaks: await this.identifyPeaks(forecast),
        valleys: await this.identifyValleys(forecast)
      });
    }

    return predictions;
  }

  private async extractFeatures(
    data: ProcessedData,
    analysis: TimeSeriesAnalysis,
    resourceType: string
  ): Promise<FeatureVector> {
    return {
      // ì‹œê³„ì—´ íŠ¹ì§•
      mean: data.statistics[resourceType].mean,
      std: data.statistics[resourceType].std,
      trend: analysis.trend.coefficient,
      seasonalityStrength: analysis.seasonality.strength,
      
      // ì‹œê°„ íŠ¹ì§•
      hourOfDay: new Date().getHours(),
      dayOfWeek: new Date().getDay(),
      dayOfMonth: new Date().getDate(),
      isWeekend: [0, 6].includes(new Date().getDay()),
      
      // ì´ë²¤íŠ¸ íŠ¹ì§•
      upcomingEvents: await this.getUpcomingEvents(),
      
      // ì™¸ë¶€ ìš”ì¸
      weather: await this.getWeatherForecast(),
      holidays: await this.getHolidayCalendar()
    };
  }
}

// ì‚¬ì „ í”„ë¡œë¹„ì €ë‹ ê´€ë¦¬ì
export class ProactiveProvisioner {
  private predictor: ResourcePredictor;
  private provisioner: ResourceProvisioner;
  private costCalculator: CostCalculator;
  private riskAssessor: RiskAssessor;

  async planProvisioning(
    currentState: ResourceState,
    constraints: ProvisioningConstraints
  ): Promise<ProvisioningPlan> {
    // 1. ìˆ˜ìš” ì˜ˆì¸¡
    const forecast = await this.predictor.predictResourceDemand(
      currentState.history,
      { start: new Date(), end: this.addHours(new Date(), 24) }
    );

    // 2. í”„ë¡œë¹„ì €ë‹ ì „ëµ ìˆ˜ë¦½
    const strategies = await this.generateStrategies(
      forecast,
      currentState,
      constraints
    );

    // 3. ê° ì „ëµ í‰ê°€
    const evaluations = await Promise.all(
      strategies.map(s => this.evaluateStrategy(s, forecast))
    );

    // 4. ìµœì  ì „ëµ ì„ íƒ
    const optimal = this.selectOptimalStrategy(evaluations, constraints);

    // 5. ì‹¤í–‰ ê³„íš ìƒì„±
    return this.createExecutionPlan(optimal);
  }

  private async generateStrategies(
    forecast: ResourceDemandForecast,
    currentState: ResourceState,
    constraints: ProvisioningConstraints
  ): Promise<ProvisioningStrategy[]> {
    const strategies: ProvisioningStrategy[] = [];

    // 1. ë³´ìˆ˜ì  ì „ëµ (ìµœì†Œ ë¹„ìš©)
    strategies.push({
      name: 'conservative',
      description: 'Provision for average demand with small buffer',
      provisions: this.calculateConservativeProvisions(forecast),
      riskLevel: 'medium'
    });

    // 2. ê³µê²©ì  ì „ëµ (ìµœê³  ì„±ëŠ¥)
    strategies.push({
      name: 'aggressive',
      description: 'Provision for peak demand with large buffer',
      provisions: this.calculateAggressiveProvisions(forecast),
      riskLevel: 'low'
    });

    // 3. ì ì‘í˜• ì „ëµ (ë™ì  ì¡°ì •)
    strategies.push({
      name: 'adaptive',
      description: 'Dynamic provisioning based on real-time metrics',
      provisions: this.calculateAdaptiveProvisions(forecast),
      riskLevel: 'low-medium'
    });

    // 4. ë¹„ìš© ìµœì í™” ì „ëµ
    strategies.push({
      name: 'cost-optimized',
      description: 'Balance between cost and performance',
      provisions: await this.calculateCostOptimizedProvisions(
        forecast,
        constraints.budget
      ),
      riskLevel: 'medium'
    });

    return strategies;
  }

  private async evaluateStrategy(
    strategy: ProvisioningStrategy,
    forecast: ResourceDemandForecast
  ): Promise<StrategyEvaluation> {
    // ë¹„ìš© ê³„ì‚°
    const cost = await this.costCalculator.calculate(strategy.provisions);

    // ìœ„í—˜ í‰ê°€
    const risk = await this.riskAssessor.assess(
      strategy,
      forecast
    );

    // ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜
    const performance = await this.simulatePerformance(
      strategy,
      forecast
    );

    return {
      strategy,
      cost,
      risk,
      performance,
      score: this.calculateScore(cost, risk, performance)
    };
  }

  private calculateScore(
    cost: CostEstimate,
    risk: RiskAssessment,
    performance: PerformanceMetrics
  ): number {
    // ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°
    const costScore = 1 / (1 + cost.total / 10000); // ì •ê·œí™”
    const riskScore = 1 - risk.overallRisk;
    const performanceScore = performance.slaCompliance;

    return (
      costScore * 0.3 +
      riskScore * 0.3 +
      performanceScore * 0.4
    );
  }
}

// ì˜ˆì¸¡ ëª¨ë¸ ì•™ìƒë¸”
export class PredictionModelEnsemble {
  private models: PredictionModel[];
  private weights: number[];
  private performanceTracker: ModelPerformanceTracker;

  constructor() {
    this.models = [
      new ARIMAModel(),
      new LSTMModel(),
      new ProphetModel(),
      new XGBoostModel(),
      new ExponentialSmoothingModel()
    ];
    
    this.weights = new Array(this.models.length).fill(1 / this.models.length);
    this.performanceTracker = new ModelPerformanceTracker();
  }

  async predict(
    data: TimeSeriesData,
    horizon: number
  ): Promise<EnsemblePrediction> {
    // 1. ê° ëª¨ë¸ ì˜ˆì¸¡
    const predictions = await Promise.all(
      this.models.map(model => model.predict(data, horizon))
    );

    // 2. ê°€ì¤‘ í‰ê· 
    const ensemble = this.weightedAverage(predictions, this.weights);

    // 3. ë¶ˆí™•ì‹¤ì„± ê³„ì‚°
    const uncertainty = this.calculateUncertainty(predictions);

    // 4. ê°œë³„ ëª¨ë¸ ê¸°ì—¬ë„
    const contributions = this.calculateContributions(predictions, ensemble);

    return {
      forecast: ensemble,
      uncertainty,
      contributions,
      confidence: this.calculateConfidence(predictions)
    };
  }

  private weightedAverage(
    predictions: Prediction[],
    weights: number[]
  ): number[] {
    const length = predictions[0].values.length;
    const result = new Array(length).fill(0);

    for (let t = 0; t < length; t++) {
      for (let i = 0; i < predictions.length; i++) {
        result[t] += predictions[i].values[t] * weights[i];
      }
    }

    return result;
  }

  async updateWeights(
    actualValues: number[]
  ): Promise<void> {
    // ê° ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€
    const performances = await Promise.all(
      this.models.map((model, index) => 
        this.performanceTracker.evaluate(model, actualValues)
      )
    );

    // ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
    const totalPerformance = performances.reduce((sum, p) => sum + p.score, 0);
    
    this.weights = performances.map(p => p.score / totalPerformance);
  }
}

// ì‹œê³„ì—´ ë¶„í•´
export class TimeSeriesDecomposer {
  async decompose(
    data: TimeSeriesData
  ): Promise<TimeSeriesComponents> {
    // STL ë¶„í•´ (Seasonal and Trend decomposition using Loess)
    const stl = new STLDecomposition({
      seasonal: 'periodic',
      trend: 'loess',
      robust: true
    });

    const components = await stl.fit(data);

    return {
      trend: components.trend,
      seasonal: components.seasonal,
      residual: components.residual,
      
      // ì¶”ê°€ ë¶„ì„
      seasonalPeriod: await this.detectSeasonalPeriod(data),
      trendStrength: this.calculateTrendStrength(components.trend),
      seasonalStrength: this.calculateSeasonalStrength(components.seasonal),
      noise: this.calculateNoise(components.residual)
    };
  }

  private async detectSeasonalPeriod(
    data: TimeSeriesData
  ): Promise<number> {
    // FFTë¥¼ ì‚¬ìš©í•œ ì£¼ê¸° ê°ì§€
    const fft = new FastFourierTransform();
    const spectrum = fft.forward(data.values);
    
    // ì£¼ìš” ì£¼íŒŒìˆ˜ ì°¾ê¸°
    const peaks = this.findSpectralPeaks(spectrum);
    
    if (peaks.length === 0) {
      return 0; // ê³„ì ˆì„± ì—†ìŒ
    }

    // ê°€ì¥ ê°•í•œ ì£¼ê¸° ë°˜í™˜
    return Math.round(data.values.length / peaks[0].frequency);
  }
}

// ì´ìƒì¹˜ ê°ì§€ ë° ë³´ì •
export class AnomalyDetectorAndCorrector {
  private detectors: AnomalyDetector[];
  
  constructor() {
    this.detectors = [
      new IsolationForestDetector(),
      new LocalOutlierFactorDetector(),
      new OneClassSVMDetector(),
      new AutoencoderDetector()
    ];
  }

  async detectAndCorrect(
    data: TimeSeriesData
  ): Promise<CorrectedData> {
    // 1. ë‹¤ì¤‘ ê°ì§€ê¸°ë¡œ ì´ìƒì¹˜ ê°ì§€
    const detections = await Promise.all(
      this.detectors.map(d => d.detect(data))
    );

    // 2. í•©ì˜ ê¸°ë°˜ ì´ìƒì¹˜ ê²°ì •
    const anomalies = this.consensusAnomalies(detections);

    // 3. ì´ìƒì¹˜ ë³´ì •
    const corrected = await this.correctAnomalies(data, anomalies);

    return {
      data: corrected,
      anomalies,
      corrections: this.generateCorrections(data, corrected, anomalies)
    };
  }

  private consensusAnomalies(
    detections: AnomalyDetection[]
  ): number[] {
    const threshold = Math.ceil(detections.length * 0.6); // 60% ë™ì˜
    const anomalyCounts = new Map<number, number>();

    // ê° í¬ì¸íŠ¸ë³„ ê°ì§€ íšŸìˆ˜ ê³„ì‚°
    for (const detection of detections) {
      for (const index of detection.anomalyIndices) {
        const count = anomalyCounts.get(index) || 0;
        anomalyCounts.set(index, count + 1);
      }
    }

    // ì„ê³„ê°’ ì´ìƒì¸ í¬ì¸íŠ¸ë§Œ ì„ íƒ
    return Array.from(anomalyCounts.entries())
      .filter(([_, count]) => count >= threshold)
      .map(([index, _]) => index);
  }

  private async correctAnomalies(
    data: TimeSeriesData,
    anomalies: number[]
  ): Promise<TimeSeriesData> {
    const corrected = { ...data, values: [...data.values] };

    for (const index of anomalies) {
      // ì£¼ë³€ ê°’ë“¤ì˜ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
      const window = 5;
      const start = Math.max(0, index - window);
      const end = Math.min(data.values.length - 1, index + window);
      
      let sum = 0;
      let weightSum = 0;
      
      for (let i = start; i <= end; i++) {
        if (!anomalies.includes(i)) {
          const weight = 1 / (1 + Math.abs(i - index));
          sum += data.values[i] * weight;
          weightSum += weight;
        }
      }
      
      if (weightSum > 0) {
        corrected.values[index] = sum / weightSum;
      }
    }

    return corrected;
  }
}

// ìš©ëŸ‰ ê³„íš ìµœì í™”
export class CapacityPlanningOptimizer {
  private scenarioGenerator: ScenarioGenerator;
  private simulator: CapacitySimulator;
  private optimizer: ConstrainedOptimizer;

  async optimizeCapacityPlan(
    forecast: ResourceDemandForecast,
    constraints: CapacityConstraints
  ): Promise<OptimalCapacityPlan> {
    // 1. ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
    const scenarios = await this.scenarioGenerator.generate(forecast);

    // 2. ê° ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜
    const simulations = await Promise.all(
      scenarios.map(s => this.simulator.simulate(s, constraints))
    );

    // 3. ìµœì í™” ë¬¸ì œ ì •ì˜
    const problem = this.formulateOptimizationProblem(
      simulations,
      constraints
    );

    // 4. ìµœì í•´ ì°¾ê¸°
    const solution = await this.optimizer.solve(problem);

    // 5. ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„íš ìƒì„±
    return this.createExecutablePlan(solution, constraints);
  }

  private formulateOptimizationProblem(
    simulations: SimulationResult[],
    constraints: CapacityConstraints
  ): OptimizationProblem {
    return {
      objective: {
        // ë¹„ìš© ìµœì†Œí™” + SLA ìœ„ë°˜ í˜ë„í‹°
        minimize: (x: number[]) => {
          let cost = 0;
          let penalty = 0;
          
          for (let i = 0; i < simulations.length; i++) {
            cost += x[i] * simulations[i].cost;
            penalty += (1 - simulations[i].slaCompliance) * 10000;
          }
          
          return cost + penalty;
        }
      },
      
      constraints: [
        // ì˜ˆì‚° ì œì•½
        {
          type: 'inequality',
          function: (x: number[]) => {
            const totalCost = x.reduce((sum, xi, i) => 
              sum + xi * simulations[i].cost, 0
            );
            return constraints.budget - totalCost; // >= 0
          }
        },
        
        // ìµœì†Œ ê°€ìš©ì„± ì œì•½
        {
          type: 'inequality',
          function: (x: number[]) => {
            const availability = this.calculateAvailability(x, simulations);
            return availability - constraints.minAvailability; // >= 0
          }
        }
      ],
      
      bounds: simulations.map(s => ({
        min: s.minCapacity,
        max: s.maxCapacity
      }))
    };
  }
}

// ì‹¤ì‹œê°„ ì¡°ì • ì‹œìŠ¤í…œ
export class RealtimeAdjuster {
  private monitor: ResourceMonitor;
  private adjuster: DynamicAdjuster;
  private feedbackLoop: FeedbackController;

  async startRealtimeAdjustment(): Promise<void> {
    // ëª¨ë‹ˆí„°ë§ ë£¨í”„
    setInterval(async () => {
      // í˜„ì¬ ìƒíƒœ í™•ì¸
      const currentState = await this.monitor.getCurrentState();
      
      // ì˜ˆì¸¡ê³¼ ì‹¤ì œ ë¹„êµ
      const deviation = await this.calculateDeviation(currentState);
      
      // ì¡°ì • í•„ìš” ì—¬ë¶€ íŒë‹¨
      if (this.needsAdjustment(deviation)) {
        await this.performAdjustment(currentState, deviation);
      }
      
      // í”¼ë“œë°± ìˆ˜ì§‘
      await this.feedbackLoop.collect(currentState, deviation);
      
    }, 30000); // 30ì´ˆë§ˆë‹¤
  }

  private async performAdjustment(
    state: ResourceState,
    deviation: Deviation
  ): Promise<void> {
    // ì¡°ì • ê³„íš ìˆ˜ë¦½
    const adjustmentPlan = await this.adjuster.plan(state, deviation);
    
    // ì ì§„ì  ì¡°ì •
    for (const step of adjustmentPlan.steps) {
      await this.executeAdjustmentStep(step);
      
      // íš¨ê³¼ í™•ì¸
      await this.waitAndVerify(step.expectedDuration);
      
      // ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´
      if (await this.isAdjustmentSufficient()) {
        break;
      }
    }
  }

  private async waitAndVerify(duration: number): Promise<void> {
    await new Promise(resolve => setTimeout(resolve, duration));
    
    const newState = await this.monitor.getCurrentState();
    const improvement = this.calculateImprovement(newState);
    
    if (improvement < 0) {
      // ì—­íš¨ê³¼ ë°œìƒ - ë¡¤ë°±
      throw new AdjustmentFailureError('Adjustment had negative effect');
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸
- [ ] ì‚¬ì „ í”„ë¡œë¹„ì €ë‹ ì „ëµ
- [ ] ì´ìƒì¹˜ ê°ì§€ ë° ë³´ì •
- [ ] ì‹¤ì‹œê°„ ì¡°ì • ì‹œìŠ¤í…œ

#### SubTask 5.9.4: ë©€í‹° ë¦¬ì „ ë¶„ì‚° ì²˜ë¦¬
**ë‹´ë‹¹ì**: ë¶„ì‚° ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/multiregion/distributed_processing.ts
export class MultiRegionOrchestrator {
  private regions: Map<string, RegionController>;
  private globalCoordinator: GlobalCoordinator;
  private dataReplicator: DataReplicator;
  private latencyOptimizer: LatencyOptimizer;

  constructor(config: MultiRegionConfig) {
    this.regions = this.initializeRegions(config.regions);
    this.globalCoordinator = new GlobalCoordinator();
    this.dataReplicator = new DataReplicator(config.replication);
    this.latencyOptimizer = new LatencyOptimizer();
  }

  async distributeWorkload(
    workload: Workload,
    constraints: DistributionConstraints
  ): Promise<DistributionPlan> {
    // 1. ì›Œí¬ë¡œë“œ ë¶„ì„
    const analysis = await this.analyzeWorkload(workload);

    // 2. ì§€ì—­ë³„ ìƒíƒœ í™•ì¸
    const regionStates = await this.getRegionStates();

    // 3. ìµœì  ë¶„ë°° ê³„íš
    const distribution = await this.latencyOptimizer.optimize({
      workload: analysis,
      regions: regionStates,
      constraints
    });

    // 4. ë°ì´í„° ë³µì œ ê³„íš
    const replicationPlan = await this.dataReplicator.plan(
      distribution,
      analysis.dataRequirements
    );

    // 5. ì‹¤í–‰ ê³„íš ìƒì„±
    return {
      distribution,
      replication: replicationPlan,
      estimatedLatency: distribution.expectedLatency,
      estimatedCost: await this.calculateCost(distribution)
    };
  }

  private async analyzeWorkload(
    workload: Workload
  ): Promise<WorkloadAnalysis> {
    return {
      type: this.classifyWorkload(workload),
      dataRequirements: await this.analyzeDataRequirements(workload),
      computeRequirements: this.estimateComputeRequirements(workload),
      latencySensitivity: this.assessLatencySensitivity(workload),
      regionAffinity: await this.determineRegionAffinity(workload)
    };
  }

  async executeDistributed(
    plan: DistributionPlan
  ): Promise<DistributedExecutionResult> {
    // 1. ë°ì´í„° ë³µì œ ì‹¤í–‰
    await this.executeReplication(plan.replication);

    // 2. ì§€ì—­ë³„ íƒœìŠ¤í¬ ë°°í¬
    const deployments = await this.deployToRegions(plan.distribution);

    // 3. ê¸€ë¡œë²Œ ì¡°ì • ì‹œì‘
    const coordination = await this.globalCoordinator.coordinate(
      deployments
    );

    // 4. ì‹¤í–‰ ëª¨ë‹ˆí„°ë§
    const monitor = new DistributedExecutionMonitor(deployments);
    
    return {
      deployments,
      coordination,
      monitor
    };
  }
}

// ê¸€ë¡œë²Œ ì¡°ì •ì
export class GlobalCoordinator {
  private consensusProtocol: ConsensusProtocol;
  private stateManager: GlobalStateManager;
  private conflictResolver: ConflictResolver;

  async coordinate(
    deployments: RegionDeployment[]
  ): Promise<CoordinationHandle> {
    // 1. ê¸€ë¡œë²Œ ìƒíƒœ ì´ˆê¸°í™”
    await this.stateManager.initialize(deployments);

    // 2. í•©ì˜ í”„ë¡œí† ì½œ ì‹œì‘
    await this.consensusProtocol.establish(
      deployments.map(d => d.region)
    );

    // 3. ì¡°ì • í•¸ë“¤ ìƒì„±
    const handle = new CoordinationHandle({
      deployments,
      stateManager: this.stateManager,
      conflictResolver: this.conflictResolver
    });

    // 4. ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
    this.setupEventListeners(handle);

    return handle;
  }

  private setupEventListeners(handle: CoordinationHandle): void {
    // ìƒíƒœ ë³€ê²½ ê°ì§€
    handle.on('stateChange', async (change) => {
      await this.handleStateChange(change);
    });

    // ì¶©ëŒ ê°ì§€
    handle.on('conflict', async (conflict) => {
      await this.resolveConflict(conflict);
    });

    // ì¥ì•  ê°ì§€
    handle.on('regionFailure', async (failure) => {
      await this.handleRegionFailure(failure);
    });
  }

  private async handleStateChange(
    change: StateChange
  ): Promise<void> {
    // 1. ë³€ê²½ ì‚¬í•­ ê²€ì¦
    const validation = await this.validateStateChange(change);
    
    if (!validation.valid) {
      throw new InvalidStateChangeError(validation.errors);
    }

    // 2. ê¸€ë¡œë²Œ ìƒíƒœ ì—…ë°ì´íŠ¸
    await this.stateManager.applyChange(change);

    // 3. ë‹¤ë¥¸ ì§€ì—­ì— ì „íŒŒ
    await this.propagateChange(change);
  }

  private async resolveConflict(
    conflict: StateConflict
  ): Promise<Resolution> {
    // ì¶©ëŒ í•´ê²° ì „ëµ ì„ íƒ
    const strategy = this.selectResolutionStrategy(conflict);

    switch (strategy) {
      case 'last-write-wins':
        return this.lastWriteWins(conflict);
      
      case 'vector-clock':
        return this.vectorClockResolution(conflict);
      
      case 'crdt':
        return this.crdtMerge(conflict);
      
      case 'consensus':
        return this.consensusResolution(conflict);
      
      default:
        throw new Error(`Unknown resolution strategy: ${strategy}`);
    }
  }
}

// ì§€ì—­ ê°„ ë°ì´í„° ë³µì œ
export class DataReplicator {
  private replicationStrategies: Map<string, ReplicationStrategy>;
  private consistencyManager: ConsistencyManager;
  private bandwidthOptimizer: BandwidthOptimizer;

  async plan(
    distribution: Distribution,
    dataRequirements: DataRequirement[]
  ): Promise<ReplicationPlan> {
    const plan: ReplicationPlan = {
      replications: [],
      estimatedTime: 0,
      estimatedCost: 0,
      consistencyLevel: 'eventual'
    };

    for (const requirement of dataRequirements) {
      // 1. ì†ŒìŠ¤ ì§€ì—­ í™•ì¸
      const sourceRegion = await this.findDataSource(requirement.dataId);

      // 2. íƒ€ê²Ÿ ì§€ì—­ ê²°ì •
      const targetRegions = this.determineTargetRegions(
        requirement,
        distribution
      );

      // 3. ë³µì œ ì „ëµ ì„ íƒ
      const strategy = this.selectStrategy(requirement, targetRegions);

      // 4. ë³µì œ ê³„íš ì¶”ê°€
      plan.replications.push({
        dataId: requirement.dataId,
        source: sourceRegion,
        targets: targetRegions,
        strategy,
        priority: requirement.priority || 'normal',
        consistencyRequirement: requirement.consistency || 'eventual'
      });
    }

    // 5. ìµœì í™”
    await this.optimizeReplicationPlan(plan);

    return plan;
  }

  private async optimizeReplicationPlan(
    plan: ReplicationPlan
  ): Promise<void> {
    // ëŒ€ì—­í­ ìµœì í™”
    const optimized = await this.bandwidthOptimizer.optimize(
      plan.replications
    );

    // ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§
    plan.replications = this.scheduleReplications(optimized);

    // ì‹œê°„ ë° ë¹„ìš© ì¶”ì •
    plan.estimatedTime = await this.estimateReplicationTime(plan.replications);
    plan.estimatedCost = await this.estimateReplicationCost(plan.replications);
  }

  async execute(
    plan: ReplicationPlan
  ): Promise<ReplicationResult> {
    const results: ReplicationTaskResult[] = [];

    // ë³‘ë ¬ ë³µì œ ê·¸ë£¹ ìƒì„±
    const groups = this.createParallelGroups(plan.replications);

    for (const group of groups) {
      // ê·¸ë£¹ ë‚´ ë³‘ë ¬ ì‹¤í–‰
      const groupResults = await Promise.all(
        group.map(rep => this.executeReplication(rep))
      );
      
      results.push(...groupResults);

      // ì¼ê´€ì„± ì²´í¬í¬ì¸íŠ¸
      await this.consistencyManager.checkpoint(groupResults);
    }

    return {
      success: results.every(r => r.success),
      results,
      consistencyReport: await this.consistencyManager.report()
    };
  }

  private async executeReplication(
    replication: ReplicationTask
  ): Promise<ReplicationTaskResult> {
    const startTime = Date.now();

    try {
      // 1. ë°ì´í„° ì½ê¸°
      const data = await this.readData(
        replication.source,
        replication.dataId
      );

      // 2. ì••ì¶• (ì„ íƒì )
      const compressed = await this.compressIfBeneficial(data);

      // 3. ì „ì†¡
      const transfers = await Promise.all(
        replication.targets.map(target =>
          this.transferData(compressed, replication.source, target)
        )
      );

      // 4. ê²€ì¦
      await this.verifyReplications(transfers);

      return {
        success: true,
        replicationId: replication.id,
        duration: Date.now() - startTime,
        bytesTransferred: compressed.size * replication.targets.length
      };

    } catch (error) {
      return {
        success: false,
        replicationId: replication.id,
        error: error.message,
        duration: Date.now() - startTime
      };
    }
  }
}

// ì§€ì—° ì‹œê°„ ìµœì í™”
export class LatencyOptimizer {
  private latencyPredictor: LatencyPredictor;
  private routingOptimizer: RoutingOptimizer;
  private cacheManager: GeoCacheManager;

  async optimize(
    params: LatencyOptimizationParams
  ): Promise<OptimizedDistribution> {
    // 1. ì§€ì—° ì‹œê°„ ì˜ˆì¸¡ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
    const latencyMatrix = await this.createLatencyMatrix(params.regions);

    // 2. ì‘ì—… ë°°ì¹˜ ìµœì í™”
    const placement = await this.optimizePlacement(
      params.workload,
      latencyMatrix,
      params.constraints
    );

    // 3. ë¼ìš°íŒ… ìµœì í™”
    const routing = await this.routingOptimizer.optimize(
      placement,
      latencyMatrix
    );

    // 4. ìºì‹œ ì „ëµ
    const cacheStrategy = await this.cacheManager.optimize(
      placement,
      params.workload.accessPatterns
    );

    return {
      placement,
      routing,
      cacheStrategy,
      expectedLatency: this.calculateExpectedLatency(
        placement,
        routing,
        latencyMatrix
      )
    };
  }

  private async createLatencyMatrix(
    regions: Region[]
  ): Promise<LatencyMatrix> {
    const matrix: number[][] = [];

    for (let i = 0; i < regions.length; i++) {
      matrix[i] = [];
      for (let j = 0; j < regions.length; j++) {
        if (i === j) {
          matrix[i][j] = 0;
        } else {
          matrix[i][j] = await this.latencyPredictor.predict(
            regions[i],
            regions[j]
          );
        }
      }
    }

    return new LatencyMatrix(matrix, regions);
  }

  private async optimizePlacement(
    workload: WorkloadAnalysis,
    latencyMatrix: LatencyMatrix,
    constraints: DistributionConstraints
  ): Promise<Placement> {
    // ILP (Integer Linear Programming) ë¬¸ì œë¡œ ë³€í™˜
    const problem = this.formulatePlacementProblem(
      workload,
      latencyMatrix,
      constraints
    );

    // ì†”ë²„ ì‹¤í–‰
    const solution = await this.solvePlacement(problem);

    return this.solutionToPlacement(solution, workload);
  }
}

// ì¥ì•  ë³µêµ¬ ê´€ë¦¬ì
export class MultiRegionFailoverManager {
  private healthMonitor: RegionHealthMonitor;
  private failoverCoordinator: FailoverCoordinator;
  private stateReplicator: StateReplicator;

  async handleRegionFailure(
    failedRegion: string
  ): Promise<FailoverResult> {
    logger.error(`Region failure detected: ${failedRegion}`);

    // 1. ì˜í–¥ ë²”ìœ„ í‰ê°€
    const impact = await this.assessImpact(failedRegion);

    // 2. ëŒ€ì²´ ì§€ì—­ ì„ íƒ
    const alternateRegions = await this.selectAlternateRegions(
      failedRegion,
      impact
    );

    // 3. ìƒíƒœ ë³µêµ¬
    const stateRecovery = await this.recoverState(
      failedRegion,
      alternateRegions
    );

    // 4. íŠ¸ë˜í”½ ë¦¬ë¼ìš°íŒ…
    const rerouting = await this.rerouteTraffic(
      failedRegion,
      alternateRegions
    );

    // 5. ì„œë¹„ìŠ¤ ì¬ì‹œì‘
    const serviceRestoration = await this.restoreServices(
      impact.affectedServices,
      alternateRegions
    );

    return {
      failedRegion,
      alternateRegions,
      recoveredState: stateRecovery,
      reroutedTraffic: rerouting,
      restoredServices: serviceRestoration,
      totalDowntime: this.calculateDowntime(impact)
    };
  }

  private async selectAlternateRegions(
    failedRegion: string,
    impact: ImpactAssessment
  ): Promise<string[]> {
    const candidates = await this.getHealthyRegions();
    const scored: ScoredRegion[] = [];

    for (const candidate of candidates) {
      const score = await this.scoreRegion(candidate, {
        capacity: await this.getAvailableCapacity(candidate),
        latency: await this.getLatencyFrom(failedRegion, candidate),
        dataLocality: await this.getDataLocality(candidate, impact),
        cost: await this.getRegionCost(candidate)
      });

      scored.push({ region: candidate, score });
    }

    // ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ ë° ì„ íƒ
    scored.sort((a, b) => b.score - a.score);
    
    const selected = [];
    let remainingLoad = impact.totalLoad;

    for (const { region } of scored) {
      const capacity = await this.getAvailableCapacity(region);
      selected.push(region);
      remainingLoad -= capacity;

      if (remainingLoad <= 0) break;
    }

    return selected;
  }

  private async recoverState(
    failedRegion: string,
    alternateRegions: string[]
  ): Promise<StateRecoveryResult> {
    // 1. ìµœì‹  ìƒíƒœ ìŠ¤ëƒ…ìƒ· ì°¾ê¸°
    const snapshot = await this.findLatestSnapshot(failedRegion);

    // 2. ë¸íƒ€ ë³€ê²½ ì‚¬í•­ ìˆ˜ì§‘
    const deltas = await this.collectDeltas(
      failedRegion,
      snapshot.timestamp
    );

    // 3. ìƒíƒœ ì¬êµ¬ì„±
    const reconstructed = await this.reconstructState(snapshot, deltas);

    // 4. ëŒ€ì²´ ì§€ì—­ì— ë°°í¬
    const deployments = await Promise.all(
      alternateRegions.map(region =>
        this.deployState(reconstructed, region)
      )
    );

    return {
      snapshot,
      deltasApplied: deltas.length,
      deployments,
      dataLoss: this.assessDataLoss(snapshot, deltas)
    };
  }
}

// ì§€ì—­ ê°„ ì¼ê´€ì„± ê´€ë¦¬
export class CrossRegionConsistencyManager {
  private vectorClockManager: VectorClockManager;
  private conflictDetector: ConflictDetector;
  private reconciler: StateReconciler;

  async ensureConsistency(
    regions: string[]
  ): Promise<ConsistencyReport> {
    // 1. ê° ì§€ì—­ì˜ ë²¡í„° í´ëŸ­ ìˆ˜ì§‘
    const clocks = await this.collectVectorClocks(regions);

    // 2. ì¼ê´€ì„± ê²€ì‚¬
    const inconsistencies = await this.detectInconsistencies(clocks);

    // 3. ì¶©ëŒ ê°ì§€
    const conflicts = await this.conflictDetector.detect(inconsistencies);

    // 4. ì¡°ì • ì‹¤í–‰
    const reconciliations = await this.reconcile(conflicts);

    return {
      regions,
      consistencyLevel: this.calculateConsistencyLevel(inconsistencies),
      conflicts: conflicts.length,
      reconciled: reconciliations.length,
      timestamp: new Date()
    };
  }

  private async reconcile(
    conflicts: Conflict[]
  ): Promise<Reconciliation[]> {
    const reconciliations: Reconciliation[] = [];

    for (const conflict of conflicts) {
      const strategy = this.selectReconciliationStrategy(conflict);
      const result = await this.reconciler.reconcile(conflict, strategy);
      
      reconciliations.push(result);

      // ì¡°ì • ê²°ê³¼ ì „íŒŒ
      await this.propagateReconciliation(result);
    }

    return reconciliations;
  }

  private selectReconciliationStrategy(
    conflict: Conflict
  ): ReconciliationStrategy {
    // ì¶©ëŒ ìœ í˜•ì— ë”°ë¥¸ ì „ëµ ì„ íƒ
    switch (conflict.type) {
      case 'write-write':
        return conflict.dataType === 'counter' 
          ? 'crdt-merge' 
          : 'last-write-wins';
      
      case 'write-delete':
        return 'resurrection';
      
      case 'ordering':
        return 'causal-ordering';
      
      default:
        return 'manual-resolution';
    }
  }
}

// ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
export class MultiRegionPerformanceDashboard {
  private metricsCollector: GlobalMetricsCollector;
  private visualizer: MetricsVisualizer;
  private alertSystem: GlobalAlertSystem;

  async initialize(): Promise<void> {
    // ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
    await this.setupMetricStreams();

    // ëŒ€ì‹œë³´ë“œ UI ì´ˆê¸°í™”
    await this.initializeDashboard();

    // ì•Œë¦¼ ê·œì¹™ ì„¤ì •
    await this.configureAlerts();
  }

  private async setupMetricStreams(): Promise<void> {
    // ê° ì§€ì—­ë³„ ë©”íŠ¸ë¦­ ìŠ¤íŠ¸ë¦¼
    const regions = await this.getAllRegions();

    for (const region of regions) {
      const stream = await this.metricsCollector.createStream(region);
      
      stream.on('metrics', async (metrics) => {
        await this.processRegionMetrics(region, metrics);
      });

      stream.on('error', (error) => {
        logger.error(`Metrics stream error for ${region}:`, error);
      });
    }

    // ê¸€ë¡œë²Œ ì§‘ê³„ ìŠ¤íŠ¸ë¦¼
    const globalStream = await this.metricsCollector.createGlobalStream();
    
    globalStream.on('aggregate', async (aggregate) => {
      await this.updateGlobalView(aggregate);
    });
  }

  private async processRegionMetrics(
    region: string,
    metrics: RegionMetrics
  ): Promise<void> {
    // 1. ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
    await this.visualizer.updateRegion(region, metrics);

    // 2. ì´ìƒ ê°ì§€
    const anomalies = await this.detectAnomalies(region, metrics);
    
    if (anomalies.length > 0) {
      await this.handleAnomalies(region, anomalies);
    }

    // 3. ì¶”ì„¸ ë¶„ì„
    await this.analyzeTrends(region, metrics);
  }

  private async updateGlobalView(
    aggregate: GlobalAggregate
  ): Promise<void> {
    // ê¸€ë¡œë²Œ ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸
    await this.visualizer.updateGlobal({
      totalRequests: aggregate.totalRequests,
      avgLatency: aggregate.avgLatency,
      errorRate: aggregate.errorRate,
      regionHealth: aggregate.regionHealth,
      crossRegionTraffic: aggregate.crossRegionTraffic
    });

    // ë¹„ìš© ë¶„ì„
    const costAnalysis = await this.analyzeCosts(aggregate);
    await this.visualizer.updateCosts(costAnalysis);
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë©€í‹° ë¦¬ì „ ì›Œí¬ë¡œë“œ ë¶„ë°°
- [ ] ê¸€ë¡œë²Œ ìƒíƒœ ì¡°ì •
- [ ] ì§€ì—­ ê°„ ë°ì´í„° ë³µì œ
- [ ] ì¥ì•  ë³µêµ¬ ë° ì¼ê´€ì„± ê´€ë¦¬

---

# Phase 5: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ - Tasks 5.10~5.12 SubTask êµ¬ì¡°

## ğŸ“‹ Task 5.10~5.12 SubTask ë¦¬ìŠ¤íŠ¸

### Task 5.10: ì‹¤ì‹œê°„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ëª¨ë‹ˆí„°ë§
- **SubTask 5.10.1**: ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ
- **SubTask 5.10.2**: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¶”ì 
- **SubTask 5.10.3**: ì•Œë¦¼ ë° ê²½ê³  ì‹œìŠ¤í…œ
- **SubTask 5.10.4**: ë¡œê·¸ ì§‘ê³„ ë° ë¶„ì„

### Task 5.11: ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë° ë¶„ì„ ì‹œìŠ¤í…œ
- **SubTask 5.11.1**: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸
- **SubTask 5.11.2**: ì‹œê³„ì—´ ë°ì´í„° ì €ì¥ì†Œ
- **SubTask 5.11.3**: ì„±ëŠ¥ ë¶„ì„ ì—”ì§„
- **SubTask 5.11.4**: ì˜ˆì¸¡ ë¶„ì„ ë° ìµœì í™” ì œì•ˆ

### Task 5.12: ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ ë° ì œì–´ íŒ¨ë„
- **SubTask 5.12.1**: ëŒ€ì‹œë³´ë“œ UI/UX ì„¤ê³„
- **SubTask 5.12.2**: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë·°
- **SubTask 5.12.3**: ì œì–´ ë° ê´€ë¦¬ ê¸°ëŠ¥
- **SubTask 5.12.4**: ë³´ê³ ì„œ ìƒì„± ë° ë‚´ë³´ë‚´ê¸°

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 5.10: ì‹¤ì‹œê°„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ëª¨ë‹ˆí„°ë§

#### SubTask 5.10.1: ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/monitoring/event_streaming.ts
export enum EventType {
  WORKFLOW_STARTED = 'workflow.started',
  WORKFLOW_COMPLETED = 'workflow.completed',
  WORKFLOW_FAILED = 'workflow.failed',
  TASK_STARTED = 'task.started',
  TASK_COMPLETED = 'task.completed',
  TASK_FAILED = 'task.failed',
  TASK_RETRIED = 'task.retried',
  RESOURCE_ALLOCATED = 'resource.allocated',
  RESOURCE_RELEASED = 'resource.released',
  SCALING_TRIGGERED = 'scaling.triggered',
  ERROR_OCCURRED = 'error.occurred',
  PERFORMANCE_DEGRADATION = 'performance.degradation'
}

export interface OrchestrationEvent {
  id: string;
  type: EventType;
  timestamp: Date;
  source: string;
  correlationId?: string;
  workflowId?: string;
  taskId?: string;
  data: Record<string, any>;
  metadata: EventMetadata;
}

export class EventStreamingSystem {
  private kafka: KafkaClient;
  private eventStore: EventStore;
  private streamProcessors: Map<string, StreamProcessor>;
  private eventEnricher: EventEnricher;

  constructor(config: EventStreamingConfig) {
    this.kafka = new KafkaClient(config.kafka);
    this.eventStore = new EventStore(config.storage);
    this.streamProcessors = new Map();
    this.eventEnricher = new EventEnricher();
    
    this.initialize();
  }

  private async initialize(): Promise<void> {
    // Kafka topics ìƒì„±
    await this.createTopics();
    
    // Stream processors ë“±ë¡
    this.registerProcessors();
    
    // Consumer groups ì‹œì‘
    await this.startConsumers();
  }

  private async createTopics(): Promise<void> {
    const topics = [
      {
        name: 'orchestration-events',
        partitions: 12,
        replicationFactor: 3
      },
      {
        name: 'orchestration-events-dlq',
        partitions: 6,
        replicationFactor: 3
      },
      {
        name: 'orchestration-metrics',
        partitions: 8,
        replicationFactor: 3
      },
      {
        name: 'orchestration-alerts',
        partitions: 4,
        replicationFactor: 3
      }
    ];

    for (const topic of topics) {
      await this.kafka.createTopic(topic);
    }
  }

  async publishEvent(event: Partial<OrchestrationEvent>): Promise<void> {
    // ì´ë²¤íŠ¸ ìƒì„± ë° ë³´ê°•
    const enrichedEvent = await this.eventEnricher.enrich({
      id: event.id || uuid(),
      timestamp: event.timestamp || new Date(),
      ...event
    } as OrchestrationEvent);

    // ì´ë²¤íŠ¸ ì €ì¥
    await this.eventStore.save(enrichedEvent);

    // Kafkaë¡œ ë°œí–‰
    await this.kafka.send({
      topic: 'orchestration-events',
      messages: [{
        key: enrichedEvent.workflowId || enrichedEvent.id,
        value: JSON.stringify(enrichedEvent),
        headers: {
          eventType: enrichedEvent.type,
          source: enrichedEvent.source,
          timestamp: enrichedEvent.timestamp.toISOString()
        }
      }]
    });

    // ì‹¤ì‹œê°„ ì²˜ë¦¬
    await this.processRealtime(enrichedEvent);
  }

  private async processRealtime(event: OrchestrationEvent): Promise<void> {
    // ê´€ë ¨ í”„ë¡œì„¸ì„œ ì°¾ê¸°
    const processors = this.findProcessors(event.type);

    // ë³‘ë ¬ ì²˜ë¦¬
    await Promise.all(
      processors.map(processor => 
        processor.process(event).catch(error => {
          logger.error('Event processing failed', { error, event });
          return this.handleProcessingError(event, error);
        })
      )
    );
  }

  registerProcessor(name: string, processor: StreamProcessor): void {
    this.streamProcessors.set(name, processor);
  }

  async subscribe(
    eventTypes: EventType[],
    handler: EventHandler
  ): Promise<Subscription> {
    const consumerId = uuid();
    const consumer = this.kafka.consumer({
      groupId: `orchestration-monitor-${consumerId}`,
      sessionTimeout: 30000,
      heartbeatInterval: 3000
    });

    await consumer.connect();
    await consumer.subscribe({
      topic: 'orchestration-events',
      fromBeginning: false
    });

    const subscription = new Subscription(consumerId, consumer);

    consumer.run({
      eachMessage: async ({ message }) => {
        const event = JSON.parse(message.value.toString());
        
        if (eventTypes.includes(event.type)) {
          await handler(event);
        }
      }
    });

    return subscription;
  }
}

// ì´ë²¤íŠ¸ ë³´ê°•ê¸°
export class EventEnricher {
  private contextProvider: ContextProvider;
  private metadataExtractor: MetadataExtractor;

  async enrich(event: OrchestrationEvent): Promise<OrchestrationEvent> {
    // ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
    const context = await this.contextProvider.getContext(event);
    
    // ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    const metadata = await this.metadataExtractor.extract(event);

    return {
      ...event,
      data: {
        ...event.data,
        context
      },
      metadata: {
        ...event.metadata,
        ...metadata,
        enrichedAt: new Date()
      }
    };
  }
}

// ìŠ¤íŠ¸ë¦¼ í”„ë¡œì„¸ì„œ
export abstract class StreamProcessor {
  abstract name: string;
  abstract eventTypes: EventType[];

  async process(event: OrchestrationEvent): Promise<void> {
    if (!this.shouldProcess(event)) {
      return;
    }

    try {
      await this.preProcess(event);
      await this.processEvent(event);
      await this.postProcess(event);
    } catch (error) {
      await this.handleError(event, error);
    }
  }

  protected shouldProcess(event: OrchestrationEvent): boolean {
    return this.eventTypes.includes(event.type);
  }

  protected async preProcess(event: OrchestrationEvent): Promise<void> {
    // Override in subclasses
  }

  protected abstract processEvent(event: OrchestrationEvent): Promise<void>;

  protected async postProcess(event: OrchestrationEvent): Promise<void> {
    // Override in subclasses
  }

  protected async handleError(
    event: OrchestrationEvent,
    error: Error
  ): Promise<void> {
    logger.error(`${this.name} processing failed`, { event, error });
  }
}

// ì‹¤ì‹œê°„ ìƒíƒœ ì¶”ì ê¸°
export class RealtimeStateTracker extends StreamProcessor {
  name = 'realtime-state-tracker';
  eventTypes = Object.values(EventType);

  private stateStore: StateStore;
  private stateAggregator: StateAggregator;
  private websocketServer: WebSocketServer;

  constructor(config: StateTrackerConfig) {
    super();
    this.stateStore = new StateStore(config.redis);
    this.stateAggregator = new StateAggregator();
    this.websocketServer = new WebSocketServer(config.websocket);
  }

  protected async processEvent(event: OrchestrationEvent): Promise<void> {
    // ìƒíƒœ ì—…ë°ì´íŠ¸
    const stateUpdate = await this.updateState(event);

    // ì§‘ê³„ ì—…ë°ì´íŠ¸
    const aggregates = await this.stateAggregator.update(event);

    // WebSocketìœ¼ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
    await this.broadcast({
      type: 'state-update',
      event,
      state: stateUpdate,
      aggregates
    });
  }

  private async updateState(
    event: OrchestrationEvent
  ): Promise<StateUpdate> {
    switch (event.type) {
      case EventType.WORKFLOW_STARTED:
        return this.handleWorkflowStarted(event);
      
      case EventType.WORKFLOW_COMPLETED:
        return this.handleWorkflowCompleted(event);
      
      case EventType.TASK_STARTED:
        return this.handleTaskStarted(event);
      
      case EventType.TASK_COMPLETED:
        return this.handleTaskCompleted(event);
      
      default:
        return this.handleGenericEvent(event);
    }
  }

  private async handleWorkflowStarted(
    event: OrchestrationEvent
  ): Promise<StateUpdate> {
    const workflowState: WorkflowState = {
      id: event.workflowId!,
      status: 'running',
      startTime: event.timestamp,
      tasks: [],
      metadata: event.data
    };

    await this.stateStore.setWorkflowState(event.workflowId!, workflowState);

    return {
      type: 'workflow-state',
      id: event.workflowId!,
      state: workflowState
    };
  }

  private async broadcast(update: any): Promise<void> {
    const message = JSON.stringify(update);
    
    // ì „ì²´ í´ë¼ì´ì–¸íŠ¸ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
    this.websocketServer.broadcast(message);

    // íŠ¹ì • êµ¬ë…ìì—ê²Œ ì „ì†¡
    if (update.event.workflowId) {
      this.websocketServer.sendToRoom(
        `workflow:${update.event.workflowId}`,
        message
      );
    }
  }
}

// ì´ë²¤íŠ¸ ì§‘ê³„ê¸°
export class EventAggregator extends StreamProcessor {
  name = 'event-aggregator';
  eventTypes = Object.values(EventType);

  private windowManager: WindowManager;
  private aggregationRules: AggregationRule[];

  constructor(config: AggregatorConfig) {
    super();
    this.windowManager = new WindowManager(config.windows);
    this.aggregationRules = config.rules;
  }

  protected async processEvent(event: OrchestrationEvent): Promise<void> {
    // ê° ìœˆë„ìš°ì— ì´ë²¤íŠ¸ ì¶”ê°€
    await this.windowManager.addEvent(event);

    // ì§‘ê³„ ê·œì¹™ ì‹¤í–‰
    for (const rule of this.aggregationRules) {
      if (rule.matches(event)) {
        await this.executeAggregation(rule, event);
      }
    }

    // ë§Œë£Œëœ ìœˆë„ìš° ì²˜ë¦¬
    await this.processExpiredWindows();
  }

  private async executeAggregation(
    rule: AggregationRule,
    event: OrchestrationEvent
  ): Promise<void> {
    const window = this.windowManager.getWindow(rule.windowType);
    const events = await window.getEvents();

    const result = await rule.aggregate(events);

    if (result.shouldEmit) {
      await this.emitAggregatedEvent({
        type: EventType.AGGREGATED,
        timestamp: new Date(),
        source: 'aggregator',
        data: {
          rule: rule.name,
          window: rule.windowType,
          result: result.value
        }
      });
    }
  }
}

// ì‹¤ì‹œê°„ ì•Œë¦¼ í”„ë¡œì„¸ì„œ
export class AlertProcessor extends StreamProcessor {
  name = 'alert-processor';
  eventTypes = [
    EventType.WORKFLOW_FAILED,
    EventType.TASK_FAILED,
    EventType.ERROR_OCCURRED,
    EventType.PERFORMANCE_DEGRADATION
  ];

  private alertManager: AlertManager;
  private notificationService: NotificationService;

  protected async processEvent(event: OrchestrationEvent): Promise<void> {
    // ì•Œë¦¼ ê·œì¹™ í‰ê°€
    const alerts = await this.alertManager.evaluate(event);

    // ì•Œë¦¼ ë°œì†¡
    for (const alert of alerts) {
      await this.notificationService.send(alert);
    }

    // ì•Œë¦¼ ê¸°ë¡
    await this.recordAlerts(alerts);
  }
}

// WebSocket ì„œë²„
export class WebSocketServer {
  private io: SocketIOServer;
  private rooms: Map<string, Set<string>> = new Map();

  constructor(config: WebSocketConfig) {
    this.io = new SocketIOServer(config.port, {
      cors: config.cors,
      transports: ['websocket', 'polling']
    });

    this.setupHandlers();
  }

  private setupHandlers(): void {
    this.io.on('connection', (socket) => {
      logger.info('Client connected', { socketId: socket.id });

      // ì¸ì¦
      socket.on('authenticate', async (token) => {
        const auth = await this.authenticate(token);
        if (auth.valid) {
          socket.data.user = auth.user;
          socket.emit('authenticated');
        } else {
          socket.disconnect();
        }
      });

      // ë£¸ êµ¬ë…
      socket.on('subscribe', (rooms: string[]) => {
        for (const room of rooms) {
          socket.join(room);
          this.addToRoom(room, socket.id);
        }
      });

      // ì—°ê²° í•´ì œ
      socket.on('disconnect', () => {
        this.removeFromAllRooms(socket.id);
        logger.info('Client disconnected', { socketId: socket.id });
      });
    });
  }

  broadcast(message: string): void {
    this.io.emit('event', message);
  }

  sendToRoom(room: string, message: string): void {
    this.io.to(room).emit('event', message);
  }

  private addToRoom(room: string, socketId: string): void {
    if (!this.rooms.has(room)) {
      this.rooms.set(room, new Set());
    }
    this.rooms.get(room)!.add(socketId);
  }

  private removeFromAllRooms(socketId: string): void {
    for (const [room, sockets] of this.rooms.entries()) {
      sockets.delete(socketId);
      if (sockets.size === 0) {
        this.rooms.delete(room);
      }
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] Kafka ê¸°ë°˜ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°
- [ ] ì‹¤ì‹œê°„ ìƒíƒœ ì¶”ì 
- [ ] WebSocket í†µì‹ 
- [ ] ì´ë²¤íŠ¸ ì§‘ê³„ ë° ë³´ê°•

#### SubTask 5.10.2: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¶”ì 
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/monitoring/workflow_tracking.ts
export interface WorkflowExecution {
  id: string;
  workflowId: string;
  version: string;
  status: WorkflowStatus;
  startTime: Date;
  endTime?: Date;
  duration?: number;
  input: Record<string, any>;
  output?: Record<string, any>;
  error?: Error;
  tasks: TaskExecution[];
  metadata: ExecutionMetadata;
  trace: ExecutionTrace;
}

export class WorkflowExecutionTracker {
  private executionStore: ExecutionStore;
  private traceCollector: TraceCollector;
  private lineageTracker: LineageTracker;
  private executionAnalyzer: ExecutionAnalyzer;

  constructor(config: TrackerConfig) {
    this.executionStore = new ExecutionStore(config.storage);
    this.traceCollector = new TraceCollector(config.tracing);
    this.lineageTracker = new LineageTracker();
    this.executionAnalyzer = new ExecutionAnalyzer();
  }

  async startTracking(
    workflowId: string,
    input: Record<string, any>
  ): Promise<ExecutionContext> {
    const executionId = uuid();
    const trace = this.traceCollector.createTrace(executionId);

    const execution: WorkflowExecution = {
      id: executionId,
      workflowId,
      version: await this.getWorkflowVersion(workflowId),
      status: WorkflowStatus.RUNNING,
      startTime: new Date(),
      input,
      tasks: [],
      metadata: {
        triggeredBy: await this.getCurrentUser(),
        environment: process.env.NODE_ENV || 'development',
        correlationId: trace.correlationId
      },
      trace
    };

    // ì‹¤í–‰ ì €ì¥
    await this.executionStore.save(execution);

    // ê³„ë³´ ì¶”ì  ì‹œì‘
    await this.lineageTracker.startTracking(execution);

    // ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜
    return new ExecutionContext(execution, this);
  }

  async trackTaskExecution(
    executionId: string,
    task: TaskDefinition
  ): Promise<TaskExecutionContext> {
    const execution = await this.executionStore.get(executionId);
    if (!execution) {
      throw new Error(`Execution ${executionId} not found`);
    }

    const taskExecution: TaskExecution = {
      id: uuid(),
      taskId: task.id,
      name: task.name,
      type: task.type,
      status: TaskStatus.PENDING,
      createdAt: new Date(),
      dependencies: task.dependencies || [],
      retries: 0,
      maxRetries: task.maxRetries || 3
    };

    // íƒœìŠ¤í¬ ì¶”ê°€
    execution.tasks.push(taskExecution);
    await this.executionStore.update(execution);

    // íŠ¸ë ˆì´ìŠ¤ ìŠ¤íŒ¬ ìƒì„±
    const span = this.traceCollector.createSpan(
      execution.trace,
      `task:${task.name}`
    );

    return new TaskExecutionContext(taskExecution, span, this);
  }

  async updateTaskStatus(
    executionId: string,
    taskId: string,
    update: TaskStatusUpdate
  ): Promise<void> {
    const execution = await this.executionStore.get(executionId);
    if (!execution) return;

    const task = execution.tasks.find(t => t.id === taskId);
    if (!task) return;

    // ìƒíƒœ ì—…ë°ì´íŠ¸
    task.status = update.status;
    
    if (update.status === TaskStatus.RUNNING) {
      task.startTime = new Date();
    } else if (update.status === TaskStatus.COMPLETED) {
      task.endTime = new Date();
      task.duration = task.endTime.getTime() - task.startTime!.getTime();
      task.output = update.output;
    } else if (update.status === TaskStatus.FAILED) {
      task.endTime = new Date();
      task.error = update.error;
      task.retries++;
    }

    // ì €ì¥
    await this.executionStore.update(execution);

    // ì´ë²¤íŠ¸ ë°œí–‰
    await this.publishTaskEvent(execution, task, update);
  }

  async completeExecution(
    executionId: string,
    result: ExecutionResult
  ): Promise<void> {
    const execution = await this.executionStore.get(executionId);
    if (!execution) return;

    // ì‹¤í–‰ ì™„ë£Œ
    execution.status = result.success 
      ? WorkflowStatus.COMPLETED 
      : WorkflowStatus.FAILED;
    execution.endTime = new Date();
    execution.duration = execution.endTime.getTime() - execution.startTime.getTime();
    
    if (result.success) {
      execution.output = result.output;
    } else {
      execution.error = result.error;
    }

    // ì €ì¥
    await this.executionStore.update(execution);

    // íŠ¸ë ˆì´ìŠ¤ ì™„ë£Œ
    await this.traceCollector.completeTrace(execution.trace);

    // ê³„ë³´ ì™„ë£Œ
    await this.lineageTracker.completeTracking(execution);

    // ë¶„ì„ ì‹¤í–‰
    await this.executionAnalyzer.analyze(execution);
  }

  async getExecutionHistory(
    workflowId: string,
    options: HistoryOptions = {}
  ): Promise<ExecutionHistory> {
    const executions = await this.executionStore.findByWorkflow(
      workflowId,
      options
    );

    // í†µê³„ ê³„ì‚°
    const stats = this.calculateStatistics(executions);

    // íŠ¸ë Œë“œ ë¶„ì„
    const trends = await this.analyzeTrends(executions);

    return {
      executions,
      stats,
      trends,
      totalCount: await this.executionStore.count(workflowId)
    };
  }

  private calculateStatistics(
    executions: WorkflowExecution[]
  ): ExecutionStatistics {
    if (executions.length === 0) {
      return {
        totalExecutions: 0,
        successRate: 0,
        averageDuration: 0,
        medianDuration: 0,
        p95Duration: 0
      };
    }

    const successful = executions.filter(
      e => e.status === WorkflowStatus.COMPLETED
    );
    const durations = executions
      .filter(e => e.duration)
      .map(e => e.duration!)
      .sort((a, b) => a - b);

    return {
      totalExecutions: executions.length,
      successRate: successful.length / executions.length,
      averageDuration: this.average(durations),
      medianDuration: this.percentile(durations, 50),
      p95Duration: this.percentile(durations, 95),
      taskStatistics: this.calculateTaskStatistics(executions)
    };
  }
}

// ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸
export class ExecutionContext {
  constructor(
    private execution: WorkflowExecution,
    private tracker: WorkflowExecutionTracker
  ) {}

  async trackTask(task: TaskDefinition): Promise<TaskExecutionContext> {
    return this.tracker.trackTaskExecution(this.execution.id, task);
  }

  async updateStatus(status: WorkflowStatus): Promise<void> {
    this.execution.status = status;
    await this.save();
  }

  async addMetadata(key: string, value: any): Promise<void> {
    this.execution.metadata[key] = value;
    await this.save();
  }

  async complete(result: ExecutionResult): Promise<void> {
    await this.tracker.completeExecution(this.execution.id, result);
  }

  private async save(): Promise<void> {
    await this.tracker.executionStore.update(this.execution);
  }
}

// ë¶„ì‚° ì¶”ì 
export class TraceCollector {
  private tracer: Tracer;
  private propagator: TracePropagator;

  constructor(config: TracingConfig) {
    this.tracer = new Tracer(config);
    this.propagator = new TracePropagator();
  }

  createTrace(executionId: string): ExecutionTrace {
    const trace = this.tracer.startSpan('workflow-execution', {
      attributes: {
        'workflow.execution.id': executionId,
        'workflow.start.time': new Date().toISOString()
      }
    });

    return {
      traceId: trace.spanContext().traceId,
      spanId: trace.spanContext().spanId,
      correlationId: uuid(),
      baggage: new Map(),
      spans: [trace]
    };
  }

  createSpan(
    parentTrace: ExecutionTrace,
    name: string,
    attributes?: Record<string, any>
  ): Span {
    const span = this.tracer.startSpan(name, {
      parent: parentTrace.spans[0],
      attributes
    });

    parentTrace.spans.push(span);
    return span;
  }

  async completeTrace(trace: ExecutionTrace): Promise<void> {
    // ëª¨ë“  ìŠ¤íŒ¬ ì™„ë£Œ
    for (const span of trace.spans.reverse()) {
      span.end();
    }

    // íŠ¸ë ˆì´ìŠ¤ ë°ì´í„° ì „ì†¡
    await this.tracer.flush();
  }

  injectContext(carrier: any, trace: ExecutionTrace): void {
    this.propagator.inject(trace, carrier);
  }

  extractContext(carrier: any): ExecutionTrace | null {
    return this.propagator.extract(carrier);
  }
}

// ë°ì´í„° ê³„ë³´ ì¶”ì 
export class LineageTracker {
  private lineageGraph: LineageGraph;
  private datasetRegistry: DatasetRegistry;

  async startTracking(execution: WorkflowExecution): Promise<void> {
    // ì…ë ¥ ë°ì´í„°ì…‹ ë“±ë¡
    const inputDatasets = await this.identifyDatasets(execution.input);
    
    for (const dataset of inputDatasets) {
      await this.datasetRegistry.register(dataset);
      await this.lineageGraph.addNode({
        type: 'dataset',
        id: dataset.id,
        metadata: dataset
      });
    }

    // ì‹¤í–‰ ë…¸ë“œ ì¶”ê°€
    await this.lineageGraph.addNode({
      type: 'execution',
      id: execution.id,
      metadata: {
        workflowId: execution.workflowId,
        startTime: execution.startTime
      }
    });

    // ì…ë ¥ ì—£ì§€ ìƒì„±
    for (const dataset of inputDatasets) {
      await this.lineageGraph.addEdge({
        from: dataset.id,
        to: execution.id,
        type: 'input',
        timestamp: execution.startTime
      });
    }
  }

  async trackDataTransformation(
    executionId: string,
    taskId: string,
    transformation: DataTransformation
  ): Promise<void> {
    // ë³€í™˜ ë…¸ë“œ ì¶”ê°€
    await this.lineageGraph.addNode({
      type: 'transformation',
      id: `${executionId}:${taskId}`,
      metadata: transformation
    });

    // ì…ë ¥/ì¶œë ¥ ì—£ì§€ ì¶”ê°€
    for (const input of transformation.inputs) {
      await this.lineageGraph.addEdge({
        from: input,
        to: `${executionId}:${taskId}`,
        type: 'transform-input'
      });
    }

    for (const output of transformation.outputs) {
      await this.lineageGraph.addEdge({
        from: `${executionId}:${taskId}`,
        to: output,
        type: 'transform-output'
      });
    }
  }

  async getLineage(
    datasetId: string,
    direction: 'upstream' | 'downstream' | 'both' = 'both'
  ): Promise<LineageInfo> {
    const paths = await this.lineageGraph.findPaths(datasetId, {
      direction,
      maxDepth: 10
    });

    return {
      datasetId,
      upstream: direction !== 'downstream' ? paths.upstream : [],
      downstream: direction !== 'upstream' ? paths.downstream : [],
      impactAnalysis: await this.analyzeImpact(paths)
    };
  }
}

// ì‹¤í–‰ ë¶„ì„ê¸°
export class ExecutionAnalyzer {
  private patternDetector: PatternDetector;
  private anomalyDetector: AnomalyDetector;
  private performanceAnalyzer: PerformanceAnalyzer;

  async analyze(execution: WorkflowExecution): Promise<ExecutionAnalysis> {
    // íŒ¨í„´ ê°ì§€
    const patterns = await this.patternDetector.detect(execution);

    // ì´ìƒ ê°ì§€
    const anomalies = await this.anomalyDetector.detect(execution);

    // ì„±ëŠ¥ ë¶„ì„
    const performance = await this.performanceAnalyzer.analyze(execution);

    // ë³‘ëª© ì§€ì  ì‹ë³„
    const bottlenecks = this.identifyBottlenecks(execution);

    // ê°œì„  ì œì•ˆ
    const recommendations = await this.generateRecommendations({
      patterns,
      anomalies,
      performance,
      bottlenecks
    });

    return {
      executionId: execution.id,
      patterns,
      anomalies,
      performance,
      bottlenecks,
      recommendations
    };
  }

  private identifyBottlenecks(
    execution: WorkflowExecution
  ): Bottleneck[] {
    const bottlenecks: Bottleneck[] = [];

    // íƒœìŠ¤í¬ë³„ ì‹¤í–‰ ì‹œê°„ ë¶„ì„
    const taskDurations = execution.tasks
      .filter(t => t.duration)
      .sort((a, b) => b.duration! - a.duration!);

    // ìƒìœ„ 20% íƒœìŠ¤í¬ë¥¼ ë³‘ëª©ìœ¼ë¡œ ì‹ë³„
    const threshold = taskDurations.length * 0.2;
    
    for (let i = 0; i < Math.min(threshold, taskDurations.length); i++) {
      const task = taskDurations[i];
      bottlenecks.push({
        type: 'task',
        id: task.id,
        name: task.name,
        duration: task.duration!,
        impact: task.duration! / execution.duration!,
        suggestions: this.getBottleneckSuggestions(task)
      });
    }

    return bottlenecks;
  }
}

// ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì¶”ì 
export class ProgressTracker {
  private progressStore: ProgressStore;
  private estimator: ProgressEstimator;
  private broadcaster: ProgressBroadcaster;

  async updateProgress(
    executionId: string,
    update: ProgressUpdate
  ): Promise<void> {
    // ì§„í–‰ë¥  ê³„ì‚°
    const progress = await this.calculateProgress(executionId, update);

    // ë‚¨ì€ ì‹œê°„ ì˜ˆì¸¡
    const eta = await this.estimator.estimateTimeRemaining(
      executionId,
      progress
    );

    // ì €ì¥
    await this.progressStore.update(executionId, {
      ...progress,
      eta,
      updatedAt: new Date()
    });

    // ë¸Œë¡œë“œìºìŠ¤íŠ¸
    await this.broadcaster.broadcast({
      executionId,
      progress,
      eta
    });
  }

  private async calculateProgress(
    executionId: string,
    update: ProgressUpdate
  ): Promise<Progress> {
    const execution = await this.getExecution(executionId);
    
    const totalTasks = execution.tasks.length;
    const completedTasks = execution.tasks.filter(
      t => t.status === TaskStatus.COMPLETED
    ).length;
    const runningTasks = execution.tasks.filter(
      t => t.status === TaskStatus.RUNNING
    ).length;

    // ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì§„í–‰ë¥ 
    let weightedProgress = 0;
    let totalWeight = 0;

    for (const task of execution.tasks) {
      const weight = task.estimatedDuration || 1;
      totalWeight += weight;

      if (task.status === TaskStatus.COMPLETED) {
        weightedProgress += weight;
      } else if (task.status === TaskStatus.RUNNING && task.progress) {
        weightedProgress += weight * task.progress;
      }
    }

    return {
      percentage: totalWeight > 0 ? (weightedProgress / totalWeight) * 100 : 0,
      completedTasks,
      totalTasks,
      runningTasks,
      phase: this.determinePhase(execution)
    };
  }

  private determinePhase(execution: WorkflowExecution): string {
    // ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ ê²°ì • ë¡œì§
    const completionRate = execution.tasks.filter(
      t => t.status === TaskStatus.COMPLETED
    ).length / execution.tasks.length;

    if (completionRate === 0) return 'initialization';
    if (completionRate < 0.3) return 'early';
    if (completionRate < 0.7) return 'middle';
    if (completionRate < 1) return 'final';
    return 'completed';
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì „ì²´ ì‹¤í–‰ ì¶”ì 
- [ ] ë¶„ì‚° ì¶”ì  í†µí•©
- [ ] ë°ì´í„° ê³„ë³´ ì¶”ì 
- [ ] ì‹¤í–‰ ë¶„ì„ ë° ë³‘ëª© ê°ì§€

#### SubTask 5.10.3: ì•Œë¦¼ ë° ê²½ê³  ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/monitoring/alert_system.ts
export interface AlertRule {
  id: string;
  name: string;
  description?: string;
  enabled: boolean;
  conditions: AlertCondition[];
  actions: AlertAction[];
  severity: AlertSeverity;
  cooldown?: number;
  metadata?: Record<string, any>;
}

export enum AlertSeverity {
  INFO = 'info',
  WARNING = 'warning',
  ERROR = 'error',
  CRITICAL = 'critical'
}

export class AlertingSystem {
  private ruleEngine: AlertRuleEngine;
  private notificationManager: NotificationManager;
  private alertStore: AlertStore;
  private deduplicator: AlertDeduplicator;

  constructor(config: AlertingConfig) {
    this.ruleEngine = new AlertRuleEngine(config.rules);
    this.notificationManager = new NotificationManager(config.notifications);
    this.alertStore = new AlertStore(config.storage);
    this.deduplicator = new AlertDeduplicator();
  }

  async evaluateEvent(event: OrchestrationEvent): Promise<void> {
    // ì ìš© ê°€ëŠ¥í•œ ê·œì¹™ ì°¾ê¸°
    const applicableRules = await this.ruleEngine.findApplicableRules(event);

    for (const rule of applicableRules) {
      try {
        const triggered = await this.evaluateRule(rule, event);
        
        if (triggered) {
          await this.handleTriggeredAlert(rule, event);
        }
      } catch (error) {
        logger.error('Alert rule evaluation failed', { rule, event, error });
      }
    }
  }

  private async evaluateRule(
    rule: AlertRule,
    event: OrchestrationEvent
  ): Promise<boolean> {
    // ëª¨ë“  ì¡°ê±´ í‰ê°€
    for (const condition of rule.conditions) {
      const met = await this.evaluateCondition(condition, event);
      
      if (!met) {
        return false; // AND ë¡œì§
      }
    }

    return true;
  }

  private async evaluateCondition(
    condition: AlertCondition,
    event: OrchestrationEvent
  ): Promise<boolean> {
    switch (condition.type) {
      case 'threshold':
        return this.evaluateThreshold(condition, event);
      
      case 'pattern':
        return this.evaluatePattern(condition, event);
      
      case 'anomaly':
        return this.evaluateAnomaly(condition, event);
      
      case 'expression':
        return this.evaluateExpression(condition, event);
      
      default:
        return false;
    }
  }

  private async handleTriggeredAlert(
    rule: AlertRule,
    event: OrchestrationEvent
  ): Promise<void> {
    // ì¤‘ë³µ ì œê±°
    if (await this.deduplicator.isDuplicate(rule, event)) {
      return;
    }

    // ì•Œë¦¼ ìƒì„±
    const alert: Alert = {
      id: uuid(),
      ruleId: rule.id,
      ruleName: rule.name,
      severity: rule.severity,
      triggeredAt: new Date(),
      triggeredBy: event,
      status: AlertStatus.ACTIVE,
      metadata: {
        ...rule.metadata,
        eventData: event.data
      }
    };

    // ì €ì¥
    await this.alertStore.save(alert);

    // ì•¡ì…˜ ì‹¤í–‰
    await this.executeActions(rule.actions, alert);

    // ì¿¨ë‹¤ìš´ ì„¤ì •
    if (rule.cooldown) {
      await this.deduplicator.setCooldown(rule, rule.cooldown);
    }
  }

  private async executeActions(
    actions: AlertAction[],
    alert: Alert
  ): Promise<void> {
    for (const action of actions) {
      try {
        await this.executeAction(action, alert);
      } catch (error) {
        logger.error('Alert action execution failed', { action, alert, error });
      }
    }
  }

  private async executeAction(
    action: AlertAction,
    alert: Alert
  ): Promise<void> {
    switch (action.type) {
      case 'notification':
        await this.sendNotification(action, alert);
        break;
      
      case 'webhook':
        await this.callWebhook(action, alert);
        break;
      
      case 'escalation':
        await this.escalate(action, alert);
        break;
      
      case 'auto-remediation':
        await this.autoRemediate(action, alert);
        break;
    }
  }

  private async sendNotification(
    action: AlertAction,
    alert: Alert
  ): Promise<void> {
    const notification: Notification = {
      channels: action.config.channels,
      recipients: await this.resolveRecipients(action.config.recipients),
      template: action.config.template,
      data: {
        alert,
        severity: alert.severity,
        timestamp: alert.triggeredAt,
        details: this.formatAlertDetails(alert)
      }
    };

    await this.notificationManager.send(notification);
  }
}

// ì•Œë¦¼ ê·œì¹™ ì—”ì§„
export class AlertRuleEngine {
  private rules: Map<string, AlertRule> = new Map();
  private ruleIndex: RuleIndex;
  private compiler: RuleCompiler;

  constructor(config: RuleEngineConfig) {
    this.ruleIndex = new RuleIndex();
    this.compiler = new RuleCompiler();
    
    this.loadRules(config.rules);
  }

  async findApplicableRules(event: OrchestrationEvent): Promise<AlertRule[]> {
    // ì´ë²¤íŠ¸ íƒ€ì… ê¸°ë°˜ ì¸ë±ìŠ¤ ê²€ìƒ‰
    const candidateRules = await this.ruleIndex.findByEventType(event.type);

    // í™œì„±í™”ëœ ê·œì¹™ë§Œ í•„í„°ë§
    return candidateRules.filter(rule => rule.enabled);
  }

  async addRule(rule: AlertRule): Promise<void> {
    // ê·œì¹™ ê²€ì¦
    const validation = await this.validateRule(rule);
    if (!validation.valid) {
      throw new ValidationError(validation.errors);
    }

    // ê·œì¹™ ì»´íŒŒì¼
    const compiled = await this.compiler.compile(rule);

    // ì €ì¥
    this.rules.set(rule.id, compiled);
    
    // ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
    await this.ruleIndex.index(compiled);
  }

  async updateRule(ruleId: string, updates: Partial<AlertRule>): Promise<void> {
    const existing = this.rules.get(ruleId);
    if (!existing) {
      throw new Error(`Rule ${ruleId} not found`);
    }

    const updated = { ...existing, ...updates };
    await this.addRule(updated);
  }

  async deleteRule(ruleId: string): Promise<void> {
    this.rules.delete(ruleId);
    await this.ruleIndex.remove(ruleId);
  }

  private async validateRule(rule: AlertRule): Promise<ValidationResult> {
    const errors: string[] = [];

    // í•„ìˆ˜ í•„ë“œ ê²€ì¦
    if (!rule.name) {
      errors.push('Rule name is required');
    }

    if (rule.conditions.length === 0) {
      errors.push('At least one condition is required');
    }

    if (rule.actions.length === 0) {
      errors.push('At least one action is required');
    }

    // ì¡°ê±´ ê²€ì¦
    for (const condition of rule.conditions) {
      const conditionErrors = await this.validateCondition(condition);
      errors.push(...conditionErrors);
    }

    return {
      valid: errors.length === 0,
      errors
    };
  }
}

// ì•Œë¦¼ ê´€ë¦¬ì
export class NotificationManager {
  private channels: Map<string, NotificationChannel>;
  private templateEngine: TemplateEngine;
  private rateLimiter: RateLimiter;

  constructor(config: NotificationConfig) {
    this.channels = this.initializeChannels(config.channels);
    this.templateEngine = new TemplateEngine(config.templates);
    this.rateLimiter = new RateLimiter(config.rateLimit);
  }

  private initializeChannels(
    channelConfigs: ChannelConfig[]
  ): Map<string, NotificationChannel> {
    const channels = new Map();

    for (const config of channelConfigs) {
      switch (config.type) {
        case 'email':
          channels.set(config.name, new EmailChannel(config));
          break;
        
        case 'slack':
          channels.set(config.name, new SlackChannel(config));
          break;
        
        case 'webhook':
          channels.set(config.name, new WebhookChannel(config));
          break;
        
        case 'sms':
          channels.set(config.name, new SMSChannel(config));
          break;
        
        case 'pagerduty':
          channels.set(config.name, new PagerDutyChannel(config));
          break;
      }
    }

    return channels;
  }

  async send(notification: Notification): Promise<void> {
    // ì†ë„ ì œí•œ í™•ì¸
    const allowed = await this.rateLimiter.allow(
      notification.recipients.join(',')
    );

    if (!allowed) {
      logger.warn('Notification rate limited', { notification });
      return;
    }

    // í…œí”Œë¦¿ ë Œë”ë§
    const content = await this.templateEngine.render(
      notification.template,
      notification.data
    );

    // ê° ì±„ë„ë¡œ ë°œì†¡
    const promises = notification.channels.map(channelName => {
      const channel = this.channels.get(channelName);
      
      if (!channel) {
        logger.error(`Channel ${channelName} not found`);
        return Promise.resolve();
      }

      return channel.send({
        recipients: notification.recipients,
        content,
        metadata: notification.data
      });
    });

    await Promise.allSettled(promises);
  }
}

// ì´ë©”ì¼ ì±„ë„
export class EmailChannel implements NotificationChannel {
  private transporter: EmailTransporter;

  constructor(config: EmailChannelConfig) {
    this.transporter = createTransporter(config);
  }

  async send(message: ChannelMessage): Promise<void> {
    const emailOptions = {
      to: message.recipients,
      subject: message.content.subject,
      html: message.content.body,
      attachments: message.content.attachments
    };

    await this.transporter.sendMail(emailOptions);
  }
}

// Slack ì±„ë„
export class SlackChannel implements NotificationChannel {
  private client: SlackWebClient;

  constructor(config: SlackChannelConfig) {
    this.client = new SlackWebClient(config.token);
  }

  async send(message: ChannelMessage): Promise<void> {
    for (const recipient of message.recipients) {
      await this.client.chat.postMessage({
        channel: recipient,
        text: message.content.text,
        blocks: this.createBlocks(message.content),
        attachments: message.content.attachments
      });
    }
  }

  private createBlocks(content: NotificationContent): any[] {
    const blocks = [];

    // í—¤ë” ë¸”ë¡
    if (content.title) {
      blocks.push({
        type: 'header',
        text: {
          type: 'plain_text',
          text: content.title
        }
      });
    }

    // ë³¸ë¬¸ ë¸”ë¡
    blocks.push({
      type: 'section',
      text: {
        type: 'mrkdwn',
        text: content.body
      }
    });

    // í•„ë“œ ë¸”ë¡
    if (content.fields) {
      blocks.push({
        type: 'section',
        fields: Object.entries(content.fields).map(([key, value]) => ({
          type: 'mrkdwn',
          text: `*${key}:* ${value}`
        }))
      });
    }

    // ì•¡ì…˜ ë¸”ë¡
    if (content.actions) {
      blocks.push({
        type: 'actions',
        elements: content.actions.map(action => ({
          type: 'button',
          text: {
            type: 'plain_text',
            text: action.label
          },
          url: action.url,
          style: action.style
        }))
      });
    }

    return blocks;
  }
}

// ì•Œë¦¼ ì¤‘ë³µ ì œê±°
export class AlertDeduplicator {
  private cache: LRUCache<string, Date>;
  private fingerprinter: AlertFingerprinter;

  constructor() {
    this.cache = new LRUCache({ max: 10000 });
    this.fingerprinter = new AlertFingerprinter();
  }

  async isDuplicate(rule: AlertRule, event: OrchestrationEvent): Promise<boolean> {
    const fingerprint = await this.fingerprinter.generate(rule, event);
    const lastSeen = this.cache.get(fingerprint);

    if (!lastSeen) {
      this.cache.set(fingerprint, new Date());
      return false;
    }

    const timeSinceLastSeen = Date.now() - lastSeen.getTime();
    const deduplicationWindow = rule.deduplication?.window || 300000; // 5ë¶„

    return timeSinceLastSeen < deduplicationWindow;
  }

  async setCooldown(rule: AlertRule, duration: number): Promise<void> {
    const key = `cooldown:${rule.id}`;
    this.cache.set(key, new Date(), { ttl: duration });
  }
}

// ì—ìŠ¤ì»¬ë ˆì´ì…˜ ê´€ë¦¬
export class EscalationManager {
  private policies: Map<string, EscalationPolicy>;
  private escalationTracker: EscalationTracker;

  async escalate(alert: Alert, policy: EscalationPolicy): Promise<void> {
    const level = await this.escalationTracker.getCurrentLevel(alert.id);
    const nextLevel = level + 1;

    if (nextLevel >= policy.levels.length) {
      logger.warn('Max escalation level reached', { alert, level });
      return;
    }

    const escalationLevel = policy.levels[nextLevel];

    // ë‹¤ìŒ ë ˆë²¨ ë‹´ë‹¹ìì—ê²Œ ì•Œë¦¼
    await this.notifyLevel(alert, escalationLevel);

    // ì—ìŠ¤ì»¬ë ˆì´ì…˜ ê¸°ë¡
    await this.escalationTracker.recordEscalation(alert.id, nextLevel);

    // ë‹¤ìŒ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì˜ˆì•½
    if (escalationLevel.timeout) {
      setTimeout(() => {
        this.checkAndEscalate(alert, policy);
      }, escalationLevel.timeout);
    }
  }

  private async notifyLevel(
    alert: Alert,
    level: EscalationLevel
  ): Promise<void> {
    const notification = {
      channels: level.channels,
      recipients: level.recipients,
      template: 'escalation',
      data: {
        alert,
        level: level.name,
        priority: level.priority
      }
    };

    await this.notificationManager.send(notification);
  }
}

// ìë™ ë³µêµ¬
export class AutoRemediator {
  private remediationScripts: Map<string, RemediationScript>;
  private executor: ScriptExecutor;

  async remediate(alert: Alert, action: RemediationAction): Promise<void> {
    const script = this.remediationScripts.get(action.scriptId);
    
    if (!script) {
      throw new Error(`Remediation script ${action.scriptId} not found`);
    }

    // ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    const context = {
      alert,
      parameters: action.parameters,
      environment: await this.getEnvironment()
    };

    // ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    const result = await this.executor.execute(script, context);

    // ê²°ê³¼ ê¸°ë¡
    await this.recordRemediation({
      alertId: alert.id,
      scriptId: script.id,
      executedAt: new Date(),
      result
    });

    // ì„±ê³µ ì‹œ ì•Œë¦¼ í•´ì œ
    if (result.success) {
      await this.resolveAlert(alert.id);
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ê·œì¹™ ê¸°ë°˜ ì•Œë¦¼ ì—”ì§„
- [ ] ë‹¤ì¤‘ ì±„ë„ ì•Œë¦¼ ì§€ì›
- [ ] ì•Œë¦¼ ì¤‘ë³µ ì œê±°
- [ ] ì—ìŠ¤ì»¬ë ˆì´ì…˜ ë° ìë™ ë³µêµ¬

#### SubTask 5.10.4: ë¡œê·¸ ì§‘ê³„ ë° ë¶„ì„
**ë‹´ë‹¹ì**: ë°ì´í„° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/monitoring/log_aggregation.ts
export interface LogEntry {
  timestamp: Date;
  level: LogLevel;
  source: string;
  correlationId?: string;
  workflowId?: string;
  taskId?: string;
  message: string;
  metadata?: Record<string, any>;
  stackTrace?: string;
}

export class LogAggregationSystem {
  private collectors: Map<string, LogCollector>;
  private pipeline: LogPipeline;
  private storage: LogStorage;
  private analyzer: LogAnalyzer;

  constructor(config: LogAggregationConfig) {
    this.collectors = this.initializeCollectors(config.sources);
    this.pipeline = new LogPipeline(config.pipeline);
    this.storage = new LogStorage(config.storage);
    this.analyzer = new LogAnalyzer();
  }

  private initializeCollectors(
    sources: LogSourceConfig[]
  ): Map<string, LogCollector> {
    const collectors = new Map();

    for (const source of sources) {
      switch (source.type) {
        case 'file':
          collectors.set(source.name, new FileLogCollector(source));
          break;
        
        case 'syslog':
          collectors.set(source.name, new SyslogCollector(source));
          break;
        
        case 'cloudwatch':
          collectors.set(source.name, new CloudWatchCollector(source));
          break;
        
        case 'kubernetes':
          collectors.set(source.name, new KubernetesLogCollector(source));
          break;
        
        case 'application':
          collectors.set(source.name, new ApplicationLogCollector(source));
          break;
      }
    }

    return collectors;
  }

  async start(): Promise<void> {
    // ê° ìˆ˜ì§‘ê¸° ì‹œì‘
    for (const [name, collector] of this.collectors) {
      await collector.start();
      
      // ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
      collector.on('log', async (log) => {
        await this.processLog(log);
      });

      collector.on('error', (error) => {
        logger.error(`Collector ${name} error:`, error);
      });
    }

    // íŒŒì´í”„ë¼ì¸ ì‹œì‘
    await this.pipeline.start();
  }

  private async processLog(log: LogEntry): Promise<void> {
    try {
      // íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
      const processed = await this.pipeline.process(log);

      // ì €ì¥
      await this.storage.store(processed);

      // ì‹¤ì‹œê°„ ë¶„ì„
      await this.analyzer.analyze(processed);

    } catch (error) {
      logger.error('Log processing failed', { log, error });
    }
  }

  async query(params: LogQueryParams): Promise<LogQueryResult> {
    // ì¿¼ë¦¬ ìµœì í™”
    const optimized = await this.optimizeQuery(params);

    // ì‹¤í–‰
    const results = await this.storage.query(optimized);

    // ì§‘ê³„
    const aggregations = params.aggregations 
      ? await this.aggregate(results, params.aggregations)
      : undefined;

    return {
      logs: results,
      total: await this.storage.count(optimized),
      aggregations
    };
  }
}

// ë¡œê·¸ íŒŒì´í”„ë¼ì¸
export class LogPipeline {
  private stages: PipelineStage[];
  private errorHandler: ErrorHandler;

  constructor(config: PipelineConfig) {
    this.stages = this.createStages(config.stages);
    this.errorHandler = new ErrorHandler(config.errorHandling);
  }

  private createStages(stageConfigs: StageConfig[]): PipelineStage[] {
    return stageConfigs.map(config => {
      switch (config.type) {
        case 'parser':
          return new ParserStage(config);
        case 'filter':
          return new FilterStage(config);
        case 'enricher':
          return new EnricherStage(config);
        case 'transformer':
          return new TransformerStage(config);
        case 'aggregator':
          return new AggregatorStage(config);
        default:
          throw new Error(`Unknown stage type: ${config.type}`);
      }
    });
  }

  async process(log: LogEntry): Promise<LogEntry> {
    let current = log;

    for (const stage of this.stages) {
      try {
        current = await stage.process(current);
        
        if (!current) {
          // í•„í„°ë§ëœ ê²½ìš°
          return null;
        }
      } catch (error) {
        current = await this.errorHandler.handle(current, error, stage);
      }
    }

    return current;
  }
}

// ë¡œê·¸ íŒŒì„œ ìŠ¤í…Œì´ì§€
export class ParserStage implements PipelineStage {
  private parsers: Map<string, LogParser>;

  constructor(config: ParserStageConfig) {
    this.parsers = new Map();
    
    // íŒŒì„œ ë“±ë¡
    this.parsers.set('json', new JSONParser());
    this.parsers.set('regex', new RegexParser(config.patterns));
    this.parsers.set('grok', new GrokParser(config.grokPatterns));
    this.parsers.set('kv', new KeyValueParser());
  }

  async process(log: LogEntry): Promise<LogEntry> {
    // ìë™ íŒŒì„œ ì„ íƒ
    const parser = this.selectParser(log);
    
    if (!parser) {
      return log;
    }

    // íŒŒì‹±
    const parsed = await parser.parse(log.message);
    
    // ë©”íƒ€ë°ì´í„° ë³‘í•©
    return {
      ...log,
      metadata: {
        ...log.metadata,
        ...parsed
      }
    };
  }

  private selectParser(log: LogEntry): LogParser | null {
    // JSON ê°ì§€
    if (log.message.trim().startsWith('{')) {
      return this.parsers.get('json');
    }

    // í‚¤-ê°’ ìŒ ê°ì§€
    if (log.message.includes('=')) {
      return this.parsers.get('kv');
    }

    // ê¸°ë³¸ ì •ê·œì‹ íŒŒì„œ
    return this.parsers.get('regex');
  }
}

// ë¡œê·¸ ë³´ê°• ìŠ¤í…Œì´ì§€
export class EnricherStage implements PipelineStage {
  private enrichers: Enricher[];

  constructor(config: EnricherStageConfig) {
    this.enrichers = [
      new GeoIPEnricher(),
      new UserAgentEnricher(),
      new HostEnricher(),
      new TraceEnricher(),
      new MetadataEnricher(config.metadata)
    ];
  }

  async process(log: LogEntry): Promise<LogEntry> {
    let enriched = log;

    for (const enricher of this.enrichers) {
      enriched = await enricher.enrich(enriched);
    }

    return enriched;
  }
}

// ë¡œê·¸ ì €ì¥ì†Œ
export class LogStorage {
  private elasticsearch: ElasticsearchClient;
  private s3: S3Client;
  private retentionManager: RetentionManager;

  constructor(config: StorageConfig) {
    this.elasticsearch = new ElasticsearchClient(config.elasticsearch);
    this.s3 = new S3Client(config.s3);
    this.retentionManager = new RetentionManager(config.retention);
  }

  async store(log: LogEntry): Promise<void> {
    // ì¸ë±ìŠ¤ ì´ë¦„ ìƒì„±
    const indexName = this.getIndexName(log);

    // Elasticsearchì— ì €ì¥
    await this.elasticsearch.index({
      index: indexName,
      body: log,
      pipeline: 'log-processing'
    });

    // ì¥ê¸° ë³´ê´€ì´ í•„ìš”í•œ ê²½ìš° S3ì—ë„ ì €ì¥
    if (this.shouldArchive(log)) {
      await this.archiveToS3(log);
    }
  }

  private getIndexName(log: LogEntry): string {
    const date = log.timestamp.toISOString().split('T')[0];
    const prefix = log.workflowId ? 'workflow-logs' : 'application-logs';
    return `${prefix}-${date}`;
  }

  async query(params: LogQueryParams): Promise<LogEntry[]> {
    const query = this.buildQuery(params);

    const response = await this.elasticsearch.search({
      index: params.index || 'logs-*',
      body: {
        query,
        sort: params.sort || [{ timestamp: 'desc' }],
        size: params.size || 100,
        from: params.from || 0,
        _source: params.fields
      }
    });

    return response.hits.hits.map(hit => hit._source as LogEntry);
  }

  private buildQuery(params: LogQueryParams): any {
    const must = [];
    const filter = [];

    // ì‹œê°„ ë²”ìœ„
    if (params.startTime || params.endTime) {
      filter.push({
        range: {
          timestamp: {
            gte: params.startTime?.toISOString(),
            lte: params.endTime?.toISOString()
          }
        }
      });
    }

    // í…ìŠ¤íŠ¸ ê²€ìƒ‰
    if (params.search) {
      must.push({
        multi_match: {
          query: params.search,
          fields: ['message', 'metadata.*'],
          type: 'phrase_prefix'
        }
      });
    }

    // í•„í„°
    if (params.filters) {
      for (const [field, value] of Object.entries(params.filters)) {
        filter.push({ term: { [field]: value } });
      }
    }

    return {
      bool: {
        must,
        filter
      }
    };
  }
}

// ë¡œê·¸ ë¶„ì„ê¸°
export class LogAnalyzer {
  private patternMiner: PatternMiner;
  private anomalyDetector: LogAnomalyDetector;
  private errorAnalyzer: ErrorAnalyzer;
  private performanceAnalyzer: LogPerformanceAnalyzer;

  async analyze(log: LogEntry): Promise<void> {
    // íŒ¨í„´ ë§ˆì´ë‹
    await this.patternMiner.process(log);

    // ì´ìƒ ê°ì§€
    const anomaly = await this.anomalyDetector.detect(log);
    if (anomaly) {
      await this.handleAnomaly(anomaly);
    }

    // ì—ëŸ¬ ë¶„ì„
    if (log.level === 'error' || log.level === 'fatal') {
      await this.errorAnalyzer.analyze(log);
    }

    // ì„±ëŠ¥ ë¶„ì„
    if (this.isPerformanceRelated(log)) {
      await this.performanceAnalyzer.analyze(log);
    }
  }

  private isPerformanceRelated(log: LogEntry): boolean {
    const keywords = ['duration', 'latency', 'response time', 'slow'];
    return keywords.some(keyword => 
      log.message.toLowerCase().includes(keyword)
    );
  }
}

// íŒ¨í„´ ë§ˆì´ë‹
export class PatternMiner {
  private patterns: Map<string, LogPattern>;
  private clustering: LogClustering;

  async process(log: LogEntry): Promise<void> {
    // ë¡œê·¸ ì •ê·œí™”
    const normalized = this.normalize(log.message);

    // íŒ¨í„´ ë§¤ì¹­
    let matched = false;
    for (const [id, pattern] of this.patterns) {
      if (pattern.matches(normalized)) {
        await this.updatePattern(pattern, log);
        matched = true;
        break;
      }
    }

    // ìƒˆ íŒ¨í„´ ë°œê²¬
    if (!matched) {
      await this.discoverNewPattern(log, normalized);
    }
  }

  private normalize(message: string): string {
    // ìˆ«ì, ë‚ ì§œ, ID ë“±ì„ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ì¹˜í™˜
    return message
      .replace(/\b\d+\b/g, '<NUM>')
      .replace(/\b[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\b/gi, '<UUID>')
      .replace(/\b\d{4}-\d{2}-\d{2}\b/g, '<DATE>')
      .replace(/\b\d{2}:\d{2}:\d{2}\b/g, '<TIME>')
      .replace(/\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b/g, '<IP>');
  }

  private async discoverNewPattern(
    log: LogEntry,
    normalized: string
  ): Promise<void> {
    // í´ëŸ¬ìŠ¤í„°ë§ì„ í†µí•œ íŒ¨í„´ ë°œê²¬
    const cluster = await this.clustering.assignCluster(normalized);

    if (cluster.size > 10) {
      // ì¶©ë¶„í•œ ìƒ˜í”Œì´ ëª¨ì´ë©´ íŒ¨í„´ìœ¼ë¡œ ë“±ë¡
      const pattern = new LogPattern({
        id: uuid(),
        template: this.extractTemplate(cluster),
        frequency: cluster.size,
        firstSeen: new Date(),
        lastSeen: new Date()
      });

      this.patterns.set(pattern.id, pattern);
    }
  }
}

// ë¡œê·¸ ì‹œê°í™” ë°ì´í„° ìƒì„±
export class LogVisualizationGenerator {
  async generateDashboardData(
    logs: LogEntry[],
    timeRange: TimeRange
  ): Promise<DashboardData> {
    return {
      timeSeries: this.generateTimeSeries(logs, timeRange),
      logLevelDistribution: this.calculateLogLevelDistribution(logs),
      topErrors: this.findTopErrors(logs),
      errorRate: this.calculateErrorRate(logs),
      sources: this.analyzeSources(logs),
      patterns: await this.extractPatterns(logs)
    };
  }

  private generateTimeSeries(
    logs: LogEntry[],
    timeRange: TimeRange
  ): TimeSeriesData {
    const buckets = this.createTimeBuckets(timeRange);
    const series: Record<string, number[]> = {};

    // ë¡œê·¸ ë ˆë²¨ë³„ ì‹œê³„ì—´
    for (const level of ['debug', 'info', 'warn', 'error', 'fatal']) {
      series[level] = new Array(buckets.length).fill(0);
    }

    // ë¡œê·¸ ë¶„ë¥˜
    for (const log of logs) {
      const bucketIndex = this.findBucketIndex(log.timestamp, buckets);
      if (bucketIndex >= 0) {
        series[log.level][bucketIndex]++;
      }
    }

    return {
      timestamps: buckets.map(b => b.start),
      series
    };
  }

  private calculateLogLevelDistribution(
    logs: LogEntry[]
  ): Record<string, number> {
    const distribution: Record<string, number> = {};

    for (const log of logs) {
      distribution[log.level] = (distribution[log.level] || 0) + 1;
    }

    return distribution;
  }

  private findTopErrors(logs: LogEntry[], limit: number = 10): ErrorSummary[] {
    const errorGroups = new Map<string, ErrorSummary>();

    const errors = logs.filter(log => 
      log.level === 'error' || log.level === 'fatal'
    );

    for (const error of errors) {
      const fingerprint = this.generateErrorFingerprint(error);
      
      if (!errorGroups.has(fingerprint)) {
        errorGroups.set(fingerprint, {
          message: error.message,
          count: 0,
          firstSeen: error.timestamp,
          lastSeen: error.timestamp,
          stackTrace: error.stackTrace
        });
      }

      const group = errorGroups.get(fingerprint)!;
      group.count++;
      group.lastSeen = error.timestamp;
    }

    // ìƒìœ„ Nê°œ ë°˜í™˜
    return Array.from(errorGroups.values())
      .sort((a, b) => b.count - a.count)
      .slice(0, limit);
  }

  private generateErrorFingerprint(log: LogEntry): string {
    // ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ë‚˜ ë©”ì‹œì§€ íŒ¨í„´ìœ¼ë¡œ fingerprint ìƒì„±
    if (log.stackTrace) {
      const lines = log.stackTrace.split('\n');
      const relevantLines = lines.slice(0, 3).join('\n');
      return crypto.createHash('md5').update(relevantLines).digest('hex');
    }

    // ë©”ì‹œì§€ ì •ê·œí™”
    const normalized = log.message
      .replace(/\b\d+\b/g, 'N')
      .replace(/\b[0-9a-f-]{36}\b/gi, 'ID');

    return crypto.createHash('md5').update(normalized).digest('hex');
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì¤‘ ì†ŒìŠ¤ ë¡œê·¸ ìˆ˜ì§‘
- [ ] ë¡œê·¸ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
- [ ] íŒ¨í„´ ë§ˆì´ë‹ ë° ë¶„ì„
- [ ] ë¡œê·¸ ì‹œê°í™” ë°ì´í„° ìƒì„±

### Task 5.11: ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë° ë¶„ì„ ì‹œìŠ¤í…œ

#### SubTask 5.11.1: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸
**ë‹´ë‹¹ì**: ë°ì´í„° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/metrics/collection_pipeline.ts
export interface Metric {
  name: string;
  value: number;
  timestamp: Date;
  tags: Record<string, string>;
  type: MetricType;
  unit?: string;
  metadata?: Record<string, any>;
}

export enum MetricType {
  COUNTER = 'counter',
  GAUGE = 'gauge',
  HISTOGRAM = 'histogram',
  SUMMARY = 'summary'
}

export class MetricsCollectionPipeline {
  private collectors: Map<string, MetricCollector>;
  private processors: MetricProcessor[];
  private exporters: Map<string, MetricExporter>;
  private aggregator: MetricAggregator;
  private buffer: MetricBuffer;

  constructor(config: PipelineConfig) {
    this.collectors = this.initializeCollectors(config.collectors);
    this.processors = this.initializeProcessors(config.processors);
    this.exporters = this.initializeExporters(config.exporters);
    this.aggregator = new MetricAggregator(config.aggregation);
    this.buffer = new MetricBuffer(config.buffer);
  }

  private initializeCollectors(
    configs: CollectorConfig[]
  ): Map<string, MetricCollector> {
    const collectors = new Map();

    for (const config of configs) {
      switch (config.type) {
        case 'system':
          collectors.set(config.name, new SystemMetricsCollector(config));
          break;
        
        case 'application':
          collectors.set(config.name, new ApplicationMetricsCollector(config));
          break;
        
        case 'custom':
          collectors.set(config.name, new CustomMetricsCollector(config));
          break;
        
        case 'prometheus':
          collectors.set(config.name, new PrometheusCollector(config));
          break;
        
        case 'statsd':
          collectors.set(config.name, new StatsDCollector(config));
          break;
      }
    }

    return collectors;
  }

  async start(): Promise<void> {
    // ì»¬ë ‰í„° ì‹œì‘
    for (const [name, collector] of this.collectors) {
      await collector.start();
      
      collector.on('metrics', async (metrics) => {
        await this.processMetrics(metrics);
      });

      collector.on('error', (error) => {
        logger.error(`Collector ${name} error:`, error);
      });
    }

    // ì£¼ê¸°ì  í”ŒëŸ¬ì‹œ
    this.startPeriodicFlush();
  }

  private async processMetrics(metrics: Metric[]): Promise<void> {
    // 1. ë²„í¼ì— ì¶”ê°€
    await this.buffer.add(metrics);

    // 2. í”„ë¡œì„¸ì‹±
    let processed = metrics;
    for (const processor of this.processors) {
      processed = await processor.process(processed);
    }

    // 3. ì§‘ê³„
    const aggregated = await this.aggregator.aggregate(processed);

    // 4. ë‚´ë³´ë‚´ê¸°
    await this.export(aggregated);
  }

  private async export(metrics: Metric[]): Promise<void> {
    const promises = [];

    for (const [name, exporter] of this.exporters) {
      promises.push(
        exporter.export(metrics).catch(error => {
          logger.error(`Exporter ${name} failed:`, error);
        })
      );
    }

    await Promise.all(promises);
  }

  private startPeriodicFlush(): void {
    setInterval(async () => {
      const buffered = await this.buffer.flush();
      if (buffered.length > 0) {
        await this.processMetrics(buffered);
      }
    }, 10000); // 10ì´ˆë§ˆë‹¤
  }
}

// ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
export class SystemMetricsCollector extends MetricCollector {
  private osUtils: OSUtils;
  private processMonitor: ProcessMonitor;

  constructor(config: SystemCollectorConfig) {
    super(config);
    this.osUtils = new OSUtils();
    this.processMonitor = new ProcessMonitor();
  }

  async collect(): Promise<Metric[]> {
    const metrics: Metric[] = [];
    const timestamp = new Date();

    // CPU ë©”íŠ¸ë¦­
    const cpuUsage = await this.osUtils.getCPUUsage();
    metrics.push({
      name: 'system.cpu.usage',
      value: cpuUsage.total,
      timestamp,
      tags: { cpu: 'all' },
      type: MetricType.GAUGE,
      unit: 'percent'
    });

    // ì½”ì–´ë³„ CPU
    cpuUsage.cores.forEach((usage, index) => {
      metrics.push({
        name: 'system.cpu.core.usage',
        value: usage,
        timestamp,
        tags: { core: index.toString() },
        type: MetricType.GAUGE,
        unit: 'percent'
      });
    });

    // ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­
    const memory = await this.osUtils.getMemoryInfo();
    metrics.push(
      {
        name: 'system.memory.total',
        value: memory.total,
        timestamp,
        tags: {},
        type: MetricType.GAUGE,
        unit: 'bytes'
      },
      {
        name: 'system.memory.used',
        value: memory.used,
        timestamp,
        tags: {},
        type: MetricType.GAUGE,
        unit: 'bytes'
      },
      {
        name: 'system.memory.free',
        value: memory.free,
        timestamp,
        tags: {},
        type: MetricType.GAUGE,
        unit: 'bytes'
      },
      {
        name: 'system.memory.usage',
        value: (memory.used / memory.total) * 100,
        timestamp,
        tags: {},
        type: MetricType.GAUGE,
        unit: 'percent'
      }
    );

    // ë””ìŠ¤í¬ ë©”íŠ¸ë¦­
    const disks = await this.osUtils.getDiskInfo();
    for (const disk of disks) {
      const tags = { device: disk.device, mount: disk.mount };
      
      metrics.push(
        {
          name: 'system.disk.total',
          value: disk.total,
          timestamp,
          tags,
          type: MetricType.GAUGE,
          unit: 'bytes'
        },
        {
          name: 'system.disk.used',
          value: disk.used,
          timestamp,
          tags,
          type: MetricType.GAUGE,
          unit: 'bytes'
        },
        {
          name: 'system.disk.usage',
          value: (disk.used / disk.total) * 100,
          timestamp,
          tags,
          type: MetricType.GAUGE,
          unit: 'percent'
        }
      );
    }

    // ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­
    const network = await this.osUtils.getNetworkInfo();
    for (const iface of network.interfaces) {
      const tags = { interface: iface.name };
      
      metrics.push(
        {
          name: 'system.network.rx.bytes',
          value: iface.rxBytes,
          timestamp,
          tags,
          type: MetricType.COUNTER,
          unit: 'bytes'
        },
        {
          name: 'system.network.tx.bytes',
          value: iface.txBytes,
          timestamp,
          tags,
          type: MetricType.COUNTER,
          unit: 'bytes'
        },
        {
          name: 'system.network.rx.packets',
          value: iface.rxPackets,
          timestamp,
          tags,
          type: MetricType.COUNTER,
          unit: 'packets'
        },
        {
          name: 'system.network.tx.packets',
          value: iface.txPackets,
          timestamp,
          tags,
          type: MetricType.COUNTER,
          unit: 'packets'
        }
      );
    }

    // í”„ë¡œì„¸ìŠ¤ ë©”íŠ¸ë¦­
    const processInfo = await this.processMonitor.getInfo();
    metrics.push(
      {
        name: 'process.cpu.usage',
        value: processInfo.cpuUsage,
        timestamp,
        tags: { pid: processInfo.pid.toString() },
        type: MetricType.GAUGE,
        unit: 'percent'
      },
      {
        name: 'process.memory.rss',
        value: processInfo.memoryRss,
        timestamp,
        tags: { pid: processInfo.pid.toString() },
        type: MetricType.GAUGE,
        unit: 'bytes'
      },
      {
        name: 'process.memory.heap.used',
        value: processInfo.heapUsed,
        timestamp,
        tags: { pid: processInfo.pid.toString() },
        type: MetricType.GAUGE,
        unit: 'bytes'
      },
      {
        name: 'process.memory.heap.total',
        value: processInfo.heapTotal,
        timestamp,
        tags: { pid: processInfo.pid.toString() },
        type: MetricType.GAUGE,
        unit: 'bytes'
      }
    );

    return metrics;
  }
}

// ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
export class ApplicationMetricsCollector extends MetricCollector {
  private metricsRegistry: MetricsRegistry;
  
  constructor(config: ApplicationCollectorConfig) {
    super(config);
    this.metricsRegistry = MetricsRegistry.getInstance();
  }

  async collect(): Promise<Metric[]> {
    const metrics: Metric[] = [];
    const timestamp = new Date();

    // ì›Œí¬í”Œë¡œìš° ë©”íŠ¸ë¦­
    const workflowMetrics = this.metricsRegistry.getWorkflowMetrics();
    
    metrics.push(
      {
        name: 'workflow.executions.total',
        value: workflowMetrics.totalExecutions,
        timestamp,
        tags: {},
        type: MetricType.COUNTER
      },
      {
        name: 'workflow.executions.active',
        value: workflowMetrics.activeExecutions,
        timestamp,
        tags: {},
        type: MetricType.GAUGE
      },
      {
        name: 'workflow.executions.success',
        value: workflowMetrics.successfulExecutions,
        timestamp,
        tags: {},
        type: MetricType.COUNTER
      },
      {
        name: 'workflow.executions.failed',
        value: workflowMetrics.failedExecutions,
        timestamp,
        tags: {},
        type: MetricType.COUNTER
      }
    );

    // íƒœìŠ¤í¬ ë©”íŠ¸ë¦­
    const taskMetrics = this.metricsRegistry.getTaskMetrics();
    
    for (const [taskType, metrics] of taskMetrics) {
      const tags = { task_type: taskType };
      
      metrics.push(
        {
          name: 'task.executions.total',
          value: metrics.total,
          timestamp,
          tags,
          type: MetricType.COUNTER
        },
        {
          name: 'task.duration.seconds',
          value: metrics.averageDuration,
          timestamp,
          tags,
          type: MetricType.HISTOGRAM,
          unit: 'seconds'
        },
        {
          name: 'task.success.rate',
          value: metrics.successRate,
          timestamp,
          tags,
          type: MetricType.GAUGE,
          unit: 'ratio'
        }
      );
    }

    // ë¦¬ì†ŒìŠ¤ ë©”íŠ¸ë¦­
    const resourceMetrics = this.metricsRegistry.getResourceMetrics();
    
    metrics.push(
      {
        name: 'resource.utilization',
        value: resourceMetrics.overallUtilization,
        timestamp,
        tags: {},
        type: MetricType.GAUGE,
        unit: 'percent'
      },
      {
        name: 'resource.allocations.active',
        value: resourceMetrics.activeAllocations,
        timestamp,
        tags: {},
        type: MetricType.GAUGE
      },
      {
        name: 'resource.queue.depth',
        value: resourceMetrics.queueDepth,
        timestamp,
        tags: {},
        type: MetricType.GAUGE
      }
    );

    // API ë©”íŠ¸ë¦­
    const apiMetrics = this.metricsRegistry.getAPIMetrics();
    
    for (const [endpoint, metrics] of apiMetrics) {
      const tags = { endpoint, method: metrics.method };
      
      metrics.push(
        {
          name: 'api.requests.total',
          value: metrics.totalRequests,
          timestamp,
          tags,
          type: MetricType.COUNTER
        },
        {
          name: 'api.requests.duration',
          value: metrics.averageDuration,
          timestamp,
          tags,
          type: MetricType.HISTOGRAM,
          unit: 'milliseconds'
        },
        {
          name: 'api.requests.errors',
          value: metrics.errorCount,
          timestamp,
          tags,
          type: MetricType.COUNTER
        }
      );
    }

    return metrics;
  }
}

// ë©”íŠ¸ë¦­ í”„ë¡œì„¸ì„œ
export abstract class MetricProcessor {
  abstract async process(metrics: Metric[]): Promise<Metric[]>;
}

// ë ˆì´íŠ¸ ê³„ì‚° í”„ë¡œì„¸ì„œ
export class RateProcessor extends MetricProcessor {
  private previousValues: Map<string, number> = new Map();

  async process(metrics: Metric[]): Promise<Metric[]> {
    const processed: Metric[] = [];

    for (const metric of metrics) {
      processed.push(metric);

      // ì¹´ìš´í„° íƒ€ì…ì¸ ê²½ìš° ë ˆì´íŠ¸ ê³„ì‚°
      if (metric.type === MetricType.COUNTER) {
        const key = this.getMetricKey(metric);
        const previousValue = this.previousValues.get(key);

        if (previousValue !== undefined) {
          const rate = (metric.value - previousValue) / 
                      (Date.now() - metric.timestamp.getTime()) * 1000;

          processed.push({
            name: `${metric.name}.rate`,
            value: rate,
            timestamp: metric.timestamp,
            tags: metric.tags,
            type: MetricType.GAUGE,
            unit: `${metric.unit || 'units'}/second`
          });
        }

        this.previousValues.set(key, metric.value);
      }
    }

    return processed;
  }

  private getMetricKey(metric: Metric): string {
    const tagStr = Object.entries(metric.tags)
      .sort(([a], [b]) => a.localeCompare(b))
      .map(([k, v]) => `${k}:${v}`)
      .join(',');
    
    return `${metric.name}:{${tagStr}}`;
  }
}

// íƒœê·¸ ë³´ê°• í”„ë¡œì„¸ì„œ
export class TagEnrichmentProcessor extends MetricProcessor {
  private enrichmentRules: EnrichmentRule[];

  constructor(rules: EnrichmentRule[]) {
    super();
    this.enrichmentRules = rules;
  }

  async process(metrics: Metric[]): Promise<Metric[]> {
    return Promise.all(metrics.map(async metric => {
      const enrichedTags = { ...metric.tags };

      for (const rule of this.enrichmentRules) {
        if (rule.matches(metric)) {
          Object.assign(enrichedTags, await rule.getTags(metric));
        }
      }

      return {
        ...metric,
        tags: enrichedTags
      };
    }));
  }
}

// ë©”íŠ¸ë¦­ ì§‘ê³„ê¸°
export class MetricAggregator {
  private windows: Map<string, AggregationWindow>;

  constructor(config: AggregationConfig) {
    this.windows = new Map();
    
    // ì§‘ê³„ ìœˆë„ìš° ìƒì„±
    for (const windowConfig of config.windows) {
      this.windows.set(
        windowConfig.name,
        new AggregationWindow(windowConfig)
      );
    }
  }

  async aggregate(metrics: Metric[]): Promise<Metric[]> {
    const aggregated: Metric[] = [...metrics];

    for (const metric of metrics) {
      // ê° ìœˆë„ìš°ì—ì„œ ì§‘ê³„
      for (const [name, window] of this.windows) {
        const agg = await window.aggregate(metric);
        
        if (agg) {
          aggregated.push(...agg);
        }
      }
    }

    return aggregated;
  }
}

// ì§‘ê³„ ìœˆë„ìš°
export class AggregationWindow {
  private buffer: Map<string, Metric[]> = new Map();
  private lastFlush: Date = new Date();

  constructor(private config: WindowConfig) {}

  async aggregate(metric: Metric): Promise<Metric[] | null> {
    const key = this.getAggregationKey(metric);
    
    if (!this.buffer.has(key)) {
      this.buffer.set(key, []);
    }

    this.buffer.get(key)!.push(metric);

    // ìœˆë„ìš° ë§Œë£Œ í™•ì¸
    if (this.shouldFlush()) {
      return this.flush();
    }

    return null;
  }

  private shouldFlush(): boolean {
    const elapsed = Date.now() - this.lastFlush.getTime();
    return elapsed >= this.config.duration;
  }

  private flush(): Metric[] {
    const aggregated: Metric[] = [];

    for (const [key, metrics] of this.buffer) {
      if (metrics.length === 0) continue;

      const values = metrics.map(m => m.value);
      const timestamp = new Date();
      const tags = metrics[0].tags;

      // ì§‘ê³„ í†µê³„ ê³„ì‚°
      aggregated.push(
        {
          name: `${metrics[0].name}.min`,
          value: Math.min(...values),
          timestamp,
          tags,
          type: MetricType.GAUGE,
          metadata: { window: this.config.name }
        },
        {
          name: `${metrics[0].name}.max`,
          value: Math.max(...values),
          timestamp,
          tags,
          type: MetricType.GAUGE,
          metadata: { window: this.config.name }
        },
        {
          name: `${metrics[0].name}.avg`,
          value: values.reduce((a, b) => a + b, 0) / values.length,
          timestamp,
          tags,
          type: MetricType.GAUGE,
          metadata: { window: this.config.name }
        },
        {
          name: `${metrics[0].name}.count`,
          value: values.length,
          timestamp,
          tags,
          type: MetricType.GAUGE,
          metadata: { window: this.config.name }
        }
      );

      // ë°±ë¶„ìœ„ìˆ˜
      const sorted = values.sort((a, b) => a - b);
      const percentiles = [50, 90, 95, 99];
      
      for (const p of percentiles) {
        const index = Math.ceil((p / 100) * sorted.length) - 1;
        aggregated.push({
          name: `${metrics[0].name}.p${p}`,
          value: sorted[index],
          timestamp,
          tags,
          type: MetricType.GAUGE,
          metadata: { window: this.config.name }
        });
      }
    }

    // ë²„í¼ ì´ˆê¸°í™”
    this.buffer.clear();
    this.lastFlush = new Date();

    return aggregated;
  }

  private getAggregationKey(metric: Metric): string {
    const tagStr = Object.entries(metric.tags)
      .filter(([k]) => this.config.groupBy.includes(k))
      .sort(([a], [b]) => a.localeCompare(b))
      .map(([k, v]) => `${k}:${v}`)
      .join(',');
    
    return `${metric.name}:{${tagStr}}`;
  }
}

// ë©”íŠ¸ë¦­ ë‚´ë³´ë‚´ê¸°
export abstract class MetricExporter {
  abstract async export(metrics: Metric[]): Promise<void>;
}

// Prometheus ë‚´ë³´ë‚´ê¸°
export class PrometheusExporter extends MetricExporter {
  private registry: PrometheusRegistry;

  constructor(config: PrometheusExporterConfig) {
    super();
    this.registry = new PrometheusRegistry();
  }

  async export(metrics: Metric[]): Promise<void> {
    for (const metric of metrics) {
      const promMetric = this.getOrCreateMetric(metric);
      
      switch (metric.type) {
        case MetricType.COUNTER:
          (promMetric as Counter).inc(metric.value);
          break;
        
        case MetricType.GAUGE:
          (promMetric as Gauge).set(metric.value);
          break;
        
        case MetricType.HISTOGRAM:
          (promMetric as Histogram).observe(metric.value);
          break;
        
        case MetricType.SUMMARY:
          (promMetric as Summary).observe(metric.value);
          break;
      }
    }
  }

  private getOrCreateMetric(metric: Metric): PrometheusMetric {
    const name = metric.name.replace(/\./g, '_');
    const labels = Object.keys(metric.tags);

    let promMetric = this.registry.getSingleMetric(name);

    if (!promMetric) {
      const config = {
        name,
        help: `${metric.name} (${metric.unit || 'units'})`,
        labelNames: labels
      };

      switch (metric.type) {
        case MetricType.COUNTER:
          promMetric = new Counter(config);
          break;
        
        case MetricType.GAUGE:
          promMetric = new Gauge(config);
          break;
        
        case MetricType.HISTOGRAM:
          promMetric = new Histogram({
            ...config,
            buckets: [0.1, 0.5, 1, 2, 5, 10, 30, 60, 120, 300]
          });
          break;
        
        case MetricType.SUMMARY:
          promMetric = new Summary({
            ...config,
            percentiles: [0.5, 0.9, 0.95, 0.99]
          });
          break;
      }

      this.registry.registerMetric(promMetric);
    }

    return promMetric;
  }

  getMetrics(): string {
    return this.registry.metrics();
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
- [ ] ë©”íŠ¸ë¦­ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
- [ ] ì§‘ê³„ ë° ìœˆë„ìš° ì²˜ë¦¬
- [ ] ë‹¤ì¤‘ ë‚´ë³´ë‚´ê¸° ì§€ì›

#### SubTask 5.11.2: ì‹œê³„ì—´ ë°ì´í„° ì €ì¥ì†Œ
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/metrics/timeseries_storage.ts
export interface TimeSeriesPoint {
  timestamp: Date;
  value: number;
  tags: Record<string, string>;
}

export interface TimeSeriesQuery {
  metric: string;
  start: Date;
  end: Date;
  tags?: Record<string, string>;
  aggregation?: AggregationFunction;
  groupBy?: string[];
  interval?: string;
  fill?: FillMethod;
}

export class TimeSeriesStorage {
  private influxDB: InfluxDBClient;
  private clickhouse: ClickHouseClient;
  private cache: TimeSeriesCache;
  private compactor: DataCompactor;

  constructor(config: TimeSeriesStorageConfig) {
    this.influxDB = new InfluxDBClient(config.influxdb);
    this.clickhouse = new ClickHouseClient(config.clickhouse);
    this.cache = new TimeSeriesCache(config.cache);
    this.compactor = new DataCompactor(config.compaction);
  }

  async write(
    metric: string,
    points: TimeSeriesPoint[]
  ): Promise<void> {
    // ìºì‹œì— ì“°ê¸°
    await this.cache.write(metric, points);

    // ë°°ì¹˜ ì“°ê¸°ë¥¼ ìœ„í•œ ë²„í¼ë§
    const batches = this.createBatches(points, 5000);

    for (const batch of batches) {
      await Promise.all([
        // InfluxDBì— ì“°ê¸° (ì‹¤ì‹œê°„ ì¿¼ë¦¬ìš©)
        this.writeToInfluxDB(metric, batch),
        
        // ClickHouseì— ì“°ê¸° (ì¥ê¸° ë³´ê´€ ë° ë¶„ì„ìš©)
        this.writeToClickHouse(metric, batch)
      ]);
    }
  }

  private async writeToInfluxDB(
    metric: string,
    points: TimeSeriesPoint[]
  ): Promise<void> {
    const writeApi = this.influxDB.getWriteApi();

    for (const point of points) {
      const influxPoint = new Point(metric)
        .timestamp(point.timestamp);

      // íƒœê·¸ ì¶”ê°€
      for (const [key, value] of Object.entries(point.tags)) {
        influxPoint.tag(key, value);
      }

      // ê°’ ì¶”ê°€
      influxPoint.floatField('value', point.value);

      writeApi.writePoint(influxPoint);
    }

    await writeApi.close();
  }

  private async writeToClickHouse(
    metric: string,
    points: TimeSeriesPoint[]
  ): Promise<void> {
    const rows = points.map(point => ({
      metric,
      timestamp: point.timestamp.toISOString(),
      value: point.value,
      tags: point.tags,
      date: point.timestamp.toISOString().split('T')[0]
    }));

    await this.clickhouse.insert({
      table: 'metrics',
      values: rows,
      format: 'JSONEachRow'
    });
  }

  async query(params: TimeSeriesQuery): Promise<TimeSeriesData> {
    // ìºì‹œ í™•ì¸
    const cached = await this.cache.get(params);
    if (cached) {
      return cached;
    }

    // ì¿¼ë¦¬ ìµœì í™”
    const optimized = this.optimizeQuery(params);

    // ì ì ˆí•œ ì €ì¥ì†Œ ì„ íƒ
    const data = await this.selectStorageAndQuery(optimized);

    // í›„ì²˜ë¦¬
    const processed = await this.postProcess(data, params);

    // ìºì‹œì— ì €ì¥
    await this.cache.set(params, processed);

    return processed;
  }

  private async selectStorageAndQuery(
    query: TimeSeriesQuery
  ): Promise<TimeSeriesData> {
    const timeRange = query.end.getTime() - query.start.getTime();
    const oneDay = 24 * 60 * 60 * 1000;

    if (timeRange <= oneDay) {
      // ìµœê·¼ ë°ì´í„°ëŠ” InfluxDBì—ì„œ
      return this.queryInfluxDB(query);
    } else if (timeRange <= 30 * oneDay) {
      // ì¤‘ê°„ ë²”ìœ„ëŠ” ë³‘ë ¬ ì¿¼ë¦¬
      const [influxData, clickhouseData] = await Promise.all([
        this.queryInfluxDB(query),
        this.queryClickHouse(query)
      ]);
      
      return this.mergeData(influxData, clickhouseData);
    } else {
      // ì¥ê¸° ë°ì´í„°ëŠ” ClickHouseì—ì„œ
      return this.queryClickHouse(query);
    }
  }

  private async queryInfluxDB(
    query: TimeSeriesQuery
  ): Promise<TimeSeriesData> {
    const fluxQuery = this.buildFluxQuery(query);
    const queryApi = this.influxDB.getQueryApi();
    const rows: any[] = [];

    await queryApi.collectRows(fluxQuery, (row) => {
      rows.push(row);
    });

    return this.transformInfluxData(rows, query);
  }

  private buildFluxQuery(query: TimeSeriesQuery): string {
    let flux = `
      from(bucket: "metrics")
        |> range(start: ${query.start.toISOString()}, stop: ${query.end.toISOString()})
        |> filter(fn: (r) => r._measurement == "${query.metric}")
    `;

    // íƒœê·¸ í•„í„°
    if (query.tags) {
      for (const [key, value] of Object.entries(query.tags)) {
        flux += `\n        |> filter(fn: (r) => r.${key} == "${value}")`;
      }
    }

    // ì§‘ê³„
    if (query.aggregation && query.interval) {
      flux += `\n        |> aggregateWindow(every: ${query.interval}, fn: ${query.aggregation})`;
    }

    // ê·¸ë£¹í™”
    if (query.groupBy) {
      flux += `\n        |> group(columns: [${query.groupBy.map(g => `"${g}"`).join(', ')}])`;
    }

    return flux;
  }

  private async queryClickHouse(
    query: TimeSeriesQuery
  ): Promise<TimeSeriesData> {
    const sql = this.buildClickHouseQuery(query);
    const result = await this.clickhouse.query({
      query: sql,
      format: 'JSONEachRow'
    });

    return this.transformClickHouseData(result.data, query);
  }

  private buildClickHouseQuery(query: TimeSeriesQuery): string {
    let sql = 'SELECT ';

    // ì‹œê°„ ë²„í‚·íŒ…
    if (query.interval) {
      sql += `toStartOfInterval(timestamp, INTERVAL ${query.interval}) as time, `;
    } else {
      sql += 'timestamp as time, ';
    }

    // ì§‘ê³„ í•¨ìˆ˜
    const aggFunc = query.aggregation || 'avg';
    sql += `${aggFunc}(value) as value`;

    // ê·¸ë£¹í™” ì»¬ëŸ¼
    if (query.groupBy) {
      sql += `, ${query.groupBy.map(g => `tags['${g}'] as ${g}`).join(', ')}`;
    }

    sql += `
      FROM metrics
      WHERE metric = '${query.metric}'
        AND timestamp >= '${query.start.toISOString()}'
        AND timestamp <= '${query.end.toISOString()}'
    `;

    // íƒœê·¸ í•„í„°
    if (query.tags) {
      for (const [key, value] of Object.entries(query.tags)) {
        sql += `\n        AND tags['${key}'] = '${value}'`;
      }
    }

    // GROUP BY
    if (query.interval || query.groupBy) {
      sql += '\n      GROUP BY time';
      if (query.groupBy) {
        sql += `, ${query.groupBy.join(', ')}`;
      }
    }

    sql += '\n      ORDER BY time ASC';

    return sql;
  }

  async downsample(
    metric: string,
    retention: RetentionPolicy
  ): Promise<void> {
    const rules = retention.downsamplingRules;

    for (const rule of rules) {
      await this.applyDownsamplingRule(metric, rule);
    }
  }

  private async applyDownsamplingRule(
    metric: string,
    rule: DownsamplingRule
  ): Promise<void> {
    const cutoffTime = new Date(Date.now() - rule.after);

    // ì›ë³¸ ë°ì´í„° ì¿¼ë¦¬
    const data = await this.query({
      metric,
      start: new Date(0),
      end: cutoffTime,
      interval: rule.interval,
      aggregation: rule.aggregation
    });

    // ë‹¤ìš´ìƒ˜í”Œëœ í…Œì´ë¸”ì— ì“°ê¸°
    const downsampledMetric = `${metric}_${rule.interval}`;
    await this.write(downsampledMetric, data.points);

    // ì›ë³¸ ë°ì´í„° ì‚­ì œ (ì„ íƒì )
    if (rule.deleteOriginal) {
      await this.deleteData(metric, new Date(0), cutoffTime);
    }
  }

  async compact(): Promise<CompactionResult> {
    return this.compactor.compact({
      tables: ['metrics'],
      strategy: 'time-based',
      settings: {
        chunkSize: '1d',
        compressionLevel: 9,
        deduplication: true
      }
    });
  }
}

// ì‹œê³„ì—´ ìºì‹œ
export class TimeSeriesCache {
  private redis: RedisClient;
  private memcached: MemcachedClient;
  private localCache: LRUCache<string, TimeSeriesData>;

  constructor(config: CacheConfig) {
    this.redis = new RedisClient(config.redis);
    this.memcached = new MemcachedClient(config.memcached);
    this.localCache = new LRUCache({ max: 1000 });
  }

  async get(query: TimeSeriesQuery): Promise<TimeSeriesData | null> {
    const key = this.generateCacheKey(query);

    // L1 ìºì‹œ (ë¡œì»¬)
    const local = this.localCache.get(key);
    if (local) return local;

    // L2 ìºì‹œ (Memcached)
    const memcached = await this.memcached.get(key);
    if (memcached) {
      this.localCache.set(key, memcached);
      return memcached;
    }

    // L3 ìºì‹œ (Redis)
    const redis = await this.redis.get(key);
    if (redis) {
      const data = JSON.parse(redis);
      this.localCache.set(key, data);
      await this.memcached.set(key, data, 300); // 5ë¶„
      return data;
    }

    return null;
  }

  async set(
    query: TimeSeriesQuery,
    data: TimeSeriesData
  ): Promise<void> {
    const key = this.generateCacheKey(query);
    const ttl = this.calculateTTL(query);

    // ëª¨ë“  ë ˆë²¨ì— ì €ì¥
    this.localCache.set(key, data);
    await this.memcached.set(key, data, ttl);
    await this.redis.setex(key, ttl, JSON.stringify(data));
  }

  private generateCacheKey(query: TimeSeriesQuery): string {
    const parts = [
      query.metric,
      query.start.getTime(),
      query.end.getTime(),
      query.aggregation || 'none',
      query.interval || 'none',
      JSON.stringify(query.tags || {}),
      (query.groupBy || []).join(',')
    ];

    return crypto
      .createHash('md5')
      .update(parts.join(':'))
      .digest('hex');
  }

  private calculateTTL(query: TimeSeriesQuery): number {
    const now = Date.now();
    const queryEnd = query.end.getTime();

    if (queryEnd < now - 86400000) { // 1ì¼ ì´ìƒ ê³¼ê±°
      return 3600; // 1ì‹œê°„
    } else if (queryEnd < now) { // ê³¼ê±° ë°ì´í„°
      return 300; // 5ë¶„
    } else { // ì‹¤ì‹œê°„ ë°ì´í„°
      return 60; // 1ë¶„
    }
  }
}

// ë°ì´í„° ì••ì¶•ê¸°
export class DataCompactor {
  private compressionEngine: CompressionEngine;
  
  constructor(config: CompactionConfig) {
    this.compressionEngine = new CompressionEngine(config.compression);
  }

  async compact(options: CompactionOptions): Promise<CompactionResult> {
    const result: CompactionResult = {
      tablesCompacted: [],
      spaceSaved: 0,
      duration: 0
    };

    const startTime = Date.now();

    for (const table of options.tables) {
      const tableResult = await this.compactTable(table, options);
      result.tablesCompacted.push(tableResult);
      result.spaceSaved += tableResult.spaceSaved;
    }

    result.duration = Date.now() - startTime;
    return result;
  }

  private async compactTable(
    table: string,
    options: CompactionOptions
  ): Promise<TableCompactionResult> {
    const originalSize = await this.getTableSize(table);

    // 1. ì¤‘ë³µ ì œê±°
    if (options.settings.deduplication) {
      await this.deduplicateData(table);
    }

    // 2. íŒŒí‹°ì…˜ ë³‘í•©
    await this.mergePartitions(table, options.settings.chunkSize);

    // 3. ì••ì¶•
    await this.compressData(table, options.settings.compressionLevel);

    const newSize = await this.getTableSize(table);

    return {
      table,
      originalSize,
      newSize,
      spaceSaved: originalSize - newSize,
      compressionRatio: newSize / originalSize
    };
  }

  private async deduplicateData(table: string): Promise<void> {
    // ClickHouseì˜ ReplacingMergeTree í™œìš©
    const sql = `
      OPTIMIZE TABLE ${table} 
      FINAL 
      DEDUPLICATE BY metric, timestamp, tags
    `;

    await this.clickhouse.query({ query: sql });
  }

  private async mergePartitions(
    table: string,
    chunkSize: string
  ): Promise<void> {
    const sql = `
      ALTER TABLE ${table}
      MODIFY SETTING 
        merge_max_block_size = ${this.parseChunkSize(chunkSize)}
    `;

    await this.clickhouse.query({ query: sql });

    // ê°•ì œ ë³‘í•© íŠ¸ë¦¬ê±°
    await this.clickhouse.query({
      query: `OPTIMIZE TABLE ${table} PARTITION tuple()`
    });
  }

  private async compressData(
    table: string,
    level: number
  ): Promise<void> {
    const codec = level > 7 ? 'ZSTD' : 'LZ4';
    
    const sql = `
      ALTER TABLE ${table}
      MODIFY COLUMN value 
      CODEC(${codec}(${level}))
    `;

    await this.clickhouse.query({ query: sql });
  }
}

// ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„
export class TimeSeriesAnalyzer {
  private statisticsCalculator: StatisticsCalculator;
  private anomalyDetector: TimeSeriesAnomalyDetector;
  private forecaster: TimeSeriesForecaster;

  async analyze(
    data: TimeSeriesData,
    options: AnalysisOptions = {}
  ): Promise<TimeSeriesAnalysis> {
    // ê¸°ë³¸ í†µê³„
    const statistics = await this.statisticsCalculator.calculate(data);

    // ì´ìƒì¹˜ ê°ì§€
    const anomalies = await this.anomalyDetector.detect(data, {
      method: options.anomalyMethod || 'isolation-forest',
      sensitivity: options.sensitivity || 0.95
    });

    // ì˜ˆì¸¡ (ì˜µì…˜)
    let forecast: TimeSeriesForecast | undefined;
    if (options.includeForecast) {
      forecast = await this.forecaster.forecast(data, {
        horizon: options.forecastHorizon || 24,
        method: options.forecastMethod || 'prophet'
      });
    }

    // íŒ¨í„´ ë¶„ì„
    const patterns = await this.analyzePatterns(data);

    return {
      statistics,
      anomalies,
      forecast,
      patterns,
      quality: this.assessDataQuality(data)
    };
  }

  private async analyzePatterns(
    data: TimeSeriesData
  ): Promise<PatternAnalysis> {
    return {
      trend: await this.detectTrend(data),
      seasonality: await this.detectSeasonality(data),
      changePoints: await this.detectChangePoints(data),
      cycles: await this.detectCycles(data)
    };
  }

  private assessDataQuality(data: TimeSeriesData): DataQuality {
    const points = data.points;
    const timestamps = points.map(p => p.timestamp.getTime());
    
    // ê°„ê²© ë¶„ì„
    const intervals = [];
    for (let i = 1; i < timestamps.length; i++) {
      intervals.push(timestamps[i] - timestamps[i - 1]);
    }

    const avgInterval = intervals.reduce((a, b) => a + b, 0) / intervals.length;
    const intervalStdDev = Math.sqrt(
      intervals.reduce((sum, i) => sum + Math.pow(i - avgInterval, 2), 0) / intervals.length
    );

    // ê²°ì¸¡ê°’ ê°ì§€
    const expectedPoints = Math.floor(
      (data.end.getTime() - data.start.getTime()) / avgInterval
    );
    const missingRatio = 1 - (points.length / expectedPoints);

    return {
      completeness: 1 - missingRatio,
      consistency: 1 - (intervalStdDev / avgInterval),
      validity: this.calculateValidity(points),
      timeliness: this.calculateTimeliness(data.end)
    };
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì´ì¤‘ ì €ì¥ì†Œ êµ¬ì¡° (InfluxDB + ClickHouse)
- [ ] ë‹¤ì¸µ ìºì‹± ì‹œìŠ¤í…œ
- [ ] ë°ì´í„° ì••ì¶• ë° ë‹¤ìš´ìƒ˜í”Œë§
- [ ] ì‹œê³„ì—´ ë¶„ì„ ê¸°ëŠ¥

#### SubTask 5.11.3: ì„±ëŠ¥ ë¶„ì„ ì—”ì§„
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/metrics/performance_analysis.ts
export interface PerformanceMetrics {
  latency: LatencyMetrics;
  throughput: ThroughputMetrics;
  errorRate: ErrorMetrics;
  saturation: SaturationMetrics;
  availability: AvailabilityMetrics;
}

export class PerformanceAnalysisEngine {
  private metricsStore: TimeSeriesStorage;
  private analyzer: MetricsAnalyzer;
  private baselineCalculator: BaselineCalculator;
  private correlationEngine: CorrelationEngine;

  constructor(config: AnalysisEngineConfig) {
    this.metricsStore = new TimeSeriesStorage(config.storage);
    this.analyzer = new MetricsAnalyzer();
    this.baselineCalculator = new BaselineCalculator();
    this.correlationEngine = new CorrelationEngine();
  }

  async analyzePerformance(
    timeRange: TimeRange,
    options: AnalysisOptions = {}
  ): Promise<PerformanceAnalysisResult> {
    // 1. ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    const metrics = await this.collectMetrics(timeRange);

    // 2. ê¸°ì¤€ì„  ê³„ì‚°
    const baselines = await this.baselineCalculator.calculate(
      metrics,
      options.baselinePeriod || 7 // 7ì¼
    );

    // 3. ì´ìƒ ê°ì§€
    const anomalies = await this.detectAnomalies(metrics, baselines);

    // 4. ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
    const scores = await this.calculatePerformanceScores(metrics);

    // 5. ë³‘ëª© ì§€ì  ì‹ë³„
    const bottlenecks = await this.identifyBottlenecks(metrics);

    // 6. ìƒê´€ ê´€ê³„ ë¶„ì„
    const correlations = await this.correlationEngine.analyze(metrics);

    // 7. ì¶”ì„¸ ë¶„ì„
    const trends = await this.analyzeTrends(metrics, timeRange);

    // 8. ê¶Œì¥ ì‚¬í•­ ìƒì„±
    const recommendations = await this.generateRecommendations({
      metrics,
      anomalies,
      bottlenecks,
      correlations,
      trends
    });

    return {
      summary: this.generateSummary(metrics),
      scores,
      anomalies,
      bottlenecks,
      correlations,
      trends,
      recommendations
    };
  }

  private async collectMetrics(
    timeRange: TimeRange
  ): Promise<PerformanceMetrics> {
    const [latency, throughput, errorRate, saturation, availability] = 
      await Promise.all([
        this.collectLatencyMetrics(timeRange),
        this.collectThroughputMetrics(timeRange),
        this.collectErrorMetrics(timeRange),
        this.collectSaturationMetrics(timeRange),
        this.collectAvailabilityMetrics(timeRange)
      ]);

    return {
      latency,
      throughput,
      errorRate,
      saturation,
      availability
    };
  }

  private async collectLatencyMetrics(
    timeRange: TimeRange
  ): Promise<LatencyMetrics> {
    const queries = [
      // API ë ˆì´í„´ì‹œ
      {
        metric: 'api.requests.duration',
        aggregation: 'percentile',
        percentiles: [50, 90, 95, 99]
      },
      // ì›Œí¬í”Œë¡œìš° ë ˆì´í„´ì‹œ
      {
        metric: 'workflow.execution.duration',
        aggregation: 'percentile',
        percentiles: [50, 90, 95, 99]
      },
      // íƒœìŠ¤í¬ ë ˆì´í„´ì‹œ
      {
        metric: 'task.execution.duration',
        aggregation: 'percentile',
        percentiles: [50, 90, 95, 99]
      }
    ];

    const results = await Promise.all(
      queries.map(q => this.metricsStore.query({
        ...q,
        start: timeRange.start,
        end: timeRange.end
      }))
    );

    return {
      api: this.processLatencyData(results[0]),
      workflow: this.processLatencyData(results[1]),
      task: this.processLatencyData(results[2])
    };
  }

  private async detectAnomalies(
    metrics: PerformanceMetrics,
    baselines: PerformanceBaselines
  ): Promise<PerformanceAnomaly[]> {
    const anomalies: PerformanceAnomaly[] = [];

    // ë ˆì´í„´ì‹œ ì´ìƒ
    const latencyAnomalies = await this.detectLatencyAnomalies(
      metrics.latency,
      baselines.latency
    );
    anomalies.push(...latencyAnomalies);

    // ì²˜ë¦¬ëŸ‰ ì´ìƒ
    const throughputAnomalies = await this.detectThroughputAnomalies(
      metrics.throughput,
      baselines.throughput
    );
    anomalies.push(...throughputAnomalies);

    // ì—ëŸ¬ìœ¨ ì´ìƒ
    const errorAnomalies = await this.detectErrorAnomalies(
      metrics.errorRate,
      baselines.errorRate
    );
    anomalies.push(...errorAnomalies);

    // ìƒê´€ ê´€ê³„ ê¸°ë°˜ ì´ìƒ
    const correlationAnomalies = await this.detectCorrelationAnomalies(metrics);
    anomalies.push(...correlationAnomalies);

    return anomalies;
  }

  private async detectLatencyAnomalies(
    current: LatencyMetrics,
    baseline: LatencyBaseline
  ): Promise<PerformanceAnomaly[]> {
    const anomalies: PerformanceAnomaly[] = [];

    // P95 ë ˆì´í„´ì‹œ ë¹„êµ
    for (const [component, data] of Object.entries(current)) {
      const baselineP95 = baseline[component]?.p95 || 0;
      const currentP95 = data.p95;

      if (currentP95 > baselineP95 * 1.5) { // 50% ì¦ê°€
        anomalies.push({
          type: 'latency_spike',
          component,
          severity: this.calculateSeverity(currentP95, baselineP95),
          current: currentP95,
          baseline: baselineP95,
          deviation: (currentP95 - baselineP95) / baselineP95,
          timestamp: new Date(),
          description: `${component} P95 latency increased by ${Math.round((currentP95 / baselineP95 - 1) * 100)}%`
        });
      }
    }

    return anomalies;
  }

  private async identifyBottlenecks(
    metrics: PerformanceMetrics
  ): Promise<Bottleneck[]> {
    const bottlenecks: Bottleneck[] = [];

    // 1. CPU ë³‘ëª©
    if (metrics.saturation.cpu > 80) {
      bottlenecks.push({
        type: 'cpu',
        severity: 'high',
        component: 'system',
        metric: 'cpu_utilization',
        value: metrics.saturation.cpu,
        threshold: 80,
        impact: await this.estimateImpact('cpu', metrics.saturation.cpu),
        recommendations: [
          'Scale up CPU resources',
          'Optimize CPU-intensive operations',
          'Enable horizontal scaling'
        ]
      });
    }

    // 2. ë©”ëª¨ë¦¬ ë³‘ëª©
    if (metrics.saturation.memory > 85) {
      bottlenecks.push({
        type: 'memory',
        severity: 'high',
        component: 'system',
        metric: 'memory_utilization',
        value: metrics.saturation.memory,
        threshold: 85,
        impact: await this.estimateImpact('memory', metrics.saturation.memory),
        recommendations: [
          'Increase memory allocation',
          'Implement memory caching',
          'Review memory leaks'
        ]
      });
    }

    // 3. I/O ë³‘ëª©
    if (metrics.saturation.io > 70) {
      bottlenecks.push({
        type: 'io',
        severity: 'medium',
        component: 'storage',
        metric: 'io_utilization',
        value: metrics.saturation.io,
        threshold: 70,
        impact: await this.estimateImpact('io', metrics.saturation.io),
        recommendations: [
          'Optimize database queries',
          'Implement read replicas',
          'Use SSD storage'
        ]
      });
    }

    // 4. ë„¤íŠ¸ì›Œí¬ ë³‘ëª©
    if (metrics.saturation.network > 75) {
      bottlenecks.push({
        type: 'network',
        severity: 'medium',
        component: 'network',
        metric: 'network_utilization',
        value: metrics.saturation.network,
        threshold: 75,
        impact: await this.estimateImpact('network', metrics.saturation.network),
        recommendations: [
          'Implement CDN',
          'Enable compression',
          'Optimize payload sizes'
        ]
      });
    }

    // 5. ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ë³‘ëª©
    const appBottlenecks = await this.identifyApplicationBottlenecks(metrics);
    bottlenecks.push(...appBottlenecks);

    return bottlenecks.sort((a, b) => b
