#### SubTask 3.5.2: 스테이크홀더 분석 모듈
**담당자**: 비즈니스 분석가  
**예상 소요시간**: 12시간

**작업 내용**:
```typescript
// backend/src/agents/implementations/business_analyst/stakeholder_analyzer.ts
import { BaseModule } from '../../framework/base-module';

interface Stakeholder {
  id: string;
  name: string;
  role: string;
  type: StakeholderType;
  influence: 'high' | 'medium' | 'low';
  interest: 'high' | 'medium' | 'low';
  concerns: string[];
  requirements: string[];
  communicationPlan: CommunicationPlan;
}

enum StakeholderType {
  PRIMARY = 'primary',
  SECONDARY = 'secondary',
  KEY = 'key',
  EXTERNAL = 'external'
}

interface CommunicationPlan {
  frequency: string;
  method: string[];
  topics: string[];
  responsible: string;
}

interface StakeholderMatrix {
  highInfluenceHighInterest: Stakeholder[];
  highInfluenceLowInterest: Stakeholder[];
  lowInfluenceHighInterest: Stakeholder[];
  lowInfluenceLowInterest: Stakeholder[];
}

export class StakeholderAnalyzer extends BaseModule {
  private stakeholders: Map<string, Stakeholder> = new Map();
  
  async analyzeStakeholders(projectData: any): Promise<{
    stakeholders: Stakeholder[];
    matrix: StakeholderMatrix;
    engagementStrategies: any[];
  }> {
    // Extract stakeholders from project description
    const identifiedStakeholders = await this.identifyStakeholders(projectData);
    
    // Analyze each stakeholder
    for (const stakeholder of identifiedStakeholders) {
      const analysis = await this.analyzeStakeholder(stakeholder, projectData);
      this.stakeholders.set(analysis.id, analysis);
    }
    
    // Create stakeholder matrix
    const matrix = this.createStakeholderMatrix();
    
    // Generate engagement strategies
    const strategies = await this.generateEngagementStrategies(matrix);
    
    return {
      stakeholders: Array.from(this.stakeholders.values()),
      matrix,
      engagementStrategies: strategies
    };
  }
  
  private async identifyStakeholders(projectData: any): Promise<any[]> {
    const prompt = `
    Based on this project description, identify all stakeholders:
    ${JSON.stringify(projectData)}
    
    For each stakeholder, determine:
    1. Role and responsibilities
    2. Direct or indirect involvement
    3. Decision-making authority
    4. Potential impact on project
    `;
    
    const response = await this.callAgentLLM(prompt);
    return this.parseStakeholderList(response);
  }
  
  private async analyzeStakeholder(
    stakeholderData: any,
    projectData: any
  ): Promise<Stakeholder> {
    // Determine influence and interest levels
    const influence = await this.assessInfluence(stakeholderData, projectData);
    const interest = await this.assessInterest(stakeholderData, projectData);
    
    // Identify concerns and requirements
    const concerns = await this.identifyConcerns(stakeholderData, projectData);
    const requirements = await this.extractStakeholderRequirements(
      stakeholderData,
      projectData
    );
    
    // Create communication plan
    const communicationPlan = this.createCommunicationPlan(
      stakeholderData,
      influence,
      interest
    );
    
    return {
      id: this.generateId(stakeholderData.name),
      name: stakeholderData.name,
      role: stakeholderData.role,
      type: this.determineStakeholderType(stakeholderData),
      influence,
      interest,
      concerns,
      requirements,
      communicationPlan
    };
  }
  
  private createStakeholderMatrix(): StakeholderMatrix {
    const matrix: StakeholderMatrix = {
      highInfluenceHighInterest: [],
      highInfluenceLowInterest: [],
      lowInfluenceHighInterest: [],
      lowInfluenceLowInterest: []
    };
    
    for (const stakeholder of this.stakeholders.values()) {
      if (stakeholder.influence === 'high' && stakeholder.interest === 'high') {
        matrix.highInfluenceHighInterest.push(stakeholder);
      } else if (stakeholder.influence === 'high' && stakeholder.interest === 'low') {
        matrix.highInfluenceLowInterest.push(stakeholder);
      } else if (stakeholder.influence === 'low' && stakeholder.interest === 'high') {
        matrix.lowInfluenceHighInterest.push(stakeholder);
      } else {
        matrix.lowInfluenceLowInterest.push(stakeholder);
      }
    }
    
    return matrix;
  }
  
  private async generateEngagementStrategies(
    matrix: StakeholderMatrix
  ): Promise<any[]> {
    const strategies = [];
    
    // Manage Closely (High Influence, High Interest)
    strategies.push({
      quadrant: 'manage_closely',
      stakeholders: matrix.highInfluenceHighInterest,
      strategy: {
        approach: 'Full engagement and collaboration',
        actions: [
          'Regular one-on-one meetings',
          'Include in key decisions',
          'Provide detailed project updates',
          'Seek input and feedback actively'
        ],
        frequency: 'Weekly or bi-weekly'
      }
    });
    
    // Keep Satisfied (High Influence, Low Interest)
    strategies.push({
      quadrant: 'keep_satisfied',
      stakeholders: matrix.highInfluenceLowInterest,
      strategy: {
        approach: 'Keep informed with minimal effort',
        actions: [
          'Executive summaries',
          'Milestone updates only',
          'Address concerns promptly',
          'Escalation path available'
        ],
        frequency: 'Monthly or at milestones'
      }
    });
    
    // Keep Informed (Low Influence, High Interest)
    strategies.push({
      quadrant: 'keep_informed',
      stakeholders: matrix.lowInfluenceHighInterest,
      strategy: {
        approach: 'Regular communication without overwhelming',
        actions: [
          'Newsletter updates',
          'Group meetings',
          'Project dashboard access',
          'Q&A sessions'
        ],
        frequency: 'Bi-weekly or monthly'
      }
    });
    
    // Monitor (Low Influence, Low Interest)
    strategies.push({
      quadrant: 'monitor',
      stakeholders: matrix.lowInfluenceLowInterest,
      strategy: {
        approach: 'Minimal effort, general communication',
        actions: [
          'General announcements',
          'Access to public project info',
          'Reactive communication only'
        ],
        frequency: 'As needed'
      }
    });
    
    return strategies;
  }
  
  private createCommunicationPlan(
    stakeholder: any,
    influence: string,
    interest: string
  ): CommunicationPlan {
    const plans: Record<string, CommunicationPlan> = {
      'high-high': {
        frequency: 'Weekly',
        method: ['Face-to-face meetings', 'Video calls', 'Detailed reports'],
        topics: ['Progress updates', 'Risk mitigation', 'Decision points', 'Feedback'],
        responsible: 'Project Manager'
      },
      'high-low': {
        frequency: 'Monthly',
        method: ['Executive summaries', 'Email updates'],
        topics: ['Milestone achievements', 'Major issues', 'Budget status'],
        responsible: 'Project Manager'
      },
      'low-high': {
        frequency: 'Bi-weekly',
        method: ['Email newsletters', 'Team meetings', 'Project portal'],
        topics: ['Progress updates', 'Team achievements', 'Upcoming milestones'],
        responsible: 'Team Lead'
      },
      'low-low': {
        frequency: 'Quarterly',
        method: ['General announcements', 'Intranet updates'],
        topics: ['Major milestones', 'Project completion'],
        responsible: 'Communications Team'
      }
    };
    
    const key = `${influence}-${interest}`;
    return plans[key] || plans['low-low'];
  }
  
  // RACI Matrix generation
  async generateRACIMatrix(
    stakeholders: Stakeholder[],
    activities: string[]
  ): Promise<any> {
    const matrix: any = {};
    
    for (const activity of activities) {
      matrix[activity] = {};
      
      for (const stakeholder of stakeholders) {
        const role = await this.determineRACIRole(stakeholder, activity);
        if (role) {
          matrix[activity][stakeholder.id] = role;
        }
      }
    }
    
    return {
      matrix,
      validation: this.validateRACIMatrix(matrix),
      recommendations: this.generateRACIRecommendations(matrix)
    };
  }
  
  private async determineRACIRole(
    stakeholder: Stakeholder,
    activity: string
  ): Promise<string | null> {
    // R - Responsible: Does the work
    // A - Accountable: Ultimately answerable
    // C - Consulted: Provides input
    // I - Informed: Kept up-to-date
    
    const roleMapping = {
      'project_manager': {
        'project_planning': 'A',
        'requirement_gathering': 'A',
        'design_review': 'A',
        'testing': 'I',
        'deployment': 'A'
      },
      'technical_lead': {
        'project_planning': 'C',
        'requirement_gathering': 'C',
        'design_review': 'R',
        'testing': 'C',
        'deployment': 'R'
      },
      'developer': {
        'project_planning': 'I',
        'requirement_gathering': 'I',
        'design_review': 'C',
        'testing': 'R',
        'deployment': 'C'
      },
      'business_owner': {
        'project_planning': 'C',
        'requirement_gathering': 'A',
        'design_review': 'C',
        'testing': 'I',
        'deployment': 'I'
      }
    };
    
    const role = stakeholder.role.toLowerCase().replace(' ', '_');
    return roleMapping[role]?.[activity] || null;
  }
  
  private validateRACIMatrix(matrix: any): any {
    const issues = [];
    
    for (const activity in matrix) {
      const roles = Object.values(matrix[activity]);
      
      // Check for single accountability
      const accountableCount = roles.filter(r => r === 'A').length;
      if (accountableCount === 0) {
        issues.push({
          activity,
          issue: 'No one accountable',
          severity: 'high'
        });
      } else if (accountableCount > 1) {
        issues.push({
          activity,
          issue: 'Multiple people accountable',
          severity: 'high'
        });
      }
      
      // Check for at least one responsible
      const responsibleCount = roles.filter(r => r === 'R').length;
      if (responsibleCount === 0) {
        issues.push({
          activity,
          issue: 'No one responsible',
          severity: 'high'
        });
      }
    }
    
    return {
      isValid: issues.length === 0,
      issues
    };
  }
}
```

#### SubTask 3.5.3: 프로세스 모델링 도구
**담당자**: 프로세스 엔지니어  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/implementations/business_analyst/process_modeler.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum
import uuid

@dataclass
class ProcessNode:
    id: str
    type: str  # start, end, task, decision, subprocess
    name: str
    description: str
    inputs: List[str]
    outputs: List[str]
    responsible: str
    duration_estimate: Optional[str]
    metadata: Dict[str, Any]

@dataclass
class ProcessFlow:
    from_node: str
    to_node: str
    condition: Optional[str]
    probability: Optional[float]

@dataclass
class ProcessModel:
    id: str
    name: str
    description: str
    nodes: List[ProcessNode]
    flows: List[ProcessFlow]
    swimlanes: Dict[str, List[str]]  # role -> node_ids
    metrics: Dict[str, Any]

class ProcessModeler:
    """Business process modeling and analysis"""
    
    def __init__(self):
        self.process_models: Dict[str, ProcessModel] = {}
        self.templates = self._load_process_templates()
        
    async def model_business_process(
        self,
        requirements: List[Any],
        context: Dict[str, Any]
    ) -> ProcessModel:
        """Create business process model from requirements"""
        
        # Identify process boundaries
        boundaries = await self._identify_process_boundaries(requirements)
        
        # Extract process steps
        steps = await self._extract_process_steps(requirements, context)
        
        # Identify decision points
        decisions = await self._identify_decision_points(steps)
        
        # Create process nodes
        nodes = await self._create_process_nodes(steps, decisions)
        
        # Define process flows
        flows = await self._define_process_flows(nodes, requirements)
        
        # Assign swimlanes
        swimlanes = await self._assign_swimlanes(nodes, context)
        
        # Calculate process metrics
        metrics = await self._calculate_process_metrics(nodes, flows)
        
        process_model = ProcessModel(
            id=str(uuid.uuid4()),
            name=f"Process_{context.get('project_name', 'Unknown')}",
            description=boundaries.get('description', ''),
            nodes=nodes,
            flows=flows,
            swimlanes=swimlanes,
            metrics=metrics
        )
        
        self.process_models[process_model.id] = process_model
        return process_model
    
    async def _extract_process_steps(
        self,
        requirements: List[Any],
        context: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Extract process steps from requirements"""
        
        prompt = f"""
        Extract business process steps from these requirements:
        {[r.description for r in requirements]}
        
        For each step identify:
        1. Action to be performed
        2. Actor/Role responsible
        3. Inputs required
        4. Outputs produced
        5. Business rules applied
        6. Estimated duration
        
        Context: {context}
        """
        
        response = await self._analyze_with_llm(prompt)
        return self._parse_process_steps(response)
    
    async def _identify_decision_points(
        self,
        steps: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Identify decision points in the process"""
        
        decisions = []
        
        for i, step in enumerate(steps):
            # Check for conditional language
            if any(word in step.get('description', '').lower() 
                   for word in ['if', 'when', 'unless', 'either', 'decide']):
                
                decision = {
                    'id': f"decision_{i}",
                    'step_index': i,
                    'condition': step.get('condition'),
                    'options': await self._extract_decision_options(step),
                    'criteria': step.get('business_rules', [])
                }
                decisions.append(decision)
        
        return decisions
    
    async def _create_process_nodes(
        self,
        steps: List[Dict[str, Any]],
        decisions: List[Dict[str, Any]]
    ) -> List[ProcessNode]:
        """Create process nodes from steps and decisions"""
        
        nodes = []
        
        # Start node
        nodes.append(ProcessNode(
            id='start',
            type='start',
            name='Process Start',
            description='Beginning of the process',
            inputs=[],
            outputs=['initial_data'],
            responsible='System',
            duration_estimate='0',
            metadata={}
        ))
        
        # Process step nodes
        for step in steps:
            node = ProcessNode(
                id=f"task_{step['id']}",
                type='task',
                name=step['name'],
                description=step['description'],
                inputs=step.get('inputs', []),
                outputs=step.get('outputs', []),
                responsible=step.get('actor', 'Unknown'),
                duration_estimate=step.get('duration'),
                metadata={
                    'business_rules': step.get('business_rules', []),
                    'tools_required': step.get('tools', [])
                }
            )
            nodes.append(node)
        
        # Decision nodes
        for decision in decisions:
            node = ProcessNode(
                id=decision['id'],
                type='decision',
                name=f"Decision: {decision.get('condition', 'Unknown')}",
                description=decision.get('description', ''),
                inputs=['decision_data'],
                outputs=decision.get('options', []),
                responsible=decision.get('decision_maker', 'Unknown'),
                duration_estimate='0',
                metadata={
                    'criteria': decision.get('criteria', []),
                    'options': decision.get('options', [])
                }
            )
            nodes.append(node)
        
        # End node
        nodes.append(ProcessNode(
            id='end',
            type='end',
            name='Process End',
            description='End of the process',
            inputs=['final_data'],
            outputs=[],
            responsible='System',
            duration_estimate='0',
            metadata={}
        ))
        
        return nodes
    
    async def optimize_process(
        self,
        process_model: ProcessModel
    ) -> Dict[str, Any]:
        """Optimize business process"""
        
        # Identify bottlenecks
        bottlenecks = await self._identify_bottlenecks(process_model)
        
        # Find parallel opportunities
        parallel_opportunities = await self._find_parallel_opportunities(process_model)
        
        # Suggest automations
        automation_suggestions = await self._suggest_automations(process_model)
        
        # Calculate optimization metrics
        current_metrics = process_model.metrics
        optimized_metrics = await self._calculate_optimized_metrics(
            process_model,
            parallel_opportunities,
            automation_suggestions
        )
        
        return {
            'current_process': process_model,
            'bottlenecks': bottlenecks,
            'parallel_opportunities': parallel_opportunities,
            'automation_suggestions': automation_suggestions,
            'metrics_comparison': {
                'current': current_metrics,
                'optimized': optimized_metrics,
                'improvement': self._calculate_improvement(
                    current_metrics,
                    optimized_metrics
                )
            },
            'recommendations': await self._generate_optimization_recommendations(
                bottlenecks,
                parallel_opportunities,
                automation_suggestions
            )
        }
    
    async def generate_bpmn(self, process_model: ProcessModel) -> str:
        """Generate BPMN 2.0 XML from process model"""
        
        bpmn = f"""<?xml version="1.0" encoding="UTF-8"?>
<definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL"
             xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI"
             xmlns:dc="http://www.omg.org/spec/DD/20100524/DC"
             xmlns:di="http://www.omg.org/spec/DD/20100524/DI"
             id="definitions_{process_model.id}"
             targetNamespace="http://bpmn.io/schema/bpmn">
    
    <process id="Process_{process_model.id}" isExecutable="true">
"""
        
        # Add nodes
        for node in process_model.nodes:
            if node.type == 'start':
                bpmn += f'        <startEvent id="{node.id}" name="{node.name}"/>\n'
            elif node.type == 'end':
                bpmn += f'        <endEvent id="{node.id}" name="{node.name}"/>\n'
            elif node.type == 'task':
                bpmn += f'        <task id="{node.id}" name="{node.name}"/>\n'
            elif node.type == 'decision':
                bpmn += f'        <exclusiveGateway id="{node.id}" name="{node.name}"/>\n'
        
        # Add flows
        for flow in process_model.flows:
            bpmn += f'        <sequenceFlow id="flow_{flow.from_node}_{flow.to_node}" '
            bpmn += f'sourceRef="{flow.from_node}" targetRef="{flow.to_node}"'
            if flow.condition:
                bpmn += f' name="{flow.condition}"'
            bpmn += '/>\n'
        
        bpmn += """    </process>
    
    <bpmndi:BPMNDiagram id="BPMNDiagram_1">
        <bpmndi:BPMNPlane id="BPMNPlane_1" bpmnElement="Process_{process_model.id}">
            <!-- Diagram elements would go here -->
        </bpmndi:BPMNPlane>
    </bpmndi:BPMNDiagram>
</definitions>"""
        
        return bpmn
    
    async def simulate_process(
        self,
        process_model: ProcessModel,
        scenarios: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Simulate process execution with different scenarios"""
        
        simulation_results = []
        
        for scenario in scenarios:
            result = await self._run_simulation(process_model, scenario)
            simulation_results.append(result)
        
        return {
            'scenarios': simulation_results,
            'summary': self._summarize_simulations(simulation_results),
            'recommendations': await self._generate_simulation_recommendations(
                simulation_results
            )
        }
    
    async def _run_simulation(
        self,
        process_model: ProcessModel,
        scenario: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Run single process simulation"""
        
        execution_path = []
        current_node = 'start'
        total_duration = 0
        resources_used = {}
        
        while current_node != 'end':
            node = self._get_node(process_model, current_node)
            
            # Record execution
            execution_path.append({
                'node': node.id,
                'timestamp': total_duration,
                'resource': node.responsible
            })
            
            # Update metrics
            if node.duration_estimate:
                duration = self._parse_duration(node.duration_estimate)
                total_duration += duration
            
            if node.responsible not in resources_used:
                resources_used[node.responsible] = 0
            resources_used[node.responsible] += 1
            
            # Determine next node
            if node.type == 'decision':
                current_node = await self._simulate_decision(
                    node,
                    scenario,
                    process_model
                )
            else:
                next_flows = [f for f in process_model.flows 
                             if f.from_node == current_node]
                if next_flows:
                    current_node = next_flows[0].to_node
                else:
                    current_node = 'end'
        
        return {
            'scenario': scenario,
            'execution_path': execution_path,
            'total_duration': total_duration,
            'resources_used': resources_used,
            'bottlenecks_encountered': self._identify_simulation_bottlenecks(
                execution_path
            )
        }
    
    def _load_process_templates(self) -> Dict[str, Any]:
        """Load standard process templates"""
        return {
            'approval_process': {
                'nodes': ['submit', 'review', 'approve/reject', 'notify'],
                'typical_duration': '3-5 days'
            },
            'development_process': {
                'nodes': ['requirements', 'design', 'implement', 'test', 'deploy'],
                'typical_duration': '2-4 weeks'
            },
            'support_ticket': {
                'nodes': ['create', 'triage', 'assign', 'resolve', 'close'],
                'typical_duration': '1-3 days'
            }
        }
```

#### SubTask 3.5.4: 비즈니스 룰 엔진
**담당자**: 룰 엔진 개발자  
**예상 소요시간**: 14시간

**작업 내용**:
```typescript
// backend/src/agents/implementations/business_analyst/business_rules_engine.ts
interface BusinessRule {
  id: string;
  name: string;
  description: string;
  category: string;
  priority: number;
  conditions: RuleCondition[];
  actions: RuleAction[];
  exceptions: RuleException[];
  metadata: {
    author: string;
    created: Date;
    lastModified: Date;
    version: string;
    tags: string[];
  };
}

interface RuleCondition {
  id: string;
  type: 'simple' | 'complex' | 'composite';
  field: string;
  operator: string;
  value: any;
  logicalOperator?: 'AND' | 'OR' | 'NOT';
  nestedConditions?: RuleCondition[];
}

interface RuleAction {
  id: string;
  type: string;
  target: string;
  operation: string;
  parameters: Record<string, any>;
  sequence: number;
}

interface RuleException {
  id: string;
  condition: RuleCondition;
  alternativeAction: RuleAction;
  reason: string;
}

export class BusinessRulesEngine {
  private rules: Map<string, BusinessRule> = new Map();
  private ruleCategories: Map<string, Set<string>> = new Map();
  private decisionTables: Map<string, DecisionTable> = new Map();
  
  async extractBusinessRules(
    requirements: any[],
    domainKnowledge: any
  ): Promise<BusinessRule[]> {
    const rules: BusinessRule[] = [];
    
    // Extract rules from requirements
    for (const req of requirements) {
      const extractedRules = await this.extractRulesFromRequirement(req);
      rules.push(...extractedRules);
    }
    
    // Apply domain knowledge
    const enrichedRules = await this.enrichWithDomainKnowledge(
      rules,
      domainKnowledge
    );
    
    // Validate and optimize rules
    const validatedRules = await this.validateRules(enrichedRules);
    const optimizedRules = await this.optimizeRules(validatedRules);
    
    // Store rules
    for (const rule of optimizedRules) {
      this.rules.set(rule.id, rule);
      this.categorizeRule(rule);
    }
    
    return optimizedRules;
  }
  
  private async extractRulesFromRequirement(
    requirement: any
  ): Promise<BusinessRule[]> {
    const rules: BusinessRule[] = [];
    
    // Pattern matching for rule indicators
    const rulePatterns = [
      /if\s+(.+?)\s+then\s+(.+)/i,
      /when\s+(.+?)\s+(?:then\s+)?(.+)/i,
      /must\s+(.+?)\s+when\s+(.+)/i,
      /should\s+(.+?)\s+if\s+(.+)/i,
      /(.+?)\s+is\s+required\s+when\s+(.+)/i
    ];
    
    const text = requirement.description;
    
    for (const pattern of rulePatterns) {
      const matches = text.match(pattern);
      if (matches) {
        const rule = await this.parseRule(matches, requirement);
        if (rule) {
          rules.push(rule);
        }
      }
    }
    
    // Extract validation rules
    const validationRules = await this.extractValidationRules(requirement);
    rules.push(...validationRules);
    
    // Extract calculation rules
    const calculationRules = await this.extractCalculationRules(requirement);
    rules.push(...calculationRules);
    
    return rules;
  }
  
  private async parseRule(
    matches: RegExpMatchArray,
    requirement: any
  ): Promise<BusinessRule | null> {
    try {
      const conditionText = matches[1];
      const actionText = matches[2];
      
      // Parse conditions
      const conditions = await this.parseConditions(conditionText);
      
      // Parse actions
      const actions = await this.parseActions(actionText);
      
      // Generate rule metadata
      const rule: BusinessRule = {
        id: `rule_${this.generateRuleId()}`,
        name: this.generateRuleName(requirement),
        description: requirement.description,
        category: this.determineRuleCategory(conditions, actions),
        priority: this.calculateRulePriority(requirement),
        conditions,
        actions,
        exceptions: [],
        metadata: {
          author: 'BusinessAnalystAgent',
          created: new Date(),
          lastModified: new Date(),
          version: '1.0.0',
          tags: this.extractRuleTags(requirement)
        }
      };
      
      return rule;
    } catch (error) {
      console.error('Error parsing rule:', error);
      return null;
    }
  }
  
  private async parseConditions(text: string): Promise<RuleCondition[]> {
    const conditions: RuleCondition[] = [];
    
    // Split by logical operators
    const parts = text.split(/\s+(and|or)\s+/i);
    
    for (let i = 0; i < parts.length; i += 2) {
      const conditionText = parts[i];
      const logicalOp = parts[i + 1];
      
      const condition = await this.parseSingleCondition(conditionText);
      if (condition) {
        if (logicalOp) {
          condition.logicalOperator = logicalOp.toUpperCase() as 'AND' | 'OR';
        }
        conditions.push(condition);
      }
    }
    
    return conditions;
  }
  
  private async parseSingleCondition(text: string): Promise<RuleCondition> {
    // Parse different condition patterns
    const patterns = {
      comparison: /(.+?)\s*(=|!=|>|<|>=|<=|contains|matches)\s*(.+)/,
      range: /(.+?)\s+between\s+(.+?)\s+and\s+(.+)/,
      list: /(.+?)\s+in\s+\[(.+?)\]/,
      existence: /(.+?)\s+(exists|is\s+present|is\s+not\s+null)/
    };
    
    for (const [type, pattern] of Object.entries(patterns)) {
      const match = text.match(pattern);
      if (match) {
        return this.createCondition(type, match);
      }
    }
    
    // Default simple condition
    return {
      id: `cond_${Date.now()}`,
      type: 'simple',
      field: text.trim(),
      operator: 'exists',
      value: true
    };
  }
  
  async evaluateRules(
    context: any,
    ruleCategory?: string
  ): Promise<RuleEvaluationResult[]> {
    const results: RuleEvaluationResult[] = [];
    const rulesToEvaluate = ruleCategory
      ? Array.from(this.ruleCategories.get(ruleCategory) || [])
          .map(id => this.rules.get(id)!)
      : Array.from(this.rules.values());
    
    // Sort by priority
    rulesToEvaluate.sort((a, b) => b.priority - a.priority);
    
    for (const rule of rulesToEvaluate) {
      const result = await this.evaluateRule(rule, context);
      results.push(result);
      
      // Apply actions if rule matches
      if (result.matched) {
        await this.applyRuleActions(rule, context, result);
      }
    }
    
    return results;
  }
  
  private async evaluateRule(
    rule: BusinessRule,
    context: any
  ): Promise<RuleEvaluationResult> {
    const startTime = Date.now();
    
    try {
      // Check exceptions first
      for (const exception of rule.exceptions) {
        if (await this.evaluateCondition(exception.condition, context)) {
          return {
            ruleId: rule.id,
            matched: false,
            exception: true,
            exceptionReason: exception.reason,
            evaluationTime: Date.now() - startTime
          };
        }
      }
      
      // Evaluate main conditions
      const conditionResults = await Promise.all(
        rule.conditions.map(cond => this.evaluateCondition(cond, context))
      );
      
      // Combine results based on logical operators
      const matched = this.combineConditionResults(
        conditionResults,
        rule.conditions
      );
      
      return {
        ruleId: rule.id,
        matched,
        conditionResults,
        evaluationTime: Date.now() - startTime
      };
    } catch (error) {
      return {
        ruleId: rule.id,
        matched: false,
        error: error.message,
        evaluationTime: Date.now() - startTime
      };
    }
  }
  
  private async evaluateCondition(
    condition: RuleCondition,
    context: any
  ): Promise<boolean> {
    if (condition.type === 'composite') {
      // Recursive evaluation for nested conditions
      const nestedResults = await Promise.all(
        (condition.nestedConditions || []).map(
          c => this.evaluateCondition(c, context)
        )
      );
      return this.combineConditionResults(
        nestedResults,
        condition.nestedConditions || []
      );
    }
    
    // Get field value from context
    const fieldValue = this.getFieldValue(condition.field, context);
    
    // Apply operator
    switch (condition.operator) {
      case '=':
      case '==':
        return fieldValue == condition.value;
      case '!=':
        return fieldValue != condition.value;
      case '>':
        return fieldValue > condition.value;
      case '<':
        return fieldValue < condition.value;
      case '>=':
        return fieldValue >= condition.value;
      case '<=':
        return fieldValue <= condition.value;
      case 'contains':
        return String(fieldValue).includes(String(condition.value));
      case 'matches':
        return new RegExp(condition.value).test(String(fieldValue));
      case 'in':
        return Array.isArray(condition.value) && 
               condition.value.includes(fieldValue);
      case 'between':
        return fieldValue >= condition.value[0] && 
               fieldValue <= condition.value[1];
      default:
        return false;
    }
  }
  
  // Decision table support
  async createDecisionTable(
    name: string,
    inputs: DecisionTableInput[],
    outputs: DecisionTableOutput[],
    rules: DecisionTableRule[]
  ): Promise<DecisionTable> {
    const table: DecisionTable = {
      id: `dt_${Date.now()}`,
      name,
      inputs,
      outputs,
      rules,
      hitPolicy: 'FIRST', // FIRST, UNIQUE, ANY, PRIORITY, etc.
      metadata: {
        created: new Date(),
        version: '1.0.0'
      }
    };
    
    this.decisionTables.set(table.id, table);
    return table;
  }
  
  async evaluateDecisionTable(
    tableId: string,
    context: any
  ): Promise<DecisionTableResult> {
    const table = this.decisionTables.get(tableId);
    if (!table) {
      throw new Error(`Decision table ${tableId} not found`);
    }
    
    const matchedRules: DecisionTableRule[] = [];
    
    for (const rule of table.rules) {
      const inputMatches = await this.evaluateTableInputs(
        rule.inputs,
        table.inputs,
        context
      );
      
      if (inputMatches) {
        matchedRules.push(rule);
        
        if (table.hitPolicy === 'FIRST') {
          break; // Stop at first match
        }
      }
    }
    
    return {
      tableId,
      matchedRules,
      outputs: this.collectTableOutputs(matchedRules, table.outputs),
      hitPolicy: table.hitPolicy
    };
  }
  
  // Rule conflict detection
  async detectConflicts(): Promise<RuleConflict[]> {
    const conflicts: RuleConflict[] = [];
    const ruleArray = Array.from(this.rules.values());
    
    for (let i = 0; i < ruleArray.length; i++) {
      for (let j = i + 1; j < ruleArray.length; j++) {
        const conflict = await this.checkRuleConflict(
          ruleArray[i],
          ruleArray[j]
        );
        
        if (conflict) {
          conflicts.push(conflict);
        }
      }
    }
    
    return conflicts;
  }
  
  private async checkRuleConflict(
    rule1: BusinessRule,
    rule2: BusinessRule
  ): Promise<RuleConflict | null> {
    // Check for overlapping conditions
    const conditionOverlap = this.checkConditionOverlap(
      rule1.conditions,
      rule2.conditions
    );
    
    if (conditionOverlap) {
      // Check for conflicting actions
      const actionConflict = this.checkActionConflict(
        rule1.actions,
        rule2.actions
      );
      
      if (actionConflict) {
        return {
          rule1Id: rule1.id,
          rule2Id: rule2.id,
          type: 'action_conflict',
          description: `Rules have overlapping conditions but conflicting actions`,
          severity: 'high',
          resolution: this.suggestConflictResolution(rule1, rule2)
        };
      }
    }
    
    return null;
  }
  
  // Rule optimization
  private async optimizeRules(rules: BusinessRule[]): Promise<BusinessRule[]> {
    // Remove duplicates
    const uniqueRules = this.removeDuplicateRules(rules);
    
    // Merge similar rules
    const mergedRules = await this.mergeSimilarRules(uniqueRules);
    
    // Optimize condition order
    const optimizedRules = mergedRules.map(rule => ({
      ...rule,
      conditions: this.optimizeConditionOrder(rule.conditions)
    }));
    
    // Create rule indexes for faster evaluation
    await this.createRuleIndexes(optimizedRules);
    
    return optimizedRules;
  }
  
  private optimizeConditionOrder(conditions: RuleCondition[]): RuleCondition[] {
    // Sort conditions by evaluation cost and selectivity
    return conditions.sort((a, b) => {
      const costA = this.estimateConditionCost(a);
      const costB = this.estimateConditionCost(b);
      const selectivityA = this.estimateSelectivity(a);
      const selectivityB = this.estimateSelectivity(b);
      
      // Prefer low cost and high selectivity
      return (costA / selectivityA) - (costB / selectivityB);
    });
  }
}

// Supporting interfaces
interface RuleEvaluationResult {
  ruleId: string;
  matched: boolean;
  conditionResults?: boolean[];
  exception?: boolean;
  exceptionReason?: string;
  error?: string;
  evaluationTime: number;
}

interface DecisionTable {
  id: string;
  name: string;
  inputs: DecisionTableInput[];
  outputs: DecisionTableOutput[];
  rules: DecisionTableRule[];
  hitPolicy: string;
  metadata: any;
}

interface DecisionTableInput {
  id: string;
  name: string;
  type: string;
  allowedValues?: any[];
}

interface DecisionTableOutput {
  id: string;
  name: string;
  type: string;
  defaultValue?: any;
}

interface DecisionTableRule {
  id: string;
  inputs: Record<string, any>;
  outputs: Record<string, any>;
  annotation?: string;
}

interface RuleConflict {
  rule1Id: string;
  rule2Id: string;
  type: string;
  description: string;
  severity: string;
  resolution: string;
}
```

---

### Task 3.6: System Design Agent 구현

#### SubTask 3.6.1: 아키텍처 설계 엔진
**담당자**: 시스템 아키텍트  
**예상 소요시간**: 16시간

**작업 내용**:
```python
# backend/src/agents/implementations/system_design_agent.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum
import json

from ..framework.base_agent import BaseAgent
from ..framework.agno_integration import AgnoEnabledAgent
from ..framework.squad_integration import SquadEnabledAgent

class ArchitecturePattern(Enum):
    MONOLITHIC = "monolithic"
    MICROSERVICES = "microservices"
    SERVERLESS = "serverless"
    EVENT_DRIVEN = "event_driven"
    LAYERED = "layered"
    HEXAGONAL = "hexagonal"
    CQRS = "cqrs"
    DDD = "domain_driven_design"

@dataclass
class SystemComponent:
    id: str
    name: str
    type: str
    responsibilities: List[str]
    interfaces: List[Dict[str, Any]]
    dependencies: List[str]
    technology_stack: Dict[str, Any]
    deployment_info: Dict[str, Any]
    constraints: List[str]

@dataclass
class SystemArchitecture:
    pattern: ArchitecturePattern
    components: List[SystemComponent]
    layers: Dict[str, List[str]]  # layer_name -> component_ids
    data_flow: List[Dict[str, Any]]
    integration_points: List[Dict[str, Any]]
    deployment_architecture: Dict[str, Any]
    quality_attributes: Dict[str, Any]

class SystemDesignAgent(AgnoEnabledAgent, SquadEnabledAgent):
    """System Design Agent for architectural design and technical decisions"""
    
    def __init__(self):
        AgnoEnabledAgent.__init__(
            self,
            name="SystemDesignAgent",
            agno_config={
                'modelId': 'anthropic.claude-3-opus-v1:0',
                'temperature': 0.4,
                'maxTokens': 8000,
                'tools': [
                    self._create_architecture_analyzer_tool(),
                    self._create_pattern_selector_tool(),
                    self._create_component_designer_tool()
                ]
            }
        )
        SquadEnabledAgent.__init__(self, name="SystemDesignAgent", team_size=4)
        
        self.architecture_patterns = self._load_architecture_patterns()
        self.design_principles = self._load_design_principles()
        self.technology_catalog = self._load_technology_catalog()
        
    async def initialize(self) -> None:
        await AgnoEnabledAgent.initialize(self)
        await SquadEnabledAgent.initialize(self)
        
        # Register capabilities
        self.capabilities = [
            {
                'name': 'design_architecture',
                'description': 'Design system architecture based on requirements',
                'input_schema': {
                    'type': 'object',
                    'properties': {
                        'requirements': {'type': 'array'},
                        'constraints': {'type': 'array'},
                        'quality_attributes': {'type': 'object'}
                    }
                }
            },
            {
                'name': 'select_technologies',
                'description': 'Select appropriate technology stack',
                'input_schema': {
                    'type': 'object',
                    'properties': {
                        'architecture': {'type': 'object'},
                        'requirements': {'type': 'array'}
                    }
                }
            },
            {
                'name': 'design_data_model',
                'description': 'Design data models and schemas',
                'input_schema': {
                    'type': 'object',
                    'properties': {
                        'entities': {'type': 'array'},
                        'relationships': {'type': 'array'}
                    }
                }
            }
        ]
    
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Process system design task"""
        task_type = task.get('task_type')
        
        if task_type == 'design_system':
            return await self.design_system(task['data'])
        elif task_type == 'select_architecture':
            return await self.select_architecture_pattern(task['data'])
        elif task_type == 'design_components':
            return await self.design_components(task['data'])
        elif task_type == 'select_tech_stack':
            return await self.select_technology_stack(task['data'])
        else:
            raise ValueError(f"Unknown task type: {task_type}")
    
    async def design_system(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Design complete system architecture"""
        
        requirements = data.get('requirements', [])
        constraints = data.get('constraints', [])
        quality_attributes = data.get('quality_attributes', {})
        
        # Analyze requirements for architectural drivers
        drivers = await self._analyze_architectural_drivers(
            requirements,
            constraints,
            quality_attributes
        )
        
        # Select architecture pattern
        pattern = await self._select_best_pattern(drivers)
        
        # Design components
        components = await self._design_system_components(
            requirements,
            pattern,
            drivers
        )
        
        # Define layers and boundaries
        layers = await self._define_architectural_layers(components, pattern)
        
        # Design data flow
        data_flow = await self._design_data_flow(components, requirements)
        
        # Design integration points
        integration_points = await self._design_integration_points(
            components,
            requirements
        )
        
        # Design deployment architecture
        deployment = await self._design_deployment_architecture(
            components,
            constraints,
            quality_attributes
        )
        
        architecture = SystemArchitecture(
            pattern=pattern,
            components=components,
            layers=layers,
            data_flow=data_flow,
            integration_points=integration_points,
            deployment_architecture=deployment,
            quality_attributes=quality_attributes
        )
        
        return {
            'architecture': architecture.__dict__,
            'decisions': await self._document_architectural_decisions(architecture),
            'trade_offs': await self._analyze_trade_offs(architecture),
            'risks': await self._identify_architectural_risks(architecture)
        }
    
    async def _analyze_architectural_drivers(
        self,
        requirements: List[Any],
        constraints: List[Any],
        quality_attributes: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Analyze key architectural drivers"""
        
        prompt = f"""
        Analyze these requirements and identify architectural drivers:
        
        Requirements: {json.dumps(requirements, indent=2)}
        Constraints: {json.dumps(constraints, indent=2)}
        Quality Attributes: {json.dumps(quality_attributes, indent=2)}
        
        Identify:
        1. Primary functional drivers
        2. Quality attribute scenarios
        3. Technical constraints impact
        4. Business constraints impact
        5. Risk factors
        """
        
        analysis = await self.processWithAgno(prompt)
        
        # Use squad for detailed analysis
        squad_result = await self.execute_with_squad({
            'objective': 'Perform detailed architectural driver analysis',
            'context': {
                'initial_analysis': analysis,
                'requirements': requirements
            },
            'requirements': [
                'Prioritize architectural drivers',
                'Identify conflicts between drivers',
                'Suggest mitigation strategies'
            ]
        })
        
        return {
            'functional_drivers': analysis.get('functional_drivers', []),
            'quality_scenarios': self._extract_quality_scenarios(analysis),
            'constraints_impact': squad_result.get('constraints_analysis'),
            'priorities': squad_result.get('driver_priorities'),
            'conflicts': squad_result.get('conflicts', [])
        }
    
    async def _select_best_pattern(
        self,
        drivers: Dict[str, Any]
    ) -> ArchitecturePattern:
        """Select most appropriate architecture pattern"""
        
        pattern_scores = {}
        
        for pattern in ArchitecturePattern:
            score = await self._evaluate_pattern_fit(pattern, drivers)
            pattern_scores[pattern] = score
        
        # Select pattern with highest score
        best_pattern = max(pattern_scores, key=pattern_scores.get)
        
        # Validate selection with team
        validation = await self.execute_with_squad({
            'objective': f'Validate {best_pattern.value} architecture selection',
            'context': {
                'drivers': drivers,
                'scores': pattern_scores
            }
        })
        
        if validation.get('approved'):
            return best_pattern
        else:
            # Use alternative suggested by team
            return ArchitecturePattern(validation.get('alternative'))
    
    async def _design_system_components(
        self,
        requirements: List[Any],
        pattern: ArchitecturePattern,
        drivers: Dict[str, Any]
    ) -> List[SystemComponent]:
        """Design system components based on pattern"""
        
        # Identify bounded contexts (for DDD) or services
        contexts = await self._identify_bounded_contexts(requirements)
        
        components = []
        
        for context in contexts:
            # Design component for each context
            component = await self._design_component(
                context,
                pattern,
                drivers
            )
            components.append(component)
        
        # Add infrastructure components
        infra_components = await self._design_infrastructure_components(
            pattern,
            components
        )
        components.extend(infra_components)
        
        # Define interfaces between components
        await self._define_component_interfaces(components)
        
        return components
    
    async def _design_component(
        self,
        context: Dict[str, Any],
        pattern: ArchitecturePattern,
        drivers: Dict[str, Any]
    ) -> SystemComponent:
        """Design individual system component"""
        
        prompt = f"""
        Design a system component for:
        Context: {context}
        Architecture Pattern: {pattern.value}
        
        Define:
        1. Component responsibilities
        2. Public interfaces (APIs)
        3. Required dependencies
        4. Technology choices
        5. Deployment requirements
        """
        
        design = await self.processWithAgno(prompt)
        
        return SystemComponent(
            id=f"comp_{context['name'].lower().replace(' ', '_')}",
            name=context['name'],
            type=self._determine_component_type(pattern),
            responsibilities=design.get('responsibilities', []),
            interfaces=design.get('interfaces', []),
            dependencies=design.get('dependencies', []),
            technology_stack=design.get('technologies', {}),
            deployment_info=design.get('deployment', {}),
            constraints=design.get('constraints', [])
        )
    
    async def _design_data_flow(
        self,
        components: List[SystemComponent],
        requirements: List[Any]
    ) -> List[Dict[str, Any]]:
        """Design data flow between components"""
        
        flows = []
        
        # Analyze data requirements
        data_requirements = await self._analyze_data_requirements(requirements)
        
        for data_req in data_requirements:
            flow = await self._design_single_data_flow(
                data_req,
                components
            )
            flows.append(flow)
        
        # Optimize data flow
        optimized_flows = await self._optimize_data_flows(flows)
        
        return optimized_flows
    
    async def select_architecture_pattern(
        self,
        data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Select and justify architecture pattern"""
        
        requirements = data.get('requirements', [])
        constraints = data.get('constraints', [])
        
        # Evaluate each pattern
        evaluations = {}
        
        for pattern in ArchitecturePattern:
            evaluation = await self._evaluate_pattern(
                pattern,
                requirements,
                constraints
            )
            evaluations[pattern.value] = evaluation
        
        # Rank patterns
        ranked_patterns = sorted(
            evaluations.items(),
            key=lambda x: x[1]['score'],
            reverse=True
        )
        
        return {
            'recommended_pattern': ranked_patterns[0][0],
            'score': ranked_patterns[0][1]['score'],
            'justification': ranked_patterns[0][1]['justification'],
            'alternatives': [
                {
                    'pattern': p[0],
                    'score': p[1]['score'],
                    'pros': p[1]['pros'],
                    'cons': p[1]['cons']
                }
                for p in ranked_patterns[1:4]  # Top 3 alternatives
            ],
            'decision_matrix': evaluations
        }
    
    async def select_technology_stack(
        self,
        data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Select technology stack for the system"""
        
        architecture = data.get('architecture', {})
        requirements = data.get('requirements', [])
        constraints = data.get('constraints', [])
        
        # Analyze technology requirements
        tech_requirements = await self._analyze_technology_requirements(
            architecture,
            requirements,
            constraints
        )
        
        # Select technologies for each layer
        stack = {}
        
        for layer in ['frontend', 'backend', 'database', 'infrastructure']:
            layer_tech = await self._select_layer_technologies(
                layer,
                tech_requirements,
                constraints
            )
            stack[layer] = layer_tech
        
        # Ensure compatibility
        compatibility_check = await self._check_technology_compatibility(stack)
        
        if not compatibility_check['compatible']:
            # Adjust selections
            stack = await self._adjust_for_compatibility(
                stack,
                compatibility_check['issues']
            )
        
        return {
            'technology_stack': stack,
            'justifications': await self._justify_technology_choices(stack),
            'alternatives': await self._identify_technology_alternatives(stack),
            'migration_path': await self._design_migration_path(stack),
            'cost_analysis': await self._analyze_technology_costs(stack)
        }
    
    def _get_lead_system_prompt(self) -> str:
        """System prompt for lead architect agent"""
        return """
        You are a Principal System Architect with expertise in:
        - Software architecture patterns and principles
        - Distributed systems design
        - Cloud-native architectures
        - Domain-driven design
        - Microservices and event-driven architectures
        - Performance and scalability optimization
        
        Your role is to lead the architecture team and make critical
        design decisions that balance technical excellence with business needs.
        """
    
    def _get_team_member_prompt(self, index: int) -> str:
        """System prompts for team member agents"""
        prompts = [
            """You are a Cloud Architecture Specialist focused on:
            - Cloud-native design patterns
            - Containerization and orchestration
            - Serverless architectures
            - Multi-cloud strategies""",
            
            """You are a Data Architecture Expert focused on:
            - Data modeling and schema design
            - Database selection and optimization
            - Data flow and integration patterns
            - Event streaming architectures""",
            
            """You are a Security Architect focused on:
            - Security patterns and best practices
            - Zero-trust architecture
            - Identity and access management
            - Compliance and regulatory requirements""",
            
            """You are a Performance Engineer focused on:
            - Performance optimization patterns
            - Caching strategies
            - Load balancing and scaling
            - Monitoring and observability"""
        ]
        
        return prompts[index % len(prompts)]
    
    def _load_architecture_patterns(self) -> Dict[str, Any]:
        """Load architecture pattern knowledge base"""
        return {
            ArchitecturePattern.MICROSERVICES: {
                'characteristics': [
                    'Service autonomy',
                    'Decentralized data',
                    'Independent deployment',
                    'Technology diversity'
                ],
                'when_to_use': [
                    'Large teams',
                    'Complex domains',
                    'Varying scaling requirements',
                    'Technology flexibility needed'
                ],
                'challenges': [
                    'Distributed system complexity',
                    'Network latency',
                    'Data consistency',
                    'Operational overhead'
                ]
            },
            ArchitecturePattern.SERVERLESS: {
                'characteristics': [
                    'No server management',
                    'Event-driven execution',
                    'Automatic scaling',
                    'Pay-per-use'
                ],
                'when_to_use': [
                    'Variable workloads',
                    'Event-driven processing',
                    'Rapid development',
                    'Cost optimization'
                ],
                'challenges': [
                    'Vendor lock-in',
                    'Cold starts',
                    'Limited execution time',
                    'Debugging complexity'
                ]
            }
            # ... other patterns
        }
    
    async def _design_deployment_architecture(
        self,
        components: List[SystemComponent],
        constraints: List[Any],
        quality_attributes: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Design deployment architecture"""
        
        # Determine deployment strategy
        strategy = await self._select_deployment_strategy(
            quality_attributes,
            constraints
        )
        
        # Design infrastructure
        infrastructure = await self._design_infrastructure(
            components,
            strategy,
            quality_attributes
        )
        
        # Design networking
        networking = await self._design_networking(
            components,
            infrastructure
        )
        
        # Design monitoring and observability
        monitoring = await self._design_monitoring(
            components,
            infrastructure
        )
        
        return {
            'strategy': strategy,
            'infrastructure': infrastructure,
            'networking': networking,
            'monitoring': monitoring,
            'disaster_recovery': await self._design_disaster_recovery(
                infrastructure,
                quality_attributes
            ),
            'scaling_strategy': await self._design_scaling_strategy(
                components,
                quality_attributes
            )
        }
```
프로젝트 지식에서 Phase 3 작업지시서를 확인하고 마무리하겠습니다.다른 Phase 3 문서를 찾아보겠습니다.Phase 3 작업지시서를 3.6.2부터 마무리하겠습니다.

## 📝 세부 작업지시서 (계속)

### Task 3.6: System Design Agent 구현 (계속)

#### SubTask 3.6.2: 기술 스택 선택 시스템
**담당자**: 시니어 아키텍트  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/implementations/tech_stack_selector.py
from typing import Dict, List, Optional, Tuple
import json
from dataclasses import dataclass

@dataclass
class TechnologyOption:
    name: str
    category: str
    version: str
    pros: List[str]
    cons: List[str]
    compatibility: Dict[str, float]  # tech_name -> compatibility_score
    learning_curve: float  # 0-1
    community_support: float  # 0-1
    cost: Dict[str, float]  # license, hosting, maintenance
    maturity: float  # 0-1

class TechStackSelector:
    """Technology stack selection engine"""
    
    def __init__(self):
        self.technology_db = self._load_technology_database()
        self.compatibility_matrix = self._load_compatibility_matrix()
        
    async def select_technology_stack(
        self,
        requirements: Dict[str, Any],
        constraints: List[str],
        team_expertise: Dict[str, float]
    ) -> Dict[str, Any]:
        """Select optimal technology stack"""
        
        categories = [
            'frontend_framework',
            'backend_framework',
            'database',
            'cache',
            'message_queue',
            'api_gateway',
            'monitoring',
            'deployment'
        ]
        
        selected_stack = {}
        
        for category in categories:
            options = await self._evaluate_category_options(
                category,
                requirements,
                constraints,
                team_expertise,
                selected_stack
            )
            
            selected_stack[category] = self._select_best_option(
                options,
                requirements.get('priorities', {})
            )
        
        return {
            'selected_technologies': selected_stack,
            'total_score': await self._calculate_stack_score(selected_stack),
            'risks': await self._identify_stack_risks(selected_stack),
            'migration_complexity': await self._assess_migration_complexity(selected_stack),
            'training_requirements': await self._calculate_training_needs(
                selected_stack,
                team_expertise
            )
        }
    
    async def _evaluate_category_options(
        self,
        category: str,
        requirements: Dict[str, Any],
        constraints: List[str],
        team_expertise: Dict[str, float],
        current_stack: Dict[str, TechnologyOption]
    ) -> List[Tuple[TechnologyOption, float]]:
        """Evaluate technology options for a category"""
        
        options = self.technology_db.get(category, [])
        evaluated_options = []
        
        for option in options:
            score = await self._calculate_option_score(
                option,
                requirements,
                constraints,
                team_expertise,
                current_stack
            )
            
            if score > 0:  # Filter out incompatible options
                evaluated_options.append((option, score))
        
        return sorted(evaluated_options, key=lambda x: x[1], reverse=True)
```

#### SubTask 3.6.3: 데이터 모델 설계 도구
**담당자**: 데이터 아키텍트  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/implementations/data_model_designer.py
from typing import Dict, List, Optional, Set
from dataclasses import dataclass
from enum import Enum

class DataType(Enum):
    STRING = "string"
    INTEGER = "integer"
    FLOAT = "float"
    BOOLEAN = "boolean"
    DATE = "date"
    DATETIME = "datetime"
    JSON = "json"
    BINARY = "binary"
    UUID = "uuid"

@dataclass
class Entity:
    name: str
    description: str
    attributes: List['Attribute']
    relationships: List['Relationship']
    constraints: List['Constraint']
    indexes: List['Index']
    partitioning: Optional['PartitioningStrategy'] = None

@dataclass
class Attribute:
    name: str
    data_type: DataType
    nullable: bool = True
    default_value: Optional[Any] = None
    constraints: List[str] = None
    description: str = ""

class DataModelDesigner:
    """Data model design and optimization engine"""
    
    def __init__(self):
        self.normalization_engine = NormalizationEngine()
        self.optimization_advisor = OptimizationAdvisor()
        
    async def design_data_model(
        self,
        business_entities: List[Dict[str, Any]],
        relationships: List[Dict[str, Any]],
        performance_requirements: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Design complete data model"""
        
        # Parse business entities
        entities = await self._parse_business_entities(business_entities)
        
        # Establish relationships
        entities = await self._establish_relationships(
            entities,
            relationships
        )
        
        # Apply normalization
        normalized_model = await self.normalization_engine.normalize(
            entities,
            target_form="3NF"  # Default to 3rd Normal Form
        )
        
        # Optimize for performance
        optimized_model = await self.optimization_advisor.optimize(
            normalized_model,
            performance_requirements
        )
        
        # Generate schemas
        schemas = await self._generate_schemas(optimized_model)
        
        return {
            'logical_model': optimized_model,
            'physical_schemas': schemas,
            'migration_scripts': await self._generate_migration_scripts(schemas),
            'documentation': await self._generate_model_documentation(optimized_model),
            'performance_analysis': await self._analyze_model_performance(optimized_model)
        }
    
    async def _establish_relationships(
        self,
        entities: List[Entity],
        relationships: List[Dict[str, Any]]
    ) -> List[Entity]:
        """Establish relationships between entities"""
        
        entity_map = {e.name: e for e in entities}
        
        for rel in relationships:
            source_entity = entity_map.get(rel['source'])
            target_entity = entity_map.get(rel['target'])
            
            if source_entity and target_entity:
                relationship = Relationship(
                    name=rel['name'],
                    source=source_entity,
                    target=target_entity,
                    type=rel['type'],  # one-to-one, one-to-many, many-to-many
                    cascade=rel.get('cascade', False),
                    optional=rel.get('optional', True)
                )
                
                source_entity.relationships.append(relationship)
                
                # Add foreign key attribute if needed
                if rel['type'] in ['one-to-many', 'one-to-one']:
                    fk_attribute = Attribute(
                        name=f"{target_entity.name.lower()}_id",
                        data_type=DataType.UUID,
                        nullable=relationship.optional,
                        description=f"Foreign key to {target_entity.name}"
                    )
                    source_entity.attributes.append(fk_attribute)
        
        return entities
```

#### SubTask 3.6.4: API 설계 자동화
**담당자**: API 아키텍트  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/implementations/api_designer.py
from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum

class HTTPMethod(Enum):
    GET = "GET"
    POST = "POST"
    PUT = "PUT"
    PATCH = "PATCH"
    DELETE = "DELETE"

@dataclass
class APIEndpoint:
    path: str
    method: HTTPMethod
    description: str
    request_schema: Dict[str, Any]
    response_schema: Dict[str, Any]
    auth_required: bool = True
    rate_limit: Optional[int] = None
    cache_ttl: Optional[int] = None
    tags: List[str] = None

class APIDesigner:
    """API design and specification generator"""
    
    def __init__(self):
        self.rest_principles = RESTfulPrinciples()
        self.schema_generator = SchemaGenerator()
        self.openapi_builder = OpenAPIBuilder()
        
    async def design_api(
        self,
        data_model: Dict[str, Any],
        business_operations: List[Dict[str, Any]],
        api_style: str = "REST"  # REST, GraphQL, gRPC
    ) -> Dict[str, Any]:
        """Design complete API specification"""
        
        if api_style == "REST":
            endpoints = await self._design_rest_api(
                data_model,
                business_operations
            )
        elif api_style == "GraphQL":
            schema = await self._design_graphql_api(
                data_model,
                business_operations
            )
            return {'graphql_schema': schema}
        else:
            raise ValueError(f"Unsupported API style: {api_style}")
        
        # Generate OpenAPI specification
        openapi_spec = await self.openapi_builder.build(
            endpoints=endpoints,
            title="System API",
            version="1.0.0"
        )
        
        return {
            'endpoints': endpoints,
            'openapi_spec': openapi_spec,
            'client_sdks': await self._generate_client_sdks(openapi_spec),
            'documentation': await self._generate_api_docs(endpoints),
            'test_collection': await self._generate_test_collection(endpoints)
        }
    
    async def _design_rest_api(
        self,
        data_model: Dict[str, Any],
        operations: List[Dict[str, Any]]
    ) -> List[APIEndpoint]:
        """Design RESTful API endpoints"""
        
        endpoints = []
        
        # Generate CRUD endpoints for entities
        for entity in data_model.get('entities', []):
            base_path = f"/api/v1/{entity.name.lower()}s"
            
            # List endpoint
            endpoints.append(APIEndpoint(
                path=base_path,
                method=HTTPMethod.GET,
                description=f"List all {entity.name}s",
                request_schema={'query': self._generate_list_query_schema()},
                response_schema=self._generate_list_response_schema(entity)
            ))
            
            # Create endpoint
            endpoints.append(APIEndpoint(
                path=base_path,
                method=HTTPMethod.POST,
                description=f"Create a new {entity.name}",
                request_schema={'body': self._entity_to_schema(entity)},
                response_schema=self._entity_to_schema(entity, include_id=True)
            ))
            
            # Read endpoint
            endpoints.append(APIEndpoint(
                path=f"{base_path}/{{id}}",
                method=HTTPMethod.GET,
                description=f"Get {entity.name} by ID",
                request_schema={'path': {'id': {'type': 'string', 'format': 'uuid'}}},
                response_schema=self._entity_to_schema(entity, include_id=True)
            ))
            
            # Update endpoint
            endpoints.append(APIEndpoint(
                path=f"{base_path}/{{id}}",
                method=HTTPMethod.PUT,
                description=f"Update {entity.name}",
                request_schema={
                    'path': {'id': {'type': 'string', 'format': 'uuid'}},
                    'body': self._entity_to_schema(entity)
                },
                response_schema=self._entity_to_schema(entity, include_id=True)
            ))
            
            # Delete endpoint
            endpoints.append(APIEndpoint(
                path=f"{base_path}/{{id}}",
                method=HTTPMethod.DELETE,
                description=f"Delete {entity.name}",
                request_schema={'path': {'id': {'type': 'string', 'format': 'uuid'}}},
                response_schema={'message': {'type': 'string'}}
            ))
        
        # Add custom operation endpoints
        for operation in operations:
            endpoint = await self._design_operation_endpoint(operation)
            endpoints.append(endpoint)
        
        return endpoints
```

---

### Task 3.7: Frontend Agent 구현

#### SubTask 3.7.1: UI 컴포넌트 생성 엔진
**담당자**: 프론트엔드 아키텍트  
**예상 소요시간**: 16시간

**작업 내용**:
```typescript
// backend/src/agents/implementations/frontend_agent.ts
import { BaseAgent } from '../framework/base_agent';
import { AgnoEnabledAgent } from '../framework/agno_integration';
import { SquadEnabledAgent } from '../framework/squad_integration';

interface ComponentSpec {
  name: string;
  type: 'page' | 'component' | 'layout' | 'widget';
  framework: 'react' | 'vue' | 'angular' | 'svelte';
  props: PropDefinition[];
  state: StateDefinition[];
  methods: MethodDefinition[];
  children?: ComponentSpec[];
  styling: StylingOptions;
}

interface PropDefinition {
  name: string;
  type: string;
  required: boolean;
  default?: any;
  description: string;
}

class FrontendAgent extends AgnoEnabledAgent {
  private componentLibrary: Map<string, ComponentTemplate>;
  private designSystem: DesignSystem;
  private codeGenerator: CodeGenerator;
  
  constructor() {
    super({
      name: 'FrontendAgent',
      agnoConfig: {
        modelId: 'anthropic.claude-3-opus-v1:0',
        temperature: 0.6,
        tools: [
          'component-analyzer',
          'style-generator',
          'accessibility-checker'
        ]
      }
    });
    
    this.componentLibrary = new Map();
    this.designSystem = new DesignSystem();
    this.codeGenerator = new CodeGenerator();
  }
  
  async generateComponent(spec: ComponentSpec): Promise<GeneratedComponent> {
    // Analyze component requirements
    const analysis = await this.analyzeComponentRequirements(spec);
    
    // Select base template
    const template = this.selectComponentTemplate(analysis);
    
    // Generate component code
    const code = await this.codeGenerator.generate({
      template,
      spec,
      framework: spec.framework,
      designTokens: this.designSystem.getTokens()
    });
    
    // Add styling
    const styledComponent = await this.applyStyles(code, spec.styling);
    
    // Validate accessibility
    const a11yReport = await this.validateAccessibility(styledComponent);
    
    return {
      code: styledComponent,
      spec,
      accessibility: a11yReport,
      dependencies: this.extractDependencies(styledComponent),
      testCode: await this.generateTests(spec)
    };
  }
  
  private async analyzeComponentRequirements(
    spec: ComponentSpec
  ): Promise<ComponentAnalysis> {
    const prompt = `
    Analyze this UI component specification:
    ${JSON.stringify(spec, null, 2)}
    
    Determine:
    1. Component complexity
    2. State management needs
    3. Data flow patterns
    4. Reusability potential
    5. Performance considerations
    `;
    
    return await this.processWithAgno(prompt);
  }
  
  private async generateTests(spec: ComponentSpec): Promise<string> {
    const testTemplate = `
    import { render, screen, fireEvent } from '@testing-library/react';
    import { ${spec.name} } from './${spec.name}';
    
    describe('${spec.name}', () => {
      ${spec.props.map(prop => `
      it('should handle ${prop.name} prop', () => {
        const { container } = render(<${spec.name} ${prop.name}={${this.getTestValue(prop.type)}} />);
        expect(container).toMatchSnapshot();
      });
      `).join('\n')}
      
      ${spec.methods.map(method => `
      it('should call ${method.name} when triggered', () => {
        const mock${method.name} = jest.fn();
        render(<${spec.name} ${method.name}={mock${method.name}} />);
        // Add interaction test
        expect(mock${method.name}).toHaveBeenCalled();
      });
      `).join('\n')}
    });
    `;
    
    return testTemplate;
  }
}
```

#### SubTask 3.7.2: 상태 관리 설계 시스템
**담당자**: 프론트엔드 개발자  
**예상 소요시간**: 12시간

**작업 내용**:
```typescript
// backend/src/agents/implementations/state_management_designer.ts
interface StateManagementStrategy {
  pattern: 'redux' | 'mobx' | 'zustand' | 'context' | 'recoil' | 'valtio';
  stores: StoreDefinition[];
  actions: ActionDefinition[];
  selectors: SelectorDefinition[];
  middleware?: MiddlewareDefinition[];
}

interface StoreDefinition {
  name: string;
  initialState: Record<string, any>;
  reducers: Record<string, Function>;
  effects?: Record<string, Function>;
}

class StateManagementDesigner {
  async designStateManagement(
    appRequirements: AppRequirements
  ): Promise<StateManagementStrategy> {
    // Analyze state complexity
    const complexity = await this.analyzeStateComplexity(appRequirements);
    
    // Select appropriate pattern
    const pattern = this.selectStatePattern(complexity);
    
    // Design stores
    const stores = await this.designStores(
      appRequirements.entities,
      appRequirements.features,
      pattern
    );
    
    // Generate actions
    const actions = await this.generateActions(stores, appRequirements.operations);
    
    // Create selectors
    const selectors = await this.createSelectors(stores, appRequirements.views);
    
    // Add middleware if needed
    const middleware = complexity.requiresMiddleware ? 
      await this.designMiddleware(pattern, appRequirements) : 
      undefined;
    
    return {
      pattern,
      stores,
      actions,
      selectors,
      middleware
    };
  }
  
  private async designStores(
    entities: Entity[],
    features: Feature[],
    pattern: string
  ): Promise<StoreDefinition[]> {
    const stores: StoreDefinition[] = [];
    
    // Entity stores
    for (const entity of entities) {
      stores.push({
        name: `${entity.name}Store`,
        initialState: {
          items: [],
          loading: false,
          error: null,
          selectedId: null
        },
        reducers: this.generateEntityReducers(entity),
        effects: this.generateEntityEffects(entity)
      });
    }
    
    // Feature stores
    for (const feature of features) {
      stores.push({
        name: `${feature.name}Store`,
        initialState: feature.defaultState,
        reducers: this.generateFeatureReducers(feature),
        effects: feature.asyncOperations ? 
          this.generateFeatureEffects(feature) : 
          undefined
      });
    }
    
    // UI store
    stores.push({
      name: 'UIStore',
      initialState: {
        theme: 'light',
        sidebarOpen: true,
        notifications: [],
        modals: {}
      },
      reducers: this.generateUIReducers()
    });
    
    return stores;
  }
  
  private generateEntityReducers(entity: Entity): Record<string, Function> {
    return {
      setItems: (state, action) => {
        state.items = action.payload;
      },
      addItem: (state, action) => {
        state.items.push(action.payload);
      },
      updateItem: (state, action) => {
        const index = state.items.findIndex(item => item.id === action.payload.id);
        if (index !== -1) {
          state.items[index] = action.payload;
        }
      },
      removeItem: (state, action) => {
        state.items = state.items.filter(item => item.id !== action.payload);
      },
      setLoading: (state, action) => {
        state.loading = action.payload;
      },
      setError: (state, action) => {
        state.error = action.payload;
      },
      setSelectedId: (state, action) => {
        state.selectedId = action.payload;
      }
    };
  }
}
```

#### SubTask 3.7.3: UI 테스트 자동화 도구
**담당자**: QA 엔지니어  
**예상 소요시간**: 14시간

**작업 내용**:
```typescript
// backend/src/agents/implementations/ui_test_automation.ts
interface UITestStrategy {
  framework: 'cypress' | 'playwright' | 'selenium' | 'puppeteer';
  testSuites: TestSuite[];
  coverage: CoverageRequirements;
  ci_integration: CIConfiguration;
}

interface TestSuite {
  name: string;
  type: 'unit' | 'integration' | 'e2e' | 'visual';
  tests: TestCase[];
  setup?: SetupScript;
  teardown?: TeardownScript;
}

class UITestAutomation {
  async generateTestStrategy(
    components: ComponentSpec[],
    userFlows: UserFlow[]
  ): Promise<UITestStrategy> {
    // Analyze testing requirements
    const requirements = await this.analyzeTestRequirements(
      components,
      userFlows
    );
    
    // Select test framework
    const framework = this.selectTestFramework(requirements);
    
    // Generate test suites
    const testSuites = await this.generateTestSuites(
      components,
      userFlows,
      framework
    );
    
    // Define coverage requirements
    const coverage = this.defineCoverageRequirements(requirements);
    
    // Configure CI integration
    const ci_integration = this.configureCIPipeline(framework, testSuites);
    
    return {
      framework,
      testSuites,
      coverage,
      ci_integration
    };
  }
  
  private async generateE2ETests(
    userFlows: UserFlow[],
    framework: string
  ): Promise<TestCase[]> {
    const tests: TestCase[] = [];
    
    for (const flow of userFlows) {
      const test: TestCase = {
        name: `E2E: ${flow.name}`,
        description: flow.description,
        steps: await this.convertFlowToTestSteps(flow, framework),
        assertions: flow.expectedOutcomes.map(outcome => 
          this.generateAssertion(outcome, framework)
        ),
        data: flow.testData
      };
      
      tests.push(test);
    }
    
    return tests;
  }
  
  private async convertFlowToTestSteps(
    flow: UserFlow,
    framework: string
  ): Promise<TestStep[]> {
    const steps: TestStep[] = [];
    
    for (const action of flow.actions) {
      let stepCode: string;
      
      switch (framework) {
        case 'cypress':
          stepCode = this.generateCypressStep(action);
          break;
        case 'playwright':
          stepCode = this.generatePlaywrightStep(action);
          break;
        default:
          throw new Error(`Unsupported framework: ${framework}`);
      }
      
      steps.push({
        description: action.description,
        code: stepCode,
        wait: action.wait,
        screenshot: action.captureScreenshot
      });
    }
    
    return steps;
  }
  
  private generateCypressStep(action: UserAction): string {
    switch (action.type) {
      case 'click':
        return `cy.get('${action.selector}').click();`;
      case 'type':
        return `cy.get('${action.selector}').type('${action.value}');`;
      case 'select':
        return `cy.get('${action.selector}').select('${action.value}');`;
      case 'navigate':
        return `cy.visit('${action.url}');`;
      case 'wait':
        return `cy.wait(${action.duration});`;
      default:
        return `// TODO: Implement ${action.type} action`;
    }
  }
}
```

#### SubTask 3.7.4: 반응형 디자인 시스템
**담당자**: UI/UX 개발자  
**예상 소요시간**: 10시간

**작업 내용**:
```typescript
// backend/src/agents/implementations/responsive_design_system.ts
interface ResponsiveDesignSystem {
  breakpoints: BreakpointDefinition[];
  layouts: LayoutStrategy[];
  components: ResponsiveComponentRules[];
  utilities: ResponsiveUtilities;
}

interface BreakpointDefinition {
  name: string;
  minWidth?: number;
  maxWidth?: number;
  orientation?: 'portrait' | 'landscape';
}

class ResponsiveDesignGenerator {
  private designTokens: DesignTokens;
  private layoutEngine: LayoutEngine;
  
  async generateResponsiveSystem(
    requirements: DesignRequirements
  ): Promise<ResponsiveDesignSystem> {
    // Define breakpoints
    const breakpoints = this.defineBreakpoints(requirements.targetDevices);
    
    // Create layout strategies
    const layouts = await this.createLayoutStrategies(
      requirements.layouts,
      breakpoints
    );
    
    // Generate component rules
    const components = await this.generateComponentRules(
      requirements.components,
      breakpoints
    );
    
    // Create utility classes
    const utilities = this.createResponsiveUtilities(breakpoints);
    
    return {
      breakpoints,
      layouts,
      components,
      utilities
    };
  }
  
  private defineBreakpoints(
    targetDevices: Device[]
  ): BreakpointDefinition[] {
    const standardBreakpoints = [
      { name: 'xs', maxWidth: 575 },
      { name: 'sm', minWidth: 576, maxWidth: 767 },
      { name: 'md', minWidth: 768, maxWidth: 991 },
      { name: 'lg', minWidth: 992, maxWidth: 1199 },
      { name: 'xl', minWidth: 1200, maxWidth: 1399 },
      { name: 'xxl', minWidth: 1400 }
    ];
    
    // Add custom breakpoints for specific devices
    const customBreakpoints = targetDevices
      .filter(device => device.customBreakpoint)
      .map(device => ({
        name: device.name,
        minWidth: device.viewport.width,
        orientation: device.orientation
      }));
    
    return [...standardBreakpoints, ...customBreakpoints];
  }
  
  private async createLayoutStrategies(
    layouts: LayoutRequirement[],
    breakpoints: BreakpointDefinition[]
  ): Promise<LayoutStrategy[]> {
    const strategies: LayoutStrategy[] = [];
    
    for (const layout of layouts) {
      const strategy: LayoutStrategy = {
        name: layout.name,
        type: layout.type,
        breakpointRules: {}
      };
      
      for (const breakpoint of breakpoints) {
        strategy.breakpointRules[breakpoint.name] = 
          await this.generateLayoutRules(layout, breakpoint);
      }
      
      strategies.push(strategy);
    }
    
    return strategies;
  }
  
  private async generateLayoutRules(
    layout: LayoutRequirement,
    breakpoint: BreakpointDefinition
  ): Promise<LayoutRules> {
    const rules: LayoutRules = {
      display: this.getDisplayRule(layout, breakpoint),
      grid: layout.type === 'grid' ? 
        this.generateGridRules(layout, breakpoint) : undefined,
      flex: layout.type === 'flex' ? 
        this.generateFlexRules(layout, breakpoint) : undefined,
      spacing: this.generateSpacingRules(layout, breakpoint),
      sizing: this.generateSizingRules(layout, breakpoint)
    };
    
    return rules;
  }
}
```

---

### Task 3.8: Backend Agent 구현

#### SubTask 3.8.1: API 엔드포인트 생성기
**담당자**: 백엔드 개발자  
**예상 소요시간**: 16시간

**작업 내용**:
```python
# backend/src/agents/implementations/backend_agent.py
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import ast
import json

@dataclass
class EndpointSpecification:
    path: str
    method: str
    handler_name: str
    request_schema: Dict[str, Any]
    response_schema: Dict[str, Any]
    middleware: List[str]
    auth_required: bool
    rate_limit: Optional[int]
    cache_config: Optional[Dict[str, Any]]

class BackendAgent(AgnoEnabledAgent, SquadEnabledAgent):
    """Backend development agent for API and service implementation"""
    
    def __init__(self):
        super().__init__(
            name="BackendAgent",
            agno_config={
                'modelId': 'anthropic.claude-3-opus-v1:0',
                'temperature': 0.3,
                'tools': [
                    'code-generator',
                    'dependency-analyzer',
                    'performance-optimizer'
                ]
            }
        )
        
        self.code_generator = CodeGenerator()
        self.test_generator = TestGenerator()
        self.optimization_engine = OptimizationEngine()
    
    async def generate_api_endpoint(
        self,
        spec: EndpointSpecification,
        framework: str = "fastapi"
    ) -> Dict[str, Any]:
        """Generate complete API endpoint implementation"""
        
        # Generate handler code
        handler_code = await self._generate_handler(spec, framework)
        
        # Generate validation schemas
        schemas = await self._generate_schemas(spec)
        
        # Generate middleware
        middleware_code = await self._generate_middleware(spec.middleware)
        
        # Generate tests
        test_code = await self.test_generator.generate_endpoint_tests(spec)
        
        # Generate documentation
        docs = await self._generate_endpoint_docs(spec)
        
        return {
            'handler': handler_code,
            'schemas': schemas,
            'middleware': middleware_code,
            'tests': test_code,
            'documentation': docs,
            'deployment_config': await self._generate_deployment_config(spec)
        }
    
    async def _generate_handler(
        self,
        spec: EndpointSpecification,
        framework: str
    ) -> str:
        if framework == "fastapi":
            return await self._generate_fastapi_handler(spec)
        elif framework == "express":
            return await self._generate_express_handler(spec)
        else:
            raise ValueError(f"Unsupported framework: {framework}")
    
    async def _generate_fastapi_handler(
        self,
        spec: EndpointSpecification
    ) -> str:
        template = f'''
from fastapi import APIRouter, Depends, HTTPException, status
from typing import List, Optional
from datetime import datetime
from .schemas import {spec.handler_name}Request, {spec.handler_name}Response
from .dependencies import get_current_user, rate_limit
from .services import {spec.handler_name}Service

router = APIRouter()

@router.{spec.method.lower()}(
    "{spec.path}",
    response_model={spec.handler_name}Response,
    status_code=status.HTTP_{"201_CREATED" if spec.method == "POST" else "200_OK"}
)
async def {spec.handler_name}(
    {"request: " + spec.handler_name + "Request," if spec.method in ["POST", "PUT", "PATCH"] else ""}
    {"current_user = Depends(get_current_user)," if spec.auth_required else ""}
    {"_rate_limit = Depends(rate_limit(" + str(spec.rate_limit) + "))," if spec.rate_limit else ""}
    service: {spec.handler_name}Service = Depends()
):
    """
    {spec.handler_name} endpoint
    
    This endpoint handles {spec.method} requests to {spec.path}
    """
    try:
        result = await service.execute(
            {"request.dict()" if spec.method in ["POST", "PUT", "PATCH"] else "{}"},
            {"user_id=current_user.id" if spec.auth_required else ""}
        )
        
        return {spec.handler_name}Response(**result)
        
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"Error in {spec.handler_name}: {{str(e)}}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Internal server error"
        )
'''
        
        return template
```

#### SubTask 3.8.2: 비즈니스 로직 구현 도구
**담당자**: 백엔드 개발자  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/implementations/business_logic_generator.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import ast

@dataclass
class BusinessRule:
    name: str
    description: str
    conditions: List[Dict[str, Any]]
    actions: List[Dict[str, Any]]
    exceptions: List[Dict[str, Any]]

class BusinessLogicGenerator:
    """Generate business logic implementation from specifications"""
    
    def __init__(self):
        self.rule_engine = RuleEngine()
        self.validation_generator = ValidationGenerator()
        self.workflow_builder = WorkflowBuilder()
    
    async def generate_business_logic(
        self,
        entity: str,
        operations: List[Dict[str, Any]],
        rules: List[BusinessRule]
    ) -> Dict[str, Any]:
        """Generate complete business logic layer"""
        
        # Generate service class
        service_code = await self._generate_service_class(entity, operations)
        
        # Generate business rules
        rules_code = await self._generate_business_rules(rules)
        
        # Generate validators
        validators = await self.validation_generator.generate(entity, rules)
        
        # Generate workflows
        workflows = await self.workflow_builder.build(operations, rules)
        
        return {
            'service': service_code,
            'rules': rules_code,
            'validators': validators,
            'workflows': workflows,
            'tests': await self._generate_logic_tests(entity, operations, rules)
        }
    
    async def _generate_service_class(
        self,
        entity: str,
        operations: List[Dict[str, Any]]
    ) -> str:
        methods = []
        
        for operation in operations:
            method_code = await self._generate_service_method(
                entity,
                operation
            )
            methods.append(method_code)
        
        template = f'''
from typing import Dict, List, Optional, Any
from datetime import datetime
import logging
from .repositories import {entity}Repository
from .validators import {entity}Validator
from .events import EventPublisher
from .cache import CacheManager

logger = logging.getLogger(__name__)

class {entity}Service:
    """Business logic for {entity} operations"""
    
    def __init__(
        self,
        repository: {entity}Repository,
        validator: {entity}Validator,
        event_publisher: EventPublisher,
        cache_manager: CacheManager
    ):
        self.repository = repository
        self.validator = validator
        self.event_publisher = event_publisher
        self.cache = cache_manager
    
    {"".join(methods)}
    
    async def _apply_business_rules(
        self,
        data: Dict[str, Any],
        operation: str
    ) -> Dict[str, Any]:
        """Apply business rules to data"""
        # Rule application logic
        return data
    
    async def _publish_event(
        self,
        event_type: str,
        data: Dict[str, Any]
    ) -> None:
        """Publish domain event"""
        await self.event_publisher.publish(
            event_type=f"{entity.lower()}.{event_type}",
            payload=data,
            timestamp=datetime.utcnow()
        )
'''
        
        return template
    
    async def _generate_service_method(
        self,
        entity: str,
        operation: Dict[str, Any]
    ) -> str:
        op_name = operation['name']
        params = operation.get('parameters', [])
        
        # Generate parameter list
        param_list = ", ".join([
            f"{p['name']}: {self._python_type(p['type'])}"
            for p in params
        ])
        
        template = f'''
    async def {op_name}(self, {param_list}) -> Dict[str, Any]:
        """
        {operation.get('description', f'Execute {op_name} operation')}
        """
        try:
            # Validate input
            validated_data = await self.validator.validate_{op_name}({{
                {", ".join([f'"{p["name"]}": {p["name"]}' for p in params])}
            }})
            
            # Apply business rules
            processed_data = await self._apply_business_rules(
                validated_data,
                "{op_name}"
            )
            
            # Execute operation
            result = await self.repository.{op_name}(processed_data)
            
            # Clear relevant caches
            await self.cache.invalidate_pattern(f"{entity.lower()}:*")
            
            # Publish event
            await self._publish_event("{op_name}_completed", result)
            
            return result
            
        except ValidationError as e:
            logger.warning(f"Validation error in {op_name}: {{e}}")
            raise
        except Exception as e:
            logger.error(f"Error in {op_name}: {{e}}")
            raise
'''
        
        return template
```

#### SubTask 3.8.3: 데이터베이스 쿼리 최적화
**담당자**: 데이터베이스 전문가  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/implementations/query_optimizer.py
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass
import sqlparse
from enum import Enum

class QueryType(Enum):
    SELECT = "SELECT"
    INSERT = "INSERT"
    UPDATE = "UPDATE"
    DELETE = "DELETE"
    AGGREGATE = "AGGREGATE"

@dataclass
class QueryOptimization:
    original_query: str
    optimized_query: str
    improvements: List[str]
    estimated_performance_gain: float
    index_recommendations: List[Dict[str, Any]]

class QueryOptimizer:
    """Database query optimization engine"""
    
    def __init__(self):
        self.query_analyzer = QueryAnalyzer()
        self.index_advisor = IndexAdvisor()
        self.statistics_analyzer = StatisticsAnalyzer()
    
    async def optimize_query(
        self,
        query: str,
        schema: Dict[str, Any],
        statistics: Dict[str, Any]
    ) -> QueryOptimization:
        """Optimize database query for performance"""
        
        # Parse and analyze query
        analysis = await self.query_analyzer.analyze(query, schema)
        
        # Identify optimization opportunities
        opportunities = await self._identify_optimizations(
            analysis,
            statistics
        )
        
        # Apply optimizations
        optimized_query = query
        improvements = []
        
        for opportunity in opportunities:
            optimized_query, improvement = await self._apply_optimization(
                optimized_query,
                opportunity
            )
            improvements.append(improvement)
        
        # Recommend indexes
        index_recommendations = await self.index_advisor.recommend(
            analysis,
            schema,
            statistics
        )
        
        # Estimate performance gain
        performance_gain = await self._estimate_performance_gain(
            query,
            optimized_query,
            statistics
        )
        
        return QueryOptimization(
            original_query=query,
            optimized_query=optimized_query,
            improvements=improvements,
            estimated_performance_gain=performance_gain,
            index_recommendations=index_recommendations
        )
    
    async def _identify_optimizations(
        self,
        analysis: Dict[str, Any],
        statistics: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Identify query optimization opportunities"""
        
        opportunities = []
        
        # Check for missing indexes
        if analysis['table_scans']:
            opportunities.append({
                'type': 'missing_index',
                'tables': analysis['table_scans'],
                'impact': 'high'
            })
        
        # Check for inefficient joins
        if analysis['nested_loops']:
            opportunities.append({
                'type': 'inefficient_join',
                'joins': analysis['nested_loops'],
                'impact': 'high'
            })
        
        # Check for unnecessary subqueries
        if analysis['subqueries']:
            opportunities.append({
                'type': 'subquery_optimization',
                'subqueries': analysis['subqueries'],
                'impact': 'medium'
            })
        
        # Check for missing statistics
        if self._check_stale_statistics(statistics):
            opportunities.append({
                'type': 'update_statistics',
                'tables': analysis['tables'],
                'impact': 'medium'
            })
        
        return opportunities
    
    async def generate_repository_queries(
        self,
        entity: str,
        operations: List[str],
        database_type: str = "dynamodb"
    ) -> Dict[str, str]:
        """Generate optimized repository queries"""
        
        queries = {}
        
        if database_type == "dynamodb":
            generator = DynamoDBQueryGenerator()
        elif database_type == "postgresql":
            generator = PostgreSQLQueryGenerator()
        else:
            raise ValueError(f"Unsupported database: {database_type}")
        
        for operation in operations:
            query = await generator.generate(entity, operation)
            optimized = await self.optimize_query(
                query,
                await generator.get_schema(entity),
                await generator.get_statistics(entity)
            )
            queries[operation] = optimized.optimized_query
        
        return queries
```

#### SubTask 3.8.4: 마이크로서비스 통신 구현
**담당자**: 시스템 아키텍트  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/implementations/microservice_communication.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum
import asyncio

class CommunicationPattern(Enum):
    SYNC_HTTP = "sync_http"
    ASYNC_MESSAGE = "async_message"
    EVENT_DRIVEN = "event_driven"
    GRPC = "grpc"

@dataclass
class ServiceInterface:
    name: str
    version: str
    endpoints: List[Dict[str, Any]]
    events: List[Dict[str, Any]]
    authentication: Dict[str, Any]

class MicroserviceCommunication:
    """Microservice communication implementation generator"""
    
    def __init__(self):
        self.client_generator = ClientGenerator()
        self.event_handler_generator = EventHandlerGenerator()
        self.circuit_breaker = CircuitBreakerImplementation()
    
    async def generate_service_communication(
        self,
        service_name: str,
        dependencies: List[ServiceInterface],
        communication_patterns: Dict[str, CommunicationPattern]
    ) -> Dict[str, Any]:
        """Generate complete service communication layer"""
        
        # Generate service clients
        clients = {}
        for dep in dependencies:
            pattern = communication_patterns.get(
                dep.name,
                CommunicationPattern.SYNC_HTTP
            )
            client = await self._generate_service_client(dep, pattern)
            clients[dep.name] = client
        
        # Generate event handlers
        event_handlers = await self._generate_event_handlers(
            service_name,
            dependencies
        )
        
        # Generate message publishers
        publishers = await self._generate_message_publishers(
            service_name,
            dependencies
        )
        
        # Generate resilience patterns
        resilience = await self._generate_resilience_patterns(
            dependencies
        )
        
        return {
            'clients': clients,
            'event_handlers': event_handlers,
            'publishers': publishers,
            'resilience': resilience,
            'configuration': await self._generate_communication_config(
                service_name,
                dependencies
            )
        }
    
    async def _generate_service_client(
        self,
        service: ServiceInterface,
        pattern: CommunicationPattern
    ) -> str:
        if pattern == CommunicationPattern.SYNC_HTTP:
            return await self._generate_http_client(service)
        elif pattern == CommunicationPattern.GRPC:
            return await self._generate_grpc_client(service)
        elif pattern == CommunicationPattern.ASYNC_MESSAGE:
            return await self._generate_message_client(service)
        else:
            raise ValueError(f"Unsupported pattern: {pattern}")
    
    async def _generate_http_client(
        self,
        service: ServiceInterface
    ) -> str:
        methods = []
        
        for endpoint in service.endpoints:
            method = f'''
    async def {endpoint['operation_name']}(
        self,
        {self._generate_params(endpoint['parameters'])}
    ) -> Dict[str, Any]:
        """Call {service.name}.{endpoint['operation_name']}"""
        
        url = f"{{self.base_url}}{endpoint['path']}"
        headers = self._prepare_headers()
        
        async with self.circuit_breaker.call(
            service_name="{service.name}",
            operation="{endpoint['operation_name']}"
        ):
            try:
                response = await self.http_client.{endpoint['method'].lower()}(
                    url,
                    headers=headers,
                    {self._generate_request_body(endpoint)}
                    timeout=self.timeout
                )
                
                response.raise_for_status()
                return response.json()
                
            except httpx.TimeoutException:
                raise ServiceTimeoutError(
                    f"Timeout calling {service.name}.{endpoint['operation_name']}"
                )
            except httpx.HTTPStatusError as e:
                if e.response.status_code == 404:
                    raise ServiceNotFoundError(str(e))
                elif e.response.status_code >= 500:
                    raise ServiceUnavailableError(str(e))
                else:
                    raise ServiceClientError(str(e))
'''
            methods.append(method)
        
        template = f'''
import httpx
from typing import Dict, Any, Optional
from datetime import datetime
import logging
from .circuit_breaker import CircuitBreaker
from .auth import ServiceAuthenticator

logger = logging.getLogger(__name__)

class {service.name}Client:
    """HTTP client for {service.name} service"""
    
    def __init__(
        self,
        base_url: str,
        timeout: float = 30.0,
        circuit_breaker: CircuitBreaker = None
    ):
        self.base_url = base_url
        self.timeout = timeout
        self.circuit_breaker = circuit_breaker or CircuitBreaker()
        self.http_client = httpx.AsyncClient()
        self.authenticator = ServiceAuthenticator()
    
    def _prepare_headers(self) -> Dict[str, str]:
        """Prepare request headers with authentication"""
        return {{
            "Content-Type": "application/json",
            "Authorization": self.authenticator.get_token(),
            "X-Service-Name": "{service.name}",
            "X-Request-ID": str(uuid.uuid4())
        }}
    
    {"".join(methods)}
    
    async def close(self):
        """Close HTTP client"""
        await self.http_client.aclose()
'''
        
        return template
```

---

### Task 3.9: Data Agent 구현

#### SubTask 3.9.1: 데이터 변환 엔진
**담당자**: 데이터 엔지니어  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/implementations/data_agent.py
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass
import pandas as pd
import json

@dataclass
class TransformationRule:
    name: str
    source_field: str
    target_field: str
    transformation: Callable
    conditions: List[Dict[str, Any]]
    error_handling: str = "skip"  # skip, default, raise

class DataAgent(AgnoEnabledAgent, SquadEnabledAgent):
    """Data processing and transformation agent"""
    
    def __init__(self):
        super().__init__(
            name="DataAgent",
            agno_config={
                'modelId': 'anthropic.claude-3-opus-v1:0',
                'temperature': 0.2,
                'tools': [
                    'data-profiler',
                    'anomaly-detector',
                    'schema-validator'
                ]
            }
        )
        
        self.transformation_engine = TransformationEngine()
        self.validation_engine = DataValidationEngine()
        self.quality_analyzer = DataQualityAnalyzer()
    
    async def create_data_pipeline(
        self,
        source_schema: Dict[str, Any],
        target_schema: Dict[str, Any],
        business_rules: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Create complete data transformation pipeline"""
        
        # Analyze schemas
        schema_mapping = await self._analyze_schema_mapping(
            source_schema,
            target_schema
        )
        
        # Generate transformation rules
        transformation_rules = await self._generate_transformation_rules(
            schema_mapping,
            business_rules
        )
        
        # Create validation rules
        validation_rules = await self.validation_engine.create_rules(
            target_schema,
            business_rules
        )
        
        # Generate pipeline code
        pipeline_code = await self._generate_pipeline_code(
            transformation_rules,
            validation_rules
        )
        
        # Create data quality checks
        quality_checks = await self.quality_analyzer.generate_checks(
            source_schema,
            target_schema
        )
        
        return {
            'pipeline_code': pipeline_code,
            'transformation_rules': transformation_rules,
            'validation_rules': validation_rules,
            'quality_checks': quality_checks,
            'documentation': await self._generate_pipeline_docs(
                transformation_rules
            )
        }
    
    async def _generate_transformation_rules(
        self,
        schema_mapping: Dict[str, Any],
        business_rules: List[Dict[str, Any]]
    ) -> List[TransformationRule]:
        """Generate transformation rules from schema mapping"""
        
        rules = []
        
        for mapping in schema_mapping['field_mappings']:
            # Direct mappings
            if mapping['type'] == 'direct':
                rule = TransformationRule(
                    name=f"map_{mapping['source']}",
                    source_field=mapping['source'],
                    target_field=mapping['target'],
                    transformation=lambda x: x,
                    conditions=[]
                )
                rules.append(rule)
            
            # Type conversions
            elif mapping['type'] == 'conversion':
                rule = TransformationRule(
                    name=f"convert_{mapping['source']}",
                    source_field=mapping['source'],
                    target_field=mapping['target'],
                    transformation=self._create_type_converter(
                        mapping['source_type'],
                        mapping['target_type']
                    ),
                    conditions=[]
                )
                rules.append(rule)
            
            # Complex transformations
            elif mapping['type'] == 'complex':
                rule = await self._generate_complex_transformation(
                    mapping,
                    business_rules
                )
                rules.append(rule)
        
        # Add business rule transformations
        for br in business_rules:
            if br['type'] == 'transformation':
                rule = await self._create_business_rule_transformation(br)
                rules.append(rule)
        
        return rules
    
    async def _generate_pipeline_code(
        self,
        transformation_rules: List[TransformationRule],
        validation_rules: List[Any]
    ) -> str:
        """Generate complete pipeline implementation"""
        
        template = f'''
from typing import Dict, List, Any, Optional
import pandas as pd
import logging
from datetime import datetime
from .transformations import TransformationEngine
from .validators import DataValidator
from .monitoring import PipelineMonitor

logger = logging.getLogger(__name__)

class DataPipeline:
    """Generated data transformation pipeline"""
    
    def __init__(self):
        self.transformer = TransformationEngine()
        self.validator = DataValidator()
        self.monitor = PipelineMonitor()
        self.transformation_rules = {self._serialize_rules(transformation_rules)}
        self.validation_rules = {json.dumps(validation_rules, indent=2)}
    
    async def process(
        self,
        input_data: pd.DataFrame,
        context: Optional[Dict[str, Any]] = None
    ) -> pd.DataFrame:
        """Process data through the pipeline"""
        
        start_time = datetime.utcnow()
        self.monitor.start_pipeline_run(context)
        
        try:
            # Data quality checks
            quality_report = await self._check_input_quality(input_data)
            if not quality_report['passed']:
                raise DataQualityError(quality_report['issues'])
            
            # Apply transformations
            transformed_data = input_data.copy()
            for rule in self.transformation_rules:
                transformed_data = await self._apply_transformation(
                    transformed_data,
                    rule
                )
            
            # Validate output
            validation_result = await self.validator.validate(
                transformed_data,
                self.validation_rules
            )
            
            if not validation_result['valid']:
                raise ValidationError(validation_result['errors'])
            
            # Record metrics
            self.monitor.record_success(
                rows_processed=len(transformed_data),
                duration=(datetime.utcnow() - start_time).total_seconds()
            )
            
            return transformed_data
            
        except Exception as e:
            self.monitor.record_failure(str(e))
            raise
    
    async def _apply_transformation(
        self,
        data: pd.DataFrame,
        rule: Dict[str, Any]
    ) -> pd.DataFrame:
        """Apply single transformation rule"""
        
        try:
            if self._check_conditions(data, rule.get('conditions', [])):
                data[rule['target_field']] = data[rule['source_field']].apply(
                    rule['transformation']
                )
            
            return data
            
        except Exception as e:
            if rule.get('error_handling') == 'raise':
                raise
            elif rule.get('error_handling') == 'default':
                data[rule['target_field']] = rule.get('default_value')
            # else skip
            
            logger.warning(f"Transformation error in {{rule['name']}}: {{e}}")
            return data
'''
        
        return template
```

#### SubTask 3.9.2: 데이터 품질 모니터링
**담당자**: 데이터 품질 전문가  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/implementations/data_quality_monitor.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum
import numpy as np

class QualityMetricType(Enum):
    COMPLETENESS = "completeness"
    ACCURACY = "accuracy"
    CONSISTENCY = "consistency"
    VALIDITY = "validity"
    UNIQUENESS = "uniqueness"
    TIMELINESS = "timeliness"

@dataclass
class QualityRule:
    name: str
    metric_type: QualityMetricType
    threshold: float
    columns: List[str]
    condition: Optional[str] = None
    severity: str = "warning"  # warning, error, critical

class DataQualityMonitor:
    """Monitor and ensure data quality"""
    
    def __init__(self):
        self.metric_calculators = self._initialize_calculators()
        self.anomaly_detector = AnomalyDetector()
        self.trend_analyzer = TrendAnalyzer()
    
    async def create_quality_profile(
        self,
        data_sample: pd.DataFrame,
        business_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Create comprehensive data quality profile"""
        
        # Basic statistics
        basic_stats = await self._calculate_basic_statistics(data_sample)
        
        # Quality metrics
        quality_metrics = await self._calculate_quality_metrics(
            data_sample,
            business_context
        )
        
        # Anomaly detection
        anomalies = await self.anomaly_detector.detect(data_sample)
        
        # Generate quality rules
        quality_rules = await self._generate_quality_rules(
            basic_stats,
            quality_metrics,
            business_context
        )
        
        # Create monitoring dashboard config
        dashboard_config = await self._create_dashboard_config(
            quality_metrics,
            anomalies
        )
        
        return {
            'profile': {
                'statistics': basic_stats,
                'quality_metrics': quality_metrics,
                'anomalies': anomalies
            },
            'rules': quality_rules,
            'monitoring': {
                'dashboard': dashboard_config,
                'alerts': await self._generate_alert_config(quality_rules)
            }
        }
    
    async def _calculate_quality_metrics(
        self,
        data: pd.DataFrame,
        context: Dict[str, Any]
    ) -> Dict[str, float]:
        """Calculate comprehensive quality metrics"""
        
        metrics = {}
        
        # Completeness
        metrics['completeness'] = {
            col: 1 - (data[col].isna().sum() / len(data))
            for col in data.columns
        }
        
        # Validity
        validity_rules = context.get('validity_rules', {})
        for col, rules in validity_rules.items():
            if col in data.columns:
                valid_count = sum(
                    self._check_validity(data[col], rules)
                )
                metrics[f'validity_{col}'] = valid_count / len(data)
        
        # Consistency
        consistency_rules = context.get('consistency_rules', [])
        for rule in consistency_rules:
            consistent_count = sum(
                self._check_consistency(data, rule)
            )
            metrics[f'consistency_{rule["name"]}'] = consistent_count / len(data)
        
        # Uniqueness
        for col in context.get('unique_columns', []):
            if col in data.columns:
                metrics[f'uniqueness_{col}'] = (
                    data[col].nunique() / len(data)
                )
        
        # Timeliness
        timestamp_cols = context.get('timestamp_columns', [])
        for col in timestamp_cols:
            if col in data.columns:
                metrics[f'timeliness_{col}'] = await self._calculate_timeliness(
                    data[col]
                )
        
        return metrics
    
    async def generate_quality_monitoring_code(
        self,
        quality_rules: List[QualityRule],
        alert_config: Dict[str, Any]
    ) -> str:
        """Generate quality monitoring implementation"""
        
        template = f'''
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import logging
from .metrics import QualityMetrics
from .alerts import AlertManager

logger = logging.getLogger(__name__)

class DataQualityMonitor:
    """Real-time data quality monitoring"""
    
    def __init__(self, alert_manager: AlertManager):
        self.alert_manager = alert_manager
        self.quality_rules = {json.dumps([r.__dict__ for r in quality_rules], indent=2)}
        self.metrics = QualityMetrics()
        self.history = []
    
    async def monitor_batch(
        self,
        data: pd.DataFrame,
        batch_id: str
    ) -> Dict[str, Any]:
        """Monitor quality of a data batch"""
        
        results = {{
            'batch_id': batch_id,
            'timestamp': datetime.utcnow(),
            'row_count': len(data),
            'metrics': {{}},
            'violations': []
        }}
        
        # Check each quality rule
        for rule in self.quality_rules:
            metric_value = await self._calculate_metric(
                data,
                rule
            )
            
            results['metrics'][rule['name']] = metric_value
            
            # Check threshold
            if metric_value < rule['threshold']:
                violation = {{
                    'rule': rule['name'],
                    'metric': metric_value,
                    'threshold': rule['threshold'],
                    'severity': rule['severity']
                }}
                results['violations'].append(violation)
                
                # Send alert if needed
                if rule['severity'] in ['error', 'critical']:
                    await self.alert_manager.send_quality_alert(
                        violation,
                        batch_id
                    )
        
        # Store history
        self.history.append(results)
        if len(self.history) > 1000:  # Keep last 1000 batches
            self.history.pop(0)
        
        # Detect trends
        trends = await self._detect_quality_trends()
        if trends['degrading']:
            await self.alert_manager.send_trend_alert(trends)
        
        return results
    
    async def _calculate_metric(
        self,
        data: pd.DataFrame,
        rule: Dict[str, Any]
    ) -> float:
        """Calculate quality metric based on rule"""
        
        metric_type = rule['metric_type']
        columns = rule['columns']
        
        if metric_type == 'completeness':
            return self._calculate_completeness(data[columns])
        elif metric_type == 'accuracy':
            return await self._calculate_accuracy(data, columns, rule)
        elif metric_type == 'consistency':
            return self._calculate_consistency(data, rule)
        elif metric_type == 'validity':
            return self._calculate_validity(data[columns], rule)
        elif metric_type == 'uniqueness':
            return self._calculate_uniqueness(data[columns])
        elif metric_type == 'timeliness':
            return await self._calculate_timeliness(data[columns])
        else:
            raise ValueError(f"Unknown metric type: {{metric_type}}")
'''
        
        return template
```

#### SubTask 3.9.3: ETL 파이프라인 생성기
**담당자**: ETL 개발자  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/implementations/etl_pipeline_generator.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

class ETLStageType(Enum):
    EXTRACT = "extract"
    TRANSFORM = "transform"
    LOAD = "load"
    VALIDATE = "validate"
    MONITOR = "monitor"

@dataclass
class ETLStage:
    name: str
    type: ETLStageType
    config: Dict[str, Any]
    dependencies: List[str]
    error_handling: Dict[str, Any]
    retry_config: Dict[str, Any]

class ETLPipelineGenerator:
    """Generate complete ETL pipeline implementations"""
    
    def __init__(self):
        self.extractor_factory = ExtractorFactory()
        self.transformer_factory = TransformerFactory()
        self.loader_factory = LoaderFactory()
    
    async def generate_etl_pipeline(
        self,
        source_configs: List[Dict[str, Any]],
        transformation_rules: List[Dict[str, Any]],
        target_config: Dict[str, Any],
        orchestration: str = "airflow"  # airflow, prefect, dagster
    ) -> Dict[str, Any]:
        """Generate complete ETL pipeline"""
        
        # Design pipeline stages
        stages = await self._design_pipeline_stages(
            source_configs,
            transformation_rules,
            target_config
        )
        
        # Generate stage implementations
        stage_implementations = {}
        for stage in stages:
            implementation = await self._generate_stage_implementation(stage)
            stage_implementations[stage.name] = implementation
        
        # Generate orchestration code
        orchestration_code = await self._generate_orchestration(
            stages,
            orchestration
        )
        
        # Generate monitoring and alerting
        monitoring = await self._generate_monitoring_config(stages)
        
        # Generate tests
        tests = await self._generate_pipeline_tests(stages)
        
        return {
            'stages': stage_implementations,
            'orchestration': orchestration_code,
            'monitoring': monitoring,
            'tests': tests,
            'deployment': await self._generate_deployment_config(
                orchestration
            )
        }
    
    async def _generate_airflow_dag(
        self,
        stages: List[ETLStage]
    ) -> str:
        """Generate Airflow DAG"""
        
        # Import statements
        imports = self._generate_airflow_imports(stages)
        
        # DAG definition
        dag_config = {
            'dag_id': 'generated_etl_pipeline',
            'default_args': {
                'owner': 'data-team',
                'depends_on_past': False,
                'start_date': 'datetime(2024, 1, 1)',
                'email_on_failure': True,
                'email_on_retry': False,
                'retries': 2,
                'retry_delay': 'timedelta(minutes=5)'
            },
            'schedule_interval': '@daily',
            'catchup': False
        }
        
        # Generate task definitions
        task_definitions = []
        for stage in stages:
            task_def = await self._generate_airflow_task(stage)
            task_definitions.append(task_def)
        
        # Generate dependencies
        dependencies = self._generate_task_dependencies(stages)
        
        template = f'''
{imports}

default_args = {dag_config['default_args']}

dag = DAG(
    '{dag_config['dag_id']}',
    default_args=default_args,
    schedule_interval='{dag_config['schedule_interval']}',
    catchup={dag_config['catchup']},
    tags=['etl', 'generated']
)

# Task definitions
{chr(10).join(task_definitions)}

# Task dependencies
{dependencies}

# Add data quality checks
quality_check = DataQualityOperator(
    task_id='data_quality_check',
    dag=dag,
    checks={{
        'row_count_check': {{
            'check_statement': 'SELECT COUNT(*) FROM target_table',
            'pass_value': lambda x: x > 0
        }},
        'duplicate_check': {{
            'check_statement': '''
                SELECT COUNT(*) - COUNT(DISTINCT id) as duplicates 
                FROM target_table
            ''',
            'pass_value': lambda x: x == 0
        }}
    }}
)

# Final task dependencies
transform_task >> load_task >> quality_check
'''
        
        return template
    
    async def _generate_airflow_task(
        self,
        stage: ETLStage
    ) -> str:
        """Generate Airflow task definition"""
        
        if stage.type == ETLStageType.EXTRACT:
            return f'''
# Extract from {stage.config['source_name']}
extract_{stage.name} = PythonOperator(
    task_id='extract_{stage.name}',
    python_callable=extract_{stage.config['source_type']},
    op_kwargs={{
        'source_config': {stage.config},
        'output_path': '/tmp/extracted_{stage.name}'
    }},
    dag=dag
)'''
        
        elif stage.type == ETLStageType.TRANSFORM:
            return f'''
# Transform {stage.name}
transform_{stage.name} = PythonOperator(
    task_id='transform_{stage.name}',
    python_callable=apply_transformations,
    op_kwargs={{
        'input_path': '/tmp/extracted_{{{{ ti.xcom_pull(task_ids="extract_{stage.config['input_stage']}") }}}}',
        'transformations': {stage.config['transformations']},
        'output_path': '/tmp/transformed_{stage.name}'
    }},
    dag=dag
)'''
        
        elif stage.type == ETLStageType.LOAD:
            return f'''
# Load to {stage.config['target_name']}
load_{stage.name} = PythonOperator(
    task_id='load_{stage.name}',
    python_callable=load_to_{stage.config['target_type']},
    op_kwargs={{
        'input_path': '/tmp/transformed_{{{{ ti.xcom_pull(task_ids="transform_{stage.config['input_stage']}") }}}}',
        'target_config': {stage.config},
        'load_mode': '{stage.config.get('load_mode', 'append')}'
    }},
    dag=dag
)'''
```

#### SubTask 3.9.4: 실시간 데이터 스트리밍
**담당자**: 스트리밍 엔지니어  
**예상 소요시간**: 16시간

**작업 내용**:
```python
# backend/src/agents/implementations/streaming_processor.py
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass
import asyncio
from enum import Enum

class StreamingEngine(Enum):
    KAFKA = "kafka"
    KINESIS = "kinesis"
    PULSAR = "pulsar"
    REDIS_STREAMS = "redis_streams"

@dataclass
class StreamProcessor:
    name: str
    input_topics: List[str]
    output_topics: List[str]
    processing_function: Callable
    window_config: Optional[Dict[str, Any]] = None
    state_backend: Optional[str] = None

class StreamingDataProcessor:
    """Real-time data streaming processor generator"""
    
    def __init__(self):
        self.processor_factory = ProcessorFactory()
        self.window_manager = WindowManager()
        self.state_manager = StateManager()
    
    async def generate_streaming_pipeline(
        self,
        stream_config: Dict[str, Any],
        processing_logic: List[Dict[str, Any]],
        output_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate complete streaming pipeline"""
        
        engine = StreamingEngine(stream_config['engine'])
        
        # Generate processor implementation
        processor_code = await self._generate_processor(
            engine,
            stream_config,
            processing_logic,
            output_config
        )
        
        # Generate state management
        state_code = None
        if any(p.get('stateful', False) for p in processing_logic):
            state_code = await self._generate_state_management(
                engine,
                processing_logic
            )
        
        # Generate windowing logic
        window_code = None
        if any(p.get('windowed', False) for p in processing_logic):
            window_code = await self._generate_windowing(
                engine,
                processing_logic
            )
        
        # Generate monitoring
        monitoring = await self._generate_streaming_monitoring(
            engine,
            stream_config
        )
        
        return {
            'processor': processor_code,
            'state_management': state_code,
            'windowing': window_code,
            'monitoring': monitoring,
            'deployment': await self._generate_streaming_deployment(
                engine,
                stream_config
            )
        }
    
    async def _generate_kafka_processor(
        self,
        config: Dict[str, Any],
        processing_logic: List[Dict[str, Any]]
    ) -> str:
        """Generate Kafka Streams processor"""
        
        template = f'''
from kafka import KafkaConsumer, KafkaProducer
from kafka.errors import KafkaError
import json
import logging
from typing import Dict, Any, Optional
from datetime import datetime
import asyncio

logger = logging.getLogger(__name__)

class KafkaStreamProcessor:
    """Real-time Kafka stream processor"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.consumer = KafkaConsumer(
            *{config['input_topics']},
            bootstrap_servers={config['bootstrap_servers']},
            auto_offset_reset='earliest',
            enable_auto_commit=True,
            group_id={config['consumer_group']},
            value_deserializer=lambda x: json.loads(x.decode('utf-8'))
        )
        
        self.producer = KafkaProducer(
            bootstrap_servers={config['bootstrap_servers']},
            value_serializer=lambda x: json.dumps(x).encode('utf-8'),
            compression_type='gzip'
        )
        
        self.processing_functions = self._initialize_processors()
        self.metrics = StreamMetrics()
    
    def _initialize_processors(self) -> Dict[str, Callable]:
        """Initialize processing functions"""
        processors = {{}}
        
        {self._generate_processor_initialization(processing_logic)}
        
        return processors
    
    async def start(self):
        """Start processing messages"""
        logger.info("Starting Kafka stream processor")
        
        try:
            for message in self.consumer:
                await self._process_message(message)
                
        except Exception as e:
            logger.error(f"Error in stream processing: {{e}}")
            raise
        finally:
            self.cleanup()
    
    async def _process_message(self, message):
        """Process individual message"""
        
        start_time = datetime.utcnow()
        
        try:
            # Extract message data
            data = message.value
            topic = message.topic
            
            # Apply processing logic
            processed_data = data
            for processor_name, processor_func in self.processing_functions.items():
                if self._should_apply_processor(processor_name, topic):
                    processed_data = await processor_func(processed_data)
            
            # Send to output topic
            output_topic = self._determine_output_topic(processed_data)
            self.producer.send(output_topic, processed_data)
            
            # Record metrics
            self.metrics.record_success(
                processing_time=(datetime.utcnow() - start_time).total_seconds(),
                message_size=len(json.dumps(processed_data))
            )
            
        except Exception as e:
            logger.error(f"Error processing message: {{e}}")
            self.metrics.record_failure(str(e))
            
            # Send to error topic
            self.producer.send(
                {config.get('error_topic', 'errors')},
                {{
                    'original_message': message.value,
                    'error': str(e),
                    'timestamp': datetime.utcnow().isoformat()
                }}
            )
    
    def cleanup(self):
        """Cleanup resources"""
        self.consumer.close()
        self.producer.close()
        logger.info("Stream processor shutdown complete")
'''
        
        return template
    
    async def _generate_windowing(
        self,
        engine: StreamingEngine,
        processing_logic: List[Dict[str, Any]]
    ) -> str:
        """Generate windowing logic"""
        
        window_types = set()
        for logic in processing_logic:
            if logic.get('windowed'):
                window_types.add(logic['window_type'])
        
        if engine == StreamingEngine.KAFKA:
            return self._generate_kafka_windowing(window_types)
        elif engine == StreamingEngine.KINESIS:
            return self._generate_kinesis_windowing(window_types)
        else:
            raise ValueError(f"Windowing not supported for {engine}")
```
### Task 3.10: Test Agent 구현

#### SubTask 3.10.1: 테스트 케이스 자동 생성
**담당자**: 테스트 자동화 엔지니어  
**예상 소요시간**: 16시간

**작업 내용**:
```python
# backend/src/agents/implementations/test_agent.py
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import ast

class TestType(Enum):
    UNIT = "unit"
    INTEGRATION = "integration"
    E2E = "e2e"
    PERFORMANCE = "performance"
    SECURITY = "security"
    ACCESSIBILITY = "accessibility"

@dataclass
class TestCase:
    id: str
    name: str
    type: TestType
    description: str
    setup: Optional[str]
    test_steps: List[Dict[str, Any]]
    assertions: List[Dict[str, Any]]
    teardown: Optional[str]
    tags: List[str]
    priority: int

class TestAgent(AgnoEnabledAgent, SquadEnabledAgent):
    """Automated testing and quality assurance agent"""
    
    def __init__(self):
        super().__init__(
            name="TestAgent",
            agno_config={
                'modelId': 'anthropic.claude-3-opus-v1:0',
                'temperature': 0.3,
                'tools': [
                    'code-analyzer',
                    'test-generator',
                    'coverage-analyzer'
                ]
            }
        )
        
        self.test_generator = TestCaseGenerator()
        self.coverage_analyzer = CoverageAnalyzer()
        self.test_optimizer = TestOptimizer()
    
    async def generate_test_suite(
        self,
        code_base: Dict[str, Any],
        requirements: List[Dict[str, Any]],
        coverage_target: float = 0.8
    ) -> Dict[str, Any]:
        """Generate comprehensive test suite"""
        
        # Analyze code structure
        code_analysis = await self._analyze_code_structure(code_base)
        
        # Generate test cases for each component
        test_cases = []
        
        # Unit tests
        unit_tests = await self._generate_unit_tests(
            code_analysis['functions'],
            code_analysis['classes']
        )
        test_cases.extend(unit_tests)
        
        # Integration tests
        integration_tests = await self._generate_integration_tests(
            code_analysis['modules'],
            code_analysis['dependencies']
        )
        test_cases.extend(integration_tests)
        
        # E2E tests from requirements
        e2e_tests = await self._generate_e2e_tests(requirements)
        test_cases.extend(e2e_tests)
        
        # Optimize test suite
        optimized_suite = await self.test_optimizer.optimize(
            test_cases,
            coverage_target
        )
        
        # Generate test code
        test_implementations = await self._generate_test_implementations(
            optimized_suite
        )
        
        return {
            'test_cases': optimized_suite,
            'implementations': test_implementations,
            'coverage_analysis': await self.coverage_analyzer.analyze(
                code_base,
                optimized_suite
            ),
            'execution_plan': await self._create_execution_plan(optimized_suite)
        }
    
    async def _generate_unit_tests(
        self,
        functions: List[Dict[str, Any]],
        classes: List[Dict[str, Any]]
    ) -> List[TestCase]:
        """Generate unit tests for functions and classes"""
        
        test_cases = []
        
        # Function tests
        for func in functions:
            # Analyze function signature and behavior
            analysis = await self._analyze_function(func)
            
            # Generate test cases for different scenarios
            test_scenarios = [
                'happy_path',
                'edge_cases',
                'error_cases',
                'boundary_values'
            ]
            
            for scenario in test_scenarios:
                test_case = await self._create_function_test(
                    func,
                    analysis,
                    scenario
                )
                if test_case:
                    test_cases.append(test_case)
        
        # Class tests
        for cls in classes:
            # Test initialization
            init_tests = await self._generate_initialization_tests(cls)
            test_cases.extend(init_tests)
            
            # Test methods
            for method in cls['methods']:
                method_tests = await self._generate_method_tests(
                    cls,
                    method
                )
                test_cases.extend(method_tests)
            
            # Test state transitions
            state_tests = await self._generate_state_tests(cls)
            test_cases.extend(state_tests)
        
        return test_cases
    
    async def _create_function_test(
        self,
        func: Dict[str, Any],
        analysis: Dict[str, Any],
        scenario: str
    ) -> Optional[TestCase]:
        """Create test case for a function"""
        
        prompt = f"""
        Generate a {scenario} test case for this function:
        
        Function: {func['name']}
        Parameters: {func['parameters']}
        Return type: {func['return_type']}
        Description: {func.get('docstring', 'No description')}
        
        Analysis: {analysis}
        
        Create test with:
        1. Appropriate test data
        2. Clear assertions
        3. Edge case handling
        """
        
        test_spec = await self.processWithAgno(prompt)
        
        if not test_spec:
            return None
        
        return TestCase(
            id=f"test_{func['name']}_{scenario}",
            name=f"Test {func['name']} - {scenario.replace('_', ' ').title()}",
            type=TestType.UNIT,
            description=test_spec['description'],
            setup=test_spec.get('setup'),
            test_steps=[
                {
                    'action': 'call_function',
                    'function': func['name'],
                    'arguments': test_spec['test_data']
                }
            ],
            assertions=test_spec['assertions'],
            teardown=test_spec.get('teardown'),
            tags=['unit', func['module'], scenario],
            priority=test_spec.get('priority', 2)
        )
```

#### SubTask 3.10.2: 테스트 실행 오케스트레이션
**담당자**: QA 리드  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/implementations/test_orchestrator.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
import asyncio

@dataclass
class TestExecutionPlan:
    phases: List['TestPhase']
    parallelization_strategy: Dict[str, Any]
    resource_allocation: Dict[str, Any]
    failure_strategy: str  # fail-fast, fail-safe, continue

@dataclass
class TestPhase:
    name: str
    test_groups: List['TestGroup']
    dependencies: List[str]
    timeout: int
    retry_policy: Dict[str, Any]

class TestOrchestrator:
    """Orchestrate test execution across different environments"""
    
    def __init__(self):
        self.execution_engine = TestExecutionEngine()
        self.resource_manager = ResourceManager()
        self.result_aggregator = ResultAggregator()
    
    async def create_execution_plan(
        self,
        test_suite: List[TestCase],
        environments: List[Dict[str, Any]],
        constraints: Dict[str, Any]
    ) -> TestExecutionPlan:
        """Create optimized test execution plan"""
        
        # Group tests by type and dependencies
        test_groups = await self._group_tests(test_suite)
        
        # Create execution phases
        phases = await self._create_execution_phases(
            test_groups,
            constraints
        )
        
        # Determine parallelization strategy
        parallelization = await self._determine_parallelization(
            phases,
            environments,
            constraints.get('max_parallel_jobs', 10)
        )
        
        # Allocate resources
        resources = await self.resource_manager.allocate(
            phases,
            environments
        )
        
        return TestExecutionPlan(
            phases=phases,
            parallelization_strategy=parallelization,
            resource_allocation=resources,
            failure_strategy=constraints.get('failure_strategy', 'fail-fast')
        )
    
    async def execute_test_plan(
        self,
        plan: TestExecutionPlan,
        environments: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Execute test plan across environments"""
        
        results = {
            'start_time': datetime.utcnow(),
            'phases': {},
            'summary': {}
        }
        
        # Execute phases in order
        for phase in plan.phases:
            # Check dependencies
            if not await self._check_phase_dependencies(
                phase,
                results['phases']
            ):
                results['phases'][phase.name] = {
                    'status': 'skipped',
                    'reason': 'dependency_failed'
                }
                continue
            
            # Execute phase
            phase_result = await self._execute_phase(
                phase,
                environments,
                plan.parallelization_strategy
            )
            
            results['phases'][phase.name] = phase_result
            
            # Check failure strategy
            if phase_result['status'] == 'failed':
                if plan.failure_strategy == 'fail-fast':
                    break
        
        # Aggregate results
        results['end_time'] = datetime.utcnow()
        results['summary'] = await self.result_aggregator.aggregate(
            results['phases']
        )
        
        return results
    
    async def _execute_phase(
        self,
        phase: TestPhase,
        environments: List[Dict[str, Any]],
        parallelization: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Execute single test phase"""
        
        phase_result = {
            'start_time': datetime.utcnow(),
            'groups': {}
        }
        
        # Determine execution strategy
        max_parallel = parallelization.get(phase.name, {}).get('max_parallel', 1)
        
        if max_parallel > 1:
            # Parallel execution
            with ThreadPoolExecutor(max_workers=max_parallel) as executor:
                futures = []
                
                for group in phase.test_groups:
                    for env in environments:
                        if self._should_run_on_environment(group, env):
                            future = executor.submit(
                                asyncio.run,
                                self._execute_test_group(group, env)
                            )
                            futures.append((group.name, env['name'], future))
                
                # Collect results
                for group_name, env_name, future in futures:
                    key = f"{group_name}_{env_name}"
                    try:
                        result = future.result(timeout=phase.timeout)
                        phase_result['groups'][key] = result
                    except Exception as e:
                        phase_result['groups'][key] = {
                            'status': 'error',
                            'error': str(e)
                        }
        else:
            # Sequential execution
            for group in phase.test_groups:
                for env in environments:
                    if self._should_run_on_environment(group, env):
                        key = f"{group.name}_{env['name']}"
                        phase_result['groups'][key] = await self._execute_test_group(
                            group,
                            env
                        )
        
        phase_result['end_time'] = datetime.utcnow()
        phase_result['status'] = self._determine_phase_status(
            phase_result['groups']
        )
        
        return phase_result
```

#### SubTask 3.10.3: 테스트 커버리지 분석
**담당자**: 품질 분석가  
**예상 소요시간**: 10시간

**작업 내용**:
```python
# backend/src/agents/implementations/coverage_analyzer.py
from typing import Dict, List, Any, Set, Tuple
from dataclasses import dataclass
import ast

@dataclass
class CoverageMetrics:
    line_coverage: float
    branch_coverage: float
    function_coverage: float
    class_coverage: float
    uncovered_lines: List[Tuple[str, int]]
    uncovered_branches: List[Dict[str, Any]]
    complexity_metrics: Dict[str, int]

class CoverageAnalyzer:
    """Analyze and improve test coverage"""
    
    def __init__(self):
        self.ast_analyzer = ASTAnalyzer()
        self.path_analyzer = PathAnalyzer()
        self.mutation_tester = MutationTester()
    
    async def analyze_coverage(
        self,
        code_base: Dict[str, Any],
        test_suite: List[TestCase]
    ) -> Dict[str, Any]:
        """Perform comprehensive coverage analysis"""
        
        # Parse code structure
        code_structure = await self.ast_analyzer.parse_codebase(code_base)
        
        # Simulate test execution to determine coverage
        coverage_data = await self._simulate_coverage(
            code_structure,
            test_suite
        )
        
        # Calculate metrics
        metrics = await self._calculate_coverage_metrics(
            code_structure,
            coverage_data
        )
        
        # Identify gaps
        coverage_gaps = await self._identify_coverage_gaps(
            code_structure,
            coverage_data
        )
        
        # Generate recommendations
        recommendations = await self._generate_coverage_recommendations(
            coverage_gaps,
            code_structure
        )
        
        # Mutation testing results
        mutation_results = await self.mutation_tester.analyze(
            code_base,
            test_suite
        )
        
        return {
            'metrics': metrics,
            'gaps': coverage_gaps,
            'recommendations': recommendations,
            'mutation_testing': mutation_results,
            'report': await self._generate_coverage_report(
                metrics,
                coverage_gaps
            )
        }
    
    async def _calculate_coverage_metrics(
        self,
        code_structure: Dict[str, Any],
        coverage_data: Dict[str, Any]
    ) -> CoverageMetrics:
        """Calculate detailed coverage metrics"""
        
        # Line coverage
        total_lines = sum(len(file['lines']) for file in code_structure['files'])
        covered_lines = sum(
            len(coverage_data['covered_lines'].get(file['path'], set()))
            for file in code_structure['files']
        )
        line_coverage = covered_lines / total_lines if total_lines > 0 else 0
        
        # Branch coverage
        total_branches = sum(
            len(file['branches'])
            for file in code_structure['files']
        )
        covered_branches = sum(
            len(coverage_data['covered_branches'].get(file['path'], set()))
            for file in code_structure['files']
        )
        branch_coverage = covered_branches / total_branches if total_branches > 0 else 0
        
        # Function coverage
        total_functions = sum(
            len(file['functions'])
            for file in code_structure['files']
        )
        covered_functions = len(coverage_data['covered_functions'])
        function_coverage = covered_functions / total_functions if total_functions > 0 else 0
        
        # Class coverage
        total_classes = sum(
            len(file['classes'])
            for file in code_structure['files']
        )
        covered_classes = len(coverage_data['covered_classes'])
        class_coverage = covered_classes / total_classes if total_classes > 0 else 0
        
        # Uncovered elements
        uncovered_lines = []
        uncovered_branches = []
        
        for file in code_structure['files']:
            file_covered = coverage_data['covered_lines'].get(file['path'], set())
            for line_num in file['lines']:
                if line_num not in file_covered:
                    uncovered_lines.append((file['path'], line_num))
            
            file_branches_covered = coverage_data['covered_branches'].get(
                file['path'],
                set()
            )
            for branch in file['branches']:
                if branch['id'] not in file_branches_covered:
                    uncovered_branches.append({
                        'file': file['path'],
                        'line': branch['line'],
                        'type': branch['type'],
                        'condition': branch.get('condition')
                    })
        
        return CoverageMetrics(
            line_coverage=line_coverage,
            branch_coverage=branch_coverage,
            function_coverage=function_coverage,
            class_coverage=class_coverage,
            uncovered_lines=uncovered_lines,
            uncovered_branches=uncovered_branches,
            complexity_metrics=await self._calculate_complexity_metrics(
                code_structure
            )
        )
    
    async def generate_coverage_improvement_plan(
        self,
        current_coverage: Dict[str, Any],
        target_coverage: float
    ) -> Dict[str, Any]:
        """Generate plan to improve test coverage"""
        
        template = f'''
# Test Coverage Improvement Plan

## Current Status
- Line Coverage: {current_coverage['metrics'].line_coverage:.1%}
- Branch Coverage: {current_coverage['metrics'].branch_coverage:.1%}
- Function Coverage: {current_coverage['metrics'].function_coverage:.1%}
- Target: {target_coverage:.0%}

## Priority Areas

### Critical Uncovered Code
{self._format_critical_gaps(current_coverage['gaps'])}

### Recommended Test Cases
{self._format_test_recommendations(current_coverage['recommendations'])}

## Implementation Strategy

### Phase 1: High-Risk Areas (Week 1)
- Focus on uncovered error handling paths
- Add tests for critical business logic
- Estimated coverage gain: +{self._estimate_coverage_gain(1)}%

### Phase 2: Core Functionality (Week 2)
- Complete unit test coverage for main modules
- Add integration tests for key workflows
- Estimated coverage gain: +{self._estimate_coverage_gain(2)}%

### Phase 3: Edge Cases (Week 3)
- Add boundary value tests
- Cover remaining branches
- Estimated coverage gain: +{self._estimate_coverage_gain(3)}%

## Test Generation Commands

```bash
# Generate missing unit tests
npm run test:generate -- --coverage-gaps

# Generate integration tests
npm run test:generate -- --type=integration

# Run mutation testing
npm run test:mutation
```

## Monitoring Progress

Track coverage trends with:
```bash
npm run test:coverage -- --watch
```
'''
        
        return {
            'plan': template,
            'estimated_effort': self._estimate_effort(current_coverage, target_coverage),
            'priority_files': self._identify_priority_files(current_coverage['gaps']),
            'test_templates': await self._generate_test_templates(
                current_coverage['recommendations']
            )
        }
```

#### SubTask 3.10.4: 성능 테스트 자동화
**담당자**: 성능 엔지니어  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/implementations/performance_tester.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

class PerformanceTestType(Enum):
    LOAD = "load"
    STRESS = "stress"
    SPIKE = "spike"
    ENDURANCE = "endurance"
    VOLUME = "volume"
    SCALABILITY = "scalability"

@dataclass
class PerformanceScenario:
    name: str
    type: PerformanceTestType
    target_endpoint: str
    user_pattern: Dict[str, Any]
    duration: int
    success_criteria: Dict[str, float]
    monitoring_config: Dict[str, Any]

class PerformanceTester:
    """Automated performance testing framework"""
    
    def __init__(self):
        self.scenario_generator = ScenarioGenerator()
        self.load_generator = LoadGenerator()
        self.metrics_collector = MetricsCollector()
    
    async def generate_performance_tests(
        self,
        api_specs: List[Dict[str, Any]],
        performance_requirements: Dict[str, Any],
        infrastructure: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate comprehensive performance test suite"""
        
        # Analyze API endpoints
        endpoint_analysis = await self._analyze_endpoints(api_specs)
        
        # Generate test scenarios
        scenarios = await self._generate_scenarios(
            endpoint_analysis,
            performance_requirements
        )
        
        # Create load profiles
        load_profiles = await self._create_load_profiles(
            scenarios,
            infrastructure
        )
        
        # Generate test scripts
        test_scripts = await self._generate_test_scripts(
            scenarios,
            load_profiles
        )
        
        # Create monitoring configuration
        monitoring = await self._configure_monitoring(
            scenarios,
            infrastructure
        )
        
        return {
            'scenarios': scenarios,
            'scripts': test_scripts,
            'monitoring': monitoring,
            'execution_plan': await self._create_execution_plan(scenarios),
            'analysis_tools': await self._setup_analysis_tools()
        }
    
    async def _generate_k6_script(
        self,
        scenario: PerformanceScenario
    ) -> str:
        """Generate k6 performance test script"""
        
        stages = self._generate_load_stages(scenario)
        checks = self._generate_checks(scenario.success_criteria)
        
        template = f'''
import http from 'k6/http';
import {{ check, sleep }} from 'k6';
import {{ Rate, Trend }} from 'k6/metrics';

// Custom metrics
const errorRate = new Rate('errors');
const apiLatency = new Trend('api_latency');

// Test configuration
export const options = {{
    scenarios: {{
        {scenario.name}: {{
            executor: '{self._get_executor_type(scenario.type)}',
            {self._generate_executor_config(scenario)}
        }}
    }},
    thresholds: {{
        'http_req_duration': ['p(95)<{scenario.success_criteria.get("p95_latency", 500)}'],
        'http_req_failed': ['rate<{scenario.success_criteria.get("error_rate", 0.01)}'],
        'errors': ['rate<{scenario.success_criteria.get("custom_error_rate", 0.05)}']
    }}
}};

// Test data
const testData = {{
    baseUrl: __ENV.BASE_URL || 'http://localhost:3000',
    headers: {{
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${{__ENV.API_TOKEN}}`
    }}
}};

// Main test function
export default function() {{
    const startTime = new Date();
    
    // Execute test scenario
    {self._generate_scenario_code(scenario)}
    
    // Record custom metrics
    apiLatency.add(new Date() - startTime);
    
    // Think time
    sleep({scenario.user_pattern.get('think_time', 1)});
}}

// Setup function
export function setup() {{
    // Verify system is ready
    const healthCheck = http.get(`${{testData.baseUrl}}/health`);
    check(healthCheck, {{
        'system is healthy': (r) => r.status === 200
    }});
    
    return {{ startTime: new Date() }};
}}

// Teardown function
export function teardown(data) {{
    // Calculate test duration
    const duration = (new Date() - data.startTime) / 1000;
    console.log(`Test completed in ${{duration}} seconds`);
}}

// Helper functions
{self._generate_helper_functions(scenario)}
'''
        
        return template
    
    async def _generate_jmeter_script(
        self,
        scenario: PerformanceScenario
    ) -> str:
        """Generate JMeter test plan"""
        
        template = f'''
<?xml version="1.0" encoding="UTF-8"?>
<jmeterTestPlan version="1.2" properties="5.0" jmeter="5.5">
  <hashTree>
    <TestPlan guiclass="TestPlanGui" testclass="TestPlan" testname="{scenario.name}" enabled="true">
      <stringProp name="TestPlan.comments">Performance test for {scenario.target_endpoint}</stringProp>
      <boolProp name="TestPlan.functional_mode">false</boolProp>
      <boolProp name="TestPlan.serialize_threadgroups">false</boolProp>
    </TestPlan>
    <hashTree>
      <!-- Thread Group -->
      <ThreadGroup guiclass="ThreadGroupGui" testclass="ThreadGroup" testname="User Load" enabled="true">
        <stringProp name="ThreadGroup.on_sample_error">continue</stringProp>
        <elementProp name="ThreadGroup.main_controller" elementType="LoopController">
          <boolProp name="LoopController.continue_forever">false</boolProp>
          <intProp name="LoopController.loops">{scenario.user_pattern.get('iterations', -1)}</intProp>
        </elementProp>
        <intProp name="ThreadGroup.num_threads">{scenario.user_pattern.get('users', 100)}</intProp>
        <intProp name="ThreadGroup.ramp_time">{scenario.user_pattern.get('ramp_up', 60)}</intProp>
        <boolProp name="ThreadGroup.scheduler">true</boolProp>
        <intProp name="ThreadGroup.duration">{scenario.duration}</intProp>
      </ThreadGroup>
      <hashTree>
        <!-- HTTP Request -->
        {self._generate_jmeter_http_request(scenario)}
        
        <!-- Assertions -->
        {self._generate_jmeter_assertions(scenario.success_criteria)}
        
        <!-- Listeners -->
        {self._generate_jmeter_listeners()}
      </hashTree>
    </hashTree>
  </hashTree>
</jmeterTestPlan>
'''
        
        return template
    
    async def analyze_performance_results(
        self,
        test_results: Dict[str, Any],
        baseline: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Analyze performance test results"""
        
        analysis = {
            'summary': await self._generate_summary(test_results),
            'bottlenecks': await self._identify_bottlenecks(test_results),
            'trends': await self._analyze_trends(test_results, baseline),
            'recommendations': await self._generate_recommendations(test_results),
            'detailed_metrics': await self._calculate_detailed_metrics(test_results)
        }
        
        # Generate performance report
        analysis['report'] = await self._generate_performance_report(analysis)
        
        return analysis
```

---

### Task 3.11: Security Agent 구현

#### SubTask 3.11.1: 보안 취약점 스캐너
**담당자**: 보안 엔지니어  
**예상 소요시간**: 16시간

**작업 내용**:
```python
# backend/src/agents/implementations/security_agent.py
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass
from enum import Enum
import re

class VulnerabilityType(Enum):
    SQL_INJECTION = "sql_injection"
    XSS = "cross_site_scripting"
    CSRF = "csrf"
    IDOR = "insecure_direct_object_reference"
    SSRF = "server_side_request_forgery"
    XXE = "xml_external_entity"
    BROKEN_AUTH = "broken_authentication"
    SENSITIVE_DATA = "sensitive_data_exposure"
    BROKEN_ACCESS = "broken_access_control"
    SECURITY_MISCONFIG = "security_misconfiguration"

@dataclass
class Vulnerability:
    type: VulnerabilityType
    severity: str  # critical, high, medium, low
    location: Dict[str, Any]
    description: str
    evidence: str
    remediation: str
    cwe_id: Optional[str] = None
    owasp_category: Optional[str] = None

class SecurityAgent(AgnoEnabledAgent, SquadEnabledAgent):
    """Security analysis and vulnerability detection agent"""
    
    def __init__(self):
        super().__init__(
            name="SecurityAgent",
            agno_config={
                'modelId': 'anthropic.claude-3-opus-v1:0',
                'temperature': 0.2,
                'tools': [
                    'code-scanner',
                    'dependency-checker',
                    'config-analyzer'
                ]
            }
        )
        
        self.vulnerability_scanner = VulnerabilityScanner()
        self.dependency_checker = DependencyChecker()
        self.security_analyzer = SecurityAnalyzer()
    
    async def perform_security_audit(
        self,
        code_base: Dict[str, Any],
        config_files: Dict[str, Any],
        dependencies: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Perform comprehensive security audit"""
        
        audit_results = {
            'scan_date': datetime.utcnow(),
            'vulnerabilities': [],
            'security_score': 0,
            'risk_assessment': {}
        }
        
        # Static code analysis
        code_vulns = await self._scan_source_code(code_base)
        audit_results['vulnerabilities'].extend(code_vulns)
        
        # Configuration analysis
        config_issues = await self._analyze_configurations(config_files)
        audit_results['vulnerabilities'].extend(config_issues)
        
        # Dependency vulnerability check
        dep_vulns = await self.dependency_checker.check_vulnerabilities(
            dependencies
        )
        audit_results['vulnerabilities'].extend(dep_vulns)
        
        # API security analysis
        api_issues = await self._analyze_api_security(code_base)
        audit_results['vulnerabilities'].extend(api_issues)
        
        # Calculate security score
        audit_results['security_score'] = await self._calculate_security_score(
            audit_results['vulnerabilities']
        )
        
        # Risk assessment
        audit_results['risk_assessment'] = await self._assess_risks(
            audit_results['vulnerabilities']
        )
        
        # Generate remediation plan
        audit_results['remediation_plan'] = await self._create_remediation_plan(
            audit_results['vulnerabilities']
        )
        
        return audit_results
    
    async def _scan_source_code(
        self,
        code_base: Dict[str, Any]
    ) -> List[Vulnerability]:
        """Scan source code for security vulnerabilities"""
        
        vulnerabilities = []
        
        for file_path, content in code_base.items():
            # SQL Injection detection
            sql_vulns = await self._detect_sql_injection(file_path, content)
            vulnerabilities.extend(sql_vulns)
            
            # XSS detection
            xss_vulns = await self._detect_xss(file_path, content)
            vulnerabilities.extend(xss_vulns)
            
            # Authentication issues
            auth_vulns = await self._detect_auth_issues(file_path, content)
            vulnerabilities.extend(auth_vulns)
            
            # Sensitive data exposure
            data_vulns = await self._detect_sensitive_data(file_path, content)
            vulnerabilities.extend(data_vulns)
            
            # Insecure cryptography
            crypto_vulns = await self._detect_crypto_issues(file_path, content)
            vulnerabilities.extend(crypto_vulns)
        
        return vulnerabilities
    
    async def _detect_sql_injection(
        self,
        file_path: str,
        content: str
    ) -> List[Vulnerability]:
        """Detect potential SQL injection vulnerabilities"""
        
        vulnerabilities = []
        patterns = [
            # Direct string concatenation in queries
            r'(query|execute)\s*\(\s*["\'].*?\+.*?["\']',
            # String interpolation in queries
            r'(query|execute)\s*\(\s*f["\'].*?\{.*?\}.*?["\']',
            # Template literals with variables
            r'(query|execute)\s*\(\s*`.*?\$\{.*?\}.*?`',
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, content, re.MULTILINE | re.DOTALL)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                
                vuln = Vulnerability(
                    type=VulnerabilityType.SQL_INJECTION,
                    severity='high',
                    location={
                        'file': file_path,
                        'line': line_num,
                        'column': match.start() - content.rfind('\n', 0, match.start())
                    },
                    description='Potential SQL injection vulnerability detected',
                    evidence=match.group(0)[:100],
                    remediation='Use parameterized queries or prepared statements',
                    cwe_id='CWE-89',
                    owasp_category='A03:2021 - Injection'
                )
                vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    async def generate_security_rules(
        self,
        project_type: str,
        tech_stack: List[str]
    ) -> Dict[str, Any]:
        """Generate security rules and policies"""
        
        rules = {
            'input_validation': await self._generate_input_validation_rules(
                project_type
            ),
            'authentication': await self._generate_auth_rules(tech_stack),
            'authorization': await self._generate_authz_rules(project_type),
            'data_protection': await self._generate_data_protection_rules(),
            'api_security': await self._generate_api_security_rules(),
            'infrastructure': await self._generate_infra_security_rules()
        }
        
        # Generate security middleware
        middleware_code = await self._generate_security_middleware(
            rules,
            tech_stack
        )
        
        # Generate security tests
        security_tests = await self._generate_security_tests(rules)
        
        return {
            'rules': rules,
            'middleware': middleware_code,
            'tests': security_tests,
            'policies': await self._generate_security_policies(rules),
            'monitoring': await self._generate_security_monitoring(rules)
        }
```

#### SubTask 3.11.2: 인증/인가 시스템 설계
**담당자**: 보안 아키텍트  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/implementations/auth_system_designer.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

class AuthMethod(Enum):
    JWT = "jwt"
    OAUTH2 = "oauth2"
    SAML = "saml"
    API_KEY = "api_key"
    MTLS = "mutual_tls"
    BASIC = "basic"

@dataclass
class AuthSystemDesign:
    authentication_method: AuthMethod
    authorization_model: str  # RBAC, ABAC, etc.
    token_strategy: Dict[str, Any]
    session_management: Dict[str, Any]
    multi_factor: Optional[Dict[str, Any]]
    security_policies: List[Dict[str, Any]]

class AuthSystemDesigner:
    """Design secure authentication and authorization systems"""
    
    def __init__(self):
        self.auth_analyzer = AuthenticationAnalyzer()
        self.policy_generator = PolicyGenerator()
        self.token_manager = TokenStrategyDesigner()
    
    async def design_auth_system(
        self,
        requirements: Dict[str, Any],
        user_types: List[Dict[str, Any]],
        security_level: str = "high"
    ) -> AuthSystemDesign:
        """Design complete authentication/authorization system"""
        
        # Analyze requirements
        auth_requirements = await self._analyze_auth_requirements(
            requirements,
            security_level
        )
        
        # Select authentication method
        auth_method = await self._select_auth_method(
            auth_requirements,
            user_types
        )
        
        # Design authorization model
        authz_model = await self._design_authorization_model(
            user_types,
            requirements.get('permissions', [])
        )
        
        # Design token strategy
        token_strategy = await self.token_manager.design_strategy(
            auth_method,
            security_level
        )
        
        # Design session management
        session_mgmt = await self._design_session_management(
            auth_method,
            security_level
        )
        
        # Multi-factor authentication
        mfa = None
        if security_level in ['high', 'critical']:
            mfa = await self._design_mfa_system(user_types)
        
        # Security policies
        policies = await self.policy_generator.generate_policies(
            auth_method,
            authz_model,
            security_level
        )
        
        return AuthSystemDesign(
            authentication_method=auth_method,
            authorization_model=authz_model,
            token_strategy=token_strategy,
            session_management=session_mgmt,
            multi_factor=mfa,
            security_policies=policies
        )
    
    async def generate_auth_implementation(
        self,
        design: AuthSystemDesign,
        framework: str = "express"
    ) -> Dict[str, Any]:
        """Generate authentication implementation code"""
        
        if design.authentication_method == AuthMethod.JWT:
            return await self._generate_jwt_implementation(design, framework)
        elif design.authentication_method == AuthMethod.OAUTH2:
            return await self._generate_oauth2_implementation(design, framework)
        else:
            raise ValueError(f"Unsupported auth method: {design.authentication_method}")
    
    async def _generate_jwt_implementation(
        self,
        design: AuthSystemDesign,
        framework: str
    ) -> Dict[str, Any]:
        """Generate JWT-based authentication"""
        
        # Auth middleware
        middleware_code = f'''
import jwt from 'jsonwebtoken';
import bcrypt from 'bcrypt';
import {{ Request, Response, NextFunction }} from 'express';
import {{ User }} from '../models/User';
import {{ TokenBlacklist }} from '../models/TokenBlacklist';

interface JwtPayload {{
    userId: string;
    email: string;
    roles: string[];
    permissions: string[];
}}

export class AuthService {{
    private readonly jwtSecret = process.env.JWT_SECRET!;
    private readonly refreshSecret = process.env.JWT_REFRESH_SECRET!;
    private readonly accessTokenExpiry = '{design.token_strategy['access_expiry']}';
    private readonly refreshTokenExpiry = '{design.token_strategy['refresh_expiry']}';
    
    async login(email: string, password: string): Promise<{{
        accessToken: string;
        refreshToken: string;
        user: any;
    }}> {{
        // Find user
        const user = await User.findOne({{ email }});
        if (!user) {{
            throw new Error('Invalid credentials');
        }}
        
        // Verify password
        const isValid = await bcrypt.compare(password, user.passwordHash);
        if (!isValid) {{
            throw new Error('Invalid credentials');
        }}
        
        // Check account status
        if (user.status !== 'active') {{
            throw new Error('Account is not active');
        }}
        
        // Generate tokens
        const payload: JwtPayload = {{
            userId: user.id,
            email: user.email,
            roles: user.roles,
            permissions: await this.getUserPermissions(user)
        }};
        
        const accessToken = this.generateAccessToken(payload);
        const refreshToken = this.generateRefreshToken(payload);
        
        // Store refresh token
        await this.storeRefreshToken(user.id, refreshToken);
        
        // Update last login
        user.lastLoginAt = new Date();
        await user.save();
        
        return {{
            accessToken,
            refreshToken,
            user: user.toJSON()
        }};
    }}
    
    async validateToken(token: string): Promise<JwtPayload> {{
        try {{
            // Check if token is blacklisted
            const isBlacklisted = await TokenBlacklist.exists({{ token }});
            if (isBlacklisted) {{
                throw new Error('Token has been revoked');
            }}
            
            // Verify token
            const decoded = jwt.verify(token, this.jwtSecret) as JwtPayload;
            
            // Additional validation
            const user = await User.findById(decoded.userId);
            if (!user || user.status !== 'active') {{
                throw new Error('Invalid token');
            }}
            
            return decoded;
        }} catch (error) {{
            throw new Error('Invalid token');
        }}
    }}
    
    private generateAccessToken(payload: JwtPayload): string {{
        return jwt.sign(payload, this.jwtSecret, {{
            expiresIn: this.accessTokenExpiry,
            issuer: '{design.token_strategy.get('issuer', 'app')}',
            audience: '{design.token_strategy.get('audience', 'api')}'
        }});
    }}
    
    private generateRefreshToken(payload: Omit<JwtPayload, 'permissions'>): string {{
        return jwt.sign(
            {{ userId: payload.userId }},
            this.refreshSecret,
            {{ expiresIn: this.refreshTokenExpiry }}
        );
    }}
}}

// Authentication middleware
export const authenticate = async (
    req: Request,
    res: Response,
    next: NextFunction
): Promise<void> => {{
    try {{
        const token = extractToken(req);
        if (!token) {{
            return res.status(401).json({{ error: 'No token provided' }});
        }}
        
        const authService = new AuthService();
        const decoded = await authService.validateToken(token);
        
        req.user = decoded;
        next();
    }} catch (error) {{
        res.status(401).json({{ error: 'Authentication failed' }});
    }}
}};

// Authorization middleware
export const authorize = (...requiredPermissions: string[]) => {{
    return async (req: Request, res: Response, next: NextFunction): Promise<void> => {{
        const user = req.user as JwtPayload;
        
        if (!user) {{
            return res.status(401).json({{ error: 'Not authenticated' }});
        }}
        
        const hasPermission = requiredPermissions.every(
            permission => user.permissions.includes(permission)
        );
        
        if (!hasPermission) {{
            return res.status(403).json({{ error: 'Insufficient permissions' }});
        }}
        
        next();
    }};
}};
'''
        
        # Rate limiting
        rate_limiting = await self._generate_rate_limiting(design)
        
        # Security headers
        security_headers = await self._generate_security_headers()
        
        return {
            'middleware': middleware_code,
            'rate_limiting': rate_limiting,
            'security_headers': security_headers,
            'tests': await self._generate_auth_tests(design)
        }
```

#### SubTask 3.11.3: 암호화 및 데이터 보호
**담당자**: 암호화 전문가  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/implementations/encryption_manager.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum
import secrets

class EncryptionMethod(Enum):
    AES_256_GCM = "aes-256-gcm"
    RSA_OAEP = "rsa-oaep"
    CHACHA20_POLY1305 = "chacha20-poly1305"
    ECDH = "ecdh"

@dataclass
class EncryptionStrategy:
    data_at_rest: Dict[str, Any]
    data_in_transit: Dict[str, Any]
    key_management: Dict[str, Any]
    sensitive_fields: List[str]
    compliance_requirements: List[str]

class EncryptionManager:
    """Manage encryption and data protection strategies"""
    
    def __init__(self):
        self.crypto_analyzer = CryptoAnalyzer()
        self.key_manager = KeyManagementSystem()
        self.compliance_checker = ComplianceChecker()
    
    async def design_encryption_strategy(
        self,
        data_classification: Dict[str, Any],
        compliance_needs: List[str],
        infrastructure: Dict[str, Any]
    ) -> EncryptionStrategy:
        """Design comprehensive encryption strategy"""
        
        # Analyze data sensitivity
        sensitivity_map = await self._analyze_data_sensitivity(
            data_classification
        )
        
        # Design data-at-rest encryption
        data_at_rest = await self._design_data_at_rest_encryption(
            sensitivity_map,
            infrastructure
        )
        
        # Design data-in-transit encryption
        data_in_transit = await self._design_data_in_transit_encryption(
            infrastructure
        )
        
        # Design key management
        key_management = await self.key_manager.design_kms(
            data_at_rest,
            compliance_needs
        )
        
        # Identify sensitive fields
        sensitive_fields = await self._identify_sensitive_fields(
            data_classification
        )
        
        # Verify compliance
        compliance = await self.compliance_checker.verify(
            data_at_rest,
            data_in_transit,
            compliance_needs
        )
        
        return EncryptionStrategy(
            data_at_rest=data_at_rest,
            data_in_transit=data_in_transit,
            key_management=key_management,
            sensitive_fields=sensitive_fields,
            compliance_requirements=compliance
        )
    
    async def generate_encryption_implementation(
        self,
        strategy: EncryptionStrategy,
        language: str = "typescript"
    ) -> Dict[str, Any]:
        """Generate encryption implementation code"""
        
        if language == "typescript":
            return await self._generate_typescript_encryption(strategy)
        elif language == "python":
            return await self._generate_python_encryption(strategy)
        else:
            raise ValueError(f"Unsupported language: {language}")
    
    async def _generate_typescript_encryption(
        self,
        strategy: EncryptionStrategy
    ) -> Dict[str, Any]:
        """Generate TypeScript encryption implementation"""
        
        encryption_service = f'''
import crypto from 'crypto';
import {{ KeyManagementService }} from './kms';
import {{ logger }} from '../utils/logger';

interface EncryptionResult {{
    encrypted: string;
    iv: string;
    authTag: string;
    keyId: string;
}}

export class EncryptionService {{
    private readonly algorithm = '{strategy.data_at_rest['algorithm']}';
    private readonly keyLength = {strategy.data_at_rest['key_length']};
    private kms: KeyManagementService;
    
    constructor() {{
        this.kms = new KeyManagementService({{
            provider: '{strategy.key_management['provider']}',
            region: '{strategy.key_management['region']}',
            keyRotationDays: {strategy.key_management['rotation_days']}
        }});
    }}
    
    async encryptField(
        data: string,
        context: {{ fieldName: string; recordId: string }}
    ): Promise<EncryptionResult> {{
        try {{
            // Get or generate data encryption key
            const {{ key, keyId }} = await this.kms.getDataEncryptionKey(context);
            
            // Generate initialization vector
            const iv = crypto.randomBytes(16);
            
            // Create cipher
            const cipher = crypto.createCipheriv(this.algorithm, key, iv);
            
            // Encrypt data
            let encrypted = cipher.update(data, 'utf8', 'base64');
            encrypted += cipher.final('base64');
            
            // Get auth tag for authenticated encryption
            const authTag = cipher.getAuthTag();
            
            // Clear key from memory
            key.fill(0);
            
            return {{
                encrypted,
                iv: iv.toString('base64'),
                authTag: authTag.toString('base64'),
                keyId
            }};
        }} catch (error) {{
            logger.error('Encryption failed', {{ error, context }});
            throw new Error('Failed to encrypt data');
        }}
    }}
    
    async decryptField(
        encryptedData: EncryptionResult,
        context: {{ fieldName: string; recordId: string }}
    ): Promise<string> {{
        try {{
            // Retrieve decryption key
            const key = await this.kms.getDecryptionKey(encryptedData.keyId, context);
            
            // Create decipher
            const decipher = crypto.createDecipheriv(
                this.algorithm,
                key,
                Buffer.from(encryptedData.iv, 'base64')
            );
            
            // Set auth tag
            decipher.setAuthTag(Buffer.from(encryptedData.authTag, 'base64'));
            
            // Decrypt data
            let decrypted = decipher.update(encryptedData.encrypted, 'base64', 'utf8');
            decrypted += decipher.final('utf8');
            
            // Clear key from memory
            key.fill(0);
            
            return decrypted;
        }} catch (error) {{
            logger.error('Decryption failed', {{ error, context }});
            throw new Error('Failed to decrypt data');
        }}
    }}
    
    async encryptDocument(
        document: any,
        sensitiveFields: string[] = {json.dumps(strategy.sensitive_fields)}
    ): Promise<any> {{
        const encrypted = {{ ...document }};
        const encryptionMetadata: Record<string, EncryptionResult> = {{}};
        
        for (const field of sensitiveFields) {{
            if (document[field] !== undefined) {{
                const fieldValue = String(document[field]);
                const encryptionResult = await this.encryptField(fieldValue, {{
                    fieldName: field,
                    recordId: document.id || crypto.randomUUID()
                }});
                
                encrypted[field] = encryptionResult.encrypted;
                encryptionMetadata[field] = encryptionResult;
            }}
        }}
        
        encrypted._encryption = encryptionMetadata;
        return encrypted;
    }}
    
    // Transparent encryption middleware
    transparentEncryption() {{
        return {{
            async beforeSave(document: any): Promise<void> {{
                const encrypted = await this.encryptDocument(document);
                Object.assign(document, encrypted);
            }},
            
            async afterFind(document: any): Promise<void> {{
                if (document._encryption) {{
                    const decrypted = await this.decryptDocument(document);
                    Object.assign(document, decrypted);
                    delete document._encryption;
                }}
            }}
        }};
    }}
}}

// Field-level encryption decorator
export function Encrypted(target: any, propertyKey: string): void {{
    const encryptionService = new EncryptionService();
    
    let value: any;
    
    const getter = function() {{
        return value;
    }};
    
    const setter = async function(newValue: any) {{
        if (newValue && typeof newValue === 'string') {{
            const encrypted = await encryptionService.encryptField(newValue, {{
                fieldName: propertyKey,
                recordId: this.id || 'temp'
            }});
            value = encrypted;
        }} else {{
            value = newValue;
        }}
    }};
    
    Object.defineProperty(target, propertyKey, {{
        get: getter,
        set: setter,
        enumerable: true,
        configurable: true
    }});
}}
'''
        
        # TLS configuration
        tls_config = await self._generate_tls_configuration(strategy)
        
        # Database encryption
        db_encryption = await self._generate_database_encryption(strategy)
        
        return {
            'service': encryption_service,
            'tls_config': tls_config,
            'database_encryption': db_encryption,
            'key_rotation': await self._generate_key_rotation_script(strategy),
            'tests': await self._generate_encryption_tests(strategy)
        }
```

#### SubTask 3.11.4: 보안 모니터링 및 대응
**담당자**: 보안 운영 전문가  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/implementations/security_monitoring.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum
import asyncio

class ThreatLevel(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class SecurityEvent:
    id: str
    timestamp: datetime
    event_type: str
    threat_level: ThreatLevel
    source: Dict[str, Any]
    details: Dict[str, Any]
    indicators: List[str]
    response_actions: List[str]

class SecurityMonitoring:
    """Real-time security monitoring and incident response"""
    
    def __init__(self):
        self.event_collector = EventCollector()
        self.threat_detector = ThreatDetector()
        self.incident_responder = IncidentResponder()
    
    async def setup_monitoring_system(
        self,
        infrastructure: Dict[str, Any],
        security_policies: List[Dict[str, Any]],
        response_playbooks: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Setup comprehensive security monitoring"""
        
        # Configure event sources
        event_sources = await self._configure_event_sources(infrastructure)
        
        # Setup detection rules
        detection_rules = await self._create_detection_rules(
            security_policies
        )
        
        # Configure alerting
        alerting_config = await self._setup_alerting(
            detection_rules,
            response_playbooks
        )
        
        # Create dashboards
        dashboards = await self._create_security_dashboards(
            event_sources,
            detection_rules
        )
        
        # Generate monitoring code
        monitoring_code = await self._generate_monitoring_implementation(
            event_sources,
            detection_rules,
            alerting_config
        )
        
        return {
            'event_sources': event_sources,
            'detection_rules': detection_rules,
            'alerting': alerting_config,
            'dashboards': dashboards,
            'implementation': monitoring_code,
            'playbooks': response_playbooks
        }
    
    async def _generate_monitoring_implementation(
        self,
        sources: List[Dict[str, Any]],
        rules: List[Dict[str, Any]],
        alerting: Dict[str, Any]
    ) -> str:
        """Generate security monitoring implementation"""
        
        template = f'''
import {{ EventEmitter }} from 'events';
import winston from 'winston';
import {{ CloudWatchLogs }} from '@aws-sdk/client-cloudwatch-logs';
import {{ SNS }} from '@aws-sdk/client-sns';
import {{ DynamoDB }} from '@aws-sdk/client-dynamodb';

interface SecurityRule {{
    id: string;
    name: string;
    condition: (event: any) => boolean;
    threatLevel: ThreatLevel;
    actions: string[];
}}

export class SecurityMonitor extends EventEmitter {{
    private rules: SecurityRule[] = {json.dumps(rules, indent=2)};
    private eventBuffer: SecurityEvent[] = [];
    private cloudwatch: CloudWatchLogs;
    private sns: SNS;
    private dynamodb: DynamoDB;
    
    constructor() {{
        super();
        this.cloudwatch = new CloudWatchLogs({{ region: process.env.AWS_REGION }});
        this.sns = new SNS({{ region: process.env.AWS_REGION }});
        this.dynamodb = new DynamoDB({{ region: process.env.AWS_REGION }});
        
        this.initializeEventSources();
        this.startMonitoring();
    }}
    
    private initializeEventSources(): void {{
        // Application logs
        this.monitorApplicationLogs();
        
        // API Gateway logs
        this.monitorAPIGateway();
        
        // Database activity
        this.monitorDatabaseActivity();
        
        // Authentication events
        this.monitorAuthEvents();
        
        // Network traffic
        this.monitorNetworkTraffic();
    }}
    
    private async processSecurityEvent(event: any): Promise<void> {{
        const timestamp = new Date();
        
        // Check against rules
        for (const rule of this.rules) {{
            if (rule.condition(event)) {{
                const securityEvent: SecurityEvent = {{
                    id: crypto.randomUUID(),
                    timestamp,
                    event_type: rule.name,
                    threat_level: rule.threatLevel,
                    source: event.source,
                    details: event,
                    indicators: this.extractIndicators(event),
                    response_actions: rule.actions
                }};
                
                // Store event
                await this.storeSecurityEvent(securityEvent);
                
                // Execute response actions
                await this.executeResponseActions(securityEvent);
                
                // Send alerts if needed
                if (rule.threatLevel in ['high', 'critical']) {{
                    await this.sendAlert(securityEvent);
                }}
            }}
        }}
    }}
    
    private extractIndicators(event: any): string[] {{
        const indicators = [];
        
        // IP addresses
        if (event.sourceIP) {{
            indicators.push(`IP:${{event.sourceIP}}`);
        }}
        
        // User agents
        if (event.userAgent && this.isSuspiciousUserAgent(event.userAgent)) {{
            indicators.push(`UA:${{event.userAgent}}`);
        }}
        
        // Failed login patterns
        if (event.type === 'auth' && event.failed_attempts > 5) {{
            indicators.push('BRUTE_FORCE_ATTEMPT');
        }}
        
        // SQL injection patterns
        if (event.query && this.detectSQLInjection(event.query)) {{
            indicators.push('SQL_INJECTION_ATTEMPT');
        }}
        
        return indicators;
    }}
    
    private async executeResponseActions(event: SecurityEvent): Promise<void> {{
        for (const action of event.response_actions) {{
            switch (action) {{
                case 'block_ip':
                    await this.blockIPAddress(event.source.ip);
                    break;
                    
                case 'disable_account':
                    await this.disableUserAccount(event.source.userId);
                    break;
                    
                case 'rate_limit':
                    await this.applyRateLimit(event.source);
                    break;
                    
                case 'capture_forensics':
                    await this.captureForensicsData(event);
                    break;
                    
                case 'notify_soc':
                    await this.notifySecurityTeam(event);
                    break;
            }}
        }}
    }}
    
    private monitorAuthEvents(): void {{
        // Monitor authentication events
        this.on('auth:login', async (event) => {{
            if (event.failed) {{
                await this.processSecurityEvent({{
                    type: 'failed_login',
                    source: {{ ip: event.ip, userId: event.userId }},
                    ...event
                }});
            }}
        }});
        
        this.on('auth:suspicious', async (event) => {{
            await this.processSecurityEvent({{
                type: 'suspicious_auth',
                threat_level: 'high',
                ...event
            }});
        }});
    }}
    
    async generateSecurityReport(
        startTime: Date,
        endTime: Date
    ): Promise<SecurityReport> {{
        const events = await this.getSecurityEvents(startTime, endTime);
        
        return {{
            period: {{ start: startTime, end: endTime }},
            total_events: events.length,
            events_by_type: this.groupEventsByType(events),
            events_by_threat_level: this.groupEventsByThreatLevel(events),
            top_indicators: this.getTopIndicators(events),
            blocked_ips: await this.getBlockedIPs(startTime, endTime),
            disabled_accounts: await this.getDisabledAccounts(startTime, endTime),
            recommendations: await this.generateRecommendations(events)
        }};
    }}
}}

// SIEM integration
export class SIEMConnector {{
    private securityMonitor: SecurityMonitor;
    
    constructor(monitor: SecurityMonitor) {{
        this.securityMonitor = monitor;
        this.setupEventForwarding();
    }}
    
    private setupEventForwarding(): void {{
        this.securityMonitor.on('security:event', async (event) => {{
            // Forward to SIEM
            await this.forwardToSIEM(event);
        }});
    }}
    
    private async forwardToSIEM(event: SecurityEvent): Promise<void> {{
        const siemFormat = this.convertToSIEMFormat(event);
        
        // Send to SIEM endpoint
        await fetch(process.env.SIEM_ENDPOINT, {{
            method: 'POST',
            headers: {{
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${{process.env.SIEM_API_KEY}}`
            }},
            body: JSON.stringify(siemFormat)
        }});
    }}
}}
'''
        
        return template
```

---

### Task 3.12: DevOps Agent 구현

#### SubTask 3.12.1: CI/CD 파이프라인 생성기
**담당자**: DevOps 엔지니어  
**예상 소요시간**: 16시간

**작업 내용**:
```python
# backend/src/agents/implementations/devops_agent.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

class PipelineType(Enum):
    BUILD = "build"
    TEST = "test"
    DEPLOY = "deploy"
    RELEASE = "release"
    ROLLBACK = "rollback"

@dataclass
class Pipeline:
    name: str
    type: PipelineType
    stages: List['PipelineStage']
    triggers: List[Dict[str, Any]]
    environment_config: Dict[str, Any]
    notifications: Dict[str, Any]

class DevOpsAgent(AgnoEnabledAgent, SquadEnabledAgent):
    """DevOps automation and infrastructure management agent"""
    
    def __init__(self):
        super().__init__(
            name="DevOpsAgent",
            agno_config={
                'modelId': 'anthropic.claude-3-opus-v1:0',
                'temperature': 0.3,
                'tools': [
                    'pipeline-designer',
                    'infra-analyzer',
                    'deployment-optimizer'
                ]
            }
        )
        
        self.pipeline_generator = PipelineGenerator()
        self.infra_designer = InfrastructureDesigner()
        self.deployment_manager = DeploymentManager()
    
    async def generate_cicd_pipeline(
        self,
        project_config: Dict[str, Any],
        deployment_targets: List[Dict[str, Any]],
        quality_gates: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate complete CI/CD pipeline"""
        
        # Analyze project requirements
        requirements = await self._analyze_project_requirements(project_config)
        
        # Design pipeline stages
        pipeline_design = await self._design_pipeline_stages(
            requirements,
            quality_gates
        )
        
        # Generate pipeline code for different platforms
        implementations = {}
        
        # GitHub Actions
        if 'github' in project_config.get('platforms', []):
            implementations['github_actions'] = await self._generate_github_actions(
                pipeline_design
            )
        
        # GitLab CI
        if 'gitlab' in project_config.get('platforms', []):
            implementations['gitlab_ci'] = await self._generate_gitlab_ci(
                pipeline_design
            )
        
        # Jenkins
        if 'jenkins' in project_config.get('platforms', []):
            implementations['jenkins'] = await self._generate_jenkinsfile(
                pipeline_design
            )
        
        # AWS CodePipeline
        if 'aws' in deployment_targets:
            implementations['aws_codepipeline'] = await self._generate_aws_pipeline(
                pipeline_design
            )
        
        return {
            'design': pipeline_design,
            'implementations': implementations,
            'monitoring': await self._generate_pipeline_monitoring(pipeline_design),
            'rollback_strategy': await self._design_rollback_strategy(deployment_targets)
        }
    
    async def _generate_github_actions(
        self,
        design: Dict[str, Any]
    ) -> str:
        """Generate GitHub Actions workflow"""
        
        template = f'''
name: {design['name']}

on:
  push:
    branches: {json.dumps(design['triggers']['branches'])}
  pull_request:
    branches: {json.dumps(design['triggers']['pr_branches'])}
  workflow_dispatch:

env:
  NODE_VERSION: '18.x'
  PYTHON_VERSION: '3.11'
  AWS_REGION: {design['environment_config']['aws_region']}

jobs:
  # Build Job
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{{{ env.NODE_VERSION }}}}
          cache: 'npm'
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.npm
            node_modules
            */node_modules
          key: ${{{{ runner.os }}}}-node-${{{{ hashFiles('**/package-lock.json') }}}}
      
      - name: Install dependencies
        run: |
          npm ci
          npm run bootstrap
      
      - name: Run linting
        run: npm run lint
      
      - name: Build application
        run: |
          npm run build
          npm run build:types
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-artifacts
          path: |
            dist/
            build/
            .next/
  
  # Test Job
  test:
    needs: build
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-suite: [unit, integration, e2e]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup test environment
        uses: actions/setup-node@v4
        with:
          node-version: ${{{{ env.NODE_VERSION }}}}
      
      - name: Download build artifacts
        uses: actions/download-artifact@v3
        with:
          name: build-artifacts
      
      - name: Run ${{{{ matrix.test-suite }}}} tests
        run: |
          npm run test:${{{{ matrix.test-suite }}}}
        env:
          CI: true
          {self._generate_test_env_vars(design)}
      
      - name: Upload coverage reports
        if: matrix.test-suite == 'unit'
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
          flags: unittests
  
  # Security Scan Job
  security:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Run security scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
      
      - name: Upload security results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'
      
      - name: Run SAST analysis
        uses: github/super-linter@v5
        env:
          DEFAULT_BRANCH: main
          GITHUB_TOKEN: ${{{{ secrets.GITHUB_TOKEN }}}}
  
  # Deploy Job
  deploy:
    needs: [test, security]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{{{ secrets.AWS_DEPLOY_ROLE }}}}
          aws-region: ${{{{ env.AWS_REGION }}}}
      
      - name: Deploy to staging
        run: |
          npm run deploy:staging
        env:
          ENVIRONMENT: staging
      
      - name: Run smoke tests
        run: |
          npm run test:smoke -- --env=staging
      
      - name: Deploy to production
        if: success()
        run: |
          npm run deploy:production
        env:
          ENVIRONMENT: production
          DEPLOYMENT_TOKEN: ${{{{ secrets.DEPLOYMENT_TOKEN }}}}
      
      - name: Notify deployment
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{{{ job.status }}}}
          text: 'Deployment ${{{{ job.status }}}} for ${{{{ github.sha }}}}'
        env:
          SLACK_WEBHOOK_URL: ${{{{ secrets.SLACK_WEBHOOK }}}}
'''
        
        return template
```

#### SubTask 3.12.2: 인프라 코드 생성 (IaC)
**담당자**: 인프라 엔지니어  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/implementations/infrastructure_generator.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class InfrastructureComponent:
    name: str
    type: str
    provider: str
    configuration: Dict[str, Any]
    dependencies: List[str]
    outputs: Dict[str, str]

class InfrastructureGenerator:
    """Generate Infrastructure as Code"""
    
    def __init__(self):
        self.terraform_generator = TerraformGenerator()
        self.cloudformation_generator = CloudFormationGenerator()
        self.pulumi_generator = PulumiGenerator()
    
    async def generate_infrastructure(
        self,
        architecture: Dict[str, Any],
        requirements: Dict[str, Any],
        provider: str = "aws"
    ) -> Dict[str, Any]:
        """Generate complete infrastructure code"""
        
        # Design infrastructure components
        components = await self._design_infrastructure_components(
            architecture,
            requirements,
            provider
        )
        
        # Generate IaC based on tool preference
        iac_tool = requirements.get('iac_tool', 'terraform')
        
        if iac_tool == 'terraform':
            iac_code = await self.terraform_generator.generate(
                components,
                provider
            )
        elif iac_tool == 'cloudformation':
            iac_code = await self.cloudformation_generator.generate(
                components
            )
        elif iac_tool == 'pulumi':
            iac_code = await self.pulumi_generator.generate(
                components,
                requirements.get('pulumi_language', 'typescript')
            )
        else:
            raise ValueError(f"Unsupported IaC tool: {iac_tool}")
        
        # Generate deployment scripts
        deployment_scripts = await self._generate_deployment_scripts(
            components,
            iac_tool
        )
        
        # Generate monitoring configuration
        monitoring = await self._generate_infrastructure_monitoring(
            components
        )
        
        return {
            'components': components,
            'iac_code': iac_code,
            'deployment_scripts': deployment_scripts,
            'monitoring': monitoring,
            'cost_estimate': await self._estimate_infrastructure_cost(components)
        }
    
    async def _generate_terraform_aws(
        self,
        components: List[InfrastructureComponent]
    ) -> Dict[str, str]:
        """Generate Terraform code for AWS"""
        
        # Main configuration
        main_tf = '''
terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
  
  backend "s3" {
    bucket = "terraform-state-${var.environment}"
    key    = "infrastructure/terraform.tfstate"
    region = var.aws_region
    
    dynamodb_table = "terraform-state-lock"
    encrypt        = true
  }
}

provider "aws" {
  region = var.aws_region
  
  default_tags {
    tags = {
      Environment = var.environment
      Project     = var.project_name
      ManagedBy   = "Terraform"
      CreatedAt   = timestamp()
    }
  }
}
'''
        
        # Variables
        variables_tf = '''
variable "environment" {
  description = "Environment name"
  type        = string
  
  validation {
    condition     = contains(["dev", "staging", "prod"], var.environment)
    error_message = "Environment must be dev, staging, or prod."
  }
}

variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-east-1"
}

variable "project_name" {
  description = "Project name"
  type        = string
}

variable "vpc_cidr" {
  description = "CIDR block for VPC"
  type        = string
  default     = "10.0.0.0/16"
}

variable "availability_zones" {
  description = "Availability zones"
  type        = list(string)
  default     = ["us-east-1a", "us-east-1b", "us-east-1c"]
}
'''
        
        # Generate module for each component
        modules = {}
        
        for component in components:
            if component.type == 'network':
                modules['network.tf'] = await self._generate_network_module(component)
            elif component.type == 'compute':
                modules['compute.tf'] = await self._generate_compute_module(component)
            elif component.type == 'database':
                modules['database.tf'] = await self._generate_database_module(component)
            elif component.type == 'storage':
                modules['storage.tf'] = await self._generate_storage_module(component)
            elif component.type == 'monitoring':
                modules['monitoring.tf'] = await self._generate_monitoring_module(component)
        
        # Outputs
        outputs_tf = '''
output "vpc_id" {
  description = "VPC ID"
  value       = module.network.vpc_id
}

output "api_endpoint" {
  description = "API Gateway endpoint"
  value       = module.api_gateway.endpoint
}

output "database_endpoint" {
  description = "Database endpoint"
  value       = module.database.endpoint
  sensitive   = true
}

output "monitoring_dashboard" {
  description = "CloudWatch dashboard URL"
  value       = module.monitoring.dashboard_url
}
'''
        
        return {
            'main.tf': main_tf,
            'variables.tf': variables_tf,
            'outputs.tf': outputs_tf,
            **modules
        }
    
    async def _generate_network_module(
        self,
        component: InfrastructureComponent
    ) -> str:
        """Generate network infrastructure"""
        
        config = component.configuration
        
        return f'''
# Network Module
module "network" {{
  source = "./modules/network"
  
  vpc_cidr           = var.vpc_cidr
  availability_zones = var.availability_zones
  environment        = var.environment
  
  enable_nat_gateway = {str(config.get('enable_nat', True)).lower()}
  enable_vpn_gateway = {str(config.get('enable_vpn', False)).lower()}
  
  public_subnet_cidrs = {json.dumps(config.get('public_subnets', ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]))}
  private_subnet_cidrs = {json.dumps(config.get('private_subnets', ["10.0.11.0/24", "10.0.12.0/24", "10.0.13.0/24"]))}
  
  tags = {{
    Name = "${{var.project_name}}-vpc-${{var.environment}}"
  }}
}}

# Security Groups
resource "aws_security_group" "app" {{
  name_prefix = "${{var.project_name}}-app-"
  vpc_id      = module.network.vpc_id
  
  ingress {{
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }}
  
  ingress {{
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }}
  
  egress {{
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }}
  
  lifecycle {{
    create_before_destroy = true
  }}
}}

resource "aws_security_group" "database" {{
  name_prefix = "${{var.project_name}}-db-"
  vpc_id      = module.network.vpc_id
  
  ingress {{
    from_port       = {config.get('db_port', 5432)}
    to_port         = {config.get('db_port', 5432)}
    protocol        = "tcp"
    security_groups = [aws_security_group.app.id]
  }}
  
  egress {{
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }}
}}
'''
```

#### SubTask 3.12.3: 컨테이너화 및 오케스트레이션
**담당자**: 컨테이너 전문가  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/implementations/container_orchestrator.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class ContainerConfig:
    name: str
    image: str
    ports: List[int]
    environment: Dict[str, str]
    resources: Dict[str, Any]
    health_check: Dict[str, Any]

class ContainerOrchestrator:
    """Container and orchestration management"""
    
    def __init__(self):
        self.docker_generator = DockerGenerator()
        self.kubernetes_generator = KubernetesGenerator()
        self.helm_generator = HelmChartGenerator()
    
    async def generate_containerization(
        self,
        services: List[Dict[str, Any]],
        orchestration: str = "kubernetes"
    ) -> Dict[str, Any]:
        """Generate container configurations"""
        
        # Generate Dockerfiles
        dockerfiles = {}
        for service in services:
            dockerfile = await self.docker_generator.generate_dockerfile(
                service
            )
            dockerfiles[service['name']] = dockerfile
        
        # Generate docker-compose
        docker_compose = await self.docker_generator.generate_compose(
            services
        )
        
        # Generate orchestration configs
        if orchestration == "kubernetes":
            k8s_configs = await self.kubernetes_generator.generate_manifests(
                services
            )
            helm_chart = await self.helm_generator.generate_chart(services)
            
            return {
                'dockerfiles': dockerfiles,
                'docker_compose': docker_compose,
                'kubernetes': k8s_configs,
                'helm': helm_chart
            }
        elif orchestration == "ecs":
            ecs_configs = await self._generate_ecs_configs(services)
            return {
                'dockerfiles': dockerfiles,
                'docker_compose': docker_compose,
                'ecs': ecs_configs
            }
        else:
            raise ValueError(f"Unsupported orchestration: {orchestration}")
    
    async def _generate_dockerfile(
        self,
        service: Dict[str, Any]
    ) -> str:
        """Generate optimized Dockerfile"""
        
        if service['type'] == 'node':
            return f'''
# Multi-stage build for Node.js application
FROM node:18-alpine AS builder

# Install build dependencies
RUN apk add --no-cache python3 make g++

# Set working directory
WORKDIR /app

# Copy package files
COPY package*.json ./
COPY lerna.json ./
COPY packages/*/package*.json ./packages/

# Install dependencies
RUN npm ci --only=production

# Copy source code
COPY . .

# Build application
RUN npm run build

# Production stage
FROM node:18-alpine

# Install runtime dependencies
RUN apk add --no-cache tini

# Create non-root user
RUN addgroup -g 1001 -S nodejs && \\
    adduser -S nodejs -u 1001

# Set working directory
WORKDIR /app

# Copy built application
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /app/package*.json ./

# Switch to non-root user
USER nodejs

# Expose port
EXPOSE {service.get('port', 3000)}

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\
  CMD node healthcheck.js || exit 1

# Use tini for proper signal handling
ENTRYPOINT ["/sbin/tini", "--"]

# Start application
CMD ["node", "dist/main.js"]
'''
        
        elif service['type'] == 'python':
            return f'''
# Multi-stage build for Python application
FROM python:3.11-slim AS builder

# Install build dependencies
RUN apt-get update && \\
    apt-get install -y --no-install-recommends \\
    build-essential \\
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --user --no-cache-dir -r requirements.txt

# Production stage
FROM python:3.11-slim

# Install runtime dependencies
RUN apt-get update && \\
    apt-get install -y --no-install-recommends \\
    tini \\
    && rm -rf /var/lib/apt/lists/*

# Create non-root user
RUN useradd -m -u 1001 python

# Set working directory
WORKDIR /app

# Copy Python dependencies
COPY --from=builder /root/.local /home/python/.local

# Copy application
COPY --chown=python:python . .

# Switch to non-root user
USER python

# Update PATH
ENV PATH=/home/python/.local/bin:$PATH

# Expose port
EXPOSE {service.get('port', 8000)}

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\
  CMD python healthcheck.py || exit 1

# Use tini for proper signal handling
ENTRYPOINT ["/usr/bin/tini", "--"]

# Start application
CMD ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "{service.get('port', 8000)}"]
'''
    
    async def _generate_kubernetes_deployment(
        self,
        service: Dict[str, Any]
    ) -> str:
        """Generate Kubernetes deployment manifest"""
        
        return f'''
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {service['name']}
  labels:
    app: {service['name']}
    version: {service.get('version', 'v1')}
spec:
  replicas: {service.get('replicas', 3)}
  selector:
    matchLabels:
      app: {service['name']}
  template:
    metadata:
      labels:
        app: {service['name']}
        version: {service.get('version', 'v1')}
    spec:
      serviceAccountName: {service['name']}
      containers:
      - name: {service['name']}
        image: {service['image']}
        ports:
        - containerPort: {service.get('port', 3000)}
          name: http
        env:
        - name: NODE_ENV
          value: production
        - name: PORT
          value: "{service.get('port', 3000)}"
        resources:
          requests:
            memory: "{service.get('resources', {}).get('memory', '256Mi')}"
            cpu: "{service.get('resources', {}).get('cpu', '100m')}"
          limits:
            memory: "{service.get('resources', {}).get('max_memory', '512Mi')}"
            cpu: "{service.get('resources', {}).get('max_cpu', '500m')}"
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
        securityContext:
          runAsNonRoot: true
          runAsUser: 1001
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
---
apiVersion: v1
kind: Service
metadata:
  name: {service['name']}
  labels:
    app: {service['name']}
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: http
    protocol: TCP
    name: http
  selector:
    app: {service['name']}
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: {service['name']}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: {service['name']}
  minReplicas: {service.get('min_replicas', 2)}
  maxReplicas: {service.get('max_replicas', 10)}
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
'''
```

#### SubTask 3.12.4: 모니터링 및 로깅 시스템
**담당자**: SRE 엔지니어  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/implementations/monitoring_system.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class MonitoringStack:
    metrics_system: str
    logging_system: str
    tracing_system: str
    alerting_system: str
    dashboards: List[Dict[str, Any]]

class MonitoringSystemGenerator:
    """Generate monitoring and observability stack"""
    
    def __init__(self):
        self.metrics_generator = MetricsGenerator()
        self.logging_generator = LoggingGenerator()
        self.tracing_generator = TracingGenerator()
    
    async def generate_monitoring_stack(
        self,
        services: List[Dict[str, Any]],
        infrastructure: Dict[str, Any],
        requirements: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate complete monitoring stack"""
        
        # Select monitoring tools
        stack = await self._select_monitoring_stack(requirements)
        
        # Generate metrics configuration
        metrics_config = await self.metrics_generator.generate_config(
            services,
            stack.metrics_system
        )
        
        # Generate logging configuration
        logging_config = await self.logging_generator.generate_config(
            services,
            stack.logging_system
        )
        
        # Generate tracing configuration
        tracing_config = await self.tracing_generator.generate_config(
            services,
            stack.tracing_system
        )
        
        # Generate dashboards
        dashboards = await self._generate_dashboards(
            services,
            infrastructure,
            stack
        )
        
        # Generate alerts
        alerts = await self._generate_alerts(
            services,
            requirements.get('sla', {})
        )
        
        return {
            'stack': stack,
            'metrics': metrics_config,
            'logging': logging_config,
            'tracing': tracing_config,
            'dashboards': dashboards,
            'alerts': alerts,
            'implementation': await self._generate_implementation(stack)
        }
    
    async def _generate_prometheus_config(
        self,
        services: List[Dict[str, Any]]
    ) -> str:
        """Generate Prometheus configuration"""
        
        scrape_configs = []
        
        for service in services:
            config = f'''
  - job_name: '{service['name']}'
    kubernetes_sd_configs:
    - role: pod
    relabel_configs:
    - source_labels: [__meta_kubernetes_pod_label_app]
      action: keep
      regex: {service['name']}
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
      action: keep
      regex: true
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
      action: replace
      target_label: __metrics_path__
      regex: (.+)
    - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
      action: replace
      regex: ([^:]+)(?::\\d+)?;(\\d+)
      replacement: $1:$2
      target_label: __address__'''
            
            scrape_configs.append(config)
        
        return f'''
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: '{infrastructure.get('cluster_name', 'production')}'
    environment: '{infrastructure.get('environment', 'prod')}'

rule_files:
  - 'alerts/*.yml'
  - 'recording_rules/*.yml'

alerting:
  alertmanagers:
  - kubernetes_sd_configs:
    - role: pod
    relabel_configs:
    - source_labels: [__meta_kubernetes_pod_label_app]
      action: keep
      regex: alertmanager

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
    - targets: ['localhost:9090']
  
  - job_name: 'kubernetes-apiservers'
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
    - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
      action: keep
      regex: default;kubernetes;https

{chr(10).join(scrape_configs)}
'''
    
    async def _generate_grafana_dashboard(
        self,
        service: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate Grafana dashboard JSON"""
        
        return {
            "dashboard": {
                "id": None,
                "uid": f"{service['name']}-dashboard",
                "title": f"{service['name'].title()} Service Dashboard",
                "tags": ["generated", service['name']],
                "timezone": "browser",
                "panels": [
                    {
                        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
                        "id": 1,
                        "title": "Request Rate",
                        "type": "graph",
                        "targets": [
                            {
                                "expr": f'rate(http_requests_total{{job="{service["name"]}"}}[5m])',
                                "refId": "A"
                            }
                        ]
                    },
                    {
                        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
                        "id": 2,
                        "title": "Error Rate",
                        "type": "graph",
                        "targets": [
                            {
                                "expr": f'rate(http_requests_total{{job="{service["name"]}",status=~"5.."}}[5m])',
                                "refId": "A"
                            }
                        ]
                    },
                    {
                        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
                        "id": 3,
                        "title": "Response Time (p95)",
                        "type": "graph",
                        "targets": [
                            {
                                "expr": f'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{{job="{service["name"]}"}}[5m]))',
                                "refId": "A"
                            }
                        ]
                    },
                    {
                        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
                        "id": 4,
                        "title": "CPU Usage",
                        "type": "graph",
                        "targets": [
                            {
                                "expr": f'rate(process_cpu_seconds_total{{job="{service["name"]}"}}[5m])',
                                "refId": "A"
                            }
                        ]
                    }
                ],
                "refresh": "5s",
                "time": {"from": "now-1h", "to": "now"},
                "timepicker": {
                    "refresh_intervals": ["5s", "10s", "30s", "1m", "5m"]
                }
            }
        }
    
    async def _generate_alert_rules(
        self,
        service: Dict[str, Any],
        sla: Dict[str, Any]
    ) -> str:
        """Generate Prometheus alert rules"""
        
        return f'''
groups:
- name: {service['name']}_alerts
  interval: 30s
  rules:
  - alert: HighErrorRate
    expr: |
      (
        sum(rate(http_requests_total{{job="{service['name']}",status=~"5.."}}[5m]))
        /
        sum(rate(http_requests_total{{job="{service['name']}"}}[5m]))
      ) > {sla.get('error_rate_threshold', 0.05)}
    for: 5m
    labels:
      severity: critical
      service: {service['name']}
    annotations:
      summary: "High error rate on {{{{ $labels.service }}}}"
      description: "Error rate is {{{{ $value | humanizePercentage }}}} (threshold: {sla.get('error_rate_threshold', 0.05) * 100}%)"
  
  - alert: HighResponseTime
    expr: |
      histogram_quantile(0.95,
        sum(rate(http_request_duration_seconds_bucket{{job="{service['name']}"}}[5m])) by (le)
      ) > {sla.get('response_time_threshold', 1)}
    for: 5m
    labels:
      severity: warning
      service: {service['name']}
    annotations:
      summary: "High response time on {{{{ $labels.service }}}}"
      description: "95th percentile response time is {{{{ $value }}}}s (threshold: {sla.get('response_time_threshold', 1)}s)"
  
  - alert: ServiceDown
    expr: up{{job="{service['name']}"}} == 0
    for: 1m
    labels:
      severity: critical
      service: {service['name']}
    annotations:
      summary: "Service {{{{ $labels.service }}}} is down"
      description: "Service has been down for more than 1 minute"
  
  - alert: HighMemoryUsage
    expr: |
      (
        process_resident_memory_bytes{{job="{service['name']}"}}
        / 
        {service.get('resources', {}).get('max_memory_bytes', 536870912)}
      ) > 0.9
    for: 5m
    labels:
      severity: warning
      service: {service['name']}
    annotations:
      summary: "High memory usage on {{{{ $labels.service }}}}"
      description: "Memory usage is {{{{ $value | humanizePercentage }}}} of limit"
'''
```

---

### Task 3.13: Document Agent 구현

#### SubTask 3.13.1: 자동 문서 생성기
**담당자**: 기술 문서 작성자  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/implementations/document_agent.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

class DocumentType(Enum):
    API = "api"
    ARCHITECTURE = "architecture"
    USER_GUIDE = "user_guide"
    DEVELOPER_GUIDE = "developer_guide"
    DEPLOYMENT = "deployment"
    TROUBLESHOOTING = "troubleshooting"

@dataclass
class Documentation:
    type: DocumentType
    title: str
    content: str
    format: str  # markdown, html, pdf
    metadata: Dict[str, Any]
    diagrams: List[Dict[str, Any]]

class DocumentAgent(AgnoEnabledAgent, SquadEnabledAgent):
    """Automated documentation generation agent"""
    
    def __init__(self):
        super().__init__(
            name="DocumentAgent",
            agno_config={
                'modelId': 'anthropic.claude-3-opus-v1:0',
                'temperature': 0.5,
                'tools': [
                    'diagram-generator',
                    'api-doc-generator',
                    'markdown-formatter'
                ]
            }
        )
        
        self.doc_generator = DocumentationGenerator()
        self.diagram_generator = DiagramGenerator()
        self.template_engine = TemplateEngine()
    
    async def generate_project_documentation(
        self,
        project_data: Dict[str, Any],
        code_base: Dict[str, Any],
        api_specs: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate complete project documentation"""
        
        documentation = {}
        
        # README
        documentation['README.md'] = await self._generate_readme(
            project_data
        )
        
        # Architecture documentation
        documentation['architecture'] = await self._generate_architecture_docs(
            project_data['architecture']
        )
        
        # API documentation
        documentation['api'] = await self._generate_api_docs(
            api_specs
        )
        
        # Developer guide
        documentation['developer_guide'] = await self._generate_developer_guide(
            project_data,
            code_base
        )
        
        # User guide
        documentation['user_guide'] = await self._generate_user_guide(
            project_data
        )
        
        # Deployment guide
        documentation['deployment'] = await self._generate_deployment_docs(
            project_data['infrastructure']
        )
        
        # Generate documentation site
        documentation['site'] = await self._generate_documentation_site(
            documentation
        )
        
        return documentation
    
    async def _generate_readme(
        self,
        project_data: Dict[str, Any]
    ) -> str:
        """Generate project README"""
        
        template = f'''
# {project_data['name']}

{project_data['description']}

## 🚀 Features

{self._format_features(project_data['features'])}

## 📋 Prerequisites

- Node.js {project_data.get('node_version', '18.x')} or higher
- npm {project_data.get('npm_version', '9.x')} or higher
- AWS Account with appropriate permissions
- Docker (optional, for containerized deployment)

## 🛠️ Installation

### 1. Clone the repository
```bash
git clone {project_data.get('repository_url', 'https://github.com/your-org/project.git')}
cd {project_data['name'].lower().replace(' ', '-')}
```

### 2. Install dependencies
```bash
npm install
npm run bootstrap
```

### 3. Configure environment
```bash
cp .env.example .env
# Edit .env with your configuration
```

### 4. Initialize database
```bash
npm run db:migrate
npm run db:seed
```

## 🏃 Running the Application

### Development
```bash
npm run dev
```

### Production
```bash
npm run build
npm start
```

### Docker
```bash
docker-compose up
```

## 📚 Documentation

- [Architecture Overview](./docs/architecture/README.md)
- [API Documentation](./docs/api/README.md)
- [Developer Guide](./docs/developer-guide/README.md)
- [Deployment Guide](./docs/deployment/README.md)

## 🧪 Testing

```bash
# Unit tests
npm test

# Integration tests
npm run test:integration

# E2E tests
npm run test:e2e

# Coverage report
npm run test:coverage
```

## 📦 Project Structure

```
{self._generate_project_structure(project_data['structure'])}
```

## 🤝 Contributing

Please read [CONTRIBUTING.md](./CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

## 📄 License

This project is licensed under the {project_data.get('license', 'MIT')} License - see the [LICENSE](./LICENSE) file for details.

## 👥 Team

{self._format_team_members(project_data.get('team', []))}

## 🙏 Acknowledgments

{self._format_acknowledgments(project_data.get('acknowledgments', []))}
'''
        
        return template
    
    async def _generate_api_documentation(
        self,
        api_specs: Dict[str, Any]
    ) -> Dict[str, str]:
        """Generate API documentation"""
        
        # OpenAPI/Swagger documentation
        openapi_doc = await self._generate_openapi_docs(api_specs)
        
        # Markdown API reference
        api_reference = f'''
# API Reference

Base URL: `{api_specs.get('base_url', 'https://api.example.com')}`

## Authentication

{self._document_authentication(api_specs.get('authentication', {}))}

## Rate Limiting

{self._document_rate_limiting(api_specs.get('rate_limiting', {}))}

## Endpoints

{self._generate_endpoint_documentation(api_specs.get('endpoints', []))}

## Error Handling

{self._document_error_handling(api_specs.get('errors', {}))}

## Webhooks

{self._document_webhooks(api_specs.get('webhooks', []))}

## SDKs

### JavaScript/TypeScript
```bash
npm install {api_specs.get('sdk_name', '@company/api-sdk')}
```

```javascript
const {{ ApiClient }} = require('{api_specs.get('sdk_name', '@company/api-sdk')}');

const client = new ApiClient({{
  apiKey: 'your-api-key',
  baseUrl: '{api_specs.get('base_url', 'https://api.example.com')}'
}});

// Example usage
const result = await client.resource.list();
```

### Python
```bash
pip install {api_specs.get('sdk_name', 'company-api-sdk').replace('@', '').replace('/', '-')}
```

```python
from {api_specs.get('sdk_name', 'company_api_sdk').replace('@', '').replace('/', '_').replace('-', '_')} import ApiClient

client = ApiClient(
    api_key='your-api-key',
    base_url='{api_specs.get('base_url', 'https://api.example.com')}'
)

# Example usage
result = client.resource.list()
```

## Postman Collection

Download our [Postman Collection](./postman-collection.json) for easy API testing.

## GraphQL Schema

{self._generate_graphql_docs(api_specs.get('graphql', {}))}
'''
        
        return {
            'openapi.yaml': openapi_doc,
            'API_REFERENCE.md': api_reference,
            'AUTHENTICATION.md': await self._generate_auth_guide(api_specs),
            'EXAMPLES.md': await self._generate_api_examples(api_specs)
        }
```

#### SubTask 3.13.2: 다이어그램 자동 생성
**담당자**: 시스템 설계자  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/implementations/diagram_generator.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class Diagram:
    type: str  # architecture, sequence, flow, erd, deployment
    title: str
    format: str  # mermaid, plantuml, drawio
    content: str
    metadata: Dict[str, Any]

class DiagramGenerator:
    """Generate technical diagrams automatically"""
    
    def __init__(self):
        self.mermaid_generator = MermaidGenerator()
        self.plantuml_generator = PlantUMLGenerator()
        self.drawio_generator = DrawIOGenerator()
    
    async def generate_architecture_diagram(
        self,
        architecture: Dict[str, Any],
        format: str = "mermaid"
    ) -> Diagram:
        """Generate system architecture diagram"""
        
        if format == "mermaid":
            content = await self._generate_mermaid_architecture(architecture)
        elif format == "plantuml":
            content = await self._generate_plantuml_architecture(architecture)
        else:
            raise ValueError(f"Unsupported format: {format}")
        
        return Diagram(
            type="architecture",
            title="System Architecture",
            format=format,
            content=content,
            metadata={
                'components': len(architecture.get('components', [])),
                'layers': architecture.get('layers', [])
            }
        )
    
    async def _generate_mermaid_architecture(
        self,
        architecture: Dict[str, Any]
    ) -> str:
        """Generate Mermaid architecture diagram"""
        
        components = architecture.get('components', [])
        connections = architecture.get('connections', [])
        
        diagram = '''graph TB
    subgraph "Client Layer"
        WEB[Web Application]
        MOBILE[Mobile App]
        API_CLIENT[API Client]
    end
    
    subgraph "API Gateway"
        GATEWAY[API Gateway]
        AUTH[Auth Service]
        RATE_LIMIT[Rate Limiter]
    end
    
    subgraph "Application Layer"
'''
        
        # Add application components
        for comp in components:
            if comp['layer'] == 'application':
                diagram += f"        {comp['id']}[{comp['name']}]\n"
        
        diagram += '''    end
    
    subgraph "Data Layer"
        DB[(Database)]
        CACHE[(Redis Cache)]
        QUEUE[Message Queue]
        STORAGE[Object Storage]
    end
    
    subgraph "External Services"
        PAYMENT[Payment Service]
        EMAIL[Email Service]
        SMS[SMS Service]
        ANALYTICS[Analytics]
    end
'''
        
        # Add connections
        for conn in connections:
            style = self._get_connection_style(conn)
            diagram += f"    {conn['from']} {style} {conn['to']}\n"
        
        # Add styling
        diagram += '''
    classDef clientStyle fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef apiStyle fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef appStyle fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px
    classDef dataStyle fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef externalStyle fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    
    class WEB,MOBILE,API_CLIENT clientStyle
    class GATEWAY,AUTH,RATE_LIMIT apiStyle
    class DB,CACHE,QUEUE,STORAGE dataStyle
    class PAYMENT,EMAIL,SMS,ANALYTICS externalStyle
'''
        
        return diagram
    
    async def generate_sequence_diagram(
        self,
        flow: Dict[str, Any],
        format: str = "mermaid"
    ) -> Diagram:
        """Generate sequence diagram for a flow"""
        
        participants = flow.get('participants', [])
        steps = flow.get('steps', [])
        
        if format == "mermaid":
            diagram = "sequenceDiagram\n"
            
            # Add participants
            for p in participants:
                diagram += f"    participant {p['id']} as {p['name']}\n"
            
            diagram += "\n"
            
            # Add interactions
            for step in steps:
                if step['type'] == 'request':
                    diagram += f"    {step['from']}->>+{step['to']}: {step['message']}\n"
                elif step['type'] == 'response':
                    diagram += f"    {step['from']}-->>-{step['to']}: {step['message']}\n"
                elif step['type'] == 'note':
                    diagram += f"    Note over {step['participant']}: {step['message']}\n"
                elif step['type'] == 'loop':
                    diagram += f"    loop {step['condition']}\n"
                    for sub_step in step['steps']:
                        diagram += f"        {sub_step['from']}->{sub_step['to']}: {sub_step['message']}\n"
                    diagram += "    end\n"
            
            return Diagram(
                type="sequence",
                title=flow.get('title', 'Sequence Diagram'),
                format=format,
                content=diagram,
                metadata={'steps': len(steps)}
            )
    
    async def generate_er_diagram(
        self,
        data_model: Dict[str, Any],
        format: str = "mermaid"
    ) -> Diagram:
        """Generate Entity Relationship diagram"""
        
        entities = data_model.get('entities', [])
        relationships = data_model.get('relationships', [])
        
        if format == "mermaid":
            diagram = "erDiagram\n"
            
            # Add entities and attributes
            for entity in entities:
                diagram += f"    {entity['name']} {{\n"
                for attr in entity['attributes']:
                    type_str = attr['type'].upper()
                    key_str = ' PK' if attr.get('primary_key') else ''
                    key_str += ' FK' if attr.get('foreign_key') else ''
                    nullable = '?' if attr.get('nullable', True) else ''
                    
                    diagram += f"        {type_str} {attr['name']}{key_str}{nullable}\n"
                diagram += "    }\n\n"
            
            # Add relationships
            for rel in relationships:
                cardinality = self._get_cardinality_notation(rel['type'])
                diagram += f"    {rel['from']} {cardinality} {rel['to']} : {rel['name']}\n"
            
            return Diagram(
                type="erd",
                title="Entity Relationship Diagram",
                format=format,
                content=diagram,
                metadata={
                    'entities': len(entities),
                    'relationships': len(relationships)
                }
            )
    
    async def generate_deployment_diagram(
        self,
        infrastructure: Dict[str, Any],
        format: str = "mermaid"
    ) -> Diagram:
        """Generate deployment diagram"""
        
        if format == "mermaid":
            diagram = '''graph TB
    subgraph "AWS Cloud"
        subgraph "VPC"
            subgraph "Public Subnet"
                ALB[Application Load Balancer]
                NAT[NAT Gateway]
            end
            
            subgraph "Private Subnet A"
                ECS_A[ECS Service A]
                FARGATE_A[Fargate Tasks]
            end
            
            subgraph "Private Subnet B"
                ECS_B[ECS Service B]
                FARGATE_B[Fargate Tasks]
            end
            
            subgraph "Data Subnet"
                RDS[(RDS Multi-AZ)]
                REDIS[(ElastiCache Redis)]
            end
        end
        
        subgraph "AWS Services"
            S3[S3 Bucket]
            CF[CloudFront CDN]
            CW[CloudWatch]
            SECRETS[Secrets Manager]
        end
    end
    
    subgraph "External"
        USERS[Users]
        MONITORING[Monitoring Service]
    end
    
    USERS --> CF
    CF --> S3
    USERS --> ALB
    ALB --> ECS_A
    ALB --> ECS_B
    ECS_A --> RDS
    ECS_B --> RDS
    ECS_A --> REDIS
    ECS_B --> REDIS
    ECS_A --> SECRETS
    ECS_B --> SECRETS
    CW --> MONITORING
'''
            
            return Diagram(
                type="deployment",
                title="Deployment Architecture",
                format=format,
                content=diagram,
                metadata=infrastructure
            )
```

#### SubTask 3.13.3: API 문서 자동화
**담당자**: API 문서 전문가  
**예상 소요시간**: 10시간

**작업 내용**:
```python
# backend/src/agents/implementations/api_doc_generator.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class APIDocumentation:
    openapi_spec: Dict[str, Any]
    markdown_docs: Dict[str, str]
    postman_collection: Dict[str, Any]
    examples: Dict[str, Any]

class APIDocGenerator:
    """Generate comprehensive API documentation"""
    
    def __init__(self):
        self.openapi_generator = OpenAPIGenerator()
        self.example_generator = ExampleGenerator()
        self.sdk_generator = SDKGenerator()
    
    async def generate_api_documentation(
        self,
        api_specs: Dict[str, Any],
        code_examples: Dict[str, Any]
    ) -> APIDocumentation:
        """Generate complete API documentation package"""
        
        # Generate OpenAPI specification
        openapi_spec = await self.openapi_generator.generate(api_specs)
        
        # Generate markdown documentation
        markdown_docs = await self._generate_markdown_docs(
            api_specs,
            openapi_spec
        )
        
        # Generate Postman collection
        postman_collection = await self._generate_postman_collection(
            api_specs
        )
        
        # Generate code examples
        examples = await self.example_generator.generate_examples(
            api_specs,
            ['javascript', 'python', 'curl', 'java', 'go']
        )
        
        return APIDocumentation(
            openapi_spec=openapi_spec,
            markdown_docs=markdown_docs,
            postman_collection=postman_collection,
            examples=examples
        )
    
    async def _generate_openapi_spec(
        self,
        api_specs: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate OpenAPI 3.0 specification"""
        
        return {
            "openapi": "3.0.0",
            "info": {
                "title": api_specs.get('title', 'API'),
                "version": api_specs.get('version', '1.0.0'),
                "description": api_specs.get('description', ''),
                "contact": api_specs.get('contact', {}),
                "license": api_specs.get('license', {})
            },
            "servers": [
                {
                    "url": api_specs.get('base_url', 'https://api.example.com'),
                    "description": "Production server"
                },
                {
                    "url": api_specs.get('staging_url', 'https://staging-api.example.com'),
                    "description": "Staging server"
                }
            ],
            "paths": await self._generate_paths(api_specs.get('endpoints', [])),
            "components": {
                "schemas": await self._generate_schemas(api_specs.get('models', {})),
                "securitySchemes": await self._generate_security_schemes(
                    api_specs.get('authentication', {})
                ),
                "responses": await self._generate_common_responses()
            },
            "security": await self._generate_security_requirements(
                api_specs.get('authentication', {})
            )
        }
    
    async def _generate_endpoint_documentation(
        self,
        endpoint: Dict[str, Any]
    ) -> str:
        """Generate markdown documentation for an endpoint"""
        
        doc = f'''
### {endpoint['method']} {endpoint['path']}

{endpoint.get('description', '')}

#### Request

**Headers**
```http
{self._format_headers(endpoint.get('headers', {}))}
```

**Path Parameters**
{self._format_parameters(endpoint.get('path_params', []))}

**Query Parameters**
{self._format_parameters(endpoint.get('query_params', []))}

**Request Body**
```json
{json.dumps(endpoint.get('request_body_example', {}), indent=2)}
```

**Schema**
```json
{json.dumps(endpoint.get('request_schema', {}), indent=2)}
```

#### Response

**Success Response (200 OK)**
```json
{json.dumps(endpoint.get('response_example', {}), indent=2)}
```

**Error Responses**
{self._format_error_responses(endpoint.get('error_responses', []))}

#### Examples

{self._generate_code_examples(endpoint)}

#### Rate Limiting
- Rate Limit: {endpoint.get('rate_limit', '100 requests per minute')}
- Burst: {endpoint.get('burst_limit', '10 requests')}

#### Notes
{endpoint.get('notes', 'None')}
'''
        
        return doc
    
    async def _generate_code_examples(
        self,
        endpoint: Dict[str, Any]
    ) -> str:
        """Generate code examples for different languages"""
        
        examples = ""
        
        # cURL example
        examples += f'''
**cURL**
```bash
curl -X {endpoint['method']} \\
  '{endpoint['base_url']}{endpoint['path']}' \\
  -H 'Authorization: Bearer YOUR_API_KEY' \\
  -H 'Content-Type: application/json' \\
  {"-d '" + json.dumps(endpoint.get('request_body_example', {})) + "'" if endpoint['method'] in ['POST', 'PUT', 'PATCH'] else ''}
```
'''
        
        # JavaScript example
        examples += f'''
**JavaScript (Fetch)**
```javascript
const response = await fetch('{endpoint['base_url']}{endpoint['path']}', {{
  method: '{endpoint['method']}',
  headers: {{
    'Authorization': 'Bearer YOUR_API_KEY',
    'Content-Type': 'application/json'
  }},
  {f"body: JSON.stringify({json.dumps(endpoint.get('request_body_example', {}))})" if endpoint['method'] in ['POST', 'PUT', 'PATCH'] else ''}
}});

const data = await response.json();
console.log(data);
```
'''
        
        # Python example
        examples += f'''
**Python (Requests)**
```python
import requests

headers = {{
    'Authorization': 'Bearer YOUR_API_KEY',
    'Content-Type': 'application/json'
}}

response = requests.{endpoint['method'].lower()}(
    '{endpoint['base_url']}{endpoint['path']}',
    headers=headers,
    {f"json={endpoint.get('request_body_example', {})}" if endpoint['method'] in ['POST', 'PUT', 'PATCH'] else ''}
)

data = response.json()
print(data)
```
'''
        
        return examples
```

#### SubTask 3.13.4: 변경 로그 자동 생성
**담당자**: 릴리즈 관리자  
**예상 소요시간**: 8시간

**작업 내용**:
```python
# backend/src/agents/implementations/changelog_generator.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ChangeEntry:
    version: str
    date: datetime
    type: str  # added, changed, deprecated, removed, fixed, security
    description: str
    breaking: bool = False
    pr_number: Optional[int] = None
    issue_number: Optional[int] = None

class ChangelogGenerator:
    """Generate and maintain project changelog"""
    
    def __init__(self):
        self.commit_analyzer = CommitAnalyzer()
        self.version_manager = VersionManager()
        self.release_notes_generator = ReleaseNotesGenerator()
    
    async def generate_changelog(
        self,
        git_history: List[Dict[str, Any]],
        current_version: str,
        previous_releases: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Generate comprehensive changelog"""
        
        # Analyze commits since last release
        changes = await self.commit_analyzer.analyze_commits(
            git_history,
            since_version=previous_releases[0]['version'] if previous_releases else None
        )
        
        # Categorize changes
        categorized_changes = await self._categorize_changes(changes)
        
```python
        # Generate version number
        next_version = await self.version_manager.calculate_next_version(
            current_version,
            categorized_changes
        )
        
        # Generate changelog entries
        changelog = await self._generate_changelog_content(
            next_version,
            categorized_changes,
            previous_releases
        )
        
        # Generate release notes
        release_notes = await self.release_notes_generator.generate(
            next_version,
            categorized_changes
        )
        
        return {
            'version': next_version,
            'changelog': changelog,
            'release_notes': release_notes,
            'migration_guide': await self._generate_migration_guide(
                categorized_changes['breaking']
            )
        }
    
    async def _generate_changelog_content(
        self,
        version: str,
        changes: Dict[str, List[ChangeEntry]],
        previous_releases: List[Dict[str, Any]]
    ) -> str:
        """Generate CHANGELOG.md content"""
        
        changelog = '''# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

'''
        
        # Add unreleased section
        if changes.get('unreleased'):
            changelog += "## [Unreleased]\n\n"
            changelog += self._format_changes(changes['unreleased'])
            changelog += "\n"
        
        # Add current version
        changelog += f"## [{version}] - {datetime.now().strftime('%Y-%m-%d')}\n\n"
        
        for category in ['added', 'changed', 'deprecated', 'removed', 'fixed', 'security']:
            if changes.get(category):
                changelog += f"### {category.capitalize()}\n"
                for change in changes[category]:
                    breaking = " **BREAKING**" if change.breaking else ""
                    pr_link = f" ([#{change.pr_number}](#{change.pr_number}))" if change.pr_number else ""
                    changelog += f"- {change.description}{breaking}{pr_link}\n"
                changelog += "\n"
        
        # Add previous releases
        for release in previous_releases[:10]:  # Last 10 releases
            changelog += f"## [{release['version']}] - {release['date']}\n\n"
            changelog += release['content']
            changelog += "\n"
        
        # Add links section
        changelog += self._generate_version_links(version, previous_releases)
        
        return changelog
    
    async def _generate_migration_guide(
        self,
        breaking_changes: List[ChangeEntry]
    ) -> Optional[str]:
        """Generate migration guide for breaking changes"""
        
        if not breaking_changes:
            return None
        
        guide = f'''# Migration Guide

This guide helps you migrate from the previous version to {version}.

## Breaking Changes

'''
        
        for i, change in enumerate(breaking_changes, 1):
            guide += f"### {i}. {change.description}\n\n"
            
            # Generate migration steps based on change type
            migration_steps = await self._analyze_breaking_change(change)
            
            guide += "**What changed:**\n"
            guide += f"{migration_steps['description']}\n\n"
            
            guide += "**Before:**\n```javascript\n"
            guide += f"{migration_steps['before']}\n```\n\n"
            
            guide += "**After:**\n```javascript\n"
            guide += f"{migration_steps['after']}\n```\n\n"
            
            guide += "**Migration steps:**\n"
            for step in migration_steps['steps']:
                guide += f"1. {step}\n"
            guide += "\n"
        
        guide += '''## Automated Migration

You can use our migration tool to automatically update your code:

```bash
npx @company/migration-tool@latest migrate --from=previous_version --to=current_version
```

## Need Help?

If you encounter any issues during migration:

1. Check our [FAQ](./docs/migration-faq.md)
2. Search [existing issues](https://github.com/company/project/issues)
3. Join our [Discord community](https://discord.gg/company)
4. Contact support at support@company.com
'''
        
        return guide
```

---

### Task 3.14: 에이전트 간 협업 프로토콜

#### SubTask 3.14.1: 메시지 교환 시스템
**담당자**: 시스템 통합 전문가  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/framework/collaboration_protocol.py
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass
from enum import Enum
import asyncio
from datetime import datetime

class MessageType(Enum):
    REQUEST = "request"
    RESPONSE = "response"
    EVENT = "event"
    COMMAND = "command"
    QUERY = "query"
    NOTIFICATION = "notification"

@dataclass
class AgentMessage:
    id: str
    type: MessageType
    sender: str
    receiver: str
    payload: Dict[str, Any]
    timestamp: datetime
    correlation_id: Optional[str] = None
    priority: int = 0
    ttl: Optional[int] = None

class CollaborationProtocol:
    """Inter-agent communication and collaboration protocol"""
    
    def __init__(self):
        self.message_bus = MessageBus()
        self.registry = AgentRegistry()
        self.router = MessageRouter()
        self.orchestrator = CollaborationOrchestrator()
    
    async def setup_collaboration_framework(
        self,
        agents: List[Dict[str, Any]],
        workflows: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Setup agent collaboration framework"""
        
        # Register agents
        for agent in agents:
            await self.registry.register_agent(agent)
        
        # Setup message routing
        routing_rules = await self._create_routing_rules(agents, workflows)
        await self.router.configure(routing_rules)
        
        # Setup collaboration patterns
        patterns = await self._setup_collaboration_patterns(workflows)
        
        # Generate protocol implementation
        implementation = await self._generate_protocol_implementation(
            agents,
            patterns
        )
        
        return {
            'registry': self.registry.get_configuration(),
            'routing': routing_rules,
            'patterns': patterns,
            'implementation': implementation,
            'monitoring': await self._setup_collaboration_monitoring()
        }
    
    async def _generate_message_bus_implementation(self) -> str:
        """Generate message bus implementation"""
        
        return '''
import { EventEmitter } from 'events';
import { v4 as uuidv4 } from 'uuid';
import pino from 'pino';

export interface AgentMessage {
    id: string;
    type: MessageType;
    sender: string;
    receiver: string;
    payload: any;
    timestamp: Date;
    correlationId?: string;
    priority: number;
    ttl?: number;
}

export enum MessageType {
    REQUEST = 'request',
    RESPONSE = 'response',
    EVENT = 'event',
    COMMAND = 'command',
    QUERY = 'query',
    NOTIFICATION = 'notification'
}

export class MessageBus extends EventEmitter {
    private readonly logger = pino();
    private readonly messageStore = new Map<string, AgentMessage>();
    private readonly subscriptions = new Map<string, Set<string>>();
    private readonly messageQueue = new PriorityQueue<AgentMessage>();
    
    constructor() {
        super();
        this.setMaxListeners(100);
        this.startMessageProcessor();
    }
    
    async publish(message: Omit<AgentMessage, 'id' | 'timestamp'>): Promise<string> {
        const fullMessage: AgentMessage = {
            ...message,
            id: uuidv4(),
            timestamp: new Date()
        };
        
        // Validate message
        this.validateMessage(fullMessage);
        
        // Store message
        this.messageStore.set(fullMessage.id, fullMessage);
        
        // Add to queue
        this.messageQueue.enqueue(fullMessage, fullMessage.priority);
        
        // Log
        this.logger.info({
            messageId: fullMessage.id,
            type: fullMessage.type,
            sender: fullMessage.sender,
            receiver: fullMessage.receiver
        }, 'Message published');
        
        return fullMessage.id;
    }
    
    async subscribe(
        agentId: string,
        patterns: string[]
    ): Promise<() => void> {
        patterns.forEach(pattern => {
            if (!this.subscriptions.has(pattern)) {
                this.subscriptions.set(pattern, new Set());
            }
            this.subscriptions.get(pattern)!.add(agentId);
        });
        
        // Return unsubscribe function
        return () => {
            patterns.forEach(pattern => {
                this.subscriptions.get(pattern)?.delete(agentId);
            });
        };
    }
    
    private async startMessageProcessor(): Promise<void> {
        while (true) {
            if (!this.messageQueue.isEmpty()) {
                const message = this.messageQueue.dequeue();
                await this.processMessage(message);
            }
            
            // Small delay to prevent CPU spinning
            await new Promise(resolve => setTimeout(resolve, 10));
        }
    }
    
    private async processMessage(message: AgentMessage): Promise<void> {
        try {
            // Direct delivery
            if (message.receiver !== '*') {
                this.emit(`agent:${message.receiver}`, message);
            } else {
                // Broadcast
                this.emit('broadcast', message);
            }
            
            // Pattern-based delivery
            const patterns = this.getMatchingPatterns(message);
            for (const pattern of patterns) {
                const subscribers = this.subscriptions.get(pattern) || new Set();
                for (const subscriber of subscribers) {
                    this.emit(`agent:${subscriber}`, message);
                }
            }
            
            // Check TTL
            if (message.ttl) {
                setTimeout(() => {
                    this.messageStore.delete(message.id);
                }, message.ttl);
            }
            
        } catch (error) {
            this.logger.error({ error, message }, 'Error processing message');
            this.emit('error', error);
        }
    }
    
    private validateMessage(message: AgentMessage): void {
        if (!message.sender || !message.receiver) {
            throw new Error('Message must have sender and receiver');
        }
        
        if (!Object.values(MessageType).includes(message.type)) {
            throw new Error(`Invalid message type: ${message.type}`);
        }
        
        if (message.ttl && message.ttl < 0) {
            throw new Error('TTL must be positive');
        }
    }
    
    private getMatchingPatterns(message: AgentMessage): string[] {
        const patterns: string[] = [];
        
        // Type-based patterns
        patterns.push(`type:${message.type}`);
        
        // Sender patterns
        patterns.push(`from:${message.sender}`);
        
        // Custom patterns from payload
        if (message.payload.tags) {
            message.payload.tags.forEach((tag: string) => {
                patterns.push(`tag:${tag}`);
            });
        }
        
        return patterns;
    }
}

// Agent communication wrapper
export class AgentCommunicator {
    constructor(
        private readonly agentId: string,
        private readonly messageBus: MessageBus
    ) {
        this.setupMessageHandling();
    }
    
    async sendRequest<T = any>(
        targetAgent: string,
        operation: string,
        data: any,
        options: { timeout?: number; priority?: number } = {}
    ): Promise<T> {
        const correlationId = uuidv4();
        
        // Send request
        await this.messageBus.publish({
            type: MessageType.REQUEST,
            sender: this.agentId,
            receiver: targetAgent,
            payload: { operation, data },
            correlationId,
            priority: options.priority || 0
        });
        
        // Wait for response
        return new Promise((resolve, reject) => {
            const timeout = setTimeout(() => {
                this.messageBus.off(`response:${correlationId}`, responseHandler);
                reject(new Error(`Request timeout for ${operation}`));
            }, options.timeout || 30000);
            
            const responseHandler = (message: AgentMessage) => {
                clearTimeout(timeout);
                if (message.payload.error) {
                    reject(new Error(message.payload.error));
                } else {
                    resolve(message.payload.result);
                }
            };
            
            this.messageBus.once(`response:${correlationId}`, responseHandler);
        });
    }
    
    async broadcast(
        event: string,
        data: any
    ): Promise<void> {
        await this.messageBus.publish({
            type: MessageType.EVENT,
            sender: this.agentId,
            receiver: '*',
            payload: { event, data },
            priority: 0
        });
    }
    
    onRequest(
        operation: string,
        handler: (data: any) => Promise<any>
    ): void {
        this.messageBus.on(`agent:${this.agentId}`, async (message: AgentMessage) => {
            if (
                message.type === MessageType.REQUEST &&
                message.payload.operation === operation
            ) {
                try {
                    const result = await handler(message.payload.data);
                    
                    // Send response
                    await this.messageBus.publish({
                        type: MessageType.RESPONSE,
                        sender: this.agentId,
                        receiver: message.sender,
                        payload: { result },
                        correlationId: message.correlationId,
                        priority: message.priority
                    });
                } catch (error: any) {
                    // Send error response
                    await this.messageBus.publish({
                        type: MessageType.RESPONSE,
                        sender: this.agentId,
                        receiver: message.sender,
                        payload: { error: error.message },
                        correlationId: message.correlationId,
                        priority: message.priority
                    });
                }
            }
        });
    }
    
    private setupMessageHandling(): void {
        this.messageBus.on(`agent:${this.agentId}`, (message: AgentMessage) => {
            this.handleMessage(message);
        });
        
        // Also listen for broadcasts
        this.messageBus.on('broadcast', (message: AgentMessage) => {
            if (message.sender !== this.agentId) {
                this.handleMessage(message);
            }
        });
    }
    
    private async handleMessage(message: AgentMessage): Promise<void> {
        // Emit local events for different message types
        this.messageBus.emit(`${message.type}:${message.correlationId || message.id}`, message);
    }
}
'''
```

#### SubTask 3.14.2: 작업 조율 메커니즘
**담당자**: 워크플로우 설계자  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/framework/task_coordination.py
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass
from enum import Enum
import asyncio

class CoordinationPattern(Enum):
    SEQUENTIAL = "sequential"
    PARALLEL = "parallel"
    PIPELINE = "pipeline"
    SCATTER_GATHER = "scatter_gather"
    SAGA = "saga"
    CHOREOGRAPHY = "choreography"

@dataclass
class CoordinatedTask:
    id: str
    agent: str
    operation: str
    input_data: Dict[str, Any]
    dependencies: List[str]
    timeout: int
    retry_policy: Dict[str, Any]
    compensation: Optional[Dict[str, Any]] = None

class TaskCoordinator:
    """Coordinate tasks across multiple agents"""
    
    def __init__(self):
        self.execution_engine = ExecutionEngine()
        self.dependency_resolver = DependencyResolver()
        self.compensation_manager = CompensationManager()
    
    async def coordinate_workflow(
        self,
        workflow: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Coordinate multi-agent workflow execution"""
        
        pattern = CoordinationPattern(workflow['pattern'])
        tasks = await self._prepare_tasks(workflow['tasks'], context)
        
        if pattern == CoordinationPattern.SEQUENTIAL:
            result = await self._execute_sequential(tasks)
        elif pattern == CoordinationPattern.PARALLEL:
            result = await self._execute_parallel(tasks)
        elif pattern == CoordinationPattern.PIPELINE:
            result = await self._execute_pipeline(tasks)
        elif pattern == CoordinationPattern.SCATTER_GATHER:
            result = await self._execute_scatter_gather(tasks)
        elif pattern == CoordinationPattern.SAGA:
            result = await self._execute_saga(tasks)
        else:
            raise ValueError(f"Unsupported pattern: {pattern}")
        
        return {
            'workflow_id': workflow['id'],
            'pattern': pattern.value,
            'result': result,
            'execution_time': self._calculate_execution_time(),
            'task_results': await self._get_task_results()
        }
    
    async def _execute_saga(
        self,
        tasks: List[CoordinatedTask]
    ) -> Dict[str, Any]:
        """Execute saga pattern with compensations"""
        
        completed_tasks = []
        results = {}
        
        try:
            # Execute tasks in sequence
            for task in tasks:
                result = await self.execution_engine.execute_task(task)
                completed_tasks.append(task)
                results[task.id] = result
                
                # Check if we should continue
                if result.get('status') == 'failed':
                    raise Exception(f"Task {task.id} failed")
            
            return {
                'status': 'completed',
                'results': results
            }
            
        except Exception as e:
            # Compensate in reverse order
            for task in reversed(completed_tasks):
                if task.compensation:
                    await self.compensation_manager.compensate(task)
            
            return {
                'status': 'compensated',
                'error': str(e),
                'compensated_tasks': [t.id for t in completed_tasks]
            }
    
    async def generate_coordination_code(
        self,
        pattern: CoordinationPattern,
        agents: List[str]
    ) -> str:
        """Generate coordination implementation"""
        
        if pattern == CoordinationPattern.PIPELINE:
            return self._generate_pipeline_coordinator(agents)
        elif pattern == CoordinationPattern.SCATTER_GATHER:
            return self._generate_scatter_gather_coordinator(agents)
        else:
            return self._generate_generic_coordinator(pattern, agents)
    
    def _generate_pipeline_coordinator(self, agents: List[str]) -> str:
        """Generate pipeline coordination code"""
        
        return f'''
export class PipelineCoordinator {{
    private readonly agents = {json.dumps(agents)};
    private readonly communicator: AgentCommunicator;
    
    constructor(communicator: AgentCommunicator) {{
        this.communicator = communicator;
    }}
    
    async executePipeline<T = any>(
        initialInput: any,
        operations: string[]
    ): Promise<T> {{
        let result = initialInput;
        const stageResults = [];
        
        for (let i = 0; i < this.agents.length; i++) {{
            const agent = this.agents[i];
            const operation = operations[i] || 'process';
            
            try {{
                result = await this.communicator.sendRequest(
                    agent,
                    operation,
                    {{
                        input: result,
                        stage: i,
                        previousResults: stageResults
                    }}
                );
                
                stageResults.push({{
                    agent,
                    operation,
                    result
                }});
                
            }} catch (error) {{
                throw new PipelineError(
                    `Pipeline failed at stage ${{i}} (agent: ${{agent}})`,
                    {{ stage: i, agent, error }}
                );
            }}
        }}
        
        return result;
    }}
    
    async executePipelineWithMonitoring<T = any>(
        initialInput: any,
        operations: string[],
        monitor: (stage: number, result: any) => void
    ): Promise<T> {{
        let result = initialInput;
        
        for (let i = 0; i < this.agents.length; i++) {{
            const startTime = Date.now();
            result = await this.executeStage(i, result, operations[i]);
            const duration = Date.now() - startTime;
            
            monitor(i, {{
                agent: this.agents[i],
                operation: operations[i],
                duration,
                result
            }});
        }}
        
        return result;
    }}
    
    private async executeStage(
        stageIndex: number,
        input: any,
        operation: string
    ): Promise<any> {{
        const agent = this.agents[stageIndex];
        const maxRetries = 3;
        let lastError;
        
        for (let attempt = 0; attempt < maxRetries; attempt++) {{
            try {{
                return await this.communicator.sendRequest(
                    agent,
                    operation,
                    input,
                    {{ timeout: 30000 }}
                );
            }} catch (error) {{
                lastError = error;
                if (attempt < maxRetries - 1) {{
                    await this.delay(Math.pow(2, attempt) * 1000);
                }}
            }}
        }}
        
        throw lastError;
    }}
    
    private delay(ms: number): Promise<void> {{
        return new Promise(resolve => setTimeout(resolve, ms));
    }}
}}
'''
```

#### SubTask 3.14.3: 상태 공유 시스템
**담당자**: 분산 시스템 전문가  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/framework/state_sharing.py
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass
from enum import Enum
import asyncio

class StateScope(Enum):
    LOCAL = "local"
    SHARED = "shared"
    GLOBAL = "global"
    PERSISTENT = "persistent"

@dataclass
class SharedState:
    key: str
    value: Any
    scope: StateScope
    owner: str
    version: int
    timestamp: datetime
    ttl: Optional[int] = None
    access_control: Optional[Dict[str, Set[str]]] = None

class StateSharing:
    """Distributed state sharing system for agents"""
    
    def __init__(self):
        self.state_store = DistributedStateStore()
        self.sync_manager = SynchronizationManager()
        self.access_controller = AccessController()
    
    async def setup_state_sharing(
        self,
        agents: List[Dict[str, Any]],
        state_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Setup state sharing infrastructure"""
        
        # Configure state store
        await self.state_store.configure(state_config)
        
        # Setup synchronization
        sync_config = await self.sync_manager.setup(
            agents,
            state_config.get('sync_strategy', 'eventual')
        )
        
        # Configure access control
        access_rules = await self.access_controller.configure(
            agents,
            state_config.get('access_rules', {})
        )
        
        # Generate implementation
        implementation = await self._generate_state_sharing_code(
            state_config,
            sync_config,
            access_rules
        )
        
        return {
            'store_config': self.state_store.get_config(),
            'sync_config': sync_config,
            'access_rules': access_rules,
            'implementation': implementation
        }
    
    async def _generate_state_sharing_code(
        self,
        config: Dict[str, Any],
        sync_config: Dict[str, Any],
        access_rules: Dict[str, Any]
    ) -> str:
        """Generate state sharing implementation"""
        
        return f'''
import {{ EventEmitter }} from 'events';
import Redis from 'ioredis';
import {{ DynamoDBClient }} from '@aws-sdk/client-dynamodb';

export interface SharedStateOptions {{
    scope: StateScope;
    ttl?: number;
    accessControl?: {{
        read?: string[];
        write?: string[];
    }};
}}

export enum StateScope {{
    LOCAL = 'local',
    SHARED = 'shared',
    GLOBAL = 'global',
    PERSISTENT = 'persistent'
}}

export class SharedStateManager extends EventEmitter {{
    private readonly agentId: string;
    private readonly localState = new Map<string, any>();
    private readonly redis: Redis;
    private readonly dynamodb: DynamoDBClient;
    private readonly subscriptions = new Map<string, (value: any) => void>();
    
    constructor(agentId: string, config: any) {{
        super();
        this.agentId = agentId;
        this.redis = new Redis(config.redis);
        this.dynamodb = new DynamoDBClient(config.dynamodb);
        this.setupStateSync();
    }}
    
    async get<T = any>(
        key: string,
        scope: StateScope = StateScope.SHARED
    ): Promise<T | null> {{
        // Check access permissions
        if (!await this.canRead(key)) {{
            throw new Error(`Access denied for reading ${{key}}`);
        }}
        
        switch (scope) {{
            case StateScope.LOCAL:
                return this.localState.get(key) || null;
                
            case StateScope.SHARED:
                const sharedValue = await this.redis.get(`state:${{key}}`);
                return sharedValue ? JSON.parse(sharedValue) : null;
                
            case StateScope.GLOBAL:
                const globalValue = await this.redis.get(`global:state:${{key}}`);
                return globalValue ? JSON.parse(globalValue) : null;
                
            case StateScope.PERSISTENT:
                return await this.getPersistentState(key);
                
            default:
                throw new Error(`Unknown scope: ${{scope}}`);
        }}
    }}
    
    async set<T = any>(
        key: string,
        value: T,
        options: SharedStateOptions = {{}}
    ): Promise<void> {{
        const {{ scope = StateScope.SHARED, ttl, accessControl }} = options;
        
        // Check access permissions
        if (!await this.canWrite(key)) {{
            throw new Error(`Access denied for writing ${{key}}`);
        }}
        
        // Store based on scope
        switch (scope) {{
            case StateScope.LOCAL:
                this.localState.set(key, value);
                break;
                
            case StateScope.SHARED:
                await this.setSharedState(key, value, ttl);
                break;
                
            case StateScope.GLOBAL:
                await this.setGlobalState(key, value, ttl);
                break;
                
            case StateScope.PERSISTENT:
                await this.setPersistentState(key, value);
                break;
        }}
        
        // Emit change event
        this.emit('stateChanged', {{
            key,
            value,
            scope,
            agent: this.agentId
        }});
        
        // Notify subscribers
        await this.notifySubscribers(key, value);
    }}
    
    async subscribe(
        pattern: string,
        callback: (key: string, value: any) => void
    ): Promise<() => void> {{
        // Redis pattern subscription
        const subscriber = new Redis(this.redis.options);
        await subscriber.psubscribe(`state:${{pattern}}`);
        
        subscriber.on('pmessage', (pattern, channel, message) => {{
            const key = channel.replace('state:', '');
            const value = JSON.parse(message);
            callback(key, value);
        }});
        
        // Return unsubscribe function
        return async () => {{
            await subscriber.punsubscribe(`state:${{pattern}}`);
            subscriber.disconnect();
        }};
    }}
    
    async transaction(
        operations: Array<{{ op: 'get' | 'set'; key: string; value?: any }}>
    ): Promise<any[]> {{
        const pipeline = this.redis.pipeline();
        const results = [];
        
        for (const op of operations) {{
            if (op.op === 'get') {{
                pipeline.get(`state:${{op.key}}`);
            }} else {{
                pipeline.set(`state:${{op.key}}`, JSON.stringify(op.value));
            }}
        }}
        
        const pipelineResults = await pipeline.exec();
        
        return pipelineResults.map(([err, result]) => {{
            if (err) throw err;
            return typeof result === 'string' ? JSON.parse(result) : result;
        }});
    }}
    
    private async setSharedState(
        key: string,
        value: any,
        ttl?: number
    ): Promise<void> {{
        const serialized = JSON.stringify({{
            value,
            agent: this.agentId,
            timestamp: new Date().toISOString(),
            version: await this.incrementVersion(key)
        }});
        
        if (ttl) {{
            await this.redis.setex(`state:${{key}}`, ttl, serialized);
        }} else {{
            await this.redis.set(`state:${{key}}`, serialized);
        }}
    }}
    
    private async getPersistentState(key: string): Promise<any> {{
        const result = await this.dynamodb.getItem({{
            TableName: 'agent-state',
            Key: {{
                stateKey: {{ S: key }},
                agentId: {{ S: this.agentId }}
            }}
        }});
        
        return result.Item ? JSON.parse(result.Item.value.S) : null;
    }}
    
    private async setPersistentState(key: string, value: any): Promise<void> {{
        await this.dynamodb.putItem({{
            TableName: 'agent-state',
            Item: {{
                stateKey: {{ S: key }},
                agentId: {{ S: this.agentId }},
                value: {{ S: JSON.stringify(value) }},
                timestamp: {{ N: Date.now().toString() }},
                ttl: {{ N: (Date.now() + 30 * 24 * 60 * 60 * 1000).toString() }}
            }}
        }});
    }}
    
    private async canRead(key: string): Promise<boolean> {{
        // Implement access control logic
        const acl = await this.getAccessControl(key);
        return !acl || !acl.read || acl.read.includes(this.agentId);
    }}
    
    private async canWrite(key: string): Promise<boolean> {{
        // Implement access control logic
        const acl = await this.getAccessControl(key);
        return !acl || !acl.write || acl.write.includes(this.agentId);
    }}
    
    private setupStateSync(): void {{
        // Setup periodic sync for eventual consistency
        setInterval(async () => {{
            await this.syncLocalState();
        }}, {sync_config.get('sync_interval', 5000)});
    }}
}}
'''
```

#### SubTask 3.14.4: 충돌 해결 메커니즘
**담당자**: 동시성 제어 전문가  
**예상 소요시간**: 10시간

**작업 내용**:
```python
# backend/src/agents/framework/conflict_resolution.py
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass
from enum import Enum

class ConflictType(Enum):
    CONCURRENT_UPDATE = "concurrent_update"
    RESOURCE_CONTENTION = "resource_contention"
    DEPENDENCY_CONFLICT = "dependency_conflict"
    STATE_INCONSISTENCY = "state_inconsistency"

@dataclass
class Conflict:
    type: ConflictType
    agents: List[str]
    resource: str
    details: Dict[str, Any]
    timestamp: datetime

class ConflictResolver:
    """Resolve conflicts in multi-agent systems"""
    
    def __init__(self):
        self.resolution_strategies = self._init_strategies()
        self.conflict_detector = ConflictDetector()
        self.consensus_manager = ConsensusManager()
    
    async def setup_conflict_resolution(
        self,
        agents: List[Dict[str, Any]],
        policies: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Setup conflict resolution system"""
        
        # Configure detection
        detection_config = await self.conflict_detector.configure(
            agents,
            policies.get('detection', {})
        )
        
        # Setup resolution strategies
        strategies = await self._configure_strategies(
            policies.get('resolution', {})
        )
        
        # Configure consensus mechanism
        consensus_config = await self.consensus_manager.configure(
            agents,
            policies.get('consensus', 'majority')
        )
        
        # Generate implementation
        implementation = await self._generate_conflict_resolution_code(
            detection_config,
            strategies,
            consensus_config
        )
        
        return {
            'detection': detection_config,
            'strategies': strategies,
            'consensus': consensus_config,
            'implementation': implementation
        }
    
    async def _generate_conflict_resolution_code(
        self,
        detection: Dict[str, Any],
        strategies: Dict[str, Any],
        consensus: Dict[str, Any]
    ) -> str:
        """Generate conflict resolution implementation"""
        
        return f'''
export interface ConflictResolutionStrategy {{
    name: string;
    canResolve: (conflict: Conflict) => boolean;
    resolve: (conflict: Conflict) => Promise<Resolution>;
}}

export class ConflictResolver {{
    private readonly strategies: ConflictResolutionStrategy[] = [
        new LastWriteWinsStrategy(),
        new MergeStrategy(),
        new ConsensusStrategy(),
        new PriorityBasedStrategy(),
        new CustomRuleStrategy()
    ];
    
    async resolveConflict(conflict: Conflict): Promise<Resolution> {{
        // Find applicable strategy
        const strategy = this.strategies.find(s => s.canResolve(conflict));
        
        if (!strategy) {{
            throw new Error(`No strategy available for conflict type: ${{conflict.type}}`);
        }}
        
        // Apply strategy
        const resolution = await strategy.resolve(conflict);
        
        // Validate resolution
        if (!await this.validateResolution(resolution)) {{
            throw new Error('Invalid resolution generated');
        }}
        
        // Apply resolution
        await this.applyResolution(resolution);
        
        return resolution;
    }}
    
    private async validateResolution(resolution: Resolution): Promise<boolean> {{
        // Check if resolution maintains system invariants
        return true;
    }}
    
    private async applyResolution(resolution: Resolution): Promise<void> {{
        // Apply the resolution to the system
        for (const action of resolution.actions) {{
            await this.executeAction(action);
        }}
    }}
}}

class LastWriteWinsStrategy implements ConflictResolutionStrategy {{
    name = 'last-write-wins';
    
    canResolve(conflict: Conflict): boolean {{
        return conflict.type === ConflictType.CONCURRENT_UPDATE;
    }}
    
    async resolve(conflict: Conflict): Promise<Resolution> {{
        // Find the latest update
        const updates = conflict.details.updates as Update[];
        const latest = updates.reduce((prev, curr) => 
            curr.timestamp > prev.timestamp ? curr : prev
        );
        
        return {{
            strategy: this.name,
            winner: latest.agent,
            actions: [{{
                type: 'apply-update',
                update: latest
            }}]
        }};
    }}
}}

class MergeStrategy implements ConflictResolutionStrategy {{
    name = 'merge';
    
    canResolve(conflict: Conflict): boolean {{
        return conflict.type === ConflictType.CONCURRENT_UPDATE &&
               conflict.details.mergeable === true;
    }}
    
    async resolve(conflict: Conflict): Promise<Resolution> {{
        const updates = conflict.details.updates as Update[];
        
        // Three-way merge
        const base = conflict.details.base;
        const merged = await this.threeWayMerge(
            base,
            updates[0].value,
            updates[1].value
        );
        
        return {{
            strategy: this.name,
            actions: [{{
                type: 'apply-merge',
                value: merged
            }}]
        }};
    }}
    
    private async threeWayMerge(base: any, a: any, b: any): Promise<any> {{
        // Implement three-way merge logic
        if (typeof base === 'object') {{
            const merged = {{ ...base }};
            
            // Apply changes from a
            for (const key in a) {{
                if (a[key] !== base[key] && b[key] === base[key]) {{
                    merged[key] = a[key];
                }}
            }}
            
            // Apply changes from b
            for (const key in b) {{
                if (b[key] !== base[key] && a[key] === base[key]) {{
                    merged[key] = b[key];
                }} else if (b[key] !== base[key] && a[key] !== base[key]) {{
                    // Both changed - need custom resolution
                    merged[key] = await this.resolveFieldConflict(key, a[key], b[key]);
                }}
            }}
            
            return merged;
        }}
        
        // For non-objects, last write wins
        return b;
    }}
}}

class ConsensusStrategy implements ConflictResolutionStrategy {{
    name = 'consensus';
    private readonly votingTimeout = 5000;
    
    canResolve(conflict: Conflict): boolean {{
        return conflict.agents.length > 2;
    }}
    
    async resolve(conflict: Conflict): Promise<Resolution> {{
        // Request votes from all agents
        const votes = await this.collectVotes(conflict);
        
        // Determine winner by majority
        const winner = this.determineMajority(votes);
        
        if (!winner) {{
            // No consensus - fallback to coordinator decision
            return this.coordinatorDecision(conflict);
        }}
        
        return {{
            strategy: this.name,
            winner: winner.agent,
            votes,
            actions: [{{
                type: 'apply-consensus',
                decision: winner.decision
            }}]
        }};
    }}
    
    private async collectVotes(conflict: Conflict): Promise<Vote[]> {{
        const votePromises = conflict.agents.map(agent => 
            this.requestVote(agent, conflict)
        );
        
        // Wait for votes with timeout
        const votes = await Promise.allSettled(votePromises);
        
        return votes
            .filter(result => result.status === 'fulfilled')
            .map(result => (result as any).value);
    }}
}}
'''
```

---

### Task 3.15: 워크플로우 오케스트레이션

#### SubTask 3.15.1: 워크플로우 정의 언어
**담당자**: 워크플로우 설계자  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/framework/workflow_definition.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

class WorkflowNodeType(Enum):
    TASK = "task"
    DECISION = "decision"
    PARALLEL = "parallel"
    LOOP = "loop"
    SUBWORKFLOW = "subworkflow"
    WAIT = "wait"

@dataclass
class WorkflowDefinition:
    id: str
    name: str
    version: str
    description: str
    nodes: List['WorkflowNode']
    edges: List['WorkflowEdge']
    variables: Dict[str, Any]
    error_handling: Dict[str, Any]
    metadata: Dict[str, Any]

class WorkflowLanguage:
    """Domain-specific language for workflow definition"""
    
    def __init__(self):
        self.parser = WorkflowParser()
        self.validator = WorkflowValidator()
        self.compiler = WorkflowCompiler()
    
    async def create_workflow_dsl(
        self,
        agents: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Create workflow definition language"""
        
        # Define DSL syntax
        dsl_syntax = await self._define_dsl_syntax(agents)
        
        # Create parser
        parser_implementation = await self._generate_parser(dsl_syntax)
        
        # Create validator
        validator_implementation = await self._generate_validator(dsl_syntax)
        
        # Create compiler
        compiler_implementation = await self._generate_compiler(dsl_syntax)
        
        # Generate examples
        examples = await self._generate_workflow_examples(agents)
        
        return {
            'syntax': dsl_syntax,
            'parser': parser_implementation,
            'validator': validator_implementation,
            'compiler': compiler_implementation,
            'examples': examples,
            'documentation': await self._generate_dsl_documentation(dsl_syntax)
        }
    
    async def _define_dsl_syntax(
        self,
        agents: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Define workflow DSL syntax"""
        
        return {
            'version': '1.0',
            'keywords': [
                'workflow', 'task', 'parallel', 'sequence',
                'decision', 'loop', 'wait', 'timeout',
                'retry', 'compensate', 'catch', 'finally'
            ],
            'operators': {
                'flow': ['->', '=>', '|>', '||'],
                'condition': ['==', '!=', '>', '<', '>=', '<=', 'in', 'not in'],
                'logical': ['and', 'or', 'not']
            },
            'agents': [agent['name'] for agent in agents],
            'builtin_functions': [
                'get', 'set', 'transform', 'validate',
                'log', 'notify', 'wait', 'retry'
            ]
        }
    
    async def _generate_workflow_yaml_schema(self) -> str:
        """Generate YAML schema for workflows"""
        
        return '''
# Workflow Definition Schema
type: object
required:
  - name
  - version
  - tasks
properties:
  name:
    type: string
    description: Workflow name
  
  version:
    type: string
    pattern: '^\\d+\\.\\d+\\.\\d+$'
  
  description:
    type: string
  
  inputs:
    type: object
    additionalProperties:
      type: object
      properties:
        type:
          enum: [string, number, boolean, object, array]
        required:
          type: boolean
        default:
          type: any
  
  outputs:
    type: object
    additionalProperties:
      type: object
      properties:
        from:
          type: string
        transform:
          type: string
  
  tasks:
    type: array
    items:
      type: object
      required:
        - id
        - type
      properties:
        id:
          type: string
        
        type:
          enum: [task, parallel, decision, loop, subworkflow]
        
        agent:
          type: string
        
        operation:
          type: string
        
        inputs:
          type: object
        
        outputs:
          type: object
        
        timeout:
          type: integer
          minimum: 1
        
        retry:
          type: object
          properties:
            attempts:
              type: integer
            delay:
              type: integer
            backoff:
              enum: [constant, linear, exponential]
        
        onError:
          type: object
          properties:
            action:
              enum: [retry, compensate, fail, continue]
            handler:
              type: string
        
        parallel:
          type: array
          items:
            $ref: '#/properties/tasks/items'
        
        condition:
          type: string
        
        branches:
          type: object
          additionalProperties:
            type: array
            items:
              $ref: '#/properties/tasks/items'
        
        loop:
          type: object
          properties:
            over:
              type: string
            as:
              type: string
            do:
              type: array
              items:
                $ref: '#/properties/tasks/items'
'''
    
    async def _generate_workflow_parser(self) -> str:
        """Generate workflow parser implementation"""
        
        return '''
import yaml from 'js-yaml';
import Ajv from 'ajv';

export interface WorkflowTask {
    id: string;
    type: 'task' | 'parallel' | 'decision' | 'loop' | 'subworkflow';
    agent?: string;
    operation?: string;
    inputs?: Record<string, any>;
    outputs?: Record<string, any>;
    timeout?: number;
    retry?: RetryConfig;
    onError?: ErrorHandler;
    // Type-specific properties
    parallel?: WorkflowTask[];
    condition?: string;
    branches?: Record<string, WorkflowTask[]>;
    loop?: LoopConfig;
}

export interface ParsedWorkflow {
    name: string;
    version: string;
    description?: string;
    inputs?: Record<string, InputDefinition>;
    outputs?: Record<string, OutputDefinition>;
    tasks: WorkflowTask[];
    errorHandling?: ErrorHandling;
}

export class WorkflowParser {
    private readonly ajv = new Ajv();
    private readonly schema: any;
    
    constructor() {
        this.schema = this.loadSchema();
        this.ajv.addSchema(this.schema, 'workflow');
    }
    
    parseYAML(yamlContent: string): ParsedWorkflow {
        try {
            // Parse YAML
            const data = yaml.load(yamlContent) as any;
            
            // Validate against schema
            const valid = this.ajv.validate('workflow', data);
            if (!valid) {
                throw new Error(`Invalid workflow: ${this.ajv.errorsText()}`);
            }
            
            // Transform to internal representation
            return this.transform(data);
            
        } catch (error: any) {
            throw new Error(`Failed to parse workflow: ${error.message}`);
        }
    }
    
    parseDSL(dslContent: string): ParsedWorkflow {
        const lines = dslContent.split('\\n').filter(line => line.trim());
        const workflow: ParsedWorkflow = {
            name: '',
            version: '1.0.0',
            tasks: []
        };
        
        let currentSection = '';
        let currentTask: WorkflowTask | null = null;
        
        for (const line of lines) {
            const trimmed = line.trim();
            
            // Parse workflow metadata
            if (trimmed.startsWith('workflow')) {
                const match = trimmed.match(/workflow\\s+(\\w+)\\s+v([\\d.]+)/);
                if (match) {
                    workflow.name = match[1];
                    workflow.version = match[2];
                }
            }
            
            // Parse task definition
            else if (trimmed.startsWith('task')) {
                if (currentTask) {
                    workflow.tasks.push(currentTask);
                }
                
                const match = trimmed.match(/task\\s+(\\w+)\\s+on\\s+(\\w+):/);
                if (match) {
                    currentTask = {
                        id: match[1],
                        type: 'task',
                        agent: match[2],
                        operation: '',
                        inputs: {}
                    };
                }
            }
            
            // Parse parallel block
            else if (trimmed.startsWith('parallel')) {
                if (currentTask) {
                    workflow.tasks.push(currentTask);
                }
                
                currentTask = {
                    id: `parallel_${workflow.tasks.length}`,
                    type: 'parallel',
                    parallel: []
                };
            }
            
            // Parse flow operators
            else if (trimmed.includes('->') || trimmed.includes('=>')) {
                const [left, right] = trimmed.split(/->|=>/);
                // Handle flow connections
                this.addFlowConnection(workflow, left.trim(), right.trim());
            }
        }
        
        if (currentTask) {
            workflow.tasks.push(currentTask);
        }
        
        return workflow;
    }
    
    private transform(data: any): ParsedWorkflow {
        // Transform validated data to internal format
        return {
            name: data.name,
            version: data.version,
            description: data.description,
            inputs: data.inputs,
            outputs: data.outputs,
            tasks: this.transformTasks(data.tasks),
            errorHandling: data.errorHandling
        };
    }
    
    private transformTasks(tasks: any[]): WorkflowTask[] {
        return tasks.map(task => {
            const transformed: WorkflowTask = {
                id: task.id,
                type: task.type,
                timeout: task.timeout,
                retry: task.retry,
                onError: task.onError
            };
            
            switch (task.type) {
                case 'task':
                    transformed.agent = task.agent;
                    transformed.operation = task.operation;
                    transformed.inputs = task.inputs;
                    transformed.outputs = task.outputs;
                    break;
                    
                case 'parallel':
                    transformed.parallel = this.transformTasks(task.parallel);
                    break;
                    
                case 'decision':
                    transformed.condition = task.condition;
                    transformed.branches = {};
                    for (const [branch, tasks] of Object.entries(task.branches)) {
                        transformed.branches[branch] = this.transformTasks(tasks as any[]);
                    }
                    break;
                    
                case 'loop':
                    transformed.loop = task.loop;
                    transformed.loop.do = this.transformTasks(task.loop.do);
                    break;
            }
            
            return transformed;
        });
    }
}
'''
```

#### SubTask 3.15.2: 실행 엔진 구현
**담당자**: 워크플로우 엔진 개발자  
**예상 소요시간**: 16시간

**작업 내용**:
```python
# backend/src/agents/framework/workflow_engine.py
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass
from enum import Enum
import asyncio

class ExecutionState(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    COMPENSATING = "compensating"

@dataclass
class ExecutionContext:
    workflow_id: str
    execution_id: str
    state: ExecutionState
    variables: Dict[str, Any]
    history: List[Dict[str, Any]]
    error: Optional[str] = None

class WorkflowEngine:
    """Workflow execution engine"""
    
    def __init__(self):
        self.executor = TaskExecutor()
        self.state_manager = StateManager()
        self.event_dispatcher = EventDispatcher()
    
    async def create_execution_engine(
        self,
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Create workflow execution engine"""
        
        # Generate engine implementation
        engine_code = await self._generate_engine_implementation(config)
        
        # Generate task executors
        executors = await self._generate_task_executors()
        
        # Generate state management
        state_management = await self._generate_state_management()
        
        # Generate monitoring
        monitoring = await self._generate_execution_monitoring()
        
        return {
            'engine': engine_code,
            'executors': executors,
            'state_management': state_management,
            'monitoring': monitoring
        }
    
    async def _generate_engine_implementation(
        self,
        config: Dict[str, Any]
    ) -> str:
        """Generate workflow engine implementation"""
        
        return f'''
import {{ EventEmitter }} from 'events';
import {{ v4 as uuidv4 }} from 'uuid';
import pino from 'pino';

export enum ExecutionState {{
    PENDING = 'pending',
    RUNNING = 'running',
    COMPLETED = 'completed',
    FAILED = 'failed',
    CANCELLED = 'cancelled',
    COMPENSATING = 'compensating'
}}

export interface ExecutionContext {{
    workflowId: string;
    executionId: string;
    state: ExecutionState;
    variables: Record<string, any>;
    history: ExecutionEvent[];
    startTime: Date;
    endTime?: Date;
    error?: Error;
}}

export class WorkflowEngine extends EventEmitter {{
    private readonly logger = pino();
    private readonly executions = new Map<string, ExecutionContext>();
    private readonly taskExecutors = new Map<string, TaskExecutor>();
    private readonly stateStore: StateStore;
    private readonly messageBus: MessageBus;
    
    constructor(config: WorkflowEngineConfig) {{
        super();
        this.stateStore = new StateStore(config.stateStore);
        this.messageBus = new MessageBus(config.messageBus);
        this.registerDefaultExecutors();
    }}
    
    async execute(
        workflow: ParsedWorkflow,
        inputs: Record<string, any> = {{}}
    ): Promise<ExecutionResult> {{
        const executionId = uuidv4();
        const context: ExecutionContext = {{
            workflowId: workflow.name,
            executionId,
            state: ExecutionState.PENDING,
            variables: {{ ...inputs }},
            history: [],
            startTime: new Date()
        }};
        
        // Store execution
        this.executions.set(executionId, context);
        await this.stateStore.saveExecution(context);
        
        // Emit start event
        this.emit('execution:start', {{ executionId, workflow: workflow.name }});
        
        try {{
            // Start execution
            context.state = ExecutionState.RUNNING;
            await this.stateStore.updateState(executionId, ExecutionState.RUNNING);
            
            // Execute workflow
            const result = await this.executeWorkflow(workflow, context);
            
            // Complete execution
            context.state = ExecutionState.COMPLETED;
            context.endTime = new Date();
            await this.stateStore.saveExecution(context);
            
            // Emit complete event
            this.emit('execution:complete', {{
                executionId,
                result,
                duration: context.endTime.getTime() - context.startTime.getTime()
            }});
            
            return {{
                executionId,
                status: 'completed',
                result,
                outputs: this.extractOutputs(workflow, context)
            }};
            
        }} catch (error: any) {{
            // Handle failure
            context.state = ExecutionState.FAILED;
            context.error = error;
            context.endTime = new Date();
            await this.stateStore.saveExecution(context);
            
            // Emit failure event
            this.emit('execution:failed', {{ executionId, error }});
            
            // Trigger compensation if needed
            if (workflow.errorHandling?.compensate) {{
                await this.compensate(workflow, context);
            }}
            
            throw error;
        }}
    }}
    
    private async executeWorkflow(
        workflow: ParsedWorkflow,
        context: ExecutionContext
    ): Promise<any> {{
        const results: Record<string, any> = {{}};
        
        for (const task of workflow.tasks) {{
            try {{
                const result = await this.executeTask(task, context);
                results[task.id] = result;
                
                // Update context variables
                if (task.outputs) {{
                    for (const [key, mapping] of Object.entries(task.outputs)) {{
                        context.variables[key] = this.mapOutput(result, mapping);
                    }}
                }}
                
                // Record in history
                context.history.push({{
                    taskId: task.id,
                    type: 'task_completed',
                    timestamp: new Date(),
                    result
                }});
                
            }} catch (error: any) {{
                // Handle task error
                context.history.push({{
                    taskId: task.id,
                    type: 'task_failed',
                    timestamp: new Date(),
                    error: error.message
                }});
                
                // Apply error handling strategy
                const handled = await this.handleTaskError(task, error, context);
                if (!handled) {{
                    throw error;
                }}
            }}
        }}
        
        return results;
    }}
    
    private async executeTask(
        task: WorkflowTask,
        context: ExecutionContext
    ): Promise<any> {{
        this.logger.info({{ task: task.id, type: task.type }}, 'Executing task');
        
        switch (task.type) {{
            case 'task':
                return await this.executeSingleTask(task, context);
                
            case 'parallel':
                return await this.executeParallelTasks(task.parallel!, context);
                
            case 'decision':
                return await this.executeDecision(task, context);
                
            case 'loop':
                return await this.executeLoop(task, context);
                
            case 'subworkflow':
                return await this.executeSubworkflow(task, context);
                
            default:
                throw new Error(`Unknown task type: ${{task.type}}`);
        }}
    }}
    
    private async executeSingleTask(
        task: WorkflowTask,
        context: ExecutionContext
    ): Promise<any> {{
        // Prepare inputs
        const inputs = this.prepareInputs(task.inputs || {{}}, context.variables);
        
        // Get executor
        const executor = this.taskExecutors.get(task.agent!) || this.defaultExecutor;
        
        // Execute with timeout and retry
        const config = {{
            timeout: task.timeout || 30000,
            retry: task.retry || {{ attempts: 1 }}
        }};
        
        return await this.executeWithRetry(
            () => executor.execute(task.operation!, inputs),
            config
        );
    }}
    
    private async executeParallelTasks(
        tasks: WorkflowTask[],
        context: ExecutionContext
    ): Promise<any[]> {{
        const promises = tasks.map(task => 
            this.executeTask(task, {{ ...context }})
        );
        
        return await Promise.all(promises);
    }}
    
    private async executeDecision(
        task: WorkflowTask,
        context: ExecutionContext
    ): Promise<any> {{
        // Evaluate condition
        const condition = this.evaluateExpression(task.condition!, context.variables);
        
        // Select branch
        const branch = task.branches![condition] || task.branches!['default'];
        
        if (!branch) {{
            throw new Error(`No branch for condition result: ${{condition}}`);
        }}
        
        // Execute selected branch
        const results: Record<string, any> = {{}};
        for (const branchTask of branch) {{
            results[branchTask.id] = await this.executeTask(branchTask, context);
        }}
        
        return results;
    }}
    
    private async executeLoop(
        task: WorkflowTask,
        context: ExecutionContext
    ): Promise<any[]> {{
        const loopConfig = task.loop!;
        const collection = this.evaluateExpression(loopConfig.over, context.variables);
        const results: any[] = [];
        
        for (const item of collection) {{
            // Create loop context
            const loopContext = {{
                ...context,
                variables: {{
                    ...context.variables,
                    [loopConfig.as]: item,
                    '$index': results.length
                }}
            }};
            
            // Execute loop body
            const loopResults: Record<string, any> = {{}};
            for (const loopTask of loopConfig.do) {{
                loopResults[loopTask.id] = await this.executeTask(loopTask, loopContext);
            }}
            
            results.push(loopResults);
        }}
        
        return results;
    }}
    
    private async executeWithRetry(
        fn: () => Promise<any>,
        config: {{ timeout: number; retry: RetryConfig }}
    ): Promise<any> {{
        let lastError: Error | null = null;
        
        for (let attempt = 0; attempt < config.retry.attempts; attempt++) {{
            try {{
                // Execute with timeout
                return await this.withTimeout(fn(), config.timeout);
                
            }} catch (error: any) {{
                lastError = error;
                
                // Don't retry on certain errors
                if (error.code === 'INVALID_INPUT' || error.code === 'UNAUTHORIZED') {{
                    throw error;
                }}
                
                // Calculate delay
                const delay = this.calculateRetryDelay(attempt, config.retry);
                await this.sleep(delay);
            }}
        }}
        
        throw lastError;
    }}
    
    private async compensate(
        workflow: ParsedWorkflow,
        context: ExecutionContext
    ): Promise<void> {{
        context.state = ExecutionState.COMPENSATING;
        this.emit('execution:compensating', {{ executionId: context.executionId }});
        
        // Execute compensation in reverse order
        const completedTasks = context.history
            .filter(event => event.type === 'task_completed')
            .reverse();
        
        for (const event of completedTasks) {{
            const task = workflow.tasks.find(t => t.id === event.taskId);
            if (task?.onError?.action === 'compensate') {{
                try {{
                    await this.executeCompensation(task, context);
                }} catch (error) {{
                    this.logger.error({{ task: task.id, error }}, 'Compensation failed');
                }}
            }}
        }}
    }}
}}
'''
```

#### SubTask 3.15.3: 모니터링 대시보드
**담당자**: 모니터링 전문가  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/framework/workflow_monitoring.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class WorkflowMetrics:
    total_executions: int
    successful_executions: int
    failed_executions: int
    average_duration: float
    p95_duration: float
    active_executions: int
    error_rate: float

class WorkflowMonitoring:
    """Workflow execution monitoring and visualization"""
    
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.dashboard_generator = DashboardGenerator()
        self.alert_manager = AlertManager()
    
    async def setup_monitoring(
        self,
        workflows: List[Dict[str, Any]],
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Setup workflow monitoring system"""
        
        # Configure metrics collection
        metrics_config = await self.metrics_collector.configure(
            workflows,
            config.get('metrics', {})
        )
        
        # Generate dashboards
        dashboards = await self.dashboard_generator.generate(
            workflows,
            config.get('dashboard', {})
        )
        
        # Setup alerting
        alerts = await self.alert_manager.configure(
            workflows,
            config.get('alerts', {})
        )
        
        # Generate monitoring implementation
        implementation = await self._generate_monitoring_implementation(
            metrics_config,
            dashboards,
            alerts
        )
        
        return {
            'metrics': metrics_config,
            'dashboards': dashboards,
            'alerts': alerts,
            'implementation': implementation
        }
    
    async def _generate_monitoring_dashboard(self) -> str:
        """Generate monitoring dashboard React component"""
        
        return '''
import React, { useState, useEffect } from 'react';
import {
    LineChart, Line, BarChart, Bar, PieChart, Pie,
    XAxis, YAxis, CartesianGrid, Tooltip, Legend,
    ResponsiveContainer, Cell
} from 'recharts';
import { Card, Grid, Typography, Box } from '@mui/material';
import { useWebSocket } from './hooks/useWebSocket';

interface WorkflowMetrics {
    totalExecutions: number;
    successfulExecutions: number;
    failedExecutions: number;
    averageDuration: number;
    p95Duration: number;
    activeExecutions: number;
    errorRate: number;
}

export const WorkflowDashboard: React.FC = () => {
    const [metrics, setMetrics] = useState<WorkflowMetrics | null>(null);
    const [executionHistory, setExecutionHistory] = useState<any[]>([]);
    const [activeWorkflows, setActiveWorkflows] = useState<any[]>([]);
    
    const { data: realtimeData } = useWebSocket('/workflow-metrics');
    
    useEffect(() => {
        // Fetch initial data
        fetchMetrics();
        fetchExecutionHistory();
        
        // Setup polling
        const interval = setInterval(() => {
            fetchMetrics();
        }, 5000);
        
        return () => clearInterval(interval);
    }, []);
    
    useEffect(() => {
        // Handle realtime updates
        if (realtimeData) {
            handleRealtimeUpdate(realtimeData);
        }
    }, [realtimeData]);
    
    const fetchMetrics = async () => {
        const response = await fetch('/api/workflows/metrics');
        const data = await response.json();
        setMetrics(data);
    };
    
    const fetchExecutionHistory = async () => {
        const response = await fetch('/api/workflows/executions/history');
        const data = await response.json();
        setExecutionHistory(data);
    };
    
    const handleRealtimeUpdate = (data: any) => {
        if (data.type === 'execution:start') {
            setActiveWorkflows(prev => [...prev, data.execution]);
        } else if (data.type === 'execution:complete' || data.type === 'execution:failed') {
            setActiveWorkflows(prev => 
                prev.filter(w => w.executionId !== data.executionId)
            );
            // Refresh metrics
            fetchMetrics();
        }
    };
    
    if (!metrics) {
        return <div>Loading...</div>;
    }
    
    const successRate = (metrics.successfulExecutions / metrics.totalExecutions) * 100;
    
    const statusData = [
        { name: 'Successful', value: metrics.successfulExecutions, color: '#4caf50' },
        { name: 'Failed', value: metrics.failedExecutions, color: '#f44336' }
    ];
    
    return (
        <Box sx={{ p: 3 }}>
            <Typography variant="h4" gutterBottom>
                Workflow Monitoring Dashboard
            </Typography>
            
            <Grid container spacing={3}>
                {/* Summary Cards */}
                <Grid item xs={12} md={3}>
                    <Card sx={{ p: 2 }}>
                        <Typography variant="subtitle2" color="textSecondary">
                            Total Executions
                        </Typography>
                        <Typography variant="h3">
                            {metrics.totalExecutions.toLocaleString()}
                        </Typography>
                    </Card>
                </Grid>
                
                <Grid item xs={12} md={3}>
                    <Card sx={{ p: 2 }}>
                        <Typography variant="subtitle2" color="textSecondary">
                            Success Rate
                        </Typography>
                        <Typography variant="h3" color="success.main">
                            {successRate.toFixed(1)}%
                        </Typography>
                    </Card>
                </Grid>
                
                <Grid item xs={12} md={3}>
                    <Card sx={{ p: 2 }}>
                        <Typography variant="subtitle2" color="textSecondary">
                            Active Executions
                        </Typography>
                        <Typography variant="h3" color="primary">
                            {metrics.activeExecutions}
                        </Typography>
                    </Card>
                </Grid>
                
                <Grid item xs={12} md={3}>
                    <Card sx={{ p: 2 }}>
                        <Typography variant="subtitle2" color="textSecondary">
                            Avg Duration
                        </Typography>
                        <Typography variant="h3">
                            {(metrics.averageDuration / 1000).toFixed(1)}s
                        </Typography>
                    </Card>
                </Grid>
                
                {/* Execution Status Chart */}
                <Grid item xs={12} md={6}>
                    <Card sx={{ p: 2 }}>
                        <Typography variant="h6" gutterBottom>
                            Execution Status Distribution
                        </Typography>
                        <ResponsiveContainer width="100%" height={300}>
                            <PieChart>
                                <Pie
                                    data={statusData}
                                    cx="50%"
                                    cy="50%"
                                    outerRadius={80}
                                    fill="#8884d8"
                                    dataKey="value"
                                    label
                                >
                                    {statusData.map((entry, index) => (
                                        <Cell key={index} fill={entry.color} />
                                    ))}
                                </Pie>
                                <Tooltip />
                                <Legend />
                            </PieChart>
                        </ResponsiveContainer>
                    </Card>
                </Grid>
                
                {/* Execution Timeline */}
                <Grid item xs={12} md={6}>
                    <Card sx={{ p: 2 }}>
                        <Typography variant="h6" gutterBottom>
                            Execution Timeline
                        </Typography>
                        <ResponsiveContainer width="100%" height={300}>
                            <LineChart data={executionHistory}>
                                <CartesianGrid strokeDasharray="3 3" />
                                <XAxis dataKey="timestamp" />
                                <YAxis />
                                <Tooltip />
                                <Legend />
                                <Line
                                    type="monotone"
                                    dataKey="successful"
                                    stroke="#4caf50"
                                    name="Successful"
                                />
                                <Line
                                    type="monotone"
                                    dataKey="failed"
                                    stroke="#f44336"
                                    name="Failed"
                                />
                            </LineChart>
                        </ResponsiveContainer>
                    </Card>
                </Grid>
                
                {/* Active Workflows */}
                <Grid item xs={12}>
                    <Card sx={{ p: 2 }}>
                        <Typography variant="h6" gutterBottom>
                            Active Workflows
                        </Typography>
                        <ActiveWorkflowsList workflows={activeWorkflows} />
                    </Card>
                </Grid>
            </Grid>
        </Box>
    );
};

const ActiveWorkflowsList: React.FC<{ workflows: any[] }> = ({ workflows }) => {
    return (
        <Box>
            {workflows.map(workflow => (
                <Box
                    key={workflow.executionId}
                    sx={{
                        p: 2,
                        mb: 1,
                        border: '1px solid #e0e0e0',
                        borderRadius: 1
                    }}
                >
                    <Grid container alignItems="center">
                        <Grid item xs={4}>
                            <Typography variant="subtitle2">
                                {workflow.name}
                            </Typography>
                            <Typography variant="caption" color="textSecondary">
                                {workflow.executionId}
                            </Typography>
                        </Grid>
                        <Grid item xs={4}>
                            <Typography variant="body2">
                                Current Task: {workflow.currentTask}
                            </Typography>
                        </Grid>
                        <Grid item xs={2}>
                            <Typography variant="body2">
                                Duration: {workflow.duration}s
                            </Typography>
                        </Grid>
                        <Grid item xs={2}>
                            <WorkflowProgress progress={workflow.progress} />
                        </Grid>
                    </Grid>
                </Box>
            ))}
        </Box>
    );
};
'''
```

#### SubTask 3.15.4: 오류 처리 및 복구
**담당자**: 신뢰성 엔지니어  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/framework/error_handling.py
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass
from enum import Enum

class ErrorType(Enum):
    TIMEOUT = "timeout"
    NETWORK = "network"
    VALIDATION = "validation"
    BUSINESS_LOGIC = "business_logic"
    SYSTEM = "system"
    UNKNOWN = "unknown"

@dataclass
class ErrorContext:
    error_type: ErrorType
    message: str
    task_id: str
    workflow_id: str
    execution_id: str
    timestamp: datetime
    stack_trace: Optional[str] = None
    retry_count: int = 0

class ErrorHandler:
    """Workflow error handling and recovery"""
    
    def __init__(self):
        self.recovery_strategies = self._init_strategies()
        self.compensation_manager = CompensationManager()
        self.circuit_breaker = CircuitBreaker()
    
    async def setup_error_handling(
        self,
        workflows: List[Dict[str, Any]],
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Setup error handling system"""
        
        # Configure recovery strategies
        strategies = await self._configure_strategies(
            config.get('recovery', {})
        )
        
        # Setup compensation
        compensation = await self.compensation_manager.configure(
            workflows,
            config.get('compensation', {})
        )
        
        # Configure circuit breakers
        circuit_breakers = await self.circuit_breaker.configure(
            config.get('circuit_breakers', {})
        )
        
        # Generate implementation
        implementation = await self._generate_error_handling_implementation(
            strategies,
            compensation,
            circuit_breakers
        )
        
        return {
            'strategies': strategies,
            'compensation': compensation,
            'circuit_breakers': circuit_breakers,
            'implementation': implementation
        }
    
    async def _generate_error_handling_implementation(
        self,
        strategies: Dict[str, Any],
        compensation: Dict[str, Any],
        circuit_breakers: Dict[str, Any]
    ) -> str:
        """Generate error handling implementation"""
        
        return f'''
export interface ErrorHandler {{
    canHandle: (error: Error) => boolean;
    handle: (error: Error, context: ErrorContext) => Promise<ErrorResolution>;
}}

export interface ErrorResolution {{
    action: 'retry' | 'compensate' | 'fail' | 'continue' | 'fallback';
    details?: any;
}}

export class WorkflowErrorHandler {{
    private readonly handlers: ErrorHandler[] = [
        new TimeoutErrorHandler(),
        new NetworkErrorHandler(),
        new ValidationErrorHandler(),
        new BusinessLogicErrorHandler(),
        new SystemErrorHandler()
    ];
    
    private readonly circuitBreakers = new Map<string, CircuitBreaker>();
    private readonly compensationManager: CompensationManager;
    
    constructor(config: ErrorHandlingConfig) {{
        this.compensationManager = new CompensationManager(config.compensation);
        this.initializeCircuitBreakers(config.circuitBreakers);
    }}
    
    async handleError(
        error: Error,
        context: ErrorContext
    ): Promise<ErrorResolution> {{
        // Log error
        this.logError(error, context);
        
        // Check circuit breaker
        const breaker = this.circuitBreakers.get(context.taskId);
        if (breaker && breaker.isOpen()) {{
            return {{
                action: 'fail',
                details: {{ reason: 'Circuit breaker open' }}
            }};
        }}
        
        // Find appropriate handler
        const handler = this.handlers.find(h => h.canHandle(error));
        
        if (!handler) {{
            // Default handling
            return this.defaultErrorHandling(error, context);
        }}
        
        try {{
            // Apply handler
            const resolution = await handler.handle(error, context);
            
            // Update circuit breaker
            if (breaker) {{
                if (resolution.action === 'fail') {{
                    breaker.recordFailure();
                }} else {{
                    breaker.recordSuccess();
                }}
            }}
            
            return resolution;
            
        }} catch (handlerError) {{
            // Handler failed, use fallback
            return {{
                action: 'fail',
                details: {{ 
                    originalError: error.message,
                    handlerError: handlerError.message
                }}
            }};
        }}
    }}
    
    private defaultErrorHandling(
        error: Error,
        context: ErrorContext
    ): ErrorResolution {{
        // Check retry count
        if (context.retryCount < 3) {{
            return {{
                action: 'retry',
                details: {{
                    delay: Math.pow(2, context.retryCount) * 1000,
                    maxAttempts: 3
                }}
            }};
        }}
        
        // Max retries exceeded
        return {{ action: 'fail' }};
    }}
}}

class TimeoutErrorHandler implements ErrorHandler {{
    canHandle(error: Error): boolean {{
        return error.name === 'TimeoutError' || 
               error.message.includes('timeout');
    }}
    
    async handle(
        error: Error,
        context: ErrorContext
    ): Promise<ErrorResolution> {{
        // For timeout errors, check if the task is idempotent
        const taskConfig = await this.getTaskConfig(context.taskId);
        
        if (taskConfig.idempotent && context.retryCount < 2) {{
            return {{
                action: 'retry',
                details: {{
                    delay: 5000,
                    timeout: taskConfig.timeout * 1.5 // Increase timeout
                }}
            }};
        }}
        
        // Check if there's a fallback
        if (taskConfig.fallback) {{
            return {{
                action: 'fallback',
                details: {{ fallbackTask: taskConfig.fallback }}
            }};
        }}
        
        return {{ action: 'fail' }};
    }}
}}

class NetworkErrorHandler implements ErrorHandler {{
    canHandle(error: Error): boolean {{
        return error.name === 'NetworkError' ||
               error.message.includes('ECONNREFUSED') ||
               error.message.includes('ETIMEDOUT');
    }}
    
    async handle(
        error: Error,
        context: ErrorContext
    ): Promise<ErrorResolution> {{
        // For network errors, use exponential backoff
        const delay = Math.min(
            Math.pow(2, context.retryCount) * 1000,
            30000 // Max 30 seconds
        );
        
        if (context.retryCount < 5) {{
            return {{
                action: 'retry',
                details: {{ delay }}
            }};
        }}
        
        // After 5 retries, check if we can continue without this task
        const taskConfig = await this.getTaskConfig(context.taskId);
        
        if (taskConfig.optional) {{
            return {{
                action: 'continue',
                details: {{ skipped: true }}
            }};
        }}
        
        return {{ action: 'fail' }};
    }}
}}

class BusinessLogicErrorHandler implements ErrorHandler {{
    canHandle(error: Error): boolean {{
        return error.name === 'BusinessLogicError' ||
               error.name === 'ValidationError';
    }}
    
    async handle(
        error: Error,
        context: ErrorContext
    ): Promise<ErrorResolution> {{
        // Business logic errors usually require compensation
        const compensationPlan = await this.createCompensationPlan(context);
        
        if (compensationPlan) {{
            return {{
                action: 'compensate',
                details: {{ plan: compensationPlan }}
            }};
        }}
        
        // No compensation available, fail immediately
        return {{ action: 'fail' }};
    }}
}}

// Compensation Manager
export class CompensationManager {{
    private readonly compensationHandlers = new Map<string, CompensationHandler>();
    
    async compensate(
        workflow: Workflow,
        executionContext: ExecutionContext
    ): Promise<CompensationResult> {{
        const compensationPlan = this.createCompensationPlan(
            workflow,
            executionContext
        );
        
        const results: CompensationStepResult[] = [];
        
        for (const step of compensationPlan.steps) {{
            try {{
                const handler = this.compensationHandlers.get(step.handlerType);
                
                if (!handler) {{
                    throw new Error(`No handler for compensation type: ${{step.handlerType}}`);
                }}
                
                const result = await handler.compensate(step, executionContext);
                results.push({{
                    step: step.id,
                    status: 'completed',
                    result
                }});
                
            }} catch (error) {{
                results.push({{
                    step: step.id,
                    status: 'failed',
                    error: error.message
                }});
                
                // Decide whether to continue
                if (compensationPlan.failureStrategy === 'stop') {{
                    break;
                }}
            }}
        }}
        
        return {{
            status: results.every(r => r.status === 'completed') ? 'completed' : 'partial',
            results
        }};
    }}
    
    private createCompensationPlan(
        workflow: Workflow,
        context: ExecutionContext
    ): CompensationPlan {{
        // Analyze execution history
        const completedTasks = context.history
            .filter(event => event.type === 'task_completed')
            .reverse(); // Compensate in reverse order
        
        const steps: CompensationStep[] = [];
        
        for (const taskEvent of completedTasks) {{
            const task = workflow.tasks.find(t => t.id === taskEvent.taskId);
            
            if (task?.compensation) {{
                steps.push({{
                    id: `compensate_${{task.id}}`,
                    taskId: task.id,
                    handlerType: task.compensation.type,
                    config: task.compensation.config,
                    dependencies: this.getCompensationDependencies(task, workflow)
                }});
            }}
        }}
        
        return {{
            id: `compensation_${{context.executionId}}`,
            steps,
            failureStrategy: workflow.compensationStrategy || 'continue'
        }};
    }}
}}

// Circuit Breaker
export class CircuitBreaker {{
    private state: 'closed' | 'open' | 'half-open' = 'closed';
    private failureCount = 0;
    private lastFailureTime?: Date;
    private successCount = 0;
    
    constructor(
        private readonly config: CircuitBreakerConfig
    ) {{}}
    
    isOpen(): boolean {{
        if (this.state === 'open') {{
            // Check if we should transition to half-open
            if (this.shouldTransitionToHalfOpen()) {{
                this.state = 'half-open';
                return false;
            }}
            return true;
        }}
        
        return false;
    }}
    
    recordSuccess(): void {{
        this.failureCount = 0;
        
        if (this.state === 'half-open') {{
            this.successCount++;
            
            if (this.successCount >= this.config.successThreshold) {{
                this.state = 'closed';
                this.successCount = 0;
            }}
        }}
    }}
    
    recordFailure(): void {{
        this.failureCount++;
        this.lastFailureTime = new Date();
        
        if (this.state === 'half-open') {{
            this.state = 'open';
            this.successCount = 0;
        }} else if (
            this.state === 'closed' &&
            this.failureCount >= this.config.failureThreshold
        ) {{
            this.state = 'open';
        }}
    }}
    
    private shouldTransitionToHalfOpen(): boolean {{
        if (!this.lastFailureTime) {{
            return true;
        }}
        
        const timeSinceLastFailure = 
            Date.now() - this.lastFailureTime.getTime();
        
        return timeSinceLastFailure >= this.config.resetTimeout;
    }}
}}
'''
```

---

### Task 3.16: 에이전트 체인 관리

#### SubTask 3.16.1: 체인 구성 관리자
**담당자**: 시스템 아키텍트  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/framework/chain_manager.py
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass
from enum import Enum
import asyncio

class ChainType(Enum):
    SEQUENTIAL = "sequential"
    CONDITIONAL = "conditional"
    LOOP = "loop"
    MAP_REDUCE = "map_reduce"
    ROUTER = "router"
    TRANSFORM = "transform"

@dataclass
class AgentChain:
    id: str
    name: str
    type: ChainType
    agents: List[str]
    config: Dict[str, Any]
    input_schema: Dict[str, Any]
    output_schema: Dict[str, Any]
    error_handling: Dict[str, Any]

class ChainManager:
    """Manage agent chains and compositions"""
    
    def __init__(self):
        self.chain_registry = ChainRegistry()
        self.chain_executor = ChainExecutor()
        self.chain_optimizer = ChainOptimizer()
    
    async def create_chain_management_system(
        self,
        agents: List[Dict[str, Any]],
        patterns: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Create chain management system"""
        
        # Generate chain types
        chain_implementations = {}
        for pattern in patterns:
            implementation = await self._generate_chain_implementation(
                pattern,
                agents
            )
            chain_implementations[pattern['type']] = implementation
        
        # Generate chain builder
        chain_builder = await self._generate_chain_builder()
        
        # Generate chain executor
        chain_executor = await self._generate_chain_executor()
        
        # Generate chain optimizer
        chain_optimizer = await self._generate_chain_optimizer()
        
        return {
            'implementations': chain_implementations,
            'builder': chain_builder,
            'executor': chain_executor,
            'optimizer': chain_optimizer
        }
    
    async def _generate_chain_builder(self) -> str:
        """Generate chain builder implementation"""
        
        return '''
import { v4 as uuidv4 } from 'uuid';

export interface ChainConfig {
    name: string;
    type: ChainType;
    agents: string[];
    config?: any;
    inputSchema?: any;
    outputSchema?: any;
    errorHandling?: ErrorHandlingConfig;
}

export enum ChainType {
    SEQUENTIAL = 'sequential',
    CONDITIONAL = 'conditional',
    LOOP = 'loop',
    MAP_REDUCE = 'map_reduce',
    ROUTER = 'router',
    TRANSFORM = 'transform'
}

export class ChainBuilder {
    private chains = new Map<string, AgentChain>();
    
    sequential(...agents: string[]): SequentialChainBuilder {
        return new SequentialChainBuilder(agents);
    }
    
    conditional(condition: string): ConditionalChainBuilder {
        return new ConditionalChainBuilder(condition);
    }
    
    mapReduce(): MapReduceChainBuilder {
        return new MapReduceChainBuilder();
    }
    
    router(routingFunction: (input: any) => string): RouterChainBuilder {
        return new RouterChainBuilder(routingFunction);
    }
    
    transform(transformer: (input: any) => any): TransformChainBuilder {
        return new TransformChainBuilder(transformer);
    }
    
    loop(condition: (input: any, iteration: number) => boolean): LoopChainBuilder {
        return new LoopChainBuilder(condition);
    }
}

export class SequentialChainBuilder {
    private config: Partial<ChainConfig> = {
        type: ChainType.SEQUENTIAL
    };
    
    constructor(private agents: string[]) {
        this.config.agents = agents;
    }
    
    withName(name: string): this {
        this.config.name = name;
        return this;
    }
    
    withInputValidation(schema: any): this {
        this.config.inputSchema = schema;
        return this;
    }
    
    withOutputValidation(schema: any): this {
        this.config.outputSchema = schema;
        return this;
    }
    
    withErrorHandling(strategy: ErrorHandlingStrategy): this {
        this.config.errorHandling = {
            strategy,
            retryAttempts: 3,
            retryDelay: 1000
        };
        return this;
    }
    
    withTimeout(timeout: number): this {
        this.config.config = {
            ...this.config.config,
            timeout
        };
        return this;
    }
    
    build(): AgentChain {
        const chain: AgentChain = {
            id: uuidv4(),
            name: this.config.name || `sequential-${Date.now()}`,
            type: ChainType.SEQUENTIAL,
            agents: this.agents,
            config: this.config.config || {},
            inputSchema: this.config.inputSchema,
            outputSchema: this.config.outputSchema,
            errorHandling: this.config.errorHandling || {
                strategy: 'fail-fast'
            }
        };
        
        this.validate(chain);
        return chain;
    }
    
    private validate(chain: AgentChain): void {
        if (chain.agents.length === 0) {
            throw new Error('Sequential chain must have at least one agent');
        }
        
        // Validate agent existence
        for (const agent of chain.agents) {
            if (!AgentRegistry.getInstance().hasAgent(agent)) {
                throw new Error(`Agent not found: ${agent}`);
            }
        }
    }
}

export class ConditionalChainBuilder {
    private branches = new Map<string, string[]>();
    private defaultBranch?: string[];
    
    constructor(private condition: string) {}
    
    when(value: any, ...agents: string[]): this {
        this.branches.set(String(value), agents);
        return this;
    }
    
    otherwise(...agents: string[]): this {
        this.defaultBranch = agents;
        return this;
    }
    
    build(): AgentChain {
        if (this.branches.size === 0) {
            throw new Error('Conditional chain must have at least one branch');
        }
        
        return {
            id: uuidv4(),
            name: `conditional-${Date.now()}`,
            type: ChainType.CONDITIONAL,
            agents: Array.from(new Set([
                ...Array.from(this.branches.values()).flat(),
                ...(this.defaultBranch || [])
            ])),
            config: {
                condition: this.condition,
                branches: Object.fromEntries(this.branches),
                default: this.defaultBranch
            },
            inputSchema: {},
            outputSchema: {},
            errorHandling: { strategy: 'fail-fast' }
        };
    }
}

export class MapReduceChainBuilder {
    private mappers: string[] = [];
    private reducer?: string;
    private config: any = {};
    
    withMappers(...agents: string[]): this {
        this.mappers = agents;
        return this;
    }
    
    withReducer(agent: string): this {
        this.reducer = agent;
        return this;
    }
    
    withPartitioner(partitioner: (input: any) => any[]): this {
        this.config.partitioner = partitioner;
        return this;
    }
    
    withCombiner(combiner: (results: any[]) => any): this {
        this.config.combiner = combiner;
        return this;
    }
    
    build(): AgentChain {
        if (this.mappers.length === 0) {
            throw new Error('MapReduce chain must have at least one mapper');
        }
        
        if (!this.reducer) {
            throw new Error('MapReduce chain must have a reducer');
        }
        
        return {
            id: uuidv4(),
            name: `mapreduce-${Date.now()}`,
            type: ChainType.MAP_REDUCE,
            agents: [...this.mappers, this.reducer],
            config: {
                mappers: this.mappers,
                reducer: this.reducer,
                ...this.config
            },
            inputSchema: {},
            outputSchema: {},
            errorHandling: { strategy: 'continue-on-error' }
        };
    }
}

// Chain Executor
export class ChainExecutor {
    private executors = new Map<ChainType, ChainTypeExecutor>();
    
    constructor(private messageBus: MessageBus) {
        this.registerExecutors();
    }
    
    async execute(
        chain: AgentChain,
        input: any,
        context?: ExecutionContext
    ): Promise<any> {
        // Validate input
        if (chain.inputSchema) {
            this.validateInput(input, chain.inputSchema);
        }
        
        // Get executor for chain type
        const executor = this.executors.get(chain.type);
        if (!executor) {
            throw new Error(`No executor for chain type: ${chain.type}`);
        }
        
        // Execute chain
        const startTime = Date.now();
        let result;
        
        try {
            result = await executor.execute(chain, input, context);
            
            // Validate output
            if (chain.outputSchema) {
                this.validateOutput(result, chain.outputSchema);
            }
            
            // Emit success event
            this.messageBus.emit('chain:completed', {
                chainId: chain.id,
                duration: Date.now() - startTime,
                result
            });
            
        } catch (error) {
            // Handle error based on strategy
            result = await this.handleChainError(chain, error, context);
            
            // Emit failure event
            this.messageBus.emit('chain:failed', {
                chainId: chain.id,
                duration: Date.now() - startTime,
                error
            });
        }
        
        return result;
    }
    
    private registerExecutors(): void {
        this.executors.set(ChainType.SEQUENTIAL, new SequentialExecutor(this.messageBus));
        this.executors.set(ChainType.CONDITIONAL, new ConditionalExecutor(this.messageBus));
        this.executors.set(ChainType.LOOP, new LoopExecutor(this.messageBus));
        this.executors.set(ChainType.MAP_REDUCE, new MapReduceExecutor(this.messageBus));
        this.executors.set(ChainType.ROUTER, new RouterExecutor(this.messageBus));
        this.executors.set(ChainType.TRANSFORM, new TransformExecutor(this.messageBus));
    }
}

class SequentialExecutor implements ChainTypeExecutor {
    constructor(private messageBus: MessageBus) {}
    
    async execute(
        chain: AgentChain,
        input: any,
        context?: ExecutionContext
    ): Promise<any> {
        let result = input;
        
        for (const agentId of chain.agents) {
            const agent = AgentRegistry.getInstance().getAgent(agentId);
            
            // Execute agent
            result = await agent.process(result, context);
            
            // Check if we should continue
            if (context?.shouldStop) {
                break;
            }
        }
        
        return result;
    }
}

class MapReduceExecutor implements ChainTypeExecutor {
    constructor(private messageBus: MessageBus) {}
    
    async execute(
        chain: AgentChain,
        input: any,
        context?: ExecutionContext
    ): Promise<any> {
        const config = chain.config;
        
        // Partition input
        const partitions = config.partitioner
            ? config.partitioner(input)
            : Array.isArray(input) ? input : [input];
        
        // Map phase - execute mappers in parallel
        const mapPromises = partitions.map((partition, index) => {
            const mapperId = config.mappers[index % config.mappers.length];
            const mapper = AgentRegistry.getInstance().getAgent(mapperId);
            return mapper.process(partition, context);
        });
        
        const mapResults = await Promise.all(mapPromises);
        
        // Combine results if combiner provided
        const combined = config.combiner
            ? config.combiner(mapResults)
            : mapResults;
        
        // Reduce phase
        const reducer = AgentRegistry.getInstance().getAgent(config.reducer);
        const result = await reducer.process(combined, context);
        
        return result;
    }
}
'''
```

#### SubTask 3.16.2: 동적 체인 구성
**담당자**: 체인 설계자  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/framework/dynamic_chain.py
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass

@dataclass
class DynamicChainNode:
    agent_id: str
    condition: Optional[Callable[[Any], bool]] = None
    transform: Optional[Callable[[Any], Any]] = None
    parallel: bool = False
    timeout: Optional[int] = None

class DynamicChainBuilder:
    """Build and modify agent chains dynamically"""
    
    def __init__(self):
        self.chain_analyzer = ChainAnalyzer()
        self.chain_optimizer = ChainOptimizer()
        self.chain_validator = ChainValidator()
    
    async def create_dynamic_chain_system(
        self,
        base_patterns: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Create dynamic chain configuration system"""
        
        # Generate dynamic builder
        builder_implementation = await self._generate_dynamic_builder()
        
        # Generate chain modifier
        modifier_implementation = await self._generate_chain_modifier()
        
        # Generate runtime composer
        composer_implementation = await self._generate_runtime_composer()
        
        # Generate adaptation engine
        adaptation_implementation = await self._generate_adaptation_engine()
        
        return {
            'builder': builder_implementation,
            'modifier': modifier_implementation,
            'composer': composer_implementation,
            'adaptation': adaptation_implementation
        }
    
    async def _generate_dynamic_builder(self) -> str:
        """Generate dynamic chain builder"""
        
        return '''
export class DynamicChainBuilder {
    private nodes: ChainNode[] = [];
    private edges: ChainEdge[] = [];
    private metadata: ChainMetadata = {};
    
    addNode(agent: string, options?: NodeOptions): string {
        const nodeId = `node_${this.nodes.length}`;
        
        this.nodes.push({
            id: nodeId,
            agent,
            type: options?.type || 'process',
            condition: options?.condition,
            transform: options?.transform,
            parallel: options?.parallel || false,
            timeout: options?.timeout,
            retryPolicy: options?.retryPolicy
        });
        
        return nodeId;
    }
    
    connect(from: string, to: string, options?: EdgeOptions): this {
        this.edges.push({
            id: `edge_${this.edges.length}`,
            from,
            to,
            condition: options?.condition,
            priority: options?.priority || 0,
            dataTransform: options?.dataTransform
        });
        
        return this;
    }
    
    parallel(...agents: string[]): string {
        const parallelNodeId = `parallel_${this.nodes.length}`;
        
        this.nodes.push({
            id: parallelNodeId,
            type: 'parallel',
            children: agents.map(agent => this.addNode(agent, { parallel: true }))
        });
        
        return parallelNodeId;
    }
    
    conditional(
        condition: (input: any) => string,
        branches: Record<string, string[]>
    ): string {
        const conditionalNodeId = `conditional_${this.nodes.length}`;
        
        this.nodes.push({
            id: conditionalNodeId,
            type: 'conditional',
            condition,
            branches: Object.entries(branches).reduce((acc, [key, agents]) => {
                acc[key] = agents.map(agent => this.addNode(agent));
                return acc;
            }, {} as Record<string, string[]>)
        });
        
        return conditionalNodeId;
    }
    
    loop(
        condition: (input: any, iteration: number) => boolean,
        body: string[]
    ): string {
        const loopNodeId = `loop_${this.nodes.length}`;
        
        this.nodes.push({
            id: loopNodeId,
            type: 'loop',
            condition,
            body: body.map(agent => this.addNode(agent)),
            maxIterations: 100 // Safety limit
        });
        
        return loopNodeId;
    }
    
    build(): DynamicChain {
        // Validate chain
        this.validate();
        
        // Optimize chain
        const optimized = this.optimize();
        
        return {
            id: uuidv4(),
            nodes: optimized.nodes,
            edges: optimized.edges,
            metadata: this.metadata,
            compiled: this.compile(optimized)
        };
    }
    
    private validate(): void {
        // Check for cycles
        if (this.hasCycles()) {
            throw new Error('Chain contains cycles');
        }
        
        // Check for disconnected nodes
        const disconnected = this.findDisconnectedNodes();
        if (disconnected.length > 0) {
            throw new Error(`Disconnected nodes: ${disconnected.join(', ')}`);
        }
        
        // Validate agent availability
        for (const node of this.nodes) {
            if (node.agent && !AgentRegistry.getInstance().hasAgent(node.agent)) {
                throw new Error(`Agent not found: ${node.agent}`);
            }
        }
    }
    
    private optimize(): { nodes: ChainNode[], edges: ChainEdge[] } {
        // Remove redundant nodes
        const nodes = this.removeRedundantNodes();
        
        // Merge sequential nodes where possible
        const merged = this.mergeSequentialNodes(nodes);
        
        // Optimize parallel execution
        const optimized = this.optimizeParallelExecution(merged);
        
        return {
            nodes: optimized,
            edges: this.edges
        };
    }
    
    private compile(chain: { nodes: ChainNode[], edges: ChainEdge[] }): CompiledChain {
        // Generate execution plan
        const executionPlan = this.generateExecutionPlan(chain);
        
        // Create optimized executor
        const executor = this.createOptimizedExecutor(executionPlan);
        
        return {
            plan: executionPlan,
            executor,
            estimatedDuration: this.estimateDuration(executionPlan)
        };
    }
}

// Runtime Chain Modifier
export class ChainModifier {
    modify(chain: DynamicChain, modifications: ChainModification[]): DynamicChain {
        let modified = { ...chain };
        
        for (const mod of modifications) {
            switch (mod.type) {
                case 'add_node':
                    modified = this.addNode(modified, mod);
                    break;
                    
                case 'remove_node':
                    modified = this.removeNode(modified, mod);
                    break;
                    
                case 'replace_node':
                    modified = this.replaceNode(modified, mod);
                    break;
                    
                case 'add_edge':
                    modified = this.addEdge(modified, mod);
                    break;
                    
                case 'remove_edge':
                    modified = this.removeEdge(modified, mod);
                    break;
                    
                case 'update_condition':
                    modified = this.updateCondition(modified, mod);
                    break;
            }
        }
        
        // Recompile after modifications
        modified.compiled = this.recompile(modified);
        
        return modified;
    }
    
    private addNode(
        chain: DynamicChain,
        mod: ChainModification
    ): DynamicChain {
        const newNode: ChainNode = {
            id: mod.nodeId || `node_${chain.nodes.length}`,
            agent: mod.agent,
            type: mod.nodeType || 'process',
            ...mod.options
        };
        
        // Find insertion point
        if (mod.after) {
            const afterIndex = chain.nodes.findIndex(n => n.id === mod.after);
            chain.nodes.splice(afterIndex + 1, 0, newNode);
            
            // Update edges
            this.updateEdgesForInsertion(chain, mod.after, newNode.id);
        } else {
            chain.nodes.push(newNode);
        }
        
        return chain;
    }
    
    private replaceNode(
        chain: DynamicChain,
        mod: ChainModification
    ): DynamicChain {
        const index = chain.nodes.findIndex(n => n.id === mod.nodeId);
        
        if (index === -1) {
            throw new Error(`Node not found: ${mod.nodeId}`);
        }
        
        // Preserve connections
        const oldNode = chain.nodes[index];
        chain.nodes[index] = {
            ...oldNode,
            agent: mod.agent || oldNode.agent,
            ...mod.options
        };
        
        return chain;
    }
}

// Runtime Chain Composer
export class RuntimeComposer {
    async compose(
        context: ExecutionContext,
        requirements: any
    ): Promise<DynamicChain> {
        // Analyze requirements
        const analysis = await this.analyzeRequirements(requirements);
        
        // Select appropriate agents
        const agents = await this.selectAgents(analysis);
        
        // Determine optimal chain structure
        const structure = await this.determineStructure(agents, analysis);
        
        // Build chain dynamically
        const builder = new DynamicChainBuilder();
        
        for (const step of structure.steps) {
            if (step.parallel) {
                builder.parallel(...step.agents);
            } else if (step.conditional) {
                builder.conditional(step.condition, step.branches);
            } else {
                step.agents.forEach(agent => builder.addNode(agent));
            }
        }
        
        // Connect nodes
        structure.connections.forEach(conn => {
            builder.connect(conn.from, conn.to, conn.options);
        });
        
        return builder.build();
    }
    
    private async analyzeRequirements(requirements: any): Promise<RequirementAnalysis> {
        return {
            complexity: this.assessComplexity(requirements),
            dataTypes: this.identifyDataTypes(requirements),
            constraints: this.extractConstraints(requirements),
            objectives: this.identifyObjectives(requirements)
        };
    }
    
    private async selectAgents(analysis: RequirementAnalysis): Promise<string[]> {
        const candidates = await AgentRegistry.getInstance().findAgents({
            capabilities: analysis.requiredCapabilities,
            dataTypes: analysis.dataTypes
        });
        
        // Rank candidates
        const ranked = this.rankAgents(candidates, analysis);
        
        // Select optimal set
        return this.selectOptimalAgents(ranked, analysis.constraints);
    }
}
'''
```

#### SubTask 3.16.3: 체인 최적화 엔진
**담당자**: 성능 엔지니어  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/framework/chain_optimizer.py
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import networkx as nx

@dataclass
class OptimizationResult:
    original_chain: Any
    optimized_chain: Any
    improvements: Dict[str, float]
    suggestions: List[str]

class ChainOptimizer:
    """Optimize agent chain performance"""
    
    def __init__(self):
        self.performance_analyzer = PerformanceAnalyzer()
        self.pattern_detector = PatternDetector()
        self.optimization_engine = OptimizationEngine()
    
    async def create_optimization_system(self) -> Dict[str, Any]:
        """Create chain optimization system"""
        
        # Generate optimizer implementation
        optimizer_implementation = await self._generate_optimizer()
        
        # Generate performance analyzer
        analyzer_implementation = await self._generate_performance_analyzer()
        
        # Generate pattern detector
        pattern_implementation = await self._generate_pattern_detector()
        
        # Generate optimization strategies
        strategies_implementation = await self._generate_optimization_strategies()
        
        return {
            'optimizer': optimizer_implementation,
            'analyzer': analyzer_implementation,
            'patterns': pattern_implementation,
            'strategies': strategies_implementation
        }
    
    async def _generate_optimizer(self) -> str:
        """Generate chain optimizer implementation"""
        
        return '''
export interface OptimizationOptions {
    targetMetric: 'latency' | 'throughput' | 'cost' | 'balanced';
    constraints?: {
        maxLatency?: number;
        minThroughput?: number;
        maxCost?: number;
    };
    enableParallelization?: boolean;
    enableCaching?: boolean;
    enableBatching?: boolean;
}

export class ChainOptimizer {
    private strategies: OptimizationStrategy[] = [
        new ParallelizationStrategy(),
        new CachingStrategy(),
        new BatchingStrategy(),
        new PruningStrategy(),
        new ReorderingStrategy(),
        new FusionStrategy()
    ];
    
    async optimize(
        chain: AgentChain,
        metrics: ChainMetrics,
        options: OptimizationOptions
    ): Promise<OptimizationResult> {
        // Analyze current performance
        const analysis = await this.analyzePerformance(chain, metrics);
        
        // Identify bottlenecks
        const bottlenecks = this.identifyBottlenecks(analysis);
        
        // Apply optimization strategies
        let optimizedChain = chain;
        const improvements: Record<string, number> = {};
        const appliedStrategies: string[] = [];
        
        for (const strategy of this.strategies) {
            if (strategy.canApply(optimizedChain, bottlenecks, options)) {
                const result = await strategy.apply(optimizedChain, analysis);
                
                if (this.isImprovement(result, optimizedChain, options)) {
                    optimizedChain = result.chain;
                    improvements[strategy.name] = result.improvement;
                    appliedStrategies.push(strategy.name);
                }
            }
        }
        
        // Validate optimized chain
        this.validate(optimizedChain);
        
        return {
            originalChain: chain,
            optimizedChain,
            improvements,
            suggestions: await this.generateSuggestions(
                analysis,
                bottlenecks,
                appliedStrategies
            )
        };
    }
    
    private analyzePerformance(
        chain: AgentChain,
        metrics: ChainMetrics
    ): PerformanceAnalysis {
        const nodeMetrics = new Map<string, NodeMetrics>();
        
        // Analyze each node
        for (const node of chain.nodes) {
            nodeMetrics.set(node.id, {
                avgDuration: metrics.getAverageDuration(node.id),
                p95Duration: metrics.getP95Duration(node.id),
                errorRate: metrics.getErrorRate(node.id),
                throughput: metrics.getThroughput(node.id),
                resourceUsage: metrics.getResourceUsage(node.id)
            });
        }
        
        // Analyze edges (data transfer)
        const edgeMetrics = new Map<string, EdgeMetrics>();
        for (const edge of chain.edges) {
            edgeMetrics.set(edge.id, {
                dataSize: metrics.getAverageDataSize(edge.id),
                transferTime: metrics.getTransferTime(edge.id)
            });
        }
        
        return {
            totalDuration: this.calculateTotalDuration(nodeMetrics, chain),
            criticalPath: this.findCriticalPath(chain, nodeMetrics),
            parallelizableNodes: this.findParallelizableNodes(chain),
            nodeMetrics,
            edgeMetrics
        };
    }
    
    private identifyBottlenecks(
        analysis: PerformanceAnalysis
    ): Bottleneck[] {
        const bottlenecks: Bottleneck[] = [];
        
        // Duration bottlenecks
        for (const [nodeId, metrics] of analysis.nodeMetrics) {
            if (metrics.avgDuration > analysis.totalDuration * 0.3) {
                bottlenecks.push({
                    type: 'duration',
                    nodeId,
                    severity: 'high',
                    impact: metrics.avgDuration / analysis.totalDuration
                });
            }
        }
        
        // Throughput bottlenecks
        const minThroughput = Math.min(
            ...Array.from(analysis.nodeMetrics.values()).map(m => m.throughput)
        );
        
        for (const [nodeId, metrics] of analysis.nodeMetrics) {
            if (metrics.throughput === minThroughput) {
                bottlenecks.push({
                    type: 'throughput',
                    nodeId,
                    severity: 'medium',
                    impact: 1 - (minThroughput / metrics.throughput)
                });
            }
        }
        
        // Resource bottlenecks
        for (const [nodeId, metrics] of analysis.nodeMetrics) {
            if (metrics.resourceUsage.cpu > 0.8 || metrics.resourceUsage.memory > 0.8) {
                bottlenecks.push({
                    type: 'resource',
                    nodeId,
                    severity: 'high',
                    impact: Math.max(metrics.resourceUsage.cpu, metrics.resourceUsage.memory)
                });
            }
        }
        
        return bottlenecks.sort((a, b) => b.impact - a.impact);
    }
}

// Optimization Strategies
class ParallelizationStrategy implements OptimizationStrategy {
    name = 'parallelization';
    
    canApply(
        chain: AgentChain,
        bottlenecks: Bottleneck[],
        options: OptimizationOptions
    ): boolean {
        return options.enableParallelization !== false &&
               this.hasParallelizableNodes(chain);
    }
    
    async apply(
        chain: AgentChain,
        analysis: PerformanceAnalysis
    ): Promise<StrategyResult> {
        const parallelizable = analysis.parallelizableNodes;
        
        if (parallelizable.length === 0) {
            return { chain, improvement: 0 };
        }
        
        // Group parallelizable nodes
        const groups = this.groupParallelizableNodes(parallelizable, chain);
        
        // Create parallel execution blocks
        const optimized = this.createParallelBlocks(chain, groups);
        
        // Estimate improvement
        const improvement = this.estimateImprovement(
            analysis.totalDuration,
            this.estimateNewDuration(optimized, analysis.nodeMetrics)
        );
        
        return { chain: optimized, improvement };
    }
    
    private groupParallelizableNodes(
        nodes: string[],
        chain: AgentChain
    ): string[][] {
        const graph = this.buildDependencyGraph(chain);
        const groups: string[][] = [];
        const visited = new Set<string>();
        
        for (const node of nodes) {
            if (!visited.has(node)) {
                const group = this.findIndependentGroup(node, nodes, graph, visited);
                if (group.length > 1) {
                    groups.push(group);
                    group.forEach(n => visited.add(n));
                }
            }
        }
        
        return groups;
    }
}

class CachingStrategy implements OptimizationStrategy {
    name = 'caching';
    
    canApply(
        chain: AgentChain,
        bottlenecks: Bottleneck[],
        options: OptimizationOptions
    ): boolean {
        return options.enableCaching !== false &&
               this.hasCachableNodes(chain);
    }
    
    async apply(
        chain: AgentChain,
        analysis: PerformanceAnalysis
    ): Promise<StrategyResult> {
        const cachableNodes = this.identifyCachableNodes(chain, analysis);
        
        if (cachableNodes.length === 0) {
            return { chain, improvement: 0 };
        }
        
        // Add caching configuration
        const optimized = { ...chain };
        optimized.nodes = chain.nodes.map(node => {
            if (cachableNodes.includes(node.id)) {
                return {
                    ...node,
                    caching: {
                        enabled: true,
                        ttl: this.calculateOptimalTTL(node, analysis),
                        key: this.generateCacheKey(node)
                    }
                };
            }
            return node;
        });
        
        // Estimate improvement based on cache hit rate
        const estimatedHitRate = 0.7; // Conservative estimate
        const improvement = this.estimateCacheImprovement(
            cachableNodes,
            analysis,
            estimatedHitRate
        );
        
        return { chain: optimized, improvement };
    }
}

class BatchingStrategy implements OptimizationStrategy {
    name = 'batching';
    
    canApply(
        chain: AgentChain,
        bottlenecks: Bottleneck[],
        options: OptimizationOptions
    ): boolean {
        return options.enableBatching !== false &&
               bottlenecks.some(b => b.type === 'throughput');
    }
    
    async apply(
        chain: AgentChain,
        analysis: PerformanceAnalysis
    ): Promise<StrategyResult> {
        const batchableNodes = this.identifyBatchableNodes(chain, analysis);
        
        if (batchableNodes.length === 0) {
            return { chain, improvement: 0 };
        }
        
        // Configure batching
        const optimized = { ...chain };
        optimized.nodes = chain.nodes.map(node => {
            if (batchableNodes.includes(node.id)) {
                return {
                    ...node,
                    batching: {
                        enabled: true,
                        size: this.calculateOptimalBatchSize(node, analysis),
                        timeout: 100, // ms
                        maxWait: 500 // ms
                    }
                };
            }
            return node;
        });
        
        // Estimate improvement
        const improvement = this.estimateBatchingImprovement(
            batchableNodes,
            analysis
        );
        
        return { chain: optimized, improvement };
    }
}

// Performance Analyzer
export class PerformanceAnalyzer {
    async analyze(
        chain: AgentChain,
        executionHistory: ExecutionRecord[]
    ): Promise<ChainMetrics> {
        const metrics = new ChainMetrics();
        
        // Process execution records
        for (const record of executionHistory) {
            this.updateMetrics(metrics, record);
        }
        
        // Calculate derived metrics
        metrics.calculateDerivedMetrics();
        
        return metrics;
    }
    
    private updateMetrics(metrics: ChainMetrics, record: ExecutionRecord): void {
        // Update node metrics
        for (const nodeExecution of record.nodeExecutions) {
            metrics.addNodeExecution(nodeExecution.nodeId, {
                duration: nodeExecution.duration,
                success: nodeExecution.success,
                dataSize: nodeExecution.outputSize,
                resourceUsage: nodeExecution.resourceUsage
            });
        }
        
        // Update edge metrics
        for (const dataTransfer of record.dataTransfers) {
            metrics.addDataTransfer(dataTransfer.edgeId, {
                size: dataTransfer.size,
                duration: dataTransfer.duration
            });
        }
    }
}
'''
```

#### SubTask 3.16.4: 체인 모니터링 시스템
**담당자**: 모니터링 전문가  
**예상 소요시간**: 10시간

**작업 내용**:
```python
# backend/src/agents/framework/chain_monitoring.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ChainMetrics:
    execution_count: int
    success_rate: float
    average_duration: float
    p95_duration: float
    throughput: float
    error_distribution: Dict[str, int]

class ChainMonitoring:
    """Monitor agent chain execution and performance"""
    
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.visualizer = ChainVisualizer()
        self.alerting = AlertingSystem()
    
    async def create_monitoring_system(
        self,
        chains: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Create chain monitoring system"""
        
        # Generate monitoring implementation
        monitoring_implementation = await self._generate_monitoring()
        
        # Generate visualization components
        visualization = await self._generate_visualization()
        
        # Generate alerting rules
        alerting = await self._generate_alerting()
        
        # Generate analytics
        analytics = await self._generate_analytics()
        
        return {
            'monitoring': monitoring_implementation,
            'visualization': visualization,
            'alerting': alerting,
            'analytics': analytics
        }
    
    async def _generate_monitoring(self) -> str:
        """Generate chain monitoring implementation"""
        
        return '''
export class ChainMonitor {
    private metrics = new Map<string, ChainMetricCollector>();
    private eventStream = new EventEmitter();
    private storage: MetricStorage;
    
    constructor(config: MonitorConfig) {
        this.storage = new MetricStorage(config.storage);
        this.setupEventHandlers();
        this.startMetricAggregation();
    }
    
    trackExecution(chainId: string, execution: ChainExecution): void {
        const collector = this.getOrCreateCollector(chainId);
        
        // Record basic metrics
        collector.recordExecution({
            executionId: execution.id,
            startTime: execution.startTime,
            endTime: execution.endTime,
            success: execution.status === 'completed',
            error: execution.error
        });
        
        // Record node-level metrics
        for (const nodeExecution of execution.nodeExecutions) {
            collector.recordNodeExecution(nodeExecution);
        }
        
        // Record data flow metrics
        for (const dataTransfer of execution.dataTransfers) {
            collector.recordDataTransfer(dataTransfer);
        }
        
        // Emit real-time event
        this.eventStream.emit('execution:tracked', {
            chainId,
            execution,
            metrics: collector.getCurrentMetrics()
        });
    }
    
    getMetrics(chainId: string, timeRange?: TimeRange): ChainMetrics {
        const collector = this.metrics.get(chainId);
        
        if (!collector) {
            return this.getEmptyMetrics();
        }
        
        return collector.getMetrics(timeRange);
    }
    
    async getHistoricalMetrics(
        chainId: string,
        timeRange: TimeRange
    ): Promise<HistoricalMetrics> {
        const current = this.getMetrics(chainId, timeRange);
        const historical = await this.storage.query(chainId, timeRange);
        
        return {
            current,
            timeSeries: this.aggregateTimeSeries(historical),
            trends: this.calculateTrends(historical),
            anomalies: this.detectAnomalies(historical)
        };
    }
    
    private getOrCreateCollector(chainId: string): ChainMetricCollector {
        if (!this.metrics.has(chainId)) {
            this.metrics.set(chainId, new ChainMetricCollector(chainId));
        }
        
        return this.metrics.get(chainId)!;
    }
    
    private setupEventHandlers(): void {
        // Listen for chain events
        ChainExecutor.on('execution:start', (event) => {
            this.handleExecutionStart(event);
        });
        
        ChainExecutor.on('execution:complete', (event) => {
            this.handleExecutionComplete(event);
        });
        
        ChainExecutor.on('node:start', (event) => {
            this.handleNodeStart(event);
        });
        
        ChainExecutor.on('node:complete', (event) => {
            this.handleNodeComplete(event);
        });
    }
    
    private startMetricAggregation(): void {
        // Aggregate metrics every minute
        setInterval(() => {
            this.aggregateAndStore();
        }, 60000);
        
        // Clean up old metrics every hour
        setInterval(() => {
            this.cleanupOldMetrics();
        }, 3600000);
    }
}

// Chain Visualization Component
export const ChainVisualization: React.FC<{ chainId: string }> = ({ chainId }) => {
    const [metrics, setMetrics] = useState<ChainMetrics | null>(null);
    const [executionFlow, setExecutionFlow] = useState<ExecutionFlow | null>(null);
    const [selectedNode, setSelectedNode] = useState<string | null>(null);
    
    useEffect(() => {
        // Subscribe to real-time updates
        const unsubscribe = ChainMonitor.subscribe(chainId, (update) => {
            setMetrics(update.metrics);
            if (update.execution) {
                setExecutionFlow(update.execution);
            }
        });
        
        return unsubscribe;
    }, [chainId]);
    
    return (
        <Box sx={{ height: '100%', display: 'flex', flexDirection: 'column' }}>
            {/* Chain Flow Diagram */}
            <Box sx={{ flex: 1, position: 'relative' }}>
                <ReactFlow
                    nodes={createFlowNodes(executionFlow)}
                    edges={createFlowEdges(executionFlow)}
                    onNodeClick={(event, node) => setSelectedNode(node.id)}
                    fitView
                >
                    <Controls />
                    <MiniMap />
                    <Background variant="dots" gap={12} size={1} />
                </ReactFlow>
            </Box>
            
            {/* Metrics Dashboard */}
            <Box sx={{ height: 300, borderTop: 1, borderColor: 'divider' }}>
                <Grid container spacing={2} sx={{ p: 2 }}>
                    <Grid item xs={3}>
                        <MetricCard
                            title="Success Rate"
                            value={`${(metrics?.successRate || 0) * 100}%`}
                            trend={metrics?.successTrend}
                            color="success"
                        />
                    </Grid>
                    <Grid item xs={3}>
                        <MetricCard
                            title="Avg Duration"
                            value={`${metrics?.avgDuration || 0}ms`}
                            trend={metrics?.durationTrend}
                            color="primary"
                        />
                    </Grid>
                    <Grid item xs={3}>
                        <MetricCard
                            title="Throughput"
                            value={`${metrics?.throughput || 0}/min`}
                            trend={metrics?.throughputTrend}
                            color="info"
                        />
                    </Grid>
                    <Grid item xs={3}>
                        <MetricCard
                            title="Error Rate"
                            value={`${(metrics?.errorRate || 0) * 100}%`}
                            trend={metrics?.errorTrend}
                            color="error"
                        />
                    </Grid>
                </Grid>
            </Box>
            
            {/* Node Details */}
            {selectedNode && (
                <NodeDetailsDrawer
                    nodeId={selectedNode}
                    metrics={getNodeMetrics(selectedNode, metrics)}
                    onClose={() => setSelectedNode(null)}
                />
            )}
        </Box>
    );
};

// Real-time Chain Analytics
export class ChainAnalytics {
    async analyzeChainPerformance(
        chainId: string,
        timeRange: TimeRange
    ): Promise<PerformanceAnalysis> {
        const metrics = await this.monitor.getHistoricalMetrics(chainId, timeRange);
        
        return {
            summary: this.generateSummary(metrics),
            bottlenecks: this.identifyBottlenecks(metrics),
            patterns: this.detectPatterns(metrics),
            recommendations: this.generateRecommendations(metrics),
            forecast: this.forecastPerformance(metrics)
        };
    }
    
    private identifyBottlenecks(metrics: HistoricalMetrics): Bottleneck[] {
        const bottlenecks: Bottleneck[] = [];
        
        // Analyze node performance
        for (const [nodeId, nodeMetrics] of metrics.nodeMetrics) {
            // Slow nodes
            if (nodeMetrics.avgDuration > metrics.current.avgDuration * 0.5) {
                bottlenecks.push({
                    type: 'slow_node',
                    nodeId,
                    impact: nodeMetrics.avgDuration / metrics.current.avgDuration,
                    recommendation: 'Consider optimizing or parallelizing this node'
                });
            }
            
            // High error rate nodes
            if (nodeMetrics.errorRate > 0.05) {
                bottlenecks.push({
                    type: 'error_prone',
                    nodeId,
                    impact: nodeMetrics.errorRate,
                    recommendation: 'Investigate and fix error causes'
                });
            }
        }
        
        return bottlenecks.sort((a, b) => b.impact - a.impact);
    }
    
    private detectPatterns(metrics: HistoricalMetrics): Pattern[] {
        return [
            ...this.detectTimePatterns(metrics.timeSeries),
            ...this.detectLoadPatterns(metrics.timeSeries),
            ...this.detectErrorPatterns(metrics.errorDistribution)
        ];
    }
}
'''
```

---

### Task 3.17: 에이전트 레지스트리 시스템

#### SubTask 3.17.1: 중앙 레지스트리 구현
**담당자**: 시스템 아키텍트  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/framework/agent_registry.py
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass
from datetime import datetime
import asyncio

@dataclass
class AgentRegistration:
    id: str
    name: str
    version: str
    capabilities: List[str]
    requirements: Dict[str, Any]
    metadata: Dict[str, Any]
    status: str
    registered_at: datetime
    last_heartbeat: datetime

class AgentRegistry:
    """Central registry for agent management"""
    
    def __init__(self):
        self.storage = RegistryStorage()
        self.discovery = ServiceDiscovery()
        self.health_checker = HealthChecker()
    
    async def create_registry_system(
        self,
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Create agent registry system"""
        
        # Generate registry implementation
        registry_implementation = await self._generate_registry()
        
        # Generate discovery service
        discovery_implementation = await self._generate_discovery_service()
        
        # Generate health monitoring
        health_implementation = await self._generate_health_monitoring()
        
        # Generate query interface
        query_implementation = await self._generate_query_interface()
        
        return {
            'registry': registry_implementation,
            'discovery': discovery_implementation,
            'health': health_implementation,
            'query': query_implementation
        }
    
    async def _generate_registry(self) -> str:
        """Generate agent registry implementation"""
        
        return '''
import { EventEmitter } from 'events';
import { DynamoDBClient } from '@aws-sdk/client-dynamodb';
import { v4 as uuidv4 } from 'uuid';

export interface AgentRegistration {
    id: string;
    name: string;
    version: string;
    capabilities: string[];
    requirements: AgentRequirements;
    metadata: Record<string, any>;
    status: AgentStatus;
    endpoint?: string;
    registeredAt: Date;
    lastHeartbeat: Date;
}

export enum AgentStatus {
    REGISTERING = 'registering',
    ACTIVE = 'active',
    INACTIVE = 'inactive',
    UNHEALTHY = 'unhealthy',
    DECOMMISSIONING = 'decommissioning',
    DECOMMISSIONED = 'decommissioned'
}

export class AgentRegistry extends EventEmitter {
    private agents = new Map<string, AgentRegistration>();
    private capabilities = new Map<string, Set<string>>(); // capability -> agent IDs
    private dynamodb: DynamoDBClient;
    private healthChecker: HealthChecker;
    
    constructor(config: RegistryConfig) {
        super();
        this.dynamodb = new DynamoDBClient(config.dynamodb);
        this.healthChecker = new HealthChecker(config.health);
        this.initializeRegistry();
    }
    
    async register(agentInfo: Omit<AgentRegistration, 'id' | 'registeredAt' | 'lastHeartbeat'>): Promise<string> {
        // Validate registration
        this.validateRegistration(agentInfo);
        
        // Check for existing registration
        const existing = this.findByNameAndVersion(agentInfo.name, agentInfo.version);
        if (existing && existing.status === AgentStatus.ACTIVE) {
            throw new Error(`Agent ${agentInfo.name}:${agentInfo.version} already registered`);
        }
        
        // Create registration
        const registration: AgentRegistration = {
            ...agentInfo,
            id: uuidv4(),
            status: AgentStatus.REGISTERING,
            registeredAt: new Date(),
            lastHeartbeat: new Date()
        };
        
        // Store in memory
        this.agents.set(registration.id, registration);
        
        // Update capability index
        this.updateCapabilityIndex(registration);
        
        // Persist to DynamoDB
        await this.persistRegistration(registration);
        
        // Start health monitoring
        this.healthChecker.startMonitoring(registration.id, registration.endpoint);
        
        // Emit registration event
        this.emit('agent:registered', registration);
        
        // Activate agent
        await this.activateAgent(registration.id);
        
        return registration.id;
    }
    
    async deregister(agentId: string): Promise<void> {
        const agent = this.agents.get(agentId);
        
        if (!agent) {
            throw new Error(`Agent ${agentId} not found`);
        }
        
        // Update status
        agent.status = AgentStatus.DECOMMISSIONING;
        
        // Stop health monitoring
        this.healthChecker.stopMonitoring(agentId);
        
        // Remove from capability index
        this.removeFromCapabilityIndex(agent);
        
        // Wait for graceful shutdown
        await this.gracefulShutdown(agent);
        
        // Update final status
        agent.status = AgentStatus.DECOMMISSIONED;
        await this.persistRegistration(agent);
        
        // Remove from memory
        this.agents.delete(agentId);
        
        // Emit deregistration event
        this.emit('agent:deregistered', agent);
    }
    
    async updateHeartbeat(agentId: string, health?: HealthStatus): Promise<void> {
        const agent = this.agents.get(agentId);
        
        if (!agent) {
            throw new Error(`Agent ${agentId} not found`);
        }
        
        agent.lastHeartbeat = new Date();
        
        // Update health status if provided
        if (health) {
            const newStatus = this.determineStatus(health);
            if (newStatus !== agent.status) {
                const oldStatus = agent.status;
                agent.status = newStatus;
                
                this.emit('agent:status_changed', {
                    agentId,
                    oldStatus,
                    newStatus,
                    health
                });
            }
        }
        
        // Update in storage
        await this.updateAgentStatus(agent);
    }
    
    findAgents(criteria: AgentSearchCriteria): AgentRegistration[] {
        let results = Array.from(this.agents.values());
        
        // Filter by status
        if (criteria.status) {
            results = results.filter(a => a.status === criteria.status);
        }
        
        // Filter by capabilities
        if (criteria.capabilities && criteria.capabilities.length > 0) {
            if (criteria.requireAllCapabilities) {
                results = results.filter(a => 
                    criteria.capabilities!.every(cap => a.capabilities.includes(cap))
                );
            } else {
                results = results.filter(a =>
                    criteria.capabilities!.some(cap => a.capabilities.includes(cap))
                );
            }
        }
        
        // Filter by version
        if (criteria.version) {
            if (criteria.version.startsWith('^')) {
                // Compatible version
                const baseVersion = criteria.version.substring(1);
                results = results.filter(a => 
                    this.isVersionCompatible(a.version, baseVersion)
                );
            } else {
                // Exact version
                results = results.filter(a => a.version === criteria.version);
            }
        }
        
        // Filter by metadata
        if (criteria.metadata) {
            results = results.filter(a => 
                this.matchesMetadata(a.metadata, criteria.metadata)
            );
        }
        
        // Sort by registration time
        results.sort((a, b) => 
            b.registeredAt.getTime() - a.registeredAt.getTime()
        );
        
        return results;
    }
    
    getAgentById(agentId: string): AgentRegistration | null {
        return this.agents.get(agentId) || null;
    }
    
    getAgentsByCapability(capability: string): AgentRegistration[] {
        const agentIds = this.capabilities.get(capability);
        
        if (!agentIds) {
            return [];
        }
        
        return Array.from(agentIds)
            .map(id => this.agents.get(id))
            .filter(agent => agent && agent.status === AgentStatus.ACTIVE) as AgentRegistration[];
    }
    
    private updateCapabilityIndex(agent: AgentRegistration): void {
        for (const capability of agent.capabilities) {
            if (!this.capabilities.has(capability)) {
                this.capabilities.set(capability, new Set());
            }
            
            this.capabilities.get(capability)!.add(agent.id);
        }
    }
    
    private async initializeRegistry(): Promise<void> {
        // Load existing registrations from DynamoDB
        const registrations = await this.loadRegistrations();
        
        for (const registration of registrations) {
            this.agents.set(registration.id, registration);
            this.updateCapabilityIndex(registration);
            
            // Resume health monitoring for active agents
            if (registration.status === AgentStatus.ACTIVE) {
                this.healthChecker.startMonitoring(
                    registration.id,
                    registration.endpoint
                );
            }
        }
        
        // Start stale agent cleanup
        this.startStaleAgentCleanup();
    }
    
    private startStaleAgentCleanup(): void {
        setInterval(async () => {
            const staleThreshold = Date.now() - 300000; // 5 minutes
            
            for (const [id, agent] of this.agents) {
                if (
                    agent.status === AgentStatus.ACTIVE &&
                    agent.lastHeartbeat.getTime() < staleThreshold
                ) {
                    agent.status = AgentStatus.INACTIVE;
                    await this.updateAgentStatus(agent);
                    
                    this.emit('agent:inactive', agent);
                }
            }
        }, 60000); // Check every minute
    }
}

// Service Discovery
export class ServiceDiscovery {
    private registry: AgentRegistry;
    private cache = new Map<string, DiscoveryResult>();
    
    constructor(registry: AgentRegistry) {
        this.registry = registry;
        this.setupCacheInvalidation();
    }
    
    async discover(
        capability: string,
        options?: DiscoveryOptions
    ): Promise<DiscoveryResult> {
        const cacheKey = this.getCacheKey(capability, options);
        
        // Check cache
        if (!options?.noCache) {
            const cached = this.cache.get(cacheKey);
            if (cached && !this.isCacheExpired(cached)) {
                return cached;
            }
        }
        
        // Find agents with capability
        const agents = this.registry.getAgentsByCapability(capability);
        
        if (agents.length === 0) {
            throw new Error(`No agents found with capability: ${capability}`);
        }
        
        // Apply filters
        let filtered = agents;
        
        if (options?.version) {
            filtered = filtered.filter(a => 
                this.matchesVersionRequirement(a.version, options.version!)
            );
        }
        
        if (options?.metadata) {
            filtered = filtered.filter(a =>
                this.matchesMetadata(a.metadata, options.metadata!)
            );
        }
        
        // Select best agent
        const selected = await this.selectBestAgent(filtered, options);
        
        const result: DiscoveryResult = {
            agentId: selected.id,
            agent: selected,
            alternatives: filtered.filter(a => a.id !== selected.id),
            discoveredAt: new Date()
        };
        
        // Cache result
        this.cache.set(cacheKey, result);
        
        return result;
    }
    
    private async selectBestAgent(
        agents: AgentRegistration[],
        options?: DiscoveryOptions
    ): Promise<AgentRegistration> {
        if (options?.selectionStrategy === 'random') {
            return agents[Math.floor(Math.random() * agents.length)];
        }
        
        if (options?.selectionStrategy === 'round-robin') {
            return this.selectRoundRobin(agents, options.capability);
        }
        
        // Default: select by load/health
        const healthScores = await Promise.all(
            agents.map(a => this.getHealthScore(a))
        );
        
        let bestIndex = 0;
        let bestScore = healthScores[0];
        
        for (let i = 1; i < healthScores.length; i++) {
            if (healthScores[i] > bestScore) {
                bestScore = healthScores[i];
                bestIndex = i;
            }
        }
        
        return agents[bestIndex];
    }
}
'''
```

#### SubTask 3.17.2: 서비스 디스커버리
**담당자**: 분산 시스템 전문가  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/framework/service_discovery.py
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass
import asyncio

@dataclass
class ServiceEndpoint:
    agent_id: str
    address: str
    port: int
    protocol: str
    metadata: Dict[str, Any]
    health_check_url: Optional[str] = None

class ServiceDiscovery:
    """Service discovery for distributed agents"""
    
    def __init__(self):
        self.endpoint_registry = EndpointRegistry()
        self.load_balancer = LoadBalancer()
        self.health_monitor = HealthMonitor()
    
    async def create_discovery_system(
        self,
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Create service discovery system"""
        
        # Generate discovery implementation
        discovery_implementation = await self._generate_discovery()
        
        # Generate load balancing
        load_balancing = await self._generate_load_balancing()
        
        # Generate health checking
        health_checking = await self._generate_health_checking()
        
        # Generate DNS integration
        dns_integration = await self._generate_dns_integration()
        
        return {
            'discovery': discovery_implementation,
            'load_balancing': load_balancing,
            'health_checking': health_checking,
            'dns_integration': dns_integration
        }
    
    async def _generate_discovery(self) -> str:
        """Generate service discovery implementation"""
        
        return '''
export interface ServiceEndpoint {
    agentId: string;
    address: string;
    port: number;
    protocol: 'http' | 'https' | 'grpc' | 'websocket';
    weight?: number;
    metadata?: Record<string, any>;
    healthCheckUrl?: string;
}

export interface DiscoveryOptions {
    loadBalancing?: 'round-robin' | 'least-connections' | 'weighted' | 'random';
    healthCheck?: boolean;
    timeout?: number;
    retries?: number;
    circuitBreaker?: CircuitBreakerConfig;
}

export class ServiceDiscovery {
    private endpoints = new Map<string, ServiceEndpoint[]>();
    private healthStatus = new Map<string, HealthStatus>();
    private loadBalancers = new Map<string, LoadBalancer>();
    private consul?: Consul;
    
    constructor(config: ServiceDiscoveryConfig) {
        if (config.backend === 'consul') {
            this.consul = new Consul(config.consul);
            this.syncWithConsul();
        }
        
        this.startHealthChecking();
    }
    
    async register(
        serviceName: string,
        endpoint: ServiceEndpoint
    ): Promise<void> {
        // Validate endpoint
        this.validateEndpoint(endpoint);
        
        // Add to local registry
        if (!this.endpoints.has(serviceName)) {
            this.endpoints.set(serviceName, []);
        }
        
        const endpoints = this.endpoints.get(serviceName)!;
        
        // Check for duplicates
        const existing = endpoints.findIndex(e => 
            e.agentId === endpoint.agentId
        );
        
        if (existing !== -1) {
            // Update existing
            endpoints[existing] = endpoint;
        } else {
            // Add new
            endpoints.push(endpoint);
        }
        
        // Register with Consul if available
        if (this.consul) {
            await this.consul.agent.service.register({
                id: endpoint.agentId,
                name: serviceName,
                address: endpoint.address,
                port: endpoint.port,
                tags: [`protocol:${endpoint.protocol}`],
                meta: endpoint.metadata,
                check: endpoint.healthCheckUrl ? {
                    http: endpoint.healthCheckUrl,
                    interval: '10s',
                    timeout: '5s'
                } : undefined
            });
        }
        
        // Update load balancer
        this.updateLoadBalancer(serviceName);
        
        // Emit registration event
        this.emit('service:registered', { serviceName, endpoint });
    }
    
    async discover(
        serviceName: string,
        options?: DiscoveryOptions
    ): Promise<ServiceEndpoint> {
        const endpoints = await this.getHealthyEndpoints(serviceName);
        
        if (endpoints.length === 0) {
            throw new Error(`No healthy endpoints found for service: ${serviceName}`);
        }
        
        // Get or create load balancer
        const loadBalancer = this.getLoadBalancer(
            serviceName,
            options?.loadBalancing || 'round-robin'
        );
        
        // Select endpoint
        let endpoint = loadBalancer.select(endpoints);
        
        // Apply circuit breaker if configured
        if (options?.circuitBreaker) {
            endpoint = await this.applyCircuitBreaker(endpoint, options.circuitBreaker);
        }
        
        return endpoint;
    }
    
    async discoverAll(
        serviceName: string,
        options?: DiscoveryOptions
    ): Promise<ServiceEndpoint[]> {
        const endpoints = await this.getHealthyEndpoints(serviceName);
        
        if (options?.loadBalancing === 'weighted') {
            // Sort by weight
            endpoints.sort((a, b) => (b.weight || 1) - (a.weight || 1));
        }
        
        return endpoints;
    }
    
    private async getHealthyEndpoints(
        serviceName: string
    ): Promise<ServiceEndpoint[]> {
        const allEndpoints = this.endpoints.get(serviceName) || [];
        
        if (allEndpoints.length === 0 && this.consul) {
            // Try to discover from Consul
            const services = await this.consul.health.service(serviceName);
            
            for (const service of services) {
                const endpoint: ServiceEndpoint = {
                    agentId: service.Service.ID,
                    address: service.Service.Address,
                    port: service.Service.Port,
                    protocol: this.extractProtocol(service.Service.Tags),
                    metadata: service.Service.Meta
                };
                
                allEndpoints.push(endpoint);
            }
            
            this.endpoints.set(serviceName, allEndpoints);
        }
        
        // Filter healthy endpoints
        return allEndpoints.filter(endpoint => {
            const health = this.healthStatus.get(endpoint.agentId);
            return !health || health.status === 'healthy';
        });
    }
    
    private getLoadBalancer(
        serviceName: string,
        strategy: string
    ): LoadBalancer {
        const key = `${serviceName}:${strategy}`;
        
        if (!this.loadBalancers.has(key)) {
            let balancer: LoadBalancer;
            
            switch (strategy) {
                case 'round-robin':
                    balancer = new RoundRobinBalancer();
                    break;
                    
                case 'least-connections':
                    balancer = new LeastConnectionsBalancer();
                    break;
                    
                case 'weighted':
                    balancer = new WeightedBalancer();
                    break;
                    
                case 'random':
                    balancer = new RandomBalancer();
                    break;
                    
                default:
                    balancer = new RoundRobinBalancer();
            }
            
            this.loadBalancers.set(key, balancer);
        }
        
        return this.loadBalancers.get(key)!;
    }
    
    private startHealthChecking(): void {
        setInterval(async () => {
            const allEndpoints = Array.from(this.endpoints.values()).flat();
            
            await Promise.all(
                allEndpoints.map(endpoint => this.checkHealth(endpoint))
            );
        }, 10000); // Check every 10 seconds
    }
    
    private async checkHealth(endpoint: ServiceEndpoint): Promise<void> {
        try {
            if (endpoint.healthCheckUrl) {
                const response = await fetch(endpoint.healthCheckUrl, {
                    method: 'GET',
                    timeout: 5000
                });
                
                const healthy = response.ok;
                
                this.healthStatus.set(endpoint.agentId, {
                    status: healthy ? 'healthy' : 'unhealthy',
                    lastCheck: new Date(),
                    consecutiveFailures: healthy ? 0 : 
                        (this.healthStatus.get(endpoint.agentId)?.consecutiveFailures || 0) + 1
                });
            }
        } catch (error) {
            const current = this.healthStatus.get(endpoint.agentId);
            
            this.healthStatus.set(endpoint.agentId, {
                status: 'unhealthy',
                lastCheck: new Date(),
                consecutiveFailures: (current?.consecutiveFailures || 0) + 1,
                error: error.message
            });
        }
    }
}

// Load Balancer Implementations
abstract class LoadBalancer {
    abstract select(endpoints: ServiceEndpoint[]): ServiceEndpoint;
}

class RoundRobinBalancer extends LoadBalancer {
    private index = 0;
    
    select(endpoints: ServiceEndpoint[]): ServiceEndpoint {
        const selected = endpoints[this.index % endpoints.length];
        this.index++;
        return selected;
    }
}

class WeightedBalancer extends LoadBalancer {
    select(endpoints: ServiceEndpoint[]): ServiceEndpoint {
        const totalWeight = endpoints.reduce((sum, e) => sum + (e.weight || 1), 0);
        let random = Math.random() * totalWeight;
        
        for (const endpoint of endpoints) {
            random -= (endpoint.weight || 1);
            if (random <= 0) {
                return endpoint;
            }
        }
        
        return endpoints[endpoints.length - 1];
    }
}

class LeastConnectionsBalancer extends LoadBalancer {
    private connections = new Map<string, number>();
    
    select(endpoints: ServiceEndpoint[]): ServiceEndpoint {
        let minConnections = Infinity;
        let selected = endpoints[0];
        
        for (const endpoint of endpoints) {
            const connections = this.connections.get(endpoint.agentId) || 0;
            
            if (connections < minConnections) {
                minConnections = connections;
                selected = endpoint;
            }
        }
        
        // Increment connection count
        this.connections.set(
            selected.agentId,
            (this.connections.get(selected.agentId) || 0) + 1
        );
        
        return selected;
    }
    
    releaseConnection(agentId: string): void {
        const current = this.connections.get(agentId) || 0;
        if (current > 0) {
            this.connections.set(agentId, current - 1);
        }
    }
}

// DNS-based Service Discovery
export class DNSServiceDiscovery {
    private resolver: DNSResolver;
    private cache = new Map<string, DNSRecord[]>();
    
    constructor(config: DNSConfig) {
        this.resolver = new DNSResolver(config);
        this.startCacheRefresh();
    }
    
    async resolve(serviceName: string): Promise<ServiceEndpoint[]> {
        const fqdn = `${serviceName}.${this.config.domain}`;
        
        // Check cache
        const cached = this.cache.get(fqdn);
        if (cached && !this.isCacheExpired(cached)) {
            return this.recordsToEndpoints(cached);
        }
        
        // Resolve SRV records
        const srvRecords = await this.resolver.resolveSrv(fqdn);
        
        // Resolve A records for each SRV
        const endpoints: ServiceEndpoint[] = [];
        
        for (const srv of srvRecords) {
            const aRecords = await this.resolver.resolveA(srv.target);
            
            for (const a of aRecords) {
                endpoints.push({
                    agentId: `${serviceName}-${a.address}:${srv.port}`,
                    address: a.address,
                    port: srv.port,
                    protocol: this.inferProtocol(srv.port),
                    weight: srv.weight,
                    metadata: {
                        priority: srv.priority
                    }
                });
            }
        }
        
        // Update cache
        this.cache.set(fqdn, { records: srvRecords, endpoints, timestamp: Date.now() });
        
        return endpoints;
    }
}
'''
```

#### SubTask 3.17.3: 메타데이터 관리
**담당자**: 데이터 관리자  
**예상 소요시간**: 10시간

**작업 내용**:
```python
# backend/src/agents/framework/metadata_management.py
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass
from datetime import datetime

@dataclass
class AgentMetadata:
    agent_id: str
    version: str
    description: str
    author: str
    tags: List[str]
    documentation_url: Optional[str]
    source_url: Optional[str]
    dependencies: List[Dict[str, str]]
    configuration_schema: Dict[str, Any]
    performance_profile: Dict[str, Any]
    created_at: datetime
    updated_at: datetime

class MetadataManager:
    """Manage agent metadata and documentation"""
    
    def __init__(self):
        self.metadata_store = MetadataStore()
        self.schema_validator = SchemaValidator()
        self.documentation_generator = DocumentationGenerator()
    
    async def create_metadata_system(self) -> Dict[str, Any]:
        """Create metadata management system"""
        
        # Generate metadata store
        store_implementation = await self._generate_metadata_store()
        
        # Generate schema management
        schema_implementation = await self._generate_schema_management()
        
        # Generate search interface
        search_implementation = await self._generate_search_interface()
        
        # Generate documentation
        docs_implementation = await self._generate_documentation_system()
        
        return {
            'store': store_implementation,
            'schema': schema_implementation,
            'search': search_implementation,
            'documentation': docs_implementation
        }
    
    async def _generate_metadata_store(self) -> str:
        """Generate metadata store implementation"""
        
        return '''
export interface AgentMetadata {
    agentId: string;
    version: string;
    name: string;
    description: string;
    author: string;
    tags: string[];
    category: string;
    documentationUrl?: string;
    sourceUrl?: string;
    dependencies: Dependency[];
    configurationSchema: JSONSchema;
    inputSchema: JSONSchema;
    outputSchema: JSONSchema;
    performanceProfile: PerformanceProfile;
    examples: Example[];
    changelog: ChangelogEntry[];
    createdAt: Date;
    updatedAt: Date;
}

export interface PerformanceProfile {
    averageLatency: number;
    throughput: number;
    memoryUsage: number;
    cpuUsage: number;
    concurrency: number;
    reliability: number;
}

export class MetadataStore {
    private metadata = new Map<string, AgentMetadata>();
    private searchIndex: SearchIndex;
    private schemaValidator: SchemaValidator;
    
    constructor(config: MetadataConfig) {
        this.searchIndex = new SearchIndex(config.search);
        this.schemaValidator = new SchemaValidator();
        this.loadMetadata();
    }
    
    async addMetadata(metadata: AgentMetadata): Promise<void> {
        // Validate metadata
        this.validateMetadata(metadata);
        
        // Generate unique key
        const key = `${metadata.agentId}:${metadata.version}`;
        
        // Store metadata
        this.metadata.set(key, metadata);
        
        // Update search index
        await this.searchIndex.index(metadata);
        
        // Persist to storage
        await this.persistMetadata(metadata);
        
        // Generate documentation
        await this.generateDocumentation(metadata);
        
        // Emit event
        this.emit('metadata:added', metadata);
    }
    
    async updateMetadata(
        agentId: string,
        version: string,
        updates: Partial<AgentMetadata>
    ): Promise<void> {
        const key = `${agentId}:${version}`;
        const existing = this.metadata.get(key);
        
        if (!existing) {
            throw new Error(`Metadata not found for ${key}`);
        }
        
        // Merge updates
        const updated: AgentMetadata = {
            ...existing,
            ...updates,
            updatedAt: new Date()
        };
        
        // Validate updated metadata
        this.validateMetadata(updated);
        
        // Update store
        this.metadata.set(key, updated);
        
        // Update search index
        await this.searchIndex.update(updated);
        
        // Persist changes
        await this.persistMetadata(updated);
        
        // Regenerate documentation if needed
        if (this.shouldRegenerateDocumentation(existing, updates)) {
            await this.generateDocumentation(updated);
        }
        
        // Emit event
        this.emit('metadata:updated', { previous: existing, current: updated });
    }
    
    async searchAgents(query: SearchQuery): Promise<SearchResult[]> {
        // Parse query
        const parsedQuery = this.parseSearchQuery(query);
        
        // Search in index
        const results = await this.searchIndex.search(parsedQuery);
        
        // Enhance results with full metadata
        const enhanced = results.map(result => ({
            ...result,
            metadata: this.metadata.get(`${result.agentId}:${result.version}`)
        }));
        
        // Apply filters
        const filtered = this.applyFilters(enhanced, parsedQuery.filters);
        
        // Sort results
        const sorted = this.sortResults(filtered, parsedQuery.sort);
        
        return sorted;
    }
    
    getCompatibleAgents(
        capability: string,
        requirements: Requirements
    ): AgentMetadata[] {
        const compatible: AgentMetadata[] = [];
        
        for (const metadata of this.metadata.values()) {
            // Check capability
            if (!metadata.tags.includes(capability)) {
                continue;
            }
            
            // Check version compatibility
            if (requirements.version && !this.isVersionCompatible(
                metadata.version,
                requirements.version
            )) {
                continue;
            }
            
            // Check dependencies
            if (!this.areDependenciesSatisfied(
                metadata.dependencies,
                requirements.availableDependencies
            )) {
                continue;
            }
            
            // Check performance requirements
            if (!this.meetsPerformanceRequirements(
                metadata.performanceProfile,
                requirements.performance
            )) {
                continue;
            }
            
            compatible.push(metadata);
        }
        
        // Rank by suitability
        return this.rankBySuitability(compatible, requirements);
    }
    
    private validateMetadata(metadata: AgentMetadata): void {
        // Validate required fields
        if (!metadata.agentId || !metadata.version || !metadata.name) {
            throw new Error('Missing required metadata fields');
        }
        
        // Validate schemas
        if (metadata.configurationSchema) {
            this.schemaValidator.validateSchema(metadata.configurationSchema);
        }
        
        if (metadata.inputSchema) {
            this.schemaValidator.validateSchema(metadata.inputSchema);
        }
        
        if (metadata.outputSchema) {
            this.schemaValidator.validateSchema(metadata.outputSchema);
        }
        
        // Validate version format
        if (!this.isValidVersion(metadata.version)) {
            throw new Error(`Invalid version format: ${metadata.version}`);
        }
        
        // Validate dependencies
        for (const dep of metadata.dependencies) {
            if (!dep.name || !dep.version) {
                throw new Error('Invalid dependency specification');
            }
        }
    }
    
    private async generateDocumentation(metadata: AgentMetadata): Promise<void> {
        const doc = {
            title: `${metadata.name} v${metadata.version}`,
            description: metadata.description,
            author: metadata.author,
            sections: [
                this.generateOverviewSection(metadata),
                this.generateConfigurationSection(metadata),
                this.generateAPISection(metadata),
                this.generateExamplesSection(metadata),
                this.generatePerformanceSection(metadata),
                this.generateChangelogSection(metadata)
            ]
        };
        
        // Generate markdown
        const markdown = this.renderDocumentation(doc);
        
        // Save documentation
        await this.saveDocumentation(metadata.agentId, metadata.version, markdown);
        
        // Update documentation URL
        metadata.documentationUrl = this.getDocumentationUrl(
            metadata.agentId,
            metadata.version
        );
    }
}

// Schema Management
export class SchemaManager {
    private schemas = new Map<string, VersionedSchema>();
    private validator: Ajv;
    
    constructor() {
        this.validator = new Ajv({ allErrors: true });
        this.registerStandardSchemas();
    }
    
    registerSchema(
        agentId: string,
        version: string,
        schemaType: 'config' | 'input' | 'output',
        schema: JSONSchema
    ): void {
        const key = `${agentId}:${version}:${schemaType}`;
        
        // Validate schema
        this.validator.compile(schema);
        
        // Store with version info
        this.schemas.set(key, {
            schema,
            version,
            registeredAt: new Date(),
            usageCount: 0
        });
    }
    
    validateData(
        agentId: string,
        version: string,
        schemaType: string,
        data: any
    ): ValidationResult {
        const key = `${agentId}:${version}:${schemaType}`;
        const versionedSchema = this.schemas.get(key);
        
        if (!versionedSchema) {
            throw new Error(`Schema not found: ${key}`);
        }
        
        const valid = this.validator.validate(versionedSchema.schema, data);
        
        // Update usage count
        versionedSchema.usageCount++;
        
        return {
            valid: valid as boolean,
            errors: this.validator.errors || [],
            schema: versionedSchema.schema
        };
    }
    
    async evolveSchema(
        agentId: string,
        fromVersion: string,
        toVersion: string,
        schemaType: string,
        changes: SchemaChange[]
    ): Promise<JSONSchema> {
        const oldKey = `${agentId}:${fromVersion}:${schemaType}`;
        const oldSchema = this.schemas.get(oldKey)?.schema;
        
        if (!oldSchema) {
            throw new Error(`Source schema not found: ${oldKey}`);
        }
        
        // Apply changes
        let newSchema = { ...oldSchema };
        
        for (const change of changes) {
            newSchema = this.applySchemaChange(newSchema, change);
        }
        
        // Validate compatibility
        const compatibility = this.checkCompatibility(oldSchema, newSchema);
        
        if (!compatibility.isCompatible) {
            throw new Error(
                `Schema evolution breaks compatibility: ${compatibility.issues.join(', ')}`
            );
        }
        
        // Register new schema
        this.registerSchema(agentId, toVersion, schemaType, newSchema);
        
        return newSchema;
    }
}
'''
```

#### SubTask 3.17.4: 버전 호환성 관리
**담당자**: 버전 관리 전문가  
**예상 소요시간**: 10시간

**작업 내용**:
```python
# backend/src/agents/framework/version_compatibility.py
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import semver

@dataclass
class VersionConstraint:
    operator: str  # =, >, <, >=, <=, ~, ^
    version: str
    pre_release: bool = False

class VersionCompatibility:
    """Manage agent version compatibility"""
    
    def __init__(self):
        self.compatibility_matrix = CompatibilityMatrix()
        self.migration_manager = MigrationManager()
        self.dependency_resolver = DependencyResolver()
    
    async def create_compatibility_system(self) -> Dict[str, Any]:
        """Create version compatibility system"""
        
        # Generate compatibility checker
        compatibility_implementation = await self._generate_compatibility_checker()
        
        # Generate migration system
        migration_implementation = await self._generate_migration_system()
        
        # Generate dependency resolver
        resolver_implementation = await self._generate_dependency_resolver()
        
        # Generate version policy
        policy_implementation = await self._generate_version_policy()
        
        return {
            'compatibility': compatibility_implementation,
            'migration': migration_implementation,
            'resolver': resolver_implementation,
            'policy': policy_implementation
        }
    
    async def _generate_compatibility_checker(self) -> str:
        """Generate version compatibility checker"""
        
        return '''
import semver from 'semver';

export interface VersionConstraint {
    operator: '=' | '>' | '<' | '>=' | '<=' | '~' | '^';
    version: string;
    preRelease?: boolean;
}

export interface CompatibilityResult {
    compatible: boolean;
    reason?: string;
    suggestedVersion?: string;
    migrationRequired?: boolean;
    breakingChanges?: string[];
}

export class VersionCompatibilityChecker {
    private compatibilityRules = new Map<string, CompatibilityRule[]>();
    private breakingChanges = new Map<string, BreakingChange[]>();
    
    checkCompatibility(
        agentId: string,
        currentVersion: string,
        requiredVersion: string | VersionConstraint
    ): CompatibilityResult {
        // Parse versions
        const current = this.parseVersion(currentVersion);
        const required = typeof requiredVersion === 'string'
            ? this.parseVersionConstraint(requiredVersion)
            : requiredVersion;
        
        // Check basic semver compatibility
        if (!this.satisfiesConstraint(current, required)) {
            return {
                compatible: false,
                reason: `Version ${currentVersion} does not satisfy ${this.constraintToString(required)}`,
                suggestedVersion: this.findCompatibleVersion(agentId, required)
            };
        }
        
        // Check for breaking changes
        const breaking = this.findBreakingChanges(agentId, currentVersion, required);
        
        if (breaking.length > 0) {
            return {
                compatible: false,
                reason: 'Breaking changes detected',
                breakingChanges: breaking.map(b => b.description),
                migrationRequired: true
            };
        }
        
        // Check custom compatibility rules
        const customRules = this.compatibilityRules.get(agentId) || [];
        
        for (const rule of customRules) {
            if (!rule.check(currentVersion, required)) {
                return {
                    compatible: false,
                    reason: rule.reason,
                    suggestedVersion: rule.suggestedVersion
                };
            }
        }
        
        return { compatible: true };
    }
    
    registerBreakingChange(
        agentId: string,
        fromVersion: string,
        toVersion: string,
        change: BreakingChange
    ): void {
        const key = `${agentId}:${fromVersion}:${toVersion}`;
        
        if (!this.breakingChanges.has(key)) {
            this.breakingChanges.set(key, []);
        }
        
        this.breakingChanges.get(key)!.push(change);
    }
    
    async resolveVersionConflicts(
        dependencies: DependencySpec[]
    ): Promise<ResolutionResult> {
        // Build dependency graph
        const graph = this.buildDependencyGraph(dependencies);
        
        // Check for conflicts
        const conflicts = this.findVersionConflicts(graph);
        
        if (conflicts.length === 0) {
            return {
                resolved: true,
                versions: this.extractVersions(graph)
            };
        }
        
        // Try to resolve conflicts
        const resolution = await this.tryResolveConflicts(conflicts, graph);
        
        if (!resolution.success) {
            return {
                resolved: false,
                conflicts: conflicts.map(c => ({
                    agent: c.agent,
                    conflictingVersions: c.versions,
                    reason: c.reason
                }))
            };
        }
        
        return {
            resolved: true,
            versions: resolution.versions,
            warnings: resolution.warnings
        };
    }
    
    private satisfiesConstraint(
        version: semver.SemVer,
        constraint: VersionConstraint
    ): boolean {
        switch (constraint.operator) {
            case '=':
                return semver.eq(version, constraint.version);
                
            case '>':
                return semver.gt(version, constraint.version);
                
            case '<':
                return semver.lt(version, constraint.version);
                
            case '>=':
                return semver.gte(version, constraint.version);
                
            case '<=':
                return semver.lte(version, constraint.version);
                
            case '~':
                // Patch-level changes
                return semver.satisfies(version, `~${constraint.version}`);
                
            case '^':
                // Minor-level changes
                return semver.satisfies(version, `^${constraint.version}`);
                
            default:
                throw new Error(`Unknown operator: ${constraint.operator}`);
        }
    }
    
    private findCompatibleVersion(
        agentId: string,
        constraint: VersionConstraint
    ): string | undefined {
        // Get all available versions
        const versions = this.getAvailableVersions(agentId);
        
        // Sort by version (descending)
        versions.sort((a, b) => semver.rcompare(a, b));
        
        // Find first compatible version
        for (const version of versions) {
            if (this.satisfiesConstraint(semver.parse(version)!, constraint)) {
                return version;
            }
        }
        
        return undefined;
    }
}

// Version Migration
export class VersionMigrator {
    private migrations = new Map<string, Migration[]>();
    
    async migrate(
        agentId: string,
        fromVersion: string,
        toVersion: string,
        data: any
    ): Promise<MigrationResult> {
        // Find migration path
        const path = this.findMigrationPath(agentId, fromVersion, toVersion);
        
        if (!path) {
            return {
                success: false,
                error: `No migration path from ${fromVersion} to ${toVersion}`
            };
        }
        
        // Execute migrations
        let currentData = data;
        let currentVersion = fromVersion;
        
        for (const migration of path) {
            try {
                const result = await this.executeMigration(
                    migration,
                    currentData,
                    currentVersion
                );
                
                currentData = result.data;
                currentVersion = result.version;
                
            } catch (error) {
                return {
                    success: false,
                    error: `Migration failed at ${currentVersion}: ${error.message}`,
                    partialData: currentData
                };
            }
        }
        
        return {
            success: true,
            data: currentData,
            fromVersion,
            toVersion,
            migrationsApplied: path.length
        };
    }
    
    registerMigration(
        agentId: string,
        migration: Migration
    ): void {
        const key = `${agentId}:${migration.fromVersion}:${migration.toVersion}`;
        
        if (!this.migrations.has(key)) {
            this.migrations.set(key, []);
        }
        
        this.migrations.get(key)!.push(migration);
    }
    
    private findMigrationPath(
        agentId: string,
        fromVersion: string,
        toVersion: string
    ): Migration[] | null {
        // Build migration graph
        const graph = new Map<string, string[]>();
        const migrations = new Map<string, Migration>();
        
        // Add all migrations for agent
        for (const [key, migrationList] of this.migrations) {
            if (key.startsWith(`${agentId}:`)) {
                for (const migration of migrationList) {
                    const migrationKey = `${migration.fromVersion}:${migration.toVersion}`;
                    migrations.set(migrationKey, migration);
                    
                    if (!graph.has(migration.fromVersion)) {
                        graph.set(migration.fromVersion, []);
                    }
                    
                    graph.get(migration.fromVersion)!.push(migration.toVersion);
                }
            }
        }
        
        // Find shortest path using BFS
        const path = this.findShortestPath(graph, fromVersion, toVersion);
        
        if (!path) {
            return null;
        }
        
        // Convert path to migrations
        const migrationPath: Migration[] = [];
        
        for (let i = 0; i < path.length - 1; i++) {
            const migrationKey = `${path[i]}:${path[i + 1]}`;
            const migration = migrations.get(migrationKey);
            
            if (!migration) {
                return null;
            }
            
            migrationPath.push(migration);
        }
        
        return migrationPath;
    }
}

// Dependency Resolution
export class DependencyResolver {
    async resolve(
        requirements: DependencyRequirement[]
    ): Promise<DependencyResolution> {
        // Build constraint system
        const constraints = this.buildConstraints(requirements);
        
        // Solve constraints
        const solution = await this.solveConstraints(constraints);
        
        if (!solution.satisfiable) {
            return {
                resolved: false,
                conflicts: solution.conflicts,
                suggestions: this.generateSuggestions(solution.conflicts)
            };
        }
        
        // Optimize solution
        const optimized = this.optimizeSolution(solution.assignments);
        
        return {
            resolved: true,
            dependencies: optimized,
            warnings: this.checkForWarnings(optimized)
        };
    }
    
    private buildConstraints(
        requirements: DependencyRequirement[]
    ): ConstraintSystem {
        const constraints = new ConstraintSystem();
        
        for (const req of requirements) {
            // Add version constraint
            constraints.addConstraint({
                type: 'version',
                agent: req.agentId,
                constraint: req.versionConstraint
            });
            
            // Add dependency constraints
            for (const dep of req.dependencies) {
                constraints.addConstraint({
                    type: 'dependency',
                    agent: req.agentId,
                    dependsOn: dep.agentId,
                    constraint: dep.versionConstraint
                });
            }
            
            // Add conflict constraints
            for (const conflict of req.conflicts || []) {
                constraints.addConstraint({
                    type: 'conflict',
                    agent: req.agentId,
                    conflictsWith: conflict.agentId,
                    versions: conflict.versions
                });
            }
        }
        
        return constraints;
    }
}
'''
```

---

### Task 3.18: 에이전트 모니터링 및 분석

#### SubTask 3.18.1: 실시간 성능 모니터링
**담당자**: 성능 엔지니어  
**예상 소요시간**: 14시간

**작업 내용**:
```python
# backend/src/agents/framework/performance_monitoring.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import asyncio

@dataclass
class PerformanceMetrics:
    agent_id: str
    timestamp: datetime
    cpu_usage: float
    memory_usage: float
    response_time: float
    throughput: float
    error_rate: float
    active_tasks: int

class PerformanceMonitoring:
    """Real-time agent performance monitoring"""
    
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.analyzer = PerformanceAnalyzer()
        self.alerting = AlertingSystem()
    
    async def create_monitoring_system(
        self,
        agents: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Create performance monitoring system"""
        
        # Generate monitoring implementation
        monitoring_implementation = await self._generate_monitoring()
        
        # Generate metrics collection
        metrics_implementation = await self._generate_metrics_collection()
        
        # Generate analysis engine
        analysis_implementation = await self._generate_analysis_engine()
        
        # Generate dashboards
        dashboard_implementation = await self._generate_dashboards()
        
        return {
            'monitoring': monitoring_implementation,
            'metrics': metrics_implementation,
            'analysis': analysis_implementation,
            'dashboards': dashboard_implementation
        }
    
    async def _generate_monitoring(self) -> str:
        """Generate performance monitoring implementation"""
        
        return '''
import { EventEmitter } from 'events';
import * as prom from 'prom-client';
import { StatsD } from 'node-statsd';

export interface PerformanceMetrics {
    agentId: string;
    timestamp: Date;
    cpu: CPUMetrics;
    memory: MemoryMetrics;
    performance: PerformanceData;
    tasks: TaskMetrics;
}

export interface CPUMetrics {
    usage: number;
    user: number;
    system: number;
    idle: number;
}

export interface MemoryMetrics {
    used: number;
    total: number;
    percentage: number;
    rss: number;
    heapUsed: number;
    heapTotal: number;
}

export class AgentPerformanceMonitor extends EventEmitter {
    private readonly metrics = new Map<string, MetricCollector>();
    private readonly prometheus = new prom.Registry();
    private readonly statsd: StatsD;
    private readonly samplingInterval = 1000; // 1 second
    
    // Prometheus metrics
    private readonly cpuGauge = new prom.Gauge({
        name: 'agent_cpu_usage',
        help: 'CPU usage percentage',
        labelNames: ['agent_id'],
        registers: [this.prometheus]
    });
    
    private readonly memoryGauge = new prom.Gauge({
        name: 'agent_memory_usage',
        help: 'Memory usage in bytes',
        labelNames: ['agent_id', 'type'],
        registers: [this.prometheus]
    });
    
    private readonly responseTimeHistogram = new prom.Histogram({
        name: 'agent_response_time',
        help: 'Response time in milliseconds',
        labelNames: ['agent_id', 'operation'],
        buckets: [10, 50, 100, 250, 500, 1000, 2500, 5000],
        registers: [this.prometheus]
    });
    
    private readonly throughputCounter = new prom.Counter({
        name: 'agent_requests_total',
        help: 'Total number of requests',
        labelNames: ['agent_id', 'status'],
        registers: [this.prometheus]
    });
    
    constructor(config: MonitorConfig) {
        super();
        this.statsd = new StatsD(config.statsd);
        this.startMonitoring();
    }
    
    startMonitoringAgent(agentId: string): void {
        if (this.metrics.has(agentId)) {
            return;
        }
        
        const collector = new MetricCollector(agentId);
        this.metrics.set(agentId, collector);
        
        // Start collecting metrics
        const interval = setInterval(() => {
            this.collectMetrics(agentId);
        }, this.samplingInterval);
        
        collector.interval = interval;
    }
    
    stopMonitoringAgent(agentId: string): void {
        const collector = this.metrics.get(agentId);
        
        if (collector) {
            clearInterval(collector.interval);
            this.metrics.delete(agentId);
        }
    }
    
    async collectMetrics(agentId: string): Promise<void> {
        const collector = this.metrics.get(agentId);
        
        if (!collector) {
            return;
        }
        
        try {
            // Collect CPU metrics
            const cpuMetrics = await this.collectCPUMetrics(agentId);
            this.cpuGauge.labels(agentId).set(cpuMetrics.usage);
            
            // Collect memory metrics
            const memoryMetrics = await this.collectMemoryMetrics(agentId);
            this.memoryGauge.labels(agentId, 'used').set(memoryMetrics.used);
            this.memoryGauge.labels(agentId, 'heap').set(memoryMetrics.heapUsed);
            
            // Collect performance metrics
            const perfMetrics = collector.getPerformanceMetrics();
            
            // Store in time series
            collector.addMetricPoint({
                timestamp: new Date(),
                cpu: cpuMetrics,
                memory: memoryMetrics,
                performance: perfMetrics
            });
            
            // Check thresholds
            this.checkThresholds(agentId, {
                cpu: cpuMetrics,
                memory: memoryMetrics,
                performance: perfMetrics
            });
            
            // Emit metrics event
            this.emit('metrics:collected', {
                agentId,
                metrics: {
                    cpu: cpuMetrics,
                    memory: memoryMetrics,
                    performance: perfMetrics
                }
            });
            
        } catch (error) {
            console.error(`Failed to collect metrics for ${agentId}:`, error);
        }
    }
    
    recordOperation(
        agentId: string,
        operation: string,
        duration: number,
        success: boolean
    ): void {
        // Update Prometheus metrics
        this.responseTimeHistogram
            .labels(agentId, operation)
            .observe(duration);
        
        this.throughputCounter
            .labels(agentId, success ? 'success' : 'failure')
            .inc();
        
        // Update StatsD metrics
        this.statsd.timing(`agent.${agentId}.${operation}.duration`, duration);
        this.statsd.increment(`agent.${agentId}.${operation}.${success ? 'success' : 'failure'}`);
        
        // Update internal metrics
        const collector = this.metrics.get(agentId);
        if (collector) {
            collector.recordOperation(operation, duration, success);
        }
    }
    
    getMetrics(agentId: string, timeRange?: TimeRange): PerformanceMetrics[] {
        const collector = this.metrics.get(agentId);
        
        if (!collector) {
            return [];
        }
        
        return collector.getMetrics(timeRange);
    }
    
    async getAggregatedMetrics(
        agentId: string,
        aggregation: AggregationType,
        timeRange: TimeRange
    ): Promise<AggregatedMetrics> {
        const metrics = this.getMetrics(agentId, timeRange);
        
        if (metrics.length === 0) {
            return this.getEmptyAggregatedMetrics();
        }
        
        return {
            cpu: this.aggregateMetric(metrics.map(m => m.cpu.usage), aggregation),
            memory: this.aggregateMetric(metrics.map(m => m.memory.percentage), aggregation),
            responseTime: this.aggregateMetric(
                metrics.map(m => m.performance.avgResponseTime),
                aggregation
            ),
            throughput: this.aggregateMetric(
                metrics.map(m => m.performance.throughput),
                aggregation
            ),
            errorRate: this.aggregateMetric(
                metrics.map(m => m.performance.errorRate),
                aggregation
            ),
            timeRange,
            dataPoints: metrics.length
        };
    }
    
    private checkThresholds(
        agentId: string,
        metrics: any
    ): void {
        const thresholds = this.getThresholds(agentId);
        
        // CPU threshold
        if (metrics.cpu.usage > thresholds.cpu) {
            this.emit('threshold:exceeded', {
                agentId,
                metric: 'cpu',
                value: metrics.cpu.usage,
                threshold: thresholds.cpu
            });
        }
        
        // Memory threshold
        if (metrics.memory.percentage > thresholds.memory) {
            this.emit('threshold:exceeded', {
                agentId,
                metric: 'memory',
                value: metrics.memory.percentage,
                threshold: thresholds.memory
            });
        }
        
        // Response time threshold
        if (metrics.performance.avgResponseTime > thresholds.responseTime) {
            this.emit('threshold:exceeded', {
                agentId,
                metric: 'responseTime',
                value: metrics.performance.avgResponseTime,
                threshold: thresholds.responseTime
            });
        }
        
        // Error rate threshold
        if (metrics.performance.errorRate > thresholds.errorRate) {
            this.emit('threshold:exceeded', {
                agentId,
                metric: 'errorRate',
                value: metrics.performance.errorRate,
                threshold: thresholds.errorRate
            });
        }
    }
}

// Performance Analysis Engine
export class PerformanceAnalyzer {
    async analyzePerformance(
        metrics: PerformanceMetrics[],
        options: AnalysisOptions
    ): Promise<PerformanceAnalysis> {
        // Trend analysis
        const trends = this.analyzeTrends(metrics);
        
        // Anomaly detection
        const anomalies = await this.detectAnomalies(metrics, options);
        
        // Performance patterns
        const patterns = this.identifyPatterns(metrics);
        
        // Bottleneck identification
        const bottlenecks = this.identifyBottlenecks(metrics);
        
        // Capacity planning
        const capacity = this.analyzeCapacity(metrics, trends);
        
        // Generate recommendations
        const recommendations = this.generateRecommendations({
            trends,
            anomalies,
            patterns,
            bottlenecks,
            capacity
        });
        
        return {
            summary: this.generateSummary(metrics),
            trends,
            anomalies,
            patterns,
            bottlenecks,
            capacity,
            recommendations,
            score: this.calculatePerformanceScore(metrics)
        };
    }
    
    private analyzeTrends(metrics: PerformanceMetrics[]): TrendAnalysis {
        // Calculate moving averages
        const cpuTrend = this.calculateTrend(metrics.map(m => m.cpu.usage));
        const memoryTrend = this.calculateTrend(metrics.map(m => m.memory.percentage));
        const responseTimeTrend = this.calculateTrend(
            metrics.map(m => m.performance.avgResponseTime)
        );
        
        return {
            cpu: cpuTrend,
            memory: memoryTrend,
            responseTime: responseTimeTrend,
            direction: this.determineTrendDirection({
                cpu: cpuTrend,
                memory: memoryTrend,
                responseTime: responseTimeTrend
            })
        };
    }
    
    private async detectAnomalies(
        metrics: PerformanceMetrics[],
        options: AnalysisOptions
    ): Promise<Anomaly[]> {
        const anomalies: Anomaly[] = [];
        
        // Statistical anomaly detection
        const stats = this.calculateStatistics(metrics);
        
        for (let i = 0; i < metrics.length; i++) {
            const metric = metrics[i];
            
            // Check for statistical anomalies
            if (this.isStatisticalAnomaly(metric.cpu.usage, stats.cpu)) {
                anomalies.push({
                    type: 'cpu',
                    timestamp: metric.timestamp,
                    value: metric.cpu.usage,
                    severity: this.calculateAnomalySeverity(metric.cpu.usage, stats.cpu),
                    description: 'Abnormal CPU usage detected'
                });
            }
            
            if (this.isStatisticalAnomaly(
                metric.performance.avgResponseTime,
                stats.responseTime
            )) {
                anomalies.push({
                    type: 'responseTime',
                    timestamp: metric.timestamp,
                    value: metric.performance.avgResponseTime,
                    severity: this.calculateAnomalySeverity(
                        metric.performance.avgResponseTime,
                        stats.responseTime
                    ),
                    description: 'Abnormal response time detected'
                });
            }
        }
        
        // Machine learning based anomaly detection if enabled
        if (options.useMLDetection) {
            const mlAnomalies = await this.detectMLAnomalies(metrics);
            anomalies.push(...mlAnomalies);
        }
        
        return anomalies;
    }
}
'''
```

#### SubTask 3.18.2: 로그 수집 및 분석
**담당자**: 로그 분석 전문가  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/framework/log_analysis.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import re

@dataclass
class LogEntry:
    timestamp: datetime
    level: str
    agent_id: str
    message: str
    context: Dict[str, Any]
    trace_id: Optional[str] = None

class LogAnalysis:
    """Agent log collection and analysis"""
    
    def __init__(self):
        self.log_collector = LogCollector()
        self.log_parser = LogParser()
        self.pattern_analyzer = PatternAnalyzer()
    
    async def create_log_analysis_system(self) -> Dict[str, Any]:
        """Create log analysis system"""
        
        # Generate log collection
        collection_implementation = await self._generate_log_collection()
        
        # Generate log parsing
        parsing_implementation = await self._generate_log_parsing()
        
        # Generate pattern analysis
        pattern_implementation = await self._generate_pattern_analysis()
        
        # Generate log visualization
        visualization_implementation = await self._generate_log_visualization()
        
        return {
            'collection': collection_implementation,
            'parsing': parsing_implementation,
            'patterns': pattern_implementation,
            'visualization': visualization_implementation
        }
    
    async def _generate_log_collection(self) -> str:
        """Generate log collection implementation"""
        
        return '''
import winston from 'winston';
import { ElasticsearchTransport } from 'winston-elasticsearch';
import { CloudWatchLogs } from '@aws-sdk/client-cloudwatch-logs';

export interface LogEntry {
    timestamp: Date;
    level: string;
    agentId: string;
    message: string;
    context: Record<string, any>;
    traceId?: string;
    spanId?: string;
    correlationId?: string;
    metadata?: Record<string, any>;
}

export class LogCollector {
    private readonly logger: winston.Logger;
    private readonly cloudwatch: CloudWatchLogs;
    private readonly buffers = new Map<string, LogEntry[]>();
    private readonly flushInterval = 5000; // 5 seconds
    
    constructor(config: LogConfig) {
        this.cloudwatch = new CloudWatchLogs({ region: config.awsRegion });
        this.logger = this.createLogger(config);
        this.startBatchProcessor();
    }
    
    private createLogger(config: LogConfig): winston.Logger {
        const transports: winston.transport[] = [
            // Console transport for development
            new winston.transports.Console({
                format: winston.format.combine(
                    winston.format.timestamp(),
                    winston.format.colorize(),
                    winston.format.printf(info => 
                        `${info.timestamp} [${info.agentId}] ${info.level}: ${info.message}`
                    )
                )
            })
        ];
        
        // Elasticsearch transport for production
        if (config.elasticsearch) {
            transports.push(new ElasticsearchTransport({
                clientOpts: config.elasticsearch,
                index: 'agent-logs',
                level: 'info',
                transformer: (logData) => this.transformForElasticsearch(logData)
            }));
        }
        
        // File transport for backup
        transports.push(new winston.transports.File({
            filename: 'logs/agent-errors.log',
            level: 'error'
        }));
        
        transports.push(new winston.transports.File({
            filename: 'logs/agent-combined.log'
        }));
        
        return winston.createLogger({
            level: config.logLevel || 'info',
            format: winston.format.combine(
                winston.format.timestamp(),
                winston.format.errors({ stack: true }),
                winston.format.json()
            ),
            transports,
            defaultMeta: { service: 'agent-system' }
        });
    }
    
    log(entry: LogEntry): void {
        // Add to winston
        this.logger.log({
            level: entry.level,
            message: entry.message,
            ...entry.context,
            agentId: entry.agentId,
            timestamp: entry.timestamp,
            traceId: entry.traceId
        });
        
        // Buffer for CloudWatch
        this.bufferForCloudWatch(entry);
        
        // Real-time analysis for critical logs
        if (entry.level === 'error' || entry.level === 'critical') {
            this.analyzeErrorLog(entry);
        }
    }
    
    private bufferForCloudWatch(entry: LogEntry): void {
        const agentBuffer = this.buffers.get(entry.agentId) || [];
        agentBuffer.push(entry);
        this.buffers.set(entry.agentId, agentBuffer);
        
        // Flush if buffer is full
        if (agentBuffer.length >= 100) {
            this.flushLogs(entry.agentId);
        }
    }
    
    private async flushLogs(agentId: string): Promise<void> {
        const buffer = this.buffers.get(agentId);
        
        if (!buffer || buffer.length === 0) {
            return;
        }
        
        // Clear buffer
        this.buffers.set(agentId, []);
        
        try {
            // Send to CloudWatch
            await this.cloudwatch.putLogEvents({
                logGroupName: `/aws/agents/${agentId}`,
                logStreamName: new Date().toISOString().split('T')[0],
                logEvents: buffer.map(entry => ({
                    timestamp: entry.timestamp.getTime(),
                    message: JSON.stringify({
                        level: entry.level,
                        message: entry.message,
                        context: entry.context,
                        traceId: entry.traceId
                    })
                }))
            });
        } catch (error) {
            console.error('Failed to send logs to CloudWatch:', error);
            // Re-add to buffer for retry
            const currentBuffer = this.buffers.get(agentId) || [];
            this.buffers.set(agentId, [...buffer, ...currentBuffer]);
        }
    }
    
    private startBatchProcessor(): void {
        setInterval(() => {
            for (const [agentId] of this.buffers) {
                this.flushLogs(agentId);
            }
        }, this.flushInterval);
    }
    
    async queryLogs(query: LogQuery): Promise<LogQueryResult> {
        if (query.source === 'elasticsearch') {
            return this.queryElasticsearch(query);
        } else if (query.source === 'cloudwatch') {
            return this.queryCloudWatch(query);
        } else {
            return this.queryLocalLogs(query);
        }
    }
}

// Log Parser
export class LogParser {
    private patterns = new Map<string, RegExp>();
    
    constructor() {
        this.initializePatterns();
    }
    
    private initializePatterns(): void {
        // Common log patterns
        this.patterns.set('error', /ERROR|FAIL|EXCEPTION|CRITICAL/i);
        this.patterns.set('warning', /WARN|WARNING|CAUTION/i);
        this.patterns.set('performance', /SLOW|TIMEOUT|LATENCY|DELAY/i);
        this.patterns.set('security', /AUTH|UNAUTHORIZED|FORBIDDEN|DENIED/i);
        this.patterns.set('api', /API|REQUEST|RESPONSE|ENDPOINT/i);
        
        // Agent-specific patterns
        this.patterns.set('task_start', /Task (\\w+) started/);
        this.patterns.set('task_complete', /Task (\\w+) completed in (\\d+)ms/);
        this.patterns.set('task_failed', /Task (\\w+) failed: (.+)/);
    }
    
    parse(logEntry: string): ParsedLog {
        const basePattern = /^(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{3}Z) \\[(\\w+)\\] (\\w+): (.+)$/;
        const match = logEntry.match(basePattern);
        
        if (!match) {
            return {
                raw: logEntry,
                parsed: false
            };
        }
        
        const [, timestamp, agentId, level, message] = match;
        
        // Extract structured data
        const structuredData = this.extractStructuredData(message);
        
        // Identify patterns
        const matchedPatterns = this.identifyPatterns(message);
        
        return {
            timestamp: new Date(timestamp),
            agentId,
            level,
            message: this.cleanMessage(message),
            structuredData,
            patterns: matchedPatterns,
            parsed: true
        };
    }
    
    private extractStructuredData(message: string): Record<string, any> {
        const data: Record<string, any> = {};
        
        // Extract JSON
        const jsonMatch = message.match(/{.+}/);
        if (jsonMatch) {
            try {
                Object.assign(data, JSON.parse(jsonMatch[0]));
            } catch {}
        }
        
        // Extract key-value pairs
        const kvPattern = /(\\w+)=([^\\s]+)/g;
        let kvMatch;
        
        while ((kvMatch = kvPattern.exec(message)) !== null) {
            const [, key, value] = kvMatch;
            data[key] = this.parseValue(value);
        }
        
        // Extract metrics
        const metricPattern = /(\\w+):(\\d+(?:\\.\\d+)?)(\\w*)/g;
        let metricMatch;
        
        while ((metricMatch = metricPattern.exec(message)) !== null) {
            const [, metric, value, unit] = metricMatch;
            data[`metric_${metric}`] = {
                value: parseFloat(value),
                unit: unit || 'count'
            };
        }
        
        return data;
    }
}

// Pattern Analysis
export class LogPatternAnalyzer {
    async analyzePatterns(
        logs: LogEntry[],
        options: PatternAnalysisOptions
    ): Promise<PatternAnalysisResult> {
        // Group logs by pattern
        const patternGroups = this.groupByPattern(logs);
        
        // Identify frequent patterns
        const frequentPatterns = this.identifyFrequentPatterns(
            patternGroups,
            options.minSupport || 0.01
        );
        
        // Detect anomalous patterns
        const anomalousPatterns = await this.detectAnomalousPatterns(
            patternGroups,
            options
        );
        
        // Extract error patterns
        const errorPatterns = this.extractErrorPatterns(logs);
        
        // Identify correlated patterns
        const correlations = this.findPatternCorrelations(patternGroups);
        
        // Generate insights
        const insights = this.generateInsights({
            frequentPatterns,
            anomalousPatterns,
            errorPatterns,
            correlations
        });
        
        return {
            patterns: frequentPatterns,
            anomalies: anomalousPatterns,
            errors: errorPatterns,
            correlations,
            insights,
            summary: this.generateSummary(patternGroups)
        };
    }
    
    private groupByPattern(logs: LogEntry[]): Map<string, LogEntry[]> {
        const groups = new Map<string, LogEntry[]>();
        
        for (const log of logs) {
            const pattern = this.extractPattern(log.message);
            
            if (!groups.has(pattern)) {
                groups.set(pattern, []);
            }
            
            groups.get(pattern)!.push(log);
        }
        
        return groups;
    }
    
    private extractPattern(message: string): string {
        // Remove timestamps
        let pattern = message.replace(
            /\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{3}Z/g,
            '<TIMESTAMP>'
        );
        
        // Remove UUIDs
        pattern = pattern.replace(
            /[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}/gi,
            '<UUID>'
        );
        
        // Remove numbers
        pattern = pattern.replace(/\\b\\d+\\b/g, '<NUM>');
        
        // Remove quoted strings
        pattern = pattern.replace(/"[^"]*"/g, '<STRING>');
        pattern = pattern.replace(/'[^']*'/g, '<STRING>');
        
        // Remove IPs
        pattern = pattern.replace(
            /\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b/g,
            '<IP>'
        );
        
        return pattern;
    }
}
'''
```

#### SubTask 3.18.3: 메트릭 대시보드
**담당자**: 시각화 전문가  
**예상 소요시간**: 12시간

**작업 내용**:
```python
# backend/src/agents/framework/metrics_dashboard.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class DashboardWidget:
    type: str
    title: str
    metrics: List[str]
    visualization: str
