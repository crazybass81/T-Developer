# Phase 2: ë°ì´í„° ë ˆì´ì–´ êµ¬í˜„ - ì „ì²´ SubTask ì‘ì—…ì§€ì‹œ ë¬¸ì„œ

## ğŸ“‹ Phase 2 ê°œìš”
- **ëª©í‘œ**: T-Developerì˜ ë°ì´í„° ì €ì¥, ê²€ìƒ‰, ìºì‹±, ë™ê¸°í™”ë¥¼ ìœ„í•œ í¬ê´„ì ì¸ ë°ì´í„° ë ˆì´ì–´ êµ¬ì¶•
- **ë²”ìœ„**: 15ê°œ Tasks Ã— 4 SubTasks = 60ê°œ ì‘ì—… ë‹¨ìœ„
- **ê¸°ê°„**: ì˜ˆìƒ 6-8ì£¼
- **ì „ì œì¡°ê±´**: Phase 1 ì½”ì–´ ì¸í”„ë¼ ì™„ë£Œ

---

## ğŸ—ï¸ Phase 2 ì „ì²´ Task êµ¬ì¡°

### ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë° êµ¬í˜„ (Tasks 2.1-2.3)
- Task 2.1: DynamoDB í…Œì´ë¸” ì„¤ê³„ ë° êµ¬í˜„
- Task 2.2: ì¸ë±ì‹± ì „ëµ ë° ì¿¼ë¦¬ ìµœì í™”
- Task 2.3: ë°ì´í„° íŒŒí‹°ì…”ë‹ ë° ìƒ¤ë”© ì „ëµ

### ë°ì´í„° ëª¨ë¸ë§ (Tasks 2.4-2.6)
- Task 2.4: ë„ë©”ì¸ ëª¨ë¸ ì •ì˜
- Task 2.5: ë°ì´í„° ê²€ì¦ ë° ìŠ¤í‚¤ë§ˆ ê´€ë¦¬
- Task 2.6: ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ

### ìºì‹± ë ˆì´ì–´ (Tasks 2.7-2.9)
- Task 2.7: Redis ìºì‹± ì‹œìŠ¤í…œ êµ¬ì¶•
- Task 2.8: ìºì‹œ ë¬´íš¨í™” ì „ëµ
- Task 2.9: ë¶„ì‚° ìºì‹± ë° ë™ê¸°í™”

### ë°ì´í„° ì ‘ê·¼ ë ˆì´ì–´ (Tasks 2.10-2.12)
- Task 2.10: Repository íŒ¨í„´ êµ¬í˜„
- Task 2.11: ë°ì´í„° ì ‘ê·¼ ì¶”ìƒí™”
- Task 2.12: íŠ¸ëœì­ì…˜ ê´€ë¦¬

### ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ (Tasks 2.13-2.15)
- Task 2.13: ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ
- Task 2.14: ë³€ê²½ ë°ì´í„° ìº¡ì²˜ (CDC)
- Task 2.15: ë°ì´í„° ë™ê¸°í™” ë©”ì»¤ë‹ˆì¦˜

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 2.1: DynamoDB í…Œì´ë¸” ì„¤ê³„ ë° êµ¬í˜„

#### SubTask 2.1.1: ë‹¨ì¼ í…Œì´ë¸” ì„¤ê³„ (Single Table Design)
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/schemas/single-table-design.ts
export interface TableDesign {
  tableName: string;
  partitionKey: AttributeDefinition;
  sortKey?: AttributeDefinition;
  globalSecondaryIndexes: GSI[];
  localSecondaryIndexes?: LSI[];
  attributes: AttributeDefinition[];
}

export const T_DEVELOPER_TABLE: TableDesign = {
  tableName: 'T-Developer-Main',
  partitionKey: {
    name: 'PK',
    type: 'S',
    description: 'Partition Key - Format: {EntityType}#{EntityId}'
  },
  sortKey: {
    name: 'SK',
    type: 'S', 
    description: 'Sort Key - Format: {RelationType}#{Timestamp}#{Id}'
  },
  globalSecondaryIndexes: [
    {
      indexName: 'GSI1',
      partitionKey: { name: 'GSI1PK', type: 'S' },
      sortKey: { name: 'GSI1SK', type: 'S' },
      projection: 'ALL',
      purpose: 'Query by User/Project relationships'
    },
    {
      indexName: 'GSI2',
      partitionKey: { name: 'GSI2PK', type: 'S' },
      sortKey: { name: 'GSI2SK', type: 'S' },
      projection: 'ALL',
      purpose: 'Query by Agent/Task relationships'
    },
    {
      indexName: 'GSI3',
      partitionKey: { name: 'GSI3PK', type: 'S' },
      sortKey: { name: 'CreatedAt', type: 'S' },
      projection: 'ALL',
      purpose: 'Time-based queries'
    }
  ],
  attributes: [
    { name: 'EntityType', type: 'S', required: true },
    { name: 'EntityId', type: 'S', required: true },
    { name: 'Status', type: 'S', required: true },
    { name: 'CreatedAt', type: 'S', required: true },
    { name: 'UpdatedAt', type: 'S', required: true },
    { name: 'TTL', type: 'N', required: false }
  ]
};

// Access Patterns ì •ì˜
export const ACCESS_PATTERNS = {
  // User ê´€ë ¨
  getUserById: {
    index: 'Primary',
    PK: 'USER#{userId}',
    SK: 'METADATA'
  },
  getUserProjects: {
    index: 'Primary',
    PK: 'USER#{userId}',
    SK: 'PROJECT#'
  },
  
  // Project ê´€ë ¨
  getProjectById: {
    index: 'Primary',
    PK: 'PROJECT#{projectId}',
    SK: 'METADATA'
  },
  getProjectAgents: {
    index: 'Primary',
    PK: 'PROJECT#{projectId}',
    SK: 'AGENT#'
  },
  
  // Agent ê´€ë ¨
  getAgentTasks: {
    index: 'GSI2',
    GSI2PK: 'AGENT#{agentId}',
    GSI2SK: 'TASK#'
  },
  getAgentsByProject: {
    index: 'GSI1',
    GSI1PK: 'PROJECT#{projectId}',
    GSI1SK: 'AGENT#'
  }
};
```

#### SubTask 2.1.2: í…Œì´ë¸” ìƒì„± ìë™í™” ìŠ¤í¬ë¦½íŠ¸
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/scripts/create-tables.ts
import { DynamoDBClient, CreateTableCommand } from '@aws-sdk/client-dynamodb';
import { T_DEVELOPER_TABLE } from '../schemas/single-table-design';

export class TableCreator {
  private dynamoDB: DynamoDBClient;
  
  constructor(region: string = process.env.AWS_REGION || 'us-east-1') {
    this.dynamoDB = new DynamoDBClient({ region });
  }
  
  async createMainTable(): Promise<void> {
    const params = {
      TableName: T_DEVELOPER_TABLE.tableName,
      KeySchema: [
        { AttributeName: 'PK', KeyType: 'HASH' },
        { AttributeName: 'SK', KeyType: 'RANGE' }
      ],
      AttributeDefinitions: [
        { AttributeName: 'PK', AttributeType: 'S' },
        { AttributeName: 'SK', AttributeType: 'S' },
        { AttributeName: 'GSI1PK', AttributeType: 'S' },
        { AttributeName: 'GSI1SK', AttributeType: 'S' },
        { AttributeName: 'GSI2PK', AttributeType: 'S' },
        { AttributeName: 'GSI2SK', AttributeType: 'S' },
        { AttributeName: 'GSI3PK', AttributeType: 'S' },
        { AttributeName: 'CreatedAt', AttributeType: 'S' }
      ],
      GlobalSecondaryIndexes: T_DEVELOPER_TABLE.globalSecondaryIndexes.map(gsi => ({
        IndexName: gsi.indexName,
        KeySchema: [
          { AttributeName: gsi.partitionKey.name, KeyType: 'HASH' },
          { AttributeName: gsi.sortKey!.name, KeyType: 'RANGE' }
        ],
        Projection: { ProjectionType: gsi.projection },
        ProvisionedThroughput: {
          ReadCapacityUnits: 5,
          WriteCapacityUnits: 5
        }
      })),
      BillingMode: 'PAY_PER_REQUEST',
      StreamSpecification: {
        StreamEnabled: true,
        StreamViewType: 'NEW_AND_OLD_IMAGES'
      },
      Tags: [
        { Key: 'Project', Value: 'T-Developer' },
        { Key: 'Environment', Value: process.env.NODE_ENV || 'development' }
      ]
    };
    
    try {
      await this.dynamoDB.send(new CreateTableCommand(params));
      console.log(`âœ… Table ${T_DEVELOPER_TABLE.tableName} created successfully`);
      
      // í…Œì´ë¸”ì´ ACTIVE ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸°
      await this.waitForTableActive(T_DEVELOPER_TABLE.tableName);
      
    } catch (error) {
      if (error.name === 'ResourceInUseException') {
        console.log(`â„¹ï¸ Table ${T_DEVELOPER_TABLE.tableName} already exists`);
      } else {
        throw error;
      }
    }
  }
  
  private async waitForTableActive(tableName: string): Promise<void> {
    // í…Œì´ë¸” ìƒíƒœ í™•ì¸ ë¡œì§
    let isActive = false;
    let attempts = 0;
    
    while (!isActive && attempts < 30) {
      const status = await this.getTableStatus(tableName);
      if (status === 'ACTIVE') {
        isActive = true;
      } else {
        await new Promise(resolve => setTimeout(resolve, 2000));
        attempts++;
      }
    }
  }
}

// ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
if (require.main === module) {
  const creator = new TableCreator();
  creator.createMainTable()
    .then(() => console.log('âœ… All tables created successfully'))
    .catch(console.error);
}
```

#### SubTask 2.1.3: ë°ì´í„° ëª¨ë¸ ì—”í‹°í‹° ì •ì˜
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/entities/base.entity.ts
export abstract class BaseEntity {
  PK: string;
  SK: string;
  EntityType: string;
  EntityId: string;
  CreatedAt: string;
  UpdatedAt: string;
  Version: number;
  
  constructor() {
    this.CreatedAt = new Date().toISOString();
    this.UpdatedAt = new Date().toISOString();
    this.Version = 1;
  }
  
  abstract toDynamoDBItem(): Record<string, any>;
  abstract fromDynamoDBItem(item: Record<string, any>): void;
}

// backend/src/data/entities/user.entity.ts
export class UserEntity extends BaseEntity {
  UserId: string;
  Email: string;
  Username: string;
  Role: 'admin' | 'developer' | 'viewer';
  Preferences: UserPreferences;
  LastLoginAt?: string;
  
  constructor(userId: string) {
    super();
    this.EntityType = 'USER';
    this.EntityId = userId;
    this.UserId = userId;
    this.PK = `USER#${userId}`;
    this.SK = 'METADATA';
  }
  
  toDynamoDBItem(): Record<string, any> {
    return {
      PK: this.PK,
      SK: this.SK,
      EntityType: this.EntityType,
      EntityId: this.EntityId,
      UserId: this.UserId,
      Email: this.Email,
      Username: this.Username,
      Role: this.Role,
      Preferences: this.Preferences,
      LastLoginAt: this.LastLoginAt,
      CreatedAt: this.CreatedAt,
      UpdatedAt: this.UpdatedAt,
      Version: this.Version,
      GSI1PK: `EMAIL#${this.Email}`,
      GSI1SK: this.UserId
    };
  }
  
  fromDynamoDBItem(item: Record<string, any>): void {
    Object.assign(this, item);
  }
}

// backend/src/data/entities/project.entity.ts
export class ProjectEntity extends BaseEntity {
  ProjectId: string;
  ProjectName: string;
  Description: string;
  OwnerId: string;
  Status: 'active' | 'archived' | 'deleted';
  Settings: ProjectSettings;
  Metadata: Record<string, any>;
  
  constructor(projectId: string, ownerId: string) {
    super();
    this.EntityType = 'PROJECT';
    this.EntityId = projectId;
    this.ProjectId = projectId;
    this.OwnerId = ownerId;
    this.PK = `PROJECT#${projectId}`;
    this.SK = 'METADATA';
  }
  
  toDynamoDBItem(): Record<string, any> {
    return {
      PK: this.PK,
      SK: this.SK,
      EntityType: this.EntityType,
      EntityId: this.EntityId,
      ProjectId: this.ProjectId,
      ProjectName: this.ProjectName,
      Description: this.Description,
      OwnerId: this.OwnerId,
      Status: this.Status,
      Settings: this.Settings,
      Metadata: this.Metadata,
      CreatedAt: this.CreatedAt,
      UpdatedAt: this.UpdatedAt,
      Version: this.Version,
      GSI1PK: `USER#${this.OwnerId}`,
      GSI1SK: `PROJECT#${this.CreatedAt}#${this.ProjectId}`,
      GSI3PK: `PROJECTS#${this.Status}`,
      GSI3SK: this.CreatedAt
    };
  }
}

// backend/src/data/entities/agent.entity.ts
export class AgentEntity extends BaseEntity {
  AgentId: string;
  AgentType: string;
  ProjectId: string;
  Name: string;
  Status: 'idle' | 'running' | 'completed' | 'failed';
  Configuration: AgentConfiguration;
  LastExecutionAt?: string;
  Metrics: AgentMetrics;
  
  constructor(agentId: string, projectId: string, agentType: string) {
    super();
    this.EntityType = 'AGENT';
    this.EntityId = agentId;
    this.AgentId = agentId;
    this.ProjectId = projectId;
    this.AgentType = agentType;
    this.PK = `PROJECT#${projectId}`;
    this.SK = `AGENT#${agentId}`;
  }
  
  toDynamoDBItem(): Record<string, any> {
    return {
      PK: this.PK,
      SK: this.SK,
      EntityType: this.EntityType,
      EntityId: this.EntityId,
      AgentId: this.AgentId,
      AgentType: this.AgentType,
      ProjectId: this.ProjectId,
      Name: this.Name,
      Status: this.Status,
      Configuration: this.Configuration,
      LastExecutionAt: this.LastExecutionAt,
      Metrics: this.Metrics,
      CreatedAt: this.CreatedAt,
      UpdatedAt: this.UpdatedAt,
      Version: this.Version,
      GSI2PK: `AGENT#${this.AgentId}`,
      GSI2SK: `STATUS#${this.Status}`,
      GSI3PK: `AGENTS#${this.AgentType}`,
      GSI3SK: this.CreatedAt
    };
  }
}
```

#### SubTask 2.1.4: ë°°ì¹˜ ì‘ì—… ë° íŠ¸ëœì­ì…˜ ì§€ì›
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/services/batch-operations.ts
import { 
  DynamoDBDocumentClient, 
  TransactWriteCommand,
  BatchWriteCommand,
  BatchGetCommand 
} from '@aws-sdk/lib-dynamodb';

export class BatchOperationService {
  constructor(private docClient: DynamoDBDocumentClient) {}
  
  // íŠ¸ëœì­ì…˜ ì“°ê¸°
  async transactWrite(operations: TransactOperation[]): Promise<void> {
    const transactItems = operations.map(op => {
      switch (op.type) {
        case 'Put':
          return { Put: { TableName: op.tableName, Item: op.item } };
        case 'Update':
          return { 
            Update: { 
              TableName: op.tableName,
              Key: op.key,
              UpdateExpression: op.updateExpression,
              ExpressionAttributeValues: op.expressionAttributeValues 
            } 
          };
        case 'Delete':
          return { Delete: { TableName: op.tableName, Key: op.key } };
        default:
          throw new Error(`Unknown operation type: ${op.type}`);
      }
    });
    
    try {
      await this.docClient.send(new TransactWriteCommand({
        TransactItems: transactItems
      }));
    } catch (error) {
      if (error.name === 'TransactionCanceledException') {
        // íŠ¸ëœì­ì…˜ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
        const reasons = error.CancellationReasons || [];
        throw new TransactionFailedError('Transaction failed', reasons);
      }
      throw error;
    }
  }
  
  // ë°°ì¹˜ ì“°ê¸° (ìµœëŒ€ 25ê°œ í•­ëª©)
  async batchWrite(
    tableName: string, 
    items: any[], 
    deleteKeys?: any[]
  ): Promise<void> {
    const chunks = this.chunkArray([...items, ...(deleteKeys || [])], 25);
    
    for (const chunk of chunks) {
      const requests = chunk.map(item => {
        if (deleteKeys?.includes(item)) {
          return { DeleteRequest: { Key: item } };
        }
        return { PutRequest: { Item: item } };
      });
      
      await this.executeBatchWrite(tableName, requests);
    }
  }
  
  private async executeBatchWrite(
    tableName: string, 
    requests: any[]
  ): Promise<void> {
    let unprocessedItems = requests;
    let retryCount = 0;
    
    while (unprocessedItems.length > 0 && retryCount < 5) {
      const result = await this.docClient.send(new BatchWriteCommand({
        RequestItems: { [tableName]: unprocessedItems }
      }));
      
      if (result.UnprocessedItems?.[tableName]) {
        unprocessedItems = result.UnprocessedItems[tableName];
        retryCount++;
        // Exponential backoff
        await new Promise(resolve => 
          setTimeout(resolve, Math.pow(2, retryCount) * 100)
        );
      } else {
        unprocessedItems = [];
      }
    }
    
    if (unprocessedItems.length > 0) {
      throw new Error(`Failed to process ${unprocessedItems.length} items after retries`);
    }
  }
  
  // ë°°ì¹˜ ì½ê¸°
  async batchGet(
    tableName: string, 
    keys: any[], 
    projectionExpression?: string
  ): Promise<any[]> {
    const chunks = this.chunkArray(keys, 100);
    const results: any[] = [];
    
    for (const chunk of chunks) {
      const response = await this.docClient.send(new BatchGetCommand({
        RequestItems: {
          [tableName]: {
            Keys: chunk,
            ProjectionExpression: projectionExpression
          }
        }
      }));
      
      if (response.Responses?.[tableName]) {
        results.push(...response.Responses[tableName]);
      }
    }
    
    return results;
  }
  
  private chunkArray<T>(array: T[], size: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
}

// ì‚¬ìš© ì˜ˆì‹œ
export class ProjectService {
  constructor(
    private batchOps: BatchOperationService,
    private tableName: string
  ) {}
  
  async createProjectWithAgents(
    project: ProjectEntity,
    agents: AgentEntity[]
  ): Promise<void> {
    const operations: TransactOperation[] = [
      {
        type: 'Put',
        tableName: this.tableName,
        item: project.toDynamoDBItem()
      },
      ...agents.map(agent => ({
        type: 'Put' as const,
        tableName: this.tableName,
        item: agent.toDynamoDBItem()
      }))
    ];
    
    await this.batchOps.transactWrite(operations);
  }
}
```

---

### Task 2.2: ì¸ë±ì‹± ì „ëµ ë° ì¿¼ë¦¬ ìµœì í™”

#### SubTask 2.2.1: ë³µí•© ì¿¼ë¦¬ íŒ¨í„´ êµ¬í˜„
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/queries/query-builder.ts
export class DynamoQueryBuilder {
  private params: any = {
    TableName: '',
    KeyConditionExpression: '',
    ExpressionAttributeNames: {},
    ExpressionAttributeValues: {}
  };
  
  constructor(tableName: string) {
    this.params.TableName = tableName;
  }
  
  // íŒŒí‹°ì…˜ í‚¤ ì¡°ê±´
  wherePartitionKey(key: string, value: string): this {
    this.params.KeyConditionExpression = '#pk = :pk';
    this.params.ExpressionAttributeNames['#pk'] = key;
    this.params.ExpressionAttributeValues[':pk'] = value;
    return this;
  }
  
  // ì†ŒíŠ¸ í‚¤ ì¡°ê±´
  andSortKey(key: string, operator: string, value: string | string[]): this {
    const skCondition = this.buildSortKeyCondition(key, operator, value);
    this.params.KeyConditionExpression += ` AND ${skCondition}`;
    return this;
  }
  
  private buildSortKeyCondition(
    key: string, 
    operator: string, 
    value: string | string[]
  ): string {
    this.params.ExpressionAttributeNames['#sk'] = key;
    
    switch (operator) {
      case '=':
        this.params.ExpressionAttributeValues[':sk'] = value;
        return '#sk = :sk';
        
      case 'begins_with':
        this.params.ExpressionAttributeValues[':sk'] = value;
        return 'begins_with(#sk, :sk)';
        
      case 'between':
        if (!Array.isArray(value) || value.length !== 2) {
          throw new Error('Between operator requires array of 2 values');
        }
        this.params.ExpressionAttributeValues[':sk1'] = value[0];
        this.params.ExpressionAttributeValues[':sk2'] = value[1];
        return '#sk BETWEEN :sk1 AND :sk2';
        
      case '>':
        this.params.ExpressionAttributeValues[':sk'] = value;
        return '#sk > :sk';
        
      case '<':
        this.params.ExpressionAttributeValues[':sk'] = value;
        return '#sk < :sk';
        
      default:
        throw new Error(`Unsupported operator: ${operator}`);
    }
  }
  
  // í•„í„° í‘œí˜„ì‹
  filter(expression: string, values: Record<string, any>): this {
    this.params.FilterExpression = expression;
    Object.assign(this.params.ExpressionAttributeValues, values);
    return this;
  }
  
  // GSI ì‚¬ìš©
  useIndex(indexName: string): this {
    this.params.IndexName = indexName;
    return this;
  }
  
  // í˜ì´ì§€ë„¤ì´ì…˜
  limit(count: number): this {
    this.params.Limit = count;
    return this;
  }
  
  startFrom(lastEvaluatedKey: any): this {
    if (lastEvaluatedKey) {
      this.params.ExclusiveStartKey = lastEvaluatedKey;
    }
    return this;
  }
  
  // ì •ë ¬
  scanForward(forward: boolean = true): this {
    this.params.ScanIndexForward = forward;
    return this;
  }
  
  // í”„ë¡œì ì…˜
  select(attributes: string[]): this {
    this.params.ProjectionExpression = attributes.join(', ');
    return this;
  }
  
  build(): any {
    return this.params;
  }
}

// ì¿¼ë¦¬ ì‹¤í–‰ ì„œë¹„ìŠ¤
export class QueryExecutor {
  constructor(private docClient: DynamoDBDocumentClient) {}
  
  async query<T>(params: any): Promise<QueryResult<T>> {
    const result = await this.docClient.send(new QueryCommand(params));
    
    return {
      items: (result.Items || []) as T[],
      lastEvaluatedKey: result.LastEvaluatedKey,
      count: result.Count || 0,
      scannedCount: result.ScannedCount || 0
    };
  }
  
  async queryAll<T>(params: any): Promise<T[]> {
    const items: T[] = [];
    let lastEvaluatedKey: any;
    
    do {
      if (lastEvaluatedKey) {
        params.ExclusiveStartKey = lastEvaluatedKey;
      }
      
      const result = await this.query<T>(params);
      items.push(...result.items);
      lastEvaluatedKey = result.lastEvaluatedKey;
      
    } while (lastEvaluatedKey);
    
    return items;
  }
  
  // ë³‘ë ¬ ì¿¼ë¦¬ ì‹¤í–‰
  async parallelQuery<T>(
    queries: any[]
  ): Promise<T[]> {
    const results = await Promise.all(
      queries.map(query => this.queryAll<T>(query))
    );
    
    return results.flat();
  }
}

// ì‚¬ìš© ì˜ˆì‹œ
export class ProjectQueryService {
  constructor(
    private queryExecutor: QueryExecutor,
    private tableName: string
  ) {}
  
  async getProjectsByUser(
    userId: string, 
    status?: string
  ): Promise<ProjectEntity[]> {
    const query = new DynamoQueryBuilder(this.tableName)
      .useIndex('GSI1')
      .wherePartitionKey('GSI1PK', `USER#${userId}`)
      .andSortKey('GSI1SK', 'begins_with', 'PROJECT#')
      .scanForward(false); // ìµœì‹ ìˆœ
    
    if (status) {
      query.filter('#status = :status', { ':status': status });
    }
    
    const params = query.build();
    return this.queryExecutor.queryAll<ProjectEntity>(params);
  }
}
```

#### SubTask 2.2.2: ì¿¼ë¦¬ ì„±ëŠ¥ ìµœì í™”
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/optimization/query-optimizer.ts
export class QueryOptimizer {
  private queryMetrics: Map<string, QueryMetrics> = new Map();
  
  // ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„
  async analyzeQueryPlan(
    query: any
  ): Promise<QueryAnalysis> {
    const analysis: QueryAnalysis = {
      estimatedRCU: this.estimateReadCapacityUnits(query),
      indexEfficiency: this.calculateIndexEfficiency(query),
      projectionEfficiency: this.calculateProjectionEfficiency(query),
      recommendations: []
    };
    
    // ê¶Œì¥ì‚¬í•­ ìƒì„±
    if (analysis.indexEfficiency < 0.8) {
      analysis.recommendations.push({
        type: 'INDEX',
        message: 'Consider using a more selective index',
        impact: 'HIGH'
      });
    }
    
    if (!query.ProjectionExpression) {
      analysis.recommendations.push({
        type: 'PROJECTION',
        message: 'Add ProjectionExpression to reduce data transfer',
        impact: 'MEDIUM'
      });
    }
    
    return analysis;
  }
  
  // ì ì‘í˜• ì¿¼ë¦¬ ìµœì í™”
  async optimizeQuery(
    originalQuery: any,
    historicalMetrics?: QueryMetrics[]
  ): Promise<any> {
    const optimized = { ...originalQuery };
    
    // 1. ìë™ í”„ë¡œì ì…˜ ì¶”ê°€
    if (!optimized.ProjectionExpression && historicalMetrics) {
      const usedAttributes = this.analyzeAttributeUsage(historicalMetrics);
      if (usedAttributes.length > 0) {
        optimized.ProjectionExpression = usedAttributes.join(', ');
      }
    }
    
    // 2. í˜ì´ì§€ í¬ê¸° ìµœì í™”
    if (!optimized.Limit) {
      optimized.Limit = this.calculateOptimalPageSize(historicalMetrics);
    }
    
    // 3. ì¸ë±ìŠ¤ ì„ íƒ ìµœì í™”
    const betterIndex = this.suggestBetterIndex(originalQuery, historicalMetrics);
    if (betterIndex) {
      optimized.IndexName = betterIndex;
    }
    
    return optimized;
  }
  
  // ì¿¼ë¦¬ ìºì‹± ì „ëµ
  getCacheKey(query: any): string {
    const normalized = {
      table: query.TableName,
      index: query.IndexName || 'primary',
      pk: query.ExpressionAttributeValues[':pk'],
      sk: query.ExpressionAttributeValues[':sk'] || '',
      filter: query.FilterExpression || ''
    };
    
    return crypto
      .createHash('sha256')
      .update(JSON.stringify(normalized))
      .digest('hex');
  }
  
  shouldCache(query: any, result: QueryResult<any>): boolean {
    // ìºì‹± ê¸°ì¤€
    const criteria = {
      minItems: 10,
      maxItems: 1000,
      minExecutionTime: 100, // ms
      frequencyThreshold: 5
    };
    
    const metrics = this.queryMetrics.get(this.getCacheKey(query));
    
    return (
      result.items.length >= criteria.minItems &&
      result.items.length <= criteria.maxItems &&
      metrics?.averageExecutionTime >= criteria.minExecutionTime &&
      metrics?.frequency >= criteria.frequencyThreshold
    );
  }
}

// ì¿¼ë¦¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
export class QueryPerformanceMonitor {
  private metrics: Map<string, QueryMetrics> = new Map();
  
  async trackQuery(
    queryKey: string,
    executionTime: number,
    itemCount: number,
    consumedRCU?: number
  ): Promise<void> {
    const existing = this.metrics.get(queryKey) || {
      queryKey,
      executionCount: 0,
      totalExecutionTime: 0,
      averageExecutionTime: 0,
      totalItemsReturned: 0,
      totalRCUConsumed: 0,
      lastExecuted: new Date()
    };
    
    existing.executionCount++;
    existing.totalExecutionTime += executionTime;
    existing.averageExecutionTime = 
      existing.totalExecutionTime / existing.executionCount;
    existing.totalItemsReturned += itemCount;
    existing.totalRCUConsumed += consumedRCU || 0;
    existing.lastExecuted = new Date();
    
    this.metrics.set(queryKey, existing);
    
    // ì„±ëŠ¥ ì €í•˜ ê°ì§€
    if (existing.averageExecutionTime > 1000) {
      await this.alertSlowQuery(queryKey, existing);
    }
  }
  
  async generatePerformanceReport(): Promise<PerformanceReport> {
    const sortedQueries = Array.from(this.metrics.values())
      .sort((a, b) => b.totalExecutionTime - a.totalExecutionTime);
    
    return {
      totalQueries: this.metrics.size,
      slowestQueries: sortedQueries.slice(0, 10),
      mostFrequentQueries: sortedQueries
        .sort((a, b) => b.executionCount - a.executionCount)
        .slice(0, 10),
      totalRCUConsumed: sortedQueries
        .reduce((sum, m) => sum + m.totalRCUConsumed, 0),
      recommendations: this.generateOptimizationRecommendations(sortedQueries)
    };
  }
}
```

#### SubTask 2.2.3: ì¸ë±ìŠ¤ ê´€ë¦¬ ìë™í™”
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/management/index-manager.ts
export class IndexManager {
  constructor(
    private dynamoDB: DynamoDBClient,
    private cloudWatch: CloudWatchClient
  ) {}
  
  // GSI ì‚¬ìš©ë¥  ë¶„ì„
  async analyzeIndexUsage(
    tableName: string,
    period: number = 7 // days
  ): Promise<IndexUsageReport> {
    const indexes = await this.listTableIndexes(tableName);
    const usage: IndexUsageMetrics[] = [];
    
    for (const index of indexes) {
      const metrics = await this.getIndexMetrics(
        tableName,
        index.IndexName,
        period
      );
      
      usage.push({
        indexName: index.IndexName,
        readUtilization: metrics.readUtilization,
        writeUtilization: metrics.writeUtilization,
        itemCount: metrics.itemCount,
        sizeBytes: metrics.sizeBytes,
        costEstimate: this.estimateIndexCost(metrics)
      });
    }
    
    return {
      tableName,
      period,
      indexes: usage,
      recommendations: this.generateIndexRecommendations(usage)
    };
  }
  
  // ì¸ë±ìŠ¤ ìë™ ìŠ¤ì¼€ì¼ë§
  async configureAutoScaling(
    tableName: string,
    indexName: string,
    config: AutoScalingConfig
  ): Promise<void> {
    const scalingClient = new ApplicationAutoScalingClient({});
    
    // ì½ê¸° ìš©ëŸ‰ ìë™ ìŠ¤ì¼€ì¼ë§
    await scalingClient.send(new PutScalingPolicyCommand({
      ServiceNamespace: 'dynamodb',
      ResourceId: `table/${tableName}/index/${indexName}`,
      ScalableDimension: 'dynamodb:index:ReadCapacityUnits',
      PolicyName: `${indexName}-read-scaling`,
      PolicyType: 'TargetTrackingScaling',
      TargetTrackingScalingPolicyConfiguration: {
        TargetValue: config.targetReadUtilization,
        PredefinedMetricSpecification: {
          PredefinedMetricType: 'DynamoDBReadCapacityUtilization'
        },
        ScaleInCooldown: config.scaleInCooldown || 60,
        ScaleOutCooldown: config.scaleOutCooldown || 60
      }
    }));
    
    // ì“°ê¸° ìš©ëŸ‰ ìë™ ìŠ¤ì¼€ì¼ë§
    await scalingClient.send(new PutScalingPolicyCommand({
      ServiceNamespace: 'dynamodb',
      ResourceId: `table/${tableName}/index/${indexName}`,
      ScalableDimension: 'dynamodb:index:WriteCapacityUnits',
      PolicyName: `${indexName}-write-scaling`,
      PolicyType: 'TargetTrackingScaling',
      TargetTrackingScalingPolicyConfiguration: {
        TargetValue: config.targetWriteUtilization,
        PredefinedMetricSpecification: {
          PredefinedMetricType: 'DynamoDBWriteCapacityUtilization'
        }
      }
    }));
  }
  
  // ë¯¸ì‚¬ìš© ì¸ë±ìŠ¤ ê°ì§€
  async detectUnusedIndexes(
    tableName: string,
    threshold: number = 30 // days
  ): Promise<UnusedIndex[]> {
    const unusedIndexes: UnusedIndex[] = [];
    const indexes = await this.listTableIndexes(tableName);
    
    for (const index of indexes) {
      const lastUsed = await this.getLastIndexUsageTime(
        tableName,
        index.IndexName
      );
      
      if (!lastUsed || 
          (Date.now() - lastUsed.getTime()) > threshold * 24 * 60 * 60 * 1000) {
        unusedIndexes.push({
          indexName: index.IndexName,
          lastUsed,
          estimatedMonthlyCost: await this.estimateIndexMonthlyCost(
            tableName,
            index.IndexName
          ),
          recommendation: 'Consider removing this unused index'
        });
      }
    }
    
    return unusedIndexes;
  }
  
  // ì¸ë±ìŠ¤ ì¬êµ¬ì„± ì œì•ˆ
  async suggestIndexReorganization(
    tableName: string,
    queryPatterns: QueryPattern[]
  ): Promise<IndexReorganizationPlan> {
    const currentIndexes = await this.listTableIndexes(tableName);
    const analysis = this.analyzeQueryPatterns(queryPatterns);
    
    const suggestions: IndexSuggestion[] = [];
    
    // ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ì œì•ˆ
    for (const pattern of analysis.uncoveredPatterns) {
      suggestions.push({
        type: 'CREATE',
        indexName: this.generateIndexName(pattern),
        keys: pattern.keys,
        projection: pattern.projection,
        estimatedImprovement: pattern.estimatedImprovement,
        reason: `Cover query pattern: ${pattern.description}`
      });
    }
    
    // ì¸ë±ìŠ¤ ë³‘í•© ì œì•ˆ
    const mergeCandidates = this.findMergeCandidates(currentIndexes);
    for (const candidate of mergeCandidates) {
      suggestions.push({
        type: 'MERGE',
        indexes: candidate.indexes,
        newIndex: candidate.mergedIndex,
        reason: 'Reduce index overhead by merging similar indexes'
      });
    }
    
    return {
      tableName,
      currentIndexCount: currentIndexes.length,
      suggestions,
      estimatedCostSavings: this.calculateCostSavings(suggestions),
      implementationSteps: this.generateImplementationSteps(suggestions)
    };
  }
}
```

#### SubTask 2.2.4: ì¿¼ë¦¬ íŒ¨í„´ í•™ìŠµ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ML ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/ml/query-pattern-learner.ts
export class QueryPatternLearner {
  private patterns: Map<string, QueryPattern> = new Map();
  private model: QueryPredictionModel;
  
  constructor() {
    this.model = new QueryPredictionModel();
  }
  
  // ì¿¼ë¦¬ íŒ¨í„´ í•™ìŠµ
  async learnFromQuery(
    query: ExecutedQuery
  ): Promise<void> {
    const pattern = this.extractPattern(query);
    const existing = this.patterns.get(pattern.id) || pattern;
    
    // íŒ¨í„´ í†µê³„ ì—…ë°ì´íŠ¸
    existing.frequency++;
    existing.lastSeen = new Date();
    existing.averageResponseTime = 
      (existing.averageResponseTime * (existing.frequency - 1) + 
       query.executionTime) / existing.frequency;
    
    this.patterns.set(pattern.id, existing);
    
    // ëª¨ë¸ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
    if (this.patterns.size % 100 === 0) {
      await this.retrainModel();
    }
  }
  
  // ì¿¼ë¦¬ ì˜ˆì¸¡
  async predictNextQueries(
    context: QueryContext
  ): Promise<PredictedQuery[]> {
    const predictions = await this.model.predict(context);
    
    return predictions.map(pred => ({
      query: this.buildQueryFromPattern(pred.pattern),
      probability: pred.probability,
      expectedResponseTime: pred.expectedTime,
      suggestedCache: pred.shouldCache
    }));
  }
  
  // ì¿¼ë¦¬ íŒ¨í„´ ì¶”ì¶œ
  private extractPattern(query: ExecutedQuery): QueryPattern {
    return {
      id: this.generatePatternId(query),
      entityType: this.extractEntityType(query),
      accessPattern: this.extractAccessPattern(query),
      timePattern: this.extractTimePattern(query),
      userPattern: this.extractUserPattern(query),
      frequency: 1,
      averageResponseTime: query.executionTime,
      lastSeen: new Date()
    };
  }
  
  // ì ì‘í˜• ì¸ë±ì‹± ì œì•ˆ
  async suggestAdaptiveIndexing(): Promise<AdaptiveIndexingSuggestion[]> {
    const suggestions: AdaptiveIndexingSuggestion[] = [];
    
    // ê³ ë¹ˆë„ íŒ¨í„´ ë¶„ì„
    const hotPatterns = Array.from(this.patterns.values())
      .filter(p => p.frequency > 100)
      .sort((a, b) => b.frequency - a.frequency);
    
    for (const pattern of hotPatterns) {
      const indexExists = await this.checkIndexCoverage(pattern);
      
      if (!indexExists) {
        suggestions.push({
          pattern,
          indexDefinition: this.generateOptimalIndex(pattern),
          expectedImprovement: this.estimateImprovement(pattern),
          priority: this.calculatePriority(pattern)
        });
      }
    }
    
    return suggestions.sort((a, b) => b.priority - a.priority);
  }
  
  // ì¿¼ë¦¬ ìµœì í™” í•™ìŠµ
  async learnOptimization(
    originalQuery: any,
    optimizedQuery: any,
    improvement: number
  ): Promise<void> {
    const optimization = {
      pattern: this.extractPattern(originalQuery),
      optimization: this.extractOptimization(originalQuery, optimizedQuery),
      improvement,
      timestamp: new Date()
    };
    
    await this.model.addOptimizationExample(optimization);
  }
}

// ì¿¼ë¦¬ ì˜ˆì¸¡ ëª¨ë¸
class QueryPredictionModel {
  private network: NeuralNetwork;
  
  constructor() {
    this.network = new NeuralNetwork({
      inputSize: 50, // íŠ¹ì„± ë²¡í„° í¬ê¸°
      hiddenLayers: [100, 50, 25],
      outputSize: 20, // ì˜ˆì¸¡ ê°€ëŠ¥í•œ íŒ¨í„´ ìˆ˜
      activation: 'relu',
      optimizer: 'adam'
    });
  }
  
  async predict(context: QueryContext): Promise<Prediction[]> {
    const features = this.extractFeatures(context);
    const predictions = await this.network.forward(features);
    
    return this.decodePredictions(predictions)
      .filter(p => p.probability > 0.3)
      .sort((a, b) => b.probability - a.probability)
      .slice(0, 5);
  }
  
  async train(examples: TrainingExample[]): Promise<void> {
    const dataset = examples.map(ex => ({
      input: this.extractFeatures(ex.context),
      output: this.encodePattern(ex.actualPattern)
    }));
    
    await this.network.train(dataset, {
      epochs: 100,
      batchSize: 32,
      validationSplit: 0.2,
      earlyStoppingPatience: 10
    });
  }
}
```

---

### Task 2.3: ë°ì´í„° íŒŒí‹°ì…”ë‹ ë° ìƒ¤ë”© ì „ëµ

#### SubTask 2.3.1: ì‹œê°„ ê¸°ë°˜ íŒŒí‹°ì…”ë‹
**ë‹´ë‹¹ì**: ë°ì´í„° ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/partitioning/time-based-partitioner.ts
export class TimeBasedPartitioner {
  private partitionStrategy: PartitionStrategy;
  
  constructor(strategy: PartitionStrategy = 'monthly') {
    this.partitionStrategy = strategy;
  }
  
  // íŒŒí‹°ì…˜ í‚¤ ìƒì„±
  generatePartitionKey(
    baseKey: string,
    timestamp: Date
  ): string {
    const suffix = this.getPartitionSuffix(timestamp);
    return `${baseKey}#${suffix}`;
  }
  
  private getPartitionSuffix(date: Date): string {
    switch (this.partitionStrategy) {
      case 'daily':
        return date.toISOString().split('T')[0];
      case 'weekly':
        return this.getWeekIdentifier(date);
      case 'monthly':
        return `${date.getFullYear()}-${String(date.getMonth() + 1).padStart(2, '0')}`;
      case 'yearly':
        return String(date.getFullYear());
      default:
        throw new Error(`Unknown partition strategy: ${this.partitionStrategy}`);
    }
  }
  
  // ì¿¼ë¦¬ ë²”ìœ„ì— ë”°ë¥¸ íŒŒí‹°ì…˜ ëª©ë¡ ìƒì„±
  getPartitionsForRange(
    startDate: Date,
    endDate: Date
  ): string[] {
    const partitions: string[] = [];
    const current = new Date(startDate);
    
    while (current <= endDate) {
      partitions.push(this.getPartitionSuffix(current));
      current.setDate(current.getDate() + 1);
    }
    
    return [...new Set(partitions)];
  }
  
  // Hot íŒŒí‹°ì…˜ ê°ì§€
  async detectHotPartitions(
    tableName: string,
    metrics: PartitionMetrics[]
  ): Promise<HotPartition[]> {
    const threshold = this.calculateDynamicThreshold(metrics);
    
    return metrics
      .filter(m => m.consumedRCU > threshold.rcu || 
                   m.consumedWCU > threshold.wcu)
      .map(m => ({
        partitionKey: m.partitionKey,
        consumedRCU: m.consumedRCU,
        consumedWCU: m.consumedWCU,
        itemCount: m.itemCount,
        recommendation: this.generateRebalancingRecommendation(m)
      }));
  }
  
  // ìë™ ì•„ì¹´ì´ë¹™
  async archiveOldPartitions(
    tableName: string,
    retentionDays: number
  ): Promise<ArchiveResult> {
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays);
    
    const partitionsToArchive = await this.identifyArchivablePartitions(
      tableName,
      cutoffDate
    );
    
    const archived: string[] = [];
    const failed: string[] = [];
    
    for (const partition of partitionsToArchive) {
      try {
        await this.archivePartition(tableName, partition);
        archived.push(partition);
      } catch (error) {
        failed.push(partition);
        console.error(`Failed to archive partition ${partition}:`, error);
      }
    }
    
    return {
      totalPartitions: partitionsToArchive.length,
      archived,
      failed,
      bytesArchived: await this.calculateArchivedSize(archived)
    };
  }
}

// íŒŒí‹°ì…˜ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬
export class PartitionLifecycleManager {
  constructor(
    private partitioner: TimeBasedPartitioner,
    private s3Client: S3Client
  ) {}
  
  // íŒŒí‹°ì…˜ ìƒì„± ìë™í™”
  async createUpcomingPartitions(
    tableName: string,
    daysAhead: number = 7
  ): Promise<void> {
    const futureDate = new Date();
    futureDate.setDate(futureDate.getDate() + daysAhead);
    
    const partitionsNeeded = this.partitioner.getPartitionsForRange(
      new Date(),
      futureDate
    );
    
    for (const partition of partitionsNeeded) {
      await this.ensurePartitionExists(tableName, partition);
    }
  }
  
  // íŒŒí‹°ì…˜ ë³‘í•©
  async mergePartitions(
    sourcePartitions: string[],
    targetPartition: string
  ): Promise<MergeResult> {
    const items: any[] = [];
    
    // ëª¨ë“  ì†ŒìŠ¤ íŒŒí‹°ì…˜ì—ì„œ ë°ì´í„° ì½ê¸°
    for (const partition of sourcePartitions) {
      const partitionItems = await this.readPartition(partition);
      items.push(...partitionItems);
    }
    
    // ëŒ€ìƒ íŒŒí‹°ì…˜ì— ì“°ê¸°
    await this.writeToPartition(targetPartition, items);
    
    // ì†ŒìŠ¤ íŒŒí‹°ì…˜ ì •ë¦¬
    for (const partition of sourcePartitions) {
      await this.deletePartition(partition);
    }
    
    return {
      sourcePartitions,
      targetPartition,
      itemsMerged: items.length,
      success: true
    };
  }
}
```

#### SubTask 2.3.2: í•« íŒŒí‹°ì…˜ ê´€ë¦¬ ë° ì¬ë¶„ë°°
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/partitioning/hot-partition-manager.ts
export class HotPartitionManager {
  private monitoringInterval: NodeJS.Timer;
  private rebalancingQueue: Queue<RebalancingJob>;
  
  constructor(
    private cloudWatch: CloudWatchClient,
    private dynamoDB: DynamoDBClient
  ) {
    this.rebalancingQueue = new Queue('partition-rebalancing');
  }
  
  // ì‹¤ì‹œê°„ íŒŒí‹°ì…˜ ëª¨ë‹ˆí„°ë§
  startMonitoring(tableName: string): void {
    this.monitoringInterval = setInterval(async () => {
      try {
        const metrics = await this.collectPartitionMetrics(tableName);
        const hotPartitions = await this.identifyHotPartitions(metrics);
        
        if (hotPartitions.length > 0) {
          await this.handleHotPartitions(tableName, hotPartitions);
        }
      } catch (error) {
        console.error('Partition monitoring error:', error);
      }
    }, 60000); // 1ë¶„ë§ˆë‹¤
  }
  
  // íŒŒí‹°ì…˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  private async collectPartitionMetrics(
    tableName: string
  ): Promise<PartitionMetrics[]> {
    const params = {
      MetricName: 'ConsumedReadCapacityUnits',
      Namespace: 'AWS/DynamoDB',
      Dimensions: [
        { Name: 'TableName', Value: tableName }
      ],
      StartTime: new Date(Date.now() - 5 * 60 * 1000), // 5ë¶„ ì „
      EndTime: new Date(),
      Period: 60,
      Statistics: ['Sum', 'Average', 'Maximum']
    };
    
    const response = await this.cloudWatch.send(
      new GetMetricStatisticsCommand(params)
    );
    
    // íŒŒí‹°ì…˜ë³„ ë©”íŠ¸ë¦­ ë¶„ì„
    return this.analyzePartitionMetrics(response.Datapoints || []);
  }
  
  // ìë™ ì¬ë¶„ë°° ì „ëµ
  async rebalanceHotPartition(
    tableName: string,
    partition: HotPartition
  ): Promise<RebalancingResult> {
    const strategy = this.selectRebalancingStrategy(partition);
    
    switch (strategy) {
      case 'SPLIT':
        return await this.splitPartition(tableName, partition);
        
      case 'REDISTRIBUTE':
        return await this.redistributeItems(tableName, partition);
        
      case 'CACHE':
        return await this.enablePartitionCaching(tableName, partition);
        
      case 'THROTTLE':
        return await this.applyThrottling(tableName, partition);
        
      default:
        throw new Error(`Unknown rebalancing strategy: ${strategy}`);
    }
  }
  
  // íŒŒí‹°ì…˜ ë¶„í• 
  private async splitPartition(
    tableName: string,
    partition: HotPartition
  ): Promise<RebalancingResult> {
    // 1. ìƒˆë¡œìš´ íŒŒí‹°ì…˜ í‚¤ ìƒì„±
    const newPartitions = this.generateSplitPartitions(partition);
    
    // 2. ê¸°ì¡´ í•­ëª© ì½ê¸°
    const items = await this.readPartitionItems(tableName, partition.partitionKey);
    
    // 3. í•­ëª© ì¬ë¶„ë°°
    const distribution = this.distributeItems(items, newPartitions);
    
    // 4. ë³‘ë ¬ë¡œ ìƒˆ íŒŒí‹°ì…˜ì— ì“°ê¸°
    const writePromises = newPartitions.map((newPartition, index) =>
      this.batchWriteItems(tableName, distribution[index], newPartition)
    );
    
    await Promise.all(writePromises);
    
    // 5. ê¸°ì¡´ íŒŒí‹°ì…˜ ì •ë¦¬
    await this.cleanupOldPartition(tableName, partition.partitionKey);
    
    return {
      strategy: 'SPLIT',
      originalPartition: partition.partitionKey,
      newPartitions,
      itemsRebalanced: items.length,
      success: true
    };
  }
  
  // ì§€ëŠ¥í˜• í•­ëª© ì¬ë¶„ë°°
  private distributeItems(
    items: any[],
    partitions: string[]
  ): any[][] {
    const distributed: any[][] = partitions.map(() => []);
    
    // í•´ì‹œ ê¸°ë°˜ ê· ë“± ë¶„ë°°
    items.forEach(item => {
      const hash = this.hashItem(item);
      const targetIndex = hash % partitions.length;
      distributed[targetIndex].push(item);
    });
    
    // ë¶„ë°° ê· í˜• ê²€ì¦
    const sizes = distributed.map(d => d.length);
    const avg = items.length / partitions.length;
    const maxDeviation = Math.max(...sizes.map(s => Math.abs(s - avg)));
    
    if (maxDeviation > avg * 0.2) {
      // ì¬ê· í˜• í•„ìš”
      return this.rebalanceDistribution(distributed);
    }
    
    return distributed;
  }
  
  // ì ì‘í˜• íŒŒí‹°ì…”ë‹
  async enableAdaptivePartitioning(
    tableName: string
  ): Promise<void> {
    const config: AdaptivePartitioningConfig = {
      enabled: true,
      minPartitionSize: 1000,
      maxPartitionSize: 100000,
      hotPartitionThreshold: {
        rcu: 3000,
        wcu: 1000
      },
      cooldownPeriod: 300, // 5ë¶„
      strategies: ['SPLIT', 'REDISTRIBUTE', 'CACHE']
    };
    
    await this.savePartitioningConfig(tableName, config);
    
    // ëª¨ë‹ˆí„°ë§ ì‹œì‘
    this.startMonitoring(tableName);
  }
}

// íŒŒí‹°ì…˜ ì˜ˆì¸¡ ëª¨ë¸
export class PartitionPredictionModel {
  async predictFutureHotspots(
    historicalData: PartitionMetrics[],
    timeframe: number
  ): Promise<PredictedHotspot[]> {
    // ì‹œê³„ì—´ ë¶„ì„
    const trends = this.analyzeTimeSeries(historicalData);
    
    // ê³„ì ˆì„± íŒ¨í„´ ê°ì§€
    const seasonality = this.detectSeasonality(historicalData);
    
    // ì˜ˆì¸¡ ëª¨ë¸ ì‹¤í–‰
    const predictions = await this.runPredictionModel({
      trends,
      seasonality,
      timeframe
    });
    
    return predictions.map(pred => ({
      partitionKey: pred.partition,
      predictedTime: pred.timestamp,
      expectedLoad: pred.load,
      confidence: pred.confidence,
      recommendation: this.generateProactiveAction(pred)
    }));
  }
}
```

#### SubTask 2.3.3: ê¸€ë¡œë²Œ í…Œì´ë¸” ë° í¬ë¡œìŠ¤ ë¦¬ì „ ë³µì œ
**ë‹´ë‹¹ì**: ì¸í”„ë¼ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/replication/global-table-manager.ts
export class GlobalTableManager {
  private regions: string[];
  private replicationMonitor: ReplicationMonitor;
  
  constructor(regions: string[]) {
    this.regions = regions;
    this.replicationMonitor = new ReplicationMonitor();
  }
  
  // ê¸€ë¡œë²Œ í…Œì´ë¸” ìƒì„±
  async createGlobalTable(
    tableName: string,
    schema: TableSchema
  ): Promise<GlobalTableCreationResult> {
    const results: RegionResult[] = [];
    
    // 1. ê° ë¦¬ì „ì— í…Œì´ë¸” ìƒì„±
    for (const region of this.regions) {
      const client = new DynamoDBClient({ region });
      
      try {
        await this.createRegionalTable(client, tableName, schema);
        results.push({ region, status: 'CREATED' });
      } catch (error) {
        results.push({ region, status: 'FAILED', error });
      }
    }
    
    // 2. ê¸€ë¡œë²Œ í…Œì´ë¸” ì„¤ì •
    if (results.every(r => r.status === 'CREATED')) {
      await this.enableGlobalTableReplication(tableName);
    }
    
    return {
      tableName,
      regions: results,
      replicationEnabled: results.every(r => r.status === 'CREATED'),
      timestamp: new Date()
    };
  }
  
  // ë³µì œ ì§€ì—° ëª¨ë‹ˆí„°ë§
  async monitorReplicationLag(): Promise<ReplicationMetrics> {
    const metrics: RegionMetrics[] = [];
    
    for (const region of this.regions) {
      const lag = await this.measureReplicationLag(region);
      const health = await this.checkRegionHealth(region);
      
      metrics.push({
        region,
        replicationLag: lag,
        health,
        lastSync: new Date()
      });
    }
    
    return {
      globalHealth: this.calculateGlobalHealth(metrics),
      regionMetrics: metrics,
      alerts: this.generateReplicationAlerts(metrics)
    };
  }
  
  // ì¶©ëŒ í•´ê²° ì „ëµ
  async resolveConflicts(
    conflicts: ReplicationConflict[]
  ): Promise<ConflictResolutionResult[]> {
    const results: ConflictResolutionResult[] = [];
    
    for (const conflict of conflicts) {
      const resolution = await this.applyConflictResolution(conflict);
      results.push(resolution);
      
      // í•´ê²° ë‚´ì—­ ê¸°ë¡
      await this.logConflictResolution(resolution);
    }
    
    return results;
  }
  
  private async applyConflictResolution(
    conflict: ReplicationConflict
  ): Promise<ConflictResolutionResult> {
    switch (conflict.type) {
      case 'CONCURRENT_UPDATE':
        return this.resolveByLastWriterWins(conflict);
        
      case 'DELETE_UPDATE':
        return this.resolveDeleteUpdate(conflict);
        
      case 'SCHEMA_MISMATCH':
        return this.resolveSchemaMismatch(conflict);
        
      default:
        return this.customConflictResolution(conflict);
    }
  }
  
  // ë¦¬ì „ ì¥ì•  ëŒ€ì‘
  async handleRegionFailure(
    failedRegion: string
  ): Promise<FailoverResult> {
    // 1. ì¥ì•  ë¦¬ì „ ê²©ë¦¬
    await this.isolateFailedRegion(failedRegion);
    
    // 2. íŠ¸ë˜í”½ ì¬ë¼ìš°íŒ…
    const newPrimary = await this.selectNewPrimaryRegion();
    await this.rerouteTraffic(failedRegion, newPrimary);
    
    // 3. ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
    await this.verifyDataConsistency(newPrimary);
    
    // 4. ì•Œë¦¼ ë°œì†¡
    await this.notifyFailover(failedRegion, newPrimary);
    
    return {
      failedRegion,
      newPrimary,
      dataLoss: false,
      recoveryTime: Date.now(),
      status: 'COMPLETED'
    };
  }
}

// í¬ë¡œìŠ¤ ë¦¬ì „ ë°ì´í„° ë™ê¸°í™”
export class CrossRegionSync {
  private syncQueue: Queue<SyncJob>;
  private syncStatus: Map<string, SyncStatus>;
  
  // ì„ íƒì  ë™ê¸°í™”
  async syncSelectedData(
    sourceRegion: string,
    targetRegions: string[],
    filter: SyncFilter
  ): Promise<SyncResult> {
    const syncJobs: SyncJob[] = [];
    
    // ë™ê¸°í™”í•  ë°ì´í„° ì‹ë³„
    const dataToSync = await this.identifyDataToSync(
      sourceRegion,
      filter
    );
    
    // ê° ëŒ€ìƒ ë¦¬ì „ì— ëŒ€í•œ ë™ê¸°í™” ì‘ì—… ìƒì„±
    for (const targetRegion of targetRegions) {
      const job: SyncJob = {
        id: uuidv4(),
        sourceRegion,
        targetRegion,
        dataSet: dataToSync,
        priority: filter.priority || 'NORMAL',
        createdAt: new Date()
      };
      
      syncJobs.push(job);
      await this.syncQueue.add(job);
    }
    
    // ë™ê¸°í™” ì§„í–‰ ìƒíƒœ ì¶”ì 
    return this.trackSyncProgress(syncJobs);
  }
  
  // ì¦ë¶„ ë™ê¸°í™”
  async performIncrementalSync(
    region: string,
    lastSyncTimestamp: Date
  ): Promise<IncrementalSyncResult> {
    // DynamoDB Streamsì—ì„œ ë³€ê²½ì‚¬í•­ ì½ê¸°
    const changes = await this.readChangesSince(
      region,
      lastSyncTimestamp
    );
    
    // ë³€ê²½ì‚¬í•­ ë¶„ë¥˜
    const classified = this.classifyChanges(changes);
    
    // ë³‘ë ¬ ë™ê¸°í™” ì‹¤í–‰
    const results = await Promise.all([
      this.syncInserts(classified.inserts),
      this.syncUpdates(classified.updates),
      this.syncDeletes(classified.deletes)
    ]);
    
    return {
      itemsSynced: results.reduce((sum, r) => sum + r.count, 0),
      duration: Date.now() - lastSyncTimestamp.getTime(),
      errors: results.filter(r => r.errors > 0),
      nextSyncTimestamp: new Date()
    };
  }
}
```

#### SubTask 2.3.4: ìƒ¤ë”© í‚¤ ì„¤ê³„ ë° ìµœì í™”
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/sharding/sharding-strategy.ts
export class ShardingStrategy {
  private shardCount: number;
  private hashFunction: HashFunction;
  
  constructor(
    shardCount: number = 10,
    hashFunction: HashFunction = 'xxhash'
  ) {
    this.shardCount = shardCount;
    this.hashFunction = this.initializeHashFunction(hashFunction);
  }
  
  // ìƒ¤ë“œ í‚¤ ìƒì„±
  generateShardKey(
    entityId: string,
    timestamp?: Date
  ): string {
    const shardId = this.calculateShardId(entityId);
    const timeComponent = timestamp ? 
      `#${timestamp.getTime()}` : '';
    
    return `SHARD#${shardId}${timeComponent}`;
  }
  
  // ì¼ê´€ëœ í•´ì‹±
  private calculateShardId(key: string): number {
    const hash = this.hashFunction(key);
    return hash % this.shardCount;
  }
  
  // ìƒ¤ë“œ ì¬ë¶„ë°°
  async reshardData(
    currentShards: number,
    targetShards: number
  ): Promise<ReshardingPlan> {
    const plan: ReshardingPlan = {
      currentShards,
      targetShards,
      migrations: [],
      estimatedDuration: 0
    };
    
    // ë§ˆì´ê·¸ë ˆì´ì…˜ ë§¤í•‘ ìƒì„±
    for (let i = 0; i < currentShards; i++) {
      const targetShard = this.mapToNewShard(
        i,
        currentShards,
        targetShards
      );
      
      if (targetShard !== i) {
        plan.migrations.push({
          fromShard: i,
          toShard: targetShard,
          estimatedItems: await this.estimateShardSize(i)
        });
      }
    }
    
    plan.estimatedDuration = this.estimateMigrationTime(plan.migrations);
    
    return plan;
  }
  
  // í•« ìƒ¤ë“œ ê°ì§€ ë° ë¶„í• 
  async detectAndSplitHotShards(
    metrics: ShardMetrics[]
  ): Promise<ShardSplitResult[]> {
    const results: ShardSplitResult[] = [];
    const threshold = this.calculateDynamicThreshold(metrics);
    
    for (const metric of metrics) {
      if (metric.load > threshold) {
        const splitResult = await this.splitShard(metric.shardId);
        results.push(splitResult);
      }
    }
    
    return results;
  }
  
  private async splitShard(
    shardId: number
  ): Promise<ShardSplitResult> {
    // ê°€ìƒ ìƒ¤ë“œ ìƒì„±
    const virtualShards = this.createVirtualShards(shardId, 2);
    
    // ë°ì´í„° ì¬ë¶„ë°°
    const items = await this.readShardItems(shardId);
    const distribution = this.distributeToVirtualShards(
      items,
      virtualShards
    );
    
    // ìƒˆ ìƒ¤ë“œì— ì“°ê¸°
    await Promise.all(
      virtualShards.map((vShard, index) =>
        this.writeToShard(vShard, distribution[index])
      )
    );
    
    return {
      originalShard: shardId,
      newShards: virtualShards,
      itemsRedistributed: items.length,
      timestamp: new Date()
    };
  }
}

// ì§€ëŠ¥í˜• ìƒ¤ë”© ìµœì í™”
export class IntelligentShardingOptimizer {
  private ml: ShardingMLModel;
  
  constructor() {
    this.ml = new ShardingMLModel();
  }
  
  // ìµœì  ìƒ¤ë“œ ìˆ˜ ì˜ˆì¸¡
  async predictOptimalShardCount(
    workload: WorkloadProfile
  ): Promise<ShardingRecommendation> {
    const features = this.extractWorkloadFeatures(workload);
    const prediction = await this.ml.predict(features);
    
    return {
      recommendedShards: prediction.shardCount,
      confidence: prediction.confidence,
      reasoning: prediction.explanation,
      expectedImprovement: {
        throughput: prediction.throughputGain,
        latency: prediction.latencyReduction,
        cost: prediction.costOptimization
      }
    };
  }
  
  // ìƒ¤ë”© ì „ëµ í•™ìŠµ
  async learnFromPerformance(
    strategy: ShardingStrategy,
    performance: PerformanceMetrics
  ): Promise<void> {
    const example = {
      strategy: this.encodeStrategy(strategy),
      performance: this.normalizeMetrics(performance),
      timestamp: new Date()
    };
    
    await this.ml.addTrainingExample(example);
    
    // ì£¼ê¸°ì  ëª¨ë¸ ì¬í•™ìŠµ
    if (this.shouldRetrain()) {
      await this.ml.retrain();
    }
  }
  
  // ë™ì  ìƒ¤ë”© ì¡°ì •
  async adjustShardingDynamically(
    currentMetrics: ShardMetrics[]
  ): Promise<ShardingAdjustment> {
    const analysis = this.analyzeCurrentPerformance(currentMetrics);
    
    if (analysis.needsAdjustment) {
      const adjustment = await this.calculateAdjustment(analysis);
      
      // ì ì§„ì  ì¡°ì • ì‹¤í–‰
      return await this.executeGradualAdjustment(adjustment);
    }
    
    return { adjusted: false };
  }
}
```
### Task 2.4: ë„ë©”ì¸ ëª¨ë¸ ì •ì˜

#### SubTask 2.4.1: í•µì‹¬ ë„ë©”ì¸ ì—”í‹°í‹° ëª¨ë¸ë§
**ë‹´ë‹¹ì**: ë„ë©”ì¸ ì „ë¬¸ê°€ & ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/domain/models/core-entities.ts
import { z } from 'zod';

// ê¸°ë³¸ ë„ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
export interface DomainEntity {
  id: string;
  version: number;
  createdAt: Date;
  updatedAt: Date;
  createdBy: string;
  updatedBy?: string;
}

// User ë„ë©”ì¸ ëª¨ë¸
export const UserSchema = z.object({
  id: z.string().uuid(),
  email: z.string().email(),
  username: z.string().min(3).max(30),
  displayName: z.string().max(100),
  role: z.enum(['admin', 'developer', 'viewer', 'guest']),
  status: z.enum(['active', 'inactive', 'suspended', 'deleted']),
  preferences: z.object({
    theme: z.enum(['light', 'dark', 'auto']),
    language: z.string().default('en'),
    timezone: z.string().default('UTC'),
    notifications: z.object({
      email: z.boolean().default(true),
      push: z.boolean().default(false),
      inApp: z.boolean().default(true)
    })
  }),
  metadata: z.record(z.any()).optional(),
  lastLoginAt: z.date().optional(),
  emailVerifiedAt: z.date().optional(),
  version: z.number().default(1),
  createdAt: z.date(),
  updatedAt: z.date()
});

export type User = z.infer<typeof UserSchema>;

// Project ë„ë©”ì¸ ëª¨ë¸
export const ProjectSchema = z.object({
  id: z.string().uuid(),
  name: z.string().min(1).max(100),
  description: z.string().max(1000).optional(),
  ownerId: z.string().uuid(),
  organizationId: z.string().uuid().optional(),
  type: z.enum(['web', 'mobile', 'api', 'ml', 'data']),
  status: z.enum(['planning', 'active', 'paused', 'completed', 'archived']),
  visibility: z.enum(['private', 'team', 'organization', 'public']),
  settings: z.object({
    autoDeployEnabled: z.boolean().default(false),
    branchProtection: z.boolean().default(true),
    requireCodeReview: z.boolean().default(true),
    testCoverage: z.number().min(0).max(100).default(80),
    maxAgents: z.number().default(10),
    resourceLimits: z.object({
      cpu: z.number().default(2),
      memory: z.number().default(4096),
      storage: z.number().default(10240)
    })
  }),
  repository: z.object({
    provider: z.enum(['github', 'gitlab', 'bitbucket', 'internal']),
    url: z.string().url(),
    defaultBranch: z.string().default('main'),
    accessToken: z.string().optional()
  }).optional(),
  tags: z.array(z.string()).default([]),
  collaborators: z.array(z.object({
    userId: z.string().uuid(),
    role: z.enum(['owner', 'admin', 'contributor', 'viewer']),
    addedAt: z.date()
  })).default([]),
  metrics: z.object({
    totalTasks: z.number().default(0),
    completedTasks: z.number().default(0),
    activeAgents: z.number().default(0),
    lastActivityAt: z.date().optional()
  }),
  version: z.number().default(1),
  createdAt: z.date(),
  updatedAt: z.date()
});

export type Project = z.infer<typeof ProjectSchema>;

// Agent ë„ë©”ì¸ ëª¨ë¸
export const AgentSchema = z.object({
  id: z.string().uuid(),
  projectId: z.string().uuid(),
  type: z.enum([
    'ProjectManagerAgent',
    'RequirementsAgent', 
    'ArchitectAgent',
    'BackendAgent',
    'FrontendAgent',
    'DatabaseAgent',
    'DevOpsAgent',
    'TestingAgent',
    'DocumentationAgent'
  ]),
  name: z.string().min(1).max(100),
  description: z.string().max(500).optional(),
  status: z.enum(['idle', 'initializing', 'running', 'paused', 'completed', 'failed', 'terminated']),
  configuration: z.object({
    model: z.string().default('claude-3-opus'),
    temperature: z.number().min(0).max(1).default(0.7),
    maxTokens: z.number().default(4096),
    systemPrompt: z.string().optional(),
    tools: z.array(z.string()).default([]),
    permissions: z.object({
      canCreateFiles: z.boolean().default(true),
      canModifyFiles: z.boolean().default(true),
      canDeleteFiles: z.boolean().default(false),
      canExecuteCommands: z.boolean().default(false),
      canAccessNetwork: z.boolean().default(true)
    }),
    resourceLimits: z.object({
      maxExecutionTime: z.number().default(300000), // 5 minutes
      maxMemoryUsage: z.number().default(512), // MB
      maxApiCalls: z.number().default(1000)
    })
  }),
  state: z.object({
    currentTask: z.string().uuid().optional(),
    workingMemory: z.record(z.any()).default({}),
    conversationHistory: z.array(z.object({
      role: z.enum(['user', 'assistant', 'system']),
      content: z.string(),
      timestamp: z.date()
    })).default([]),
    checkpoints: z.array(z.object({
      id: z.string().uuid(),
      timestamp: z.date(),
      state: z.record(z.any())
    })).default([])
  }),
  metrics: z.object({
    tasksCompleted: z.number().default(0),
    tasksFailed: z.number().default(0),
    averageExecutionTime: z.number().default(0),
    totalExecutionTime: z.number().default(0),
    apiCallsUsed: z.number().default(0),
    errorRate: z.number().default(0),
    lastExecutionAt: z.date().optional()
  }),
  dependencies: z.array(z.string().uuid()).default([]),
  version: z.number().default(1),
  createdAt: z.date(),
  updatedAt: z.date()
});

export type Agent = z.infer<typeof AgentSchema>;

// Task ë„ë©”ì¸ ëª¨ë¸
export const TaskSchema = z.object({
  id: z.string().uuid(),
  projectId: z.string().uuid(),
  parentTaskId: z.string().uuid().optional(),
  agentId: z.string().uuid().optional(),
  type: z.enum(['epic', 'story', 'task', 'subtask', 'bug', 'spike']),
  title: z.string().min(1).max(200),
  description: z.string().max(5000).optional(),
  status: z.enum(['todo', 'in_progress', 'review', 'testing', 'done', 'cancelled']),
  priority: z.enum(['critical', 'high', 'medium', 'low']),
  complexity: z.enum(['XS', 'S', 'M', 'L', 'XL', 'XXL']),
  assignee: z.object({
    type: z.enum(['user', 'agent']),
    id: z.string().uuid()
  }).optional(),
  requirements: z.array(z.object({
    id: z.string().uuid(),
    description: z.string(),
    type: z.enum(['functional', 'technical', 'constraint']),
    status: z.enum(['pending', 'approved', 'implemented'])
  })).default([]),
  acceptance_criteria: z.array(z.string()).default([]),
  dependencies: z.array(z.object({
    taskId: z.string().uuid(),
    type: z.enum(['blocks', 'relates_to', 'duplicates'])
  })).default([]),
  artifacts: z.array(z.object({
    id: z.string().uuid(),
    type: z.enum(['code', 'document', 'diagram', 'test', 'config']),
    path: z.string(),
    url: z.string().url().optional(),
    createdAt: z.date()
  })).default([]),
  timeline: z.object({
    estimatedHours: z.number().optional(),
    actualHours: z.number().default(0),
    startDate: z.date().optional(),
    dueDate: z.date().optional(),
    completedAt: z.date().optional()
  }),
  metadata: z.record(z.any()).default({}),
  version: z.number().default(1),
  createdAt: z.date(),
  updatedAt: z.date()
});

export type Task = z.infer<typeof TaskSchema>;

// Conversation ë„ë©”ì¸ ëª¨ë¸
export const ConversationSchema = z.object({
  id: z.string().uuid(),
  projectId: z.string().uuid(),
  participants: z.array(z.object({
    type: z.enum(['user', 'agent']),
    id: z.string().uuid(),
    name: z.string()
  })),
  type: z.enum(['direct', 'group', 'broadcast']),
  status: z.enum(['active', 'archived', 'deleted']),
  messages: z.array(z.object({
    id: z.string().uuid(),
    senderId: z.string().uuid(),
    senderType: z.enum(['user', 'agent']),
    content: z.string(),
    attachments: z.array(z.object({
      type: z.enum(['file', 'code', 'image', 'link']),
      url: z.string().url(),
      metadata: z.record(z.any())
    })).default([]),
    mentions: z.array(z.string().uuid()).default([]),
    reactions: z.array(z.object({
      userId: z.string().uuid(),
      emoji: z.string(),
      timestamp: z.date()
    })).default([]),
    editedAt: z.date().optional(),
    deletedAt: z.date().optional(),
    timestamp: z.date()
  })).default([]),
  metadata: z.record(z.any()).default({}),
  version: z.number().default(1),
  createdAt: z.date(),
  updatedAt: z.date()
});

export type Conversation = z.infer<typeof ConversationSchema>;
```

#### SubTask 2.4.2: ë„ë©”ì¸ ì´ë²¤íŠ¸ ëª¨ë¸ë§
**ë‹´ë‹¹ì**: ì´ë²¤íŠ¸ ì£¼ë„ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/domain/events/domain-events.ts
export abstract class DomainEvent {
  public readonly occurredAt: Date;
  public readonly eventId: string;
  public readonly eventType: string;
  public readonly aggregateId: string;
  public readonly aggregateType: string;
  public readonly causationId?: string;
  public readonly correlationId?: string;
  public readonly metadata: Record<string, any>;

  constructor(params: {
    aggregateId: string;
    aggregateType: string;
    causationId?: string;
    correlationId?: string;
    metadata?: Record<string, any>;
  }) {
    this.eventId = uuidv4();
    this.occurredAt = new Date();
    this.eventType = this.constructor.name;
    this.aggregateId = params.aggregateId;
    this.aggregateType = params.aggregateType;
    this.causationId = params.causationId;
    this.correlationId = params.correlationId || uuidv4();
    this.metadata = params.metadata || {};
  }

  abstract toJSON(): Record<string, any>;
}

// User ì´ë²¤íŠ¸
export class UserCreatedEvent extends DomainEvent {
  constructor(
    public readonly userId: string,
    public readonly email: string,
    public readonly username: string,
    public readonly role: string
  ) {
    super({
      aggregateId: userId,
      aggregateType: 'User'
    });
  }

  toJSON() {
    return {
      userId: this.userId,
      email: this.email,
      username: this.username,
      role: this.role
    };
  }
}

export class UserRoleChangedEvent extends DomainEvent {
  constructor(
    public readonly userId: string,
    public readonly oldRole: string,
    public readonly newRole: string,
    public readonly changedBy: string
  ) {
    super({
      aggregateId: userId,
      aggregateType: 'User'
    });
  }

  toJSON() {
    return {
      userId: this.userId,
      oldRole: this.oldRole,
      newRole: this.newRole,
      changedBy: this.changedBy
    };
  }
}

// Project ì´ë²¤íŠ¸
export class ProjectCreatedEvent extends DomainEvent {
  constructor(
    public readonly projectId: string,
    public readonly name: string,
    public readonly ownerId: string,
    public readonly type: string
  ) {
    super({
      aggregateId: projectId,
      aggregateType: 'Project'
    });
  }

  toJSON() {
    return {
      projectId: this.projectId,
      name: this.name,
      ownerId: this.ownerId,
      type: this.type
    };
  }
}

export class ProjectStatusChangedEvent extends DomainEvent {
  constructor(
    public readonly projectId: string,
    public readonly oldStatus: string,
    public readonly newStatus: string,
    public readonly reason?: string
  ) {
    super({
      aggregateId: projectId,
      aggregateType: 'Project'
    });
  }

  toJSON() {
    return {
      projectId: this.projectId,
      oldStatus: this.oldStatus,
      newStatus: this.newStatus,
      reason: this.reason
    };
  }
}

// Agent ì´ë²¤íŠ¸
export class AgentStartedEvent extends DomainEvent {
  constructor(
    public readonly agentId: string,
    public readonly projectId: string,
    public readonly agentType: string,
    public readonly taskId?: string
  ) {
    super({
      aggregateId: agentId,
      aggregateType: 'Agent'
    });
  }

  toJSON() {
    return {
      agentId: this.agentId,
      projectId: this.projectId,
      agentType: this.agentType,
      taskId: this.taskId
    };
  }
}

export class AgentCompletedTaskEvent extends DomainEvent {
  constructor(
    public readonly agentId: string,
    public readonly taskId: string,
    public readonly executionTime: number,
    public readonly result: any
  ) {
    super({
      aggregateId: agentId,
      aggregateType: 'Agent'
    });
  }

  toJSON() {
    return {
      agentId: this.agentId,
      taskId: this.taskId,
      executionTime: this.executionTime,
      result: this.result
    };
  }
}

export class AgentFailedEvent extends DomainEvent {
  constructor(
    public readonly agentId: string,
    public readonly error: string,
    public readonly stackTrace?: string,
    public readonly retryable: boolean = false
  ) {
    super({
      aggregateId: agentId,
      aggregateType: 'Agent'
    });
  }

  toJSON() {
    return {
      agentId: this.agentId,
      error: this.error,
      stackTrace: this.stackTrace,
      retryable: this.retryable
    };
  }
}

// Task ì´ë²¤íŠ¸  
export class TaskCreatedEvent extends DomainEvent {
  constructor(
    public readonly taskId: string,
    public readonly projectId: string,
    public readonly title: string,
    public readonly type: string,
    public readonly createdBy: string
  ) {
    super({
      aggregateId: taskId,
      aggregateType: 'Task'
    });
  }

  toJSON() {
    return {
      taskId: this.taskId,
      projectId: this.projectId,
      title: this.title,
      type: this.type,
      createdBy: this.createdBy
    };
  }
}

export class TaskAssignedEvent extends DomainEvent {
  constructor(
    public readonly taskId: string,
    public readonly assigneeType: 'user' | 'agent',
    public readonly assigneeId: string,
    public readonly previousAssigneeId?: string
  ) {
    super({
      aggregateId: taskId,
      aggregateType: 'Task'
    });
  }

  toJSON() {
    return {
      taskId: this.taskId,
      assigneeType: this.assigneeType,
      assigneeId: this.assigneeId,
      previousAssigneeId: this.previousAssigneeId
    };
  }
}

// ì´ë²¤íŠ¸ ìŠ¤í† ì–´
export class EventStore {
  constructor(
    private dynamoDB: DynamoDBDocumentClient,
    private tableName: string
  ) {}

  async saveEvent(event: DomainEvent): Promise<void> {
    const item = {
      PK: `EVENT#${event.aggregateType}#${event.aggregateId}`,
      SK: `${event.occurredAt.toISOString()}#${event.eventId}`,
      EventId: event.eventId,
      EventType: event.eventType,
      AggregateId: event.aggregateId,
      AggregateType: event.aggregateType,
      OccurredAt: event.occurredAt.toISOString(),
      CausationId: event.causationId,
      CorrelationId: event.correlationId,
      Metadata: event.metadata,
      Data: event.toJSON(),
      TTL: Math.floor(Date.now() / 1000) + (365 * 24 * 60 * 60) // 1ë…„
    };

    await this.dynamoDB.send(new PutCommand({
      TableName: this.tableName,
      Item: item
    }));
  }

  async getEvents(
    aggregateId: string,
    aggregateType: string,
    fromDate?: Date,
    toDate?: Date
  ): Promise<DomainEvent[]> {
    const params: QueryCommandInput = {
      TableName: this.tableName,
      KeyConditionExpression: 'PK = :pk',
      ExpressionAttributeValues: {
        ':pk': `EVENT#${aggregateType}#${aggregateId}`
      }
    };

    if (fromDate || toDate) {
      params.KeyConditionExpression += ' AND SK BETWEEN :from AND :to';
      params.ExpressionAttributeValues![':from'] = fromDate?.toISOString() || '0';
      params.ExpressionAttributeValues![':to'] = toDate?.toISOString() || '9999';
    }

    const result = await this.dynamoDB.send(new QueryCommand(params));
    return result.Items?.map(item => this.deserializeEvent(item)) || [];
  }

  private deserializeEvent(item: any): DomainEvent {
    // ì´ë²¤íŠ¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ í´ë˜ìŠ¤ë¡œ ì—­ì§ë ¬í™”
    const eventClass = this.getEventClass(item.EventType);
    return new eventClass(item.Data);
  }
}
```

#### SubTask 2.4.3: ê°’ ê°ì²´ ë° ì§‘ê³„ ì •ì˜
**ë‹´ë‹¹ì**: DDD ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/domain/value-objects/index.ts

// Email ê°’ ê°ì²´
export class Email {
  private readonly value: string;

  constructor(email: string) {
    if (!this.isValid(email)) {
      throw new Error(`Invalid email format: ${email}`);
    }
    this.value = email.toLowerCase();
  }

  private isValid(email: string): boolean {
    const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
    return emailRegex.test(email);
  }

  toString(): string {
    return this.value;
  }

  equals(other: Email): boolean {
    return this.value === other.value;
  }

  getDomain(): string {
    return this.value.split('@')[1];
  }
}

// ProjectName ê°’ ê°ì²´
export class ProjectName {
  private readonly value: string;

  constructor(name: string) {
    const trimmed = name.trim();
    if (trimmed.length < 1 || trimmed.length > 100) {
      throw new Error('Project name must be between 1 and 100 characters');
    }
    if (!/^[a-zA-Z0-9\s\-_]+$/.test(trimmed)) {
      throw new Error('Project name contains invalid characters');
    }
    this.value = trimmed;
  }

  toString(): string {
    return this.value;
  }

  toSlug(): string {
    return this.value
      .toLowerCase()
      .replace(/\s+/g, '-')
      .replace(/[^a-z0-9\-]/g, '');
  }
}

// TimeRange ê°’ ê°ì²´
export class TimeRange {
  constructor(
    public readonly start: Date,
    public readonly end: Date
  ) {
    if (start >= end) {
      throw new Error('Start time must be before end time');
    }
  }

  getDuration(): number {
    return this.end.getTime() - this.start.getTime();
  }

  contains(date: Date): boolean {
    return date >= this.start && date <= this.end;
  }

  overlaps(other: TimeRange): boolean {
    return this.start < other.end && this.end > other.start;
  }
}

// ResourceLimits ê°’ ê°ì²´
export class ResourceLimits {
  constructor(
    public readonly cpu: number,
    public readonly memory: number,
    public readonly storage: number
  ) {
    if (cpu <= 0 || memory <= 0 || storage <= 0) {
      throw new Error('Resource limits must be positive');
    }
  }

  exceedsLimits(usage: ResourceUsage): boolean {
    return usage.cpu > this.cpu || 
           usage.memory > this.memory || 
           usage.storage > this.storage;
  }
}

// backend/src/domain/aggregates/project-aggregate.ts
export class ProjectAggregate {
  private events: DomainEvent[] = [];
  
  constructor(
    private state: Project,
    private eventStore: EventStore
  ) {}

  // Commands
  async create(params: CreateProjectParams): Promise<void> {
    if (this.state.id) {
      throw new Error('Project already exists');
    }

    const project: Project = {
      id: uuidv4(),
      name: params.name,
      description: params.description,
      ownerId: params.ownerId,
      type: params.type,
      status: 'planning',
      visibility: params.visibility || 'private',
      settings: this.getDefaultSettings(),
      tags: params.tags || [],
      collaborators: [{
        userId: params.ownerId,
        role: 'owner',
        addedAt: new Date()
      }],
      metrics: {
        totalTasks: 0,
        completedTasks: 0,
        activeAgents: 0
      },
      version: 1,
      createdAt: new Date(),
      updatedAt: new Date()
    };

    this.state = project;
    this.addEvent(new ProjectCreatedEvent(
      project.id,
      project.name,
      project.ownerId,
      project.type
    ));
  }

  async updateStatus(
    newStatus: Project['status'],
    reason?: string
  ): Promise<void> {
    const validTransitions: Record<string, string[]> = {
      planning: ['active', 'archived'],
      active: ['paused', 'completed', 'archived'],
      paused: ['active', 'archived'],
      completed: ['archived'],
      archived: []
    };

    if (!validTransitions[this.state.status].includes(newStatus)) {
      throw new Error(
        `Invalid status transition from ${this.state.status} to ${newStatus}`
      );
    }

    const oldStatus = this.state.status;
    this.state.status = newStatus;
    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new ProjectStatusChangedEvent(
      this.state.id,
      oldStatus,
      newStatus,
      reason
    ));
  }

  async addCollaborator(
    userId: string,
    role: 'admin' | 'contributor' | 'viewer',
    addedBy: string
  ): Promise<void> {
    if (this.state.collaborators.some(c => c.userId === userId)) {
      throw new Error('User is already a collaborator');
    }

    this.state.collaborators.push({
      userId,
      role,
      addedAt: new Date()
    });

    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new ProjectCollaboratorAddedEvent(
      this.state.id,
      userId,
      role,
      addedBy
    ));
  }

  async removeCollaborator(
    userId: string,
    removedBy: string
  ): Promise<void> {
    const collaborator = this.state.collaborators.find(
      c => c.userId === userId
    );

    if (!collaborator) {
      throw new Error('User is not a collaborator');
    }

    if (collaborator.role === 'owner') {
      throw new Error('Cannot remove project owner');
    }

    this.state.collaborators = this.state.collaborators.filter(
      c => c.userId !== userId
    );

    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new ProjectCollaboratorRemovedEvent(
      this.state.id,
      userId,
      removedBy
    ));
  }

  // Event handling
  private addEvent(event: DomainEvent): void {
    this.events.push(event);
  }

  async commit(): Promise<void> {
    // Save state to database
    await this.saveState();

    // Save events
    for (const event of this.events) {
      await this.eventStore.saveEvent(event);
    }

    // Publish events
    await this.publishEvents();

    // Clear events
    this.events = [];
  }

  private async saveState(): Promise<void> {
    // Implementation to save aggregate state to DynamoDB
  }

  private async publishEvents(): Promise<void> {
    // Implementation to publish events to event bus
  }

  // Queries
  hasPermission(userId: string, permission: string): boolean {
    const collaborator = this.state.collaborators.find(
      c => c.userId === userId
    );

    if (!collaborator) {
      return false;
    }

    const permissions: Record<string, string[]> = {
      owner: ['read', 'write', 'delete', 'admin'],
      admin: ['read', 'write', 'admin'],
      contributor: ['read', 'write'],
      viewer: ['read']
    };

    return permissions[collaborator.role].includes(permission);
  }

  getState(): Readonly<Project> {
    return Object.freeze({ ...this.state });
  }
}

// backend/src/domain/aggregates/agent-aggregate.ts
export class AgentAggregate {
  private events: DomainEvent[] = [];
  private stateHistory: AgentState[] = [];

  constructor(
    private state: Agent,
    private eventStore: EventStore
  ) {}

  async start(taskId?: string): Promise<void> {
    if (this.state.status !== 'idle') {
      throw new Error(`Cannot start agent in ${this.state.status} state`);
    }

    this.state.status = 'initializing';
    this.state.state.currentTask = taskId;
    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new AgentStartedEvent(
      this.state.id,
      this.state.projectId,
      this.state.type,
      taskId
    ));

    // Initialize agent runtime
    await this.initializeRuntime();
    
    this.state.status = 'running';
    this.state.metrics.lastExecutionAt = new Date();
  }

  async completeTask(
    taskId: string,
    result: any,
    executionTime: number
  ): Promise<void> {
    if (this.state.state.currentTask !== taskId) {
      throw new Error('Task mismatch');
    }

    this.state.metrics.tasksCompleted++;
    this.state.metrics.totalExecutionTime += executionTime;
    this.state.metrics.averageExecutionTime = 
      this.state.metrics.totalExecutionTime / this.state.metrics.tasksCompleted;

    this.state.state.currentTask = undefined;
    this.state.status = 'idle';
    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new AgentCompletedTaskEvent(
      this.state.id,
      taskId,
      executionTime,
      result
    ));
  }

  async fail(error: Error, retryable: boolean = false): Promise<void> {
    this.state.status = 'failed';
    this.state.metrics.tasksFailed++;
    this.state.metrics.errorRate = 
      this.state.metrics.tasksFailed / 
      (this.state.metrics.tasksCompleted + this.state.metrics.tasksFailed);

    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new AgentFailedEvent(
      this.state.id,
      error.message,
      error.stack,
      retryable
    ));
  }

  async checkpoint(): Promise<string> {
    const checkpointId = uuidv4();
    const checkpoint = {
      id: checkpointId,
      timestamp: new Date(),
      state: {
        ...this.state.state,
        workingMemory: { ...this.state.state.workingMemory }
      }
    };

    this.state.state.checkpoints.push(checkpoint);
    
    // Keep only last 10 checkpoints
    if (this.state.state.checkpoints.length > 10) {
      this.state.state.checkpoints.shift();
    }

    this.state.updatedAt = new Date();
    this.state.version++;

    return checkpointId;
  }

  async restore(checkpointId: string): Promise<void> {
    const checkpoint = this.state.state.checkpoints.find(
      c => c.id === checkpointId
    );

    if (!checkpoint) {
      throw new Error(`Checkpoint ${checkpointId} not found`);
    }

    // Save current state to history
    this.stateHistory.push({ ...this.state.state });

    // Restore from checkpoint
    this.state.state = {
      ...checkpoint.state,
      checkpoints: this.state.state.checkpoints
    };

    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new AgentRestoredEvent(
      this.state.id,
      checkpointId
    ));
  }

  private async initializeRuntime(): Promise<void> {
    // Implementation to initialize agent runtime environment
  }

  private addEvent(event: DomainEvent): void {
    this.events.push(event);
  }

  async commit(): Promise<void> {
    // Similar to ProjectAggregate commit
  }
}
```

#### SubTask 2.4.4: ë„ë©”ì¸ ì„œë¹„ìŠ¤ êµ¬í˜„
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/domain/services/project-orchestration.service.ts
export class ProjectOrchestrationService {
  constructor(
    private projectRepo: ProjectRepository,
    private agentRepo: AgentRepository,
    private taskRepo: TaskRepository,
    private eventBus: EventBus
  ) {}

  async createProjectWithAgents(
    params: CreateProjectWithAgentsParams
  ): Promise<ProjectCreationResult> {
    const transaction = new DomainTransaction();

    try {
      // 1. Create project
      const project = await this.createProject(params.project, transaction);

      // 2. Create initial agents based on project type
      const agents = await this.createInitialAgents(
        project.id,
        project.type,
        transaction
      );

      // 3. Create initial task structure
      const tasks = await this.createInitialTasks(
        project.id,
        params.initialRequirements,
        transaction
      );

      // 4. Assign tasks to agents
      await this.assignTasksToAgents(tasks, agents, transaction);

      // 5. Commit transaction
      await transaction.commit();

      // 6. Publish project creation event
      await this.eventBus.publish(new ProjectInitializedEvent(
        project.id,
        agents.map(a => a.id),
        tasks.map(t => t.id)
      ));

      return {
        project,
        agents,
        tasks,
        success: true
      };
    } catch (error) {
      await transaction.rollback();
      throw error;
    }
  }

  private async createInitialAgents(
    projectId: string,
    projectType: string,
    transaction: DomainTransaction
  ): Promise<Agent[]> {
    const agentTypes = this.getRequiredAgentTypes(projectType);
    const agents: Agent[] = [];

    for (const agentType of agentTypes) {
      const agent = await this.agentRepo.create({
        projectId,
        type: agentType,
        name: `${agentType} for ${projectId}`,
        status: 'idle',
        configuration: this.getAgentConfiguration(agentType)
      }, transaction);

      agents.push(agent);
    }

    return agents;
  }

  private getRequiredAgentTypes(projectType: string): string[] {
    const agentTypeMap: Record<string, string[]> = {
      web: [
        'ProjectManagerAgent',
        'RequirementsAgent',
        'ArchitectAgent',
        'BackendAgent',
        'FrontendAgent',
        'DatabaseAgent',
        'TestingAgent',
        'DevOpsAgent'
      ],
      api: [
        'ProjectManagerAgent',
        'RequirementsAgent',
        'ArchitectAgent',
        'BackendAgent',
        'DatabaseAgent',
        'TestingAgent',
        'DocumentationAgent'
      ],
      mobile: [
        'ProjectManagerAgent',
        'RequirementsAgent',
        'ArchitectAgent',
        'FrontendAgent',
        'BackendAgent',
        'TestingAgent'
      ]
    };

    return agentTypeMap[projectType] || agentTypeMap.web;
  }
}

// backend/src/domain/services/agent-coordination.service.ts
export class AgentCoordinationService {
  private coordinationRules: CoordinationRule[] = [];

  constructor(
    private agentManager: AgentManager,
    private messageQueue: MessageQueue,
    private stateManager: StateManager
  ) {
    this.initializeCoordinationRules();
  }

  async coordinateAgents(
    context: CoordinationContext
  ): Promise<CoordinationResult> {
    // 1. Analyze current state
    const currentState = await this.analyzeCurrentState(context);

    // 2. Determine coordination strategy
    const strategy = this.selectCoordinationStrategy(currentState);

    // 3. Execute coordination
    const result = await this.executeCoordination(strategy, context);

    // 4. Update agent states
    await this.updateAgentStates(result);

    return result;
  }

  private async analyzeCurrentState(
    context: CoordinationContext
  ): Promise<SystemState> {
    const agentStates = await Promise.all(
      context.agentIds.map(id => this.agentManager.getAgentState(id))
    );

    const taskProgress = await this.calculateTaskProgress(context.taskIds);
    const dependencies = await this.analyzeDependencies(context);

    return {
      agents: agentStates,
      taskProgress,
      dependencies,
      bottlenecks: this.identifyBottlenecks(agentStates, dependencies)
    };
  }

  private selectCoordinationStrategy(
    state: SystemState
  ): CoordinationStrategy {
    // Rule-based strategy selection
    for (const rule of this.coordinationRules) {
      if (rule.matches(state)) {
        return rule.strategy;
      }
    }

    // Default strategy
    return new ParallelCoordinationStrategy();
  }

  private async executeCoordination(
    strategy: CoordinationStrategy,
    context: CoordinationContext
  ): Promise<CoordinationResult> {
    const plan = strategy.createPlan(context);
    const results: AgentExecutionResult[] = [];

    for (const step of plan.steps) {
      if (step.parallel) {
        const parallelResults = await this.executeParallelStep(step);
        results.push(...parallelResults);
      } else {
        const sequentialResult = await this.executeSequentialStep(step);
        results.push(sequentialResult);
      }
    }

    return {
      plan,
      results,
      success: results.every(r => r.success),
      duration: this.calculateTotalDuration(results)
    };
  }

  private initializeCoordinationRules(): void {
    this.coordinationRules = [
      {
        name: 'Sequential Dependencies',
        matches: (state) => state.dependencies.some(d => d.type === 'sequential'),
        strategy: new SequentialCoordinationStrategy()
      },
      {
        name: 'Resource Constraints',
        matches: (state) => state.bottlenecks.length > 0,
        strategy: new ResourceOptimizedStrategy()
      },
      {
        name: 'High Parallelism',
        matches: (state) => state.dependencies.every(d => d.type === 'parallel'),
        strategy: new ParallelCoordinationStrategy()
      }
    ];
  }
}

// backend/src/domain/services/task-assignment.service.ts
export class TaskAssignmentService {
  constructor(
    private agentCapabilities: AgentCapabilityRegistry,
    private workloadAnalyzer: WorkloadAnalyzer,
    private performanceTracker: PerformanceTracker
  ) {}

  async assignTaskToOptimalAgent(
    task: Task,
    availableAgents: Agent[]
  ): Promise<TaskAssignment> {
    // 1. Filter capable agents
    const capableAgents = await this.filterCapableAgents(
      task,
      availableAgents
    );

    if (capableAgents.length === 0) {
      throw new Error(`No capable agents found for task ${task.id}`);
    }

    // 2. Score agents
    const scores = await this.scoreAgents(task, capableAgents);

    // 3. Select optimal agent
    const optimalAgent = this.selectOptimalAgent(scores);

    // 4. Create assignment
    const assignment = await this.createAssignment(
      task,
      optimalAgent,
      scores.get(optimalAgent.id)!
    );

    // 5. Update workload
    await this.workloadAnalyzer.updateAgentWorkload(
      optimalAgent.id,
      task
    );

    return assignment;
  }

  private async filterCapableAgents(
    task: Task,
    agents: Agent[]
  ): Promise<Agent[]> {
    const capable: Agent[] = [];

    for (const agent of agents) {
      const capabilities = await this.agentCapabilities.getCapabilities(
        agent.type
      );

      if (this.taskMatchesCapabilities(task, capabilities)) {
        capable.push(agent);
      }
    }

    return capable;
  }

  private async scoreAgents(
    task: Task,
    agents: Agent[]
  ): Promise<Map<string, AgentScore>> {
    const scores = new Map<string, AgentScore>();

    for (const agent of agents) {
      const workload = await this.workloadAnalyzer.getAgentWorkload(
        agent.id
      );
      const performance = await this.performanceTracker.getAgentPerformance(
        agent.id,
        task.type
      );

      const score = this.calculateAgentScore({
        agent,
        task,
        workload,
        performance
      });

      scores.set(agent.id, score);
    }

    return scores;
  }

  private calculateAgentScore(params: {
    agent: Agent;
    task: Task;
    workload: AgentWorkload;
    performance: AgentPerformance;
  }): AgentScore {
    const weights = {
      availability: 0.3,
      expertise: 0.3,
      performance: 0.2,
      workload: 0.2
    };

    const availabilityScore = this.calculateAvailabilityScore(
      params.workload
    );
    const expertiseScore = this.calculateExpertiseScore(
      params.agent,
      params.task
    );
    const performanceScore = this.calculatePerformanceScore(
      params.performance
    );
    const workloadScore = this.calculateWorkloadScore(
      params.workload
    );

    const totalScore = 
      availabilityScore * weights.availability +
      expertiseScore * weights.expertise +
      performanceScore * weights.performance +
      workloadScore * weights.workload;

    return {
      agentId: params.agent.id,
      totalScore,
      breakdown: {
        availability: availabilityScore,
        expertise: expertiseScore,
        performance: performanceScore,
        workload: workloadScore
      }
    };
  }
}
```

---

### Task 2.5: ë°ì´í„° ê²€ì¦ ë° ìŠ¤í‚¤ë§ˆ ê´€ë¦¬

#### SubTask 2.5.1: ëŸ°íƒ€ì„ ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/validation/runtime-validator.ts
import { z, ZodError, ZodSchema } from 'zod';

export class RuntimeValidator {
  private schemas: Map<string, ZodSchema> = new Map();
  private validationStats: Map<string, ValidationStats> = new Map();

  // ìŠ¤í‚¤ë§ˆ ë“±ë¡
  registerSchema(name: string, schema: ZodSchema): void {
    this.schemas.set(name, schema);
    this.validationStats.set(name, {
      totalValidations: 0,
      successfulValidations: 0,
      failedValidations: 0,
      commonErrors: new Map()
    });
  }

  // ë°ì´í„° ê²€ì¦
  validate<T>(
    schemaName: string,
    data: unknown,
    options?: ValidationOptions
  ): ValidationResult<T> {
    const schema = this.schemas.get(schemaName);
    if (!schema) {
      throw new Error(`Schema '${schemaName}' not found`);
    }

    const stats = this.validationStats.get(schemaName)!;
    stats.totalValidations++;

    try {
      const validated = schema.parse(data) as T;
      stats.successfulValidations++;

      return {
        success: true,
        data: validated,
        errors: []
      };
    } catch (error) {
      stats.failedValidations++;

      if (error instanceof ZodError) {
        const errors = this.formatZodErrors(error);
        this.updateErrorStats(schemaName, errors);

        if (options?.throwOnError) {
          throw new ValidationError(schemaName, errors);
        }

        return {
          success: false,
          data: null,
          errors
        };
      }

      throw error;
    }
  }

  // ë°°ì¹˜ ê²€ì¦
  async validateBatch<T>(
    schemaName: string,
    items: unknown[],
    options?: BatchValidationOptions
  ): Promise<BatchValidationResult<T>> {
    const results: ValidationResult<T>[] = [];
    const validItems: T[] = [];
    const invalidItems: InvalidItem[] = [];

    const batchSize = options?.batchSize || 100;
    const chunks = this.chunkArray(items, batchSize);

    for (const chunk of chunks) {
      const chunkResults = await Promise.all(
        chunk.map((item, index) => {
          const result = this.validate<T>(schemaName, item);
          if (result.success) {
            validItems.push(result.data!);
          } else {
            invalidItems.push({
              index,
              item,
              errors: result.errors
            });
          }
          return result;
        })
      );

      results.push(...chunkResults);

      // ì¡°ê¸° ì¢…ë£Œ ì˜µì…˜
      if (options?.stopOnFirstError && invalidItems.length > 0) {
        break;
      }
    }

    return {
      totalItems: items.length,
      validItems,
      invalidItems,
      successRate: validItems.length / items.length,
      validationTime: Date.now()
    };
  }

  // ë™ì  ìŠ¤í‚¤ë§ˆ ìƒì„±
  createDynamicSchema(
    definition: SchemaDefinition
  ): ZodSchema {
    const shape: Record<string, any> = {};

    for (const [field, config] of Object.entries(definition.fields)) {
      let fieldSchema = this.createFieldSchema(config);

      if (config.required === false) {
        fieldSchema = fieldSchema.optional();
      }

      if (config.nullable) {
        fieldSchema = fieldSchema.nullable();
      }

      if (config.default !== undefined) {
        fieldSchema = fieldSchema.default(config.default);
      }

      shape[field] = fieldSchema;
    }

    return z.object(shape);
  }

  private createFieldSchema(config: FieldConfig): ZodSchema {
    switch (config.type) {
      case 'string':
        let stringSchema = z.string();
        if (config.min) stringSchema = stringSchema.min(config.min);
        if (config.max) stringSchema = stringSchema.max(config.max);
        if (config.pattern) stringSchema = stringSchema.regex(config.pattern);
        if (config.format === 'email') stringSchema = stringSchema.email();
        if (config.format === 'url') stringSchema = stringSchema.url();
        if (config.format === 'uuid') stringSchema = stringSchema.uuid();
        return stringSchema;

      case 'number':
        let numberSchema = z.number();
        if (config.min !== undefined) numberSchema = numberSchema.min(config.min);
        if (config.max !== undefined) numberSchema = numberSchema.max(config.max);
        if (config.integer) numberSchema = numberSchema.int();
        return numberSchema;

      case 'boolean':
        return z.boolean();

      case 'date':
        let dateSchema = z.date();
        if (config.min) dateSchema = dateSchema.min(new Date(config.min));
        if (config.max) dateSchema = dateSchema.max(new Date(config.max));
        return dateSchema;

      case 'array':
        const itemSchema = this.createFieldSchema(config.items!);
        let arraySchema = z.array(itemSchema);
        if (config.min !== undefined) arraySchema = arraySchema.min(config.min);
        if (config.max !== undefined) arraySchema = arraySchema.max(config.max);
        return arraySchema;

      case 'object':
        if (config.properties) {
          const shape: Record<string, ZodSchema> = {};
          for (const [key, value] of Object.entries(config.properties)) {
            shape[key] = this.createFieldSchema(value);
          }
          return z.object(shape);
        }
        return z.record(z.any());

      case 'enum':
        return z.enum(config.values as [string, ...string[]]);

      default:
        return z.any();
    }
  }

  // ê²€ì¦ í†µê³„
  getValidationStats(schemaName?: string): ValidationStats | Map<string, ValidationStats> {
    if (schemaName) {
      return this.validationStats.get(schemaName) || {
        totalValidations: 0,
        successfulValidations: 0,
        failedValidations: 0,
        commonErrors: new Map()
      };
    }
    return this.validationStats;
  }

  private formatZodErrors(error: ZodError): ValidationError[] {
    return error.errors.map(err => ({
      path: err.path.join('.'),
      message: err.message,
      code: err.code,
      expected: (err as any).expected,
      received: (err as any).received
    }));
  }

  private updateErrorStats(schemaName: string, errors: ValidationError[]): void {
    const stats = this.validationStats.get(schemaName)!;
    
    for (const error of errors) {
      const errorKey = `${error.path}:${error.code}`;
      const count = stats.commonErrors.get(errorKey) || 0;
      stats.commonErrors.set(errorKey, count + 1);
    }
  }

  private chunkArray<T>(array: T[], size: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
}

// ì»¤ìŠ¤í…€ ê²€ì¦ ê·œì¹™
export class CustomValidationRules {
  static readonly rules = new Map<string, ValidationRule>();

  static register(name: string, rule: ValidationRule): void {
    this.rules.set(name, rule);
  }

  static validate(ruleName: string, value: any, context?: any): boolean {
    const rule = this.rules.get(ruleName);
    if (!rule) {
      throw new Error(`Validation rule '${ruleName}' not found`);
    }
    return rule.validate(value, context);
  }
}

// ë„ë©”ì¸ë³„ ê²€ì¦ê¸°
export class DomainValidator extends RuntimeValidator {
  constructor() {
    super();
    this.registerDomainSchemas();
    this.registerCustomRules();
  }

  private registerDomainSchemas(): void {
    // User ë„ë©”ì¸
    this.registerSchema('User', UserSchema);
    this.registerSchema('UserUpdate', UserSchema.partial());
    
    // Project ë„ë©”ì¸
    this.registerSchema('Project', ProjectSchema);
    this.registerSchema('ProjectCreate', ProjectSchema.omit({ 
      id: true, 
      createdAt: true, 
      updatedAt: true 
    }));
    
    // Agent ë„ë©”ì¸
    this.registerSchema('Agent', AgentSchema);
    this.registerSchema('AgentConfiguration', AgentSchema.shape.configuration);
    
    // Task ë„ë©”ì¸
    this.registerSchema('Task', TaskSchema);
    this.registerSchema('TaskCreate', TaskSchema.omit({ 
      id: true, 
      version: true,
      createdAt: true,
      updatedAt: true 
    }));
  }

  private registerCustomRules(): void {
    // í”„ë¡œì íŠ¸ ì´ë¦„ ìœ ì¼ì„±
    CustomValidationRules.register('uniqueProjectName', {
      validate: async (name: string, context: { userId: string }) => {
        const exists = await this.checkProjectNameExists(name, context.userId);
        return !exists;
      },
      message: 'Project name already exists'
    });

    // ì—ì´ì „íŠ¸ íƒ€ì…ë³„ ì„¤ì • ê²€ì¦
    CustomValidationRules.register('validAgentConfig', {
      validate: (config: any, context: { agentType: string }) => {
        const requiredTools = this.getRequiredToolsForAgent(context.agentType);
        return requiredTools.every(tool => config.tools.includes(tool));
      },
      message: 'Agent configuration missing required tools'
    });

    // íƒœìŠ¤í¬ ì˜ì¡´ì„± ìˆœí™˜ ì°¸ì¡° ê²€ì¦
    CustomValidationRules.register('noCyclicDependencies', {
      validate: async (dependencies: any[], context: { taskId: string }) => {
        return !await this.hasCyclicDependency(context.taskId, dependencies);
      },
      message: 'Cyclic dependency detected'
    });
  }

  private async checkProjectNameExists(name: string, userId: string): Promise<boolean> {
    // Implementation
    return false;
  }

  private getRequiredToolsForAgent(agentType: string): string[] {
    const toolMap: Record<string, string[]> = {
      'BackendAgent': ['code-generator', 'test-runner', 'git'],
      'FrontendAgent': ['ui-builder', 'style-generator', 'bundler'],
      'DatabaseAgent': ['schema-designer', 'query-optimizer', 'migrator']
    };
    return toolMap[agentType] || [];
  }

  private async hasCyclicDependency(taskId: string, dependencies: any[]): Promise<boolean> {
    // Implementation
    return false;
  }
}
```

#### SubTask 2.5.2: ìŠ¤í‚¤ë§ˆ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/schema/version-manager.ts
export class SchemaVersionManager {
  private versions: Map<string, SchemaVersion[]> = new Map();
  private migrations: Map<string, Migration[]> = new Map();
  
  constructor(
    private storage: SchemaStorage,
    private validator: RuntimeValidator
  ) {}

  // ìŠ¤í‚¤ë§ˆ ë²„ì „ ë“±ë¡
  async registerVersion(
    entityName: string,
    version: SchemaVersion
  ): Promise<void> {
    const versions = this.versions.get(entityName) || [];
    
    // ë²„ì „ ì¤‘ë³µ í™•ì¸
    if (versions.some(v => v.version === version.version)) {
      throw new Error(
        `Schema version ${version.version} already exists for ${entityName}`
      );
    }

    // ë²„ì „ ê²€ì¦
    await this.validateSchemaVersion(version);

    // ì´ì „ ë²„ì „ê³¼ì˜ í˜¸í™˜ì„± í™•ì¸
    if (versions.length > 0) {
      const previousVersion = versions[versions.length - 1];
      await this.checkCompatibility(previousVersion, version);
    }

    versions.push(version);
    versions.sort((a, b) => this.compareVersions(a.version, b.version));
    this.versions.set(entityName, versions);

    // ìŠ¤í† ë¦¬ì§€ì— ì €ì¥
    await this.storage.saveSchemaVersion(entityName, version);
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±
  async createMigration(
    entityName: string,
    fromVersion: string,
    toVersion: string
  ): Promise<Migration> {
    const fromSchema = await this.getSchema(entityName, fromVersion);
    const toSchema = await this.getSchema(entityName, toVersion);

    const changes = this.detectSchemaChanges(fromSchema, toSchema);
    
    const migration: Migration = {
      id: uuidv4(),
      entityName,
      fromVersion,
      toVersion,
      changes,
      up: this.generateUpMigration(changes),
      down: this.generateDownMigration(changes),
      createdAt: new Date()
    };

    // ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦
    await this.validateMigration(migration);

    // ë§ˆì´ê·¸ë ˆì´ì…˜ ì €ì¥
    const migrations = this.migrations.get(entityName) || [];
    migrations.push(migration);
    this.migrations.set(entityName, migrations);

    return migration;
  }

  // ìŠ¤í‚¤ë§ˆ ë³€ê²½ ê°ì§€
  private detectSchemaChanges(
    fromSchema: SchemaDefinition,
    toSchema: SchemaDefinition
  ): SchemaChange[] {
    const changes: SchemaChange[] = [];

    // í•„ë“œ ì¶”ê°€ ê°ì§€
    for (const [field, config] of Object.entries(toSchema.fields)) {
      if (!fromSchema.fields[field]) {
        changes.push({
          type: 'ADD_FIELD',
          field,
          config
        });
      }
    }

    // í•„ë“œ ì œê±° ê°ì§€
    for (const field of Object.keys(fromSchema.fields)) {
      if (!toSchema.fields[field]) {
        changes.push({
          type: 'REMOVE_FIELD',
          field
        });
      }
    }

    // í•„ë“œ ë³€ê²½ ê°ì§€
    for (const [field, newConfig] of Object.entries(toSchema.fields)) {
      const oldConfig = fromSchema.fields[field];
      if (oldConfig && !this.isFieldConfigEqual(oldConfig, newConfig)) {
        changes.push({
          type: 'MODIFY_FIELD',
          field,
          oldConfig,
          newConfig
        });
      }
    }

    // ì¸ë±ìŠ¤ ë³€ê²½ ê°ì§€
    const indexChanges = this.detectIndexChanges(
      fromSchema.indexes || [],
      toSchema.indexes || []
    );
    changes.push(...indexChanges);

    return changes;
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
  async executeMigration(
    entityName: string,
    targetVersion: string,
    options?: MigrationOptions
  ): Promise<MigrationResult> {
    const currentVersion = await this.getCurrentVersion(entityName);
    const migrations = await this.getMigrationPath(
      entityName,
      currentVersion,
      targetVersion
    );

    const result: MigrationResult = {
      entityName,
      fromVersion: currentVersion,
      toVersion: targetVersion,
      migrationsApplied: [],
      success: true,
      errors: []
    };

    // ë“œë¼ì´ëŸ° ëª¨ë“œ
    if (options?.dryRun) {
      return this.simulateMigration(migrations, options);
    }

    // íŠ¸ëœì­ì…˜ ì‹œì‘
    const transaction = await this.storage.beginTransaction();

    try {
      for (const migration of migrations) {
        await this.applyMigration(migration, transaction, options);
        result.migrationsApplied.push(migration.id);
      }

      // ë²„ì „ ì—…ë°ì´íŠ¸
      await this.updateCurrentVersion(entityName, targetVersion, transaction);

      await transaction.commit();
    } catch (error) {
      await transaction.rollback();
      result.success = false;
      result.errors.push({
        migration: migrations[result.migrationsApplied.length]?.id,
        error: error.message
      });
    }

    return result;
  }

  // ìŠ¤í‚¤ë§ˆ ì§„í™” ì¶”ì 
  async trackSchemaEvolution(
    entityName: string
  ): Promise<SchemaEvolution> {
    const versions = this.versions.get(entityName) || [];
    const migrations = this.migrations.get(entityName) || [];

    const evolution: SchemaEvolution = {
      entityName,
      versions: versions.map(v => ({
        version: v.version,
        releaseDate: v.releaseDate,
        changes: v.changes,
        breaking: v.breaking
      })),
      totalVersions: versions.length,
      totalMigrations: migrations.length,
      timeline: this.createEvolutionTimeline(versions, migrations)
    };

    return evolution;
  }

  // ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± í™•ì¸
  private async checkCompatibility(
    oldVersion: SchemaVersion,
    newVersion: SchemaVersion
  ): Promise<CompatibilityResult> {
    const result: CompatibilityResult = {
      compatible: true,
      breaking: [],
      warnings: []
    };

    const changes = this.detectSchemaChanges(
      oldVersion.schema,
      newVersion.schema
    );

    for (const change of changes) {
      switch (change.type) {
        case 'REMOVE_FIELD':
          if (!change.config?.deprecated) {
            result.breaking.push({
              type: 'FIELD_REMOVED',
              field: change.field,
              message: `Field '${change.field}' was removed without deprecation`
            });
            result.compatible = false;
          }
          break;

        case 'MODIFY_FIELD':
          if (this.isBreakingFieldChange(change)) {
            result.breaking.push({
              type: 'FIELD_TYPE_CHANGED',
              field: change.field,
              message: `Field '${change.field}' type changed incompatibly`
            });
            result.compatible = false;
          }
          break;

        case 'ADD_FIELD':
          if (change.config?.required && !change.config?.default) {
            result.warnings.push({
              type: 'REQUIRED_FIELD_ADDED',
              field: change.field,
              message: `Required field '${change.field}' added without default`
            });
          }
          break;
      }
    }

    return result;
  }

  // ë²„ì „ ë¹„êµ
  private compareVersions(v1: string, v2: string): number {
    const parts1 = v1.split('.').map(Number);
    const parts2 = v2.split('.').map(Number);

    for (let i = 0; i < Math.max(parts1.length, parts2.length); i++) {
      const p1 = parts1[i] || 0;
      const p2 = parts2[i] || 0;
      
      if (p1 > p2) return 1;
      if (p1 < p2) return -1;
    }

    return 0;
  }
}

// ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ê¸°
export class MigrationExecutor {
  constructor(
    private dynamoDB: DynamoDBDocumentClient,
    private logger: Logger
  ) {}

  async applyMigration(
    migration: Migration,
    options?: ExecutionOptions
  ): Promise<void> {
    this.logger.info(`Applying migration ${migration.id}`, {
      entity: migration.entityName,
      from: migration.fromVersion,
      to: migration.toVersion
    });

    const batchSize = options?.batchSize || 1000;
    let lastEvaluatedKey: any;
    let processedCount = 0;

    do {
      // ë°ì´í„° ì½ê¸°
      const items = await this.scanItems(
        migration.entityName,
        batchSize,
        lastEvaluatedKey
      );

      if (items.length === 0) break;

      // ë³€í™˜ ì ìš©
      const transformedItems = await this.transformItems(
        items,
        migration
      );

      // ë°°ì¹˜ ì“°ê¸°
      await this.batchWriteItems(transformedItems);

      processedCount += items.length;
      lastEvaluatedKey = items[items.length - 1]?.SK;

      // ì§„í–‰ ìƒí™© ë¦¬í¬íŠ¸
      if (options?.onProgress) {
        options.onProgress({
          processed: processedCount,
          current: items.length,
          migration: migration.id
        });
      }

    } while (lastEvaluatedKey);

    this.logger.info(`Migration ${migration.id} completed`, {
      processedItems: processedCount
    });
  }

  private async transformItems(
    items: any[],
    migration: Migration
  ): Promise<any[]> {
    const transformed: any[] = [];

    for (const item of items) {
      try {
        const newItem = { ...item };

        for (const change of migration.changes) {
          switch (change.type) {
            case 'ADD_FIELD':
              newItem[change.field] = change.config.default ?? null;
              break;

            case 'REMOVE_FIELD':
              delete newItem[change.field];
              break;

            case 'MODIFY_FIELD':
              newItem[change.field] = await this.transformField(
                item[change.field],
                change.oldConfig,
                change.newConfig
              );
              break;

            case 'RENAME_FIELD':
              newItem[change.newField] = item[change.oldField];
              delete newItem[change.oldField];
              break;
          }
        }

        // ë²„ì „ ì—…ë°ì´íŠ¸
        newItem.SchemaVersion = migration.toVersion;
        newItem.UpdatedAt = new Date().toISOString();

        transformed.push(newItem);
      } catch (error) {
        this.logger.error(`Failed to transform item`, {
          item,
          migration: migration.id,
          error
        });
        throw error;
      }
    }

    return transformed;
  }
}
```

#### SubTask 2.5.3: ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
**ë‹´ë‹¹ì**: ë°ì´í„° í’ˆì§ˆ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/quality/data-quality-monitor.ts
export class DataQualityMonitor {
  private rules: Map<string, QualityRule[]> = new Map();
  private metrics: Map<string, QualityMetrics> = new Map();
  private alerts: AlertManager;

  constructor(
    private dataSource: DataSource,
    private notificationService: NotificationService
  ) {
    this.alerts = new AlertManager(notificationService);
    this.initializeDefaultRules();
  }

  // ë°ì´í„° í’ˆì§ˆ ê·œì¹™ ë“±ë¡
  registerRule(
    entityType: string,
    rule: QualityRule
  ): void {
    const rules = this.rules.get(entityType) || [];
    rules.push(rule);
    this.rules.set(entityType, rules);
  }

  // ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì‚¬
  async checkDataQuality(
    entityType: string,
    data: any
  ): Promise<QualityCheckResult> {
    const rules = this.rules.get(entityType) || [];
    const violations: QualityViolation[] = [];

    for (const rule of rules) {
      try {
        const passed = await rule.check(data);
        
        if (!passed) {
          violations.push({
            rule: rule.name,
            severity: rule.severity,
            message: rule.message,
            field: rule.field,
            value: data[rule.field]
          });
        }
      } catch (error) {
        violations.push({
          rule: rule.name,
          severity: 'error',
          message: `Rule execution failed: ${error.message}`,
          field: rule.field
        });
      }
    }

    const result: QualityCheckResult = {
      entityType,
      passed: violations.length === 0,
      violations,
      score: this.calculateQualityScore(violations),
      timestamp: new Date()
    };

    // ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    await this.updateMetrics(entityType, result);

    // ì‹¬ê°í•œ ìœ„ë°˜ ì‹œ ì•Œë¦¼
    if (violations.some(v => v.severity === 'critical')) {
      await this.alerts.sendCriticalAlert(entityType, violations);
    }

    return result;
  }

  // ë°°ì¹˜ í’ˆì§ˆ ë¶„ì„
  async analyzeBatchQuality(
    entityType: string,
    timeRange: TimeRange
  ): Promise<BatchQualityReport> {
    const items = await this.dataSource.queryByTimeRange(
      entityType,
      timeRange
    );

    const results: QualityCheckResult[] = [];
    const fieldStats: Map<string, FieldStatistics> = new Map();

    // ê° í•­ëª© ê²€ì‚¬
    for (const item of items) {
      const result = await this.checkDataQuality(entityType, item);
      results.push(result);
      
      // í•„ë“œë³„ í†µê³„ ìˆ˜ì§‘
      this.collectFieldStatistics(item, fieldStats);
    }

    // ì´ìƒì¹˜ ê°ì§€
    const anomalies = await this.detectAnomalies(fieldStats);

    // í’ˆì§ˆ íŠ¸ë Œë“œ ë¶„ì„
    const trends = await this.analyzeQualityTrends(
      entityType,
      results,
      timeRange
    );

    return {
      entityType,
      timeRange,
      totalItems: items.length,
      qualityScore: this.calculateAverageScore(results),
      violations: this.aggregateViolations(results),
      fieldStatistics: Array.from(fieldStats.values()),
      anomalies,
      trends,
      recommendations: this.generateRecommendations(results, anomalies)
    };
  }

  // ë°ì´í„° í”„ë¡œíŒŒì¼ë§
  async profileData(
    entityType: string,
    sampleSize?: number
  ): Promise<DataProfile> {
    const sample = await this.dataSource.getSample(
      entityType,
      sampleSize || 10000
    );

    const profile: DataProfile = {
      entityType,
      sampleSize: sample.length,
      fields: new Map(),
      relationships: [],
      patterns: []
    };

    // ê° í•„ë“œ ë¶„ì„
    for (const field of this.getFields(sample)) {
      const fieldProfile = await this.profileField(field, sample);
      profile.fields.set(field, fieldProfile);
    }

    // ê´€ê³„ ë¶„ì„
    profile.relationships = await this.analyzeRelationships(sample);

    // íŒ¨í„´ ê°ì§€
    profile.patterns = await this.detectPatterns(sample);

    return profile;
  }

  private async profileField(
    fieldName: string,
    data: any[]
  ): Promise<FieldProfile> {
    const values = data.map(item => item[fieldName]);
    const nonNullValues = values.filter(v => v != null);

    const profile: FieldProfile = {
      name: fieldName,
      type: this.inferFieldType(nonNullValues),
      nullable: values.length > nonNullValues.length,
      uniqueCount: new Set(nonNullValues).size,
      nullCount: values.length - nonNullValues.length,
      statistics: {}
    };

    // íƒ€ì…ë³„ í†µê³„
    switch (profile.type) {
      case 'number':
        profile.statistics = this.calculateNumericStats(nonNullValues);
        break;
      case 'string':
        profile.statistics = this.calculateStringStats(nonNullValues);
        break;
      case 'date':
        profile.statistics = this.calculateDateStats(nonNullValues);
        break;
    }

    // ë¶„í¬ ë¶„ì„
    profile.distribution = this.analyzeDistribution(nonNullValues);

    return profile;
  }

  // ì´ìƒì¹˜ ê°ì§€
  private async detectAnomalies(
    fieldStats: Map<string, FieldStatistics>
  ): Promise<Anomaly[]> {
    const anomalies: Anomaly[] = [];

    for (const [field, stats] of fieldStats) {
      // IQR ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ ê°ì§€
      if (stats.type === 'numeric') {
        const iqr = stats.q3 - stats.q1;
        const lowerBound = stats.q1 - 1.5 * iqr;
        const upperBound = stats.q3 + 1.5 * iqr;

        const outliers = stats.values.filter(
          v => v < lowerBound || v > upperBound
        );

        if (outliers.length > 0) {
          anomalies.push({
            field,
            type: 'outlier',
            values: outliers,
            threshold: { lower: lowerBound, upper: upperBound },
            severity: outliers.length / stats.values.length > 0.1 ? 
              'high' : 'medium'
          });
        }
      }

      // íŒ¨í„´ ì´ìƒ ê°ì§€
      if (stats.type === 'string') {
        const patterns = this.detectStringPatterns(stats.values);
        const violations = stats.values.filter(
          v => !patterns.some(p => p.test(v))
        );

        if (violations.length > 0) {
          anomalies.push({
            field,
            type: 'pattern_violation',
            values: violations.slice(0, 10), // ìƒ˜í”Œë§Œ
            severity: 'medium'
          });
        }
      }
    }

    return anomalies;
  }

  // í’ˆì§ˆ íŠ¸ë Œë“œ ë¶„ì„
  private async analyzeQualityTrends(
    entityType: string,
    results: QualityCheckResult[],
    timeRange: TimeRange
  ): Promise<QualityTrend[]> {
    const trends: QualityTrend[] = [];

    // ì‹œê°„ë³„ ê·¸ë£¹í™”
    const hourlyGroups = this.groupByHour(results);

    for (const [hour, group] of hourlyGroups) {
      const score = this.calculateAverageScore(group);
      const previousScore = await this.getPreviousScore(
        entityType,
        hour
      );

      trends.push({
        timestamp: hour,
        score,
        change: score - previousScore,
        violationCount: group.reduce(
          (sum, r) => sum + r.violations.length,
          0
        ),
        trend: this.calculateTrend(score, previousScore)
      });
    }

    return trends;
  }

  // ê¸°ë³¸ í’ˆì§ˆ ê·œì¹™ ì´ˆê¸°í™”
  private initializeDefaultRules(): void {
    // ê³µí†µ ê·œì¹™
    const commonRules: QualityRule[] = [
      {
        name: 'not_null_id',
        field: 'id',
        severity: 'critical',
        message: 'ID cannot be null',
        check: async (data) => data.id != null
      },
      {
        name: 'valid_timestamps',
        field: 'createdAt',
        severity: 'high',
        message: 'Invalid timestamp',
        check: async (data) => {
          if (!data.createdAt) return false;
          const date = new Date(data.createdAt);
          return !isNaN(date.getTime()) && date <= new Date();
        }
      },
      {
        name: 'version_consistency',
        field: 'version',
        severity: 'medium',
        message: 'Version must be positive',
        check: async (data) => data.version > 0
      }
    ];

    // ëª¨ë“  ì—”í‹°í‹°ì— ê³µí†µ ê·œì¹™ ì ìš©
    for (const entityType of ['User', 'Project', 'Agent', 'Task']) {
      this.rules.set(entityType, [...commonRules]);
    }

    // ì—”í‹°í‹°ë³„ íŠ¹í™” ê·œì¹™
    this.registerRule('User', {
      name: 'valid_email',
      field: 'email',
      severity: 'high',
      message: 'Invalid email format',
      check: async (data) => /^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(data.email)
    });

    this.registerRule('Project', {
      name: 'valid_status',
      field: 'status',
      severity: 'high',
      message: 'Invalid project status',
      check: async (data) => 
        ['planning', 'active', 'paused', 'completed', 'archived']
          .includes(data.status)
    });

    this.registerRule('Agent', {
      name: 'valid_agent_type',
      field: 'type',
      severity: 'critical',
      message: 'Invalid agent type',
      check: async (data) => 
        data.type && data.type.endsWith('Agent')
    });
  }

  // í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
  private calculateQualityScore(violations: QualityViolation[]): number {
    if (violations.length === 0) return 100;

    const weights = {
      critical: 10,
      high: 5,
      medium: 2,
      low: 1
    };

    const totalPenalty = violations.reduce(
      (sum, v) => sum + (weights[v.severity] || 0),
      0
    );

    return Math.max(0, 100 - totalPenalty);
  }

  // ê¶Œì¥ì‚¬í•­ ìƒì„±
  private generateRecommendations(
    results: QualityCheckResult[],
    anomalies: Anomaly[]
  ): Recommendation[] {
    const recommendations: Recommendation[] = [];

    // ë¹ˆë²ˆí•œ ìœ„ë°˜ ë¶„ì„
    const violationCounts = new Map<string, number>();
    for (const result of results) {
      for (const violation of result.violations) {
        const count = violationCounts.get(violation.rule) || 0;
        violationCounts.set(violation.rule, count + 1);
      }
    }

    // ìƒìœ„ ìœ„ë°˜ì— ëŒ€í•œ ê¶Œì¥ì‚¬í•­
    for (const [rule, count] of violationCounts) {
      if (count > results.length * 0.1) { // 10% ì´ìƒ
        recommendations.push({
          type: 'validation',
          priority: 'high',
          title: `Frequent ${rule} violations`,
          description: `${count} items failed ${rule} validation`,
          action: `Review and update ${rule} validation logic or data source`
        });
      }
    }

    // ì´ìƒì¹˜ì— ëŒ€í•œ ê¶Œì¥ì‚¬í•­
    for (const anomaly of anomalies) {
      if (anomaly.severity === 'high') {
        recommendations.push({
          type: 'anomaly',
          priority: 'high',
          title: `High number of outliers in ${anomaly.field}`,
          description: `${anomaly.values.length} outliers detected`,
          action: 'Investigate data source for potential issues'
        });
      }
    }

    return recommendations;
  }
}

// ë°ì´í„° í’ˆì§ˆ ëŒ€ì‹œë³´ë“œ
export class DataQualityDashboard {
  constructor(
    private monitor: DataQualityMonitor,
    private storage: MetricsStorage
  ) {}

  async generateDashboard(
    timeRange: TimeRange
  ): Promise<DashboardData> {
    const entities = ['User', 'Project', 'Agent', 'Task'];
    const entityMetrics: EntityMetrics[] = [];

    for (const entity of entities) {
      const report = await this.monitor.analyzeBatchQuality(
        entity,
        timeRange
      );

      entityMetrics.push({
        entity,
        score: report.qualityScore,
        violations: report.violations.length,
        anomalies: report.anomalies.length,
        trend: report.trends[report.trends.length - 1]?.trend || 'stable'
      });
    }

    return {
      timeRange,
      overallScore: this.calculateOverallScore(entityMetrics),
      entityMetrics,
      alerts: await this.getRecentAlerts(timeRange),
      trends: await this.getQualityTrends(timeRange),
      recommendations: await this.getTopRecommendations()
    };
  }
}
```

#### SubTask 2.5.4: ìë™ ìŠ¤í‚¤ë§ˆ ë¬¸ì„œí™”
**ë‹´ë‹¹ì**: ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±ì & ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/documentation/schema-documenter.ts
export class SchemaDocumenter {
  private templates: Map<string, DocumentTemplate> = new Map();
  
  constructor(
    private schemaRegistry: SchemaRegistry,
    private outputPath: string
  ) {
    this.initializeTemplates();
  }

  // ìŠ¤í‚¤ë§ˆ ë¬¸ì„œ ìë™ ìƒì„±
  async generateDocumentation(
    options?: DocumentationOptions
  ): Promise<void> {
    const schemas = await this.schemaRegistry.getAllSchemas();
    
    // ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„±
    if (options?.formats?.includes('markdown') !== false) {
      await this.generateMarkdownDocs(schemas);
    }

    // HTML ë¬¸ì„œ ìƒì„±
    if (options?.formats?.includes('html')) {
      await this.generateHtmlDocs(schemas);
    }

    // OpenAPI ìŠ¤í™ ìƒì„±
    if (options?.formats?.includes('openapi')) {
      await this.generateOpenApiSpec(schemas);
    }

    // GraphQL ìŠ¤í‚¤ë§ˆ ìƒì„±
    if (options?.formats?.includes('graphql')) {
      await this.generateGraphQLSchema(schemas);
    }

    // ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
    if (options?.includeDiagrams) {
      await this.generateDiagrams(schemas);
    }
  }

  // ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„±
  private async generateMarkdownDocs(
    schemas: SchemaDefinition[]
  ): Promise<void> {
    const toc: string[] = ['# Data Model Documentation\n'];
    const content: string[] = [];

    // ê°œìš” ì„¹ì…˜
    content.push(await this.generateOverview(schemas));

    // ê° ìŠ¤í‚¤ë§ˆë³„ ë¬¸ì„œ
    for (const schema of schemas) {
      const doc = await this.generateSchemaMarkdown(schema);
      content.push(doc);
      toc.push(`- [${schema.name}](#${schema.name.toLowerCase()})`);
    }

    // ê´€ê³„ ë‹¤ì´ì–´ê·¸ë¨
    content.push('\n## Entity Relationships\n');
    content.push(await this.generateRelationshipDiagram(schemas));

    // íŒŒì¼ ì €ì¥
    const fullContent = [...toc, '\n---\n', ...content].join('\n');
    await fs.writeFile(
      path.join(this.outputPath, 'data-model.md'),
      fullContent
    );
  }

  // ê°œë³„ ìŠ¤í‚¤ë§ˆ ë§ˆí¬ë‹¤ìš´ ìƒì„±
  private async generateSchemaMarkdown(
    schema: SchemaDefinition
  ): Promise<string> {
    const sections: string[] = [];

    // í—¤ë”
    sections.push(`## ${schema.name}`);
    sections.push(`\n${schema.description || 'No description provided.'}\n`);

    // ë©”íƒ€ë°ì´í„°
    if (schema.metadata) {
      sections.push('### Metadata');
      sections.push(`- **Version**: ${schema.metadata.version}`);
      sections.push(`- **Last Updated**: ${schema.metadata.lastUpdated}`);
      if (schema.metadata.author) {
        sections.push(`- **Author**: ${schema.metadata.author}`);
      }
      sections.push('');
    }

    // í•„ë“œ í…Œì´ë¸”
    sections.push('### Fields\n');
    sections.push(this.generateFieldTable(schema.fields));

    // ì¸ë±ìŠ¤
    if (schema.indexes && schema.indexes.length > 0) {
      sections.push('\n### Indexes\n');
      sections.push(this.generateIndexTable(schema.indexes));
    }

    // ê²€ì¦ ê·œì¹™
    if (schema.validations && schema.validations.length > 0) {
      sections.push('\n### Validation Rules\n');
      for (const validation of schema.validations) {
        sections.push(`- **${validation.rule}**: ${validation.description}`);
      }
    }

    // ì˜ˆì œ
    if (schema.examples && schema.examples.length > 0) {
      sections.push('\n### Examples\n');
      for (const example of schema.examples) {
        sections.push('```json');
        sections.push(JSON.stringify(example, null, 2));
        sections.push('```\n');
      }
    }

    // ê´€ë ¨ ì—”í‹°í‹°
    const relationships = this.findRelationships(schema);
    if (relationships.length > 0) {
      sections.push('\n### Relationships\n');
      for (const rel of relationships) {
        sections.push(`- **${rel.type}** ${rel.target} via \`${rel.field}\``);
      }
    }

    return sections.join('\n');
  }

  // í•„ë“œ í…Œì´ë¸” ìƒì„±
  private generateFieldTable(fields: Record<string, FieldConfig>): string {
    const rows: string[] = [
      '| Field | Type | Required | Description | Constraints |',
      '|-------|------|----------|-------------|-------------|'
    ];

    for (const [name, config] of Object.entries(fields)) {
      const required = config.required !== false ? 'âœ“' : '';
      const constraints = this.formatConstraints(config);
      const description = config.description || '-';
      
      rows.push(
        `| \`${name}\` | ${config.type} | ${required} | ${description} | ${constraints} |`
      );
    }

    return rows.join('\n');
  }

  // OpenAPI ìŠ¤í™ ìƒì„±
  private async generateOpenApiSpec(
    schemas: SchemaDefinition[]
  ): Promise<void> {
    const spec: any = {
      openapi: '3.0.0',
      info: {
        title: 'T-Developer Data Models',
        version: '1.0.0',
        description: 'Data model definitions for T-Developer'
      },
      components: {
        schemas: {}
      }
    };

    for (const schema of schemas) {
      spec.components.schemas[schema.name] = 
        this.convertToOpenApiSchema(schema);
    }

    await fs.writeFile(
      path.join(this.outputPath, 'openapi-schemas.json'),
      JSON.stringify(spec, null, 2)
    );
  }

  // GraphQL ìŠ¤í‚¤ë§ˆ ìƒì„±
  private async generateGraphQLSchema(
    schemas: SchemaDefinition[]
  ): Promise<void> {
    const types: string[] = [];

    for (const schema of schemas) {
      types.push(this.convertToGraphQLType(schema));
    }

    // ì¿¼ë¦¬ íƒ€ì… ì¶”ê°€
    types.push(this.generateGraphQLQueries(schemas));

    // ë®¤í…Œì´ì…˜ íƒ€ì… ì¶”ê°€
    types.push(this.generateGraphQLMutations(schemas));

    const fullSchema = types.join('\n\n');
    await fs.writeFile(
      path.join(this.outputPath, 'schema.graphql'),
      fullSchema
    );
  }

  // GraphQL íƒ€ì… ë³€í™˜
  private convertToGraphQLType(schema: SchemaDefinition): string {
    const fields: string[] = [];

    for (const [name, config] of Object.entries(schema.fields)) {
      const type = this.mapToGraphQLType(config);
      const required = config.required !== false ? '!' : '';
      const description = config.description ? 
        `  "${config.description}"` : '';
      
      if (description) {
        fields.push(description);
      }
      fields.push(`  ${name}: ${type}${required}`);
    }

    return `type ${schema.name} {
${fields.join('\n')}
}`;
  }

  // ER ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
  private async generateRelationshipDiagram(
    schemas: SchemaDefinition[]
  ): Promise<string> {
    const mermaid: string[] = ['```mermaid', 'erDiagram'];

    // ì—”í‹°í‹° ì •ì˜
    for (const schema of schemas) {
      const fields = Object.entries(schema.fields)
        .map(([name, config]) => 
          `    ${config.type} ${name}${config.required !== false ? '' : '?'}`
        )
        .join('\n');
      
      mermaid.push(`  ${schema.name} {`);
      mermaid.push(fields);
      mermaid.push('  }');
    }

    // ê´€ê³„ ì •ì˜
    for (const schema of schemas) {
      const relationships = this.findRelationships(schema);
      for (const rel of relationships) {
        const cardinality = this.determineCardinality(rel);
        mermaid.push(`  ${schema.name} ${cardinality} ${rel.target} : "${rel.field}"`);
      }
    }

    mermaid.push('```');
    return mermaid.join('\n');
  }

  // ëŒ€í™”í˜• ë¬¸ì„œ ìƒì„±
  private async generateInteractiveDocs(
    schemas: SchemaDefinition[]
  ): Promise<void> {
    const html = `
<!DOCTYPE html>
<html>
<head>
  <title>T-Developer Data Model Explorer</title>
  <style>
    ${await this.loadStyles()}
  </style>
</head>
<body>
  <div id="app">
    <nav class="sidebar">
      ${this.generateNavigation(schemas)}
    </nav>
    <main class="content">
      ${schemas.map(s => this.generateInteractiveSchema(s)).join('')}
    </main>
  </div>
  <script>
    ${await this.loadInteractiveScript()}
  </script>
</body>
</html>`;

    await fs.writeFile(
      path.join(this.outputPath, 'interactive-docs.html'),
      html
    );
  }

  // ìŠ¤í‚¤ë§ˆ ë³€ê²½ ë¡œê·¸ ìƒì„±
  async generateChangeLog(
    fromVersion: string,
    toVersion: string
  ): Promise<string> {
    const changes = await this.schemaRegistry.getChangesBetweenVersions(
      fromVersion,
      toVersion
    );

    const sections: string[] = [
      `# Schema Change Log (${fromVersion} â†’ ${toVersion})`,
      `\n## Summary`,
      `- **Breaking Changes**: ${changes.breaking.length}`,
      `- **New Features**: ${changes.additions.length}`,
      `- **Modifications**: ${changes.modifications.length}`,
      `- **Deprecations**: ${changes.deprecations.length}`,
      `\n---\n`
    ];

    if (changes.breaking.length > 0) {
      sections.push('## âš ï¸ Breaking Changes\n');
      for (const change of changes.breaking) {
        sections.push(`- **${change.entity}.${change.field}**: ${change.description}`);
        if (change.migration) {
          sections.push(`  - Migration: \`${change.migration}\``);
        }
      }
      sections.push('');
    }

    if (changes.additions.length > 0) {
      sections.push('## âœ¨ New Features\n');
      for (const addition of changes.additions) {
        sections.push(`- Added \`${addition.entity}.${addition.field}\` (${addition.type})`);
        if (addition.description) {
          sections.push(`  - ${addition.description}`);
        }
      }
      sections.push('');
    }

    return sections.join('\n');
  }

  // API ì‚¬ìš© ì˜ˆì œ ìƒì„±
  private generateApiExamples(schema: SchemaDefinition): string {
    const examples: string[] = [
      `### API Usage Examples for ${schema.name}\n`
    ];

    // Create ì˜ˆì œ
    examples.push('#### Create');
    examples.push('```typescript');
    examples.push(`const new${schema.name} = await create${schema.name}({`);
    for (const [field, config] of Object.entries(schema.fields)) {
      if (config.required !== false && !config.computed) {
        const value = this.generateExampleValue(config);
        examples.push(`  ${field}: ${value},`);
      }
    }
    examples.push('});');
    examples.push('```\n');

    // Query ì˜ˆì œ
    examples.push('#### Query');
    examples.push('```typescript');
    examples.push(`const ${schema.name.toLowerCase()}s = await query${schema.name}s({`);
    examples.push(`  filter: { status: 'active' },`);
    examples.push(`  sort: { createdAt: 'desc' },`);
    examples.push(`  limit: 10`);
    examples.push('});');
    examples.push('```\n');

    return examples.join('\n');
  }
}
```

---

### Task 2.6: ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ

#### SubTask 2.6.1: ë§ˆì´ê·¸ë ˆì´ì…˜ í”„ë ˆì„ì›Œí¬ êµ¬ì¶•
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/migration/migration-framework.ts
export abstract class Migration {
  abstract readonly id: string;
  abstract readonly name: string;
  abstract readonly version: string;
  abstract readonly description: string;
  
  abstract up(context: MigrationContext): Promise<void>;
  abstract down(context: MigrationContext): Promise<void>;
  
  async validate(context: MigrationContext): Promise<ValidationResult> {
    // ê¸°ë³¸ ê²€ì¦ ë¡œì§
    return { valid: true };
  }
  
  async estimate(context: MigrationContext): Promise<MigrationEstimate> {
    // ì˜ˆìƒ ì‹œê°„ ë° ë¦¬ì†ŒìŠ¤ ê³„ì‚°
    return {
      estimatedTime: 0,
      estimatedItems: 0,
      requiredResources: {}
    };
  }
}

export class MigrationRunner {
  private migrations: Map<string, Migration> = new Map();
  private history: MigrationHistory;
  private lock: DistributedLock;
  
  constructor(
    private context: MigrationContext,
    private options: MigrationOptions
  ) {
    this.history = new MigrationHistory(context.dynamoDB);
    this.lock = new DistributedLock(context.dynamoDB);
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ë“±ë¡
  register(migration: Migration): void {
    if (this.migrations.has(migration.id)) {
      throw new Error(`Migration ${migration.id} already registered`);
    }
    this.migrations.set(migration.id, migration);
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
  async run(targetVersion?: string): Promise<MigrationResult> {
    const lockId = await this.acquireLock();
    
    try {
      // í˜„ì¬ ë²„ì „ í™•ì¸
      const currentVersion = await this.history.getCurrentVersion();
      
      // ì‹¤í–‰í•  ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ì •
      const pendingMigrations = await this.getPendingMigrations(
        currentVersion,
        targetVersion
      );

      if (pendingMigrations.length === 0) {
        return {
          success: true,
          message: 'No migrations to run',
          migrationsRun: []
        };
      }

      // ê²€ì¦
      if (this.options.validate) {
        await this.validateMigrations(pendingMigrations);
      }

      // ë“œë¼ì´ëŸ°
      if (this.options.dryRun) {
        return await this.dryRun(pendingMigrations);
      }

      // ì‹¤ì œ ì‹¤í–‰
      return await this.executeMigrations(pendingMigrations);
      
    } finally {
      await this.releaseLock(lockId);
    }
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
  private async executeMigrations(
    migrations: Migration[]
  ): Promise<MigrationResult> {
    const results: MigrationExecutionResult[] = [];
    
    for (const migration of migrations) {
      const startTime = Date.now();
      
      try {
        // ì‚¬ì „ ê²€ì¦
        const validation = await migration.validate(this.context);
        if (!validation.valid) {
          throw new Error(`Validation failed: ${validation.errors.join(', ')}`);
        }

        // ë°±ì—… ìƒì„±
        if (this.options.backup) {
          await this.createBackup(migration.id);
        }

        // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
        await this.executeWithProgress(migration);

        // íˆìŠ¤í† ë¦¬ ê¸°ë¡
        await this.history.recordMigration({
          id: migration.id,
          version: migration.version,
          executedAt: new Date(),
          duration: Date.now() - startTime,
          status: 'completed'
        });

        results.push({
          migration: migration.id,
          status: 'success',
          duration: Date.now() - startTime
        });

      } catch (error) {
        // ë¡¤ë°±
        if (this.options.rollbackOnError) {
          await this.rollback(migration);
        }

        // ì‹¤íŒ¨ ê¸°ë¡
        await this.history.recordMigration({
          id: migration.id,
          version: migration.version,
          executedAt: new Date(),
          duration: Date.now() - startTime,
          status: 'failed',
          error: error.message
        });

        results.push({
          migration: migration.id,
          status: 'failed',
          error: error.message,
          duration: Date.now() - startTime
        });

        if (!this.options.continueOnError) {
          break;
        }
      }
    }

    return {
      success: results.every(r => r.status === 'success'),
      migrationsRun: results.map(r => r.migration),
      results
    };
  }

  // ì§„í–‰ ìƒí™© ì¶”ì 
  private async executeWithProgress(migration: Migration): Promise<void> {
    const progressTracker = new ProgressTracker();
    
    const contextWithProgress = {
      ...this.context,
      progress: progressTracker
    };

    // ì§„í–‰ ìƒí™© ë¦¬í¬í„° ì‹œì‘
    const reporter = setInterval(() => {
      const progress = progressTracker.getProgress();
      this.options.onProgress?.(migration.id, progress);
    }, 1000);

    try {
      await migration.up(contextWithProgress);
    } finally {
      clearInterval(reporter);
    }
  }

  // ë¡¤ë°±
  async rollback(
    steps: number = 1
  ): Promise<RollbackResult> {
    const lockId = await this.acquireLock();
    
    try {
      const executedMigrations = await this.history.getExecutedMigrations();
      const toRollback = executedMigrations.slice(-steps);

      const results: RollbackExecutionResult[] = [];

      for (const record of toRollback.reverse()) {
        const migration = this.migrations.get(record.id);
        
        if (!migration) {
          results.push({
            migration: record.id,
            status: 'skipped',
            reason: 'Migration not found'
          });
          continue;
        }

        try {
          await migration.down(this.context);
          
          await this.history.removeMigration(record.id);
          
          results.push({
            migration: record.id,
            status: 'success'
          });
        } catch (error) {
          results.push({
            migration: record.id,
            status: 'failed',
            error: error.message
          });
          
          if (!this.options.continueOnError) {
            break;
          }
        }
      }

      return {
        success: results.every(r => r.status === 'success'),
        rollbackCount: results.filter(r => r.status === 'success').length,
        results
      };
      
    } finally {
      await this.releaseLock(lockId);
    }
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸
  async status(): Promise<MigrationStatus> {
    const currentVersion = await this.history.getCurrentVersion();
    const executedMigrations = await this.history.getExecutedMigrations();
    const pendingMigrations = await this.getPendingMigrations(currentVersion);

    return {
      currentVersion,
      executedCount: executedMigrations.length,
      pendingCount: pendingMigrations.length,
      executedMigrations: executedMigrations.map(m => ({
        id: m.id,
        version: m.version,
        executedAt: m.executedAt,
        duration: m.duration
      })),
      pendingMigrations: pendingMigrations.map(m => ({
        id: m.id,
        version: m.version,
        description: m.description
      }))
    };
  }

  // ë¶„ì‚° ì ê¸ˆ íšë“
  private async acquireLock(): Promise<string> {
    const lockId = uuidv4();
    const acquired = await this.lock.acquire(
      'migration-lock',
      lockId,
      this.options.lockTimeout || 300000 // 5ë¶„
    );

    if (!acquired) {
      throw new Error('Failed to acquire migration lock');
    }

    return lockId;
  }

  private async releaseLock(lockId: string): Promise<void> {
    await this.lock.release('migration-lock', lockId);
  }
}

// ë§ˆì´ê·¸ë ˆì´ì…˜ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
export class MigrationHistory {
  constructor(
    private dynamoDB: DynamoDBDocumentClient,
    private tableName: string = 'MigrationHistory'
  ) {}

  async getCurrentVersion(): Promise<string | null> {
    const result = await this.dynamoDB.send(new QueryCommand({
      TableName: this.tableName,
      KeyConditionExpression: 'PK = :pk',
      ExpressionAttributeValues: {
        ':pk': 'MIGRATION#CURRENT'
      },
      ScanIndexForward: false,
      Limit: 1
    }));

    return result.Items?.[0]?.version || null;
  }

  async getExecutedMigrations(): Promise<MigrationRecord[]> {
    const result = await this.dynamoDB.send(new QueryCommand({
      TableName: this.tableName,
      KeyConditionExpression: 'PK = :pk',
      ExpressionAttributeValues: {
        ':pk': 'MIGRATION#HISTORY'
      },
      ScanIndexForward: false
    }));

    return result.Items || [];
  }

  async recordMigration(record: MigrationRecord): Promise<void> {
    await this.dynamoDB.send(new TransactWriteCommand({
      TransactItems: [
        {
          Put: {
            TableName: this.tableName,
            Item: {
              PK: 'MIGRATION#HISTORY',
              SK: `${record.executedAt.toISOString()}#${record.id}`,
              ...record
            }
          }
        },
        {
          Update: {
            TableName: this.tableName,
            Key: {
              PK: 'MIGRATION#CURRENT',
              SK: 'VERSION'
            },
            UpdateExpression: 'SET version = :version, updatedAt = :now',
            ExpressionAttributeValues: {
              ':version': record.version,
              ':now': new Date().toISOString()
            }
          }
        }
      ]
    }));
  }
}
```

#### SubTask 2.6.2: ëŒ€ìš©ëŸ‰ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬
**ë‹´ë‹¹ì**: ë¹…ë°ì´í„° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/migration/bulk-migration.ts
export class BulkDataMigration {
  private workers: Worker[] = [];
  private progressTracker: ProgressTracker;
  private errorHandler: ErrorHandler;
  
  constructor(
    private source: DataSource,
    private target: DataSource,
    private options: BulkMigrationOptions
  ) {
    this.progressTracker = new ProgressTracker();
    this.errorHandler = new ErrorHandler(options.errorHandling);
    this.initializeWorkers();
  }

  // ì›Œì»¤ ì´ˆê¸°í™”
  private initializeWorkers(): void {
    const workerCount = this.options.parallelism || os.cpus().length;
    
    for (let i = 0; i < workerCount; i++) {
      const worker = new Worker(
        path.join(__dirname, 'migration-worker.js'),
        { workerData: { workerId: i } }
      );
      
      worker.on('message', this.handleWorkerMessage.bind(this));
      worker.on('error', this.handleWorkerError.bind(this));
      
      this.workers.push(worker);
    }
  }

  // ëŒ€ìš©ëŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
  async migrate(
    transformation?: DataTransformation
  ): Promise<BulkMigrationResult> {
    const startTime = Date.now();
    
    try {
      // 1. ë°ì´í„° í¬ê¸° ì¶”ì •
      const estimate = await this.estimateDataSize();
      this.progressTracker.initialize(estimate);

      // 2. ë°ì´í„° íŒŒí‹°ì…”ë‹
      const partitions = await this.partitionData(estimate);

      // 3. ë³‘ë ¬ ë§ˆì´ê·¸ë ˆì´ì…˜
      const results = await this.migratePartitions(
        partitions,
        transformation
      );

      // 4. ê²€ì¦
      if (this.options.validate) {
        await this.validateMigration(results);
      }

      return {
        success: true,
        totalItems: estimate.itemCount,
        migratedItems: results.reduce((sum, r) => sum + r.itemCount, 0),
        duration: Date.now() - startTime,
        partitionResults: results
      };

    } catch (error) {
      return {
        success: false,
        error: error.message,
        duration: Date.now() - startTime,
        partitionResults: []
      };
    } finally {
      this.cleanup();
    }
  }

  // ë°ì´í„° íŒŒí‹°ì…”ë‹
  private async partitionData(
    estimate: DataEstimate
  ): Promise<DataPartition[]> {
    const partitions: DataPartition[] = [];
    const partitionSize = Math.ceil(
      estimate.itemCount / this.workers.length
    );

    // ë²”ìœ„ ê¸°ë°˜ íŒŒí‹°ì…”ë‹
    if (this.options.partitionStrategy === 'range') {
      const ranges = await this.calculateRanges(partitionSize);
      
      for (const range of ranges) {
        partitions.push({
          id: uuidv4(),
          startKey: range.start,
          endKey: range.end,
          estimatedSize: partitionSize
        });
      }
    }
    // í•´ì‹œ ê¸°ë°˜ íŒŒí‹°ì…”ë‹
    else if (this.options.partitionStrategy === 'hash') {
      for (let i = 0; i < this.workers.length; i++) {
        partitions.push({
          id: uuidv4(),
          hashBucket: i,
          totalBuckets: this.workers.length,
          estimatedSize: partitionSize
        });
      }
    }

    return partitions;
  }

  // íŒŒí‹°ì…˜ ë§ˆì´ê·¸ë ˆì´ì…˜
  private async migratePartitions(
    partitions: DataPartition[],
    transformation?: DataTransformation
  ): Promise<PartitionResult[]> {
    const queue = new PQueue({ 
      concurrency: this.workers.length 
    });
    
    const results: PartitionResult[] = [];

    for (const partition of partitions) {
      queue.add(async () => {
        const result = await this.migratePartition(
          partition,
          transformation
        );
        results.push(result);
        
        // ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        this.progressTracker.updatePartition(
          partition.id,
          result.itemCount
        );
      });
    }

    await queue.onIdle();
    return results;
  }

  // ë‹¨ì¼ íŒŒí‹°ì…˜ ë§ˆì´ê·¸ë ˆì´ì…˜
  private async migratePartition(
    partition: DataPartition,
    transformation?: DataTransformation
  ): Promise<PartitionResult> {
    const worker = this.getAvailableWorker();
    const startTime = Date.now();
    
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error(`Partition ${partition.id} timeout`));
      }, this.options.partitionTimeout || 3600000); // 1ì‹œê°„

      worker.postMessage({
        type: 'MIGRATE_PARTITION',
        partition,
        transformation: transformation?.toString(),
        options: {
          batchSize: this.options.batchSize,
          retryPolicy: this.options.retryPolicy
        }
      });

      worker.once('message', (message) => {
        clearTimeout(timeout);
        
        if (message.type === 'PARTITION_COMPLETE') {
          resolve({
            partitionId: partition.id,
            itemCount: message.itemCount,
            duration: Date.now() - startTime,
            errors: message.errors || []
          });
        } else if (message.type === 'PARTITION_ERROR') {
          reject(new Error(message.error));
        }
      });
    });
  }

  // ìŠ¤íŠ¸ë¦¬ë° ë§ˆì´ê·¸ë ˆì´ì…˜
  async streamMigrate(
    filter?: DataFilter
  ): Promise<AsyncGenerator<MigrationChunk>> {
    const stream = this.source.createReadStream(filter);
    const transformer = new TransformStream();

    return async function* () {
      for await (const chunk of stream) {
        const transformed = await transformer.transform(chunk);
        
        // ëŒ€ìƒì— ì“°ê¸°
        await this.target.writeBatch(transformed);
        
        yield {
          items: transformed,
          timestamp: new Date(),
          sequenceNumber: chunk.sequenceNumber
        };
      }
    }.call(this);
  }

  // ì¦ë¶„ ë§ˆì´ê·¸ë ˆì´ì…˜
  async incrementalMigrate(
    lastCheckpoint?: string
  ): Promise<IncrementalMigrationResult> {
    // DynamoDB Streams ë˜ëŠ” ë³€ê²½ ë¡œê·¸ ì‚¬ìš©
    const changes = await this.source.getChangesSince(lastCheckpoint);
    const results: ChangeResult[] = [];

    for (const change of changes) {
      try {
        const result = await this.applyChange(change);
        results.push(result);
      } catch (error) {
        this.errorHandler.handle(error, change);
      }
    }

    return {
      checkpoint: changes[changes.length - 1]?.sequenceNumber,
      changesProcessed: results.length,
      results
    };
  }

  // ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„
  private async handleFailedItems(
    failures: FailedItem[]
  ): Promise<RetryResult> {
    const retryPolicy = this.options.retryPolicy || {
      maxAttempts: 3,
      backoffMultiplier: 2,
      initialDelay: 1000
    };

    const retryResults: RetryItemResult[] = [];

    for (const failure of failures) {
      let attempt = 0;
      let success = false;
      let lastError: Error | null = null;

      while (attempt < retryPolicy.maxAttempts && !success) {
        try {
          await this.retrySingleItem(failure);
          success = true;
        } catch (error) {
          lastError = error;
          attempt++;
          
          if (attempt < retryPolicy.maxAttempts) {
            const delay = retryPolicy.initialDelay * 
              Math.pow(retryPolicy.backoffMultiplier, attempt - 1);
            await new Promise(resolve => setTimeout(resolve, delay));
          }
        }
      }

      retryResults.push({
        item: failure.item,
        success,
        attempts: attempt,
        error: success ? null : lastError
      });
    }

    return {
      totalItems: failures.length,
      successCount: retryResults.filter(r => r.success).length,
      failureCount: retryResults.filter(r => !r.success).length,
      results: retryResults
    };
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦
  private async validateMigration(
    results: PartitionResult[]
  ): Promise<ValidationResult> {
    const validator = new MigrationValidator(
      this.source,
      this.target
    );

    // ë ˆì½”ë“œ ìˆ˜ ê²€ì¦
    const countValidation = await validator.validateCounts();

    // ìƒ˜í”Œ ë°ì´í„° ê²€ì¦
    const sampleValidation = await validator.validateSampleData(
      this.options.validationSampleSize || 1000
    );

    // ì²´í¬ì„¬ ê²€ì¦
    const checksumValidation = await validator.validateChecksums(
      results.map(r => r.partitionId)
    );

    return {
      valid: countValidation.valid && 
             sampleValidation.valid && 
             checksumValidation.valid,
      validations: {
        count: countValidation,
        sample: sampleValidation,
        checksum: checksumValidation
      }
    };
  }

  // ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
  getProgress(): MigrationProgress {
    return this.progressTracker.getOverallProgress();
  }

  // ì •ë¦¬
  private cleanup(): void {
    for (const worker of this.workers) {
      worker.terminate();
    }
    this.workers = [];
  }
}

// ë§ˆì´ê·¸ë ˆì´ì…˜ ì›Œì»¤
// migration-worker.js
const { parentPort, workerData } = require('worker_threads');

parentPort.on('message', async (message) => {
  if (message.type === 'MIGRATE_PARTITION') {
    try {
      const result = await migratePartitionData(
        message.partition,
        message.transformation,
        message.options
      );
      
      parentPort.postMessage({
        type: 'PARTITION_COMPLETE',
        itemCount: result.itemCount,
        errors: result.errors
      });
    } catch (error) {
      parentPort.postMessage({
        type: 'PARTITION_ERROR',
        error: error.message
      });
    }
  }
});

async function migratePartitionData(partition, transformation, options) {
  let itemCount = 0;
  const errors = [];
  const batchSize = options.batchSize || 100;

  // íŒŒí‹°ì…˜ ë°ì´í„° ì½ê¸°
  const reader = createPartitionReader(partition);
  const writer = createBatchWriter();

  let batch = [];
  
  for await (const item of reader) {
    try {
      // ë³€í™˜ ì ìš©
      const transformed = transformation ? 
        await applyTransformation(item, transformation) : item;
      
      batch.push(transformed);
      
      if (batch.length >= batchSize) {
        await writer.write(batch);
        itemCount += batch.length;
        batch = [];
      }
    } catch (error) {
      errors.push({
        item: item.id,
        error: error.message
      });
    }
  }

  // ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬
  if (batch.length > 0) {
    await writer.write(batch);
    itemCount += batch.length;
  }

  return { itemCount, errors };
}
```

#### SubTask 2.6.3: ë¬´ì¤‘ë‹¨ ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/migration/zero-downtime-migration.ts
export class ZeroDowntimeMigration {
  private dualWriteManager: DualWriteManager;
  private backfillManager: BackfillManager;
  private cutoverManager: CutoverManager;
  
  constructor(
    private oldSystem: DataSystem,
    private newSystem: DataSystem,
    private options: ZeroDowntimeOptions
  ) {
    this.dualWriteManager = new DualWriteManager(oldSystem, newSystem);
    this.backfillManager = new BackfillManager(oldSystem, newSystem);
    this.cutoverManager = new CutoverManager();
  }

  // ë¬´ì¤‘ë‹¨ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
  async execute(): Promise<MigrationExecutionResult> {
    const phases: Phase[] = [
      this.phaseDualWrite.bind(this),
      this.phaseBackfill.bind(this),
      this.phaseValidation.bind(this),
      this.phaseCutover.bind(this),
      this.phaseCleanup.bind(this)
    ];

    const results: PhaseResult[] = [];

    for (const [index, phase] of phases.entries()) {
      try {
        const result = await phase();
        results.push(result);

        if (!result.success) {
          // ë¡¤ë°±
          await this.rollback(index, results);
          break;
        }
      } catch (error) {
        await this.handlePhaseError(index, error);
        break;
      }
    }

    return {
      success: results.every(r => r.success),
      phases: results,
      totalDuration: results.reduce((sum, r) => sum + r.duration, 0)
    };
  }

  // Phase 1: ì´ì¤‘ ì“°ê¸° í™œì„±í™”
  private async phaseDualWrite(): Promise<PhaseResult> {
    const startTime = Date.now();
    
    // ì´ì¤‘ ì“°ê¸° ì„¤ì •
    await this.dualWriteManager.enable({
      primaryTarget: 'old',
      secondaryTarget: 'new',
      asyncWrite: true,
      errorHandling: 'log_and_continue'
    });

    // ì“°ê¸° í”„ë¡ì‹œ ì„¤ì •
    await this.setupWriteProxy();

    // ëª¨ë‹ˆí„°ë§ ì‹œì‘
    await this.startDualWriteMonitoring();

    return {
      phase: 'dual_write',
      success: true,
      duration: Date.now() - startTime,
      metrics: await this.dualWriteManager.getMetrics()
    };
  }

  // Phase 2: ê¸°ì¡´ ë°ì´í„° ë°±í•„
  private async phaseBackfill(): Promise<PhaseResult> {
    const startTime = Date.now();
    
    // ë°±í•„ ì‘ì—… ìƒì„±
    const backfillJob = await this.backfillManager.createJob({
      source: this.oldSystem,
      target: this.newSystem,
      strategy: 'incremental',
      batchSize: this.options.backfillBatchSize || 1000,
      parallelism: this.options.backfillParallelism || 10
    });

    // ë°±í•„ ì‹¤í–‰
    const backfillResult = await this.backfillManager.execute(
      backfillJob,
      {
        onProgress: (progress) => {
          this.options.onProgress?.('backfill', progress);
        }
      }
    );

    return {
      phase: 'backfill',
      success: backfillResult.success,
      duration: Date.now() - startTime,
      metrics: {
        totalItems: backfillResult.totalItems,
        migratedItems: backfillResult.migratedItems,
        errorCount: backfillResult.errors.length
      }
    };
  }

  // Phase 3: ë°ì´í„° ê²€ì¦
  private async phaseValidation(): Promise<PhaseResult> {
    const startTime = Date.now();
    
    const validator = new DataValidator(
      this.oldSystem,
      this.newSystem
    );

    // ì „ì²´ ê²€ì¦
    const validationResult = await validator.validate({
      strategies: ['count', 'checksum', 'sample'],
      sampleSize: this.options.validationSampleSize || 10000,
      parallelism: 5
    });

    // ë¶ˆì¼ì¹˜ ì²˜ë¦¬
    if (!validationResult.valid) {
      await this.handleValidationDiscrepancies(
        validationResult.discrepancies
      );
    }

    return {
      phase: 'validation',
      success: validationResult.valid,
      duration: Date.now() - startTime,
      metrics: validationResult
    };
  }

  // Phase 4: ì‹œìŠ¤í…œ ì „í™˜
  private async phaseCutover(): Promise<PhaseResult> {
    const startTime = Date.now();
    
    // 1. ì½ê¸° íŠ¸ë˜í”½ ì ì§„ì  ì´ë™
    await this.cutoverManager.startGradualCutover({
      trafficPercentages: [10, 25, 50, 75, 100],
      intervalMinutes: this.options.cutoverInterval || 5,
      rollbackThreshold: {
        errorRate: 0.01,
        latencyP99: 100
      }
    });

    // 2. ê±´ê°• ìƒíƒœ ëª¨ë‹ˆí„°ë§
    const healthChecker = new HealthChecker(this.newSystem);
    const healthCheckResult = await healthChecker.continuousCheck({
      duration: 300000, // 5ë¶„
      interval: 5000
    });

    if (!healthCheckResult.healthy) {
      throw new Error('New system health check failed');
    }

    // 3. ì´ì¤‘ ì“°ê¸° ë°©í–¥ ì „í™˜
    await this.dualWriteManager.switchPrimary('new');

    // 4. ìµœì¢… ë™ê¸°í™”
    await this.performFinalSync();

    return {
      phase: 'cutover',
      success: true,
      duration: Date.now() - startTime,
      metrics: {
        trafficMigrated: true,
        healthStatus: healthCheckResult.status,
        errorRate: healthCheckResult.errorRate
      }
    };
  }

  // Phase 5: ì •ë¦¬ ì‘ì—…
  private async phaseCleanup(): Promise<PhaseResult> {
    const startTime = Date.now();
    
    // 1. ì´ì¤‘ ì“°ê¸° ë¹„í™œì„±í™”
    await this.dualWriteManager.disable();

    // 2. ì„ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    await this.cleanupTemporaryResources();

    // 3. êµ¬ ì‹œìŠ¤í…œ ì•„ì¹´ì´ë¸Œ
    if (this.options.archiveOldData) {
      await this.archiveOldSystem();
    }

    return {
      phase: 'cleanup',
      success: true,
      duration: Date.now() - startTime,
      metrics: {
        resourcesCleaned: true,
        oldSystemArchived: this.options.archiveOldData || false
      }
    };
  }

  // ì“°ê¸° í”„ë¡ì‹œ ì„¤ì •
  private async setupWriteProxy(): Promise<void> {
    const proxy = new WriteProxy({
      interceptor: async (operation) => {
        // ì›ë³¸ ì‹œìŠ¤í…œì— ì“°ê¸°
        const oldResult = await this.oldSystem.write(operation);
        
        // ìƒˆ ì‹œìŠ¤í…œì— ë¹„ë™ê¸° ì“°ê¸°
        this.newSystem.writeAsync(operation).catch(error => {
          this.options.onDualWriteError?.(error, operation);
        });

        return oldResult;
      }
    });

    await proxy.install();
  }

  // ìµœì¢… ë™ê¸°í™”
  private async performFinalSync(): Promise<void> {
    // ë§ˆì§€ë§‰ ë³€ê²½ì‚¬í•­ í™•ì¸
    const lastChanges = await this.oldSystem.getChangesSince(
      this.backfillManager.getLastSyncTimestamp()
    );

    if (lastChanges.length > 0) {
      // ë™ê¸°í™” ìˆ˜í–‰
      await this.backfillManager.syncChanges(lastChanges);
    }
  }

  // ë¡¤ë°± ì²˜ë¦¬
  private async rollback(
    failedPhase: number,
    completedPhases: PhaseResult[]
  ): Promise<void> {
    // ì—­ìˆœìœ¼ë¡œ ë¡¤ë°±
    for (let i = failedPhase - 1; i >= 0; i--) {
      const phase = completedPhases[i];
      
      switch (phase.phase) {
        case 'cutover':
          await this.cutoverManager.rollback();
          break;
        case 'dual_write':
          await this.dualWriteManager.disable();
          break;
        // ë‹¤ë¥¸ phaseë“¤ì˜ ë¡¤ë°± ë¡œì§
      }
    }
  }
}

// ì´ì¤‘ ì“°ê¸° ê´€ë¦¬ì
export class DualWriteManager {
  private writeMetrics: WriteMetrics;
  private errorHandler: ErrorHandler;
  
  constructor(
    private primarySystem: DataSystem,
    private secondarySystem: DataSystem
  ) {
    this.writeMetrics = new WriteMetrics();
    this.errorHandler = new ErrorHandler();
  }

  async enable(config: DualWriteConfig): Promise<void> {
    // ì“°ê¸° ì¸í„°ì…‰í„° ì„¤ì •
    this.primarySystem.addWriteInterceptor(async (operation) => {
      const primaryResult = await this.primarySystem.executeWrite(operation);
      
      // ë³´ì¡° ì‹œìŠ¤í…œì— ì“°ê¸°
      if (config.asyncWrite) {
        this.writeToSecondaryAsync(operation);
      } else {
        await this.writeToSecondarySync(operation);
      }
      
      return primaryResult;
    });
  }

  private async writeToSecondaryAsync(operation: WriteOperation): Promise<void> {
    try {
      await this.secondarySystem.executeWrite(operation);
      this.writeMetrics.recordSuccess('secondary');
    } catch (error) {
      this.writeMetrics.recordFailure('secondary');
      await this.errorHandler.handle(error, operation);
    }
  }

  async switchPrimary(newPrimary: 'old' | 'new'): Promise<void> {
    // íŠ¸ë˜í”½ ì¼ì‹œ ì •ì§€
    await this.pauseWrites();
    
    // ì‹œìŠ¤í…œ ì „í™˜
    if (newPrimary === 'new') {
      [this.primarySystem, this.secondarySystem] = 
        [this.secondarySystem, this.primarySystem];
    }
    
    // íŠ¸ë˜í”½ ì¬ê°œ
    await this.resumeWrites();
  }

  getMetrics(): DualWriteMetrics {
    return {
      primaryWrites: this.writeMetrics.getPrimaryMetrics(),
      secondaryWrites: this.writeMetrics.getSecondaryMetrics(),
      errorRate: this.writeMetrics.getErrorRate(),
      latencyDiff: this.writeMetrics.getLatencyDifference()
    };
  }
}

// ì ì§„ì  ì „í™˜ ê´€ë¦¬ì
export class CutoverManager {
  private trafficRouter: TrafficRouter;
  private healthMonitor: HealthMonitor;
  
  async startGradualCutover(config: CutoverConfig): Promise<void> {
    for (const percentage of config.trafficPercentages) {
      // íŠ¸ë˜í”½ ë¹„ìœ¨ ì¡°ì •
      await this.trafficRouter.setDistribution({
        old: 100 - percentage,
        new: percentage
      });

      // ëŒ€ê¸° ë° ëª¨ë‹ˆí„°ë§
      await this.waitAndMonitor(
        config.intervalMinutes * 60 * 1000,
        config.rollbackThreshold
      );

      // ì„ê³„ê°’ í™•ì¸
      const metrics = await this.healthMonitor.getCurrentMetrics();
      if (this.shouldRollback(metrics, config.rollbackThreshold)) {
        throw new Error('Cutover rollback triggered');
      }
    }
  }

  private async waitAndMonitor(
    duration: number,
    threshold: RollbackThreshold
  ): Promise<void> {
    const endTime = Date.now() + duration;
    
    while (Date.now() < endTime) {
      const metrics = await this.healthMonitor.getCurrentMetrics();
      
      if (this.shouldRollback(metrics, threshold)) {
        throw new Error('Health check failed during cutover');
      }
      
      await new Promise(resolve => setTimeout(resolve, 5000));
    }
  }

  private shouldRollback(
    metrics: SystemMetrics,
    threshold: RollbackThreshold
  ): boolean {
    return metrics.errorRate > threshold.errorRate ||
           metrics.latencyP99 > threshold.latencyP99;
  }

  async rollback(): Promise<void> {
    // ëª¨ë“  íŠ¸ë˜í”½ì„ êµ¬ ì‹œìŠ¤í…œìœ¼ë¡œ
    await this.trafficRouter.setDistribution({
      old: 100,
      new: 0
    });
  }
}

---

#### SubTask 2.6.4: ë¡¤ë°± ë° ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜
**ë‹´ë‹¹ì**: ì¬í•´ ë³µêµ¬ ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/migration/rollback-recovery.ts
export class RollbackRecoveryManager {
  private snapshotManager: SnapshotManager;
  private auditLog: AuditLog;
  private recoveryOrchestrator: RecoveryOrchestrator;
  
  constructor(
    private dataSource: DataSource,
    private options: RecoveryOptions
  ) {
    this.snapshotManager = new SnapshotManager(dataSource);
    this.auditLog = new AuditLog();
    this.recoveryOrchestrator = new RecoveryOrchestrator();
  }

  // ìŠ¤ëƒ…ìƒ· ìƒì„±
  async createSnapshot(
    snapshotId: string,
    metadata?: SnapshotMetadata
  ): Promise<Snapshot> {
    const snapshot: Snapshot = {
      id: snapshotId,
      timestamp: new Date(),
      metadata: {
        ...metadata,
        dataVersion: await this.dataSource.getCurrentVersion(),
        itemCount: await this.dataSource.getItemCount()
      },
      status: 'in_progress'
    };

    try {
      // ìŠ¤ëƒ…ìƒ· ìƒì„± ì‹œì‘
      await this.auditLog.log('snapshot_started', snapshot);

      // ë°ì´í„° ë°±ì—…
      const backupResult = await this.snapshotManager.backup(
        snapshotId,
        {
          compression: this.options.compression || 'gzip',
          encryption: this.options.encryption,
          parallelism: this.options.backupParallelism || 5
        }
      );

      snapshot.status = 'completed';
      snapshot.size = backupResult.totalSize;
      snapshot.location = backupResult.location;

      await this.auditLog.log('snapshot_completed', snapshot);

      return snapshot;

    } catch (error) {
      snapshot.status = 'failed';
      snapshot.error = error.message;
      
      await this.auditLog.log('snapshot_failed', snapshot);
      throw error;
    }
  }

  // ìë™ ìŠ¤ëƒ…ìƒ· ìŠ¤ì¼€ì¤„ë§
  async scheduleAutoSnapshots(
    schedule: SnapshotSchedule
  ): Promise<void> {
    const scheduler = new CronScheduler();
    
    scheduler.schedule(schedule.cronExpression, async () => {
      try {
        const snapshotId = `auto-${Date.now()}`;
        await this.createSnapshot(snapshotId, {
          type: 'scheduled',
          retention: schedule.retention
        });

        // ì˜¤ë˜ëœ ìŠ¤ëƒ…ìƒ· ì •ë¦¬
        await this.cleanupOldSnapshots(schedule.retention);
        
      } catch (error) {
        await this.notifySnapshotFailure(error);
      }
    });
  }

  // í¬ì¸íŠ¸ ì¸ íƒ€ì„ ë³µêµ¬
  async performPointInTimeRecovery(
    targetTime: Date,
    options?: RecoveryOptions
  ): Promise<RecoveryResult> {
    // 1. ê°€ì¥ ê°€ê¹Œìš´ ìŠ¤ëƒ…ìƒ· ì°¾ê¸°
    const snapshot = await this.findNearestSnapshot(targetTime);
    
    if (!snapshot) {
      throw new Error('No suitable snapshot found for recovery');
    }

    // 2. ìŠ¤ëƒ…ìƒ· ë³µì›
    const restoreResult = await this.restoreSnapshot(
      snapshot.id,
      options
    );

    // 3. ë³€ê²½ ë¡œê·¸ ì¬ìƒ
    if (snapshot.timestamp < targetTime) {
      await this.replayChangeLogs(
        snapshot.timestamp,
        targetTime,
        restoreResult.restoredData
      );
    }

    return {
      success: true,
      snapshotUsed: snapshot.id,
      recoveredToTime: targetTime,
      itemsRecovered: restoreResult.itemCount,
      duration: restoreResult.duration
    };
  }

  // ìŠ¤ëƒ…ìƒ· ë³µì›
  async restoreSnapshot(
    snapshotId: string,
    options?: RestoreOptions
  ): Promise<RestoreResult> {
    const startTime = Date.now();
    
    try {
      // ë³µì› ì „ ê²€ì¦
      if (options?.validate) {
        await this.validateSnapshot(snapshotId);
      }

      // ë³µì› ëŒ€ìƒ ì¤€ë¹„
      if (options?.clearTarget) {
        await this.clearTargetData();
      }

      // ìŠ¤ëƒ…ìƒ· ë°ì´í„° ë³µì›
      const result = await this.snapshotManager.restore(
        snapshotId,
        {
          targetTable: options?.targetTable,
          parallelism: options?.restoreParallelism || 10,
          transformFn: options?.transformFn
        }
      );

      // ë³µì› í›„ ê²€ì¦
      if (options?.postValidation) {
        await this.validateRestoredData(result);
      }

      return {
        success: true,
        itemCount: result.restoredItems,
        duration: Date.now() - startTime,
        warnings: result.warnings || []
      };

    } catch (error) {
      await this.handleRestoreFailure(error, snapshotId);
      throw error;
    }
  }

  // ë³€ê²½ ë¡œê·¸ ì¬ìƒ
  private async replayChangeLogs(
    fromTime: Date,
    toTime: Date,
    targetData: any
  ): Promise<void> {
    const changeLogs = await this.getChangeLogs(fromTime, toTime);
    
    for (const log of changeLogs) {
      try {
        await this.applyChange(log, targetData);
      } catch (error) {
        if (this.options.stopOnError) {
          throw error;
        }
        await this.logChangeApplicationError(log, error);
      }
    }
  }

  // ë¶€ë¶„ ë¡¤ë°±
  async performPartialRollback(
    criteria: RollbackCriteria
  ): Promise<PartialRollbackResult> {
    const affectedItems = await this.identifyAffectedItems(criteria);
    const rollbackPlan = await this.createRollbackPlan(affectedItems);

    // ë¡¤ë°± ì‹¤í–‰
    const results: ItemRollbackResult[] = [];
    
    for (const item of rollbackPlan.items) {
      try {
        const previousVersion = await this.getPreviousVersion(
          item.id,
          criteria.beforeTime
        );
        
        if (previousVersion) {
          await this.restoreItem(item.id, previousVersion);
          results.push({
            itemId: item.id,
            status: 'success',
            rolledBackTo: previousVersion.version
          });
        }
      } catch (error) {
        results.push({
          itemId: item.id,
          status: 'failed',
          error: error.message
        });
      }
    }

    return {
      totalItems: affectedItems.length,
      successCount: results.filter(r => r.status === 'success').length,
      failureCount: results.filter(r => r.status === 'failed').length,
      results
    };
  }

  // ì¬í•´ ë³µêµ¬ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
  async orchestrateDisasterRecovery(
    disaster: DisasterEvent
  ): Promise<DisasterRecoveryResult> {
    const plan = await this.recoveryOrchestrator.createPlan(disaster);
    
    // 1. ì˜í–¥ í‰ê°€
    const impact = await this.assessImpact(disaster);
    
    // 2. ë³µêµ¬ ìš°ì„ ìˆœìœ„ ê²°ì •
    const priorities = this.determinePriorities(impact);
    
    // 3. ë³µêµ¬ ì‹¤í–‰
    const recoveryTasks = priorities.map(priority => 
      this.executeRecoveryTask(priority)
    );
    
    const results = await Promise.allSettled(recoveryTasks);
    
    // 4. ë³µêµ¬ ê²€ì¦
    const validation = await this.validateRecovery(results);
    
    return {
      disaster,
      impact,
      recoveryPlan: plan,
      results: results.map((r, i) => ({
        task: priorities[i],
        status: r.status,
        result: r.status === 'fulfilled' ? r.value : r.reason
      })),
      validation,
      totalRecoveryTime: Date.now() - disaster.occurredAt.getTime()
    };
  }

  // ë³µêµ¬ ì‹œë®¬ë ˆì´ì…˜
  async simulateRecovery(
    scenario: RecoveryScenario
  ): Promise<SimulationResult> {
    const simulator = new RecoverySimulator(this.dataSource);
    
    // ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
    const result = await simulator.run(scenario, {
      dryRun: true,
      collectMetrics: true
    });

    return {
      scenario: scenario.name,
      estimatedRecoveryTime: result.estimatedTime,
      estimatedDataLoss: result.dataLoss,
      requiredResources: result.resources,
      recommendations: this.generateRecommendations(result)
    };
  }

  // ì—°ì† ë°ì´í„° ë³´í˜¸ (CDP)
  async enableContinuousDataProtection(): Promise<void> {
    const cdp = new ContinuousDataProtection({
      captureInterval: this.options.cdpInterval || 1000,
      retentionPeriod: this.options.cdpRetention || 7 * 24 * 60 * 60 * 1000 // 7ì¼
    });

    // ë³€ê²½ ìº¡ì²˜ ì‹œì‘
    cdp.startCapture(this.dataSource, async (changes) => {
      await this.storeChanges(changes);
      
      // ì‹¤ì‹œê°„ ë³µì œ
      if (this.options.realtimeReplication) {
        await this.replicateChanges(changes);
      }
    });

    // ì •ê¸°ì ì¸ ì²´í¬í¬ì¸íŠ¸
    cdp.scheduleCheckpoints(async () => {
      await this.createCheckpoint();
    });
  }
}

// ë³µêµ¬ ì‹œë®¬ë ˆì´í„°
class RecoverySimulator {
  constructor(private dataSource: DataSource) {}

  async run(
    scenario: RecoveryScenario,
    options: SimulationOptions
  ): Promise<SimulationMetrics> {
    const startTime = Date.now();
    const metrics: SimulationMetrics = {
      steps: [],
      estimatedTime: 0,
      dataLoss: 0,
      resources: {}
    };

    // ì‹œë‚˜ë¦¬ì˜¤ ë‹¨ê³„ë³„ ì‹¤í–‰
    for (const step of scenario.steps) {
      const stepResult = await this.simulateStep(step, options);
      metrics.steps.push(stepResult);
      metrics.estimatedTime += stepResult.duration;
    }

    // ë¦¬ì†ŒìŠ¤ ê³„ì‚°
    metrics.resources = this.calculateRequiredResources(metrics.steps);

    return metrics;
  }

  private async simulateStep(
    step: RecoveryStep,
    options: SimulationOptions
  ): Promise<StepResult> {
    switch (step.type) {
      case 'restore_snapshot':
        return this.simulateSnapshotRestore(step);
      case 'replay_logs':
        return this.simulateLogReplay(step);
      case 'validate_data':
        return this.simulateValidation(step);
      default:
        throw new Error(`Unknown step type: ${step.type}`);
    }
  }
}
```

---

### Task 2.7: Redis ìºì‹± ì‹œìŠ¤í…œ êµ¬ì¶•

#### SubTask 2.7.1: ìºì‹± ë ˆì´ì–´ ì•„í‚¤í…ì²˜
**ë‹´ë‹¹ì**: ìºì‹± ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/cache/architecture/cache-layer.ts
export class CacheLayer {
  private redisCluster: RedisCluster;
  private cacheStrategies: Map<string, CacheStrategy>;
  private metrics: CacheMetrics;
  
  constructor(config: CacheLayerConfig) {
    this.redisCluster = new RedisCluster(config.redis);
    this.cacheStrategies = new Map();
    this.metrics = new CacheMetrics();
    
    this.initializeStrategies();
    this.setupHealthChecks();
  }

  // ìºì‹œ ì „ëµ ì´ˆê¸°í™”
  private initializeStrategies(): void {
    // ì—”í‹°í‹°ë³„ ìºì‹± ì „ëµ
    this.cacheStrategies.set('User', new UserCacheStrategy());
    this.cacheStrategies.set('Project', new ProjectCacheStrategy());
    this.cacheStrategies.set('Agent', new AgentCacheStrategy());
    this.cacheStrategies.set('Task', new TaskCacheStrategy());
    
    // ì¿¼ë¦¬ ê²°ê³¼ ìºì‹±
    this.cacheStrategies.set('Query', new QueryResultCacheStrategy());
    
    // ì§‘ê³„ ë°ì´í„° ìºì‹±
    this.cacheStrategies.set('Aggregation', new AggregationCacheStrategy());
  }

  // ìºì‹œ ì½ê¸°
  async get<T>(
    key: string,
    options?: CacheGetOptions
  ): Promise<T | null> {
    const startTime = Date.now();
    
    try {
      // ë©€í‹° ë ˆë²¨ ìºì‹œ í™•ì¸
      const value = await this.getFromMultiLevel(key, options);
      
      if (value !== null) {
        this.metrics.recordHit(key, Date.now() - startTime);
        return value;
      }
      
      this.metrics.recordMiss(key, Date.now() - startTime);
      
      // ìºì‹œ ë¯¸ìŠ¤ ì‹œ ë¡œë“œ
      if (options?.loader) {
        return await this.loadAndCache(key, options);
      }
      
      return null;
      
    } catch (error) {
      this.metrics.recordError(key, error);
      
      if (options?.fallbackToSource) {
        return await options.loader?.();
      }
      
      throw error;
    }
  }

  // ë©€í‹° ë ˆë²¨ ìºì‹œ ì¡°íšŒ
  private async getFromMultiLevel(
    key: string,
    options?: CacheGetOptions
  ): Promise<any> {
    // L1: ë¡œì»¬ ë©”ëª¨ë¦¬ ìºì‹œ
    if (options?.useL1Cache !== false) {
      const l1Value = this.getFromL1(key);
      if (l1Value !== null) {
        return l1Value;
      }
    }
    
    // L2: Redis ìºì‹œ
    const l2Value = await this.getFromL2(key);
    if (l2Value !== null && options?.useL1Cache !== false) {
      // L1 ìºì‹œ ì—…ë°ì´íŠ¸
      this.setL1(key, l2Value, options?.l1Ttl);
    }
    
    return l2Value;
  }

  // ìºì‹œ ì“°ê¸°
  async set<T>(
    key: string,
    value: T,
    options?: CacheSetOptions
  ): Promise<void> {
    const strategy = this.getStrategy(key);
    const ttl = options?.ttl || strategy.getDefaultTTL();
    
    try {
      // ì§ë ¬í™”
      const serialized = await this.serialize(value, options);
      
      // ë©€í‹° ë ˆë²¨ ìºì‹œ ì„¤ì •
      if (options?.useL1Cache !== false) {
        this.setL1(key, value, options?.l1Ttl || ttl / 10);
      }
      
      await this.setL2(key, serialized, ttl);
      
      // ìºì‹œ ì›Œë°
      if (options?.warmRelated) {
        await this.warmRelatedCaches(key, value);
      }
      
      this.metrics.recordSet(key, serialized.length);
      
    } catch (error) {
      this.metrics.recordError(key, error);
      throw error;
    }
  }

  // íŒ¨í„´ ê¸°ë°˜ ë¬´íš¨í™”
  async invalidatePattern(
    pattern: string,
    options?: InvalidateOptions
  ): Promise<number> {
    const keys = await this.scanKeys(pattern);
    let invalidated = 0;
    
    // ë°°ì¹˜ ì²˜ë¦¬
    const batches = this.chunk(keys, 1000);
    
    for (const batch of batches) {
      if (options?.useL1Cache !== false) {
        batch.forEach(key => this.invalidateL1(key));
      }
      
      const deleted = await this.redisCluster.del(...batch);
      invalidated += deleted;
      
      // ì´ë²¤íŠ¸ ë°œí–‰
      if (options?.publishEvent) {
        await this.publishInvalidationEvent(batch);
      }
    }
    
    this.metrics.recordInvalidation(pattern, invalidated);
    return invalidated;
  }

  // ìºì‹œ í†µê³„
  async getStats(
    timeRange?: TimeRange
  ): Promise<CacheStatistics> {
    const stats = await this.metrics.getStats(timeRange);
    
    return {
      hitRate: stats.hits / (stats.hits + stats.misses),
      missRate: stats.misses / (stats.hits + stats.misses),
      averageLatency: stats.totalLatency / stats.totalRequests,
      totalRequests: stats.totalRequests,
      cacheSize: await this.getCacheSize(),
      evictionRate: stats.evictions / stats.totalRequests,
      errorRate: stats.errors / stats.totalRequests,
      topMissedKeys: stats.topMissedKeys,
      breakdown: await this.getBreakdownByStrategy()
    };
  }

  // ìºì‹œ ì˜ˆì—´
  async warmup(
    warmupConfig: WarmupConfig
  ): Promise<WarmupResult> {
    const warmer = new CacheWarmer(this);
    
    return await warmer.execute(warmupConfig, {
      onProgress: (progress) => {
        this.metrics.recordWarmupProgress(progress);
      }
    });
  }

  // ì ì‘í˜• TTL
  private async calculateAdaptiveTTL(
    key: string,
    accessPattern: AccessPattern
  ): Promise<number> {
    const strategy = this.getStrategy(key);
    
    // ì ‘ê·¼ ë¹ˆë„ ê¸°ë°˜ TTL ì¡°ì •
    if (accessPattern.frequency === 'high') {
      return strategy.getDefaultTTL() * 2;
    } else if (accessPattern.frequency === 'low') {
      return strategy.getDefaultTTL() / 2;
    }
    
    // ë³€ê²½ ë¹ˆë„ ê¸°ë°˜ TTL ì¡°ì •
    if (accessPattern.volatility === 'high') {
      return Math.min(strategy.getDefaultTTL(), 300); // ìµœëŒ€ 5ë¶„
    }
    
    return strategy.getDefaultTTL();
  }
}

// ìºì‹± ì „ëµ ì¸í„°í˜ì´ìŠ¤
export abstract class CacheStrategy {
  abstract getDefaultTTL(): number;
  abstract getCacheKey(params: any): string;
  abstract shouldCache(value: any): boolean;
  abstract onCacheMiss(key: string): Promise<void>;
  abstract onCacheHit(key: string): Promise<void>;
}

// User ìºì‹± ì „ëµ
export class UserCacheStrategy extends CacheStrategy {
  getDefaultTTL(): number {
    return 3600; // 1ì‹œê°„
  }
  
  getCacheKey(params: { userId: string }): string {
    return `user:${params.userId}`;
  }
  
  shouldCache(user: User): boolean {
    // í™œì„± ì‚¬ìš©ìë§Œ ìºì‹œ
    return user.status === 'active';
  }
  
  async onCacheMiss(key: string): Promise<void> {
    // ìºì‹œ ë¯¸ìŠ¤ ì‹œ í”„ë¦¬í˜ì¹˜
    const userId = key.split(':')[1];
    await this.prefetchRelatedData(userId);
  }
  
  private async prefetchRelatedData(userId: string): Promise<void> {
    // ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ í”„ë¦¬í˜ì¹˜
    await this.prefetchUserProjects(userId);
  }
}

// ë¶„ì‚° ìºì‹œ ê´€ë¦¬
export class DistributedCacheManager {
  private nodes: CacheNode[];
  private consistentHash: ConsistentHash;
  
  constructor(config: DistributedCacheConfig) {
    this.nodes = config.nodes.map(n => new CacheNode(n));
    this.consistentHash = new ConsistentHash(this.nodes);
  }

  async get(key: string): Promise<any> {
    const node = this.consistentHash.getNode(key);
    
    try {
      return await node.get(key);
    } catch (error) {
      // í´ë°± ë…¸ë“œ ì‹œë„
      const fallbackNode = this.consistentHash.getNextNode(key);
      return await fallbackNode.get(key);
    }
  }

  // ë…¸ë“œ ì¶”ê°€/ì œê±° ì‹œ ë¦¬ë°¸ëŸ°ì‹±
  async rebalance(): Promise<void> {
    const migrations = this.consistentHash.calculateMigrations();
    
    for (const migration of migrations) {
      await this.migrateKeys(
        migration.fromNode,
        migration.toNode,
        migration.keys
      );
    }
  }
}

// ìºì‹œ ì¼ê´€ì„± ê´€ë¦¬
export class CacheConsistencyManager {
  private invalidationQueue: Queue;
  private versionManager: VersionManager;
  
  // Write-through ìºì‹±
  async writeThrough(
    key: string,
    value: any,
    writer: DataWriter
  ): Promise<void> {
    // 1. ë°ì´í„°ë² ì´ìŠ¤ ì“°ê¸°
    await writer.write(key, value);
    
    // 2. ìºì‹œ ì—…ë°ì´íŠ¸
    await this.cache.set(key, value);
    
    // 3. ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”
    await this.invalidateRelated(key);
  }

  // Write-behind ìºì‹±
  async writeBehind(
    key: string,
    value: any,
    writer: DataWriter
  ): Promise<void> {
    // 1. ìºì‹œ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
    await this.cache.set(key, value);
    
    // 2. ë¹„ë™ê¸° ë°ì´í„°ë² ì´ìŠ¤ ì“°ê¸°
    this.writeQueue.push({
      key,
      value,
      writer,
      timestamp: Date.now()
    });
  }

  // ë²„ì „ ê¸°ë°˜ ì¼ê´€ì„±
  async versionedGet(key: string): Promise<VersionedData> {
    const cached = await this.cache.get(key);
    
    if (cached) {
      const currentVersion = await this.versionManager.getVersion(key);
      
      if (cached.version === currentVersion) {
        return cached;
      }
      
      // ë²„ì „ ë¶ˆì¼ì¹˜ ì‹œ ì¬ë¡œë“œ
      await this.cache.invalidate(key);
    }
    
    return null;
  }
}
```

#### SubTask 2.7.2: ìºì‹œ ë¬´íš¨í™” ì „ëµ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/cache/invalidation/invalidation-strategy.ts
export class CacheInvalidationManager {
  private invalidationStrategies: Map<string, InvalidationStrategy>;
  private eventBus: EventBus;
  private dependencyGraph: DependencyGraph;
  
  constructor(
    private cache: CacheLayer,
    private config: InvalidationConfig
  ) {
    this.invalidationStrategies = new Map();
    this.eventBus = new EventBus();
    this.dependencyGraph = new DependencyGraph();
    
    this.initializeStrategies();
    this.setupEventListeners();
  }

  // ë¬´íš¨í™” ì „ëµ ì´ˆê¸°í™”
  private initializeStrategies(): void {
    // TTL ê¸°ë°˜ ë¬´íš¨í™”
    this.registerStrategy('ttl', new TTLInvalidationStrategy());
    
    // ì´ë²¤íŠ¸ ê¸°ë°˜ ë¬´íš¨í™”
    this.registerStrategy('event', new EventBasedInvalidationStrategy());
    
    // íƒœê·¸ ê¸°ë°˜ ë¬´íš¨í™”
    this.registerStrategy('tag', new TagBasedInvalidationStrategy());
    
    // ì˜ì¡´ì„± ê¸°ë°˜ ë¬´íš¨í™”
    this.registerStrategy('dependency', new DependencyInvalidationStrategy());
    
    // ìŠ¤ë§ˆíŠ¸ ë¬´íš¨í™”
    this.registerStrategy('smart', new SmartInvalidationStrategy());
  }

  // ì—”í‹°í‹° ì—…ë°ì´íŠ¸ ì‹œ ë¬´íš¨í™”
  async invalidateOnUpdate(
    entity: string,
    id: string,
    changes: any
  ): Promise<InvalidationResult> {
    const startTime = Date.now();
    const invalidated: string[] = [];

    try {
      // 1. ì§ì ‘ ìºì‹œ ë¬´íš¨í™”
      const directKey = `${entity}:${id}`;
      await this.cache.invalidate(directKey);
      invalidated.push(directKey);

      // 2. ê´€ë ¨ ì¿¼ë¦¬ ìºì‹œ ë¬´íš¨í™”
      const queryKeys = await this.findRelatedQueryCaches(entity, id);
      for (const key of queryKeys) {
        await this.cache.invalidate(key);
        invalidated.push(key);
      }

      // 3. ì˜ì¡´ì„± ê·¸ë˜í”„ ê¸°ë°˜ ë¬´íš¨í™”
      const dependencies = this.dependencyGraph.getDependencies(directKey);
      for (const dep of dependencies) {
        await this.cache.invalidate(dep);
        invalidated.push(dep);
      }

      // 4. ê³„ë‹¨ì‹ ë¬´íš¨í™”
      if (this.shouldCascade(entity, changes)) {
        const cascaded = await this.cascadeInvalidation(entity, id);
        invalidated.push(...cascaded);
      }

      // 5. ì´ë²¤íŠ¸ ë°œí–‰
      await this.publishInvalidationEvent({
        entity,
        id,
        invalidatedKeys: invalidated,
        reason: 'update'
      });

      return {
        success: true,
        invalidatedCount: invalidated.length,
        duration: Date.now() - startTime,
        keys: invalidated
      };

    } catch (error) {
      return {
        success: false,
        error: error.message,
        duration: Date.now() - startTime,
        keys: invalidated
      };
    }
  }

  // íƒœê·¸ ê¸°ë°˜ ë¬´íš¨í™”
  async invalidateByTags(
    tags: string[]
  ): Promise<InvalidationResult> {
    const strategy = this.invalidationStrategies.get('tag') as TagBasedInvalidationStrategy;
    const keysToInvalidate = new Set<string>();

    // ê° íƒœê·¸ì— ëŒ€í•œ í‚¤ ìˆ˜ì§‘
    for (const tag of tags) {
      const keys = await strategy.getKeysByTag(tag);
      keys.forEach(key => keysToInvalidate.add(key));
    }

    // ë°°ì¹˜ ë¬´íš¨í™”
    const invalidated = await this.batchInvalidate(
      Array.from(keysToInvalidate)
    );

    return {
      success: true,
      invalidatedCount: invalidated.length,
      tags,
      keys: invalidated
    };
  }

  // ìŠ¤ë§ˆíŠ¸ ë¬´íš¨í™”
  async smartInvalidate(
    context: InvalidationContext
  ): Promise<SmartInvalidationResult> {
    const strategy = this.invalidationStrategies.get('smart') as SmartInvalidationStrategy;
    
    // ë¬´íš¨í™” ì˜í–¥ ë¶„ì„
    const impact = await strategy.analyzeImpact(context);
    
    // ë¬´íš¨í™” ê²°ì •
    const decision = await strategy.makeDecision(impact);
    
    if (decision.shouldInvalidate) {
      // ì„ íƒì  ë¬´íš¨í™”
      const results = await this.selectiveInvalidate(
        decision.keys,
        decision.priority
      );
      
      return {
        success: true,
        decision,
        impact,
        results,
        optimizationApplied: decision.optimizations
      };
    }
    
    return {
      success: true,
      decision,
      impact,
      results: [],
      optimizationApplied: []
    };
  }

  // ì˜ì¡´ì„± ê·¸ë˜í”„ êµ¬ì¶•
  async buildDependencyGraph(
    entities: EntityRelation[]
  ): Promise<void> {
    for (const relation of entities) {
      this.dependencyGraph.addRelation(
        relation.parent,
        relation.child,
        relation.type
      );
    }
    
    // ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€
    const cycles = this.dependencyGraph.detectCycles();
    if (cycles.length > 0) {
      throw new Error(`Circular dependencies detected: ${cycles.join(', ')}`);
    }
  }

  // ë°°ì¹˜ ë¬´íš¨í™” ìµœì í™”
  private async batchInvalidate(
    keys: string[]
  ): Promise<string[]> {
    const batchSize = this.config.batchSize || 1000;
    const invalidated: string[] = [];
    
    // Pipeline ì‚¬ìš©
    const pipeline = this.cache.pipeline();
    
    for (let i = 0; i < keys.length; i += batchSize) {
      const batch = keys.slice(i, i + batchSize);
      
      for (const key of batch) {
        pipeline.del(key);
      }
      
      await pipeline.exec();
      invalidated.push(...batch);
      
      // ì§„í–‰ ìƒí™© ì•Œë¦¼
      if (this.config.onProgress) {
        this.config.onProgress({
          processed: invalidated.length,
          total: keys.length
        });
      }
    }
    
    return invalidated;
  }

  // ê³„ë‹¨ì‹ ë¬´íš¨í™”
  private async cascadeInvalidation(
    entity: string,
    id: string
  ): Promise<string[]> {
    const cascaded: string[] = [];
    const visited = new Set<string>();
    const queue = [`${entity}:${id}`];
    
    while (queue.length > 0) {
      const current = queue.shift()!;
      
      if (visited.has(current)) continue;
      visited.add(current);
      
      const children = this.dependencyGraph.getChildren(current);
      
      for (const child of children) {
        await this.cache.invalidate(child);
        cascaded.push(child);
        queue.push(child);
      }
    }
    
    return cascaded;
  }

  // ë¬´íš¨í™” ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
  private setupEventListeners(): void {
    // ë°ì´í„° ë³€ê²½ ì´ë²¤íŠ¸
    this.eventBus.on('data:updated', async (event) => {
      await this.invalidateOnUpdate(
        event.entity,
        event.id,
        event.changes
      );
    });
    
    // ì¼ê´„ ë³€ê²½ ì´ë²¤íŠ¸
    this.eventBus.on('data:bulk-updated', async (event) => {
      await this.invalidateByTags(event.tags);
    });
    
    // ì‹œìŠ¤í…œ ì´ë²¤íŠ¸
    this.eventBus.on('cache:flush-requested', async (event) => {
      await this.flushCache(event.pattern);
    });
  }
}

// íƒœê·¸ ê¸°ë°˜ ë¬´íš¨í™” ì „ëµ
export class TagBasedInvalidationStrategy implements InvalidationStrategy {
  private tagIndex: Map<string, Set<string>> = new Map();
  
  async addTags(key: string, tags: string[]): Promise<void> {
    for (const tag of tags) {
      if (!this.tagIndex.has(tag)) {
        this.tagIndex.set(tag, new Set());
      }
      this.tagIndex.get(tag)!.add(key);
    }
    
    // Redisì—ë„ íƒœê·¸ ì •ë³´ ì €ì¥
    await this.persistTagMapping(key, tags);
  }
  
  async getKeysByTag(tag: string): Promise<string[]> {
    // ë©”ëª¨ë¦¬ì—ì„œ ë¨¼ì € í™•ì¸
    if (this.tagIndex.has(tag)) {
      return Array.from(this.tagIndex.get(tag)!);
    }
    
    // Redisì—ì„œ ë¡œë“œ
    return await this.loadKeysFromRedis(tag);
  }
  
  async invalidateByTag(tag: string): Promise<string[]> {
    const keys = await this.getKeysByTag(tag);
    const invalidated: string[] = [];
    
    for (const key of keys) {
      await this.cache.invalidate(key);
      invalidated.push(key);
    }
    
    // íƒœê·¸ ì¸ë±ìŠ¤ ì •ë¦¬
    this.tagIndex.delete(tag);
    
    return invalidated;
  }
}

// ìŠ¤ë§ˆíŠ¸ ë¬´íš¨í™” ì „ëµ
export class SmartInvalidationStrategy implements InvalidationStrategy {
  private ml: InvalidationMLModel;
  private metrics: InvalidationMetrics;
  
  constructor() {
    this.ml = new InvalidationMLModel();
    this.metrics = new InvalidationMetrics();
  }
  
  async analyzeImpact(
    context: InvalidationContext
  ): Promise<InvalidationImpact> {
    // ì ‘ê·¼ íŒ¨í„´ ë¶„ì„
    const accessPattern = await this.analyzeAccessPattern(context.key);
    
    // ë¹„ìš© ê³„ì‚°
    const cost = this.calculateInvalidationCost(context);
    
    // ì´ìµ ê³„ì‚°
    const benefit = this.calculateInvalidationBenefit(context);
    
    // ML ì˜ˆì¸¡
    const prediction = await this.ml.predict({
      context,
      accessPattern,
      historicalData: await this.metrics.getHistoricalData(context.key)
    });
    
    return {
      accessPattern,
      cost,
      benefit,
      prediction,
      score: benefit / cost
    };
  }
  
  async makeDecision(
    impact: InvalidationImpact
  ): Promise<InvalidationDecision> {
    const threshold = this.config.decisionThreshold || 1.5;
    
    if (impact.score < threshold) {
      // ë¬´íš¨í™” ì§€ì—° ë˜ëŠ” ìŠ¤í‚µ
      return {
        shouldInvalidate: false,
        reason: 'Low benefit-to-cost ratio',
        alternativeAction: 'refresh_on_next_access'
      };
    }
    
    // ë¬´íš¨í™” ìµœì í™” ê²°ì •
    const optimizations = this.determineOptimizations(impact);
    
    return {
      shouldInvalidate: true,
      keys: await this.selectKeysToInvalidate(impact),
      priority: this.calculatePriority(impact),
      optimizations
    };
  }
  
  private determineOptimizations(
    impact: InvalidationImpact
  ): InvalidationOptimization[] {
    const optimizations: InvalidationOptimization[] = [];
    
    // ë¶€ë¶„ ë¬´íš¨í™”
    if (impact.accessPattern.hotKeys.length > 0) {
      optimizations.push({
        type: 'partial',
        description: 'Invalidate only hot keys',
        keys: impact.accessPattern.hotKeys
      });
    }
    
    // ì§€ì—° ë¬´íš¨í™”
    if (impact.accessPattern.peakHours.includes(new Date().getHours())) {
      optimizations.push({
        type: 'delayed',
        description: 'Delay invalidation until off-peak hours',
        delayUntil: this.getNextOffPeakTime()
      });
    }
    
    // ì ì§„ì  ë¬´íš¨í™”
    if (impact.cost > 1000) {
      optimizations.push({
        type: 'gradual',
        description: 'Gradual invalidation to reduce impact',
        phases: this.calculateGradualPhases(impact)
      });
    }
    
    return optimizations;
  }
}

// ë¬´íš¨í™” ë©”íŠ¸ë¦­ ìˆ˜ì§‘
export class InvalidationMetrics {
  async trackInvalidation(
    event: InvalidationEvent
  ): Promise<void> {
    await this.recordMetrics({
      timestamp: Date.now(),
      keys: event.keys,
      reason: event.reason,
      duration: event.duration,
      impact: {
        cacheHitRateBefore: await this.getCacheHitRate(),
        estimatedCacheMisses: event.keys.length
      }
    });
  }
  
  async analyzeInvalidationPatterns(): Promise<PatternAnalysis> {
    const data = await this.getInvalidationHistory();
    
    return {
      frequentPatterns: this.findFrequentPatterns(data),
      timeBasedPatterns: this.findTimePatterns(data),
      correlations: this.findCorrelations(data),
      anomalies: this.detectAnomalies(data)
    };
  }
}
```

#### SubTask 2.7.3: ë¶„ì‚° ìºì‹± ë° ë™ê¸°í™”
**ë‹´ë‹¹ì**: ë¶„ì‚° ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/cache/distributed/distributed-cache.ts
export class DistributedCache {
  private nodes: RedisNode[];
  private hashRing: ConsistentHashRing;
  private replicationManager: ReplicationManager;
  private gossipProtocol: GossipProtocol;
  
  constructor(config: DistributedCacheConfig) {
    this.nodes = this.initializeNodes(config.nodes);
    this.hashRing = new ConsistentHashRing(
      this.nodes,
      config.virtualNodes || 150
    );
    this.replicationManager = new ReplicationManager(
      config.replicationFactor || 3
    );
    this.gossipProtocol = new GossipProtocol(this.nodes);
    
    this.startHealthMonitoring();
    this.startGossipProtocol();
  }

  // ë¶„ì‚° ì½ê¸°
  async get(key: string): Promise<any> {
    const primaryNode = this.hashRing.getNode(key);
    
    try {
      // ì£¼ ë…¸ë“œì—ì„œ ì½ê¸°
      const value = await primaryNode.get(key);
      if (value !== null) {
        return value;
      }
      
      // ë³µì œë³¸ì—ì„œ ì½ê¸° (read repair)
      return await this.readFromReplicas(key);
      
    } catch (error) {
      // ì¥ì•  ì‹œ ë³µì œë³¸ì—ì„œ ì½ê¸°
      if (error.code === 'NODE_DOWN') {
        return await this.readFromReplicas(key);
      }
      throw error;
    }
  }

  // ë¶„ì‚° ì“°ê¸°
  async set(
    key: string,
    value: any,
    options?: DistributedSetOptions
  ): Promise<void> {
    const primaryNode = this.hashRing.getNode(key);
    const replicas = this.replicationManager.getReplicas(key);
    
    // ì“°ê¸° ì¼ê´€ì„± ìˆ˜ì¤€
    const consistency = options?.consistency || 'quorum';
    
    switch (consistency) {
      case 'all':
        await this.writeToAll(key, value, [primaryNode, ...replicas]);
        break;
        
      case 'quorum':
        await this.writeWithQuorum(key, value, [primaryNode, ...replicas]);
        break;
        
      case 'one':
        await this.writeToOne(key, value, primaryNode);
        // ë¹„ë™ê¸° ë³µì œ
        this.replicateAsync(key, value, replicas);
        break;
    }
    
    // ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
    await this.updateMetadata(key, {
      version: Date.now(),
      node: primaryNode.id,
      replicas: replicas.map(r => r.id)
    });
  }

  // ì¿¼ëŸ¼ ì“°ê¸°
  private async writeWithQuorum(
    key: string,
    value: any,
    nodes: RedisNode[]
  ): Promise<void> {
    const quorumSize = Math.floor(nodes.length / 2) + 1;
    const promises = nodes.map(node => 
      node.set(key, value).catch(err => ({ error: err, node }))
    );
    
    const results = await Promise.all(promises);
    const successful = results.filter(r => !r.error).length;
    
    if (successful < quorumSize) {
      // ë¡¤ë°±
      await this.rollbackWrites(key, results);
      throw new Error('Quorum write failed');
    }
    
    // ì‹¤íŒ¨í•œ ë…¸ë“œì— ëŒ€í•œ íŒíŠ¸ ì €ì¥
    for (const result of results) {
      if (result.error) {
        await this.storeHintedHandoff(result.node, key, value);
      }
    }
  }

  // ë…¸ë“œ ì¶”ê°€/ì œê±°
  async addNode(node: RedisNode): Promise<void> {
    // 1. ë…¸ë“œë¥¼ í•´ì‹œ ë§ì— ì¶”ê°€
    this.hashRing.addNode(node);
    this.nodes.push(node);
    
    // 2. ë°ì´í„° ì¬ë¶„ë°° ê³„ì‚°
    const migrations = this.calculateDataMigration(node, 'add');
    
    // 3. ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
    await this.migrateData(migrations);
    
    // 4. ê°€ì‹­ í”„ë¡œí† ì½œ ì—…ë°ì´íŠ¸
    this.gossipProtocol.announceNodeAddition(node);
  }

  async removeNode(nodeId: string): Promise<void> {
    const node = this.nodes.find(n => n.id === nodeId);
    if (!node) return;
    
    // 1. ë°ì´í„° ì¬ë¶„ë°°
    const migrations = this.calculateDataMigration(node, 'remove');
    await this.migrateData(migrations);
    
    // 2. í•´ì‹œ ë§ì—ì„œ ì œê±°
    this.hashRing.removeNode(nodeId);
    this.nodes = this.nodes.filter(n => n.id !== nodeId);
    
    // 3. ê°€ì‹­ í”„ë¡œí† ì½œ ì—…ë°ì´íŠ¸
    this.gossipProtocol.announceNodeRemoval(nodeId);
  }

  // ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
  private async migrateData(
    migrations: DataMigration[]
  ): Promise<void> {
    const migrationTasks = migrations.map(async (migration) => {
      const keys = await migration.sourceNode.scanKeys(
        migration.keyRange
      );
      
      // ë°°ì¹˜ ì²˜ë¦¬
      const batchSize = 100;
      for (let i = 0; i < keys.length; i += batchSize) {
        const batch = keys.slice(i, i + batchSize);
        const values = await migration.sourceNode.mget(batch);
        
        // ëŒ€ìƒ ë…¸ë“œì— ì“°ê¸°
        await migration.targetNode.mset(
          batch.map((key, idx) => ({ key, value: values[idx] }))
        );
        
        // ì§„í–‰ ìƒí™© ì¶”ì 
        this.trackMigrationProgress(migration, i + batch.length, keys.length);
      }
      
      // ì†ŒìŠ¤ì—ì„œ ì‚­ì œ (ì„ íƒì )
      if (migration.deleteFromSource) {
        await migration.sourceNode.del(...keys);
      }
    });
    
    await Promise.all(migrationTasks);
  }

  // ë™ê¸°í™” ë©”ì»¤ë‹ˆì¦˜
  async syncNodes(): Promise<SyncResult> {
    const syncTasks: SyncTask[] = [];
    
    // ê° ë…¸ë“œ ìŒì— ëŒ€í•´ ë™ê¸°í™” í™•ì¸
    for (let i = 0; i < this.nodes.length; i++) {
      for (let j = i + 1; j < this.nodes.length; j++) {
        const task = await this.createSyncTask(
          this.nodes[i],
          this.nodes[j]
        );
        if (task.hasDifferences) {
          syncTasks.push(task);
        }
      }
    }
    
    // ë™ê¸°í™” ì‹¤í–‰
    const results = await Promise.all(
      syncTasks.map(task => this.executeSyncTask(task))
    );
    
    return {
      totalTasks: syncTasks.length,
      successful: results.filter(r => r.success).length,
      failed: results.filter(r => !r.success).length,
      syncedKeys: results.reduce((sum, r) => sum + r.keysSynced, 0)
    };
  }

  // Gossip í”„ë¡œí† ì½œ
  private startGossipProtocol(): void {
    setInterval(async () => {
      // ëœë¤ ë…¸ë“œ ì„ íƒ
      const peer = this.selectRandomPeer();
      if (!peer) return;
      
      // ìƒíƒœ êµí™˜
      const localState = await this.getLocalState();
      const peerState = await peer.exchangeState(localState);
      
      // ìƒíƒœ ë³‘í•©
      await this.mergeStates(localState, peerState);
      
      // ë©¤ë²„ì‹­ ì—…ë°ì´íŠ¸
      this.updateMembership(peerState.membership);
      
    }, this.config.gossipInterval || 1000);
  }

  // Anti-Entropy ë³µêµ¬
  async performAntiEntropy(): Promise<void> {
    const merkleTree = await this.buildMerkleTree();
    
    for (const peer of this.nodes) {
      if (peer.id === this.localNode.id) continue;
      
      const peerTree = await peer.getMerkleTree();
      const differences = merkleTree.compare(peerTree);
      
      if (differences.length > 0) {
        await this.reconcileDifferences(peer, differences);
      }
    }
  }

  // ì½ê¸° ë³µêµ¬
  private async readFromReplicas(key: string): Promise<any> {
    const replicas = this.replicationManager.getReplicas(key);
    const values: Array<{ value: any; version: number }> = [];
    
    // ëª¨ë“  ë³µì œë³¸ì—ì„œ ì½ê¸°
    for (const replica of replicas) {
      try {
        const result = await replica.getWithVersion(key);
        if (result) {
          values.push(result);
        }
      } catch (error) {
        // ë³µì œë³¸ ì½ê¸° ì‹¤íŒ¨ ë¬´ì‹œ
      }
    }
    
    if (values.length === 0) {
      return null;
    }
    
    // ìµœì‹  ë²„ì „ ì„ íƒ
    const latest = values.reduce((prev, curr) => 
      curr.version > prev.version ? curr : prev
    );
    
    // Read repair
    await this.repairInconsistencies(key, latest, replicas);
    
    return latest.value;
  }

  // ì¼ê´€ì„± ë³µêµ¬
  private async repairInconsistencies(
    key: string,
    correctValue: { value: any; version: number },
    nodes: RedisNode[]
  ): Promise<void> {
    const repairs = nodes.map(async (node) => {
      try {
        const current = await node.getWithVersion(key);
        if (!current || current.version < correctValue.version) {
          await node.setWithVersion(key, correctValue.value, correctValue.version);
        }
      } catch (error) {
        // ë³µêµ¬ ì‹¤íŒ¨ ë¡œê¹…
        this.logger.error(`Failed to repair ${key} on node ${node.id}`, error);
      }
    });
    
    await Promise.all(repairs);
  }

  // ë¶„í•  ë‡Œ ê°ì§€ ë° í•´ê²°
  async detectAndResolveSplitBrain(): Promise<void> {
    const partitions = await this.detectNetworkPartitions();
    
    if (partitions.length > 1) {
      // ë¶„í•  ë‡Œ ìƒí™© ê°ì§€
      this.logger.warn('Split brain detected', { partitions });
      
      // ë¦¬ë” ì„ ì¶œ
      const leader = await this.electLeader(partitions);
      
      // ë°ì´í„° ë³‘í•©
      await this.mergePartitions(partitions, leader);
      
      // ë„¤íŠ¸ì›Œí¬ ë³µêµ¬
      await this.healPartitions(partitions);
    }
  }
}

// ì¼ê´€ëœ í•´ì‹± ë§
export class ConsistentHashRing {
  private ring: Map<number, RedisNode>;
  private sortedKeys: number[];
  
  constructor(
    nodes: RedisNode[],
    private virtualNodes: number = 150
  ) {
    this.ring = new Map();
    this.sortedKeys = [];
    
    nodes.forEach(node => this.addNode(node));
  }
  
  addNode(node: RedisNode): void {
    // ê°€ìƒ ë…¸ë“œ ìƒì„±
    for (let i = 0; i < this.virtualNodes; i++) {
      const hash = this.hash(`${node.id}:${i}`);
      this.ring.set(hash, node);
    }
    
    // ì •ë ¬ëœ í‚¤ ì—…ë°ì´íŠ¸
    this.sortedKeys = Array.from(this.ring.keys()).sort((a, b) => a - b);
  }
  
  getNode(key: string): RedisNode {
    const hash = this.hash(key);
    
    // ì´ì§„ ê²€ìƒ‰ìœ¼ë¡œ ë…¸ë“œ ì°¾ê¸°
    let left = 0;
    let right = this.sortedKeys.length - 1;
    
    while (left <= right) {
      const mid = Math.floor((left + right) / 2);
      if (this.sortedKeys[mid] === hash) {
        return this.ring.get(this.sortedKeys[mid])!;
      } else if (this.sortedKeys[mid] < hash) {
        left = mid + 1;
      } else {
        right = mid - 1;
      }
    }
    
    // ë‹¤ìŒ ë…¸ë“œ ë°˜í™˜ (ì›í˜•)
    const index = left % this.sortedKeys.length;
    return this.ring.get(this.sortedKeys[index])!;
  }
  
  private hash(key: string): number {
    // MurmurHash3 êµ¬í˜„
    return murmur3(key);
  }
}

// ë³µì œ ê´€ë¦¬ì
export class ReplicationManager {
  constructor(private replicationFactor: number) {}
  
  getReplicas(key: string): RedisNode[] {
    const primaryNode = this.hashRing.getNode(key);
    const replicas: RedisNode[] = [];
    
    let currentNode = primaryNode;
    for (let i = 0; i < this.replicationFactor - 1; i++) {
      currentNode = this.hashRing.getNextNode(currentNode);
      if (!replicas.includes(currentNode)) {
        replicas.push(currentNode);
      }
    }
    
    return replicas;
  }
  
  async ensureReplication(
    key: string,
    value: any
  ): Promise<void> {
    const replicas = this.getReplicas(key);
    
    // ë³‘ë ¬ ë³µì œ
    await Promise.all(
      replicas.map(replica => 
        replica.set(key, value).catch(err => {
          // ë³µì œ ì‹¤íŒ¨ ì²˜ë¦¬
          this.handleReplicationFailure(replica, key, value, err);
        })
      )
    );
  }
}
```

#### SubTask 2.7.4: ìºì‹œ ì„±ëŠ¥ ìµœì í™”
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/cache/optimization/performance-optimizer.ts
export class CachePerformanceOptimizer {
  private metricsCollector: MetricsCollector;
  private analyzer: PerformanceAnalyzer;
  private tuner: CacheTuner;
  
  constructor(
    private cache: DistributedCache,
    private config: OptimizationConfig
  ) {
    this.metricsCollector = new MetricsCollector(cache);
    this.analyzer = new PerformanceAnalyzer();
    this.tuner = new CacheTuner(cache);
    
    this.startContinuousOptimization();
  }

  // ì§€ì†ì  ìµœì í™”
  private startContinuousOptimization(): void {
    setInterval(async () => {
      const metrics = await this.metricsCollector.collect();
      const analysis = await this.analyzer.analyze(metrics);
      
      if (analysis.needsOptimization) {
        await this.applyOptimizations(analysis.recommendations);
      }
    }, this.config.optimizationInterval || 300000); // 5ë¶„
  }

  // ë©”ëª¨ë¦¬ ìµœì í™”
  async optimizeMemory(): Promise<MemoryOptimizationResult> {
    const memoryStats = await this.cache.getMemoryStats();
    
    // 1. ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë¶„ì„
    const fragmentation = this.analyzeFragmentation(memoryStats);
    if (fragmentation.ratio > 1.4) {
      await this.defragmentMemory();
    }
    
    // 2. í‡´ê±° ì •ì±… ìµœì í™”
    const evictionStats = await this.analyzeEvictionPatterns();
    const optimalPolicy = this.selectOptimalEvictionPolicy(evictionStats);
    await this.cache.setEvictionPolicy(optimalPolicy);
    
    // 3. ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”
    const allocation = this.calculateOptimalAllocation(memoryStats);
    await this.adjustMemoryAllocation(allocation);
    
    // 4. ì••ì¶• í™œì„±í™”
    if (memoryStats.pressure > 0.8) {
      await this.enableCompression();
    }
    
    return {
      fragmentationReduced: fragmentation.ratio > 1.4,
      evictionPolicyChanged: optimalPolicy !== memoryStats.currentPolicy,
      compressionEnabled: memoryStats.pressure > 0.8,
      memorySaved: await this.calculateMemorySaved()
    };
  }

  // ë„¤íŠ¸ì›Œí¬ ìµœì í™”
  async optimizeNetwork(): Promise<NetworkOptimizationResult> {
    // 1. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
    const batchConfig = await this.optimizeBatching();
    
    // 2. íŒŒì´í”„ë¼ì´ë‹ ì„¤ì •
    const pipelineConfig = await this.optimizePipelining();
    
    // 3. ì••ì¶• í”„ë¡œí† ì½œ
    const compressionConfig = await this.selectCompressionProtocol();
    
    // 4. ì—°ê²° í’€ ì¡°ì •
    const connectionConfig = await this.tuneConnectionPool();
    
    return {
      batchSize: batchConfig.optimalSize,
      pipelineDepth: pipelineConfig.depth,
      compressionEnabled: compressionConfig.enabled,
      connectionPoolSize: connectionConfig.poolSize,
      latencyReduction: await this.measureLatencyReduction()
    };
  }

  // ìºì‹œ ì›Œë° ìµœì í™”
  async optimizeCacheWarming(): Promise<WarmingOptimizationResult> {
    const accessPatterns = await this.analyzer.getAccessPatterns();
    
    // 1. í•« ë°ì´í„° ì‹ë³„
    const hotData = this.identifyHotData(accessPatterns);
    
    // 2. í”„ë¦¬í˜ì¹˜ ì „ëµ
    const prefetchStrategy = this.createPrefetchStrategy(accessPatterns);
    
    // 3. ì›Œë° ìŠ¤ì¼€ì¤„ ìµœì í™”
    const warmingSchedule = this.optimizeWarmingSchedule(hotData);
    
    // 4. ì ì‘í˜• ì›Œë°
    const adaptiveConfig = await this.configureAdaptiveWarming({
      hotData,
      prefetchStrategy,
      warmingSchedule
    });
    
    return {
      hotDataIdentified: hotData.length,
      prefetchRules: prefetchStrategy.rules,
      warmingSchedule,
      adaptiveConfig,
      hitRateImprovement: await this.measureHitRateImprovement()
    };
  }

  // ì¿¼ë¦¬ ìµœì í™”
  async optimizeQueries(): Promise<QueryOptimizationResult> {
    const queryStats = await this.metricsCollector.getQueryStats();
    
    // 1. ëŠë¦° ì¿¼ë¦¬ ë¶„ì„
    const slowQueries = this.identifySlowQueries(queryStats);
    
    // 2. ì¿¼ë¦¬ íŒ¨í„´ ìµœì í™”
    const optimizedPatterns = await this.optimizeQueryPatterns(slowQueries);
    
    // 3. ì¸ë±ìŠ¤ ì¶”ì²œ
    const indexRecommendations = this.recommendIndexes(queryStats);
    
    // 4. ì¿¼ë¦¬ ì¬ì‘ì„±
    const rewrittenQueries = await this.rewriteQueries(slowQueries);
    
    return {
      slowQueriesOptimized: slowQueries.length,
      patternsOptimized: optimizedPatterns.length,
      indexesRecommended: indexRecommendations,
      queriesRewritten: rewrittenQueries.length,
      performanceGain: await this.measureQueryPerformanceGain()
    };
  }

  // ì ì‘í˜• TTL ì¡°ì •
  async adjustTTLDynamically(): Promise<void> {
    const ttlAnalyzer = new TTLAnalyzer(this.cache);
    
    // ê° í‚¤ íŒ¨í„´ë³„ ë¶„ì„
    const patterns = await ttlAnalyzer.analyzeKeyPatterns();
    
    for (const pattern of patterns) {
      const optimalTTL = await this.calculateOptimalTTL(pattern);
      
      // TTL ì¡°ì •
      await this.cache.adjustPatternTTL(
        pattern.pattern,
        optimalTTL
      );
      
      // ëª¨ë‹ˆí„°ë§
      this.monitorTTLEffectiveness(pattern.pattern, optimalTTL);
    }
  }

  // ìµœì  TTL ê³„ì‚°
  private async calculateOptimalTTL(
    pattern: KeyPattern
  ): Promise<number> {
    const factors = {
      accessFrequency: pattern.accessFrequency,
      updateFrequency: pattern.updateFrequency,
      dataVolatility: pattern.volatility,
      memoryPressure: await this.cache.getMemoryPressure(),
      hitRate: pattern.hitRate
    };
    
    // ML ëª¨ë¸ì„ ì‚¬ìš©í•œ TTL ì˜ˆì¸¡
    const predictedTTL = await this.ttlPredictor.predict(factors);
    
    // ì œì•½ ì¡°ê±´ ì ìš©
    return Math.min(
      Math.max(predictedTTL, this.config.minTTL || 60),
      this.config.maxTTL || 86400
    );
  }

  // ë©”ëª¨ë¦¬ ë‹¨í¸í™” í•´ê²°
  private async defragmentMemory(): Promise<void> {
    const strategy = this.config.defragStrategy || 'active';
    
    switch (strategy) {
      case 'active':
        // í™œì„± ì¡°ê° ëª¨ìŒ
        await this.performActiveDefragmentation();
        break;
        
      case 'lazy':
        // ì§€ì—° ì¡°ê° ëª¨ìŒ
        await this.scheduleLazyDefragmentation();
        break;
        
      case 'restart':
        // ì¬ì‹œì‘ ê¸°ë°˜ ì¡°ê° ëª¨ìŒ
        await this.performRollingRestart();
        break;
    }
  }

  // ì••ì¶• ìµœì í™”
  private async enableCompression(): Promise<void> {
    const compressionAnalyzer = new CompressionAnalyzer();
    
    // ë°ì´í„° íƒ€ì…ë³„ ë¶„ì„
    const dataTypes = await this.analyzeDataTypes();
    
    for (const dataType of dataTypes) {
      const algorithm = compressionAnalyzer.selectAlgorithm(dataType);
      
      await this.cache.enableCompression({
        pattern: dataType.pattern,
        algorithm,
        threshold: dataType.averageSize,
        level: this.selectCompressionLevel(dataType)
      });
    }
  }

  // ì„±ëŠ¥ ë³‘ëª© ì§€ì  ë¶„ì„
  async identifyBottlenecks(): Promise<Bottleneck[]> {
    const bottlenecks: Bottleneck[] = [];
    
    // CPU ë³‘ëª©
    const cpuStats = await this.metricsCollector.getCPUStats();
    if (cpuStats.usage > 0.8) {
      bottlenecks.push({
        type: 'cpu',
        severity: 'high',
        metrics: cpuStats,
        recommendations: ['Enable lazy deletion', 'Reduce background tasks']
      });
    }
    
    // ë„¤íŠ¸ì›Œí¬ ë³‘ëª©
    const networkStats = await this.metricsCollector.getNetworkStats();
    if (networkStats.saturation > 0.7) {
      bottlenecks.push({
        type: 'network',
        severity: 'medium',
        metrics: networkStats,
        recommendations: ['Enable compression', 'Increase batching']
      });
    }
    
    // ë©”ëª¨ë¦¬ ë³‘ëª©
    const memoryStats = await this.metricsCollector.getMemoryStats();
    if (memoryStats.usage > 0.9) {
      bottlenecks.push({
        type: 'memory',
        severity: 'critical',
        metrics: memoryStats,
        recommendations: ['Adjust eviction policy', 'Scale horizontally']
      });
    }
    
    return bottlenecks;
  }

  // ìë™ ìŠ¤ì¼€ì¼ë§
  async autoScale(): Promise<ScalingResult> {
    const metrics = await this.metricsCollector.getScalingMetrics();
    const decision = this.makeScalingDecision(metrics);
    
    if (decision.shouldScale) {
      if (decision.direction === 'up') {
        return await this.scaleUp(decision.count);
      } else {
        return await this.scaleDown(decision.count);
      }
    }
    
    return { scaled: false };
  }

  private async scaleUp(count: number): Promise<ScalingResult> {
    const newNodes: RedisNode[] = [];
    
    for (let i = 0; i < count; i++) {
      const node = await this.provisionNewNode();
      await this.cache.addNode(node);
      newNodes.push(node);
    }
    
    // ë°ì´í„° ë¦¬ë°¸ëŸ°ì‹±
    await this.rebalanceData();
    
    return {
      scaled: true,
      direction: 'up',
      nodesAdded: newNodes.length,
      newCapacity: await this.cache.getTotalCapacity()
    };
  }
}

// ì„±ëŠ¥ ë¶„ì„ê¸°
export class PerformanceAnalyzer {
  async analyze(metrics: CacheMetrics): Promise<AnalysisResult> {
    const problems = this.identifyProblems(metrics);
    const recommendations = this.generateRecommendations(problems);
    
    return {
      needsOptimization: problems.length > 0,
      problems,
      recommendations,
      estimatedImprovement: this.estimateImprovement(recommendations)
    };
  }
  
  private identifyProblems(metrics: CacheMetrics): Problem[] {
    const problems: Problem[] = [];
    
    // ë‚®ì€ íˆíŠ¸ìœ¨
    if (metrics.hitRate < 0.8) {
      problems.push({
        type: 'low_hit_rate',
        severity: 'high',
        value: metrics.hitRate,
        threshold: 0.8
      });
    }
    
    // ë†’ì€ ì§€ì—° ì‹œê°„
    if (metrics.p99Latency > 10) {
      problems.push({
        type: 'high_latency',
        severity: 'medium',
        value: metrics.p99Latency,
        threshold: 10
      });
    }
    
    // ë†’ì€ í‡´ê±°ìœ¨
    if (metrics.evictionRate > 0.1) {
      problems.push({
        type: 'high_eviction',
        severity: 'high',
        value: metrics.evictionRate,
        threshold: 0.1
      });
    }
    
    return problems;
  }
}
```

---

### Task 2.8: ìºì‹œ ë¬´íš¨í™” ì „ëµ

#### SubTask 2.8.1: ì´ë²¤íŠ¸ ê¸°ë°˜ ë¬´íš¨í™” ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ì´ë²¤íŠ¸ ì£¼ë„ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/cache/invalidation/event-based-invalidation.ts
export class EventBasedInvalidationSystem {
  private eventStream: EventStream;
  private invalidationRules: InvalidationRuleEngine;
  private cascadeManager: CascadeInvalidationManager;
  
  constructor(
    private cache: CacheLayer,
    private eventBus: EventBus,
    private config: EventInvalidationConfig
  ) {
    this.eventStream = new EventStream(eventBus);
    this.invalidationRules = new InvalidationRuleEngine();
    this.cascadeManager = new CascadeInvalidationManager(cache);
    
    this.initializeEventHandlers();
    this.loadInvalidationRules();
  }

  // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
  private initializeEventHandlers(): void {
    // ë„ë©”ì¸ ì´ë²¤íŠ¸ êµ¬ë…
    this.eventStream.subscribe('domain.*', async (event) => {
      await this.handleDomainEvent(event);
    });
    
    // ì‹œìŠ¤í…œ ì´ë²¤íŠ¸ êµ¬ë…
    this.eventStream.subscribe('system.*', async (event) => {
      await this.handleSystemEvent(event);
    });
    
    // ì»¤ìŠ¤í…€ ë¬´íš¨í™” ì´ë²¤íŠ¸
    this.eventStream.subscribe('cache.invalidate.*', async (event) => {
      await this.handleInvalidationEvent(event);
    });
  }

  // ë„ë©”ì¸ ì´ë²¤íŠ¸ ì²˜ë¦¬
  private async handleDomainEvent(event: DomainEvent): Promise<void> {
    const rules = this.invalidationRules.getRulesForEvent(event.type);
    
    for (const rule of rules) {
      try {
        const keysToInvalidate = await rule.evaluate(event);
        
        if (keysToInvalidate.length > 0) {
          await this.performInvalidation(keysToInvalidate, {
            reason: `Domain event: ${event.type}`,
            cascade: rule.cascade,
            priority: rule.priority
          });
        }
      } catch (error) {
        this.logger.error(`Rule evaluation failed: ${rule.id}`, error);
      }
    }
  }

  // ë¬´íš¨í™” ê·œì¹™ ì—”ì§„
  class InvalidationRuleEngine {
    private rules: Map<string, InvalidationRule[]> = new Map();
    
    // ê·œì¹™ ë“±ë¡
    registerRule(rule: InvalidationRule): void {
      const eventType = rule.eventPattern;
      
      if (!this.rules.has(eventType)) {
        this.rules.set(eventType, []);
      }
      
      this.rules.get(eventType)!.push(rule);
    }
    
    // ë™ì  ê·œì¹™ í‰ê°€
    async evaluate(
      event: DomainEvent,
      rule: InvalidationRule
    ): Promise<string[]> {
      const context = this.buildContext(event);
      const keysToInvalidate: string[] = [];
      
      // ì¡°ê±´ í‰ê°€
      if (await this.evaluateCondition(rule.condition, context)) {
        // í‚¤ íŒ¨í„´ ìƒì„±
        const patterns = this.generateKeyPatterns(rule.keyPatterns, context);
        
        // ì‹¤ì œ í‚¤ ì°¾ê¸°
        for (const pattern of patterns) {
          const keys = await this.cache.scanKeys(pattern);
          keysToInvalidate.push(...keys);
        }
        
        // ì¶”ê°€ í‚¤ ê³„ì‚°
        if (rule.computeAdditionalKeys) {
          const additionalKeys = await rule.computeAdditionalKeys(event);
          keysToInvalidate.push(...additionalKeys);
        }
      }
      
      return keysToInvalidate;
    }
    
    // ì¡°ê±´ í‰ê°€
    private async evaluateCondition(
      condition: InvalidationCondition,
      context: EvaluationContext
    ): Promise<boolean> {
      switch (condition.type) {
        case 'simple':
          return this.evaluateSimpleCondition(condition, context);
          
        case 'complex':
          return await this.evaluateComplexCondition(condition, context);
          
        case 'script':
          return await this.evaluateScriptCondition(condition, context);
          
        default:
          return true;
      }
    }
  }

  // ê³„ë‹¨ì‹ ë¬´íš¨í™” ê´€ë¦¬ì
  class CascadeInvalidationManager {
    private dependencyGraph: DependencyGraph;
    
    constructor(private cache: CacheLayer) {
      this.dependencyGraph = new DependencyGraph();
    }
    
    // ê³„ë‹¨ì‹ ë¬´íš¨í™” ì‹¤í–‰
    async performCascade(
      initialKeys: string[],
      options: CascadeOptions
    ): Promise<CascadeResult> {
      const visited = new Set<string>();
      const queue = [...initialKeys];
      const invalidated: string[] = [];
      
      while (queue.length > 0 && invalidated.length < options.maxKeys) {
        const key = queue.shift()!;
        
        if (visited.has(key)) continue;
        visited.add(key);
        
        // í‚¤ ë¬´íš¨í™”
        await this.cache.invalidate(key);
        invalidated.push(key);
        
        // ì˜ì¡´ì„± ì°¾ê¸°
        if (options.depth > 0) {
          const dependencies = await this.findDependencies(key);
          
          for (const dep of dependencies) {
            if (!visited.has(dep)) {
              queue.push(dep);
            }
          }
        }
      }
      
      return {
        invalidatedKeys: invalidated,
        cascadeDepth: this.calculateDepth(initialKeys, invalidated),
        truncated: queue.length > 0
      };
    }
    
    // ì˜ì¡´ì„± ì°¾ê¸°
    private async findDependencies(key: string): Promise<string[]> {
      const dependencies: string[] = [];
      
      // ì§ì ‘ ì˜ì¡´ì„±
      const directDeps = this.dependencyGraph.getDirectDependencies(key);
      dependencies.push(...directDeps);
      
      // íŒ¨í„´ ê¸°ë°˜ ì˜ì¡´ì„±
      const patternDeps = await this.findPatternDependencies(key);
      dependencies.push(...patternDeps);
      
      // ê³„ì‚°ëœ ì˜ì¡´ì„±
      const computedDeps = await this.computeDependencies(key);
      dependencies.push(...computedDeps);
      
      return [...new Set(dependencies)];
    }
  }

  // ì‹¤ì‹œê°„ ë¬´íš¨í™” ì¶”ì 
  async trackInvalidation(
    invalidation: InvalidationEvent
  ): Promise<void> {
    const tracking = {
      id: uuidv4(),
      timestamp: Date.now(),
      keys: invalidation.keys,
      reason: invalidation.reason,
      source: invalidation.source,
      impact: await this.assessImpact(invalidation)
    };
    
    // ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    await this.updateMetrics(tracking);
    
    // ì´ìƒ ê°ì§€
    if (tracking.impact.severity === 'high') {
      await this.handleHighImpactInvalidation(tracking);
    }
    
    // ë¡œê¹…
    await this.logInvalidation(tracking);
  }

  // ì˜í–¥ í‰ê°€
  private async assessImpact(
    invalidation: InvalidationEvent
  ): Promise<InvalidationImpact> {
    const metrics = await this.cache.getMetrics();
    
    return {
      keysInvalidated: invalidation.keys.length,
      estimatedCacheMisses: this.estimateCacheMisses(invalidation),
      affectedUsers: await this.estimateAffectedUsers(invalidation),
      performanceImpact: this.calculatePerformanceImpact(metrics),
      severity: this.calculateSeverity(invalidation)
    };
  }

  // ë¬´íš¨í™” ìµœì í™”
  async optimizeInvalidation(
    event: DomainEvent
  ): Promise<OptimizedInvalidation> {
    const baseKeys = await this.getBaseKeysForInvalidation(event);
    
    // 1. ì¤‘ë³µ ì œê±°
    const uniqueKeys = this.deduplicateKeys(baseKeys);
    
    // 2. ë°°ì¹˜ ê·¸ë£¹í™”
    const batches = this.groupIntoBatches(uniqueKeys);
    
    // 3. ìš°ì„ ìˆœìœ„ ì •ë ¬
    const prioritized = this.prioritizeKeys(batches);
    
    // 4. ì‹œê°„ ë¶„ì‚°
    const scheduled = this.scheduleInvalidation(prioritized);
    
    return {
      original: baseKeys.length,
      optimized: uniqueKeys.length,
      batches: scheduled,
      estimatedDuration: this.estimateDuration(scheduled)
    };
  }
}

// ë¬´íš¨í™” ê·œì¹™ ì •ì˜
export const invalidationRules: InvalidationRule[] = [
  {
    id: 'user-update-profile',
    eventPattern: 'user.profile.updated',
    condition: {
      type: 'simple',
      field: 'changes',
      operator: 'contains',
      value: ['email', 'username', 'role']
    },
    keyPatterns: [
      'user:{event.userId}',
      'user:{event.userId}:profile',
      'user:email:{event.oldEmail}',
      'user:username:{event.oldUsername}'
    ],
    cascade: true,
    priority: 'high',
    computeAdditionalKeys: async (event) => {
      // ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ ìºì‹œë„ ë¬´íš¨í™”
      return [
        `user:${event.userId}:projects`,
        `user:${event.userId}:permissions`
      ];
    }
  },
  
  {
    id: 'project-status-change',
    eventPattern: 'project.status.changed',
    condition: {
      type: 'complex',
      expression: `
        event.oldStatus !== event.newStatus && 
        ['active', 'archived'].includes(event.newStatus)
      `
    },
    keyPatterns: [
      'project:{event.projectId}',
      'project:{event.projectId}:*',
      'projects:status:{event.oldStatus}',
      'projects:status:{event.newStatus}'
    ],
    cascade: true,
    priority: 'medium'
  },
  
  {
    id: 'agent-task-completion',
    eventPattern: 'agent.task.completed',
    condition: {
      type: 'simple',
      field: 'success',
      operator: 'equals',
      value: true
    },
    keyPatterns: [
      'agent:{event.agentId}:status',
      'task:{event.taskId}',
      'project:{event.projectId}:tasks',
      'project:{event.projectId}:progress'
    ],
    cascade: false,
    priority: 'low'
  }
];

// ë¬´íš¨í™” ì´ë²¤íŠ¸ í”„ë¡œì„¸ì„œ
export class InvalidationEventProcessor {
  private queue: Queue<InvalidationJob>;
  private workers: InvalidationWorker[];
  
  constructor(
    private cache: CacheLayer,
    private config: ProcessorConfig
  ) {
    this.queue = new Queue('invalidation-jobs');
    this.workers = this.createWorkers(config.workerCount || 4);
  }
  
  // ë¹„ë™ê¸° ì²˜ë¦¬
  async processAsync(job: InvalidationJob): Promise<void> {
    await this.queue.add(job, {
      priority: this.getPriority(job),
      delay: this.calculateDelay(job),
      attempts: 3,
      backoff: {
        type: 'exponential',
        delay: 1000
      }
    });
  }
  
  // ì›Œì»¤ ìƒì„±
  private createWorkers(count: number): InvalidationWorker[] {
    const workers: InvalidationWorker[] = [];
    
    for (let i = 0; i < count; i++) {
      const worker = new InvalidationWorker(this.cache, {
        id: `worker-${i}`,
        batchSize: this.config.batchSize || 100,
        concurrency: this.config.concurrency || 10
      });
      
      worker.on('job:complete', this.onJobComplete.bind(this));
      worker.on('job:failed', this.onJobFailed.bind(this));
      
      workers.push(worker);
    }
    
    return workers;
  }
  
  // ì‘ì—… ì™„ë£Œ ì²˜ë¦¬
  private async onJobComplete(result: JobResult): Promise<void> {
    await this.updateMetrics(result);
    
    if (result.cascadeRequired) {
      await this.scheduleCascadeJobs(result.cascadeKeys);
    }
  }
}
```

#### SubTask 2.8.2: ì§€ëŠ¥í˜• ìºì‹œ ê°±ì‹ 
**ë‹´ë‹¹ì**: ML ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/cache/intelligent/smart-refresh.ts
export class IntelligentCacheRefresh {
  private predictor: CacheAccessPredictor;
  private refreshScheduler: RefreshScheduler;
  private costAnalyzer: RefreshCostAnalyzer;
  
  constructor(
    private cache: CacheLayer,
    private dataSource: DataSource,
    private config: SmartRefreshConfig
  ) {
    this.predictor = new CacheAccessPredictor();
    this.refreshScheduler = new RefreshScheduler();
    this.costAnalyzer = new RefreshCostAnalyzer();
    
    this.initializeMLModels();
    this.startPredictiveRefresh();
  }

  // ML ëª¨ë¸ ì´ˆê¸°í™”
  private async initializeMLModels(): Promise<void> {
    // ì ‘ê·¼ íŒ¨í„´ ì˜ˆì¸¡ ëª¨ë¸
    await this.predictor.loadModel('access-pattern-v2');
    
    // ë¹„ìš© ì˜ˆì¸¡ ëª¨ë¸
    await this.costAnalyzer.loadModel('refresh-cost-v1');
    
    // ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    this.monitorModelPerformance();
  }

  // ì˜ˆì¸¡ì  ê°±ì‹  ì‹œì‘
  private startPredictiveRefresh(): void {
    setInterval(async () => {
      const predictions = await this.generateRefreshPredictions();
      const optimizedPlan = await this.optimizeRefreshPlan(predictions);
      
      await this.executeRefreshPlan(optimizedPlan);
    }, this.config.predictionInterval || 60000); // 1ë¶„
  }

  // ê°±ì‹  ì˜ˆì¸¡ ìƒì„±
  private async generateRefreshPredictions(): Promise<RefreshPrediction[]> {
    const predictions: RefreshPrediction[] = [];
    
    // 1. ì‹œê³„ì—´ ë¶„ì„
    const timeSeriesPatterns = await this.analyzeTimeSeriesPatterns();
    
    // 2. ì ‘ê·¼ ë¹ˆë„ ì˜ˆì¸¡
    const accessPredictions = await this.predictor.predictNextAccess(
      timeSeriesPatterns
    );
    
    // 3. ë°ì´í„° ë³€ê²½ í™•ë¥  ì˜ˆì¸¡
    const changeProbabilities = await this.predictDataChanges();
    
    // 4. í†µí•© ì˜ˆì¸¡ ìƒì„±
    for (const pattern of timeSeriesPatterns) {
      const prediction = await this.createRefreshPrediction(
        pattern,
        accessPredictions.get(pattern.key),
        changeProbabilities.get(pattern.key)
      );
      
      predictions.push(prediction);
    }
    
    return predictions;
  }

  // ê°±ì‹  ì˜ˆì¸¡ ìƒì„±
  private async createRefreshPrediction(
    pattern: TimeSeriesPattern,
    accessPrediction: AccessPrediction,
    changeProbability: number
  ): Promise<RefreshPrediction> {
    const now = Date.now();
    
    return {
      key: pattern.key,
      nextAccessTime: accessPrediction.timestamp,
      accessProbability: accessPrediction.probability,
      changeProbability,
      currentAge: now - pattern.lastRefresh,
      ttlRemaining: pattern.ttl - (now - pattern.lastRefresh),
      refreshValue: this.calculateRefreshValue(
        accessPrediction,
        changeProbability,
        pattern
      ),
      recommendedAction: this.determineAction(
        accessPrediction,
        changeProbability,
        pattern
      )
    };
  }

  // ê°±ì‹  ê°€ì¹˜ ê³„ì‚°
  private calculateRefreshValue(
    access: AccessPrediction,
    changeProb: number,
    pattern: TimeSeriesPattern
  ): number {
    // ê°±ì‹  ì´ìµ = (ì ‘ê·¼ í™•ë¥  Ã— íˆíŠ¸ ê°€ì¹˜) - (ê°±ì‹  ë¹„ìš©)
    const hitValue = pattern.averageResponseTime * pattern.accessFrequency;
    const refreshCost = pattern.dataSize * this.config.refreshCostPerByte;
    
    const expectedBenefit = access.probability * hitValue;
    const expectedCost = refreshCost + (changeProb * refreshCost);
    
    return expectedBenefit - expectedCost;
  }

  // ê°±ì‹  ê³„íš ìµœì í™”
  private async optimizeRefreshPlan(
    predictions: RefreshPrediction[]
  ): Promise<RefreshPlan> {
    // 1. ë¦¬ì†ŒìŠ¤ ì œì•½ í™•ì¸
    const resources = await this.getAvailableResources();
    
    // 2. ìš°ì„ ìˆœìœ„ í ìƒì„±
    const priorityQueue = new PriorityQueue<RefreshTask>(
      (a, b) => b.priority - a.priority
    );
    
    // 3. íƒœìŠ¤í¬ ìƒì„± ë° ìš°ì„ ìˆœìœ„ ì§€ì •
    for (const prediction of predictions) {
      if (prediction.recommendedAction === 'refresh') {
        const task = await this.createRefreshTask(prediction);
        priorityQueue.enqueue(task);
      }
    }
    
    // 4. ë¦¬ì†ŒìŠ¤ í• ë‹¹ ìµœì í™”
    const plan = await this.allocateResources(
      priorityQueue,
      resources
    );
    
    return plan;
  }

  // ì ì‘í˜• TTL ì¡°ì •
  async adaptiveTTLAdjustment(): Promise<void> {
    const patterns = await this.cache.getAccessPatterns();
    
    for (const pattern of patterns) {
      const analysis = await this.analyzeTTLEffectiveness(pattern);
      
      if (analysis.needsAdjustment) {
        const newTTL = await this.calculateOptimalTTL(pattern, analysis);
        
        await this.cache.adjustTTL(pattern.key, newTTL);
        
        // í•™ìŠµ
        await this.predictor.learn({
          pattern,
          oldTTL: pattern.ttl,
          newTTL,
          outcome: analysis
        });
      }
    }
  }

  // ìµœì  TTL ê³„ì‚°
  private async calculateOptimalTTL(
    pattern: AccessPattern,
    analysis: TTLAnalysis
  ): Promise<number> {
    const factors = {
      accessFrequency: pattern.frequency,
      accessVariability: pattern.variability,
      dataVolatility: analysis.changeRate,
      hitRate: analysis.hitRate,
      memoryPressure: await this.cache.getMemoryPressure()
    };
    
    // ML ê¸°ë°˜ TTL ì˜ˆì¸¡
    const predictedTTL = await this.predictor.predictOptimalTTL(factors);
    
    // ì•ˆì „ ë²”ìœ„ ì ìš©
    return this.constrainTTL(predictedTTL, pattern);
  }

  // í”„ë¡œì•¡í‹°ë¸Œ ê°±ì‹ 
  async proactiveRefresh(): Promise<ProactiveRefreshResult> {
    const candidates = await this.identifyRefreshCandidates();
    const refreshed: string[] = [];
    const skipped: string[] = [];
    
    for (const candidate of candidates) {
      const decision = await this.makeRefreshDecision(candidate);
      
      if (decision.shouldRefresh) {
        try {
          await this.refreshCacheEntry(candidate.key);
          refreshed.push(candidate.key);
          
          // ì„±ê³µ í•™ìŠµ
          await this.recordRefreshSuccess(candidate, decision);
        } catch (error) {
          // ì‹¤íŒ¨ í•™ìŠµ
          await this.recordRefreshFailure(candidate, decision, error);
        }
      } else {
        skipped.push(candidate.key);
      }
    }
    
    return {
      totalCandidates: candidates.length,
      refreshed: refreshed.length,
      skipped: skipped.length,
      successRate: refreshed.length / candidates.length
    };
  }

  // ê°±ì‹  í›„ë³´ ì‹ë³„
  private async identifyRefreshCandidates(): Promise<RefreshCandidate[]> {
    const candidates: RefreshCandidate[] = [];
    
    // 1. TTL ì„ë°• í•­ëª©
    const expiringKeys = await this.cache.getExpiringKeys(
      this.config.refreshWindow || 300000 // 5ë¶„
    );
    
    for (const key of expiringKeys) {
      const metadata = await this.cache.getMetadata(key);
      const score = await this.scoreCandidate(key, metadata);
      
      candidates.push({
        key,
        score,
        metadata,
        reason: 'ttl_expiring'
      });
    }
    
    // 2. ì ‘ê·¼ íŒ¨í„´ ê¸°ë°˜
    const predictedAccess = await this.predictor.getUpcomingAccess();
    
    for (const prediction of predictedAccess) {
      if (!this.cache.exists(prediction.key)) {
        candidates.push({
          key: prediction.key,
          score: prediction.confidence,
          metadata: null,
          reason: 'predicted_access'
        });
      }
    }
    
    // 3. ë³€ê²½ ê°ì§€ ê¸°ë°˜
    const potentialChanges = await this.detectPotentialChanges();
    
    for (const change of potentialChanges) {
      candidates.push({
        key: change.key,
        score: change.probability,
        metadata: await this.cache.getMetadata(change.key),
        reason: 'change_detected'
      });
    }
    
    return candidates.sort((a, b) => b.score - a.score);
  }

  // ê°±ì‹  ê²°ì •
  private async makeRefreshDecision(
    candidate: RefreshCandidate
  ): Promise<RefreshDecision> {
    // ë¹„ìš©-ì´ìµ ë¶„ì„
    const cost = await this.costAnalyzer.calculateRefreshCost(candidate);
    const benefit = await this.calculateRefreshBenefit(candidate);
    
    // ë¦¬ì†ŒìŠ¤ ê°€ìš©ì„±
    const resourceAvailable = await this.checkResourceAvailability();
    
    // ML ì˜ˆì¸¡
    const prediction = await this.predictor.shouldRefresh({
      candidate,
      cost,
      benefit,
      resources: resourceAvailable
    });
    
    return {
      shouldRefresh: prediction.confidence > 0.7 && benefit > cost * 1.5,
      confidence: prediction.confidence,
      reasoning: prediction.reasoning,
      expectedValue: benefit - cost
    };
  }

  // ë³€ê²½ ê°ì§€
  private async detectPotentialChanges(): Promise<ChangeDetection[]> {
    const detections: ChangeDetection[] = [];
    
    // 1. ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ë¶„ì„
    const recentEvents = await this.eventStream.getRecent(1000);
    const changeSignals = this.analyzeEventsForChanges(recentEvents);
    
    // 2. ë°ì´í„° ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
    const sourceChanges = await this.monitorDataSources();
    
    // 3. íŒ¨í„´ ê¸°ë°˜ ê°ì§€
    const patternChanges = await this.detectPatternBasedChanges();
    
    // í†µí•©
    for (const signal of [...changeSignals, ...sourceChanges, ...patternChanges]) {
      detections.push({
        key: signal.key,
        probability: signal.probability,
        source: signal.source,
        timestamp: Date.now()
      });
    }
    
    return detections;
  }

  // ê°±ì‹  ì‹¤í–‰
  private async refreshCacheEntry(key: string): Promise<void> {
    const startTime = Date.now();
    
    try {
      // 1. ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë¡œë“œ
      const freshData = await this.dataSource.load(key);
      
      // 2. ë³€í™˜ ì ìš©
      const transformed = await this.applyTransformation(freshData);
      
      // 3. ìºì‹œ ì—…ë°ì´íŠ¸
      await this.cache.set(key, transformed, {
        ttl: await this.calculateAdaptiveTTL(key),
        tags: await this.generateTags(key, transformed)
      });
      
      // 4. ë©”íŠ¸ë¦­ ê¸°ë¡
      await this.recordRefreshMetrics(key, {
        duration: Date.now() - startTime,
        dataSize: JSON.stringify(transformed).length,
        success: true
      });
      
    } catch (error) {
      await this.handleRefreshError(key, error);
      throw error;
    }
  }
}

// ìºì‹œ ì ‘ê·¼ ì˜ˆì¸¡ê¸°
export class CacheAccessPredictor {
  private model: TensorFlowModel;
  private featureExtractor: FeatureExtractor;
  
  async predictNextAccess(
    patterns: TimeSeriesPattern[]
  ): Promise<Map<string, AccessPrediction>> {
    const predictions = new Map<string, AccessPrediction>();
    
    for (const pattern of patterns) {
      // íŠ¹ì§• ì¶”ì¶œ
      const features = await this.featureExtractor.extract(pattern);
      
      // ì˜ˆì¸¡
      const prediction = await this.model.predict(features);
      
      predictions.set(pattern.key, {
        timestamp: prediction.nextAccessTime,
        probability: prediction.confidence,
        uncertainty: prediction.uncertainty
      });
    }
    
    return predictions;
  }
  
  // ëª¨ë¸ í•™ìŠµ
  async learn(example: LearningExample): Promise<void> {
    const features = await this.featureExtractor.extract(example.pattern);
    const label = example.outcome;
    
    await this.model.train([{ features, label }]);
    
    // ì£¼ê¸°ì  ì¬í•™ìŠµ
    if (this.shouldRetrain()) {
      await this.retrainModel();
    }
  }
}

// ê°±ì‹  ìŠ¤ì¼€ì¤„ëŸ¬
export class RefreshScheduler {
  private schedule: Map<string, ScheduledRefresh> = new Map();
  private executor: ScheduledExecutor;
  
  async scheduleRefresh(
    key: string,
    time: Date,
    priority: number
  ): Promise<void> {
    const task: ScheduledRefresh = {
      id: uuidv4(),
      key,
      scheduledTime: time,
      priority,
      status: 'pending'
    };
    
    this.schedule.set(task.id, task);
    
    await this.executor.schedule(task.id, time, async () => {
      await this.executeRefresh(task);
    });
  }
  
  // ë™ì  ì¬ìŠ¤ì¼€ì¤„ë§
  async reschedule(
    taskId: string,
    newTime: Date
  ): Promise<void> {
    const task = this.schedule.get(taskId);
    if (!task || task.status !== 'pending') {
      return;
    }
    
    await this.executor.cancel(taskId);
    task.scheduledTime = newTime;
    
    await this.executor.schedule(taskId, newTime, async () => {
      await this.executeRefresh(task);
    });
  }
  
  // ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì‹¤í–‰
  private async executeRefresh(task: ScheduledRefresh): Promise<void> {
    task.status = 'executing';
    
    try {
      await this.refreshWithPriority(task.key, task.priority);
      task.status = 'completed';
    } catch (error) {
      task.status = 'failed';
      task.error = error;
      
      // ì¬ì‹œë„ ë¡œì§
      if (this.shouldRetry(task)) {
        await this.scheduleRetry(task);
      }
    }
  }
}
```

#### SubTask 2.8.3: ì˜ì¡´ì„± ê¸°ë°˜ ë¬´íš¨í™”
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/cache/invalidation/dependency-invalidation.ts
export class DependencyBasedInvalidation {
  private dependencyGraph: CacheDependencyGraph;
  private invalidationEngine: InvalidationEngine;
  private impactAnalyzer: ImpactAnalyzer;
  
  constructor(
    private cache: CacheLayer,
    private config: DependencyConfig
  ) {
    this.dependencyGraph = new CacheDependencyGraph();
    this.invalidationEngine = new InvalidationEngine(cache);
    this.impactAnalyzer = new ImpactAnalyzer();
    
    this.initializeDependencyTracking();
  }

  // ì˜ì¡´ì„± ê·¸ë˜í”„ êµ¬ì¶•
  async buildDependencyGraph(
    entities: EntityDefinition[]
  ): Promise<void> {
    // 1. ì—”í‹°í‹° ê´€ê³„ ë¶„ì„
    const relationships = this.analyzeEntityRelationships(entities);
    
    // 2. ìºì‹œ í‚¤ ì˜ì¡´ì„± ë§¤í•‘
    for (const rel of relationships) {
      await this.mapCacheDependencies(rel);
    }
    
    // 3. ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
    const cycles = this.dependencyGraph.detectCycles();
    if (cycles.length > 0) {
      throw new Error(`Circular dependencies detected: ${cycles}`);
    }
    
    // 4. ìµœì í™”
    await this.optimizeDependencyGraph();
  }

  // ìºì‹œ ì˜ì¡´ì„± ë§¤í•‘
  private async mapCacheDependencies(
    relationship: EntityRelationship
  ): Promise<void> {
    const patterns = this.generateDependencyPatterns(relationship);
    
    for (const pattern of patterns) {
      this.dependencyGraph.addDependency(
        pattern.parent,
        pattern.child,
        {
          type: pattern.type,
          propagation: pattern.propagation,
          condition: pattern.condition
        }
      );
    }
  }

  // ì˜ì¡´ì„± ì „íŒŒ ë¬´íš¨í™”
  async invalidateWithDependencies(
    key: string,
    options?: InvalidationOptions
  ): Promise<DependencyInvalidationResult> {
    const startTime = Date.now();
    const invalidated = new Set<string>();
    
    try {
      // 1. ë£¨íŠ¸ í‚¤ ë¬´íš¨í™”
      await this.cache.invalidate(key);
      invalidated.add(key);
      
      // 2. ì§ì ‘ ì˜ì¡´ì„± ì°¾ê¸°
      const directDeps = this.dependencyGraph.getDirectDependents(key);
      
      // 3. ì „ì´ì  ì˜ì¡´ì„± ê³„ì‚°
      const transitiveDeps = await this.calculateTransitiveDependencies(
        key,
        options?.maxDepth || 5
      );
      
      // 4. ì˜í–¥ ë¶„ì„
      const impact = await this.impactAnalyzer.analyze(
        key,
        [...directDeps, ...transitiveDeps]
      );
      
      // 5. ì„ íƒì  ë¬´íš¨í™”
      const toInvalidate = await this.selectKeysForInvalidation(
        [...directDeps, ...transitiveDeps],
        impact,
        options
      );
      
      // 6. ë°°ì¹˜ ë¬´íš¨í™” ì‹¤í–‰
      await this.batchInvalidate(toInvalidate);
      toInvalidate.forEach(k => invalidated.add(k));
      
      return {
        success: true,
        rootKey: key,
        invalidatedCount: invalidated.size,
        directDependencies: directDeps.length,
        transitiveDependencies: transitiveDeps.length,
        duration: Date.now() - startTime,
        impact
      };
      
    } catch (error) {
      return {
        success: false,
        rootKey: key,
        error: error.message,
        invalidatedCount: invalidated.size,
        duration: Date.now() - startTime
      };
    }
  }

  // ì „ì´ì  ì˜ì¡´ì„± ê³„ì‚°
  private async calculateTransitiveDependencies(
    rootKey: string,
    maxDepth: number
  ): Promise<string[]> {
    const visited = new Set<string>();
    const dependencies: string[] = [];
    const queue: Array<{ key: string; depth: number }> = [
      { key: rootKey, depth: 0 }
    ];
    
    while (queue.length > 0) {
      const { key, depth } = queue.shift()!;
      
      if (visited.has(key) || depth >= maxDepth) {
        continue;
      }
      
      visited.add(key);
      
      const deps = this.dependencyGraph.getDirectDependents(key);
      
      for (const dep of deps) {
        if (!visited.has(dep)) {
          dependencies.push(dep);
          queue.push({ key: dep, depth: depth + 1 });
        }
      }
    }
    
    return dependencies;
  }

  // ì„ íƒì  ë¬´íš¨í™”
  private async selectKeysForInvalidation(
    candidates: string[],
    impact: ImpactAnalysis,
    options?: InvalidationOptions
  ): Promise<string[]> {
    const selected: string[] = [];
    
    for (const key of candidates) {
      const shouldInvalidate = await this.evaluateInvalidation(
        key,
        impact,
        options
      );
      
      if (shouldInvalidate) {
        selected.push(key);
      }
    }
    
    return selected;
  }

  // ë¬´íš¨í™” í‰ê°€
  private async evaluateInvalidation(
    key: string,
    impact: ImpactAnalysis,
    options?: InvalidationOptions
  ): Promise<boolean> {
    // 1. ì˜ì¡´ì„± ì¡°ê±´ í™•ì¸
    const dependency = this.dependencyGraph.getDependency(key);
    if (dependency.condition) {
      const conditionMet = await this.evaluateCondition(
        dependency.condition,
        { key, impact }
      );
      
      if (!conditionMet) {
        return false;
      }
    }
    
    // 2. ì „íŒŒ ì •ì±… í™•ì¸
    if (dependency.propagation === 'manual') {
      return false;
    }
    
    // 3. ì„ê³„ê°’ í™•ì¸
    if (options?.threshold) {
      const score = this.calculateInvalidationScore(key, impact);
      return score >= options.threshold;
    }
    
    return true;
  }

  // ì˜ì¡´ì„± ê·¸ë˜í”„ ì‹œê°í™”
  async visualizeDependencies(
    rootKey?: string
  ): Promise<DependencyVisualization> {
    const nodes: VisualizationNode[] = [];
    const edges: VisualizationEdge[] = [];
    
    if (rootKey) {
      // íŠ¹ì • í‚¤ì˜ ì˜ì¡´ì„± íŠ¸ë¦¬
      await this.buildVisualizationTree(rootKey, nodes, edges);
    } else {
      // ì „ì²´ ê·¸ë˜í”„
      await this.buildFullVisualization(nodes, edges);
    }
    
    return {
      nodes,
      edges,
      stats: {
        totalNodes: nodes.length,
        totalEdges: edges.length,
        maxDepth: this.calculateMaxDepth(nodes, edges),
        clusters: this.identifyClusters(nodes, edges)
      },
      layout: this.calculateLayout(nodes, edges)
    };
  }

  // ì˜ì¡´ì„± ìµœì í™”
  private async optimizeDependencyGraph(): Promise<void> {
    // 1. ì¤‘ë³µ ê²½ë¡œ ì œê±°
    this.removeDuplicatePaths();
    
    // 2. ì•½í•œ ì˜ì¡´ì„± ì œê±°
    await this.pruneWeakDependencies();
    
    // 3. ì˜ì¡´ì„± ë³‘í•©
    this.mergeSimilarDependencies();
    
    // 4. ì¸ë±ìŠ¤ ì¬êµ¬ì„±
    this.rebuildIndices();
  }

  // ë™ì  ì˜ì¡´ì„± ì¶”ì 
  async trackDynamicDependencies(): Promise<void> {
    // ìºì‹œ ì ‘ê·¼ íŒ¨í„´ ëª¨ë‹ˆí„°ë§
    this.cache.on('access', async (event) => {
      if (event.context?.parentKey) {
        await this.recordDynamicDependency(
          event.context.parentKey,
          event.key
        );
      }
    });
    
    // ì£¼ê¸°ì  ë¶„ì„
    setInterval(async () => {
      await this.analyzeDynamicDependencies();
    }, this.config.analysisInterval || 3600000); // 1ì‹œê°„
  }

  // ë™ì  ì˜ì¡´ì„± ê¸°ë¡
  private async recordDynamicDependency(
    parentKey: string,
    childKey: string
  ): Promise<void> {
    const existing = this.dependencyGraph.getDependency(childKey);
    
    if (!existing || existing.type === 'dynamic') {
      await this.dependencyGraph.addDependency(
        parentKey,
        childKey,
        {
          type: 'dynamic',
          confidence: 0.5,
          lastSeen: Date.now()
        }
      );
    }
  }

  // ì˜ì¡´ì„± íŒ¨í„´ í•™ìŠµ
  async learnDependencyPatterns(): Promise<void> {
    const patterns = await this.extractDependencyPatterns();
    
    for (const pattern of patterns) {
      if (pattern.frequency > this.config.patternThreshold) {
        await this.applyPatternToDependencyGraph(pattern);
      }
    }
  }
}

// ìºì‹œ ì˜ì¡´ì„± ê·¸ë˜í”„
export class CacheDependencyGraph {
  private adjacencyList: Map<string, Set<DependencyEdge>>;
  private reverseAdjacencyList: Map<string, Set<DependencyEdge>>;
  private metadata: Map<string, DependencyMetadata>;
  
  constructor() {
    this.adjacencyList = new Map();
    this.reverseAdjacencyList = new Map();
    this.metadata = new Map();
  }
  
  // ì˜ì¡´ì„± ì¶”ê°€
  addDependency(
    parent: string,
    child: string,
    options: DependencyOptions
  ): void {
    const edge: DependencyEdge = {
      from: parent,
      to: child,
      ...options
    };
    
    // ì •ë°©í–¥ ê·¸ë˜í”„
    if (!this.adjacencyList.has(parent)) {
      this.adjacencyList.set(parent, new Set());
    }
    this.adjacencyList.get(parent)!.add(edge);
    
    // ì—­ë°©í–¥ ê·¸ë˜í”„
    if (!this.reverseAdjacencyList.has(child)) {
      this.reverseAdjacencyList.set(child, new Set());
    }
    this.reverseAdjacencyList.get(child)!.add(edge);
    
    // ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
    this.updateMetadata(parent, child);
  }
  
  // ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€
  detectCycles(): string[][] {
    const cycles: string[][] = [];
    const visited = new Set<string>();
    const recursionStack = new Set<string>();
    
    const dfs = (node: string, path: string[]): void => {
      visited.add(node);
      recursionStack.add(node);
      path.push(node);
      
      const edges = this.adjacencyList.get(node) || new Set();
      
      for (const edge of edges) {
        if (!visited.has(edge.to)) {
          dfs(edge.to, [...path]);
        } else if (recursionStack.has(edge.to)) {
          // ì‚¬ì´í´ ë°œê²¬
          const cycleStart = path.indexOf(edge.to);
          cycles.push(path.slice(cycleStart));
        }
      }
      
      recursionStack.delete(node);
    };
    
    // ëª¨ë“  ë…¸ë“œì—ì„œ DFS ì‹œì‘
    for (const node of this.adjacencyList.keys()) {
      if (!visited.has(node)) {
        dfs(node, []);
      }
    }
    
    return cycles;
  }
  
  // ì˜ì¡´ì„± ê²½ë¡œ ì°¾ê¸°
  findPaths(
    from: string,
    to: string,
    maxDepth: number = 10
  ): string[][] {
    const paths: string[][] = [];
    
    const dfs = (
      current: string,
      target: string,
      path: string[],
      depth: number
    ): void => {
      if (depth > maxDepth) return;
      
      path.push(current);
      
      if (current === target) {
        paths.push([...path]);
        return;
      }
      
      const edges = this.adjacencyList.get(current) || new Set();
      
      for (const edge of edges) {
        if (!path.includes(edge.to)) {
          dfs(edge.to, target, path, depth + 1);
          path.pop();
        }
      }
    };
    
    dfs(from, to, [], 0);
    return paths;
  }
  
  // ì˜í–¥ ë²”ìœ„ ê³„ì‚°
  calculateImpactScope(key: string): ImpactScope {
    const directImpact = new Set<string>();
    const indirectImpact = new Set<string>();
    
    // BFSë¡œ ì˜í–¥ ë²”ìœ„ ê³„ì‚°
    const queue: Array<{ key: string; distance: number }> = [
      { key, distance: 0 }
    ];
    const visited = new Set<string>();
    
    while (queue.length > 0) {
      const { key: current, distance } = queue.shift()!;
      
      if (visited.has(current)) continue;
      visited.add(current);
      
      const edges = this.adjacencyList.get(current) || new Set();
      
      for (const edge of edges) {
        if (distance === 0) {
          directImpact.add(edge.to);
        } else {
          indirectImpact.add(edge.to);
        }
        
        queue.push({ key: edge.to, distance: distance + 1 });
      }
    }
    
    return {
      direct: Array.from(directImpact),
      indirect: Array.from(indirectImpact),
      total: directImpact.size + indirectImpact.size
    };
  }
}

// ì˜í–¥ ë¶„ì„ê¸°
export class ImpactAnalyzer {
  async analyze(
    rootKey: string,
    affectedKeys: string[]
  ): Promise<ImpactAnalysis> {
    const metrics = await this.collectMetrics(affectedKeys);
    
    return {
      totalKeys: affectedKeys.length,
      estimatedCacheMisses: this.estimateCacheMisses(metrics),
      estimatedLatencyIncrease: this.estimateLatencyIncrease(metrics),
      affectedUsers: await this.estimateAffectedUsers(affectedKeys),
      criticalPaths: this.identifyCriticalPaths(rootKey, affectedKeys),
      severity: this.calculateSeverity(metrics),
      recommendations: this.generateRecommendations(metrics)
    };
  }
  
  private calculateSeverity(metrics: CacheMetrics): 'low' | 'medium' | 'high' | 'critical' {
    const score = 
      metrics.accessFrequency * 0.4 +
      metrics.userImpact * 0.3 +
      metrics.dataImportance * 0.3;
    
    if (score > 0.8) return 'critical';
    if (score > 0.6) return 'high';
    if (score > 0.3) return 'medium';
    return 'low';
  }
}
```

#### SubTask 2.8.4: ë¬´íš¨í™” ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
**ë‹´ë‹¹ì**: ëª¨ë‹ˆí„°ë§ ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/cache/monitoring/invalidation-monitor.ts
export class InvalidationMonitor {
  private metricsCollector: InvalidationMetricsCollector;
  private analyzer: InvalidationAnalyzer;
  private optimizer: InvalidationOptimizer;
  private dashboard: InvalidationDashboard;
  
  constructor(
    private cache: CacheLayer,
    private config: MonitoringConfig
  ) {
    this.metricsCollector = new InvalidationMetricsCollector(cache);
    this.analyzer = new InvalidationAnalyzer();
    this.optimizer = new InvalidationOptimizer();
    this.dashboard = new InvalidationDashboard();
    
    this.startMonitoring();
  }

  // ëª¨ë‹ˆí„°ë§ ì‹œì‘
  private startMonitoring(): void {
    // ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    this.cache.on('invalidation', async (event) => {
      await this.metricsCollector.record(event);
    });
    
    // ì£¼ê¸°ì  ë¶„ì„
    setInterval(async () => {
      await this.performAnalysis();
    }, this.config.analysisInterval || 60000);
    
    // ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸
    setInterval(async () => {
      await this.updateDashboard();
    }, this.config.dashboardInterval || 5000);
  }

  // ë¬´íš¨í™” ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  class InvalidationMetricsCollector {
    private metrics: InvalidationMetrics;
    
    async record(event: InvalidationEvent): Promise<void> {
      // ê¸°ë³¸ ë©”íŠ¸ë¦­
      this.metrics.totalInvalidations++;
      this.metrics.invalidationsByType[event.type]++;
      
      // ì‹œê°„ ê¸°ë°˜ ë©”íŠ¸ë¦­
      const hour = new Date().getHours();
      this.metrics.hourlyDistribution[hour]++;
      
      // ì„±ëŠ¥ ë©”íŠ¸ë¦­
      this.metrics.avgInvalidationTime = 
        (this.metrics.avgInvalidationTime * (this.metrics.totalInvalidations - 1) + 
         event.duration) / this.metrics.totalInvalidations;
      
      // ì˜í–¥ ë©”íŠ¸ë¦­
      this.metrics.totalKeysInvalidated += event.keysInvalidated;
      this.metrics.cascadeDepth = Math.max(
        this.metrics.cascadeDepth,
        event.cascadeDepth || 0
      );
      
      // íŒ¨í„´ ì¶”ì 
      await this.trackInvalidationPattern(event);
    }
    
    private async trackInvalidationPattern(
      event: InvalidationEvent
    ): Promise<void> {
      const pattern = this.extractPattern(event);
      
      if (!this.metrics.patterns.has(pattern)) {
        this.metrics.patterns.set(pattern, {
          count: 0,
          avgDuration: 0,
          avgKeysAffected: 0,
          lastSeen: null
        });
      }
      
      const patternMetric = this.metrics.patterns.get(pattern)!;
      patternMetric.count++;
      patternMetric.avgDuration = 
        (patternMetric.avgDuration * (patternMetric.count - 1) + event.duration) / 
        patternMetric.count;
      patternMetric.avgKeysAffected = 
        (patternMetric.avgKeysAffected * (patternMetric.count - 1) + event.keysInvalidated) / 
        patternMetric.count;
      patternMetric.lastSeen = new Date();
    }
  }

  // ë¬´íš¨í™” ë¶„ì„
  private async performAnalysis(): Promise<void> {
    const metrics = await this.metricsCollector.getMetrics();
    const analysis = await this.analyzer.analyze(metrics);
    
    // ì´ìƒ ê°ì§€
    if (analysis.anomalies.length > 0) {
      await this.handleAnomalies(analysis.anomalies);
    }
    
    // ìµœì í™” ê¸°íšŒ ì‹ë³„
    if (analysis.optimizationOpportunities.length > 0) {
      await this.applyOptimizations(analysis.optimizationOpportunities);
    }
    
    // ë³´ê³ ì„œ ìƒì„±
    await this.generateReport(analysis);
  }

  // ì´ìƒ ê°ì§€
  class InvalidationAnalyzer {
    async analyze(
      metrics: InvalidationMetrics
    ): Promise<InvalidationAnalysis> {
      const anomalies = await this.detectAnomalies(metrics);
      const patterns = await this.analyzePatterns(metrics);
      const bottlenecks = await this.identifyBottlenecks(metrics);
      const opportunities = await this.findOptimizationOpportunities(metrics);
      
      return {
        anomalies,
        patterns,
        bottlenecks,
        optimizationOpportunities: opportunities,
        summary: this.generateSummary(metrics),
        recommendations: this.generateRecommendations(anomalies, patterns, bottlenecks)
      };
    }
    
    private async detectAnomalies(
      metrics: InvalidationMetrics
    ): Promise<Anomaly[]> {
      const anomalies: Anomaly[] = [];
      
      // 1. ê¸‰ì¦ ê°ì§€
      const spike = this.detectSpike(metrics.hourlyDistribution);
      if (spike) {
        anomalies.push({
          type: 'spike',
          severity: 'high',
          description: `Invalidation spike detected: ${spike.value}x normal`,
          timestamp: spike.timestamp,
          data: spike
        });
      }
      
      // 2. íŒ¨í„´ ì´ìƒ ê°ì§€
      for (const [pattern, data] of metrics.patterns) {
        if (data.avgDuration > metrics.avgInvalidationTime * 3) {
          anomalies.push({
            type: 'slow_pattern',
            severity: 'medium',
            description: `Pattern "${pattern}" is 3x slower than average`,
            pattern,
            data
          });
        }
      }
      
      // 3. ìºìŠ¤ì¼€ì´ë“œ ì´ìƒ
      if (metrics.cascadeDepth > 5) {
        anomalies.push({
          type: 'deep_cascade',
          severity: 'high',
          description: `Deep cascade detected: ${metrics.cascadeDepth} levels`,
          data: { depth: metrics.cascadeDepth }
        });
      }
      
      return anomalies;
    }
    
    private async identifyBottlenecks(
      metrics: InvalidationMetrics
    ): Promise<Bottleneck[]> {
      const bottlenecks: Bottleneck[] = [];
      
      // 1. í•«ìŠ¤íŒŸ íŒ¨í„´
      const hotPatterns = Array.from(metrics.patterns.entries())
        .filter(([_, data]) => data.count > metrics.totalInvalidations * 0.2)
        .sort((a, b) => b[1].count - a[1].count);
        
      if (hotPatterns.length > 0) {
        bottlenecks.push({
          type: 'hot_pattern',
          impact: 'high',
          patterns: hotPatterns.map(([pattern, data]) => ({
            pattern,
            percentage: (data.count / metrics.totalInvalidations) * 100
          }))
        });
      }
      
      // 2. ì‹œê°„ëŒ€ë³„ ì§‘ì¤‘
      const peakHours = this.findPeakHours(metrics.hourlyDistribution);
      if (peakHours.concentration > 0.5) {
        bottlenecks.push({
          type: 'temporal_concentration',
          impact: 'medium',
          hours: peakHours.hours,
          concentration: peakHours.concentration
        });
      }
      
      return bottlenecks;
    }
  }

  // ë¬´íš¨í™” ìµœì í™”
  class InvalidationOptimizer {
    async optimize(
      opportunity: OptimizationOpportunity
    ): Promise<OptimizationResult> {
      switch (opportunity.type) {
        case 'batch_consolidation':
          return await this.consolidateBatches(opportunity);
          
        case 'pattern_caching':
          return await this.cachePatterns(opportunity);
          
        case 'cascade_reduction':
          return await this.reduceCascades(opportunity);
          
        case 'timing_optimization':
          return await this.optimizeTiming(opportunity);
          
        default:
          return { applied: false, reason: 'Unknown optimization type' };
      }
    }
    
    private async consolidateBatches(
      opportunity: OptimizationOpportunity
    ): Promise<OptimizationResult> {
      const config = opportunity.config as BatchConsolidationConfig;
      
      // ë°°ì¹˜ í¬ê¸° ì¡°ì •
      await this.cache.setConfig({
        invalidationBatchSize: config.optimalBatchSize,
        invalidationBatchDelay: config.batchDelay
      });
      
      return {
        applied: true,
        expectedImprovement: {
          latency: '-30%',
          throughput: '+50%'
        }
      };
    }
    
    private async reduceCascades(
      opportunity: OptimizationOpportunity
    ): Promise<OptimizationResult> {
      const config = opportunity.config as CascadeReductionConfig;
      
      // ì˜ì¡´ì„± ê·¸ë˜í”„ ì¬êµ¬ì„±
      for (const optimization of config.graphOptimizations) {
        await this.applyGraphOptimization(optimization);
      }
      
      return {
        applied: true,
        expectedImprovement: {
          cascadeDepth: `-${config.expectedReduction}%`,
          invalidations: '-20%'
        }
      };
    }
  }

  // ë¬´íš¨í™” ëŒ€ì‹œë³´ë“œ
  class InvalidationDashboard {
    private realtimeData: RealtimeData;
    private historicalData: HistoricalData;
    
    async update(
      metrics: InvalidationMetrics,
      analysis: InvalidationAnalysis
    ): Promise<void> {
      // ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸
      this.realtimeData = {
        currentRate: this.calculateRate(metrics),
        activePatterns: this.getActivePatterns(metrics),
        cascadeDepth: metrics.cascadeDepth,
        anomalies: analysis.anomalies,
        timestamp: Date.now()
      };
      
      // ì°¨íŠ¸ ë°ì´í„° ì—…ë°ì´íŠ¸
      await this.updateCharts(metrics);
      
      // ì•Œë¦¼ í™•ì¸
      await this.checkAlerts(analysis);
      
      // WebSocketìœ¼ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
      await this.broadcast({
        type: 'dashboard_update',
        data: this.realtimeData
      });
    }
    
    async generateVisualization(): Promise<DashboardVisualization> {
      return {
        overview: {
          totalInvalidations: this.realtimeData.totalInvalidations,
          averageRate: this.realtimeData.currentRate,
          healthScore: this.calculateHealthScore()
        },
        charts: {
          timeline: await this.generateTimelineChart(),
          patterns: await this.generatePatternChart(),
          cascade: await this.generateCascadeChart(),
          heatmap: await this.generateHeatmap()
        },
        alerts: await this.getActiveAlerts(),
        recommendations: await this.getRecommendations()
      };
    }
  }

  // ìµœì í™” ì ìš©
  private async applyOptimizations(
    opportunities: OptimizationOpportunity[]
  ): Promise<void> {
    for (const opportunity of opportunities) {
      try {
        const result = await this.optimizer.optimize(opportunity);
        
        if (result.applied) {
          await this.trackOptimization(opportunity, result);
        }
      } catch (error) {
        this.logger.error(`Failed to apply optimization: ${opportunity.type}`, error);
      }
    }
  }

  // ë¦¬í¬íŠ¸ ìƒì„±
  private async generateReport(
    analysis: InvalidationAnalysis
  ): Promise<InvalidationReport> {
    const report: InvalidationReport = {
      timestamp: new Date(),
      period: this.config.reportPeriod || '1h',
      summary: analysis.summary,
      metrics: {
        total: analysis.summary.totalInvalidations,
        rate: analysis.summary.averageRate,
        patterns: analysis.patterns.length,
        anomalies: analysis.anomalies.length
      },
      topPatterns: analysis.patterns.slice(0, 10),
      anomalies: analysis.anomalies,
      optimizations: {
        applied: await this.getAppliedOptimizations(),
        pending: analysis.optimizationOpportunities,
        results: await this.getOptimizationResults()
      },
      recommendations: analysis.recommendations
    };
    
    // ë¦¬í¬íŠ¸ ì €ì¥
    await this.saveReport(report);
    
    // ì´ë©”ì¼ ì•Œë¦¼ (ì„¤ì •ëœ ê²½ìš°)
    if (this.config.emailReports) {
      await this.emailReport(report);
    }
    
    return report;
  }

  // ë¬´íš¨í™” ì˜ˆì¸¡
  async predictInvalidations(
    timeframe: TimeRange
  ): Promise<InvalidationPrediction> {
    const historicalData = await this.getHistoricalData();
    const patterns = await this.analyzer.extractPatterns(historicalData);
    
    // ML ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜ˆì¸¡
    const prediction = await this.mlPredictor.predict({
      historicalData,
      patterns,
      timeframe
    });
    
    return {
      timeframe,
      expectedInvalidations: prediction.count,
      peakTimes: prediction.peaks,
      hotPatterns: prediction.patterns,
      confidence: prediction.confidence,
      recommendations: this.generatePredictiveRecommendations(prediction)
    };
  }
}

// ë¬´íš¨í™” ìµœì í™” ì œì•ˆ
export class InvalidationOptimizationAdvisor {
  async analyzeAndSuggest(
    metrics: InvalidationMetrics
  ): Promise<OptimizationSuggestions> {
    const suggestions: OptimizationSuggestion[] = [];
    
    // 1. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
    if (metrics.avgBatchSize < 10) {
      suggestions.push({
        type: 'increase_batch_size',
        priority: 'high',
        description: 'Increase batch size to reduce overhead',
        expectedBenefit: {
          latency: '-40%',
          throughput: '+60%'
        },
        implementation: {
          currentValue: metrics.avgBatchSize,
          suggestedValue: 50,
          code: `cache.setConfig({ invalidationBatchSize: 50 })`
        }
      });
    }
    
    // 2. ìºìŠ¤ì¼€ì´ë“œ ìµœì í™”
    if (metrics.avgCascadeDepth > 3) {
      suggestions.push({
        type: 'reduce_cascade_depth',
        priority: 'medium',
        description: 'Optimize dependency graph to reduce cascade depth',
        expectedBenefit: {
          invalidations: '-30%',
          complexity: '-50%'
        },
        implementation: {
          strategy: 'dependency_flattening',
          steps: [
            'Identify common cascade paths',
            'Create direct dependencies',
            'Remove intermediate nodes'
          ]
        }
      });
    }
    
    // 3. ì‹œê°„ ê¸°ë°˜ ìµœì í™”
    const peakHours = this.findPeakHours(metrics.hourlyDistribution);
    if (peakHours.length > 0) {
      suggestions.push({
        type: 'schedule_invalidations',
        priority: 'low',
        description: 'Schedule non-critical invalidations during off-peak hours',
        expectedBenefit: {
          peakLoad: '-25%',
          userExperience: '+15%'
        },
        implementation: {
          peakHours,
          offPeakHours: this.findOffPeakHours(metrics.hourlyDistribution),
          schedulingStrategy: 'delayed_invalidation'
        }
      });
    }
    
    return {
      suggestions,
      estimatedTotalBenefit: this.calculateTotalBenefit(suggestions),
      implementationPlan: this.createImplementationPlan(suggestions)
    };
  }
}

// ì‹¤ì‹œê°„ ë¬´íš¨í™” ì¶”ì 
export class RealtimeInvalidationTracker {
  private stream: InvalidationStream;
  private buffer: CircularBuffer<InvalidationEvent>;
  
  constructor(bufferSize: number = 10000) {
    this.stream = new InvalidationStream();
    this.buffer = new CircularBuffer(bufferSize);
    
    this.stream.on('invalidation', event => {
      this.buffer.push(event);
      this.processRealtimeEvent(event);
    });
  }
  
  // ì‹¤ì‹œê°„ í†µê³„
  getRealtimeStats(): RealtimeStats {
    const window = this.buffer.getRecent(1000); // ìµœê·¼ 1000ê°œ
    
    return {
      rate: this.calculateRate(window),
      avgLatency: this.calculateAvgLatency(window),
      patterns: this.extractPatterns(window),
      anomalies: this.detectRealtimeAnomalies(window)
    };
  }
  
  // ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„
  async streamAnalysis(
    callback: (analysis: StreamAnalysis) => void
  ): Promise<void> {
    const analyzer = new StreamingAnalyzer();
    
    this.stream.on('invalidation', async (event) => {
      const analysis = await analyzer.analyze(event);
      callback(analysis);
    });
  }
}
```
í”„ë¡œì íŠ¸ ì§€ì‹ì—ì„œ Phase 2 Subtask Planningì˜ êµ¬ì¡°ì™€ 2.9.1 ë¬¸ì„œì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤.Phase 2 ë°ì´í„° ë ˆì´ì–´ êµ¬í˜„ì˜ ì „ì²´ êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ Task 2.9ë¶€í„° ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤. Phase 0ê³¼ Phase 1ì˜ íŒ¨í„´ì„ ì°¸ê³ í•˜ì—¬ Phase 2ì˜ Task êµ¬ì¡°ë¥¼ ì¶”ì •í•˜ë©´:

# Phase 2: ë°ì´í„° ë ˆì´ì–´ êµ¬í˜„ - Task 2.9 ì´í›„ SubTask ë¬¸ì„œ

## ğŸ—ï¸ Phase 2 ì „ì²´ Task êµ¬ì¡° (ì¶”ì •)

### ë°ì´í„° ëª¨ë¸ë§ (Tasks 2.1-2.3)
- Task 2.1: DynamoDB í…Œì´ë¸” ì„¤ê³„
- Task 2.2: ì—”í‹°í‹° ëª¨ë¸ ì •ì˜
- Task 2.3: ì¸ë±ìŠ¤ ì „ëµ ìˆ˜ë¦½

### ë°ì´í„° ì ‘ê·¼ ê³„ì¸µ (Tasks 2.4-2.6)
- Task 2.4: Repository íŒ¨í„´ êµ¬í˜„
- Task 2.5: ì¿¼ë¦¬ ë¹Œë” ì‹œìŠ¤í…œ
- Task 2.6: íŠ¸ëœì­ì…˜ ê´€ë¦¬

### ìºì‹± ë° ìµœì í™” (Tasks 2.7-2.9)
- Task 2.7: Redis ìºì‹± ì‹œìŠ¤í…œ êµ¬ì¶•
- Task 2.8: ìºì‹œ ë¬´íš¨í™” ì „ëµ
- Task 2.9: ì¼ê´„ ì²˜ë¦¬ ì‹œìŠ¤í…œ

### ë°ì´í„° ë™ê¸°í™” (Tasks 2.10-2.12)
- Task 2.10: ë³€ê²½ ë°ì´í„° ìº¡ì²˜ (CDC)
- Task 2.11: ì´ë²¤íŠ¸ ì†Œì‹±
- Task 2.12: ë°ì´í„° ë³µì œ ë° ë™ê¸°í™”

### ë°±ì—… ë° ë³µêµ¬ (Tasks 2.13-2.15)
- Task 2.13: ë°±ì—… ìë™í™”
- Task 2.14: ì¬í•´ ë³µêµ¬ ê³„íš
- Task 2.15: ë°ì´í„° ë³´ì•ˆ ë° ì•”í˜¸í™”

---

## ğŸ“ Task 2.9: ì¼ê´„ ì²˜ë¦¬ ì‹œìŠ¤í…œ

### SubTask 2.9.1: ë°°ì¹˜ í”„ë¡œì„¸ì‹± ì•„í‚¤í…ì²˜ ì„¤ê³„
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì‹œìŠ¤í…œ ì„¤ê³„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/batch/architecture/batch-processor.ts
import { SQSClient } from '@aws-sdk/client-sqs';
import { DynamoDBDocumentClient } from '@aws-sdk/lib-dynamodb';
import Bull from 'bull';
import { EventEmitter } from 'events';

export interface BatchConfig {
  maxBatchSize: number;
  processingTimeout: number;
  parallelism: number;
  retryAttempts: number;
  scheduleCron?: string;
}

export interface BatchJob<T> {
  id: string;
  type: BatchJobType;
  data: T[];
  status: 'pending' | 'processing' | 'completed' | 'failed';
  createdAt: Date;
  startedAt?: Date;
  completedAt?: Date;
  metadata: BatchMetadata;
}

export class BatchProcessor extends EventEmitter {
  private queue: Bull.Queue;
  private workers: Map<string, BatchWorker>;
  private monitor: BatchMonitor;
  
  constructor(
    private config: BatchConfig,
    private dynamoClient: DynamoDBDocumentClient,
    private sqsClient: SQSClient
  ) {
    super();
    this.queue = new Bull('batch-processing', {
      redis: {
        host: process.env.REDIS_HOST,
        port: parseInt(process.env.REDIS_PORT || '6379')
      }
    });
    
    this.workers = new Map();
    this.monitor = new BatchMonitor(this.queue);
    
    this.initializeWorkers();
    this.setupScheduler();
  }
  
  private initializeWorkers(): void {
    // ì‚¬ìš©ì ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬
    this.registerWorker('UserBatch', new UserBatchWorker());
    
    // í”„ë¡œì íŠ¸ ì§‘ê³„ ì²˜ë¦¬
    this.registerWorker('ProjectAggregation', new ProjectAggregationWorker());
    
    // ë¡œê·¸ ì•„ì¹´ì´ë¹™
    this.registerWorker('LogArchiving', new LogArchivingWorker());
    
    // ë°ì´í„° ì •ë¦¬
    this.registerWorker('DataCleanup', new DataCleanupWorker());
  }
  
  async submitBatch<T>(
    type: BatchJobType,
    data: T[],
    options?: BatchOptions
  ): Promise<string> {
    // ë°ì´í„°ë¥¼ ì²­í¬ë¡œ ë¶„í• 
    const chunks = this.chunkData(data, this.config.maxBatchSize);
    
    const jobs: Bull.Job[] = [];
    for (const chunk of chunks) {
      const job = await this.queue.add(type, {
        data: chunk,
        options: options || {},
        timestamp: new Date()
      }, {
        attempts: this.config.retryAttempts,
        backoff: {
          type: 'exponential',
          delay: 2000
        },
        removeOnComplete: false,
        removeOnFail: false
      });
      
      jobs.push(job);
    }
    
    // ë°°ì¹˜ ê·¸ë£¹ ID ìƒì„±
    const batchGroupId = this.generateBatchGroupId();
    await this.saveBatchGroup(batchGroupId, jobs);
    
    return batchGroupId;
  }
  
  private chunkData<T>(data: T[], size: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < data.length; i += size) {
      chunks.push(data.slice(i, i + size));
    }
    return chunks;
  }
}

// ë°°ì¹˜ ì›Œì»¤ ê¸°ë³¸ í´ë˜ìŠ¤
export abstract class BatchWorker<T> {
  abstract async process(data: T[], context: BatchContext): Promise<BatchResult>;
  
  async preProcess(data: T[]): Promise<T[]> {
    // ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬
    return data.filter(item => this.validate(item));
  }
  
  abstract validate(item: T): boolean;
  
  async postProcess(result: BatchResult): Promise<void> {
    // ê²°ê³¼ í›„ì²˜ë¦¬ ë° ì•Œë¦¼
    if (result.failed.length > 0) {
      await this.handleFailures(result.failed);
    }
  }
  
  protected async handleFailures(failures: any[]): Promise<void> {
    // ì‹¤íŒ¨ í•­ëª© ì²˜ë¦¬ ë¡œì§
    console.error(`Batch processing failed for ${failures.length} items`);
  }
}
```

### SubTask 2.9.2: ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ í†µí•©
**ë‹´ë‹¹ì**: ë°ì´í„° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ëª©í‘œ**: DynamoDB Streamsì™€ Kinesisë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/batch/stream/stream-processor.ts
import { DynamoDBStreamsClient } from '@aws-sdk/client-dynamodb-streams';
import { KinesisClient } from '@aws-sdk/client-kinesis';
import { unmarshall } from '@aws-sdk/util-dynamodb';

export interface StreamConfig {
  streamArn: string;
  shardIteratorType: 'TRIM_HORIZON' | 'LATEST' | 'AT_SEQUENCE_NUMBER';
  batchSize: number;
  parallelProcessing: boolean;
  checkpointInterval: number;
}

export class StreamProcessor {
  private isProcessing: boolean = false;
  private checkpoints: Map<string, string> = new Map();
  private processors: Map<string, StreamRecordProcessor> = new Map();
  
  constructor(
    private config: StreamConfig,
    private streamsClient: DynamoDBStreamsClient,
    private kinesisClient: KinesisClient
  ) {
    this.initializeProcessors();
  }
  
  private initializeProcessors(): void {
    // ë ˆì½”ë“œ íƒ€ì…ë³„ í”„ë¡œì„¸ì„œ ë“±ë¡
    this.processors.set('INSERT', new InsertRecordProcessor());
    this.processors.set('MODIFY', new ModifyRecordProcessor());
    this.processors.set('REMOVE', new RemoveRecordProcessor());
  }
  
  async startProcessing(): Promise<void> {
    if (this.isProcessing) {
      throw new Error('Stream processing is already running');
    }
    
    this.isProcessing = true;
    
    // ìƒ¤ë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    const shards = await this.getStreamShards();
    
    // ê° ìƒ¤ë“œì— ëŒ€í•´ ë³‘ë ¬ ì²˜ë¦¬
    if (this.config.parallelProcessing) {
      await Promise.all(shards.map(shard => this.processShard(shard)));
    } else {
      for (const shard of shards) {
        await this.processShard(shard);
      }
    }
  }
  
  private async processShard(shardId: string): Promise<void> {
    let shardIterator = await this.getShardIterator(shardId);
    
    while (this.isProcessing && shardIterator) {
      try {
        const records = await this.getRecords(shardIterator);
        
        if (records.Records && records.Records.length > 0) {
          // ë°°ì¹˜ë¡œ ë ˆì½”ë“œ ì²˜ë¦¬
          await this.processBatch(records.Records);
          
          // ì²´í¬í¬ì¸íŠ¸ ì €ì¥
          if (records.Records.length > 0) {
            const lastSequenceNumber = records.Records[records.Records.length - 1].dynamodb?.SequenceNumber;
            if (lastSequenceNumber) {
              await this.saveCheckpoint(shardId, lastSequenceNumber);
            }
          }
        }
        
        shardIterator = records.NextShardIterator || null;
        
        // ë ˆì½”ë“œê°€ ì—†ìœ¼ë©´ ì ì‹œ ëŒ€ê¸°
        if (!records.Records || records.Records.length === 0) {
          await this.sleep(1000);
        }
      } catch (error) {
        console.error(`Error processing shard ${shardId}:`, error);
        await this.handleShardError(shardId, error);
      }
    }
  }
  
  private async processBatch(records: any[]): Promise<void> {
    const processedRecords = await Promise.all(
      records.map(async record => {
        try {
          const eventName = record.eventName;
          const processor = this.processors.get(eventName);
          
          if (processor) {
            const unmarshalledRecord = this.unmarshallRecord(record);
            return await processor.process(unmarshalledRecord);
          }
        } catch (error) {
          console.error('Error processing record:', error);
          return { success: false, error };
        }
      })
    );
    
    // Kinesisë¡œ ì²˜ë¦¬ ê²°ê³¼ ì „ì†¡
    await this.sendToKinesis(processedRecords);
  }
  
  private unmarshallRecord(record: any): any {
    return {
      eventName: record.eventName,
      eventID: record.eventID,
      eventVersion: record.eventVersion,
      dynamodb: {
        Keys: record.dynamodb.Keys ? unmarshall(record.dynamodb.Keys) : undefined,
        NewImage: record.dynamodb.NewImage ? unmarshall(record.dynamodb.NewImage) : undefined,
        OldImage: record.dynamodb.OldImage ? unmarshall(record.dynamodb.OldImage) : undefined,
        SequenceNumber: record.dynamodb.SequenceNumber,
        SizeBytes: record.dynamodb.SizeBytes,
        StreamViewType: record.dynamodb.StreamViewType
      }
    };
  }
}

// ë ˆì½”ë“œ í”„ë¡œì„¸ì„œ ì¸í„°í˜ì´ìŠ¤
export abstract class StreamRecordProcessor {
  abstract async process(record: any): Promise<ProcessingResult>;
  
  protected async enrichRecord(record: any): Promise<any> {
    // ë ˆì½”ë“œì— ì¶”ê°€ ì •ë³´ ë³´ê°•
    return {
      ...record,
      processedAt: new Date(),
      processorVersion: '1.0.0'
    };
  }
}
```

### SubTask 2.9.3: ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³‘ë ¬í™” ë° ì„±ëŠ¥ ìµœì í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/batch/optimization/parallel-optimizer.ts
import { Worker } from 'worker_threads';
import os from 'os';
import PQueue from 'p-queue';

export class ParallelOptimizer {
  private workerPool: Worker[] = [];
  private queue: PQueue;
  private metrics: PerformanceMetrics;
  
  constructor(
    private config: ParallelConfig
  ) {
    const concurrency = config.concurrency || os.cpus().length;
    this.queue = new PQueue({ concurrency });
    this.metrics = new PerformanceMetrics();
    
    this.initializeWorkerPool(concurrency);
  }
  
  private initializeWorkerPool(size: number): void {
    for (let i = 0; i < size; i++) {
      const worker = new Worker('./batch-worker.js', {
        workerData: {
          workerId: i,
          config: this.config
        }
      });
      
      worker.on('message', this.handleWorkerMessage.bind(this));
      worker.on('error', this.handleWorkerError.bind(this));
      
      this.workerPool.push(worker);
    }
  }
  
  async processBatchParallel<T, R>(
    items: T[],
    processor: (item: T) => Promise<R>,
    options?: ProcessingOptions
  ): Promise<BatchProcessingResult<R>> {
    const startTime = Date.now();
    const results: R[] = [];
    const errors: ProcessingError[] = [];
    
    // ë™ì  ì²­í¬ í¬ê¸° ê³„ì‚°
    const chunkSize = this.calculateOptimalChunkSize(items.length);
    const chunks = this.createChunks(items, chunkSize);
    
    // ê° ì²­í¬ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    const chunkPromises = chunks.map((chunk, index) => 
      this.queue.add(async () => {
        try {
          const chunkResults = await this.processChunk(
            chunk, 
            processor, 
            index
          );
          results.push(...chunkResults);
        } catch (error) {
          errors.push({
            chunkIndex: index,
            error: error as Error,
            items: chunk
          });
        }
      })
    );
    
    await Promise.all(chunkPromises);
    
    // ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    const processingTime = Date.now() - startTime;
    this.metrics.record({
      totalItems: items.length,
      successfulItems: results.length,
      failedItems: errors.length,
      processingTime,
      throughput: items.length / (processingTime / 1000)
    });
    
    return {
      results,
      errors,
      metrics: this.metrics.getSummary()
    };
  }
  
  private calculateOptimalChunkSize(totalItems: number): number {
    // CPU ì½”ì–´ ìˆ˜ì™€ ë©”ëª¨ë¦¬ë¥¼ ê³ ë ¤í•œ ìµœì  ì²­í¬ í¬ê¸° ê³„ì‚°
    const cpuCount = os.cpus().length;
    const freeMemory = os.freemem();
    const itemSizeEstimate = 1024; // ì˜ˆìƒ ì•„ì´í…œ í¬ê¸° (bytes)
    
    const memoryBasedLimit = Math.floor(freeMemory * 0.7 / itemSizeEstimate);
    const cpuBasedLimit = Math.ceil(totalItems / cpuCount);
    
    return Math.min(
      memoryBasedLimit,
      cpuBasedLimit,
      this.config.maxChunkSize || 1000
    );
  }
  
  // ì ì‘í˜• ë™ì‹œì„± ì œì–´
  async adaptiveConcurrencyControl<T>(
    tasks: (() => Promise<T>)[]
  ): Promise<T[]> {
    let concurrency = this.config.initialConcurrency || 10;
    const results: T[] = [];
    let taskIndex = 0;
    
    while (taskIndex < tasks.length) {
      const batchSize = Math.min(concurrency, tasks.length - taskIndex);
      const batch = tasks.slice(taskIndex, taskIndex + batchSize);
      
      const startTime = Date.now();
      const batchResults = await Promise.all(
        batch.map(task => this.executeWithTimeout(task))
      );
      const batchTime = Date.now() - startTime;
      
      results.push(...batchResults);
      taskIndex += batchSize;
      
      // ë™ì‹œì„± ë ˆë²¨ ì¡°ì •
      concurrency = this.adjustConcurrency(
        concurrency,
        batchTime,
        batchSize
      );
    }
    
    return results;
  }
  
  private adjustConcurrency(
    current: number,
    executionTime: number,
    batchSize: number
  ): number {
    const targetTime = 1000; // ëª©í‘œ ì‹¤í–‰ ì‹œê°„ (ms)
    const ratio = targetTime / executionTime;
    
    if (ratio > 1.2) {
      // ì‹¤í–‰ì´ ë¹ ë¥´ë©´ ë™ì‹œì„± ì¦ê°€
      return Math.min(current * 1.5, this.config.maxConcurrency || 100);
    } else if (ratio < 0.8) {
      // ì‹¤í–‰ì´ ëŠë¦¬ë©´ ë™ì‹œì„± ê°ì†Œ
      return Math.max(current * 0.7, this.config.minConcurrency || 5);
    }
    
    return current;
  }
}

// ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
export class PerformanceMetrics {
  private metrics: Metric[] = [];
  
  record(metric: Metric): void {
    this.metrics.push({
      ...metric,
      timestamp: new Date()
    });
    
    // ë©”íŠ¸ë¦­ì„ CloudWatchë¡œ ì „ì†¡
    this.sendToCloudWatch(metric);
  }
  
  getSummary(): MetricsSummary {
    const recentMetrics = this.getRecentMetrics(60); // ìµœê·¼ 60ì´ˆ
    
    return {
      averageThroughput: this.calculateAverage(
        recentMetrics.map(m => m.throughput)
      ),
      successRate: this.calculateSuccessRate(recentMetrics),
      p99ProcessingTime: this.calculatePercentile(
        recentMetrics.map(m => m.processingTime),
        99
      )
    };
  }
}
```

### SubTask 2.9.4: ë°°ì¹˜ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ë°°ì¹˜ ì‘ì—… ìƒíƒœì™€ ì„±ëŠ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ëŒ€ì‹œë³´ë“œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/batch/monitoring/batch-monitor.ts
import { EventEmitter } from 'events';
import Bull from 'bull';
import { CloudWatchClient } from '@aws-sdk/client-cloudwatch';
import WebSocket from 'ws';

export interface BatchMetrics {
  activeJobs: number;
  completedJobs: number;
  failedJobs: number;
  averageProcessingTime: number;
  throughput: number;
  queueLength: number;
  workerUtilization: number;
}

export class BatchMonitor extends EventEmitter {
  private metrics: BatchMetrics;
  private cloudWatch: CloudWatchClient;
  private wsServer: WebSocket.Server;
  private updateInterval: NodeJS.Timer;
  
  constructor(
    private queue: Bull.Queue,
    private config: MonitorConfig
  ) {
    super();
    this.cloudWatch = new CloudWatchClient({ region: config.region });
    this.wsServer = new WebSocket.Server({ port: config.wsPort || 8080 });
    
    this.initializeMetrics();
    this.setupEventListeners();
    this.startMetricsCollection();
  }
  
  private initializeMetrics(): void {
    this.metrics = {
      activeJobs: 0,
      completedJobs: 0,
      failedJobs: 0,
      averageProcessingTime: 0,
      throughput: 0,
      queueLength: 0,
      workerUtilization: 0
    };
  }
  
  private setupEventListeners(): void {
    // í ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
    this.queue.on('active', this.onJobActive.bind(this));
    this.queue.on('completed', this.onJobCompleted.bind(this));
    this.queue.on('failed', this.onJobFailed.bind(this));
    this.queue.on('stalled', this.onJobStalled.bind(this));
    
    // WebSocket ì—°ê²° ì²˜ë¦¬
    this.wsServer.on('connection', (ws) => {
      // ìƒˆ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ í˜„ì¬ ë©”íŠ¸ë¦­ ì „ì†¡
      ws.send(JSON.stringify({
        type: 'metrics',
        data: this.metrics
      }));
      
      // ì£¼ê¸°ì  ì—…ë°ì´íŠ¸ êµ¬ë…
      const interval = setInterval(() => {
        if (ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({
            type: 'metrics',
            data: this.metrics
          }));
        }
      }, 1000);
      
      ws.on('close', () => clearInterval(interval));
    });
  }
  
  private async collectMetrics(): Promise<void> {
    const [waiting, active, completed, failed] = await Promise.all([
      this.queue.getWaitingCount(),
      this.queue.getActiveCount(),
      this.queue.getCompletedCount(),
      this.queue.getFailedCount()
    ]);
    
    this.metrics = {
      ...this.metrics,
      queueLength: waiting,
      activeJobs: active,
      completedJobs: completed,
      failedJobs: failed,
      throughput: this.calculateThroughput(),
      workerUtilization: this.calculateWorkerUtilization()
    };
    
    // CloudWatchë¡œ ë©”íŠ¸ë¦­ ì „ì†¡
    await this.publishMetrics();
    
    // ì„ê³„ê°’ ì²´í¬
    this.checkThresholds();
  }
  
  private async publishMetrics(): Promise<void> {
    const metricData = [
      {
        MetricName: 'BatchQueueLength',
        Value: this.metrics.queueLength,
        Unit: 'Count'
      },
      {
        MetricName: 'BatchThroughput',
        Value: this.metrics.throughput,
        Unit: 'Count/Second'
      },
      {
        MetricName: 'BatchWorkerUtilization',
        Value: this.metrics.workerUtilization,
        Unit: 'Percent'
      }
    ];
    
    try {
      await this.cloudWatch.putMetricData({
        Namespace: 'T-Developer/Batch',
        MetricData: metricData
      });
    } catch (error) {
      console.error('Failed to publish metrics:', error);
    }
  }
  
  private checkThresholds(): void {
    // í ê¸¸ì´ ì„ê³„ê°’
    if (this.metrics.queueLength > this.config.queueLengthThreshold) {
      this.emit('threshold:queue_length', {
        current: this.metrics.queueLength,
        threshold: this.config.queueLengthThreshold
      });
    }
    
    // ì‹¤íŒ¨ìœ¨ ì„ê³„ê°’
    const failureRate = this.metrics.failedJobs / 
      (this.metrics.completedJobs + this.metrics.failedJobs);
    
    if (failureRate > this.config.failureRateThreshold) {
      this.emit('threshold:failure_rate', {
        current: failureRate,
        threshold: this.config.failureRateThreshold
      });
    }
  }
  
  // ëŒ€ì‹œë³´ë“œ API
  async getDashboardData(): Promise<DashboardData> {
    const jobCounts = await this.queue.getJobCounts();
    const workers = await this.queue.getWorkers();
    
    return {
      overview: this.metrics,
      jobDistribution: jobCounts,
      workers: workers.map(w => ({
        id: w.id,
        status: w.status,
        currentJob: w.currentJob,
        startTime: w.startTime
      })),
      recentJobs: await this.getRecentJobs(),
      performanceHistory: await this.getPerformanceHistory()
    };
  }
}

// ëŒ€ì‹œë³´ë“œ REST API
export class BatchDashboardAPI {
  constructor(
    private monitor: BatchMonitor,
    private app: any // Express app
  ) {
    this.setupRoutes();
  }
  
  private setupRoutes(): void {
    // ëŒ€ì‹œë³´ë“œ ë°ì´í„°
    this.app.get('/api/batch/dashboard', async (req: any, res: any) => {
      try {
        const data = await this.monitor.getDashboardData();
        res.json(data);
      } catch (error) {
        res.status(500).json({ error: 'Failed to get dashboard data' });
      }
    });
    
    // íŠ¹ì • ì‘ì—… ìƒì„¸
    this.app.get('/api/batch/jobs/:id', async (req: any, res: any) => {
      try {
        const job = await this.monitor.getJobDetails(req.params.id);
        res.json(job);
      } catch (error) {
        res.status(404).json({ error: 'Job not found' });
      }
    });
    
    // ì‘ì—… ì¬ì‹œë„
    this.app.post('/api/batch/jobs/:id/retry', async (req: any, res: any) => {
      try {
        await this.monitor.retryJob(req.params.id);
        res.json({ success: true });
      } catch (error) {
        res.status(500).json({ error: 'Failed to retry job' });
      }
    });
  }
}
```
## Task 2.10: ë³€ê²½ ë°ì´í„° ìº¡ì²˜ (CDC)

### SubTask 2.10.1: DynamoDB Streams ì„¤ì •
**ë‹´ë‹¹ì**: ë°ì´í„° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: DynamoDB í…Œì´ë¸”ì— ìŠ¤íŠ¸ë¦¼ì„ í™œì„±í™”í•˜ê³  ë³€ê²½ ì‚¬í•­ ìº¡ì²˜ ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/cdc/streams/dynamodb-cdc.ts
import { 
  DynamoDBClient, 
  UpdateTableCommand,
  DescribeTableCommand 
} from '@aws-sdk/client-dynamodb';
import { 
  DynamoDBStreamsClient,
  DescribeStreamCommand,
  GetShardIteratorCommand,
  GetRecordsCommand
} from '@aws-sdk/client-dynamodb-streams';

export interface CDCConfig {
  tableName: string;
  streamViewType: 'NEW_IMAGE' | 'OLD_IMAGE' | 'NEW_AND_OLD_IMAGES' | 'KEYS_ONLY';
  batchSize: number;
  processingInterval: number;
  errorRetryAttempts: number;
}

export class DynamoDBCDC {
  private dynamoClient: DynamoDBClient;
  private streamsClient: DynamoDBStreamsClient;
  private processors: Map<string, CDCProcessor> = new Map();
  private isRunning: boolean = false;
  
  constructor(
    private config: CDCConfig,
    region: string
  ) {
    this.dynamoClient = new DynamoDBClient({ region });
    this.streamsClient = new DynamoDBStreamsClient({ region });
    
    this.initializeProcessors();
  }
  
  // ìŠ¤íŠ¸ë¦¼ í™œì„±í™”
  async enableStreams(): Promise<string> {
    const describeResponse = await this.dynamoClient.send(
      new DescribeTableCommand({ TableName: this.config.tableName })
    );
    
    if (!describeResponse.Table?.StreamSpecification?.StreamEnabled) {
      // ìŠ¤íŠ¸ë¦¼ í™œì„±í™”
      await this.dynamoClient.send(
        new UpdateTableCommand({
          TableName: this.config.tableName,
          StreamSpecification: {
            StreamEnabled: true,
            StreamViewType: this.config.streamViewType
          }
        })
      );
      
      // ìŠ¤íŠ¸ë¦¼ì´ í™œì„±í™”ë  ë•Œê¹Œì§€ ëŒ€ê¸°
      await this.waitForStreamEnabled();
    }
    
    return describeResponse.Table?.LatestStreamArn || '';
  }
  
  // CDC í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
  private initializeProcessors(): void {
    // ì—”í‹°í‹°ë³„ CDC í”„ë¡œì„¸ì„œ
    this.processors.set('User', new UserCDCProcessor());
    this.processors.set('Project', new ProjectCDCProcessor());
    this.processors.set('Task', new TaskCDCProcessor());
    this.processors.set('Agent', new AgentCDCProcessor());
  }
  
  // ë³€ê²½ ì‚¬í•­ ì²˜ë¦¬ ì‹œì‘
  async startCDC(streamArn: string): Promise<void> {
    this.isRunning = true;
    
    const streamDescription = await this.streamsClient.send(
      new DescribeStreamCommand({ StreamArn: streamArn })
    );
    
    const shards = streamDescription.StreamDescription?.Shards || [];
    
    // ê° ìƒ¤ë“œì— ëŒ€í•´ ë³‘ë ¬ ì²˜ë¦¬
    await Promise.all(
      shards.map(shard => this.processShard(streamArn, shard.ShardId!))
    );
  }
  
  // ìƒ¤ë“œ ì²˜ë¦¬
  private async processShard(streamArn: string, shardId: string): Promise<void> {
    let shardIterator = await this.getInitialShardIterator(streamArn, shardId);
    let consecutiveEmptyReads = 0;
    
    while (this.isRunning && shardIterator) {
      try {
        const records = await this.streamsClient.send(
          new GetRecordsCommand({ 
            ShardIterator: shardIterator,
            Limit: this.config.batchSize 
          })
        );
        
        if (records.Records && records.Records.length > 0) {
          await this.processRecords(records.Records);
          consecutiveEmptyReads = 0;
        } else {
          consecutiveEmptyReads++;
          
          // ì—°ì†ì ìœ¼ë¡œ ë¹ˆ ì‘ë‹µì´ ì˜¤ë©´ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
          const waitTime = Math.min(
            consecutiveEmptyReads * 100,
            this.config.processingInterval
          );
          await this.sleep(waitTime);
        }
        
        shardIterator = records.NextShardIterator || null;
        
      } catch (error) {
        console.error(`Error processing shard ${shardId}:`, error);
        await this.handleShardError(shardId, error);
        
        // ì—ëŸ¬ ë°œìƒ ì‹œ ìƒ¤ë“œ ì´í„°ë ˆì´í„° ì¬íšë“
        shardIterator = await this.getInitialShardIterator(streamArn, shardId);
      }
    }
  }
  
  // ë ˆì½”ë“œ ì²˜ë¦¬
  private async processRecords(records: any[]): Promise<void> {
    const changeEvents: ChangeEvent[] = records.map(record => ({
      eventId: record.eventID,
      eventName: record.eventName as ChangeEventType,
      tableName: this.extractTableName(record),
      keys: record.dynamodb.Keys,
      newImage: record.dynamodb.NewImage,
      oldImage: record.dynamodb.OldImage,
      sequenceNumber: record.dynamodb.SequenceNumber,
      timestamp: new Date(record.dynamodb.ApproximateCreationDateTime! * 1000)
    }));
    
    // ë°°ì¹˜ë¡œ ë³€ê²½ ì´ë²¤íŠ¸ ì²˜ë¦¬
    await this.processChangeEvents(changeEvents);
  }
  
  // ë³€ê²½ ì´ë²¤íŠ¸ ì²˜ë¦¬
  private async processChangeEvents(events: ChangeEvent[]): Promise<void> {
    const groupedEvents = this.groupEventsByEntity(events);
    
    for (const [entityType, entityEvents] of groupedEvents) {
      const processor = this.processors.get(entityType);
      
      if (processor) {
        try {
          await processor.processChanges(entityEvents);
        } catch (error) {
          console.error(`Error processing ${entityType} changes:`, error);
          await this.handleProcessingError(entityType, entityEvents, error);
        }
      }
    }
  }
}

// CDC í”„ë¡œì„¸ì„œ ì¸í„°í˜ì´ìŠ¤
export abstract class CDCProcessor {
  abstract async processChanges(events: ChangeEvent[]): Promise<void>;
  
  protected async handleInsert(event: ChangeEvent): Promise<void> {
    // ìƒˆ ë ˆì½”ë“œ ì‚½ì… ì²˜ë¦¬
  }
  
  protected async handleModify(event: ChangeEvent): Promise<void> {
    // ë ˆì½”ë“œ ìˆ˜ì • ì²˜ë¦¬
  }
  
  protected async handleRemove(event: ChangeEvent): Promise<void> {
    // ë ˆì½”ë“œ ì‚­ì œ ì²˜ë¦¬
  }
}

// ì‚¬ìš©ì CDC í”„ë¡œì„¸ì„œ ì˜ˆì‹œ
export class UserCDCProcessor extends CDCProcessor {
  async processChanges(events: ChangeEvent[]): Promise<void> {
    for (const event of events) {
      switch (event.eventName) {
        case 'INSERT':
          await this.handleUserCreated(event);
          break;
        case 'MODIFY':
          await this.handleUserUpdated(event);
          break;
        case 'REMOVE':
          await this.handleUserDeleted(event);
          break;
      }
    }
  }
  
  private async handleUserCreated(event: ChangeEvent): Promise<void> {
    // ì‚¬ìš©ì ìƒì„± ì´ë²¤íŠ¸ ë°œí–‰
    await this.publishEvent('UserCreated', {
      userId: event.keys.userId,
      userData: event.newImage,
      timestamp: event.timestamp
    });
    
    // ê²€ìƒ‰ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
    await this.updateSearchIndex('create', event.newImage);
    
    // ìºì‹œ ì›Œë°
    await this.warmCache(event.keys.userId, event.newImage);
  }
}
```

### SubTask 2.10.2: ë³€ê²½ ì´ë²¤íŠ¸ ë¼ìš°íŒ…
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: ìº¡ì²˜ëœ ë³€ê²½ ì‚¬í•­ì„ ì ì ˆí•œ ì†Œë¹„ìì—ê²Œ ë¼ìš°íŒ…í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/cdc/routing/event-router.ts
import { EventBridge } from '@aws-sdk/client-eventbridge';
import { SQSClient } from '@aws-sdk/client-sqs';
import { SNSClient } from '@aws-sdk/client-sns';

export interface RoutingRule {
  id: string;
  name: string;
  eventPattern: EventPattern;
  targets: RoutingTarget[];
  enabled: boolean;
}

export interface EventPattern {
  source?: string[];
  detailType?: string[];
  detail?: {
    eventName?: string[];
    entityType?: string[];
    [key: string]: any;
  };
}

export interface RoutingTarget {
  type: 'sqs' | 'sns' | 'lambda' | 'webhook';
  arn?: string;
  url?: string;
  retryPolicy?: RetryPolicy;
  deadLetterConfig?: DeadLetterConfig;
}

export class EventRouter {
  private eventBridge: EventBridge;
  private sqsClient: SQSClient;
  private snsClient: SNSClient;
  private routingRules: Map<string, RoutingRule> = new Map();
  private metrics: RouterMetrics;
  
  constructor(
    private config: RouterConfig
  ) {
    this.eventBridge = new EventBridge({ region: config.region });
    this.sqsClient = new SQSClient({ region: config.region });
    this.snsClient = new SNSClient({ region: config.region });
    this.metrics = new RouterMetrics();
    
    this.loadRoutingRules();
  }
  
  // ë¼ìš°íŒ… ê·œì¹™ ë¡œë“œ
  private async loadRoutingRules(): Promise<void> {
    // ì‚¬ìš©ì ì´ë²¤íŠ¸ ë¼ìš°íŒ…
    this.addRule({
      id: 'user-events',
      name: 'User Change Events',
      eventPattern: {
        source: ['dynamodb.cdc'],
        detailType: ['User Change'],
        detail: {
          eventName: ['INSERT', 'MODIFY', 'REMOVE']
        }
      },
      targets: [
        {
          type: 'sqs',
          arn: process.env.USER_EVENTS_QUEUE_ARN!,
          retryPolicy: { maxAttempts: 3, backoffRate: 2 }
        },
        {
          type: 'sns',
          arn: process.env.USER_EVENTS_TOPIC_ARN!
        }
      ],
      enabled: true
    });
    
    // í”„ë¡œì íŠ¸ ì´ë²¤íŠ¸ ë¼ìš°íŒ…
    this.addRule({
      id: 'project-events',
      name: 'Project Change Events',
      eventPattern: {
        source: ['dynamodb.cdc'],
        detailType: ['Project Change'],
        detail: {
          eventName: ['INSERT', 'MODIFY']
        }
      },
      targets: [
        {
          type: 'lambda',
          arn: process.env.PROJECT_PROCESSOR_LAMBDA_ARN!
        },
        {
          type: 'webhook',
          url: process.env.PROJECT_WEBHOOK_URL!,
          retryPolicy: { maxAttempts: 5, backoffRate: 2 }
        }
      ],
      enabled: true
    });
  }
  
  // ì´ë²¤íŠ¸ ë¼ìš°íŒ…
  async routeEvent(event: ChangeEvent): Promise<RoutingResult> {
    const startTime = Date.now();
    const results: TargetResult[] = [];
    
    // ë§¤ì¹­ë˜ëŠ” ê·œì¹™ ì°¾ê¸°
    const matchingRules = this.findMatchingRules(event);
    
    if (matchingRules.length === 0) {
      this.metrics.recordUnroutedEvent(event);
      return { success: false, reason: 'No matching rules' };
    }
    
    // ê° ê·œì¹™ì˜ íƒ€ê²Ÿìœ¼ë¡œ ì´ë²¤íŠ¸ ì „ì†¡
    for (const rule of matchingRules) {
      if (!rule.enabled) continue;
      
      for (const target of rule.targets) {
        try {
          const result = await this.sendToTarget(event, target);
          results.push({
            targetType: target.type,
            success: true,
            latency: result.latency
          });
        } catch (error) {
          results.push({
            targetType: target.type,
            success: false,
            error: error as Error
          });
          
          // ë°ë“œë ˆí„° íë¡œ ì „ì†¡
          if (target.deadLetterConfig) {
            await this.sendToDeadLetter(event, target, error);
          }
        }
      }
    }
    
    // ë©”íŠ¸ë¦­ ê¸°ë¡
    this.metrics.recordRouting({
      eventType: event.eventName,
      entityType: event.entityType,
      ruleCount: matchingRules.length,
      targetCount: results.length,
      successCount: results.filter(r => r.success).length,
      latency: Date.now() - startTime
    });
    
    return {
      success: results.some(r => r.success),
      results
    };
  }
  
  // íƒ€ê²Ÿìœ¼ë¡œ ì´ë²¤íŠ¸ ì „ì†¡
  private async sendToTarget(
    event: ChangeEvent, 
    target: RoutingTarget
  ): Promise<SendResult> {
    const startTime = Date.now();
    
    switch (target.type) {
      case 'sqs':
        await this.sendToSQS(event, target.arn!);
        break;
        
      case 'sns':
        await this.sendToSNS(event, target.arn!);
        break;
        
      case 'lambda':
        await this.invokeLambda(event, target.arn!);
        break;
        
      case 'webhook':
        await this.sendToWebhook(event, target.url!);
        break;
        
      default:
        throw new Error(`Unknown target type: ${target.type}`);
    }
    
    return {
      success: true,
      latency: Date.now() - startTime
    };
  }
  
  // ì´ë²¤íŠ¸ ë³€í™˜ ë° ë³´ê°•
  private async enrichEvent(event: ChangeEvent): Promise<EnrichedEvent> {
    const enriched: EnrichedEvent = {
      ...event,
      metadata: {
        routedAt: new Date(),
        routerId: this.config.routerId,
        version: '1.0.0'
      }
    };
    
    // ì—”í‹°í‹°ë³„ ë³´ê°• ë¡œì§
    switch (event.entityType) {
      case 'User':
        enriched.additionalData = await this.enrichUserEvent(event);
        break;
        
      case 'Project':
        enriched.additionalData = await this.enrichProjectEvent(event);
        break;
    }
    
    return enriched;
  }
}

// ì´ë²¤íŠ¸ í•„í„°ë§ ë° ë³€í™˜
export class EventFilter {
  private filters: Map<string, FilterFunction> = new Map();
  private transformers: Map<string, TransformFunction> = new Map();
  
  constructor() {
    this.initializeFilters();
    this.initializeTransformers();
  }
  
  private initializeFilters(): void {
    // ë¯¼ê°í•œ ë°ì´í„° í•„í„°
    this.filters.set('sensitive-data', (event: ChangeEvent) => {
      if (event.newImage) {
        delete event.newImage.password;
        delete event.newImage.ssn;
        delete event.newImage.creditCard;
      }
      return event;
    });
    
    // ë‚´ë¶€ í•„ë“œ í•„í„°
    this.filters.set('internal-fields', (event: ChangeEvent) => {
      if (event.newImage) {
        Object.keys(event.newImage).forEach(key => {
          if (key.startsWith('_')) {
            delete event.newImage[key];
          }
        });
      }
      return event;
    });
  }
  
  async filterEvent(
    event: ChangeEvent, 
    filterNames: string[]
  ): Promise<ChangeEvent> {
    let filteredEvent = { ...event };
    
    for (const filterName of filterNames) {
      const filter = this.filters.get(filterName);
      if (filter) {
        filteredEvent = await filter(filteredEvent);
      }
    }
    
    return filteredEvent;
  }
}
```

### SubTask 2.10.3: ë³€ê²½ ì‚¬í•­ ì¶”ì  ë° ê°ì‚¬
**ë‹´ë‹¹ì**: ë³´ì•ˆ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ëª¨ë“  ë°ì´í„° ë³€ê²½ ì‚¬í•­ì— ëŒ€í•œ ê°ì‚¬ ë¡œê·¸ ë° ì¶”ì  ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/cdc/audit/audit-trail.ts
import { DynamoDBDocumentClient } from '@aws-sdk/lib-dynamodb';
import { S3Client } from '@aws-sdk/client-s3';
import crypto from 'crypto';

export interface AuditRecord {
  auditId: string;
  timestamp: Date;
  entityType: string;
  entityId: string;
  action: 'CREATE' | 'UPDATE' | 'DELETE' | 'ACCESS';
  userId?: string;
  userRole?: string;
  clientIp?: string;
  userAgent?: string;
  changes?: FieldChange[];
  metadata?: Record<string, any>;
  hash: string;
  previousHash?: string;
}

export interface FieldChange {
  fieldName: string;
  oldValue: any;
  newValue: any;
  encrypted?: boolean;
}

export class AuditTrail {
  private auditTable: string = 'AuditTrail';
  private s3Bucket: string;
  private encryptionKey: Buffer;
  private chainValidator: ChainValidator;
  
  constructor(
    private dynamoClient: DynamoDBDocumentClient,
    private s3Client: S3Client,
    private config: AuditConfig
  ) {
    this.s3Bucket = config.archiveBucket;
    this.encryptionKey = Buffer.from(config.encryptionKey, 'base64');
    this.chainValidator = new ChainValidator(dynamoClient);
  }
  
  // ê°ì‚¬ ë ˆì½”ë“œ ìƒì„±
  async createAuditRecord(params: CreateAuditParams): Promise<AuditRecord> {
    // ì´ì „ í•´ì‹œ ê°€ì ¸ì˜¤ê¸° (ë¸”ë¡ì²´ì¸ ìŠ¤íƒ€ì¼)
    const previousHash = await this.getPreviousHash(params.entityType, params.entityId);
    
    // ë³€ê²½ ì‚¬í•­ ì¶”ì¶œ
    const changes = this.extractChanges(params.oldData, params.newData);
    
    // ë¯¼ê°í•œ í•„ë“œ ì•”í˜¸í™”
    const encryptedChanges = await this.encryptSensitiveFields(changes);
    
    // ê°ì‚¬ ë ˆì½”ë“œ ìƒì„±
    const auditRecord: AuditRecord = {
      auditId: this.generateAuditId(),
      timestamp: new Date(),
      entityType: params.entityType,
      entityId: params.entityId,
      action: params.action,
      userId: params.context?.userId,
      userRole: params.context?.userRole,
      clientIp: params.context?.clientIp,
      userAgent: params.context?.userAgent,
      changes: encryptedChanges,
      metadata: params.metadata,
      hash: '',
      previousHash
    };
    
    // í•´ì‹œ ê³„ì‚°
    auditRecord.hash = this.calculateHash(auditRecord);
    
    // DynamoDBì— ì €ì¥
    await this.saveAuditRecord(auditRecord);
    
    // ì‹¤ì‹œê°„ ì•Œë¦¼ (ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í™œë™)
    await this.checkSuspiciousActivity(auditRecord);
    
    return auditRecord;
  }
  
  // ë³€ê²½ ì‚¬í•­ ì¶”ì¶œ
  private extractChanges(oldData: any, newData: any): FieldChange[] {
    const changes: FieldChange[] = [];
    const allKeys = new Set([
      ...Object.keys(oldData || {}),
      ...Object.keys(newData || {})
    ]);
    
    for (const key of allKeys) {
      const oldValue = oldData?.[key];
      const newValue = newData?.[key];
      
      if (!this.deepEqual(oldValue, newValue)) {
        changes.push({
          fieldName: key,
          oldValue: this.sanitizeValue(oldValue),
          newValue: this.sanitizeValue(newValue),
          encrypted: this.isSensitiveField(key)
        });
      }
    }
    
    return changes;
  }
  
  // ë¯¼ê°í•œ í•„ë“œ ì•”í˜¸í™”
  private async encryptSensitiveFields(
    changes: FieldChange[]
  ): Promise<FieldChange[]> {
    return Promise.all(
      changes.map(async change => {
        if (change.encrypted) {
          return {
            ...change,
            oldValue: change.oldValue ? 
              await this.encrypt(JSON.stringify(change.oldValue)) : null,
            newValue: change.newValue ? 
              await this.encrypt(JSON.stringify(change.newValue)) : null
          };
        }
        return change;
      })
    );
  }
  
  // ê°ì‚¬ ë¡œê·¸ ì¿¼ë¦¬
  async queryAuditLogs(params: AuditQueryParams): Promise<AuditQueryResult> {
    const query = this.buildAuditQuery(params);
    const results = await this.executeQuery(query);
    
    // ì²´ì¸ ë¬´ê²°ì„± ê²€ì¦
    if (params.verifyIntegrity) {
      const integrityCheck = await this.chainValidator.verifyChain(
        results.records
      );
      
      if (!integrityCheck.valid) {
        throw new Error('Audit chain integrity violation detected');
      }
    }
    
    return {
      records: results.records,
      nextToken: results.nextToken,
      summary: this.generateAuditSummary(results.records)
    };
  }
  
  // ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í™œë™ ê°ì§€
  private async checkSuspiciousActivity(
    record: AuditRecord
  ): Promise<void> {
    const suspiciousPatterns = [
      // ëŒ€ëŸ‰ ì‚­ì œ
      {
        pattern: 'mass-deletion',
        check: () => record.action === 'DELETE' && 
                     record.metadata?.affectedCount > 100
      },
      // ê¶Œí•œ ìƒìŠ¹
      {
        pattern: 'privilege-escalation',
        check: () => record.entityType === 'User' && 
                     record.changes?.some(c => 
                       c.fieldName === 'role' && 
                       this.isPrivilegeEscalation(c.oldValue, c.newValue)
                     )
      },
      // ë¹„ì •ìƒ ì ‘ê·¼ ì‹œê°„
      {
        pattern: 'unusual-time',
        check: () => {
          const hour = record.timestamp.getHours();
          return hour < 6 || hour > 22; // ì—…ë¬´ ì‹œê°„ ì™¸
        }
      },
      // ë¹„ì •ìƒ ìœ„ì¹˜
      {
        pattern: 'unusual-location',
        check: async () => {
          if (record.clientIp) {
            const location = await this.getGeoLocation(record.clientIp);
            return this.isUnusualLocation(record.userId!, location);
          }
          return false;
        }
      }
    ];
    
    for (const { pattern, check } of suspiciousPatterns) {
      if (await check()) {
        await this.raiseSuspiciousActivityAlert({
          pattern,
          auditRecord: record,
          severity: this.calculateSeverity(pattern, record)
        });
      }
    }
  }
  
  // ê°ì‚¬ ë¡œê·¸ ì•„ì¹´ì´ë¹™
  async archiveAuditLogs(
    startDate: Date,
    endDate: Date
  ): Promise<ArchiveResult> {
    const records = await this.getAuditRecordsForPeriod(startDate, endDate);
    
    // S3ì— ì••ì¶•í•˜ì—¬ ì €ì¥
    const archiveKey = `audit-logs/${startDate.toISOString()}-${endDate.toISOString()}.gz`;
    const compressedData = await this.compressData(records);
    
    await this.s3Client.putObject({
      Bucket: this.s3Bucket,
      Key: archiveKey,
      Body: compressedData,
      ServerSideEncryption: 'aws:kms',
      Metadata: {
        recordCount: records.length.toString(),
        startDate: startDate.toISOString(),
        endDate: endDate.toISOString(),
        checksum: this.calculateChecksum(compressedData)
      }
    });
    
    // DynamoDBì—ì„œ ì‚­ì œ (ì„ íƒì )
    if (this.config.deleteAfterArchive) {
      await this.deleteArchivedRecords(records);
    }
    
    return {
      archivedCount: records.length,
      archiveSize: compressedData.length,
      archiveLocation: `s3://${this.s3Bucket}/${archiveKey}`
    };
  }
}

// ê°ì‚¬ ë³´ê³ ì„œ ìƒì„±ê¸°
export class AuditReporter {
  constructor(
    private auditTrail: AuditTrail,
    private config: ReporterConfig
  ) {}
  
  // ì»´í”Œë¼ì´ì–¸ìŠ¤ ë³´ê³ ì„œ ìƒì„±
  async generateComplianceReport(
    period: ReportPeriod
  ): Promise<ComplianceReport> {
    const auditData = await this.auditTrail.queryAuditLogs({
      startDate: period.start,
      endDate: period.end,
      verifyIntegrity: true
    });
    
    return {
      period,
      summary: {
        totalActions: auditData.records.length,
        actionBreakdown: this.groupByAction(auditData.records),
        userActivity: this.analyzeUserActivity(auditData.records),
        dataAccessPatterns: this.analyzeAccessPatterns(auditData.records)
      },
      compliance: {
        gdpr: this.checkGDPRCompliance(auditData.records),
        hipaa: this.checkHIPAACompliance(auditData.records),
        sox: this.checkSOXCompliance(auditData.records)
      },
      anomalies: await this.detectAnomalies(auditData.records),
      recommendations: this.generateRecommendations(auditData)
    };
  }
}
```

### SubTask 2.10.4: CDC ì„±ëŠ¥ ìµœì í™”
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ëŒ€ìš©ëŸ‰ ë³€ê²½ ì‚¬í•­ ì²˜ë¦¬ë¥¼ ìœ„í•œ CDC ì„±ëŠ¥ ìµœì í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/cdc/optimization/cdc-optimizer.ts
export class CDCOptimizer {
  private performanceMonitor: CDCPerformanceMonitor;
  private adaptiveController: AdaptiveController;
  private resourceManager: ResourceManager;
  
  constructor(
    private config: OptimizerConfig
  ) {
    this.performanceMonitor = new CDCPerformanceMonitor();
    this.adaptiveController = new AdaptiveController(config);
    this.resourceManager = new ResourceManager();
  }
  
  // ì ì‘í˜• ë°°ì¹˜ í¬ê¸° ì¡°ì •
  async optimizeBatchSize(
    currentMetrics: CDCMetrics
  ): Promise<number> {
    const optimalSize = this.adaptiveController.calculateOptimalBatchSize({
      currentBatchSize: currentMetrics.batchSize,
      processingTime: currentMetrics.avgProcessingTime,
      memoryUsage: currentMetrics.memoryUsage,
      cpuUsage: currentMetrics.cpuUsage,
      errorRate: currentMetrics.errorRate
    });
    
    // ì ì§„ì  ì¡°ì •
    const adjustment = Math.min(
      Math.abs(optimalSize - currentMetrics.batchSize) * 0.2,
      100
    );
    
    return currentMetrics.batchSize + 
           (optimalSize > currentMetrics.batchSize ? adjustment : -adjustment);
  }
  
  // ìƒ¤ë“œ ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
  async optimizeShardProcessing(
    shards: Shard[]
  ): Promise<ShardProcessingPlan> {
    // ìƒ¤ë“œë³„ ë¶€í•˜ ë¶„ì„
    const shardLoads = await this.analyzeShardLoads(shards);
    
    // ìµœì  ì›Œì»¤ ìˆ˜ ê³„ì‚°
    const optimalWorkers = this.calculateOptimalWorkers(shardLoads);
    
    // ìƒ¤ë“œ-ì›Œì»¤ ë§¤í•‘
    const shardAssignments = this.assignShardsToWorkers(
      shards,
      shardLoads,
      optimalWorkers
    );
    
    return {
      workerCount: optimalWorkers,
      assignments: shardAssignments,
      estimatedThroughput: this.estimateThroughput(shardAssignments)
    };
  }
  
  // ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë ˆì½”ë“œ ì²˜ë¦¬
  async processRecordsEfficiently(
    records: StreamRecord[]
  ): Promise<ProcessingResult[]> {
    // ë ˆì½”ë“œë¥¼ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²­í¬ë¡œ ë¶„í• 
    const memoryLimit = this.resourceManager.getAvailableMemory() * 0.7;
    const chunks = this.createMemoryEfficientChunks(records, memoryLimit);
    
    const results: ProcessingResult[] = [];
    
    for (const chunk of chunks) {
      // ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
      const chunkResults = await this.streamProcessChunk(chunk);
      results.push(...chunkResults);
      
      // ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íŒíŠ¸
      if (global.gc) {
        global.gc();
      }
    }
    
    return results;
  }
  
  // ë°±í”„ë ˆì…” ê´€ë¦¬
  private backpressureManager = new BackpressureManager({
    highWaterMark: 1000,
    lowWaterMark: 100,
    strategy: 'adaptive'
  });
  
  async handleBackpressure(
    incomingRate: number,
    processingRate: number
  ): Promise<BackpressureAction> {
    if (incomingRate > processingRate * 1.2) {
      return this.backpressureManager.applyBackpressure({
        severity: this.calculateSeverity(incomingRate, processingRate),
        duration: this.estimateRecoveryTime(incomingRate, processingRate)
      });
    }
    
    return { action: 'none' };
  }
}

// CDC ì„±ëŠ¥ ëª¨ë‹ˆí„°
export class CDCPerformanceMonitor {
  private metrics: Map<string, Metric[]> = new Map();
  private alerts: AlertManager;
  
  async collectMetrics(): Promise<CDCMetrics> {
    const metrics: CDCMetrics = {
      recordsPerSecond: await this.calculateThroughput(),
      avgProcessingTime: await this.getAverageProcessingTime(),
      errorRate: await this.getErrorRate(),
      lagTime: await this.getStreamLag(),
      memoryUsage: process.memoryUsage().heapUsed,
      cpuUsage: await this.getCPUUsage(),
      activeShards: await this.getActiveShardCount()
    };
    
    // ì´ìƒ ê°ì§€
    await this.detectAnomalies(metrics);
    
    return metrics;
  }
  
  // ì„±ëŠ¥ ì´ìƒ ê°ì§€
  private async detectAnomalies(metrics: CDCMetrics): Promise<void> {
    // ì²˜ë¦¬ ì§€ì—° ê°ì§€
    if (metrics.lagTime > this.config.maxAcceptableLag) {
      await this.alerts.send({
        severity: 'high',
        type: 'cdc-lag',
        message: `CDC lag detected: ${metrics.lagTime}ms`,
        metrics
      });
    }
    
    // ì—ëŸ¬ìœ¨ ìƒìŠ¹ ê°ì§€
    if (metrics.errorRate > 0.05) { // 5% ì´ìƒ
      await this.alerts.send({
        severity: 'critical',
        type: 'cdc-errors',
        message: `High CDC error rate: ${metrics.errorRate * 100}%`,
        metrics
      });
    }
  }
}
```

## Task 2.11: ì´ë²¤íŠ¸ ì†Œì‹±

### SubTask 2.11.1: ì´ë²¤íŠ¸ ìŠ¤í† ì–´ êµ¬í˜„
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ëª©í‘œ**: ë¶ˆë³€ ì´ë²¤íŠ¸ ì €ì¥ì†Œ ë° ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/event-sourcing/store/event-store.ts
import { DynamoDBDocumentClient } from '@aws-sdk/lib-dynamodb';
import { EventStoreDBClient } from '@eventstore/db-client';
import { v4 as uuidv4 } from 'uuid';

export interface Event {
  eventId: string;
  streamId: string;
  eventType: string;
  eventVersion: number;
  aggregateId: string;
  aggregateType: string;
  causationId?: string;
  correlationId?: string;
  data: any;
  metadata: EventMetadata;
  timestamp: Date;
  sequenceNumber: number;
}

export interface EventMetadata {
  userId?: string;
  source: string;
  ipAddress?: string;
  userAgent?: string;
  [key: string]: any;
}

export class EventStore {
  private eventStoreDB: EventStoreDBClient;
  private dynamoClient: DynamoDBDocumentClient;
  private projectionManager: ProjectionManager;
  private snapshotStore: SnapshotStore;
  
  constructor(
    private config: EventStoreConfig
  ) {
    this.eventStoreDB = new EventStoreDBClient(
      { endpoint: config.eventStoreEndpoint },
      { insecure: config.insecure }
    );
    
    this.projectionManager = new ProjectionManager(this);
    this.snapshotStore = new SnapshotStore(dynamoClient);
  }
  
  // ì´ë²¤íŠ¸ ì¶”ê°€
  async appendEvents(
    streamId: string,
    events: NewEvent[],
    expectedVersion?: number
  ): Promise<AppendResult> {
    // ì´ë²¤íŠ¸ ê²€ì¦
    this.validateEvents(events);
    
    // ë‚™ê´€ì  ë™ì‹œì„± ì œì–´
    if (expectedVersion !== undefined) {
      const currentVersion = await this.getStreamVersion(streamId);
      if (currentVersion !== expectedVersion) {
        throw new ConcurrencyError(
          `Expected version ${expectedVersion}, but stream is at ${currentVersion}`
        );
      }
    }
    
    // ì´ë²¤íŠ¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€
    const enrichedEvents = events.map((event, index) => ({
      eventId: uuidv4(),
      streamId,
      eventType: event.type,
      eventVersion: 1,
      aggregateId: event.aggregateId,
      aggregateType: event.aggregateType,
      causationId: event.causationId,
      correlationId: event.correlationId || uuidv4(),
      data: event.data,
      metadata: {
        ...event.metadata,
        source: this.config.serviceName,
        timestamp: new Date()
      },
      timestamp: new Date(),
      sequenceNumber: (expectedVersion || 0) + index + 1
    }));
    
    // EventStoreDBì— ì €ì¥
    const writeResult = await this.eventStoreDB.appendToStream(
      streamId,
      enrichedEvents.map(e => ({
        type: e.eventType,
        data: e.data,
        metadata: e.metadata
      })),
      {
        expectedRevision: expectedVersion !== undefined ? 
          BigInt(expectedVersion) : constants.ANY
      }
    );
    
    // DynamoDBì—ë„ ì €ì¥ (ì¿¼ë¦¬ ìµœì í™”)
    await this.saveEventsToDynamoDB(enrichedEvents);
    
    // í”„ë¡œì ì…˜ ì—…ë°ì´íŠ¸
    await this.projectionManager.handleEvents(enrichedEvents);
    
    // ì´ë²¤íŠ¸ ë°œí–‰
    await this.publishEvents(enrichedEvents);
    
    return {
      nextExpectedVersion: Number(writeResult.nextExpectedRevision),
      events: enrichedEvents
    };
  }
  
  // ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì½ê¸°
  async readStream(
    streamId: string,
    options?: ReadStreamOptions
  ): Promise<Event[]> {
    const fromRevision = options?.fromVersion !== undefined ?
      BigInt(options.fromVersion) : constants.START;
    
    const direction = options?.direction || 'forwards';
    const maxCount = options?.maxCount || 1000;
    
    const events: Event[] = [];
    
    const stream = this.eventStoreDB.readStream(streamId, {
      direction,
      fromRevision,
      maxCount
    });
    
    for await (const resolvedEvent of stream) {
      events.push(this.mapToEvent(resolvedEvent));
    }
    
    return events;
  }
  
  // ì§‘ê³„ ì¬êµ¬ì„±
  async loadAggregate<T extends AggregateRoot>(
    aggregateId: string,
    aggregateType: string,
    AggregateClass: new () => T
  ): Promise<T> {
    // ìŠ¤ëƒ…ìƒ· í™•ì¸
    const snapshot = await this.snapshotStore.getSnapshot(
      aggregateId,
      aggregateType
    );
    
    let aggregate = new AggregateClass();
    let fromVersion = 0;
    
    if (snapshot) {
      aggregate.loadFromSnapshot(snapshot);
      fromVersion = snapshot.version + 1;
    }
    
    // ìŠ¤ëƒ…ìƒ· ì´í›„ ì´ë²¤íŠ¸ ë¡œë“œ
    const streamId = `${aggregateType}-${aggregateId}`;
    const events = await this.readStream(streamId, {
      fromVersion,
      direction: 'forwards'
    });
    
    // ì´ë²¤íŠ¸ ì ìš©
    for (const event of events) {
      aggregate.apply(event);
    }
    
    // ìŠ¤ëƒ…ìƒ· ìƒì„± ì—¬ë¶€ í™•ì¸
    if (this.shouldCreateSnapshot(aggregate, snapshot)) {
      await this.snapshotStore.saveSnapshot(aggregate);
    }
    
    return aggregate;
  }
  
  // ì´ë²¤íŠ¸ ì¿¼ë¦¬
  async queryEvents(
    criteria: EventQueryCriteria
  ): Promise<QueryResult<Event>> {
    // EventStoreDBì˜ í”„ë¡œì ì…˜ ì‚¬ìš©
    if (criteria.useProjection) {
      return await this.queryProjection(criteria);
    }
    
    // DynamoDB ì¿¼ë¦¬ (ìµœì í™”ëœ)
    const query = this.buildDynamoQuery(criteria);
    const result = await this.dynamoClient.query(query);
    
    const events = result.Items?.map(item => this.mapFromDynamoDB(item)) || [];
    
    return {
      events,
      nextToken: result.LastEvaluatedKey,
      totalCount: result.Count
    };
  }
  
  // ì´ë²¤íŠ¸ ì¬ìƒ
  async replayEvents(
    options: ReplayOptions
  ): Promise<ReplayResult> {
    const { fromTimestamp, toTimestamp, eventTypes, targetProjection } = options;
    
    // ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ í•„í„°ë§
    const events = await this.queryEvents({
      fromTimestamp,
      toTimestamp,
      eventTypes,
      orderBy: 'timestamp',
      direction: 'asc'
    });
    
    // ëŒ€ìƒ í”„ë¡œì ì…˜ ì´ˆê¸°í™”
    if (targetProjection) {
      await this.projectionManager.resetProjection(targetProjection);
    }
    
    // ë°°ì¹˜ë¡œ ì´ë²¤íŠ¸ ì¬ìƒ
    const batchSize = 1000;
    let processedCount = 0;
    
    for (let i = 0; i < events.events.length; i += batchSize) {
      const batch = events.events.slice(i, i + batchSize);
      
      if (targetProjection) {
        await this.projectionManager.replayBatch(targetProjection, batch);
      } else {
        // ëª¨ë“  í”„ë¡œì ì…˜ì— ì¬ìƒ
        await this.projectionManager.handleEvents(batch);
      }
      
      processedCount += batch.length;
      
      // ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
      this.emit('replay:progress', {
        processed: processedCount,
        total: events.totalCount,
        percentage: (processedCount / events.totalCount) * 100
      });
    }
    
    return {
      processedEvents: processedCount,
      duration: Date.now() - startTime,
      errors: []
    };
  }
}

// ì§‘ê³„ ë£¨íŠ¸ ê¸°ë³¸ í´ë˜ìŠ¤
export abstract class AggregateRoot {
  protected version: number = 0;
  protected uncommittedEvents: Event[] = [];
  
  abstract get aggregateId(): string;
  abstract get aggregateType(): string;
  
  // ì´ë²¤íŠ¸ ì ìš©
  apply(event: Event): void {
    // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ í˜¸ì¶œ
    const handler = this.getEventHandler(event.eventType);
    if (handler) {
      handler.call(this, event);
    }
    
    this.version = event.sequenceNumber;
  }
  
  // ìƒˆ ì´ë²¤íŠ¸ ë°œìƒ
  protected raiseEvent(eventType: string, data: any): void {
    const event: Event = {
      eventId: uuidv4(),
      streamId: `${this.aggregateType}-${this.aggregateId}`,
      eventType,
      eventVersion: 1,
      aggregateId: this.aggregateId,
      aggregateType: this.aggregateType,
      data,
      metadata: {},
      timestamp: new Date(),
      sequenceNumber: this.version + 1
    };
    
    this.apply(event);
    this.uncommittedEvents.push(event);
  }
  
  // ì»¤ë°‹ë˜ì§€ ì•Šì€ ì´ë²¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
  getUncommittedEvents(): Event[] {
    return this.uncommittedEvents;
  }
  
  // ì»¤ë°‹ ì™„ë£Œ í‘œì‹œ
  markEventsAsCommitted(): void {
    this.uncommittedEvents = [];
  }
  
  private getEventHandler(eventType: string): Function | undefined {
    const handlerName = `on${eventType}`;
    return (this as any)[handlerName];
  }
}
```

### SubTask 2.11.2: í”„ë¡œì ì…˜ ì‹œìŠ¤í…œ êµ¬ì¶•
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ì—ì„œ ì½ê¸° ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” í”„ë¡œì ì…˜ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/event-sourcing/projections/projection-manager.ts
export interface Projection {
  name: string;
  version: string;
  state: ProjectionState;
  handlers: Map<string, ProjectionHandler>;
  dependencies?: string[];
}

export interface ProjectionState {
  status: 'running' | 'stopped' | 'paused' | 'rebuilding';
  lastProcessedEvent?: string;
  lastProcessedTimestamp?: Date;
  checkpointPosition?: bigint;
  errors?: ProjectionError[];
}

export class ProjectionManager {
  private projections: Map<string, Projection> = new Map();
  private checkpointStore: CheckpointStore;
  private readModelStore: ReadModelStore;
  
  constructor(
    private eventStore: EventStore,
    private config: ProjectionConfig
  ) {
    this.checkpointStore = new CheckpointStore();
    this.readModelStore = new ReadModelStore();
    
    this.registerBuiltInProjections();
  }
  
  // í”„ë¡œì ì…˜ ë“±ë¡
  registerProjection(projection: Projection): void {
    // ì˜ì¡´ì„± ê²€ì¦
    if (projection.dependencies) {
      for (const dep of projection.dependencies) {
        if (!this.projections.has(dep)) {
          throw new Error(`Dependency ${dep} not found`);
        }
      }
    }
    
    this.projections.set(projection.name, projection);
    
    // ìë™ ì‹œì‘
    if (this.config.autoStart) {
      this.startProjection(projection.name);
    }
  }
  
  // í”„ë¡œì ì…˜ ì‹œì‘
  async startProjection(name: string): Promise<void> {
    const projection = this.projections.get(name);
    if (!projection) {
      throw new Error(`Projection ${name} not found`);
    }
    
    projection.state.status = 'running';
    
    // ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    const checkpoint = await this.checkpointStore.getCheckpoint(name);
    const startPosition = checkpoint?.position || BigInt(0);
    
    // ì´ë²¤íŠ¸ êµ¬ë…
    const subscription = await this.eventStore.subscribeToAll({
      fromPosition: startPosition,
      resolveLinkTos: true
    });
    
    // ì´ë²¤íŠ¸ ì²˜ë¦¬ ë£¨í”„
    for await (const event of subscription) {
      try {
        await this.processEvent(projection, event);
        
        // ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸
        if (this.shouldCheckpoint(projection)) {
          await this.saveCheckpoint(projection);
        }
      } catch (error) {
        await this.handleProjectionError(projection, event, error);
      }
    }
  }
  
  // ì´ë²¤íŠ¸ ì²˜ë¦¬
  private async processEvent(
    projection: Projection,
    event: Event
  ): Promise<void> {
    const handler = projection.handlers.get(event.eventType);
    
    if (!handler) {
      // ì´ í”„ë¡œì ì…˜ì´ ì²˜ë¦¬í•˜ì§€ ì•ŠëŠ” ì´ë²¤íŠ¸
      return;
    }
    
    // ì½ê¸° ëª¨ë¸ ì—…ë°ì´íŠ¸
    await this.readModelStore.transaction(async (tx) => {
      const context = this.createProjectionContext(projection, tx);
      await handler(event, context);
    });
    
    // ìƒíƒœ ì—…ë°ì´íŠ¸
    projection.state.lastProcessedEvent = event.eventId;
    projection.state.lastProcessedTimestamp = event.timestamp;
    projection.state.checkpointPosition = BigInt(event.sequenceNumber);
  }
  
  // í”„ë¡œì ì…˜ ì¬êµ¬ì¶•
  async rebuildProjection(
    name: string,
    options?: RebuildOptions
  ): Promise<RebuildResult> {
    const projection = this.projections.get(name);
    if (!projection) {
      throw new Error(`Projection ${name} not found`);
    }
    
    projection.state.status = 'rebuilding';
    
    // ì½ê¸° ëª¨ë¸ ì´ˆê¸°í™”
    await this.readModelStore.clearProjection(name);
    
    // ì²´í¬í¬ì¸íŠ¸ ë¦¬ì…‹
    await this.checkpointStore.resetCheckpoint(name);
    
    // ì´ë²¤íŠ¸ ì¬ìƒ
    const startTime = Date.now();
    let processedCount = 0;
    
    const events = this.eventStore.readAll({
      fromPosition: BigInt(0),
      direction: 'forwards',
      maxCount: options?.batchSize || 10000
    });
    
    for await (const event of events) {
      if (projection.handlers.has(event.eventType)) {
        await this.processEvent(projection, event);
        processedCount++;
        
        // ì§„í–‰ ìƒí™© ë³´ê³ 
        if (processedCount % 1000 === 0) {
          this.emit('rebuild:progress', {
            projection: name,
            processed: processedCount,
            currentEvent: event.eventId
          });
        }
      }
    }
    
    projection.state.status = 'running';
    
    return {
      projectionName: name,
      eventsProcessed: processedCount,
      duration: Date.now() - startTime,
      finalPosition: projection.state.checkpointPosition
    };
  }
  
  // ë‚´ì¥ í”„ë¡œì ì…˜ ë“±ë¡
  private registerBuiltInProjections(): void {
    // ì‚¬ìš©ì í”„ë¡œì ì…˜
    this.registerProjection({
      name: 'UserProjection',
      version: '1.0.0',
      state: { status: 'stopped' },
      handlers: new Map([
        ['UserCreated', this.handleUserCreated.bind(this)],
        ['UserUpdated', this.handleUserUpdated.bind(this)],
        ['UserDeleted', this.handleUserDeleted.bind(this)]
      ])
    });
    
    // í”„ë¡œì íŠ¸ í†µê³„ í”„ë¡œì ì…˜
    this.registerProjection({
      name: 'ProjectStatistics',
      version: '1.0.0',
      state: { status: 'stopped' },
      handlers: new Map([
        ['ProjectCreated', this.handleProjectCreatedStats.bind(this)],
        ['TaskAdded', this.handleTaskAddedStats.bind(this)],
        ['TaskCompleted', this.handleTaskCompletedStats.bind(this)]
      ])
    });
  }
  
  // ì‚¬ìš©ì ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
  private async handleUserCreated(
    event: Event,
    context: ProjectionContext
  ): Promise<void> {
    await context.store.put('users', event.aggregateId, {
      userId: event.aggregateId,
      ...event.data,
      createdAt: event.timestamp,
      updatedAt: event.timestamp
    });
  }
}

// ì½ê¸° ëª¨ë¸ ìŠ¤í† ì–´
export class ReadModelStore {
  constructor(
    private dynamoClient: DynamoDBDocumentClient
  ) {}
  
  async transaction<T>(
    handler: (tx: ReadModelTransaction) => Promise<T>
  ): Promise<T> {
    const tx = new ReadModelTransaction(this.dynamoClient);
    
    try {
      const result = await handler(tx);
      await tx.commit();
      return result;
    } catch (error) {
      await tx.rollback();
      throw error;
    }
  }
  
  async query(
    projection: string,
    criteria: QueryCriteria
  ): Promise<QueryResult> {
    const params = this.buildQueryParams(projection, criteria);
    const result = await this.dynamoClient.query(params);
    
    return {
      items: result.Items || [],
      nextToken: result.LastEvaluatedKey,
      count: result.Count || 0
    };
  }
}
```

### SubTask 2.11.3: CQRS íŒ¨í„´ êµ¬í˜„
**ë‹´ë‹¹ì**: ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: Commandì™€ Query ë¶„ë¦¬ë¥¼ í†µí•œ ì½ê¸°/ì“°ê¸° ìµœì í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/event-sourcing/cqrs/command-bus.ts
export interface Command {
  commandId: string;
  commandType: string;
  aggregateId: string;
  payload: any;
  metadata: CommandMetadata;
}

export interface CommandMetadata {
  userId: string;
  correlationId: string;
  causationId?: string;
  timestamp: Date;
}

export class CommandBus {
  private handlers: Map<string, CommandHandler> = new Map();
  private middleware: CommandMiddleware[] = [];
  private eventStore: EventStore;
  private sagaManager: SagaManager;
  
  constructor(
    eventStore: EventStore,
    private config: CommandBusConfig
  ) {
    this.eventStore = eventStore;
    this.sagaManager = new SagaManager(eventStore);
    
    this.registerDefaultMiddleware();
  }
  
  // ì»¤ë§¨ë“œ í•¸ë“¤ëŸ¬ ë“±ë¡
  registerHandler<T extends Command>(
    commandType: string,
    handler: CommandHandler<T>
  ): void {
    if (this.handlers.has(commandType)) {
      throw new Error(`Handler already registered for ${commandType}`);
    }
    
    this.handlers.set(commandType, handler);
  }
  
  // ì»¤ë§¨ë“œ ì‹¤í–‰
  async execute<T extends Command>(command: T): Promise<CommandResult> {
    // ë¯¸ë“¤ì›¨ì–´ ì²´ì¸ ì‹¤í–‰
    const context = await this.runMiddleware(command);
    
    // í•¸ë“¤ëŸ¬ ì°¾ê¸°
    const handler = this.handlers.get(command.commandType);
    if (!handler) {
      throw new Error(`No handler registered for ${command.commandType}`);
    }
    
    try {
      // ì»¤ë§¨ë“œ ì‹¤í–‰
      const events = await handler.handle(command, context);
      
      // ì´ë²¤íŠ¸ ì €ì¥
      const appendResult = await this.eventStore.appendEvents(
        `${command.aggregateId}`,
        events.map(e => ({
          ...e,
          causationId: command.commandId,
          correlationId: command.metadata.correlationId
        }))
      );
      
      // ì‚¬ê°€ ì²˜ë¦¬
      await this.sagaManager.handleEvents(appendResult.events);
      
      return {
        success: true,
        aggregateId: command.aggregateId,
        version: appendResult.nextExpectedVersion,
        events: appendResult.events
      };
    } catch (error) {
      return {
        success: false,
        error: error as Error,
        aggregateId: command.aggregateId
      };
    }
  }
  
  // ë¯¸ë“¤ì›¨ì–´ ì‹¤í–‰
  private async runMiddleware(command: Command): Promise<CommandContext> {
    const context: CommandContext = {
      command,
      metadata: {},
      startTime: Date.now()
    };
    
    for (const middleware of this.middleware) {
      await middleware.process(context);
    }
    
    return context;
  }
  
  // ê¸°ë³¸ ë¯¸ë“¤ì›¨ì–´ ë“±ë¡
  private registerDefaultMiddleware(): void {
    // ê²€ì¦ ë¯¸ë“¤ì›¨ì–´
    this.use(new ValidationMiddleware());
    
    // ì¸ì¦/ì¸ê°€ ë¯¸ë“¤ì›¨ì–´
    this.use(new AuthorizationMiddleware());
    
    // ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
    this.use(new LoggingMiddleware());
    
    // ì„±ëŠ¥ ì¸¡ì • ë¯¸ë“¤ì›¨ì–´
    this.use(new PerformanceMiddleware());
  }
}

// ì¿¼ë¦¬ ë²„ìŠ¤
export class QueryBus {
  private handlers: Map<string, QueryHandler> = new Map();
  private cache: QueryCache;
  private readModelStore: ReadModelStore;
  
  constructor(
    readModelStore: ReadModelStore,
    private config: QueryBusConfig
  ) {
    this.readModelStore = readModelStore;
    this.cache = new QueryCache(config.cache);
  }
  
  // ì¿¼ë¦¬ í•¸ë“¤ëŸ¬ ë“±ë¡
  registerHandler<T extends Query, R>(
    queryType: string,
    handler: QueryHandler<T, R>
  ): void {
    this.handlers.set(queryType, handler);
  }
  
  // ì¿¼ë¦¬ ì‹¤í–‰
  async execute<T extends Query, R>(query: T): Promise<R> {
    // ìºì‹œ í™•ì¸
    const cacheKey = this.getCacheKey(query);
    const cached = await this.cache.get<R>(cacheKey);
    
    if (cached && !query.bypassCache) {
      return cached;
    }
    
    // í•¸ë“¤ëŸ¬ ì‹¤í–‰
    const handler = this.handlers.get(query.queryType);
    if (!handler) {
      throw new Error(`No handler registered for ${query.queryType}`);
    }
    
    const result = await handler.handle(query, this.readModelStore);
    
    // ìºì‹œ ì €ì¥
    if (query.cacheable !== false) {
      await this.cache.set(cacheKey, result, query.cacheTTL);
    }
    
    return result;
  }
  
  // ìºì‹œ ë¬´íš¨í™”
  async invalidateCache(pattern: string): Promise<void> {
    await this.cache.invalidatePattern(pattern);
  }
}

// ì»¤ë§¨ë“œ í•¸ë“¤ëŸ¬ ì˜ˆì‹œ
export class CreateUserCommandHandler implements CommandHandler<CreateUserCommand> {
  constructor(
    private userRepository: UserRepository,
    private validator: UserValidator
  ) {}
  
  async handle(
    command: CreateUserCommand,
    context: CommandContext
  ): Promise<Event[]> {
    // ê²€ì¦
    await this.validator.validateCreateUser(command.payload);
    
    // ì¤‘ë³µ í™•ì¸
    const existing = await this.userRepository.findByEmail(
      command.payload.email
    );
    if (existing) {
      throw new Error('User with this email already exists');
    }
    
    // ì§‘ê³„ ìƒì„±
    const user = User.create(
      command.aggregateId,
      command.payload.name,
      command.payload.email,
      command.payload.role
    );
    
    // ì´ë²¤íŠ¸ ë°˜í™˜
    return user.getUncommittedEvents();
  }
}

// ì‚¬ê°€ ê´€ë¦¬ì
export class SagaManager {
  private sagas: Map<string, Saga> = new Map();
  private sagaStore: SagaStore;
  
  constructor(
    private eventStore: EventStore
  ) {
    this.sagaStore = new SagaStore();
    this.registerSagas();
  }
  
  // ì‚¬ê°€ ë“±ë¡
  private registerSagas(): void {
    this.register(new UserRegistrationSaga());
    this.register(new ProjectCreationSaga());
    this.register(new PaymentProcessingSaga());
  }
  
  // ì´ë²¤íŠ¸ ì²˜ë¦¬
  async handleEvents(events: Event[]): Promise<void> {
    for (const event of events) {
      const interestedSagas = this.findInterestedSagas(event);
      
      for (const sagaType of interestedSagas) {
        await this.processSagaEvent(sagaType, event);
      }
    }
  }
  
  private async processSagaEvent(
    sagaType: string,
    event: Event
  ): Promise<void> {
    // ì‚¬ê°€ ì¸ìŠ¤í„´ìŠ¤ ì°¾ê¸° ë˜ëŠ” ìƒì„±
    let sagaInstance = await this.sagaStore.findByCorrelationId(
      sagaType,
      event.correlationId
    );
    
    if (!sagaInstance) {
      const SagaClass = this.sagas.get(sagaType);
      if (!SagaClass) return;
      
      sagaInstance = new SagaClass();
      sagaInstance.correlationId = event.correlationId;
    }
    
    // ì´ë²¤íŠ¸ ì²˜ë¦¬
    const commands = await sagaInstance.handle(event);
    
    // ìƒì„±ëœ ì»¤ë§¨ë“œ ì‹¤í–‰
    for (const command of commands) {
      await this.commandBus.execute(command);
    }
    
    // ì‚¬ê°€ ìƒíƒœ ì €ì¥
    await this.sagaStore.save(sagaInstance);
  }
}
```

### SubTask 2.11.4: ì´ë²¤íŠ¸ ë²„ì „ ê´€ë¦¬
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ ì§„í™”ì™€ í˜¸í™˜ì„± ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/event-sourcing/versioning/event-versioning.ts
export interface EventSchema {
  eventType: string;
  version: number;
  schema: JSONSchema;
  deprecated?: boolean;
  migrationPath?: MigrationPath[];
}

export interface MigrationPath {
  fromVersion: number;
  toVersion: number;
  migrator: EventMigrator;
}

export class EventVersionManager {
  private schemas: Map<string, Map<number, EventSchema>> = new Map();
  private migrators: Map<string, EventMigrator> = new Map();
  private schemaRegistry: SchemaRegistry;
  
  constructor(
    private config: VersioningConfig
  ) {
    this.schemaRegistry = new SchemaRegistry(config.registryUrl);
    this.registerBuiltInSchemas();
  }
  
  // ìŠ¤í‚¤ë§ˆ ë“±ë¡
  async registerSchema(schema: EventSchema): Promise<void> {
    // ìŠ¤í‚¤ë§ˆ ê²€ì¦
    await this.validateSchema(schema);
    
    // ë²„ì „ ì¶©ëŒ í™•ì¸
    if (this.hasSchema(schema.eventType, schema.version)) {
      throw new Error(
        `Schema already exists for ${schema.eventType} v${schema.version}`
      );
    }
    
    // ì´ì „ ë²„ì „ê³¼ì˜ í˜¸í™˜ì„± í™•ì¸
    if (schema.version > 1) {
      await this.checkBackwardCompatibility(schema);
    }
    
    // ìŠ¤í‚¤ë§ˆ ì €ì¥
    if (!this.schemas.has(schema.eventType)) {
      this.schemas.set(schema.eventType, new Map());
    }
    this.schemas.get(schema.eventType)!.set(schema.version, schema);
    
    // ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡
    await this.schemaRegistry.register(schema);
  }
  
  // ì´ë²¤íŠ¸ ì—…ê·¸ë ˆì´ë“œ
  async upgradeEvent(
    event: Event,
    targetVersion: number
  ): Promise<Event> {
    const currentVersion = event.eventVersion;
    
    if (currentVersion === targetVersion) {
      return event;
    }
    
    if (currentVersion > targetVersion) {
      throw new Error('Downgrade not supported');
    }
    
    // ë§ˆì´ê·¸ë ˆì´ì…˜ ê²½ë¡œ ì°¾ê¸°
    const path = this.findMigrationPath(
      event.eventType,
      currentVersion,
      targetVersion
    );
    
    if (!path) {
      throw new Error(
        `No migration path from v${currentVersion} to v${targetVersion}`
      );
    }
    
    // ë‹¨ê³„ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜
    let migratedEvent = { ...event };
    
    for (const step of path) {
      const migrator = step.migrator;
      migratedEvent = await migrator.migrate(migratedEvent);
      migratedEvent.eventVersion = step.toVersion;
    }
    
    // ìµœì¢… ìŠ¤í‚¤ë§ˆ ê²€ì¦
    await this.validateEventAgainstSchema(
      migratedEvent,
      targetVersion
    );
    
    return migratedEvent;
  }
  
  // ì´ë²¤íŠ¸ ë‹¤ìš´ê·¸ë ˆì´ë“œ (ì½ê¸° ì „ìš©)
  async downgradeEventForReading(
    event: Event,
    targetVersion: number
  ): Promise<any> {
    if (targetVersion >= event.eventVersion) {
      return event.data;
    }
    
    // ë‹¤ìš´ê·¸ë ˆì´ë“œ ë³€í™˜
    const downgrader = this.findDowngrader(
      event.eventType,
      event.eventVersion,
      targetVersion
    );
    
    if (!downgrader) {
      throw new Error('Cannot downgrade event for reading');
    }
    
    return await downgrader.transform(event.data);
  }
  
  // í˜¸í™˜ì„± ê²€ì‚¬
  private async checkBackwardCompatibility(
    schema: EventSchema
  ): Promise<void> {
    const previousVersion = schema.version - 1;
    const previousSchema = this.getSchema(
      schema.eventType,
      previousVersion
    );
    
    if (!previousSchema) {
      throw new Error(`Previous version ${previousVersion} not found`);
    }
    
    const compatibility = await this.schemaRegistry.checkCompatibility(
      previousSchema.schema,
      schema.schema
    );
    
    if (!compatibility.isCompatible) {
      throw new Error(
        `Schema not backward compatible: ${compatibility.errors.join(', ')}`
      );
    }
  }
  
  // ë‚´ì¥ ìŠ¤í‚¤ë§ˆ ë“±ë¡
  private registerBuiltInSchemas(): void {
    // UserCreated v1
    this.registerSchema({
      eventType: 'UserCreated',
      version: 1,
      schema: {
        type: 'object',
        properties: {
          userId: { type: 'string' },
          email: { type: 'string' },
          name: { type: 'string' }
        },
        required: ['userId', 'email', 'name']
      }
    });
    
    // UserCreated v2 (role ì¶”ê°€)
    this.registerSchema({
      eventType: 'UserCreated',
      version: 2,
      schema: {
        type: 'object',
        properties: {
          userId: { type: 'string' },
          email: { type: 'string' },
          name: { type: 'string' },
          role: { type: 'string', default: 'user' }
        },
        required: ['userId', 'email', 'name', 'role']
      },
      migrationPath: [{
        fromVersion: 1,
        toVersion: 2,
        migrator: new AddDefaultRoleMigrator()
      }]
    });
  }
}

// ì´ë²¤íŠ¸ ë§ˆì´ê·¸ë ˆì´í„° ì˜ˆì‹œ
export class AddDefaultRoleMigrator implements EventMigrator {
  async migrate(event: Event): Promise<Event> {
    return {
      ...event,
      data: {
        ...event.data,
        role: event.data.role || 'user'
      }
    };
  }
}

// ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬
export class SchemaRegistry {
  constructor(
    private registryUrl: string
  ) {}
  
  async register(schema: EventSchema): Promise<void> {
    const response = await fetch(`${this.registryUrl}/schemas`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        subject: `${schema.eventType}-v${schema.version}`,
        schema: JSON.stringify(schema.schema)
      })
    });
    
    if (!response.ok) {
      throw new Error('Failed to register schema');
    }
  }
  
  async checkCompatibility(
    oldSchema: JSONSchema,
    newSchema: JSONSchema
  ): Promise<CompatibilityResult> {
    // JSON Schema í˜¸í™˜ì„± ê²€ì‚¬ ë¡œì§
    const validator = new SchemaCompatibilityValidator();
    return validator.check(oldSchema, newSchema);
  }
}
```

## Task 2.12: ë°ì´í„° ë³µì œ ë° ë™ê¸°í™”

### SubTask 2.12.1: ë©€í‹° ë¦¬ì „ ë³µì œ ì„¤ì •
**ë‹´ë‹¹ì**: ì¸í”„ë¼ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: DynamoDB Global Tablesë¥¼ í™œìš©í•œ ë©€í‹° ë¦¬ì „ ë°ì´í„° ë³µì œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/replication/multi-region/replication-manager.ts
import { 
  DynamoDBClient,
  CreateGlobalTableCommand,
  UpdateGlobalTableCommand,
  DescribeGlobalTableCommand
} from '@aws-sdk/client-dynamodb';

export interface ReplicationConfig {
  primaryRegion: string;
  replicaRegions: string[];
  tables: TableReplicationConfig[];
  conflictResolution: ConflictResolutionStrategy;
}

export interface TableReplicationConfig {
  tableName: string;
  replicationMode: 'ACTIVE_ACTIVE' | 'ACTIVE_PASSIVE';
  readCapacity?: number;
  writeCapacity?: number;
  globalSecondaryIndexes?: GSIReplicationConfig[];
}

export class MultiRegionReplicationManager {
  private clients: Map<string, DynamoDBClient> = new Map();
  private healthMonitor: RegionHealthMonitor;
  private conflictResolver: ConflictResolver;
  
  constructor(
    private config: ReplicationConfig
  ) {
    this.initializeClients();
    this.healthMonitor = new RegionHealthMonitor(this.clients);
    this.conflictResolver = new ConflictResolver(config.conflictResolution);
  }
  
  // í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
  private initializeClients(): void {
    const allRegions = [
      this.config.primaryRegion,
      ...this.config.replicaRegions
    ];
    
    for (const region of allRegions) {
      this.clients.set(
        region,
        new DynamoDBClient({ region })
      );
    }
  }
  
  // ê¸€ë¡œë²Œ í…Œì´ë¸” ìƒì„±
  async createGlobalTable(
    tableConfig: TableReplicationConfig
  ): Promise<void> {
    const primaryClient = this.clients.get(this.config.primaryRegion)!;
    
    // ê¸°ì¡´ í…Œì´ë¸”ì„ ê¸€ë¡œë²Œ í…Œì´ë¸”ë¡œ ë³€í™˜
    const replicaUpdates = this.config.replicaRegions.map(region => ({
      Create: {
        RegionName: region,
        GlobalSecondaryIndexes: tableConfig.globalSecondaryIndexes?.map(
          gsi => ({
            IndexName: gsi.indexName,
            ProvisionedThroughputOverride: {
              ReadCapacityUnits: gsi.readCapacity,
              WriteCapacityUnits: gsi.writeCapacity
            }
          })
        )
      }
    }));
    
    await primaryClient.send(
      new UpdateGlobalTableCommand({
        GlobalTableName: tableConfig.tableName,
        ReplicaUpdates: replicaUpdates
      })
    );
    
    // ë³µì œ ìƒíƒœ ëª¨ë‹ˆí„°ë§
    await this.waitForReplicationActive(tableConfig.tableName);
  }
  
  // ë³µì œ ìƒíƒœ í™•ì¸
  async getReplicationStatus(
    tableName: string
  ): Promise<ReplicationStatus> {
    const primaryClient = this.clients.get(this.config.primaryRegion)!;
    
    const response = await primaryClient.send(
      new DescribeGlobalTableCommand({
        GlobalTableName: tableName
      })
    );
    
    const globalTable = response.GlobalTableDescription!;
    
    return {
      tableName,
      status: globalTable.GlobalTableStatus as ReplicationStatusType,
      regions: globalTable.ReplicationGroup?.map(replica => ({
        region: replica.RegionName!,
        status: replica.ReplicaStatus!,
        lastUpdated: replica.ReplicaStatusDateTime,
        backlog: replica.ReplicaBacklogSizeBytes
      })) || [],
      creationDateTime: globalTable.CreationDateTime
    };
  }
  
  // ë¦¬ì „ë³„ ì§€ì—° ì‹œê°„ ëª¨ë‹ˆí„°ë§
  async monitorReplicationLag(): Promise<ReplicationLagMetrics> {
    const metrics: ReplicationLagMetrics = {
      timestamp: new Date(),
      regions: new Map()
    };
    
    for (const [region, client] of this.clients) {
      const lag = await this.measureReplicationLag(region);
      metrics.regions.set(region, {
        lagMs: lag,
        healthy: lag < this.config.maxAcceptableLagMs
      });
    }
    
    return metrics;
  }
  
  // ë³µì œ ì¶©ëŒ í•´ê²°
  async resolveConflicts(
    tableName: string,
    conflictRecords: ConflictRecord[]
  ): Promise<ConflictResolutionResult> {
    const resolutions: Resolution[] = [];
    
    for (const conflict of conflictRecords) {
      const resolution = await this.conflictResolver.resolve(conflict);
      
      // í•´ê²°ëœ ë ˆì½”ë“œ ì ìš©
      await this.applyResolution(tableName, resolution);
      
      resolutions.push(resolution);
    }
    
    return {
      resolved: resolutions.filter(r => r.status === 'resolved').length,
      failed: resolutions.filter(r => r.status === 'failed').length,
      resolutions
    };
  }
  
  // ë¦¬ì „ í˜ì¼ì˜¤ë²„
  async failoverToRegion(
    targetRegion: string
  ): Promise<FailoverResult> {
    // í˜„ì¬ Primary ë¦¬ì „ ìƒíƒœ í™•ì¸
    const primaryHealth = await this.healthMonitor.checkRegion(
      this.config.primaryRegion
    );
    
    if (primaryHealth.healthy) {
      throw new Error('Primary region is healthy, failover not needed');
    }
    
    // íƒ€ê²Ÿ ë¦¬ì „ ê²€ì¦
    const targetHealth = await this.healthMonitor.checkRegion(targetRegion);
    if (!targetHealth.healthy) {
      throw new Error(`Target region ${targetRegion} is not healthy`);
    }
    
    // ë¼ìš°íŒ… ì—…ë°ì´íŠ¸
    await this.updateRouting(targetRegion);
    
    // ìƒˆ Primary ìŠ¹ê²©
    this.config.primaryRegion = targetRegion;
    
    // ì•Œë¦¼ ë°œì†¡
    await this.notifyFailover(targetRegion);
    
    return {
      newPrimaryRegion: targetRegion,
      timestamp: new Date(),
      affectedTables: this.config.tables.map(t => t.tableName)
    };
  }
}

// ì¶©ëŒ í•´ê²°ì
export class ConflictResolver {
  constructor(
    private strategy: ConflictResolutionStrategy
  ) {}
  
  async resolve(conflict: ConflictRecord): Promise<Resolution> {
    switch (this.strategy) {
      case 'LAST_WRITER_WINS':
        return this.lastWriterWins(conflict);
        
      case 'CUSTOM_LOGIC':
        return this.customResolution(conflict);
        
      case 'MANUAL_REVIEW':
        return this.queueForManualReview(conflict);
        
      default:
        throw new Error(`Unknown strategy: ${this.strategy}`);
    }
  }
  
  private lastWriterWins(conflict: ConflictRecord): Resolution {
    // íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ í•´ê²°
    const winner = conflict.versions.reduce((latest, current) => {
      return current.timestamp > latest.timestamp ? current : latest;
    });
    
    return {
      conflictId: conflict.id,
      winningVersion: winner,
      strategy: 'LAST_WRITER_WINS',
      status: 'resolved'
    };
  }
  
  private async customResolution(
    conflict: ConflictRecord
  ): Promise<Resolution> {
    // ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì— ë”°ë¥¸ í•´ê²°
    if (conflict.entityType === 'User') {
      return this.resolveUserConflict(conflict);
    } else if (conflict.entityType === 'Project') {
      return this.resolveProjectConflict(conflict);
    }
    
    // ê¸°ë³¸ ì „ëµìœ¼ë¡œ í´ë°±
    return this.lastWriterWins(conflict);
  }
}

// ë¦¬ì „ ê±´ê°• ëª¨ë‹ˆí„°
export class RegionHealthMonitor {
  private healthChecks: Map<string, HealthCheck> = new Map();
  
  constructor(
    private clients: Map<string, DynamoDBClient>
  ) {
    this.initializeHealthChecks();
  }
  
  async checkRegion(region: string): Promise<RegionHealth> {
    const client = this.clients.get(region);
    if (!client) {
      return { region, healthy: false, reason: 'No client configured' };
    }
    
    const checks = await Promise.all([
      this.checkConnectivity(client),
      this.checkLatency(client),
      this.checkThroughput(client)
    ]);
    
    const healthy = checks.every(check => check.passed);
    
    return {
      region,
      healthy,
      checks,
      timestamp: new Date()
    };
  }
  
  private async checkConnectivity(
    client: DynamoDBClient
  ): Promise<HealthCheckResult> {
    try {
      await client.send(new ListTablesCommand({ Limit: 1 }));
      return { name: 'connectivity', passed: true };
    } catch (error) {
      return { 
        name: 'connectivity', 
        passed: false, 
        error: error.message 
      };
    }
  }
}
```

### SubTask 2.12.2: ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™”
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: WebSocketê³¼ Server-Sent Eventsë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/sync/realtime/sync-manager.ts
import WebSocket from 'ws';
import { EventEmitter } from 'events';
import { DynamoDBStreamsClient } from '@aws-sdk/client-dynamodb-streams';

export interface SyncConfig {
  wsPort: number;
  sseEndpoint: string;
  syncChannels: SyncChannel[];
  authentication: AuthConfig;
}

export interface SyncChannel {
  name: string;
  entityTypes: string[];
  filters?: SyncFilter[];
  transformers?: DataTransformer[];
}

export class RealtimeSyncManager extends EventEmitter {
  private wsServer: WebSocket.Server;
  private sseClients: Map<string, SSEClient> = new Map();
  private syncEngine: SyncEngine;
  private subscriptionManager: SubscriptionManager;
  
  constructor(
    private config: SyncConfig,
    private streamsClient: DynamoDBStreamsClient
  ) {
    super();
    this.wsServer = new WebSocket.Server({ port: config.wsPort });
    this.syncEngine = new SyncEngine(streamsClient);
    this.subscriptionManager = new SubscriptionManager();
    
    this.initialize();
  }
  
  private initialize(): void {
    // WebSocket ì„œë²„ ì„¤ì •
    this.wsServer.on('connection', this.handleWebSocketConnection.bind(this));
    
    // DynamoDB Streams êµ¬ë…
    this.syncEngine.on('dataChange', this.handleDataChange.bind(this));
    this.syncEngine.start();
  }
  
  // WebSocket ì—°ê²° ì²˜ë¦¬
  private async handleWebSocketConnection(
    ws: WebSocket,
    req: any
  ): Promise<void> {
    // ì¸ì¦
    const auth = await this.authenticate(req);
    if (!auth.valid) {
      ws.close(1008, 'Unauthorized');
      return;
    }
    
    const client = new SyncClient(ws, auth.userId);
    
    // ë©”ì‹œì§€ í•¸ë“¤ëŸ¬
    ws.on('message', async (data) => {
      try {
        const message = JSON.parse(data.toString());
        await this.handleClientMessage(client, message);
      } catch (error) {
        client.sendError('Invalid message format');
      }
    });
    
    // ì—°ê²° ì¢…ë£Œ ì²˜ë¦¬
    ws.on('close', () => {
      this.subscriptionManager.removeClient(client.id);
    });
    
    // ì´ˆê¸° ë™ê¸°í™”
    await this.performInitialSync(client);
  }
  
  // í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
  private async handleClientMessage(
    client: SyncClient,
    message: ClientMessage
  ): Promise<void> {
    switch (message.type) {
      case 'subscribe':
        await this.handleSubscribe(client, message.payload);
        break;
        
      case 'unsubscribe':
        await this.handleUnsubscribe(client, message.payload);
        break;
        
      case 'sync':
        await this.handleSyncRequest(client, message.payload);
        break;
        
      case 'update':
        await this.handleClientUpdate(client, message.payload);
        break;
        
      default:
        client.sendError(`Unknown message type: ${message.type}`);
    }
  }
  
  // êµ¬ë… ì²˜ë¦¬
  private async handleSubscribe(
    client: SyncClient,
    payload: SubscribePayload
  ): Promise<void> {
    const { channels, entities, filters } = payload;
    
    // ê¶Œí•œ í™•ì¸
    const authorized = await this.checkSubscriptionAuth(
      client.userId,
      channels
    );
    
    if (!authorized) {
      client.sendError('Unauthorized subscription');
      return;
    }
    
    // êµ¬ë… ë“±ë¡
    const subscription = this.subscriptionManager.subscribe(
      client.id,
      {
        channels,
        entities,
        filters,
        transformers: this.getTransformersForClient(client)
      }
    );
    
    // êµ¬ë… í™•ì¸ ì „ì†¡
    client.send({
      type: 'subscribed',
      subscriptionId: subscription.id,
      channels: subscription.channels
    });
  }
  
  // ë°ì´í„° ë³€ê²½ ì²˜ë¦¬
  private async handleDataChange(change: DataChange): Promise<void> {
    // ê´€ë ¨ êµ¬ë…ì ì°¾ê¸°
    const subscribers = this.subscriptionManager.findSubscribers(change);
    
    // ê° êµ¬ë…ìì—ê²Œ ë³€ê²½ ì‚¬í•­ ì „ì†¡
    for (const subscription of subscribers) {
      const client = this.findClient(subscription.clientId);
      if (!client) continue;
      
      // í•„í„° ì ìš©
      if (!this.applyFilters(change, subscription.filters)) {
        continue;
      }
      
      // ë³€í™˜ ì ìš©
      const transformed = await this.applyTransformers(
        change,
        subscription.transformers
      );
      
      // ì „ì†¡
      client.send({
        type: 'dataChange',
        subscriptionId: subscription.id,
        change: transformed
      });
    }
  }
  
  // ì¶©ëŒ ê°ì§€ ë° í•´ê²°
  private conflictDetector = new ConflictDetector();
  
  private async handleClientUpdate(
    client: SyncClient,
    update: UpdatePayload
  ): Promise<void> {
    // ë²„ì „ í™•ì¸
    const currentVersion = await this.getEntityVersion(
      update.entityType,
      update.entityId
    );
    
    if (update.baseVersion !== currentVersion) {
      // ì¶©ëŒ ê°ì§€
      const conflict = await this.conflictDetector.analyze(
        update,
        currentVersion
      );
      
      if (conflict.resolvable) {
        // ìë™ í•´ê²°
        const resolved = await this.autoResolveConflict(conflict);
        await this.applyUpdate(resolved);
        
        client.send({
          type: 'updateAccepted',
          entityId: update.entityId,
          newVersion: resolved.version,
          resolved: true
        });
      } else {
        // í´ë¼ì´ì–¸íŠ¸ì— ì¶©ëŒ ì•Œë¦¼
        client.send({
          type: 'conflict',
          entityId: update.entityId,
          currentVersion,
          conflictData: conflict.data
        });
      }
    } else {
      // ì—…ë°ì´íŠ¸ ì ìš©
      const result = await this.applyUpdate(update);
      
      client.send({
        type: 'updateAccepted',
        entityId: update.entityId,
        newVersion: result.version
      });
    }
  }
  
  // SSE (Server-Sent Events) ì§€ì›
  async handleSSEConnection(
    req: any,
    res: any
  ): Promise<void> {
    // SSE í—¤ë” ì„¤ì •
    res.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
      'Access-Control-Allow-Origin': '*'
    });
    
    const clientId = uuidv4();
    const sseClient = new SSEClient(clientId, res);
    
    this.sseClients.set(clientId, sseClient);
    
    // ì´ˆê¸° ì—°ê²° ì´ë²¤íŠ¸
    sseClient.send({
      type: 'connected',
      clientId
    });
    
    // í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ ì²˜ë¦¬
    req.on('close', () => {
      this.sseClients.delete(clientId);
      this.subscriptionManager.removeClient(clientId);
    });
  }
}

// ë™ê¸°í™” ì—”ì§„
export class SyncEngine extends EventEmitter {
  private isRunning: boolean = false;
  private checkpoints: Map<string, string> = new Map();
  
  constructor(
    private streamsClient: DynamoDBStreamsClient
  ) {
    super();
  }
  
  async start(): Promise<void> {
    this.isRunning = true;
    
    // ëª¨ë“  í…Œì´ë¸”ì˜ ìŠ¤íŠ¸ë¦¼ êµ¬ë…
    const streams = await this.discoverStreams();
    
    for (const streamArn of streams) {
      this.processStream(streamArn);
    }
  }
  
  private async processStream(streamArn: string): Promise<void> {
    const shards = await this.getStreamShards(streamArn);
    
    for (const shard of shards) {
      this.processShard(streamArn, shard.ShardId!);
    }
  }
  
  private async processShard(
    streamArn: string,
    shardId: string
  ): Promise<void> {
    let shardIterator = await this.getShardIterator(streamArn, shardId);
    
    while (this.isRunning && shardIterator) {
      const records = await this.getRecords(shardIterator);
      
      if (records.Records) {
        for (const record of records.Records) {
          const change = this.parseRecord(record);
          this.emit('dataChange', change);
        }
        
        // ì²´í¬í¬ì¸íŠ¸ ì—…ë°ì´íŠ¸
        if (records.Records.length > 0) {
          const lastRecord = records.Records[records.Records.length - 1];
          await this.updateCheckpoint(
            shardId,
            lastRecord.dynamodb?.SequenceNumber!
          );
        }
      }
      
      shardIterator = records.NextShardIterator || null;
    }
  }
}

// êµ¬ë… ê´€ë¦¬ì
export class SubscriptionManager {
  private subscriptions: Map<string, Subscription> = new Map();
  private clientSubscriptions: Map<string, Set<string>> = new Map();
  private entityIndex: Map<string, Set<string>> = new Map();
  
  subscribe(
    clientId: string,
    options: SubscriptionOptions
  ): Subscription {
    const subscription: Subscription = {
      id: uuidv4(),
      clientId,
      ...options,
      createdAt: new Date()
    };
    
    this.subscriptions.set(subscription.id, subscription);
    
    // í´ë¼ì´ì–¸íŠ¸ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
    if (!this.clientSubscriptions.has(clientId)) {
      this.clientSubscriptions.set(clientId, new Set());
    }
    this.clientSubscriptions.get(clientId)!.add(subscription.id);
    
    // ì—”í‹°í‹° ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
    for (const entity of options.entities || []) {
      if (!this.entityIndex.has(entity)) {
        this.entityIndex.set(entity, new Set());
      }
      this.entityIndex.get(entity)!.add(subscription.id);
    }
    
    return subscription;
  }
  
  findSubscribers(change: DataChange): Subscription[] {
    const subscribers: Set<string> = new Set();
    
    // ì—”í‹°í‹° íƒ€ì…ìœ¼ë¡œ ì°¾ê¸°
    const entitySubs = this.entityIndex.get(change.entityType) || new Set();
    entitySubs.forEach(id => subscribers.add(id));
    
    // ì±„ë„ë¡œ ì°¾ê¸°
    for (const [id, sub] of this.subscriptions) {
      if (sub.channels?.includes(change.channel || 'default')) {
        subscribers.add(id);
      }
    }
    
    return Array.from(subscribers)
      .map(id => this.subscriptions.get(id)!)
      .filter(Boolean);
  }
}
```

### SubTask 2.12.3: ì˜¤í”„ë¼ì¸ ë™ê¸°í™” ì§€ì›
**ë‹´ë‹¹ì**: ëª¨ë°”ì¼ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: í´ë¼ì´ì–¸íŠ¸ì˜ ì˜¤í”„ë¼ì¸ ì‘ì—…ì„ ì§€ì›í•˜ëŠ” ë™ê¸°í™” ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/sync/offline/offline-sync.ts
export interface OfflineSyncConfig {
  conflictResolution: 'client_wins' | 'server_wins' | 'manual';
  syncBatchSize: number;
  compressionEnabled: boolean;
  encryptionEnabled: boolean;
}

export class OfflineSyncManager {
  private syncQueue: SyncQueue;
  private conflictResolver: OfflineConflictResolver;
  private deltaGenerator: DeltaGenerator;
  private encryptionService: EncryptionService;
  
  constructor(
    private config: OfflineSyncConfig,
    private dataStore: DataStore
  ) {
    this.syncQueue = new SyncQueue();
    this.conflictResolver = new OfflineConflictResolver(config.conflictResolution);
    this.deltaGenerator = new DeltaGenerator();
    this.encryptionService = new EncryptionService();
  }
  
  // ì˜¤í”„ë¼ì¸ ë³€ê²½ ì‚¬í•­ ìˆ˜ì‹ 
  async receiveSyncRequest(
    request: SyncRequest
  ): Promise<SyncResponse> {
    // ì¸ì¦ ë° ê¶Œí•œ í™•ì¸
    const auth = await this.validateSyncRequest(request);
    if (!auth.valid) {
      throw new UnauthorizedError('Invalid sync credentials');
    }
    
    // ìš”ì²­ ë³µí˜¸í™”
    const decryptedData = this.config.encryptionEnabled ?
      await this.encryptionService.decrypt(request.encryptedData) :
      request.data;
    
    // ì••ì¶• í•´ì œ
    const changes = this.config.compressionEnabled ?
      await this.decompress(decryptedData) :
      decryptedData;
    
    // ë™ê¸°í™” ì²˜ë¦¬
    const result = await this.processSyncBatch(
      changes,
      request.clientId,
      request.lastSyncTimestamp
    );
    
    // ì‘ë‹µ ì¤€ë¹„
    const response = await this.prepareSyncResponse(
      result,
      request.clientId
    );
    
    return response;
  }
  
  // ë™ê¸°í™” ë°°ì¹˜ ì²˜ë¦¬
  private async processSyncBatch(
    changes: ClientChange[],
    clientId: string,
    lastSyncTimestamp: Date
  ): Promise<SyncResult> {
    const results: ChangeResult[] = [];
    const conflicts: Conflict[] = [];
    
    // íŠ¸ëœì­ì…˜ìœ¼ë¡œ ë³€ê²½ ì‚¬í•­ ì²˜ë¦¬
    await this.dataStore.transaction(async (tx) => {
      for (const change of changes) {
        try {
          const result = await this.processChange(
            change,
            clientId,
            tx
          );
          
          if (result.conflict) {
            conflicts.push(result.conflict);
          } else {
            results.push(result);
          }
        } catch (error) {
          results.push({
            changeId: change.id,
            status: 'error',
            error: error.message
          });
        }
      }
    });
    
    // ì„œë²„ ë³€ê²½ ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°
    const serverChanges = await this.getServerChanges(
      clientId,
      lastSyncTimestamp
    );
    
    return {
      clientResults: results,
      serverChanges,
      conflicts,
      newSyncTimestamp: new Date()
    };
  }
  
  // ê°œë³„ ë³€ê²½ ì‚¬í•­ ì²˜ë¦¬
  private async processChange(
    change: ClientChange,
    clientId: string,
    tx: Transaction
  ): Promise<ChangeResult> {
    // í˜„ì¬ ì„œë²„ ìƒíƒœ í™•ì¸
    const serverEntity = await tx.get(
      change.entityType,
      change.entityId
    );
    
    // ì¶©ëŒ ê°ì§€
    if (serverEntity && 
        serverEntity.version !== change.baseVersion) {
      
      // ì¶©ëŒ í•´ê²° ì‹œë„
      const resolution = await this.conflictResolver.resolve({
        clientChange: change,
        serverState: serverEntity,
        strategy: this.config.conflictResolution
      });
      
      if (resolution.resolved) {
        // í•´ê²°ëœ ë³€ê²½ ì‚¬í•­ ì ìš©
        await this.applyChange(resolution.mergedData, tx);
        
        return {
          changeId: change.id,
          status: 'resolved',
          newVersion: resolution.newVersion
        };
      } else {
        // ì¶©ëŒ ë°˜í™˜
        return {
          changeId: change.id,
          status: 'conflict',
          conflict: {
            id: uuidv4(),
            changeId: change.id,
            clientData: change.data,
            serverData: serverEntity,
            type: resolution.conflictType
          }
        };
      }
    }
    
    // ì¶©ëŒ ì—†ìŒ - ë³€ê²½ ì‚¬í•­ ì ìš©
    const newVersion = await this.applyChange(change.data, tx);
    
    return {
      changeId: change.id,
      status: 'success',
      newVersion
    };
  }
  
  // ë¸íƒ€ ë™ê¸°í™”
  async generateDelta(
    entityType: string,
    fromVersion: number,
    toVersion: number
  ): Promise<Delta> {
    const changes = await this.dataStore.getChangesBetween(
      entityType,
      fromVersion,
      toVersion
    );
    
    return this.deltaGenerator.generate(changes);
  }
  
  // ì ì§„ì  ë™ê¸°í™”
  async performIncrementalSync(
    clientId: string,
    syncState: ClientSyncState
  ): Promise<IncrementalSyncResult> {
    const pendingChanges: any[] = [];
    
    // ê° ì—”í‹°í‹° íƒ€ì…ë³„ë¡œ ë³€ê²½ ì‚¬í•­ ìˆ˜ì§‘
    for (const [entityType, lastSync] of syncState.entities) {
      const changes = await this.dataStore.getChangesSince(
        entityType,
        lastSync.version,
        lastSync.timestamp
      );
      
      if (changes.length > 0) {
        pendingChanges.push({
          entityType,
          changes: changes.slice(0, this.config.syncBatchSize),
          hasMore: changes.length > this.config.syncBatchSize
        });
      }
    }
    
    // ì••ì¶• ë° ì•”í˜¸í™”
    let payload = pendingChanges;
    
    if (this.config.compressionEnabled) {
      payload = await this.compress(payload);
    }
    
    if (this.config.encryptionEnabled) {
      payload = await this.encryptionService.encrypt(
        payload,
        clientId
      );
    }
    
    return {
      payload,
      syncToken: this.generateSyncToken(clientId),
      hasMoreChanges: pendingChanges.some(p => p.hasMore)
    };
  }
}

// ì˜¤í”„ë¼ì¸ ì¶©ëŒ í•´ê²°ì
export class OfflineConflictResolver {
  constructor(
    private defaultStrategy: ConflictResolutionStrategy
  ) {}
  
  async resolve(
    conflict: OfflineConflict
  ): Promise<ConflictResolution> {
    // ìë™ í•´ê²° ê°€ëŠ¥í•œ ê²½ìš° í™•ì¸
    if (this.canAutoResolve(conflict)) {
      return this.autoResolve(conflict);
    }
    
    // ì „ëµì— ë”°ë¥¸ í•´ê²°
    switch (this.defaultStrategy) {
      case 'client_wins':
        return this.clientWins(conflict);
        
      case 'server_wins':
        return this.serverWins(conflict);
        
      case 'manual':
        return this.requireManualResolution(conflict);
        
      default:
        throw new Error('Unknown conflict resolution strategy');
    }
  }
  
  private canAutoResolve(conflict: OfflineConflict): boolean {
    // í•„ë“œ ë ˆë²¨ ì¶©ëŒ ë¶„ì„
    const clientFields = Object.keys(conflict.clientChange.data);
    const serverFields = Object.keys(conflict.serverState);
    
    // ì„œë¡œ ë‹¤ë¥¸ í•„ë“œë¥¼ ìˆ˜ì •í•œ ê²½ìš° ìë™ ë³‘í•© ê°€ëŠ¥
    const conflictingFields = clientFields.filter(
      field => serverFields.includes(field) &&
               conflict.clientChange.data[field] !== 
               conflict.serverState[field]
    );
    
    return conflictingFields.length === 0;
  }
  
  private autoResolve(
    conflict: OfflineConflict
  ): ConflictResolution {
    // ë¹„ì¶©ëŒ í•„ë“œ ë³‘í•©
    const merged = {
      ...conflict.serverState,
      ...conflict.clientChange.data
    };
    
    return {
      resolved: true,
      mergedData: merged,
      newVersion: conflict.serverState.version + 1,
      strategy: 'auto_merge'
    };
  }
}

// ë™ê¸°í™” í
export class SyncQueue {
  private queue: PriorityQueue<SyncJob>;
  private processing: Map<string, SyncJob> = new Map();
  
  constructor() {
    this.queue = new PriorityQueue((a, b) => 
      a.priority - b.priority
    );
  }
  
  async enqueue(job: SyncJob): Promise<void> {
    // ì¤‘ë³µ í™•ì¸
    if (this.processing.has(job.id)) {
      throw new Error('Job already processing');
    }
    
    // ìš°ì„ ìˆœìœ„ ê³„ì‚°
    job.priority = this.calculatePriority(job);
    
    this.queue.enqueue(job);
  }
  
  private calculatePriority(job: SyncJob): number {
    let priority = 0;
    
    // ì‘ì—… íƒ€ì…ë³„ ê°€ì¤‘ì¹˜
    if (job.type === 'critical') priority += 100;
    if (job.type === 'user_initiated') priority += 50;
    
    // ëŒ€ê¸° ì‹œê°„ ê³ ë ¤
    const waitTime = Date.now() - job.createdAt.getTime();
    priority += Math.min(waitTime / 1000, 50);
    
    return priority;
  }
}
```

### SubTask 2.12.4: ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
**ë‹´ë‹¹ì**: QA ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ë¶„ì‚° í™˜ê²½ì—ì„œ ë°ì´í„° ì¼ê´€ì„±ì„ ê²€ì¦í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/sync/consistency/consistency-validator.ts
export class ConsistencyValidator {
  private validators: Map<string, EntityValidator> = new Map();
  private reconciler: DataReconciler;
  private reporter: ConsistencyReporter;
  
  constructor(
    private config: ConsistencyConfig,
    private dataStores: Map<string, DataStore>
  ) {
    this.reconciler = new DataReconciler();
    this.reporter = new ConsistencyReporter();
    
    this.registerValidators();
  }
  
  // ì¼ê´€ì„± ê²€ì¦ ì‹¤í–‰
  async validateConsistency(
    options: ValidationOptions
  ): Promise<ConsistencyReport> {
    const startTime = Date.now();
    const results: ValidationResult[] = [];
    
    // ì—”í‹°í‹°ë³„ ê²€ì¦
    for (const [entityType, validator] of this.validators) {
      if (options.entityTypes && 
          !options.entityTypes.includes(entityType)) {
        continue;
      }
      
      const result = await this.validateEntityType(
        entityType,
        validator,
        options
      );
      
      results.push(result);
    }
    
    // ê´€ê³„ ì¼ê´€ì„± ê²€ì¦
    const relationshipResults = await this.validateRelationships(
      results,
      options
    );
    
    // ë¦¬í¬íŠ¸ ìƒì„±
    const report = this.reporter.generateReport({
      results,
      relationshipResults,
      duration: Date.now() - startTime,
      timestamp: new Date()
    });
    
    // ë¶ˆì¼ì¹˜ ìë™ ìˆ˜ì • (ì„¤ì •ëœ ê²½ìš°)
    if (options.autoFix && report.inconsistencies.length > 0) {
      await this.autoFixInconsistencies(report.inconsistencies);
    }
    
    return report;
  }
  
  // ì—”í‹°í‹° íƒ€ì…ë³„ ê²€ì¦
  private async validateEntityType(
    entityType: string,
    validator: EntityValidator,
    options: ValidationOptions
  ): Promise<ValidationResult> {
    const inconsistencies: Inconsistency[] = [];
    
    // ëª¨ë“  ë¦¬ì „ì˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    const regionData = await this.fetchDataFromAllRegions(
      entityType,
      options
    );
    
    // ê¸°ì¤€ ë¦¬ì „ ì„¤ì •
    const primaryData = regionData.get(this.config.primaryRegion)!;
    
    // ê° ì—”í‹°í‹° ê²€ì¦
    for (const [entityId, primaryEntity] of primaryData) {
      const entityInconsistencies = await this.validateEntity(
        entityType,
        entityId,
        primaryEntity,
        regionData,
        validator
      );
      
      inconsistencies.push(...entityInconsistencies);
    }
    
    return {
      entityType,
      totalEntities: primaryData.size,
      inconsistencyCount: inconsistencies.length,
      inconsistencies
    };
  }
  
  // ê°œë³„ ì—”í‹°í‹° ê²€ì¦
  private async validateEntity(
    entityType: string,
    entityId: string,
    primaryEntity: any,
    regionData: Map<string, Map<string, any>>,
    validator: EntityValidator
  ): Promise<Inconsistency[]> {
    const inconsistencies: Inconsistency[] = [];
    
    for (const [region, data] of regionData) {
      if (region === this.config.primaryRegion) continue;
      
      const regionEntity = data.get(entityId);
      
      // ì¡´ì¬ ì—¬ë¶€ í™•ì¸
      if (!regionEntity) {
        inconsistencies.push({
          type: 'missing',
          entityType,
          entityId,
          primaryRegion: this.config.primaryRegion,
          affectedRegion: region,
          severity: 'high'
        });
        continue;
      }
      
      // í•„ë“œë³„ ê²€ì¦
      const fieldInconsistencies = await validator.validateFields(
        primaryEntity,
        regionEntity,
        region
      );
      
      inconsistencies.push(...fieldInconsistencies);
      
      // ë²„ì „ í™•ì¸
      if (primaryEntity.version !== regionEntity.version) {
        const versionDiff = Math.abs(
          primaryEntity.version - regionEntity.version
        );
        
        inconsistencies.push({
          type: 'version_mismatch',
          entityType,
          entityId,
          primaryRegion: this.config.primaryRegion,
          affectedRegion: region,
          severity: versionDiff > 5 ? 'high' : 'medium',
          details: {
            primaryVersion: primaryEntity.version,
            regionVersion: regionEntity.version
          }
        });
      }
    }
    
    return inconsistencies;
  }
  
  // ê´€ê³„ ì¼ê´€ì„± ê²€ì¦
  private async validateRelationships(
    entityResults: ValidationResult[],
    options: ValidationOptions
  ): Promise<RelationshipValidationResult[]> {
    const results: RelationshipValidationResult[] = [];
    
    // ì™¸ë˜ í‚¤ ê²€ì¦
    const fkResults = await this.validateForeignKeys(entityResults);
    results.push(...fkResults);
    
    // ì–‘ë°©í–¥ ê´€ê³„ ê²€ì¦
    const bidirectionalResults = await this.validateBidirectionalRelations();
    results.push(...bidirectionalResults);
    
    // ì°¸ì¡° ë¬´ê²°ì„± ê²€ì¦
    const integrityResults = await this.validateReferentialIntegrity();
    results.push(...integrityResults);
    
    return results;
  }
  
  // ìë™ ìˆ˜ì •
  private async autoFixInconsistencies(
    inconsistencies: Inconsistency[]
  ): Promise<FixResult[]> {
    const results: FixResult[] = [];
    
    // ì‹¬ê°ë„ë³„ ê·¸ë£¹í™”
    const grouped = this.groupBySeverity(inconsistencies);
    
    // ë‚®ì€ ì‹¬ê°ë„ë¶€í„° ìˆ˜ì •
    for (const severity of ['low', 'medium', 'high']) {
      const group = grouped[severity] || [];
      
      for (const inconsistency of group) {
        try {
          const fixResult = await this.reconciler.reconcile(
            inconsistency
          );
          results.push(fixResult);
        } catch (error) {
          results.push({
            inconsistency,
            status: 'failed',
            error: error.message
          });
        }
      }
    }
    
    return results;
  }
}

// ë°ì´í„° ì¡°ì •ì
export class DataReconciler {
  async reconcile(
    inconsistency: Inconsistency
  ): Promise<FixResult> {
    switch (inconsistency.type) {
      case 'missing':
        return await this.handleMissingEntity(inconsistency);
        
      case 'field_mismatch':
        return await this.handleFieldMismatch(inconsistency);
        
      case 'version_mismatch':
        return await this.handleVersionMismatch(inconsistency);
        
      default:
        throw new Error(`Unknown inconsistency type: ${inconsistency.type}`);
    }
  }
  
  private async handleMissingEntity(
    inconsistency: Inconsistency
  ): Promise<FixResult> {
    // Primary ë¦¬ì „ì—ì„œ ë°ì´í„° ë³µì‚¬
    const primaryData = await this.fetchFromPrimary(
      inconsistency.entityType,
      inconsistency.entityId
    );
    
    // ëˆ„ë½ëœ ë¦¬ì „ì— ë°ì´í„° ì‚½ì…
    await this.insertToRegion(
      inconsistency.affectedRegion,
      inconsistency.entityType,
      primaryData
    );
    
    return {
      inconsistency,
      status: 'fixed',
      action: 'replicated_to_region'
    };
  }
}

// ì¼ê´€ì„± ë¦¬í¬í„°
export class ConsistencyReporter {
  generateReport(data: ReportData): ConsistencyReport {
    const summary = this.generateSummary(data);
    const details = this.generateDetails(data);
    const recommendations = this.generateRecommendations(data);
    
    return {
      summary,
      details,
      recommendations,
      metadata: {
        generatedAt: new Date(),
        duration: data.duration,
        regionsChecked: this.getRegionsChecked(data)
      }
    };
  }
  
  private generateSummary(data: ReportData): ReportSummary {
    const totalInconsistencies = data.results.reduce(
      (sum, r) => sum + r.inconsistencyCount,
      0
    );
    
    const severityCounts = this.countBySeverity(
      data.results.flatMap(r => r.inconsistencies)
    );
    
    return {
      totalEntitiesChecked: data.results.reduce(
        (sum, r) => sum + r.totalEntities,
        0
      ),
      totalInconsistencies,
      severityBreakdown: severityCounts,
      affectedEntityTypes: data.results
        .filter(r => r.inconsistencyCount > 0)
        .map(r => r.entityType),
      overallHealth: this.calculateHealthScore(
        totalInconsistencies,
        data.results
      )
    };
  }
}
```

## Task 2.13: ë°±ì—… ìë™í™”

### SubTask 2.13.1: ìë™ ë°±ì—… ìŠ¤ì¼€ì¤„ëŸ¬
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: DynamoDB í…Œì´ë¸”ì˜ ìë™ ë°±ì—… ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/backup/scheduler/backup-scheduler.ts
import { DynamoDBClient, CreateBackupCommand } from '@aws-sdk/client-dynamodb';
import { EventBridgeClient, PutRuleCommand } from '@aws-sdk/client-eventbridge';
import { S3Client } from '@aws-sdk/client-s3';
import cron from 'node-cron';

export interface BackupSchedule {
  id: string;
  name: string;
  tables: string[];
  schedule: CronSchedule;
  retention: RetentionPolicy;
  destination: BackupDestination;
  enabled: boolean;
  notifications?: NotificationConfig;
}

export interface CronSchedule {
  expression: string;
  timezone: string;
  type: 'continuous' | 'point_in_time';
}

export class BackupScheduler {
  private schedules: Map<string, cron.ScheduledTask> = new Map();
  private backupExecutor: BackupExecutor;
  private retentionManager: RetentionManager;
  private notificationService: NotificationService;
  
  constructor(
    private dynamoClient: DynamoDBClient,
    private s3Client: S3Client,
    private config: BackupConfig
  ) {
    this.backupExecutor = new BackupExecutor(dynamoClient, s3Client);
    this.retentionManager = new RetentionManager();
    this.notificationService = new NotificationService();
    
    this.loadSchedules();
  }
  
  // ë°±ì—… ìŠ¤ì¼€ì¤„ ìƒì„±
  async createSchedule(schedule: BackupSchedule): Promise<void> {
    // í¬ë¡  í‘œí˜„ì‹ ê²€ì¦
    if (!cron.validate(schedule.schedule.expression)) {
      throw new Error('Invalid cron expression');
    }
    
    // ìŠ¤ì¼€ì¤„ ì‘ì—… ìƒì„±
    const task = cron.schedule(
      schedule.schedule.expression,
      async () => {
        await this.executeBackup(schedule);
      },
      {
        scheduled: schedule.enabled,
        timezone: schedule.schedule.timezone
      }
    );
    
    this.schedules.set(schedule.id, task);
    
    // EventBridge ê·œì¹™ ìƒì„± (ê³ ê°€ìš©ì„±)
    await this.createEventBridgeRule(schedule);
    
    // ìŠ¤ì¼€ì¤„ ì €ì¥
    await this.saveSchedule(schedule);
  }
  
  // ë°±ì—… ì‹¤í–‰
  private async executeBackup(
    schedule: BackupSchedule
  ): Promise<BackupResult> {
    const backupId = this.generateBackupId();
    const startTime = Date.now();
    
    try {
      // ë°±ì—… ì‹œì‘ ì•Œë¦¼
      await this.notificationService.send({
        type: 'backup_started',
        schedule: schedule.name,
        tables: schedule.tables,
        timestamp: new Date()
      });
      
      // ê° í…Œì´ë¸” ë°±ì—…
      const results = await Promise.all(
        schedule.tables.map(table => 
          this.backupTable(table, backupId, schedule)
        )
      );
      
      // ë°±ì—… ë©”íƒ€ë°ì´í„° ì €ì¥
      const metadata = await this.saveBackupMetadata({
        backupId,
        scheduleId: schedule.id,
        tables: results,
        duration: Date.now() - startTime,
        status: 'completed',
        timestamp: new Date()
      });
      
      // ì´ì „ ë°±ì—… ì •ë¦¬
      await this.retentionManager.applyRetentionPolicy(
        schedule.retention,
        schedule.tables
      );
      
      // ì„±ê³µ ì•Œë¦¼
      await this.notificationService.send({
        type: 'backup_completed',
        schedule: schedule.name,
        backupId,
        duration: metadata.duration,
        size: this.calculateTotalSize(results)
      });
      
      return {
        success: true,
        backupId,
        metadata
      };
    } catch (error) {
      // ì‹¤íŒ¨ ì•Œë¦¼
      await this.notificationService.send({
        type: 'backup_failed',
        schedule: schedule.name,
        error: error.message,
        timestamp: new Date()
      });
      
      throw error;
    }
  }
  
  // í…Œì´ë¸” ë°±ì—…
  private async backupTable(
    tableName: string,
    backupId: string,
    schedule: BackupSchedule
  ): Promise<TableBackupResult> {
    if (schedule.schedule.type === 'continuous') {
      // ì—°ì† ë°±ì—… (Point-in-time Recovery)
      return await this.enableContinuousBackup(tableName);
    } else {
      // ì˜¨ë””ë§¨ë“œ ë°±ì—…
      const backupName = `${tableName}-${backupId}`;
      
      const response = await this.dynamoClient.send(
        new CreateBackupCommand({
          TableName: tableName,
          BackupName: backupName
        })
      );
      
      // S3ë¡œ ì¶”ê°€ ë°±ì—… (ì„ íƒì )
      if (schedule.destination.type === 's3') {
        await this.exportToS3(
          tableName,
          backupId,
          schedule.destination
        );
      }
      
      return {
        tableName,
        backupArn: response.BackupDetails?.BackupArn!,
        backupSize: response.BackupDetails?.BackupSizeBytes,
        status: response.BackupDetails?.BackupStatus!,
        createdAt: response.BackupDetails?.BackupCreationDateTime!
      };
    }
  }
  
  // S3 ë‚´ë³´ë‚´ê¸°
  private async exportToS3(
    tableName: string,
    backupId: string,
    destination: BackupDestination
  ): Promise<void> {
    // DynamoDB Export to S3
    const exportParams = {
      TableArn: await this.getTableArn(tableName),
      S3Bucket: destination.s3Bucket!,
      S3Prefix: `backups/${backupId}/${tableName}/`,
      S3SseAlgorithm: 'AES256',
      ExportFormat: 'DYNAMODB_JSON',
      ExportTime: new Date()
    };
    
    await this.dynamoClient.exportTableToPointInTime(exportParams);
  }
}

// ë³´ì¡´ ì •ì±… ê´€ë¦¬ì
export class RetentionManager {
  async applyRetentionPolicy(
    policy: RetentionPolicy,
    tables: string[]
  ): Promise<void> {
    for (const table of tables) {
      await this.cleanupOldBackups(table, policy);
    }
  }
  
  private async cleanupOldBackups(
    tableName: string,
    policy: RetentionPolicy
  ): Promise<void> {
    const backups = await this.listBackups(tableName);
    const now = Date.now();
    
    // ì •ì±…ë³„ ì •ë¦¬
    const backupsToDelete = backups.filter(backup => {
      const age = now - backup.createdAt.getTime();
      
      // ì¼ì¼ ë°±ì—…
      if (policy.daily && age > policy.daily * 24 * 60 * 60 * 1000) {
        return !this.isRetainedBackup(backup, policy);
      }
      
      // ì£¼ê°„ ë°±ì—…
      if (policy.weekly && age > policy.weekly * 7 * 24 * 60 * 60 * 1000) {
        return !this.isWeeklyBackup(backup);
      }
      
      // ì›”ê°„ ë°±ì—…
      if (policy.monthly && age > policy.monthly * 30 * 24 * 60 * 60 * 1000) {
        return !this.isMonthlyBackup(backup);
      }
      
      return false;
    });
    
    // ë°±ì—… ì‚­ì œ
    for (const backup of backupsToDelete) {
      await this.deleteBackup(backup);
    }
  }
  
  private isRetainedBackup(
    backup: Backup,
    policy: RetentionPolicy
  ): boolean {
    // ìµœì†Œ ë³´ì¡´ ê°œìˆ˜ í™•ì¸
    if (policy.minimumBackups) {
      return true; // ë³„ë„ ë¡œì§ìœ¼ë¡œ ì²˜ë¦¬
    }
    
    // íŠ¹ë³„ ë³´ì¡´ íƒœê·¸ í™•ì¸
    return backup.tags?.includes('retain');
  }
}

// ë°±ì—… ì‹¤í–‰ì
export class BackupExecutor {
  constructor(
    private dynamoClient: DynamoDBClient,
    private s3Client: S3Client
  ) {}
  
  async executeIncremental(
    tableName: string,
    lastBackupTime: Date
  ): Promise<IncrementalBackupResult> {
    // ë³€ê²½ ì‚¬í•­ë§Œ ë°±ì—…
    const changes = await this.getChangesSince(tableName, lastBackupTime);
    
    if (changes.length === 0) {
      return {
        tableName,
        status: 'no_changes',
        itemCount: 0
      };
    }
    
    // S3ì— ì¦ë¶„ ë°±ì—… ì €ì¥
    const key = `incremental/${tableName}/${Date.now()}.json`;
    await this.s3Client.putObject({
      Bucket: this.config.backupBucket,
      Key: key,
      Body: JSON.stringify(changes),
      ServerSideEncryption: 'AES256'
    });
    
    return {
      tableName,
      status: 'completed',
      itemCount: changes.length,
      s3Location: `s3://${this.config.backupBucket}/${key}`
    };
  }
}
```

### SubTask 2.13.2: ë°±ì—… ê²€ì¦ ë° í…ŒìŠ¤íŠ¸
**ë‹´ë‹¹ì**: QA ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ë°±ì—… ë¬´ê²°ì„± ê²€ì¦ ë° ë³µì› í…ŒìŠ¤íŠ¸ ìë™í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/backup/validation/backup-validator.ts
export class BackupValidator {
  private integrityChecker: IntegrityChecker;
  private restoreTester: RestoreTester;
  private comparisonEngine: ComparisonEngine;
  
  constructor(
    private dynamoClient: DynamoDBClient,
    private config: ValidationConfig
  ) {
    this.integrityChecker = new IntegrityChecker();
    this.restoreTester = new RestoreTester(dynamoClient);
    this.comparisonEngine = new ComparisonEngine();
  }
  
  // ë°±ì—… ê²€ì¦ ì‹¤í–‰
  async validateBackup(
    backupId: string,
    options?: ValidationOptions
  ): Promise<ValidationReport> {
    const startTime = Date.now();
    const results: ValidationResult[] = [];
        
    // 1. ë°±ì—… ë©”íƒ€ë°ì´í„° ê²€ì¦
    const metadataResult = await this.validateMetadata(backupId);
    results.push(metadataResult);
    
    // 2. ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
    const integrityResult = await this.validateIntegrity(backupId);
    results.push(integrityResult);
    
    // 3. ë³µì› ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸
    if (options?.testRestore) {
      const restoreResult = await this.testRestore(backupId);
      results.push(restoreResult);
    }
    
    // 4. ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
    if (options?.compareWithSource) {
      const comparisonResult = await this.compareWithSource(backupId);
      results.push(comparisonResult);
    }
    
    return {
      backupId,
      validationTime: Date.now() - startTime,
      results,
      overallStatus: this.determineOverallStatus(results),
      recommendations: this.generateRecommendations(results)
    };
  }
  
  // ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
  private async validateIntegrity(
    backupId: string
  ): Promise<ValidationResult> {
    const backup = await this.getBackupDetails(backupId);
    const errors: IntegrityError[] = [];
    
    // ì²´í¬ì„¬ ê²€ì¦
    if (backup.checksum) {
      const calculatedChecksum = await this.integrityChecker.calculateChecksum(
        backup.data
      );
      
      if (calculatedChecksum !== backup.checksum) {
        errors.push({
          type: 'checksum_mismatch',
          expected: backup.checksum,
          actual: calculatedChecksum,
          severity: 'critical'
        });
      }
    }
    
    // ë ˆì½”ë“œ ìˆ˜ ê²€ì¦
    const recordCount = await this.integrityChecker.countRecords(backup);
    if (recordCount !== backup.metadata.recordCount) {
      errors.push({
        type: 'record_count_mismatch',
        expected: backup.metadata.recordCount,
        actual: recordCount,
        severity: 'high'
      });
    }
    
    // ìŠ¤í‚¤ë§ˆ ê²€ì¦
    const schemaValidation = await this.integrityChecker.validateSchema(
      backup
    );
    if (!schemaValidation.valid) {
      errors.push(...schemaValidation.errors);
    }
    
    return {
      type: 'integrity',
      status: errors.length === 0 ? 'passed' : 'failed',
      errors,
      details: {
        checksumVerified: !errors.some(e => e.type === 'checksum_mismatch'),
        recordCountVerified: !errors.some(e => e.type === 'record_count_mismatch'),
        schemaValid: schemaValidation.valid
      }
    };
  }
  
  // ë³µì› í…ŒìŠ¤íŠ¸
  private async testRestore(
    backupId: string
  ): Promise<ValidationResult> {
    const testTableName = `test_restore_${Date.now()}`;
    
    try {
      // 1. í…ŒìŠ¤íŠ¸ í…Œì´ë¸”ë¡œ ë³µì›
      const restoreResult = await this.restoreTester.restoreToTable(
        backupId,
        testTableName
      );
      
      // 2. ë³µì›ëœ ë°ì´í„° ê²€ì¦
      const validation = await this.validateRestoredData(
        testTableName,
        backupId
      );
      
      // 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
      const metrics = {
        restoreTime: restoreResult.duration,
        dataSize: restoreResult.dataSize,
        throughput: restoreResult.dataSize / restoreResult.duration
      };
      
      // 4. í…ŒìŠ¤íŠ¸ í…Œì´ë¸” ì •ë¦¬
      await this.cleanupTestTable(testTableName);
      
      return {
        type: 'restore_test',
        status: validation.success ? 'passed' : 'failed',
        errors: validation.errors,
        details: {
          restoreTime: metrics.restoreTime,
          throughput: metrics.throughput,
          validationResults: validation
        }
      };
    } catch (error) {
      return {
        type: 'restore_test',
        status: 'failed',
        errors: [{
          type: 'restore_failed',
          message: error.message,
          severity: 'critical'
        }]
      };
    } finally {
      // ì •ë¦¬
      await this.cleanupTestTable(testTableName).catch(() => {});
    }
  }
  
  // ì›ë³¸ ë°ì´í„°ì™€ ë¹„êµ
  private async compareWithSource(
    backupId: string
  ): Promise<ValidationResult> {
    const backup = await this.getBackupDetails(backupId);
    const sourceTable = backup.metadata.sourceTable;
    
    // ìƒ˜í”Œë§ ë¹„êµ (ì „ì²´ ë¹„êµëŠ” ë¹„ìš©ì´ ë§ì´ ë“¦)
    const sampleSize = Math.min(
      1000,
      backup.metadata.recordCount * 0.1
    );
    
    const comparisonResult = await this.comparisonEngine.compare(
      sourceTable,
      backup,
      {
        sampleSize,
        compareFields: ['id', 'version', 'updatedAt'],
        ignoreFields: ['backupTimestamp']
      }
    );
    
    return {
      type: 'data_comparison',
      status: comparisonResult.identical ? 'passed' : 'failed',
      errors: comparisonResult.differences.map(diff => ({
        type: 'data_mismatch',
        field: diff.field,
        sourceValue: diff.sourceValue,
        backupValue: diff.backupValue,
        severity: 'medium'
      })),
      details: {
        samplesCompared: sampleSize,
        differencesFound: comparisonResult.differences.length,
        matchRate: comparisonResult.matchRate
      }
    };
  }
}

// ë³µì› í…ŒìŠ¤í„°
export class RestoreTester {
  constructor(
    private dynamoClient: DynamoDBClient
  ) {}
  
  async restoreToTable(
    backupId: string,
    targetTable: string
  ): Promise<RestoreResult> {
    const startTime = Date.now();
    
    // ë°±ì—…ì—ì„œ í…Œì´ë¸” ë³µì›
    const response = await this.dynamoClient.restoreTableFromBackup({
      BackupArn: backupId,
      TargetTableName: targetTable
    });
    
    // ë³µì› ì™„ë£Œ ëŒ€ê¸°
    await this.waitForTableActive(targetTable);
    
    const duration = Date.now() - startTime;
    const tableInfo = await this.getTableInfo(targetTable);
    
    return {
      success: true,
      duration,
      dataSize: tableInfo.TableSizeBytes,
      itemCount: tableInfo.ItemCount
    };
  }
  
  async performRandomSpotChecks(
    sourceTable: string,
    restoredTable: string,
    sampleCount: number
  ): Promise<SpotCheckResult> {
    const mismatches: any[] = [];
    
    // ëœë¤ í‚¤ ì„ íƒ
    const randomKeys = await this.selectRandomKeys(sourceTable, sampleCount);
    
    for (const key of randomKeys) {
      const sourceItem = await this.getItem(sourceTable, key);
      const restoredItem = await this.getItem(restoredTable, key);
      
      if (!this.deepEqual(sourceItem, restoredItem)) {
        mismatches.push({
          key,
          source: sourceItem,
          restored: restoredItem
        });
      }
    }
    
    return {
      totalChecked: sampleCount,
      mismatches: mismatches.length,
      details: mismatches
    };
  }
}

// ë°±ì—… ì„±ëŠ¥ ë¶„ì„ê¸°
export class BackupPerformanceAnalyzer {
  async analyzeBackupPerformance(
    backupHistory: BackupRecord[]
  ): Promise<PerformanceAnalysis> {
    return {
      averageBackupTime: this.calculateAverage(
        backupHistory.map(b => b.duration)
      ),
      averageThroughput: this.calculateAverageThroughput(backupHistory),
      peakTimes: this.identifyPeakTimes(backupHistory),
      recommendations: this.generatePerformanceRecommendations(backupHistory)
    };
  }
  
  private calculateAverageThroughput(
    history: BackupRecord[]
  ): number {
    const throughputs = history.map(b => b.dataSize / b.duration);
    return this.calculateAverage(throughputs);
  }
  
  private generatePerformanceRecommendations(
    history: BackupRecord[]
  ): string[] {
    const recommendations: string[] = [];
    
    // ë°±ì—… ì‹œê°„ ë¶„ì„
    const avgTime = this.calculateAverage(history.map(b => b.duration));
    if (avgTime > 3600000) { // 1ì‹œê°„ ì´ìƒ
      recommendations.push(
        'Consider using parallel backup streams for large tables'
      );
    }
    
    // ì‹¤íŒ¨ìœ¨ ë¶„ì„
    const failureRate = history.filter(b => b.status === 'failed').length / 
                       history.length;
    if (failureRate > 0.05) { // 5% ì´ìƒ
      recommendations.push(
        'High failure rate detected. Review backup configuration and error logs'
      );
    }
    
    return recommendations;
  }
}
```

### SubTask 2.13.3: ì¦ë¶„ ë°±ì—… ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ë³€ê²½ëœ ë°ì´í„°ë§Œ ë°±ì—…í•˜ëŠ” ì¦ë¶„ ë°±ì—… ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/backup/incremental/incremental-backup.ts
export class IncrementalBackupManager {
  private changeTracker: ChangeTracker;
  private deltaCalculator: DeltaCalculator;
  private backupStorage: BackupStorage;
  
  constructor(
    private dynamoClient: DynamoDBClient,
    private s3Client: S3Client,
    private config: IncrementalBackupConfig
  ) {
    this.changeTracker = new ChangeTracker(dynamoClient);
    this.deltaCalculator = new DeltaCalculator();
    this.backupStorage = new BackupStorage(s3Client);
  }
  
  // ì¦ë¶„ ë°±ì—… ì‹¤í–‰
  async performIncrementalBackup(
    tableName: string,
    lastBackupId?: string
  ): Promise<IncrementalBackupResult> {
    // ë§ˆì§€ë§‰ ë°±ì—… ì‹œì  í™•ì¸
    const lastBackup = lastBackupId ? 
      await this.getBackupInfo(lastBackupId) :
      await this.getLastFullBackup(tableName);
    
    if (!lastBackup) {
      // ì „ì²´ ë°±ì—… ìˆ˜í–‰
      return await this.performFullBackup(tableName);
    }
    
    // ë³€ê²½ ì‚¬í•­ ì¶”ì 
    const changes = await this.changeTracker.getChangesSince(
      tableName,
      lastBackup.timestamp
    );
    
    if (changes.totalChanges === 0) {
      return {
        type: 'incremental',
        status: 'no_changes',
        backupId: lastBackup.backupId,
        changesBackedUp: 0
      };
    }
    
    // ë¸íƒ€ ê³„ì‚°
    const delta = await this.deltaCalculator.calculate(
      changes,
      lastBackup
    );
    
    // ì¦ë¶„ ë°±ì—… ì €ì¥
    const backupId = await this.saveIncrementalBackup(
      tableName,
      delta,
      lastBackup.backupId
    );
    
    return {
      type: 'incremental',
      status: 'completed',
      backupId,
      parentBackupId: lastBackup.backupId,
      changesBackedUp: changes.totalChanges,
      deltaSize: delta.size,
      compression: delta.compressionRatio
    };
  }
  
  // ë°±ì—… ì²´ì¸ ê´€ë¦¬
  async getBackupChain(
    backupId: string
  ): Promise<BackupChain> {
    const chain: BackupNode[] = [];
    let currentId = backupId;
    
    while (currentId) {
      const backup = await this.getBackupInfo(currentId);
      chain.unshift({
        backupId: backup.backupId,
        type: backup.type,
        timestamp: backup.timestamp,
        size: backup.size,
        parentId: backup.parentBackupId
      });
      
      currentId = backup.parentBackupId;
    }
    
    return {
      fullBackupId: chain[0].backupId,
      incrementalBackups: chain.slice(1),
      totalSize: chain.reduce((sum, node) => sum + node.size, 0),
      chainLength: chain.length
    };
  }
  
  // ì¦ë¶„ ë°±ì—… ë³‘í•©
  async mergeIncrementalBackups(
    chainId: string,
    targetCount: number = 1
  ): Promise<MergeResult> {
    const chain = await this.getBackupChain(chainId);
    
    if (chain.chainLength <= targetCount) {
      return {
        status: 'no_merge_needed',
        originalCount: chain.chainLength,
        mergedCount: chain.chainLength
      };
    }
    
    // ë³‘í•© ì „ëµ ê²°ì •
    const mergeStrategy = this.determineMergeStrategy(chain);
    
    // ë³‘í•© ì‹¤í–‰
    const mergedBackups = await this.executeMerge(
      chain,
      mergeStrategy,
      targetCount
    );
    
    // ì´ì „ ë°±ì—… ì •ë¦¬
    await this.cleanupOldBackups(
      chain.incrementalBackups.map(b => b.backupId)
    );
    
    return {
      status: 'completed',
      originalCount: chain.chainLength,
      mergedCount: mergedBackups.length,
      spaceSaved: chain.totalSize - mergedBackups.reduce(
        (sum, b) => sum + b.size, 0
      )
    };
  }
}

// ë³€ê²½ ì¶”ì ê¸°
export class ChangeTracker {
  constructor(
    private dynamoClient: DynamoDBClient
  ) {}
  
  async getChangesSince(
    tableName: string,
    timestamp: Date
  ): Promise<Changes> {
    const changes: Changes = {
      inserted: [],
      updated: [],
      deleted: [],
      totalChanges: 0,
      timestamp: new Date()
    };
    
    // DynamoDB Streamsì—ì„œ ë³€ê²½ ì‚¬í•­ ì½ê¸°
    const streamRecords = await this.readStreamRecords(
      tableName,
      timestamp
    );
    
    for (const record of streamRecords) {
      switch (record.eventName) {
        case 'INSERT':
          changes.inserted.push({
            key: record.dynamodb.Keys,
            item: record.dynamodb.NewImage
          });
          break;
          
        case 'MODIFY':
          changes.updated.push({
            key: record.dynamodb.Keys,
            oldItem: record.dynamodb.OldImage,
            newItem: record.dynamodb.NewImage,
            changedFields: this.identifyChangedFields(
              record.dynamodb.OldImage,
              record.dynamodb.NewImage
            )
          });
          break;
          
        case 'REMOVE':
          changes.deleted.push({
            key: record.dynamodb.Keys,
            item: record.dynamodb.OldImage
          });
          break;
      }
    }
    
    changes.totalChanges = 
      changes.inserted.length + 
      changes.updated.length + 
      changes.deleted.length;
    
    return changes;
  }
  
  private identifyChangedFields(
    oldItem: any,
    newItem: any
  ): string[] {
    const changedFields: string[] = [];
    const allFields = new Set([
      ...Object.keys(oldItem || {}),
      ...Object.keys(newItem || {})
    ]);
    
    for (const field of allFields) {
      if (!this.deepEqual(oldItem?.[field], newItem?.[field])) {
        changedFields.push(field);
      }
    }
    
    return changedFields;
  }
}

// ë¸íƒ€ ê³„ì‚°ê¸°
export class DeltaCalculator {
  async calculate(
    changes: Changes,
    baseBackup: BackupInfo
  ): Promise<Delta> {
    const delta: Delta = {
      baseBackupId: baseBackup.backupId,
      changes: {
        inserted: changes.inserted,
        updated: changes.updated.map(u => ({
          key: u.key,
          patches: this.createPatches(u.oldItem, u.newItem)
        })),
        deleted: changes.deleted.map(d => d.key)
      },
      metadata: {
        timestamp: new Date(),
        changeCount: changes.totalChanges,
        baseVersion: baseBackup.version
      }
    };
    
    // ì••ì¶•
    const compressed = await this.compress(delta);
    
    return {
      ...delta,
      size: compressed.length,
      compressionRatio: JSON.stringify(delta).length / compressed.length,
      compressedData: compressed
    };
  }
  
  private createPatches(
    oldItem: any,
    newItem: any
  ): Patch[] {
    const patches: Patch[] = [];
    
    // JSON Patch í˜•ì‹ìœ¼ë¡œ ë³€ê²½ ì‚¬í•­ í‘œí˜„
    const diff = this.diff(oldItem, newItem);
    
    for (const operation of diff) {
      patches.push({
        op: operation.op,
        path: operation.path,
        value: operation.value,
        oldValue: operation.oldValue
      });
    }
    
    return patches;
  }
}

// ë°±ì—… ë³µì›ê¸°
export class BackupRestorer {
  async restoreFromIncremental(
    backupId: string,
    targetTable: string
  ): Promise<RestoreResult> {
    // ë°±ì—… ì²´ì¸ ê°€ì ¸ì˜¤ê¸°
    const chain = await this.getBackupChain(backupId);
    
    // 1. ì „ì²´ ë°±ì—… ë³µì›
    await this.restoreFullBackup(
      chain.fullBackupId,
      targetTable
    );
    
    // 2. ì¦ë¶„ ë°±ì—… ìˆœì°¨ ì ìš©
    for (const incremental of chain.incrementalBackups) {
      await this.applyIncrementalBackup(
        incremental,
        targetTable
      );
    }
    
    // 3. ê²€ì¦
    const validation = await this.validateRestore(
      targetTable,
      backupId
    );
    
    return {
      success: validation.success,
      restoredTable: targetTable,
      itemCount: validation.itemCount,
      finalVersion: chain.incrementalBackups.slice(-1)[0]?.version
    };
  }
  
  private async applyIncrementalBackup(
    backup: BackupNode,
    targetTable: string
  ): Promise<void> {
    const delta = await this.loadDelta(backup.backupId);
    
    // ì‚½ì… ì ìš©
    for (const insert of delta.changes.inserted) {
      await this.putItem(targetTable, insert.item);
    }
    
    // ì—…ë°ì´íŠ¸ ì ìš©
    for (const update of delta.changes.updated) {
      await this.applyPatches(
        targetTable,
        update.key,
        update.patches
      );
    }
    
    // ì‚­ì œ ì ìš©
    for (const deleteKey of delta.changes.deleted) {
      await this.deleteItem(targetTable, deleteKey);
    }
  }
}
```

### SubTask 2.13.4: ì¬í•´ ë³µêµ¬ ìë™í™”
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ì¬í•´ ë°œìƒ ì‹œ ìë™ ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/backup/disaster-recovery/dr-automation.ts
export class DisasterRecoveryAutomation {
  private healthMonitor: HealthMonitor;
  private failoverManager: FailoverManager;
  private recoveryOrchestrator: RecoveryOrchestrator;
  private alertingService: AlertingService;
  
  constructor(
    private config: DRConfig,
    private backupManager: BackupManager
  ) {
    this.healthMonitor = new HealthMonitor(config.monitoring);
    this.failoverManager = new FailoverManager(config.failover);
    this.recoveryOrchestrator = new RecoveryOrchestrator();
    this.alertingService = new AlertingService(config.alerting);
    
    this.initializeAutomation();
  }
  
  // DR ìë™í™” ì´ˆê¸°í™”
  private initializeAutomation(): void {
    // í—¬ìŠ¤ ì²´í¬ ëª¨ë‹ˆí„°ë§
    this.healthMonitor.on('unhealthy', async (event) => {
      await this.handleUnhealthyEvent(event);
    });
    
    // ìë™ í˜ì¼ì˜¤ë²„ íŠ¸ë¦¬ê±°
    this.healthMonitor.on('failover_required', async (event) => {
      await this.executeFailover(event);
    });
    
    // ì •ê¸° DR í›ˆë ¨
    if (this.config.drillSchedule) {
      this.scheduleDRDrills();
    }
  }
  
  // ì¬í•´ ê°ì§€ ë° ëŒ€ì‘
  async handleDisasterEvent(
    event: DisasterEvent
  ): Promise<DisasterResponse> {
    const startTime = Date.now();
    
    // 1. ì¬í•´ ìˆ˜ì¤€ í‰ê°€
    const assessment = await this.assessDisasterLevel(event);
    
    // 2. ëŒ€ì‘ ê³„íš ìˆ˜ë¦½
    const recoveryPlan = await this.createRecoveryPlan(assessment);
    
    // 3. ì´í•´ê´€ê³„ì ì•Œë¦¼
    await this.notifyStakeholders(assessment, recoveryPlan);
    
    // 4. ë³µêµ¬ ì‹¤í–‰
    const recoveryResult = await this.executeRecovery(recoveryPlan);
    
    // 5. ë³µêµ¬ ê²€ì¦
    const validation = await this.validateRecovery(recoveryResult);
    
    return {
      disasterType: event.type,
      severity: assessment.severity,
      recoveryTime: Date.now() - startTime,
      dataLoss: recoveryResult.dataLoss,
      validation,
      report: await this.generateDRReport(event, recoveryResult)
    };
  }
  
  // ë³µêµ¬ ê³„íš ìˆ˜ë¦½
  private async createRecoveryPlan(
    assessment: DisasterAssessment
  ): Promise<RecoveryPlan> {
    const plan: RecoveryPlan = {
      id: uuidv4(),
      priority: this.determinePriority(assessment),
      steps: [],
      estimatedTime: 0,
      resources: []
    };
    
    // ì˜í–¥ë°›ì€ ì„œë¹„ìŠ¤ ì‹ë³„
    const affectedServices = await this.identifyAffectedServices(
      assessment
    );
    
    // ì„œë¹„ìŠ¤ë³„ ë³µêµ¬ ë‹¨ê³„ ìƒì„±
    for (const service of affectedServices) {
      const steps = await this.createServiceRecoverySteps(
        service,
        assessment
      );
      plan.steps.push(...steps);
    }
    
    // ì˜ì¡´ì„± ìˆœì„œ ì •ë ¬
    plan.steps = this.sortByDependencies(plan.steps);
    
    // ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ ê³„ì‚°
    plan.resources = this.calculateRequiredResources(plan.steps);
    
    // ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
    plan.estimatedTime = this.estimateRecoveryTime(plan.steps);
    
    return plan;
  }
  
  // ë³µêµ¬ ì‹¤í–‰
  private async executeRecovery(
    plan: RecoveryPlan
  ): Promise<RecoveryResult> {
    const executor = new RecoveryExecutor(plan);
    const result: RecoveryResult = {
      planId: plan.id,
      startTime: new Date(),
      steps: [],
      dataLoss: 0
    };
    
    // ë‹¨ê³„ë³„ ì‹¤í–‰
    for (const step of plan.steps) {
      try {
        const stepResult = await executor.executeStep(step);
        result.steps.push(stepResult);
        
        // ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        await this.updateProgress(plan.id, step.id, stepResult);
        
      } catch (error) {
        // ë³µêµ¬ ì‹¤íŒ¨ ì²˜ë¦¬
        await this.handleRecoveryFailure(step, error);
        
        // ëŒ€ì²´ ì „ëµ ì‹¤í–‰
        const fallbackResult = await this.executeFallbackStrategy(
          step,
          error
        );
        result.steps.push(fallbackResult);
      }
    }
    
    result.endTime = new Date();
    result.duration = result.endTime.getTime() - result.startTime.getTime();
    
    return result;
  }
  
  // DR í›ˆë ¨ ìŠ¤ì¼€ì¤„ë§
  private scheduleDRDrills(): void {
    cron.schedule(this.config.drillSchedule, async () => {
      await this.executeDRDrill();
    });
  }
  
  // DR í›ˆë ¨ ì‹¤í–‰
  async executeDRDrill(): Promise<DrillResult> {
    const drill: DRDrill = {
      id: uuidv4(),
      type: this.selectDrillScenario(),
      startTime: new Date(),
      scope: this.config.drillScope
    };
    
    try {
      // 1. í›ˆë ¨ í™˜ê²½ ì¤€ë¹„
      await this.prepareDrillEnvironment(drill);
      
      // 2. ì¬í•´ ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜
      const disaster = await this.simulateDisaster(drill.type);
      
      // 3. ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
      const recovery = await this.handleDisasterEvent(disaster);
      
      // 4. ê²°ê³¼ í‰ê°€
      const evaluation = await this.evaluateDrillResults(
        drill,
        recovery
      );
      
      // 5. ê°œì„  ì‚¬í•­ ë„ì¶œ
      const improvements = this.identifyImprovements(evaluation);
      
      return {
        drillId: drill.id,
        scenario: drill.type,
        duration: Date.now() - drill.startTime.getTime(),
        evaluation,
        improvements,
        nextActions: this.generateActionItems(improvements)
      };
      
    } finally {
      // í›ˆë ¨ í™˜ê²½ ì •ë¦¬
      await this.cleanupDrillEnvironment(drill);
    }
  }
}

// í˜ì¼ì˜¤ë²„ ê´€ë¦¬ì
export class FailoverManager {
  async executeFailover(
    event: FailoverEvent
  ): Promise<FailoverResult> {
    // 1. í˜„ì¬ ìƒíƒœ ìŠ¤ëƒ…ìƒ·
    const snapshot = await this.captureCurrentState();
    
    // 2. íƒ€ê²Ÿ ë¦¬ì „ ì¤€ë¹„
    await this.prepareTargetRegion(event.targetRegion);
    
    // 3. ë°ì´í„° ë™ê¸°í™” í™•ì¸
    const syncStatus = await this.verifySyncStatus(
      event.sourceRegion,
      event.targetRegion
    );
    
    if (syncStatus.lag > this.config.maxAcceptableLag) {
      // ê¸´ê¸‰ ë™ê¸°í™”
      await this.performEmergencySync(
        event.sourceRegion,
        event.targetRegion
      );
    }
    
    // 4. íŠ¸ë˜í”½ ì „í™˜
    await this.switchTraffic(event.targetRegion);
    
    // 5. ìƒíƒœ ê²€ì¦
    const validation = await this.validateFailover(
      snapshot,
      event.targetRegion
    );
    
    return {
      success: validation.success,
      sourceRegion: event.sourceRegion,
      targetRegion: event.targetRegion,
      dataLoss: syncStatus.estimatedDataLoss,
      switchoverTime: validation.switchoverTime,
      validation
    };
  }
}

// ë³µêµ¬ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
export class RecoveryOrchestrator {
  async orchestrateRecovery(
    services: AffectedService[]
  ): Promise<OrchestrationResult> {
    // ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ê·¸ë˜í”„ ìƒì„±
    const dependencyGraph = this.buildDependencyGraph(services);
    
    // ë³‘ë ¬ ë³µêµ¬ ê°€ëŠ¥í•œ ê·¸ë£¹ ì‹ë³„
    const recoveryGroups = this.identifyParallelGroups(dependencyGraph);
    
    // ê·¸ë£¹ë³„ ë³µêµ¬ ì‹¤í–‰
    const results: ServiceRecoveryResult[] = [];
    
    for (const group of recoveryGroups) {
      const groupResults = await Promise.all(
        group.map(service => this.recoverService(service))
      );
      results.push(...groupResults);
    }
    
    return {
      totalServices: services.length,
      recoveredServices: results.filter(r => r.success).length,
      failedServices: results.filter(r => !r.success).length,
      results
    };
  }
}
```

## Task 2.14: ì¬í•´ ë³µêµ¬ ê³„íš

### SubTask 2.14.1: RTO/RPO ëª©í‘œ êµ¬í˜„
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: Recovery Time Objective(RTO)ì™€ Recovery Point Objective(RPO) ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/dr/objectives/rto-rpo-manager.ts
export interface RTORPOObjectives {
  serviceName: string;
  rto: number; // ëª©í‘œ ë³µêµ¬ ì‹œê°„ (ë¶„)
  rpo: number; // ëª©í‘œ ë³µêµ¬ ì‹œì  (ë¶„)
  tier: 'critical' | 'high' | 'medium' | 'low';
  dependencies: string[];
}

export class RTORPOManager {
  private objectives: Map<string, RTORPOObjectives> = new Map();
  private metricsCollector: MetricsCollector;
  private complianceMonitor: ComplianceMonitor;
  
  constructor(
    private config: DRConfig,
    private backupManager: BackupManager,
    private replicationManager: ReplicationManager
  ) {
    this.metricsCollector = new MetricsCollector();
    this.complianceMonitor = new ComplianceMonitor();
    
    this.loadObjectives();
    this.initializeMonitoring();
  }
  
  // RTO/RPO ëª©í‘œ ì„¤ì •
  setObjectives(objectives: RTORPOObjectives): void {
    // ê²€ì¦
    this.validateObjectives(objectives);
    
    // ì‹¤í˜„ ê°€ëŠ¥ì„± í™•ì¸
    const feasibility = this.assessFeasibility(objectives);
    if (!feasibility.achievable) {
      throw new Error(
        `Objectives not achievable: ${feasibility.reasons.join(', ')}`
      );
    }
    
    this.objectives.set(objectives.serviceName, objectives);
    
    // ë°±ì—… ë° ë³µì œ ì „ëµ ì¡°ì •
    this.adjustStrategies(objectives);
  }
  
  // ì‹¤í˜„ ê°€ëŠ¥ì„± í‰ê°€
  private assessFeasibility(
    objectives: RTORPOObjectives
  ): FeasibilityAssessment {
    const assessment: FeasibilityAssessment = {
      achievable: true,
      reasons: [],
      recommendations: []
    };
    
    // RPO í‰ê°€
    if (objectives.rpo < 5) { // 5ë¶„ ë¯¸ë§Œ
      assessment.recommendations.push(
        'Enable continuous replication for sub-5 minute RPO'
      );
      
      if (!this.config.continuousReplication) {
        assessment.achievable = false;
        assessment.reasons.push(
          'Continuous replication not enabled'
        );
      }
    }
    
    // RTO í‰ê°€
    if (objectives.rto < 15) { // 15ë¶„ ë¯¸ë§Œ
      assessment.recommendations.push(
        'Implement hot standby for sub-15 minute RTO'
      );
      
      if (!this.config.hotStandby) {
        assessment.achievable = false;
        assessment.reasons.push(
          'Hot standby not configured'
        );
      }
    }
    
    // ì˜ì¡´ì„± í‰ê°€
    for (const dep of objectives.dependencies) {
      const depObjective = this.objectives.get(dep);
      if (depObjective && depObjective.rto > objectives.rto) {
        assessment.achievable = false;
        assessment.reasons.push(
          `Dependency ${dep} has longer RTO`
        );
      }
    }
    
    return assessment;
  }
  
  // ì „ëµ ì¡°ì •
  private adjustStrategies(objectives: RTORPOObjectives): void {
    // ë°±ì—… ì „ëµ ì¡°ì •
    if (objectives.rpo <= 60) { // 1ì‹œê°„ ì´í•˜
      this.backupManager.enableContinuousBackup(
        objectives.serviceName
      );
    }
    
    // ë³µì œ ì „ëµ ì¡°ì •
    if (objectives.rpo <= 5) { // 5ë¶„ ì´í•˜
      this.replicationManager.enableSynchronousReplication(
        objectives.serviceName
      );
    }
    
    // ë³µêµ¬ ì¤€ë¹„ ì¡°ì •
    if (objectives.rto <= 30) { // 30ë¶„ ì´í•˜
      this.prepareRapidRecovery(objectives.serviceName);
    }
  }
  
  // ì»´í”Œë¼ì´ì–¸ìŠ¤ ëª¨ë‹ˆí„°ë§
  async monitorCompliance(): Promise<ComplianceReport> {
    const report: ComplianceReport = {
      timestamp: new Date(),
      services: [],
      overallCompliance: 0
    };
    
    for (const [service, objectives] of this.objectives) {
      const metrics = await this.measureActualMetrics(service);
      
      const compliance = {
        service,
        rtoTarget: objectives.rto,
        rtoActual: metrics.actualRTO,
        rtoCompliant: metrics.actualRTO <= objectives.rto,
        rpoTarget: objectives.rpo,
        rpoActual: metrics.actualRPO,
        rpoCompliant: metrics.actualRPO <= objectives.rpo,
        lastTested: metrics.lastDRTest
      };
      
      report.services.push(compliance);
    }
    
    report.overallCompliance = this.calculateOverallCompliance(
      report.services
    );
    
    // ë¹„ì¤€ìˆ˜ ì•Œë¦¼
    await this.alertNonCompliance(report);
    
    return report;
  }
  
  // ì‹¤ì œ ë©”íŠ¸ë¦­ ì¸¡ì •
  private async measureActualMetrics(
    service: string
  ): Promise<ActualMetrics> {
    // ë§ˆì§€ë§‰ ë³µêµ¬ ì—°ìŠµ ê²°ê³¼
    const lastDrill = await this.getLastDRDrill(service);
    
    // ë°±ì—… ì£¼ê¸° í™•ì¸
    const backupMetrics = await this.backupManager.getMetrics(service);
    
    // ë³µì œ ì§€ì—° í™•ì¸
    const replicationLag = await this.replicationManager.getLag(service);
    
    return {
      actualRTO: lastDrill?.recoveryTime || Infinity,
      actualRPO: Math.max(
        backupMetrics.interval,
        replicationLag
      ),
      lastDRTest: lastDrill?.timestamp,
      confidence: this.calculateConfidence(lastDrill, backupMetrics)
    };
  }
}

// RTO ìµœì í™” ì—”ì§„
export class RTOOptimizer {
  async optimizeRecoveryTime(
    service: string,
    currentRTO: number,
    targetRTO: number
  ): Promise<OptimizationPlan> {
    const optimizations: Optimization[] = [];
    
    // í˜„ì¬ ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ ë¶„ì„
    const analysis = await this.analyzeRecoveryProcess(service);
    
    // ë³‘ëª© ì§€ì  ì‹ë³„
    const bottlenecks = this.identifyBottlenecks(analysis);
    
    // ìµœì í™” ì „ëµ ìƒì„±
    if (bottlenecks.includes('backup_restore')) {
      optimizations.push({
        type: 'parallel_restore',
        estimatedImprovement: 40,
        cost: 'medium',
        implementation: 'Enable parallel table restore'
      });
    }
    
    if (bottlenecks.includes('data_validation')) {
      optimizations.push({
        type: 'async_validation',
        estimatedImprovement: 20,
        cost: 'low',
        implementation: 'Perform validation asynchronously'
      });
    }
    
    if (targetRTO < 15 && !analysis.hasHotStandby) {
      optimizations.push({
        type: 'hot_standby',
        estimatedImprovement: 70,
        cost: 'high',
        implementation: 'Implement hot standby infrastructure'
      });
    }
    
    return {
      currentRTO,
      targetRTO,
      achievableRTO: this.calculateAchievableRTO(
        currentRTO,
        optimizations
      ),
      optimizations,
      implementationPlan: this.createImplementationPlan(optimizations)
    };
  }
}

// RPO ëª¨ë‹ˆí„°
export class RPOMonitor {
  private lastBackupTimes: Map<string, Date> = new Map();
  private lastReplicationSync: Map<string, Date> = new Map();
  
  async monitorRPO(service: string): Promise<RPOStatus> {
    const objectives = this.getObjectives(service);
    
    // í˜„ì¬ ì ì¬ ë°ì´í„° ì†ì‹¤ ê³„ì‚°
    const potentialDataLoss = await this.calculatePotentialDataLoss(
      service
    );
    
    // RPO ìœ„ë°˜ í™•ì¸
    const violation = potentialDataLoss > objectives.rpo;
    
    if (violation) {
      // ì¦‰ì‹œ ë°±ì—… íŠ¸ë¦¬ê±°
      await this.triggerEmergencyBackup(service);
      
      // ì•Œë¦¼ ë°œì†¡
      await this.sendRPOViolationAlert({
        service,
        targetRPO: objectives.rpo,
        currentRPO: potentialDataLoss,
        severity: this.calculateSeverity(
          potentialDataLoss,
          objectives.rpo
        )
      });
    }
    
    return {
      service,
      compliant: !violation,
      currentRPO: potentialDataLoss,
      targetRPO: objectives.rpo,
      lastBackup: this.lastBackupTimes.get(service),
      nextBackupIn: this.calculateNextBackupTime(service)
    };
  }
  
  private async calculatePotentialDataLoss(
    service: string
  ): Promise<number> {
    const lastBackup = this.lastBackupTimes.get(service);
    const lastSync = this.lastReplicationSync.get(service);
    
    const now = Date.now();
    const timeSinceBackup = lastBackup ? 
      (now - lastBackup.getTime()) / 60000 : Infinity;
    const timeSinceSync = lastSync ? 
      (now - lastSync.getTime()) / 60000 : Infinity;
    
    return Math.min(timeSinceBackup, timeSinceSync);
  }
}
```

### SubTask 2.14.2: ë‹¤ì¤‘ ë¦¬ì „ í˜ì¼ì˜¤ë²„
**ë‹´ë‹¹ì**: ì¸í”„ë¼ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: ë‹¤ì¤‘ AWS ë¦¬ì „ ê°„ ìë™ í˜ì¼ì˜¤ë²„ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/dr/failover/multi-region-failover.ts
export interface RegionConfig {
  region: string;
  role: 'primary' | 'secondary' | 'dr';
  priority: number;
  healthEndpoint: string;
  resources: RegionResources;
}

export class MultiRegionFailoverManager {
  private regions: Map<string, RegionConfig> = new Map();
  private healthChecker: RegionHealthChecker;
  private dnsManager: DNSManager;
  private dataSync: DataSyncManager;
  private stateManager: FailoverStateManager;
  
  constructor(
    private config: FailoverConfig
  ) {
    this.healthChecker = new RegionHealthChecker();
    this.dnsManager = new DNSManager(config.route53);
    this.dataSync = new DataSyncManager();
    this.stateManager = new FailoverStateManager();
    
    this.initializeRegions();
    this.startHealthMonitoring();
  }
  
  // ë¦¬ì „ ì´ˆê¸°í™”
  private initializeRegions(): void {
    for (const regionConfig of this.config.regions) {
      this.regions.set(regionConfig.region, regionConfig);
      
      // ë¦¬ì „ë³„ ë¦¬ì†ŒìŠ¤ ê²€ì¦
      this.validateRegionResources(regionConfig);
    }
  }
  
  // í˜ì¼ì˜¤ë²„ ì‹¤í–‰
  async executeFailover(
    fromRegion: string,
    toRegion: string,
    reason: FailoverReason
  ): Promise<FailoverResult> {
    const failoverId = uuidv4();
    const startTime = Date.now();
    
    try {
      // 1. í˜ì¼ì˜¤ë²„ ìƒíƒœ ì´ˆê¸°í™”
      await this.stateManager.initializeFailover({
        id: failoverId,
        fromRegion,
        toRegion,
        reason,
        startTime: new Date()
      });
      
      // 2. Pre-failover ê²€ì¦
      await this.preFailoverValidation(fromRegion, toRegion);
      
      // 3. ë°ì´í„° ë™ê¸°í™” í™•ì¸
      const syncStatus = await this.dataSync.checkSyncStatus(
        fromRegion,
        toRegion
      );
      
      if (!syncStatus.synchronized) {
        await this.performEmergencySync(fromRegion, toRegion);
      }
      
      // 4. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¤‘ì§€ (ì„ íƒì )
      if (this.config.gracefulShutdown) {
        await this.gracefulShutdown(fromRegion);
      }
      
      // 5. DNS ì „í™˜
      await this.switchDNS(fromRegion, toRegion);
      
      // 6. ìƒˆ Primary í™œì„±í™”
      await this.activateNewPrimary(toRegion);
      
      // 7. ìƒíƒœ ê²€ì¦
      const validation = await this.postFailoverValidation(toRegion);
      
      // 8. ì´ì „ Primary ì •ë¦¬
      await this.decommissionOldPrimary(fromRegion);
      
      const result: FailoverResult = {
        id: failoverId,
        success: true,
        duration: Date.now() - startTime,
        fromRegion,
        toRegion,
        validation,
        dataLoss: syncStatus.estimatedDataLoss
      };
      
      await this.stateManager.completeFailover(failoverId, result);
      
      return result;
      
    } catch (error) {
      // í˜ì¼ì˜¤ë²„ ë¡¤ë°±
      await this.rollbackFailover(failoverId, error);
      throw error;
    }
  }
  
  // DNS ì „í™˜
  private async switchDNS(
    fromRegion: string,
    toRegion: string
  ): Promise<void> {
    const hostedZone = this.config.route53.hostedZoneId;
    
    // í˜„ì¬ ë ˆì½”ë“œ ë°±ì—…
    const currentRecords = await this.dnsManager.getRecords(hostedZone);
    await this.stateManager.saveState('dns_backup', currentRecords);
    
    // ìƒˆ ë ˆì½”ë“œ ìƒì„±
    const newRecords = this.generateDNSRecords(toRegion);
    
    // ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì „í™˜ (ì ì§„ì )
    if (this.config.gradualFailover) {
      await this.performGradualDNSSwitch(
        hostedZone,
        fromRegion,
        toRegion,
        newRecords
      );
    } else {
      // ì¦‰ì‹œ ì „í™˜
      await this.dnsManager.updateRecords(
        hostedZone,
        newRecords
      );
    }
    
    // DNS ì „íŒŒ ëŒ€ê¸°
    await this.waitForDNSPropagation(newRecords);
  }
  
  // ì ì§„ì  DNS ì „í™˜
  private async performGradualDNSSwitch(
    hostedZone: string,
    fromRegion: string,
    toRegion: string,
    targetRecords: DNSRecord[]
  ): Promise<void> {
    const steps = [10, 25, 50, 75, 100]; // íŠ¸ë˜í”½ ë¹„ìœ¨
    
    for (const percentage of steps) {
      // ê°€ì¤‘ì¹˜ ë ˆì½”ë“œ ìƒì„±
      const weightedRecords = this.createWeightedRecords(
        fromRegion,
        toRegion,
        percentage
      );
      
      await this.dnsManager.updateRecords(
        hostedZone,
        weightedRecords
      );
      
      // ëª¨ë‹ˆí„°ë§
      await this.monitorTrafficDistribution(
        fromRegion,
        toRegion,
        percentage
      );
      
      // ì•ˆì •í™” ëŒ€ê¸°
      await this.sleep(this.config.stabilizationTime);
    }
  }
  
  // ìë™ í˜ì¼ë°±
  async executeFailback(
    originalRegion: string
  ): Promise<FailbackResult> {
    // ì›ë³¸ ë¦¬ì „ ìƒíƒœ í™•ì¸
    const health = await this.healthChecker.checkRegion(originalRegion);
    
    if (!health.healthy) {
      throw new Error('Original region not healthy for failback');
    }
    
    // ë°ì´í„° ì—­ë™ê¸°í™”
    const currentPrimary = await this.getCurrentPrimary();
    await this.dataSync.reverseSync(
      currentPrimary,
      originalRegion
    );
    
    // í˜ì¼ë°± ì‹¤í–‰
    const result = await this.executeFailover(
      currentPrimary,
      originalRegion,
      { type: 'failback', automated: true }
    );
    
    return {
      ...result,
      type: 'failback'
    };
  }
}

// ë¦¬ì „ ìƒíƒœ ê²€ì‚¬ê¸°
export class RegionHealthChecker {
  private checks: HealthCheck[] = [];
  
  constructor() {
    this.initializeHealthChecks();
  }
  
  private initializeHealthChecks(): void {
    // API ì—”ë“œí¬ì¸íŠ¸ ê²€ì‚¬
    this.checks.push(new APIHealthCheck());
    
    // ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê²€ì‚¬
    this.checks.push(new DatabaseHealthCheck());
    
    // ìŠ¤í† ë¦¬ì§€ ê°€ìš©ì„± ê²€ì‚¬
    this.checks.push(new StorageHealthCheck());
    
    // ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„± ê²€ì‚¬
    this.checks.push(new NetworkHealthCheck());
    
    // ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ê²€ì‚¬
    this.checks.push(new ApplicationHealthCheck());
  }
  
  async checkRegion(region: string): Promise<RegionHealth> {
    const results: HealthCheckResult[] = [];
    
    for (const check of this.checks) {
      try {
        const result = await check.execute(region);
        results.push(result);
      } catch (error) {
        results.push({
          check: check.name,
          healthy: false,
          error: error.message
        });
      }
    }
    
    const healthScore = this.calculateHealthScore(results);
    
    return {
      region,
      healthy: healthScore >= this.config.healthThreshold,
      score: healthScore,
      checks: results,
      timestamp: new Date()
    };
  }
  
  private calculateHealthScore(
    results: HealthCheckResult[]
  ): number {
    const weights = {
      'api': 0.3,
      'database': 0.3,
      'storage': 0.2,
      'network': 0.1,
      'application': 0.1
    };
    
    let score = 0;
    for (const result of results) {
      if (result.healthy) {
        score += weights[result.check] || 0;
      }
    }
    
    return score;
  }
}

// í˜ì¼ì˜¤ë²„ ìƒíƒœ ê´€ë¦¬ì
export class FailoverStateManager {
  private state: Map<string, any> = new Map();
  private history: FailoverHistory[] = [];
  
  async initializeFailover(
    failover: FailoverInitiation
  ): Promise<void> {
    // ìƒíƒœ ì €ì¥
    this.state.set(failover.id, {
      ...failover,
      status: 'in_progress',
      steps: []
    });
    
    // ì´ë²¤íŠ¸ ë°œìƒ
    await this.emit('failover:started', failover);
    
    // ê°ì‚¬ ë¡œê·¸
    await this.auditLog({
      event: 'failover_initiated',
      failoverId: failover.id,
      details: failover
    });
  }
  
  async saveCheckpoint(
    failoverId: string,
    checkpoint: FailoverCheckpoint
  ): Promise<void> {
    const failover = this.state.get(failoverId);
    failover.steps.push(checkpoint);
    
    // ì˜êµ¬ ì €ì¥
    await this.persistState(failoverId, failover);
  }
  
  async rollback(
    failoverId: string,
    toCheckpoint: string
  ): Promise<void> {
    const failover = this.state.get(failoverId);
    const checkpoint = failover.steps.find(
      s => s.id === toCheckpoint
    );
    
    if (!checkpoint) {
      throw new Error('Checkpoint not found');
    }
    
    // ì²´í¬í¬ì¸íŠ¸ ì´í›„ ë‹¨ê³„ ë¡¤ë°±
    const stepsToRollback = failover.steps.filter(
      s => s.timestamp > checkpoint.timestamp
    );
    
    for (const step of stepsToRollback.reverse()) {
      await this.rollbackStep(step);
    }
  }
}
```

### SubTask 2.14.3: ë³µêµ¬ ì‹œë®¬ë ˆì´ì…˜
**ë‹´ë‹¹ì**: QA ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì¬í•´ ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜ ë° ê²€ì¦ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/dr/simulation/dr-simulator.ts
export interface SimulationScenario {
  id: string;
  name: string;
  disasterType: DisasterType;
  affectedComponents: string[];
  dataLossPercentage: number;
  duration: number;
  complexity: 'low' | 'medium' | 'high';
}

export class DisasterRecoverySimulator {
  private scenarioRunner: ScenarioRunner;
  private environmentManager: SimulationEnvironmentManager;
  private metricsCollector: SimulationMetricsCollector;
  private reportGenerator: SimulationReportGenerator;
  
  constructor(
    private config: SimulationConfig
  ) {
    this.scenarioRunner = new ScenarioRunner();
    this.environmentManager = new SimulationEnvironmentManager();
    this.metricsCollector = new SimulationMetricsCollector();
    this.reportGenerator = new SimulationReportGenerator();
  }
  
  // ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
  async runSimulation(
    scenario: SimulationScenario,
    options?: SimulationOptions
  ): Promise<SimulationResult> {
    const simulationId = uuidv4();
    const startTime = Date.now();
    
    try {
      // 1. ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì¤€ë¹„
      const environment = await this.prepareEnvironment(
        scenario,
        options
      );
      
      // 2. ì´ˆê¸° ìƒíƒœ ìº¡ì²˜
      const initialState = await this.captureSystemState(environment);
      
      // 3. ì¬í•´ ì‹œë®¬ë ˆì´ì…˜
      await this.simulateDisaster(environment, scenario);
      
      // 4. ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
      const recoveryResult = await this.executeRecovery(
        environment,
        scenario
      );
      
      // 5. ê²°ê³¼ ê²€ì¦
      const validation = await this.validateRecovery(
        environment,
        initialState
      );
      
      // 6. ë©”íŠ¸ë¦­ ìˆ˜ì§‘
      const metrics = await this.metricsCollector.collect(
        simulationId,
        environment
      );
      
      // 7. ë¦¬í¬íŠ¸ ìƒì„±
      const report = await this.reportGenerator.generate({
        simulationId,
        scenario,
        recoveryResult,
        validation,
        metrics
      });
      
      return {
        id: simulationId,
        success: validation.success,
        duration: Date.now() - startTime,
        report,
        learnings: this.extractLearnings(recoveryResult, validation)
      };
      
    } finally {
      // í™˜ê²½ ì •ë¦¬
      await this.cleanupEnvironment(simulationId);
    }
  }
  
  // ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì¤€ë¹„
  private async prepareEnvironment(
    scenario: SimulationScenario,
    options?: SimulationOptions
  ): Promise<SimulationEnvironment> {
    // ê²©ë¦¬ëœ í™˜ê²½ ìƒì„±
    const environment = await this.environmentManager.create({
      isolated: true,
      copyProductionData: options?.useProductionData || false,
      scale: options?.scale || 0.1 // 10% ê·œëª¨
    });
    
    // ì»´í¬ë„ŒíŠ¸ ë°°í¬
    await this.deployComponents(environment, scenario.affectedComponents);
    
    // ë°ì´í„° ì‹œë”©
    await this.seedData(environment, scenario);
    
    // ëª¨ë‹ˆí„°ë§ ì„¤ì •
    await this.setupMonitoring(environment);
    
    return environment;
  }
  
  // ì¬í•´ ì‹œë®¬ë ˆì´ì…˜
  private async simulateDisaster(
    environment: SimulationEnvironment,
    scenario: SimulationScenario
  ): Promise<void> {
    const disasterSimulator = this.getDisasterSimulator(
      scenario.disasterType
    );
    
    await disasterSimulator.simulate({
      environment,
      components: scenario.affectedComponents,
      severity: scenario.dataLossPercentage,
      duration: scenario.duration
    });
    
    // ì¬í•´ ì˜í–¥ í™•ì¸
    await this.waitForDisasterImpact(environment);
  }
  
  // ë³µêµ¬ ì‹¤í–‰
  private async executeRecovery(
    environment: SimulationEnvironment,
    scenario: SimulationScenario
  ): Promise<RecoveryExecutionResult> {
    const recoveryPlan = await this.createRecoveryPlan(scenario);
    const executor = new SimulatedRecoveryExecutor(environment);
    
    const steps: StepResult[] = [];
    
    for (const step of recoveryPlan.steps) {
      const stepResult = await executor.executeStep(step);
      steps.push(stepResult);
      
      // ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
      await this.metricsCollector.recordStep(stepResult);
    }
    
    return {
      plan: recoveryPlan,
      steps,
      totalTime: steps.reduce((sum, s) => sum + s.duration, 0),
      dataRecovered: this.calculateDataRecovery(steps)
    };
  }
}

// ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ê¸°
export class ScenarioRunner {
  private scenarios: Map<string, SimulationScenario> = new Map();
  
  constructor() {
    this.loadBuiltInScenarios();
  }
  
  private loadBuiltInScenarios(): void {
    // ë¦¬ì „ ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤
    this.scenarios.set('region_failure', {
      id: 'region_failure',
      name: 'Complete Region Failure',
      disasterType: 'region_outage',
      affectedComponents: ['all'],
      dataLossPercentage: 0,
      duration: 3600000, // 1ì‹œê°„
      complexity: 'high'
    });
    
    // ë°ì´í„° ì†ìƒ ì‹œë‚˜ë¦¬ì˜¤
    this.scenarios.set('data_corruption', {
      id: 'data_corruption',
      name: 'Database Corruption',
      disasterType: 'data_corruption',
      affectedComponents: ['database'],
      dataLossPercentage: 30,
      duration: 1800000, // 30ë¶„
      complexity: 'medium'
    });
    
    // ëœì„¬ì›¨ì–´ ì‹œë‚˜ë¦¬ì˜¤
    this.scenarios.set('ransomware', {
      id: 'ransomware',
      name: 'Ransomware Attack',
      disasterType: 'security_breach',
      affectedComponents: ['storage', 'database'],
      dataLossPercentage: 100,
      duration: 7200000, // 2ì‹œê°„
      complexity: 'high'
    });
  }
  
  async runScenario(
    scenarioId: string,
    customizations?: ScenarioCustomization
  ): Promise<ScenarioResult> {
    let scenario = this.scenarios.get(scenarioId);
    
    if (!scenario) {
      throw new Error(`Scenario ${scenarioId} not found`);
    }
    
    // ì‹œë‚˜ë¦¬ì˜¤ ì»¤ìŠ¤í„°ë§ˆì´ì§•
    if (customizations) {
      scenario = this.applyCustomizations(scenario, customizations);
    }
    
    // ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‹¤í–‰ ë¡œì§
    switch (scenario.disasterType) {
      case 'region_outage':
        return await this.runRegionOutageScenario(scenario);
        
      case 'data_corruption':
        return await this.runDataCorruptionScenario(scenario);
        
      case 'security_breach':
        return await this.runSecurityBreachScenario(scenario);
        
      default:
        throw new Error(`Unknown disaster type: ${scenario.disasterType}`);
    }
  }
}

// ì‹œë®¬ë ˆì´ì…˜ ê²€ì¦ê¸°
export class SimulationValidator {
  async validateRecovery(
    environment: SimulationEnvironment,
    expectedState: SystemState
  ): Promise<ValidationResult> {
    const currentState = await this.captureSystemState(environment);
    const validators: Validator[] = [
      new DataIntegrityValidator(),
      new ServiceAvailabilityValidator(),
      new PerformanceValidator(),
      new ConsistencyValidator()
    ];
    
    const results: ValidationCheck[] = [];
    
    for (const validator of validators) {
      const result = await validator.validate(
        expectedState,
        currentState
      );
      results.push(result);
    }
    
    return {
      success: results.every(r => r.passed),
      checks: results,
      summary: this.generateValidationSummary(results),
      recommendations: this.generateRecommendations(results)
    };
  }
  
  private generateValidationSummary(
    results: ValidationCheck[]
  ): ValidationSummary {
    return {
      totalChecks: results.length,
      passed: results.filter(r => r.passed).length,
      failed: results.filter(r => !r.passed).length,
      criticalFailures: results.filter(
        r => !r.passed && r.severity === 'critical'
      ).length
    };
  }
}

// í•™ìŠµ ì¶”ì¶œê¸°
export class LearningExtractor {
  extractLearnings(
    result: RecoveryExecutionResult,
    validation: ValidationResult
  ): Learning[] {
    const learnings: Learning[] = [];
    
    // ì„±ëŠ¥ ê´€ë ¨ í•™ìŠµ
    if (result.totalTime > this.config.targetRTO) {
      learnings.push({
        category: 'performance',
        finding: 'RTO exceeded',
        impact: 'high',
        recommendation: this.generateRTOImprovement(result)
      });
    }
    
    // ë°ì´í„° ì†ì‹¤ ê´€ë ¨ í•™ìŠµ
    if (result.dataRecovered < 100) {
      learnings.push({
        category: 'data_integrity',
        finding: `${100 - result.dataRecovered}% data loss`,
        impact: 'critical',
        recommendation: this.generateRPOImprovement(result)
      });
    }
    
    // í”„ë¡œì„¸ìŠ¤ ê°œì„  ì‚¬í•­
    const processImprovements = this.analyzeProcessEfficiency(result);
    learnings.push(...processImprovements);
    
    return learnings;
  }
}
```

### SubTask 2.14.4: ë¹„ì¦ˆë‹ˆìŠ¤ ì—°ì†ì„± ê³„íš
**ë‹´ë‹¹ì**: ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ë¹„ì¦ˆë‹ˆìŠ¤ ì—°ì†ì„±ì„ ë³´ì¥í•˜ëŠ” ìë™í™”ëœ ì¬í•´ ë³µêµ¬ ê³„íš êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/dr/bcp/business-continuity-planner.ts
export interface BusinessContinuityPlan {
  id: string;
  version: string;
  businessFunctions: BusinessFunction[];
  dependencies: DependencyMap;
  priorityMatrix: PriorityMatrix;
  communicationPlan: CommunicationPlan;
  escalationProcedures: EscalationProcedure[];
}

export class BusinessContinuityPlanner {
  private plan: BusinessContinuityPlan;
  private impactAnalyzer: BusinessImpactAnalyzer;
  private orchestrator: BCPOrchestrator;
  private notificationManager: NotificationManager;
  
  constructor(
    private config: BCPConfig
  ) {
    this.impactAnalyzer = new BusinessImpactAnalyzer();
    this.orchestrator = new BCPOrchestrator();
    this.notificationManager = new NotificationManager();
    
    this.loadBusinessContinuityPlan();
  }
  
  // BCP í™œì„±í™”
  async activateBCP(
    incident: Incident
  ): Promise<BCPActivationResult> {
    const activationId = uuidv4();
    
    // 1. ì˜í–¥ ë¶„ì„
    const impact = await this.impactAnalyzer.analyze(incident);
    
    // 2. ìš°ì„ ìˆœìœ„ ê²°ì •
    const priorities = this.determinePriorities(impact);
    
    // 3. ì´í•´ê´€ê³„ì ì•Œë¦¼
    await this.notifyStakeholders(incident, impact);
    
    // 4. ë³µêµ¬ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
    const recoveryPlan = this.createRecoveryPlan(priorities);
    const recoveryResult = await this.orchestrator.execute(recoveryPlan);
    
    // 5. ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°ëŠ¥ ë³µì›
    const restorationResult = await this.restoreBusinessFunctions(
      priorities,
      recoveryResult
    );
    
    // 6. ìƒíƒœ ë³´ê³ 
    await this.reportStatus(activationId, restorationResult);
    
    return {
      activationId,
      impact,
      recoveryTime: restorationResult.totalTime,
      functionsRestored: restorationResult.restored,
      residualRisk: this.calculateResidualRisk(restorationResult)
    };
  }
  
  // ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°ëŠ¥ ìš°ì„ ìˆœìœ„ ê²°ì •
  private determinePriorities(
    impact: BusinessImpact
  ): PrioritizedFunctions[] {
    const prioritized: PrioritizedFunctions[] = [];
    
    for (const func of this.plan.businessFunctions) {
      const priority = this.calculatePriority(func, impact);
      
      prioritized.push({
        function: func,
        priority,
        criticalityScore: func.criticality,
        dependencies: this.plan.dependencies[func.id],
        estimatedDowntime: impact.downtime[func.id]
      });
    }
    
    // ìš°ì„ ìˆœìœ„ ì •ë ¬
    return prioritized.sort((a, b) => b.priority - a.priority);
  }
  
  // ì´í•´ê´€ê³„ì ì•Œë¦¼
  private async notifyStakeholders(
    incident: Incident,
    impact: BusinessImpact
  ): Promise<void> {
    const notifications = this.plan.communicationPlan.notifications;
    
    for (const notification of notifications) {
      if (this.shouldNotify(notification, incident, impact)) {
        await this.notificationManager.send({
          recipients: notification.recipients,
          template: notification.template,
          data: {
            incident,
            impact,
            estimatedResolution: this.estimateResolution(impact)
          },
          channels: notification.channels
        });
      }
    }
  }
  
  // ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°ëŠ¥ ë³µì›
  private async restoreBusinessFunctions(
    priorities: PrioritizedFunctions[],
    recoveryResult: RecoveryResult
  ): Promise<RestorationResult> {
    const results: FunctionRestoration[] = [];
    
    for (const prioritized of priorities) {
      const restoration = await this.restoreFunction(
        prioritized.function,
        recoveryResult
      );
      
      results.push(restoration);
      
      // ì¤‘ê°„ ìƒíƒœ ë³´ê³ 
      if (prioritized.priority === 'critical') {
        await this.reportFunctionRestoration(restoration);
      }
    }
    
    return {
      restored: results.filter(r => r.success).length,
      failed: results.filter(r => !r.success).length,
      totalTime: this.calculateTotalTime(results),
      results
    };
  }
}

// ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ ë¶„ì„ê¸°
export class BusinessImpactAnalyzer {
  async analyze(incident: Incident): Promise<BusinessImpact> {
    const impact: BusinessImpact = {
      severity: this.calculateSeverity(incident),
      affectedFunctions: [],
      estimatedLoss: 0,
      downtime: {},
      customers: 0
    };
    
    // ì˜í–¥ë°›ëŠ” ê¸°ëŠ¥ ì‹ë³„
    impact.affectedFunctions = await this.identifyAffectedFunctions(
      incident
    );
    
    // ë‹¤ìš´íƒ€ì„ ì˜ˆì¸¡
    for (const func of impact.affectedFunctions) {
      impact.downtime[func.id] = await this.estimateDowntime(
        func,
        incident
      );
    }
    
    // ì¬ë¬´ ì˜í–¥ ê³„ì‚°
    impact.estimatedLoss = await this.calculateFinancialImpact(
      impact.affectedFunctions,
      impact.downtime
    );
    
    // ê³ ê° ì˜í–¥ ê³„ì‚°
    impact.customers = await this.estimateCustomerImpact(
      impact.affectedFunctions
    );
    
    return impact;
  }
  
  private async calculateFinancialImpact(
    functions: BusinessFunction[],
    downtime: Record<string, number>
  ): Promise<number> {
    let totalLoss = 0;
    
    for (const func of functions) {
      const hourlyLoss = func.financialImpact.hourlyLoss;
      const downtimeHours = downtime[func.id] / 60;
      
      totalLoss += hourlyLoss * downtimeHours;
      
      // ì¶”ê°€ ë¹„ìš© (ë³µêµ¬, ë³´ìƒ ë“±)
      totalLoss += func.financialImpact.recoveryC

ost || 0;
    }
    
    return totalLoss;
  }
}

// BCP ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
export class BCPOrchestrator {
  async execute(
    plan: RecoveryPlan
  ): Promise<RecoveryResult> {
    const executor = new PlanExecutor(plan);
    const monitor = new ExecutionMonitor();
    
    // ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—… ì‹ë³„
    const parallelTasks = this.identifyParallelTasks(plan.tasks);
    
    // ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§
    const results = await this.executeWithMonitoring(
      parallelTasks,
      executor,
      monitor
    );
    
    return {
      success: results.every(r => r.success),
      tasks: results,
      duration: monitor.getTotalDuration(),
      metrics: monitor.getMetrics()
    };
  }
  
  private async executeWithMonitoring(
    tasks: Task[][],
    executor: PlanExecutor,
    monitor: ExecutionMonitor
  ): Promise<TaskResult[]> {
    const allResults: TaskResult[] = [];
    
    for (const batch of tasks) {
      const batchResults = await Promise.all(
        batch.map(task => 
          executor.executeTask(task)
            .then(result => {
              monitor.recordSuccess(task, result);
              return result;
            })
            .catch(error => {
              monitor.recordFailure(task, error);
              return this.handleTaskFailure(task, error);
            })
        )
      );
      
      allResults.push(...batchResults);
    }
    
    return allResults;
  }
}

// ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê´€ë¦¬ì
export class CommunicationManager {
  private channels: Map<string, CommunicationChannel> = new Map();
  
  constructor() {
    this.initializeChannels();
  }
  
  private initializeChannels(): void {
    this.channels.set('email', new EmailChannel());
    this.channels.set('sms', new SMSChannel());
    this.channels.set('slack', new SlackChannel());
    this.channels.set('teams', new TeamsChannel());
    this.channels.set('voice', new VoiceCallChannel());
  }
  
  async sendEmergencyNotification(
    notification: EmergencyNotification
  ): Promise<void> {
    // ìš°ì„ ìˆœìœ„ë³„ ì±„ë„ ì„ íƒ
    const channels = this.selectChannelsByPriority(
      notification.priority
    );
    
    // ë³‘ë ¬ ì „ì†¡
    await Promise.all(
      channels.map(channel => 
        this.sendViaChannel(channel, notification)
      )
    );
    
    // ì „ì†¡ í™•ì¸
    await this.verifyDelivery(notification);
  }
  
  private selectChannelsByPriority(
    priority: Priority
  ): CommunicationChannel[] {
    switch (priority) {
      case 'critical':
        return [
          this.channels.get('voice')!,
          this.channels.get('sms')!,
          this.channels.get('email')!
        ];
      case 'high':
        return [
          this.channels.get('sms')!,
          this.channels.get('email')!,
          this.channels.get('slack')!
        ];
      default:
        return [
          this.channels.get('email')!,
          this.channels.get('slack')!
        ];
    }
  }
}
```

## Task 2.15: ë°ì´í„° ë³´ì•ˆ ë° ì•”í˜¸í™”

### SubTask 2.15.1: ì €ì¥ ë°ì´í„° ì•”í˜¸í™”
**ë‹´ë‹¹ì**: ë³´ì•ˆ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: DynamoDBì™€ S3ì˜ ëª¨ë“  ì €ì¥ ë°ì´í„°ì— ëŒ€í•œ ì•”í˜¸í™” êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/encryption/data-encryption.ts
import { KMSClient, EncryptCommand, DecryptCommand } from '@aws-sdk/client-kms';
import crypto from 'crypto';

export interface EncryptionConfig {
  kmsKeyId: string;
  algorithm: 'AES-256-GCM' | 'AES-256-CBC';
  rotationPolicy: KeyRotationPolicy;
  fieldLevelEncryption: FieldEncryptionConfig[];
}

export class DataEncryptionManager {
  private kmsClient: KMSClient;
  private keyCache: KeyCache;
  private encryptionService: EncryptionService;
  
  constructor(
    private config: EncryptionConfig
  ) {
    this.kmsClient = new KMSClient({ region: config.region });
    this.keyCache = new KeyCache();
    this.encryptionService = new EncryptionService(config.algorithm);
    
    this.initializeEncryption();
  }
  
  // í•„ë“œ ë ˆë²¨ ì•”í˜¸í™”
  async encryptSensitiveFields(
    data: any,
    entityType: string
  ): Promise<any> {
    const encryptionConfig = this.getFieldConfig(entityType);
    if (!encryptionConfig) return data;
    
    const encrypted = { ...data };
    
    for (const field of encryptionConfig.fields) {
      if (data[field.name] !== undefined) {
        encrypted[field.name] = await this.encryptField(
          data[field.name],
          field
        );
      }
    }
    
    // ì•”í˜¸í™” ë©”íƒ€ë°ì´í„° ì¶”ê°€
    encrypted._encryption = {
      version: this.config.version,
      timestamp: new Date(),
      fields: encryptionConfig.fields.map(f => f.name)
    };
    
    return encrypted;
  }
  
  // ê°œë³„ í•„ë“œ ì•”í˜¸í™”
  private async encryptField(
    value: any,
    fieldConfig: FieldConfig
  ): Promise<EncryptedField> {
    // ë°ì´í„° í‚¤ ìƒì„±/ìºì‹±
    const dataKey = await this.getOrGenerateDataKey(fieldConfig.keyId);
    
    // ê°’ ì§ë ¬í™”
    const serialized = this.serialize(value, fieldConfig.type);
    
    // ì•”í˜¸í™”
    const encrypted = await this.encryptionService.encrypt(
      serialized,
      dataKey.plaintext
    );
    
    return {
      ciphertext: encrypted.ciphertext,
      iv: encrypted.iv,
      authTag: encrypted.authTag,
      keyId: fieldConfig.keyId,
      algorithm: this.config.algorithm
    };
  }
  
  // ë°ì´í„° í‚¤ ê´€ë¦¬
  private async getOrGenerateDataKey(
    keyId: string
  ): Promise<DataKey> {
    // ìºì‹œ í™•ì¸
    let dataKey = await this.keyCache.get(keyId);
    
    if (!dataKey) {
      // KMSì—ì„œ ìƒˆ ë°ì´í„° í‚¤ ìƒì„±
      const response = await this.kmsClient.send(
        new GenerateDataKeyCommand({
          KeyId: this.config.kmsKeyId,
          KeySpec: 'AES_256'
        })
      );
      
      dataKey = {
        keyId,
        plaintext: response.Plaintext!,
        ciphertext: response.CiphertextBlob!,
        createdAt: new Date()
      };
      
      // ìºì‹œì— ì €ì¥
      await this.keyCache.set(keyId, dataKey, {
        ttl: 3600 // 1ì‹œê°„
      });
    }
    
    return dataKey;
  }
  
  // ë³µí˜¸í™”
  async decryptSensitiveFields(
    data: any,
    entityType: string
  ): Promise<any> {
    if (!data._encryption) return data;
    
    const decrypted = { ...data };
    delete decrypted._encryption;
    
    for (const fieldName of data._encryption.fields) {
      if (data[fieldName]) {
        decrypted[fieldName] = await this.decryptField(
          data[fieldName]
        );
      }
    }
    
    return decrypted;
  }
  
  // í‚¤ ë¡œí…Œì´ì…˜
  async rotateKeys(): Promise<KeyRotationResult> {
    const rotationPlan = await this.createRotationPlan();
    const results: RotationResult[] = [];
    
    for (const task of rotationPlan.tasks) {
      try {
        const result = await this.rotateKey(task);
        results.push(result);
      } catch (error) {
        results.push({
          keyId: task.keyId,
          success: false,
          error: error.message
        });
      }
    }
    
    return {
      totalKeys: rotationPlan.tasks.length,
      rotated: results.filter(r => r.success).length,
      failed: results.filter(r => !r.success).length,
      results
    };
  }
}

// íˆ¬ëª…í•œ ì•”í˜¸í™” í”„ë¡ì‹œ
export class TransparentEncryptionProxy {
  constructor(
    private encryptionManager: DataEncryptionManager,
    private dynamoClient: DynamoDBDocumentClient
  ) {}
  
  async putItem(params: PutItemInput): Promise<PutItemOutput> {
    // ìë™ ì•”í˜¸í™”
    const encryptedItem = await this.encryptionManager.encryptSensitiveFields(
      params.Item,
      params.TableName
    );
    
    return this.dynamoClient.put({
      ...params,
      Item: encryptedItem
    });
  }
  
  async getItem(params: GetItemInput): Promise<GetItemOutput> {
    const response = await this.dynamoClient.get(params);
    
    if (response.Item) {
      // ìë™ ë³µí˜¸í™”
      response.Item = await this.encryptionManager.decryptSensitiveFields(
        response.Item,
        params.TableName
      );
    }
    
    return response;
  }
  
  async query(params: QueryInput): Promise<QueryOutput> {
    const response = await this.dynamoClient.query(params);
    
    if (response.Items) {
      // ëª¨ë“  í•­ëª© ë³µí˜¸í™”
      response.Items = await Promise.all(
        response.Items.map(item => 
          this.encryptionManager.decryptSensitiveFields(
            item,
            params.TableName
          )
        )
      );
    }
    
    return response;
  }
}

// ì•”í˜¸í™” ì„œë¹„ìŠ¤
export class EncryptionService {
  constructor(
    private algorithm: string
  ) {}
  
  async encrypt(
    plaintext: Buffer,
    key: Buffer
  ): Promise<EncryptedData> {
    const iv = crypto.randomBytes(16);
    const cipher = crypto.createCipheriv(this.algorithm, key, iv);
    
    const encrypted = Buffer.concat([
      cipher.update(plaintext),
      cipher.final()
    ]);
    
    return {
      ciphertext: encrypted,
      iv,
      authTag: (cipher as any).getAuthTag()
    };
  }
  
  async decrypt(
    encryptedData: EncryptedData,
    key: Buffer
  ): Promise<Buffer> {
    const decipher = crypto.createDecipheriv(
      this.algorithm,
      key,
      encryptedData.iv
    );
    
    (decipher as any).setAuthTag(encryptedData.authTag);
    
    return Buffer.concat([
      decipher.update(encryptedData.ciphertext),
      decipher.final()
    ]);
  }
}
```

### SubTask 2.15.2: ì „ì†¡ ì¤‘ ë°ì´í„° ì•”í˜¸í™”
**ë‹´ë‹¹ì**: ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ëª¨ë“  ë„¤íŠ¸ì›Œí¬ í†µì‹ ì—ì„œ ë°ì´í„° ì•”í˜¸í™” êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/encryption/transport-encryption.ts
import tls from 'tls';
import { Agent } from 'https';

export class TransportEncryptionManager {
  private tlsConfig: TLSConfig;
  private certificateManager: CertificateManager;
  private securityHeaders: SecurityHeadersManager;
  
  constructor(
    private config: TransportSecurityConfig
  ) {
    this.tlsConfig = new TLSConfig(config.tls);
    this.certificateManager = new CertificateManager();
    this.securityHeaders = new SecurityHeadersManager();
    
    this.initializeTransportSecurity();
  }
  
  // HTTPS ì—ì´ì „íŠ¸ ìƒì„±
  createSecureAgent(): Agent {
    return new Agent({
      minVersion: 'TLSv1.2',
      ciphers: this.tlsConfig.getSecureCiphers(),
      rejectUnauthorized: true,
      cert: this.certificateManager.getClientCert(),
      key: this.certificateManager.getClientKey(),
      ca: this.certificateManager.getCACerts()
    });
  }
  
  // ìƒí˜¸ TLS ì„¤ì •
  setupMutualTLS(options: MutualTLSOptions): tls.Server {
    return tls.createServer({
      cert: this.certificateManager.getServerCert(),
      key: this.certificateManager.getServerKey(),
      ca: this.certificateManager.getClientCACerts(),
      requestCert: true,
      rejectUnauthorized: true,
      ciphers: this.tlsConfig.getSecureCiphers(),
      minVersion: 'TLSv1.2'
    }, (socket) => {
      // í´ë¼ì´ì–¸íŠ¸ ì¸ì¦ì„œ ê²€ì¦
      const cert = socket.getPeerCertificate();
      if (this.validateClientCertificate(cert)) {
        this.handleSecureConnection(socket);
      } else {
        socket.destroy();
      }
    });
  }
  
  // ë³´ì•ˆ í—¤ë” ë¯¸ë“¤ì›¨ì–´
  securityHeadersMiddleware() {
    return (req: any, res: any, next: any) => {
      // HSTS
      res.setHeader(
        'Strict-Transport-Security',
        'max-age=31536000; includeSubDomains; preload'
      );
      
      // Certificate Pinning
      res.setHeader(
        'Public-Key-Pins',
        this.generatePinningHeader()
      );
      
      // Content Security Policy
      res.setHeader(
        'Content-Security-Policy',
        this.generateCSPHeader()
      );
      
      // ê¸°íƒ€ ë³´ì•ˆ í—¤ë”
      res.setHeader('X-Content-Type-Options', 'nosniff');
      res.setHeader('X-Frame-Options', 'DENY');
      res.setHeader('X-XSS-Protection', '1; mode=block');
      
      next();
    };
  }
  
  // API ê²Œì´íŠ¸ì›¨ì´ ë³´ì•ˆ
  async secureAPIGateway(
    request: APIRequest
  ): Promise<SecuredAPIRequest> {
    // ìš”ì²­ ì•”í˜¸í™”
    const encryptedPayload = await this.encryptPayload(
      request.body,
      request.headers['x-api-key']
    );
    
    // HMAC ì„œëª… ì¶”ê°€
    const signature = this.generateHMAC(
      encryptedPayload,
      request.headers['x-api-key']
    );
    
    return {
      ...request,
      body: encryptedPayload,
      headers: {
        ...request.headers,
        'X-Signature': signature,
        'X-Timestamp': Date.now().toString(),
        'X-Nonce': this.generateNonce()
      }
    };
  }
  
  // WebSocket ë³´ì•ˆ
  setupSecureWebSocket(ws: WebSocket): SecureWebSocket {
    // ì•”í˜¸í™” ë ˆì´ì–´ ì¶”ê°€
    const secureWS = new SecureWebSocket(ws);
    
    // ë©”ì‹œì§€ ì•”í˜¸í™”/ë³µí˜¸í™”
    secureWS.on('message', async (encryptedMessage) => {
      const decrypted = await this.decryptWSMessage(encryptedMessage);
      secureWS.emit('decrypted-message', decrypted);
    });
    
    secureWS.send = async (data: any) => {
      const encrypted = await this.encryptWSMessage(data);
      ws.send(encrypted);
    };
    
    return secureWS;
  }
  
  // ì¸ì¦ì„œ ê²€ì¦
  private validateClientCertificate(
    cert: tls.PeerCertificate
  ): boolean {
    // CN ê²€ì¦
    if (!this.isValidCN(cert.subject.CN)) {
      return false;
    }
    
    // ì¸ì¦ì„œ ì²´ì¸ ê²€ì¦
    if (!this.validateCertificateChain(cert)) {
      return false;
    }
    
    // ì¸ì¦ì„œ í•´ì§€ ëª©ë¡ í™•ì¸
    if (this.isRevoked(cert)) {
      return false;
    }
    
    // ì¸ì¦ì„œ ìœ íš¨ê¸°ê°„ í™•ì¸
    if (!this.isValidPeriod(cert)) {
      return false;
    }
    
    return true;
  }
}

// TLS ì„¤ì • ê´€ë¦¬
export class TLSConfig {
  private secureCiphers = [
    'ECDHE-RSA-AES256-GCM-SHA384',
    'ECDHE-RSA-AES128-GCM-SHA256',
    'ECDHE-RSA-AES256-SHA384',
    'ECDHE-RSA-AES128-SHA256'
  ];
  
  getSecureCiphers(): string {
    return this.secureCiphers.join(':');
  }
  
  generateDHParams(): Buffer {
    // 2048ë¹„íŠ¸ DH íŒŒë¼ë¯¸í„° ìƒì„±
    return crypto.generateKeyPairSync('dh', {
      primeLength: 2048
    }).publicKey.export({ type: 'spki', format: 'der' });
  }
}

// ì—”ë“œíˆ¬ì—”ë“œ ì•”í˜¸í™”
export class EndToEndEncryption {
  async establishSecureChannel(
    clientPublicKey: string
  ): Promise<SecureChannel> {
    // ECDH í‚¤ êµí™˜
    const serverKeyPair = crypto.generateKeyPairSync('ec', {
      namedCurve: 'P-256'
    });
    
    // ê³µìœ  ë¹„ë°€ ìƒì„±
    const sharedSecret = crypto.diffieHellman({
      privateKey: serverKeyPair.privateKey,
      publicKey: crypto.createPublicKey(clientPublicKey)
    });
    
    // ì„¸ì…˜ í‚¤ ë„ì¶œ
    const sessionKey = crypto.hkdfSync(
      'sha256',
      sharedSecret,
      'salt',
      'info',
      32
    );
    
    return {
      sessionId: uuidv4(),
      sessionKey,
      serverPublicKey: serverKeyPair.publicKey.export({
        type: 'spki',
        format: 'pem'
      }),
      algorithm: 'aes-256-gcm',
      established: new Date()
    };
  }
}
```

### SubTask 2.15.3: ì ‘ê·¼ ì œì–´ ë° ê°ì‚¬
**ë‹´ë‹¹ì**: ë³´ì•ˆ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì„¸ë¶„í™”ëœ ì ‘ê·¼ ì œì–´ì™€ í¬ê´„ì ì¸ ê°ì‚¬ ë¡œê¹… ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/access-control/access-controller.ts
export interface AccessControlPolicy {
  id: string;
  name: string;
  effect: 'allow' | 'deny';
  principals: Principal[];
  actions: string[];
  resources: string[];
  conditions?: Condition[];
}

export class AccessController {
  private policyEngine: PolicyEngine;
  private attributeResolver: AttributeResolver;
  private auditLogger: AuditLogger;
  
  constructor(
    private config: AccessControlConfig
  ) {
    this.policyEngine = new PolicyEngine();
    this.attributeResolver = new AttributeResolver();
    this.auditLogger = new AuditLogger();
    
    this.loadPolicies();
  }
  
  // ì ‘ê·¼ ê¶Œí•œ í™•ì¸
  async authorize(
    request: AccessRequest
  ): Promise<AccessDecision> {
    const startTime = Date.now();
    
    try {
      // 1. ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
      const context = await this.buildContext(request);
      
      // 2. ì ìš© ê°€ëŠ¥í•œ ì •ì±… ì°¾ê¸°
      const applicablePolicies = await this.findApplicablePolicies(
        context
      );
      
      // 3. ì •ì±… í‰ê°€
      const decision = await this.evaluatePolicies(
        applicablePolicies,
        context
      );
      
      // 4. ê°ì‚¬ ë¡œê¹…
      await this.auditLogger.logAccessDecision({
        request,
        context,
        decision,
        duration: Date.now() - startTime
      });
      
      return decision;
      
    } catch (error) {
      // ì—ëŸ¬ ì‹œ ê¸°ë³¸ ê±°ë¶€
      await this.auditLogger.logAccessError({
        request,
        error: error.message
      });
      
      return {
        allowed: false,
        reason: 'Authorization error',
        error: error.message
      };
    }
  }
  
  // ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
  private async buildContext(
    request: AccessRequest
  ): Promise<AccessContext> {
    // ì‚¬ìš©ì ì†ì„±
    const userAttributes = await this.attributeResolver.getUserAttributes(
      request.principalId
    );
    
    // ë¦¬ì†ŒìŠ¤ ì†ì„±
    const resourceAttributes = await this.attributeResolver.getResourceAttributes(
      request.resource
    );
    
    // í™˜ê²½ ì†ì„±
    const environmentAttributes = {
      sourceIp: request.sourceIp,
      timestamp: new Date(),
      mfaAuthenticated: request.mfaAuthenticated,
      sessionAge: request.sessionAge
    };
    
    return {
      principal: {
        id: request.principalId,
        type: request.principalType,
        attributes: userAttributes
      },
      action: request.action,
      resource: {
        id: request.resource,
        type: request.resourceType,
        attributes: resourceAttributes
      },
      environment: environmentAttributes
    };
  }
  
  // ì •ì±… í‰ê°€
  private async evaluatePolicies(
    policies: AccessControlPolicy[],
    context: AccessContext
  ): Promise<AccessDecision> {
    let explicitDeny = false;
    let explicitAllow = false;
    const matchedPolicies: string[] = [];
    
    for (const policy of policies) {
      // ì¡°ê±´ í‰ê°€
      if (policy.conditions) {
        const conditionsMet = await this.evaluateConditions(
          policy.conditions,
          context
        );
        
        if (!conditionsMet) continue;
      }
      
      matchedPolicies.push(policy.id);
      
      if (policy.effect === 'deny') {
        explicitDeny = true;
        break; // Explicit denyëŠ” ì¦‰ì‹œ ì¤‘ë‹¨
      } else if (policy.effect === 'allow') {
        explicitAllow = true;
      }
    }
    
    // ìµœì¢… ê²°ì •
    const allowed = explicitAllow && !explicitDeny;
    
    return {
      allowed,
      matchedPolicies,
      reason: this.generateDecisionReason(
        explicitAllow,
        explicitDeny,
        matchedPolicies
      )
    };
  }
  
  // ì¡°ê±´ í‰ê°€
  private async evaluateConditions(
    conditions: Condition[],
    context: AccessContext
  ): Promise<boolean> {
    for (const condition of conditions) {
      const met = await this.evaluateCondition(condition, context);
      if (!met) return false;
    }
    
    return true;
  }
  
  // ê°œë³„ ì¡°ê±´ í‰ê°€
  private async evaluateCondition(
    condition: Condition,
    context: AccessContext
  ): Promise<boolean> {
    const value = this.resolveValue(condition.key, context);
    
    switch (condition.operator) {
      case 'equals':
        return value === condition.value;
        
      case 'notEquals':
        return value !== condition.value;
        
      case 'contains':
        return Array.isArray(value) && 
               value.includes(condition.value);
        
      case 'ipMatch':
        return this.matchIPAddress(value, condition.value);
        
      case 'dateGreaterThan':
        return new Date(value) > new Date(condition.value);
        
      case 'dateLessThan':
        return new Date(value) < new Date(condition.value);
        
      default:
        throw new Error(`Unknown operator: ${condition.operator}`);
    }
  }
}

// ê°ì‚¬ ë¡œê±°
export class AuditLogger {
  private logStore: AuditLogStore;
  private encryptor: LogEncryptor;
  private alertManager: SecurityAlertManager;
  
  constructor() {
    this.logStore = new AuditLogStore();
    this.encryptor = new LogEncryptor();
    this.alertManager = new SecurityAlertManager();
  }
  
  async logAccessDecision(
    event: AccessDecisionEvent
  ): Promise<void> {
    const auditLog: AuditLog = {
      id: uuidv4(),
      timestamp: new Date(),
      eventType: 'ACCESS_DECISION',
      principalId: event.request.principalId,
      action: event.request.action,
      resource: event.request.resource,
      decision: event.decision.allowed ? 'ALLOW' : 'DENY',
      sourceIp: event.request.sourceIp,
      userAgent: event.request.userAgent,
      duration: event.duration,
      metadata: {
        matchedPolicies: event.decision.matchedPolicies,
        reason: event.decision.reason,
        context: event.context
      }
    };
    
    // ë¡œê·¸ ì•”í˜¸í™”
    const encryptedLog = await this.encryptor.encrypt(auditLog);
    
    // ì €ì¥
    await this.logStore.store(encryptedLog);
    
    // ì´ìƒ íŒ¨í„´ ê°ì§€
    await this.detectAnomalies(auditLog);
  }
  
  // ì´ìƒ íŒ¨í„´ ê°ì§€
  private async detectAnomalies(
    log: AuditLog
  ): Promise<void> {
    // ì—°ì† ê±°ë¶€
    const recentDenials = await this.getRecentDenials(
      log.principalId,
      5 // ìµœê·¼ 5ë¶„
    );
    
    if (recentDenials.length > 10) {
      await this.alertManager.raise({
        type: 'EXCESSIVE_DENIALS',
        severity: 'medium',
        principal: log.principalId,
        count: recentDenials.length
      });
    }
    
    // ë¹„ì •ìƒ ì ‘ê·¼ íŒ¨í„´
    if (await this.isUnusualAccess(log)) {
      await this.alertManager.raise({
        type: 'UNUSUAL_ACCESS_PATTERN',
        severity: 'high',
        details: log
      });
    }
    
    // ê¶Œí•œ ìƒìŠ¹ ì‹œë„
    if (this.isPrivilegeEscalation(log)) {
      await this.alertManager.raise({
        type: 'PRIVILEGE_ESCALATION_ATTEMPT',
        severity: 'critical',
        details: log
      });
    }
  }
}

// ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´ (RBAC)
export class RBACManager {
  private roleHierarchy: RoleHierarchy;
  private permissionRegistry: PermissionRegistry;
  
  async assignRole(
    principalId: string,
    roleId: string
  ): Promise<void> {
    // ì—­í•  ê²€ì¦
    const role = await this.getRole(roleId);
    if (!role) {
      throw new Error(`Role ${roleId} not found`);
    }
    
    // ìˆœí™˜ ì°¸ì¡° í™•ì¸
    if (await this.wouldCreateCycle(principalId, roleId)) {
      throw new Error('Role assignment would create circular dependency');
    }
    
    // ì—­í•  í• ë‹¹
    await this.roleStore.assignRole(principalId, roleId);
    
    // ê°ì‚¬ ë¡œê·¸
    await this.auditLogger.log({
      event: 'ROLE_ASSIGNED',
      principal: principalId,
      role: roleId,
      assignedBy: this.getCurrentUser()
    });
  }
  
  // ìœ íš¨ ê¶Œí•œ ê³„ì‚°
  async getEffectivePermissions(
    principalId: string
  ): Promise<Permission[]> {
    const roles = await this.getRoles(principalId);
    const permissions: Set<string> = new Set();
    
    // ì—­í•  ê³„ì¸µ êµ¬ì¡° íƒìƒ‰
    for (const role of roles) {
      const rolePermissions = await this.getRolePermissions(
        role,
        true // ìƒì†ëœ ê¶Œí•œ í¬í•¨
      );
      
      rolePermissions.forEach(p => permissions.add(p));
    }
    
    return Array.from(permissions).map(p => 
      this.permissionRegistry.get(p)
    );
  }
}
```

### SubTask 2.15.4: ê·œì • ì¤€ìˆ˜ ìë™í™”
**ë‹´ë‹¹ì**: ì»´í”Œë¼ì´ì–¸ìŠ¤ ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: GDPR, HIPAA, SOC2 ë“± ê·œì • ì¤€ìˆ˜ë¥¼ ìœ„í•œ ìë™í™” ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/compliance/compliance-automation.ts
export interface ComplianceFramework {
  name: 'GDPR' | 'HIPAA' | 'SOC2' | 'PCI-DSS' | 'ISO27001';
  requirements: ComplianceRequirement[];
  controls: ComplianceControl[];
  auditSchedule: AuditSchedule;
}

export class ComplianceAutomationManager {
  private frameworks: Map<string, ComplianceFramework> = new Map();
  private controlExecutor: ControlExecutor;
  private evidenceCollector: EvidenceCollector;
  private reportGenerator: ComplianceReportGenerator;
  
  constructor(
    private config: ComplianceConfig
  ) {
    this.controlExecutor = new ControlExecutor();
    this.evidenceCollector = new EvidenceCollector();
    this.reportGenerator = new ComplianceReportGenerator();
    
    this.loadComplianceFrameworks();
    this.scheduleAutomatedAudits();
  }
  
  // GDPR ì¤€ìˆ˜ ìë™í™”
  async ensureGDPRCompliance(): Promise<ComplianceResult> {
    const gdprControls = this.frameworks.get('GDPR')!.controls;
    const results: ControlResult[] = [];
    
    // ê°œì¸ì •ë³´ ì²˜ë¦¬ ë™ì˜
    results.push(
      await this.controlExecutor.execute(
        new ConsentManagementControl()
      )
    );
    
    // ë°ì´í„° ì ‘ê·¼ ê¶Œí•œ
    results.push(
      await this.controlExecutor.execute(
        new DataAccessRightsControl()
      )
    );
    
    // ì‚­ì œ ê¶Œí•œ (ìŠí ê¶Œë¦¬)
    results.push(
      await this.controlExecutor.execute(
        new RightToErasureControl()
      )
    );
    
    // ë°ì´í„° ì´ë™ì„±
    results.push(
      await this.controlExecutor.execute(
        new DataPortabilityControl()
      )
    );
    
    // ì¹¨í•´ í†µì§€
    results.push(
      await this.controlExecutor.execute(
        new BreachNotificationControl()
      )
    );
    
    return {
      framework: 'GDPR',
      compliant: results.every(r => r.passed),
      results,
      evidence: await this.collectGDPREvidence()
    };
  }
  
  // ë°ì´í„° ì‚­ì œ ìë™í™” (GDPR)
  async handleDataErasureRequest(
    request: ErasureRequest
  ): Promise<ErasureResult> {
    // 1. ìš”ì²­ ê²€ì¦
    await this.validateErasureRequest(request);
    
    // 2. ë°ì´í„° ì‹ë³„
    const dataMap = await this.identifyPersonalData(request.subjectId);
    
    // 3. ë²•ì  ë³´ì¡´ ìš”êµ¬ì‚¬í•­ í™•ì¸
    const retentionExceptions = await this.checkLegalRetention(
      dataMap
    );
    
    // 4. ì‚­ì œ ì‹¤í–‰
    const erasureResults = await this.executeErasure(
      dataMap,
      retentionExceptions
    );
    
    // 5. ì‚­ì œ ì¦ëª… ìƒì„±
    const certificate = await this.generateErasureCertificate(
      request,
      erasureResults
    );
    
    // 6. ê°ì‚¬ ë¡œê·¸
    await this.logErasureActivity(request, erasureResults);
    
    return {
      requestId: request.id,
      erasedData: erasureResults.erased,
      retainedData: erasureResults.retained,
      certificate,
      completedAt: new Date()
    };
  }
  
  // HIPAA ì¤€ìˆ˜ ìë™í™”
  async ensureHIPAACompliance(): Promise<ComplianceResult> {
    const controls: ControlResult[] = [];
    
    // PHI ì•”í˜¸í™”
    controls.push(
      await this.verifyPHIEncryption()
    );
    
    // ì ‘ê·¼ ì œì–´
    controls.push(
      await this.verifyAccessControls()
    );
    
    // ê°ì‚¬ ë¡œê·¸
    controls.push(
      await this.verifyAuditLogging()
    );
    
    // ë¬´ê²°ì„± ì œì–´
    controls.push(
      await this.verifyIntegrityControls()
    );
    
    // ì „ì†¡ ë³´ì•ˆ
    controls.push(
      await this.verifyTransmissionSecurity()
    );
    
    return {
      framework: 'HIPAA',
      compliant: controls.every(c => c.passed),
      results: controls
    };
  }
  
  // ìë™ ì»´í”Œë¼ì´ì–¸ìŠ¤ ìŠ¤ìº”
  async runComplianceScan(
    frameworks: string[]
  ): Promise<ComplianceScanResult> {
    const scanId = uuidv4();
    const results: FrameworkResult[] = [];
    
    for (const framework of frameworks) {
      const result = await this.scanFramework(framework);
      results.push(result);
      
      // ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
      await this.updateScanProgress(scanId, framework, result);
    }
    
    // ì¢…í•© ë³´ê³ ì„œ ìƒì„±
    const report = await this.reportGenerator.generateReport({
      scanId,
      frameworks: results,
      timestamp: new Date(),
      recommendations: this.generateRecommendations(results)
    });
    
    return {
      scanId,
      results,
      report,
      nextSteps: this.identifyRemediationSteps(results)
    };
  }
}

// ì¦ê±° ìˆ˜ì§‘ê¸°
export class EvidenceCollector {
  async collectGDPREvidence(): Promise<Evidence[]> {
    const evidence: Evidence[] = [];
    
    // ë™ì˜ ê¸°ë¡
    evidence.push(
      await this.collectConsentRecords()
    );
    
    // ë°ì´í„° ì²˜ë¦¬ í™œë™ ê¸°ë¡
    evidence.push(
      await this.collectProcessingRecords()
    );
    
    // ë°ì´í„° ë³´í˜¸ ì˜í–¥ í‰ê°€
    evidence.push(
      await this.collectDPIA()
    );
    
    // ì œ3ì ê³„ì•½
    evidence.push(
      await this.collectThirdPartyAgreements()
    );
    
    return evidence;
  }
  
  private async collectConsentRecords(): Promise<Evidence> {
    const records = await this.queryConsentDatabase();
    
    return {
      type: 'consent_records',
      description: 'User consent records for data processing',
      artifacts: records.map(r => ({
        id: r.id,
        timestamp: r.timestamp,
        hash: this.hashRecord(r)
      })),
      collectedAt: new Date()
    };
  }
}

// ì»´í”Œë¼ì´ì–¸ìŠ¤ ë³´ê³ ì„œ ìƒì„±ê¸°
export class ComplianceReportGenerator {
  async generateReport(
    data: ReportData
  ): Promise<ComplianceReport> {
    const report: ComplianceReport = {
      id: uuidv4(),
      generatedAt: new Date(),
      executive_summary: this.generateExecutiveSummary(data),
      detailed_findings: this.generateDetailedFindings(data),
      risk_assessment: this.assessRisks(data),
      remediation_plan: this.createRemediationPlan(data),
      evidence_links: this.compileEvidenceLinks(data)
    };
    
    // ë³´ê³ ì„œ ì„œëª…
    report.signature = await this.signReport(report);
    
    // ë³´ê³ ì„œ ì €ì¥
    await this.storeReport(report);
    
    return report;
  }
  
  private generateExecutiveSummary(
    data: ReportData
  ): ExecutiveSummary {
    const overallCompliance = this.calculateOverallCompliance(data);
    const criticalIssues = this.identifyCriticalIssues(data);
    
    return {
      overallScore: overallCompliance,
      status: overallCompliance > 90 ? 'Compliant' : 'Non-Compliant',
      criticalIssues: criticalIssues.length,
      keyFindings: this.summarizeKeyFindings(data),
      recommendations: this.topRecommendations(data, 3)
    };
  }
}

// ì§€ì†ì  ì»´í”Œë¼ì´ì–¸ìŠ¤ ëª¨ë‹ˆí„°
export class ContinuousComplianceMonitor {
  private monitors: Map<string, ComplianceMonitor> = new Map();
  
  constructor() {
    this.initializeMonitors();
  }
  
  private initializeMonitors(): void {
    // GDPR ëª¨ë‹ˆí„°
    this.monitors.set('gdpr', new GDPRMonitor());
    
    // HIPAA ëª¨ë‹ˆí„°
    this.monitors.set('hipaa', new HIPAAMonitor());
    
    // SOC2 ëª¨ë‹ˆí„°
    this.monitors.set('soc2', new SOC2Monitor());
  }
  
  async startMonitoring(): Promise<void> {
    for (const [framework, monitor] of this.monitors) {
      monitor.on('violation', async (violation) => {
        await this.handleViolation(framework, violation);
      });
      
      await monitor.start();
    }
  }
  
  private async handleViolation(
    framework: string,
    violation: ComplianceViolation
  ): Promise<void> {
    // ì¦‰ì‹œ ì•Œë¦¼
    await this.notifyCompliance íŒ€(violation);
    
    // ìë™ ìˆ˜ì • ì‹œë„
    if (violation.autoRemediable) {
      await this.attemptAutoRemediation(violation);
    }
    
    // ì¸ì‹œë˜íŠ¸ ìƒì„±
    await this.createComplianceIncident(framework, violation);
  }
}
```

ì´ë ‡ê²Œ Phase 2 ë°ì´í„° ë ˆì´ì–´ êµ¬í˜„ì˜ ëª¨ë“  15ê°œ Tasks (ê° 4ê°œ SubTasks)ê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!

ì „ì²´ êµ¬í˜„ ë‚´ìš©:
- **Task 2.1-2.3**: ë°ì´í„° ëª¨ë¸ë§ (DynamoDB ì„¤ê³„, ì—”í‹°í‹° ëª¨ë¸, ì¸ë±ìŠ¤ ì „ëµ)
- **Task 2.4-2.6**: ë°ì´í„° ì ‘ê·¼ ê³„ì¸µ (Repository íŒ¨í„´, ì¿¼ë¦¬ ë¹Œë”, íŠ¸ëœì­ì…˜)
- **Task 2.7-2.9**: ìºì‹± ë° ìµœì í™” (Redis ìºì‹±, ë¬´íš¨í™” ì „ëµ, ì¼ê´„ ì²˜ë¦¬)
- **Task 2.10-2.12**: ë°ì´í„° ë™ê¸°í™” (CDC, ì´ë²¤íŠ¸ ì†Œì‹±, ë©€í‹°ë¦¬ì „ ë³µì œ)
- **Task 2.13-2.15**: ë°±ì—… ë° ë³´ì•ˆ (ìë™ ë°±ì—…, ì¬í•´ ë³µêµ¬, ì•”í˜¸í™”/ì»´í”Œë¼ì´ì–¸ìŠ¤)

ê° TaskëŠ” ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ ìƒì„¸ ì½”ë“œì™€ í•¨ê»˜ ì‘ì„±ë˜ì—ˆìœ¼ë©°, AWS ì„œë¹„ìŠ¤ í†µí•©, ì„±ëŠ¥ ìµœì í™”, ë³´ì•ˆ, ê·œì • ì¤€ìˆ˜ ë“± ëª¨ë“  ì¸¡ë©´ì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.