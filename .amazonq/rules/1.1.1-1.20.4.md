# Phase 1: ì½”ì–´ ì¸í”„ë¼ êµ¬ì¶• - ì „ì²´ SubTask ì‘ì—…ì§€ì‹œ ë¬¸ì„œ

## ğŸ“‹ Phase 1 ê°œìš”
- **ëª©í‘œ**: AWS Agent Squad + Agno Framework ê¸°ë°˜ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì½”ì–´ êµ¬ì¶•
- **ë²”ìœ„**: 20ê°œ Tasks Ã— 4 SubTasks = 80ê°œ ì‘ì—… ë‹¨ìœ„
- **ê¸°ê°„**: ì˜ˆìƒ 8-10ì£¼

---

## ğŸ—ï¸ Phase 1 ì „ì²´ Task êµ¬ì¡°

### ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ (Tasks 1.1-1.4)
- Task 1.1: Agent Squad ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì„¤ì •
- Task 1.2: SupervisorAgent ì‹œìŠ¤í…œ êµ¬í˜„
- Task 1.3: íƒœìŠ¤í¬ ë¼ìš°íŒ… ì—”ì§„
- Task 1.4: ì›Œí¬í”Œë¡œìš° ì¡°ì • ì‹œìŠ¤í…œ

### Agno Framework í†µí•© (Tasks 1.5-1.8)
- Task 1.5: Agno ì½”ì–´ ì„¤ì¹˜ ë° ì„¤ì •
- Task 1.6: ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ
- Task 1.7: LLM ëª¨ë¸ í†µí•© ë ˆì´ì–´
- Task 1.8: ë©”ëª¨ë¦¬ ë° ìƒíƒœ ê´€ë¦¬

### Bedrock ëŸ°íƒ€ì„ í™˜ê²½ (Tasks 1.9-1.11)
- Task 1.9: AgentCore ëŸ°íƒ€ì„ êµ¬ì„±
- Task 1.10: ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ
- Task 1.11: ë³´ì•ˆ ë° ì¸ì¦ ë ˆì´ì–´

### ë°ì´í„° ì¸í”„ë¼ (Tasks 1.12-1.14)
- Task 1.12: DynamoDB ì—°ê²° ì„¤ì •
- Task 1.13: ìºì‹± ì‹œìŠ¤í…œ êµ¬ì¶•
- Task 1.14: ë©”ì‹œì§• í ì‹œìŠ¤í…œ

### ì‹œìŠ¤í…œ ì¸í”„ë¼ (Tasks 1.15-1.17)
- Task 1.15: ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
- Task 1.16: ì—ëŸ¬ ì²˜ë¦¬ í”„ë ˆì„ì›Œí¬
- Task 1.17: ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ

### í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (Tasks 1.18-1.20)
- Task 1.18: ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë„êµ¬
- Task 1.19: í†µí•© í…ŒìŠ¤íŠ¸ í™˜ê²½
- Task 1.20: CI/CD íŒŒì´í”„ë¼ì¸ ê¸°ì´ˆ

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 1.1: Agent Squad ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì„¤ì •

#### SubTask 1.1.1: Agent Squad ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì´ˆê¸° ì„¤ì •
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```bash
# Python í™˜ê²½
pip install agent-squad[aws]
pip install agent-squad[monitoring]

# TypeScript/JavaScript í™˜ê²½
npm install agent-squad
npm install @types/agent-squad --save-dev
```

**ì„¤ì • íŒŒì¼ ìƒì„±**:
```typescript
// backend/src/config/agent-squad.config.ts
export const agentSquadConfig = {
  orchestrator: {
    maxConcurrentAgents: 50,
    timeout: 300000, // 5ë¶„
    retryPolicy: {
      maxAttempts: 3,
      backoffMultiplier: 2
    }
  },
  monitoring: {
    enabled: true,
    metricsEndpoint: '/metrics',
    healthCheckInterval: 30000
  },
  storage: {
    type: 'dynamodb',
    region: process.env.AWS_REGION,
    tableName: 't-developer-agents'
  }
};
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] Agent Squad íŒ¨í‚¤ì§€ ì •ìƒ ì„¤ì¹˜
- [ ] ì„¤ì • íŒŒì¼ ë¡œë“œ í™•ì¸
- [ ] ê¸°ë³¸ orchestrator ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ

#### SubTask 1.1.2: ê¸°ë³¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° êµ¬í˜„
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/orchestration/base_orchestrator.py
from agent_squad import AgentSquad, Agent
from typing import Dict, List, Any
import asyncio

class BaseOrchestrator:
    def __init__(self):
        self.squad = AgentSquad()
        self.agent_registry: Dict[str, Agent] = {}
        self.active_sessions: Dict[str, Any] = {}
        
    async def initialize(self):
        """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”"""
        await self.squad.initialize()
        await self.register_default_agents()
        
    async def register_agent(self, name: str, agent: Agent):
        """ì—ì´ì „íŠ¸ ë“±ë¡"""
        self.agent_registry[name] = agent
        await self.squad.add_agent(agent)
        
    async def route_task(self, task: Dict[str, Any]) -> Any:
        """íƒœìŠ¤í¬ ë¼ìš°íŒ…"""
        agent_name = self.determine_agent(task)
        if agent_name in self.agent_registry:
            return await self.agent_registry[agent_name].execute(task)
        raise ValueError(f"No agent found for task: {task}")
```

#### SubTask 1.1.3: ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/agent-registry.ts
interface AgentMetadata {
  name: string;
  version: string;
  capabilities: string[];
  maxConcurrent: number;
  timeout: number;
}

class AgentRegistry {
  private agents: Map<string, AgentMetadata> = new Map();
  private instances: Map<string, any> = new Map();
  
  async register(metadata: AgentMetadata): Promise<void> {
    this.agents.set(metadata.name, metadata);
    await this.persistToDatabase(metadata);
  }
  
  async getAgent(name: string): Promise<any> {
    if (!this.instances.has(name)) {
      await this.instantiateAgent(name);
    }
    return this.instances.get(name);
  }
  
  private async instantiateAgent(name: string): Promise<void> {
    const metadata = this.agents.get(name);
    if (!metadata) throw new Error(`Agent ${name} not found`);
    
    // Dynamic import and instantiation
    const AgentClass = await import(`../agents/${name}`);
    this.instances.set(name, new AgentClass.default(metadata));
  }
}
```

#### SubTask 1.1.4: í—¬ìŠ¤ì²´í¬ ë° ëª¨ë‹ˆí„°ë§ í†µí•©
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/monitoring/health_check.py
class OrchestratorHealthCheck:
    def __init__(self, orchestrator):
        self.orchestrator = orchestrator
        self.metrics = {
            'active_agents': 0,
            'queued_tasks': 0,
            'completed_tasks': 0,
            'failed_tasks': 0,
            'avg_response_time': 0
        }
    
    async def check_health(self) -> Dict[str, Any]:
        return {
            'status': 'healthy' if self.is_healthy() else 'unhealthy',
            'timestamp': datetime.utcnow().isoformat(),
            'metrics': await self.collect_metrics(),
            'agents': await self.check_agent_health()
        }
    
    async def collect_metrics(self):
        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë¡œì§
        pass
```

---

### Task 1.2: SupervisorAgent ì‹œìŠ¤í…œ êµ¬í˜„

#### SubTask 1.2.1: SupervisorAgent ì•„í‚¤í…ì²˜ ì„¤ê³„
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/agents/supervisor/supervisor_agent.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any
import asyncio

class SupervisorAgent(ABC):
    """ëª¨ë“  ì‘ì—…ì„ ê°ë…í•˜ê³  ì¡°ì •í•˜ëŠ” ìµœìƒìœ„ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.sub_agents: Dict[str, Agent] = {}
        self.workflow_engine = WorkflowEngine()
        self.decision_engine = DecisionEngine()
        
    async def analyze_request(self, request: Dict[str, Any]) -> WorkflowPlan:
        """ìš”ì²­ ë¶„ì„ ë° ì›Œí¬í”Œë¡œìš° ê³„íš ìˆ˜ë¦½"""
        # NLPë¥¼ ì‚¬ìš©í•œ ìš”ì²­ ë¶„ì„
        intent = await self.extract_intent(request)
        
        # í•„ìš”í•œ ì—ì´ì „íŠ¸ ê²°ì •
        required_agents = await self.decision_engine.determine_agents(intent)
        
        # ì›Œí¬í”Œë¡œìš° ìƒì„±
        workflow = await self.workflow_engine.create_workflow(
            intent, required_agents
        )
        
        return workflow
        
    async def execute_workflow(self, workflow: WorkflowPlan) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ë° ì¡°ì •"""
        results = {}
        
        for step in workflow.steps:
            if step.parallel:
                # ë³‘ë ¬ ì‹¤í–‰
                tasks = [
                    self.execute_agent_task(agent, step.task)
                    for agent in step.agents
                ]
                step_results = await asyncio.gather(*tasks)
            else:
                # ìˆœì°¨ ì‹¤í–‰
                step_results = []
                for agent in step.agents:
                    result = await self.execute_agent_task(agent, step.task)
                    step_results.append(result)
            
            results[step.name] = step_results
            
        return results
```

#### SubTask 1.2.2: ì˜ì‚¬ê²°ì • ì—”ì§„ êµ¬í˜„
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/agents/supervisor/decision-engine.ts
interface Decision {
  agentName: string;
  confidence: number;
  reasoning: string;
  alternativeAgents?: string[];
}

class DecisionEngine {
  private modelEndpoint: string;
  private decisionHistory: Map<string, Decision[]> = new Map();
  
  async determineAgents(intent: Intent): Promise<Decision[]> {
    // 1. ê·œì¹™ ê¸°ë°˜ ë§¤ì¹­
    const ruleBasedAgents = this.matchByRules(intent);
    
    // 2. ML ê¸°ë°˜ ì˜ˆì¸¡
    const mlPredictions = await this.predictAgents(intent);
    
    // 3. íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ìµœì í™”
    const historicalPatterns = this.analyzeHistory(intent);
    
    // 4. ìµœì¢… ê²°ì •
    return this.combineDecisions(
      ruleBasedAgents,
      mlPredictions,
      historicalPatterns
    );
  }
  
  private matchByRules(intent: Intent): Decision[] {
    const rules = [
      { pattern: /code|implement|develop/, agents: ['CodeAgent'] },
      { pattern: /test|verify|validate/, agents: ['TestAgent'] },
      { pattern: /design|architect/, agents: ['DesignAgent'] },
      { pattern: /security|vulnerabilit/, agents: ['SecurityAgent'] }
    ];
    
    return rules
      .filter(rule => rule.pattern.test(intent.description))
      .map(rule => ({
        agentName: rule.agents[0],
        confidence: 0.8,
        reasoning: `Rule-based match: ${rule.pattern}`
      }));
  }
}
```

#### SubTask 1.2.3: ì›Œí¬í”Œë¡œìš° ì—”ì§„ ê°œë°œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 20ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/workflow/workflow_engine.py
from dataclasses import dataclass
from typing import List, Optional
from enum import Enum

class StepType(Enum):
    SEQUENTIAL = "sequential"
    PARALLEL = "parallel"
    CONDITIONAL = "conditional"

@dataclass
class WorkflowStep:
    id: str
    name: str
    type: StepType
    agents: List[str]
    dependencies: List[str]
    condition: Optional[str] = None
    timeout: int = 300

class WorkflowEngine:
    def __init__(self):
        self.templates = self.load_workflow_templates()
        self.validator = WorkflowValidator()
        
    async def create_workflow(
        self, 
        intent: Intent, 
        agents: List[str]
    ) -> Workflow:
        # 1. í…œí”Œë¦¿ ì„ íƒ
        template = self.select_template(intent)
        
        # 2. ì›Œí¬í”Œë¡œìš° ìƒì„±
        workflow = Workflow()
        
        if template:
            workflow = self.apply_template(template, agents)
        else:
            workflow = self.create_dynamic_workflow(intent, agents)
        
        # 3. ê²€ì¦
        await self.validator.validate(workflow)
        
        # 4. ìµœì í™”
        workflow = self.optimize_workflow(workflow)
        
        return workflow
    
    def create_dynamic_workflow(
        self, 
        intent: Intent, 
        agents: List[str]
    ) -> Workflow:
        """ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        steps = []
        
        # ì˜ì¡´ì„± ë¶„ì„
        dependencies = self.analyze_dependencies(agents)
        
        # ë³‘ë ¬í™” ê°€ëŠ¥í•œ ì‘ì—… ì‹ë³„
        parallel_groups = self.identify_parallel_tasks(dependencies)
        
        # ì›Œí¬í”Œë¡œìš° ìŠ¤í… ìƒì„±
        for group in parallel_groups:
            if len(group) > 1:
                step = WorkflowStep(
                    id=f"step_{len(steps)}",
                    name=f"Parallel execution: {', '.join(group)}",
                    type=StepType.PARALLEL,
                    agents=group,
                    dependencies=[]
                )
            else:
                step = WorkflowStep(
                    id=f"step_{len(steps)}",
                    name=f"Execute: {group[0]}",
                    type=StepType.SEQUENTIAL,
                    agents=group,
                    dependencies=[]
                )
            steps.append(step)
        
        return Workflow(steps=steps)
```

#### SubTask 1.2.4: ì‹¤í–‰ ìƒíƒœ ì¶”ì  ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/workflow/execution-tracker.ts
interface ExecutionState {
  workflowId: string;
  status: 'pending' | 'running' | 'completed' | 'failed';
  currentStep: string;
  startTime: Date;
  endTime?: Date;
  results: Map<string, any>;
  errors: Error[];
}

class ExecutionTracker {
  private states: Map<string, ExecutionState> = new Map();
  private eventEmitter: EventEmitter;
  
  async trackExecution(
    workflowId: string, 
    workflow: Workflow
  ): Promise<void> {
    const state: ExecutionState = {
      workflowId,
      status: 'pending',
      currentStep: workflow.steps[0].id,
      startTime: new Date(),
      results: new Map(),
      errors: []
    };
    
    this.states.set(workflowId, state);
    this.emitUpdate(workflowId, state);
    
    // ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ WebSocket ì—°ê²°
    this.setupRealtimeUpdates(workflowId);
  }
  
  async updateStepProgress(
    workflowId: string,
    stepId: string,
    progress: number
  ): Promise<void> {
    const state = this.states.get(workflowId);
    if (!state) return;
    
    state.currentStep = stepId;
    this.emitUpdate(workflowId, {
      ...state,
      progress
    });
  }
  
  private setupRealtimeUpdates(workflowId: string): void {
    // WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
    this.eventEmitter.on(`progress:${workflowId}`, (data) => {
      this.broadcast(workflowId, {
        type: 'progress',
        data
      });
    });
  }
}
```

---

### Task 1.3: íƒœìŠ¤í¬ ë¼ìš°íŒ… ì—”ì§„

#### SubTask 1.3.1: ì§€ëŠ¥í˜• ë¼ìš°íŒ… ì•Œê³ ë¦¬ì¦˜
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/routing/intelligent_router.py
import numpy as np
from sklearn.preprocessing import StandardScaler
from typing import List, Tuple

class IntelligentRouter:
    def __init__(self):
        self.routing_model = self.load_routing_model()
        self.feature_extractor = FeatureExtractor()
        self.load_balancer = LoadBalancer()
        
    async def route_task(self, task: Task) -> Agent:
        """íƒœìŠ¤í¬ë¥¼ ê°€ì¥ ì ì ˆí•œ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…"""
        
        # 1. íŠ¹ì§• ì¶”ì¶œ
        features = await self.feature_extractor.extract(task)
        
        # 2. ì—ì´ì „íŠ¸ ì ìˆ˜ ê³„ì‚°
        agent_scores = await self.calculate_agent_scores(features)
        
        # 3. ë¡œë“œ ë°¸ëŸ°ì‹± ê³ ë ¤
        available_agents = await self.load_balancer.get_available_agents()
        
        # 4. ìµœì¢… ì„ íƒ
        selected_agent = self.select_best_agent(
            agent_scores, 
            available_agents
        )
        
        # 5. ë¼ìš°íŒ… ê¸°ë¡
        await self.record_routing_decision(task, selected_agent)
        
        return selected_agent
    
    async def calculate_agent_scores(
        self, 
        features: np.ndarray
    ) -> List[Tuple[str, float]]:
        """ê° ì—ì´ì „íŠ¸ì˜ ì í•©ë„ ì ìˆ˜ ê³„ì‚°"""
        
        # ML ëª¨ë¸ ì˜ˆì¸¡
        predictions = self.routing_model.predict_proba(features)
        
        # ì—ì´ì „íŠ¸ë³„ ì ìˆ˜
        agent_scores = []
        for idx, agent_name in enumerate(self.agent_names):
            score = predictions[0][idx]
            
            # ê³¼ê±° ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ì ìš©
            historical_weight = await self.get_historical_performance(
                agent_name
            )
            adjusted_score = score * historical_weight
            
            agent_scores.append((agent_name, adjusted_score))
        
        return sorted(agent_scores, key=lambda x: x[1], reverse=True)
```

#### SubTask 1.3.2: ë¡œë“œ ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/routing/load-balancer.ts
interface AgentLoad {
  agentId: string;
  currentTasks: number;
  cpuUsage: number;
  memoryUsage: number;
  avgResponseTime: number;
  capacity: number;
}

class LoadBalancer {
  private agentLoads: Map<string, AgentLoad> = new Map();
  private strategy: BalancingStrategy;
  
  constructor(strategy: BalancingStrategy = 'weighted-round-robin') {
    this.strategy = strategy;
    this.startMonitoring();
  }
  
  async getAvailableAgents(): Promise<string[]> {
    const agents = Array.from(this.agentLoads.entries());
    
    // ìš©ëŸ‰ì´ ë‚¨ì€ ì—ì´ì „íŠ¸ í•„í„°ë§
    const available = agents.filter(([_, load]) => 
      load.currentTasks < load.capacity * 0.8
    );
    
    // ì „ëµì— ë”°ë¼ ì •ë ¬
    switch (this.strategy) {
      case 'least-connections':
        return this.sortByLeastConnections(available);
      case 'weighted-round-robin':
        return this.weightedRoundRobin(available);
      case 'resource-based':
        return this.sortByResourceUsage(available);
      default:
        return available.map(([id]) => id);
    }
  }
  
  private sortByResourceUsage(
    agents: [string, AgentLoad][]
  ): string[] {
    return agents
      .sort((a, b) => {
        const scoreA = this.calculateResourceScore(a[1]);
        const scoreB = this.calculateResourceScore(b[1]);
        return scoreA - scoreB;
      })
      .map(([id]) => id);
  }
  
  private calculateResourceScore(load: AgentLoad): number {
    // ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¢…í•© ì ìˆ˜
    return (
      load.cpuUsage * 0.4 +
      load.memoryUsage * 0.3 +
      (load.currentTasks / load.capacity) * 0.3
    );
  }
}
```

#### SubTask 1.3.3: íƒœìŠ¤í¬ ìš°ì„ ìˆœìœ„ ê´€ë¦¬
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/routing/priority_manager.py
from enum import Enum
from heapq import heappush, heappop
import time

class Priority(Enum):
    CRITICAL = 1
    HIGH = 2
    NORMAL = 3
    LOW = 4

class PriorityQueue:
    def __init__(self):
        self.queue = []
        self.task_map = {}
        
    def add_task(self, task: Task, priority: Priority):
        """ìš°ì„ ìˆœìœ„ íì— íƒœìŠ¤í¬ ì¶”ê°€"""
        # ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°
        priority_score = self.calculate_priority_score(task, priority)
        
        # í™ì— ì¶”ê°€
        heappush(self.queue, (priority_score, time.time(), task))
        self.task_map[task.id] = priority_score
        
    def get_next_task(self) -> Optional[Task]:
        """ë‹¤ìŒ ì‹¤í–‰í•  íƒœìŠ¤í¬ ë°˜í™˜"""
        while self.queue:
            _, _, task = heappop(self.queue)
            if task.id in self.task_map:
                del self.task_map[task.id]
                return task
        return None
    
    def calculate_priority_score(
        self, 
        task: Task, 
        priority: Priority
    ) -> float:
        """ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°"""
        base_score = priority.value
        
        # ëŒ€ê¸° ì‹œê°„ ê°€ì¤‘ì¹˜
        wait_time = time.time() - task.created_at
        wait_weight = min(wait_time / 300, 1.0)  # 5ë¶„ ì´ìƒ ëŒ€ê¸° ì‹œ ìµœëŒ€ ê°€ì¤‘ì¹˜
        
        # SLA ê°€ì¤‘ì¹˜
        sla_weight = 0
        if hasattr(task, 'sla_deadline'):
            time_to_deadline = task.sla_deadline - time.time()
            if time_to_deadline < 300:  # 5ë¶„ ì´ë‚´
                sla_weight = 2.0
        
        return base_score - (wait_weight + sla_weight)
```

#### SubTask 1.3.4: ë¼ìš°íŒ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/routing/routing-metrics.ts
interface RoutingMetrics {
  totalRequests: number;
  routingLatency: number[];
  agentUtilization: Map<string, number>;
  queueDepth: number;
  errorRate: number;
}

class RoutingMonitor {
  private metrics: RoutingMetrics;
  private metricsHistory: RoutingMetrics[] = [];
  
  async collectMetrics(): Promise<void> {
    this.metrics = {
      totalRequests: await this.getTotalRequests(),
      routingLatency: await this.getLatencyPercentiles(),
      agentUtilization: await this.getAgentUtilization(),
      queueDepth: await this.getQueueDepth(),
      errorRate: await this.getErrorRate()
    };
    
    // CloudWatchì— ë©”íŠ¸ë¦­ ì „ì†¡
    await this.publishToCloudWatch(this.metrics);
    
    // ì´ìƒ ê°ì§€
    await this.detectAnomalies(this.metrics);
  }
  
  private async detectAnomalies(
    metrics: RoutingMetrics
  ): Promise<void> {
    // ì§€ì—° ì‹œê°„ ì´ìƒ
    const p99Latency = metrics.routingLatency[99];
    if (p99Latency > 1000) {  // 1ì´ˆ ì´ˆê³¼
      await this.alert('High routing latency detected', {
        p99Latency,
        threshold: 1000
      });
    }
    
    // ì—ëŸ¬ìœ¨ ì´ìƒ
    if (metrics.errorRate > 0.05) {  // 5% ì´ˆê³¼
      await this.alert('High error rate in routing', {
        errorRate: metrics.errorRate,
        threshold: 0.05
      });
    }
  }
}
```

---

### Task 1.4: ì›Œí¬í”Œë¡œìš° ì¡°ì • ì‹œìŠ¤í…œ

#### SubTask 1.4.1: ë³‘ë ¬ ì‹¤í–‰ ì—”ì§„
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/workflow/parallel_executor.py
import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any

class ParallelExecutor:
    def __init__(self, max_workers: int = 50):
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.semaphore = asyncio.Semaphore(max_workers)
        self.task_tracker = TaskTracker()
        
    async def execute_parallel(
        self, 
        tasks: List[Task]
    ) -> List[Dict[str, Any]]:
        """ë³‘ë ¬ íƒœìŠ¤í¬ ì‹¤í–‰"""
        
        # ì˜ì¡´ì„± ê·¸ë˜í”„ ìƒì„±
        dependency_graph = self.build_dependency_graph(tasks)
        
        # ì‹¤í–‰ ìˆœì„œ ê²°ì •
        execution_order = self.topological_sort(dependency_graph)
        
        # ë³‘ë ¬ ì‹¤í–‰ ê·¸ë£¹ ìƒì„±
        parallel_groups = self.create_parallel_groups(
            execution_order, 
            dependency_graph
        )
        
        results = []
        for group in parallel_groups:
            # ê·¸ë£¹ ë‚´ íƒœìŠ¤í¬ ë³‘ë ¬ ì‹¤í–‰
            group_results = await self.execute_group(group)
            results.extend(group_results)
        
        return results
    
    async def execute_group(
        self, 
        group: List[Task]
    ) -> List[Dict[str, Any]]:
        """ê·¸ë£¹ ë‚´ íƒœìŠ¤í¬ ë³‘ë ¬ ì‹¤í–‰"""
        async with self.semaphore:
            tasks = []
            for task in group:
                # ê° íƒœìŠ¤í¬ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
                task_future = asyncio.create_task(
                    self.execute_single_task(task)
                )
                tasks.append(task_future)
            
            # ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì—ëŸ¬ ì²˜ë¦¬
            processed_results = []
            for idx, result in enumerate(results):
                if isinstance(result, Exception):
                    await self.handle_task_error(group[idx], result)
                    processed_results.append({
                        'task_id': group[idx].id,
                        'status': 'failed',
                        'error': str(result)
                    })
                else:
                    processed_results.append(result)
            
            return processed_results
```

#### SubTask 1.4.2: ì˜ì¡´ì„± ê´€ë¦¬ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/workflow/dependency-manager.ts
interface Dependency {
  taskId: string;
  dependsOn: string[];
  type: 'hard' | 'soft';
  condition?: string;
}

class DependencyManager {
  private dependencies: Map<string, Dependency> = new Map();
  private graph: DirectedGraph<string>;
  
  constructor() {
    this.graph = new DirectedGraph();
  }
  
  addDependency(dependency: Dependency): void {
    this.dependencies.set(dependency.taskId, dependency);
    
    // ê·¸ë˜í”„ì— ë…¸ë“œ ì¶”ê°€
    this.graph.addNode(dependency.taskId);
    
    // ì˜ì¡´ì„± ì—£ì§€ ì¶”ê°€
    for (const dep of dependency.dependsOn) {
      this.graph.addEdge(dep, dependency.taskId);
    }
    
    // ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
    if (this.graph.hasCycle()) {
      throw new Error(
        `Circular dependency detected for task: ${dependency.taskId}`
      );
    }
  }
  
  async canExecute(taskId: string): Promise<boolean> {
    const dependency = this.dependencies.get(taskId);
    if (!dependency) return true;
    
    // ëª¨ë“  ì˜ì¡´ì„± í™•ì¸
    for (const depId of dependency.dependsOn) {
      const depStatus = await this.getTaskStatus(depId);
      
      if (dependency.type === 'hard' && depStatus !== 'completed') {
        return false;
      }
      
      if (dependency.type === 'soft' && depStatus === 'failed') {
        // Soft ì˜ì¡´ì„±ì€ ì‹¤íŒ¨í•´ë„ ì§„í–‰ ê°€ëŠ¥
        console.warn(`Soft dependency ${depId} failed for ${taskId}`);
      }
    }
    
    // ì¡°ê±´ë¶€ ì˜ì¡´ì„± í‰ê°€
    if (dependency.condition) {
      return await this.evaluateCondition(dependency.condition);
    }
    
    return true;
  }
  
  getExecutionOrder(): string[] {
    // ìœ„ìƒ ì •ë ¬ë¡œ ì‹¤í–‰ ìˆœì„œ ê²°ì •
    return this.graph.topologicalSort();
  }
}
```

#### SubTask 1.4.3: ìƒíƒœ ë™ê¸°í™” ë©”ì»¤ë‹ˆì¦˜
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/workflow/state_synchronizer.py
import redis
import json
from typing import Dict, Any
import asyncio

class StateSynchronizer:
    def __init__(self):
        self.redis_client = redis.Redis(
            host=os.getenv('REDIS_HOST'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            decode_responses=True
        )
        self.state_locks = {}
        self.pubsub = self.redis_client.pubsub()
        
    async def sync_state(
        self, 
        workflow_id: str, 
        state: Dict[str, Any]
    ) -> None:
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë™ê¸°í™”"""
        
        # ë¶„ì‚° ë½ íšë“
        lock_key = f"lock:workflow:{workflow_id}"
        async with self.acquire_lock(lock_key):
            # í˜„ì¬ ìƒíƒœ ì½ê¸°
            current_state = await self.get_state(workflow_id)
            
            # ìƒíƒœ ë³‘í•©
            merged_state = self.merge_states(current_state, state)
            
            # ìƒíƒœ ì €ì¥
            await self.save_state(workflow_id, merged_state)
            
            # ë³€ê²½ ì‚¬í•­ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            await self.broadcast_state_change(workflow_id, merged_state)
    
    async def acquire_lock(
        self, 
        lock_key: str, 
        timeout: int = 30
    ) -> AsyncContextManager:
        """ë¶„ì‚° ë½ íšë“"""
        lock = self.redis_client.lock(
            lock_key,
            timeout=timeout,
            blocking_timeout=5
        )
        return lock
    
    def merge_states(
        self, 
        current: Dict[str, Any], 
        new: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ìƒíƒœ ë³‘í•© ë¡œì§"""
        merged = current.copy()
        
        for key, value in new.items():
            if key in merged and isinstance(merged[key], dict):
                # ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ ì¬ê·€ì  ë³‘í•©
                merged[key] = self.merge_states(merged[key], value)
            else:
                merged[key] = value
        
        merged['last_updated'] = datetime.utcnow().isoformat()
        return merged
```

#### SubTask 1.4.4: ì¥ì•  ë³µêµ¬ ë° ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/workflow/recovery-manager.ts
interface RecoveryStrategy {
  maxRetries: number;
  backoffMultiplier: number;
  maxBackoffSeconds: number;
  retryableErrors: string[];
}

class RecoveryManager {
  private strategies: Map<string, RecoveryStrategy> = new Map();
  private recoveryHistory: Map<string, any[]> = new Map();
  
  async handleFailure(
    task: Task,
    error: Error
  ): Promise<RecoveryAction> {
    const strategy = this.getStrategy(task.type);
    const history = this.getHistory(task.id);
    
    // ì¬ì‹œë„ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if (!this.isRetryable(error, strategy)) {
      return { action: 'fail', reason: 'Non-retryable error' };
    }
    
    // ì¬ì‹œë„ íšŸìˆ˜ í™•ì¸
    if (history.length >= strategy.maxRetries) {
      return { action: 'fail', reason: 'Max retries exceeded' };
    }
    
    // ë°±ì˜¤í”„ ê³„ì‚°
    const backoffTime = this.calculateBackoff(
      history.length,
      strategy
    );
    
    // ë³µêµ¬ ì•¡ì…˜ ê²°ì •
    return {
      action: 'retry',
      delaySeconds: backoffTime,
      attemptNumber: history.length + 1
    };
  }
  
  async executeRecovery(
    task: Task,
    action: RecoveryAction
  ): Promise<void> {
    switch (action.action) {
      case 'retry':
        await this.scheduleRetry(task, action.delaySeconds);
        break;
      case 'compensate':
        await this.executeCompensation(task);
        break;
      case 'fail':
        await this.handlePermanentFailure(task);
        break;
    }
  }
  
  private calculateBackoff(
    attemptNumber: number,
    strategy: RecoveryStrategy
  ): number {
    const backoff = Math.min(
      strategy.backoffMultiplier ** attemptNumber,
      strategy.maxBackoffSeconds
    );
    
    // Jitter ì¶”ê°€ë¡œ ì¬ì‹œë„ í­ì£¼ ë°©ì§€
    const jitter = Math.random() * 0.3 * backoff;
    return Math.floor(backoff + jitter);
  }
}
```

---

### Task 1.5: Agno ì½”ì–´ ì„¤ì¹˜ ë° ì„¤ì •

#### SubTask 1.5.1: Agno Framework ì„¤ì¹˜
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```bash
# Agno ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash

# Python í™˜ê²½
pip install agno
pip install agno[all]  # ëª¨ë“  í™•ì¥ ê¸°ëŠ¥ í¬í•¨
pip install agno[monitoring]
pip install agno[tracing]

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install pydantic>=2.0
pip install httpx>=0.24
pip install rich>=13.0
```

**ì„¤ì • íŒŒì¼**:
```python
# backend/src/config/agno_config.py
from agno import AgnoConfig
from agno.monitoring import MonitoringConfig
from agno.tracing import TracingConfig

AGNO_CONFIG = AgnoConfig(
    # ì„±ëŠ¥ ì„¤ì •
    performance={
        "instantiation_target_us": 3,  # 3Î¼s ëª©í‘œ
        "memory_target_kb": 6.5,        # 6.5KB ëª©í‘œ
        "enable_optimizations": True,
        "use_native_extensions": True
    },
    
    # ëª¨ë‹ˆí„°ë§ ì„¤ì •
    monitoring=MonitoringConfig(
        enabled=True,
        endpoint="https://agno.com/metrics",
        api_key=os.getenv("AGNO_API_KEY"),
        metrics_interval=30,
        custom_metrics=[
            "agent_instantiation_time",
            "memory_usage_per_agent",
            "total_active_agents"
        ]
    ),
    
    # íŠ¸ë ˆì´ì‹± ì„¤ì •
    tracing=TracingConfig(
        enabled=True,
        sample_rate=0.1,  # 10% ìƒ˜í”Œë§
        export_endpoint="https://agno.com/traces"
    ),
    
    # ë¦¬ì†ŒìŠ¤ ì œí•œ
    resources={
        "max_agents": 10000,
        "max_memory_per_agent_kb": 10,
        "agent_timeout_seconds": 300
    }
)
```

#### SubTask 1.5.2: ì„±ëŠ¥ ìµœì í™” ì„¤ì •
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/agno/performance_optimizer.py
import agno
from agno.optimizers import (
    MemoryOptimizer,
    InstantiationOptimizer,
    CacheOptimizer
)

class AgnoPerformanceOptimizer:
    def __init__(self):
        self.memory_optimizer = MemoryOptimizer()
        self.instantiation_optimizer = InstantiationOptimizer()
        self.cache_optimizer = CacheOptimizer()
        
    async def optimize_agent_creation(self):
        """ì—ì´ì „íŠ¸ ìƒì„± ìµœì í™”"""
        
        # 1. í”„ë¦¬ë¡œë“œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ëª¨ë“ˆ
        await self.preload_common_modules()
        
        # 2. ì—ì´ì „íŠ¸ í’€ ì´ˆê¸°í™”
        await self.initialize_agent_pool()
        
        # 3. JIT ì»´íŒŒì¼ í™œì„±í™”
        self.enable_jit_compilation()
        
        # 4. ë©”ëª¨ë¦¬ ì‚¬ì „ í• ë‹¹
        await self.preallocate_memory()
    
    def enable_jit_compilation(self):
        """JIT ì»´íŒŒì¼ í™œì„±í™”"""
        import numba
        
        # í•µì‹¬ í•¨ìˆ˜ë“¤ JIT ì»´íŒŒì¼
        @numba.jit(nopython=True, cache=True)
        def fast_agent_init(config):
            # ìµœì í™”ëœ ì´ˆê¸°í™” ë¡œì§
            pass
        
        agno.set_init_function(fast_agent_init)
    
    async def benchmark_performance(self):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        import time
        
        # ì¸ìŠ¤í„´ìŠ¤í™” ì‹œê°„ ì¸¡ì •
        start = time.perf_counter_ns()
        agent = agno.Agent()
        end = time.perf_counter_ns()
        
        instantiation_time_us = (end - start) / 1000
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        memory_before = process.memory_info().rss
        
        agents = [agno.Agent() for _ in range(1000)]
        
        memory_after = process.memory_info().rss
        memory_per_agent_kb = (memory_after - memory_before) / 1000 / 1024
        
        return {
            "instantiation_time_us": instantiation_time_us,
            "memory_per_agent_kb": memory_per_agent_kb,
            "target_met": (
                instantiation_time_us <= 3 and 
                memory_per_agent_kb <= 6.5
            )
        }
```

#### SubTask 1.5.3: Agno ì—ì´ì „íŠ¸ í’€ êµ¬í˜„
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/agno/agent-pool.ts
import { Agent as AgnoAgent } from 'agno';

interface PoolConfig {
  minSize: number;
  maxSize: number;
  idleTimeout: number;
  preWarm: boolean;
}

class AgentPool {
  private available: AgnoAgent[] = [];
  private inUse: Map<string, AgnoAgent> = new Map();
  private config: PoolConfig;
  
  constructor(config: PoolConfig) {
    this.config = config;
    if (config.preWarm) {
      this.warmUp();
    }
  }
  
  private async warmUp(): Promise<void> {
    // ë¯¸ë¦¬ ì—ì´ì „íŠ¸ ìƒì„±
    const promises = [];
    for (let i = 0; i < this.config.minSize; i++) {
      promises.push(this.createAgent());
    }
    
    const agents = await Promise.all(promises);
    this.available.push(...agents);
  }
  
  async getAgent(): Promise<AgnoAgent> {
    // ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ê°€ ìˆìœ¼ë©´ ë°˜í™˜
    if (this.available.length > 0) {
      const agent = this.available.pop()!;
      const id = this.generateId();
      this.inUse.set(id, agent);
      return agent;
    }
    
    // í’€ í¬ê¸° ì œí•œ í™•ì¸
    if (this.inUse.size >= this.config.maxSize) {
      throw new Error('Agent pool exhausted');
    }
    
    // ìƒˆ ì—ì´ì „íŠ¸ ìƒì„±
    const agent = await this.createAgent();
    const id = this.generateId();
    this.inUse.set(id, agent);
    
    return agent;
  }
  
  async releaseAgent(agentId: string): Promise<void> {
    const agent = this.inUse.get(agentId);
    if (!agent) return;
    
    this.inUse.delete(agentId);
    
    // ì—ì´ì „íŠ¸ ìƒíƒœ ì´ˆê¸°í™”
    await this.resetAgent(agent);
    
    // í’€ì— ë°˜í™˜
    if (this.available.length < this.config.maxSize) {
      this.available.push(agent);
    } else {
      // í’€ì´ ê°€ë“ ì°¨ë©´ ì—ì´ì „íŠ¸ ì œê±°
      await this.destroyAgent(agent);
    }
  }
  
  private async createAgent(): Promise<AgnoAgent> {
    // 3Î¼s ëª©í‘œë¡œ ìµœì í™”ëœ ìƒì„±
    const start = performance.now();
    const agent = new AgnoAgent({
      lightweight: true,
      skipValidation: true,
      useCache: true
    });
    const duration = performance.now() - start;
    
    // ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    if (duration > 0.003) {  // 3Î¼s
      console.warn(`Agent creation took ${duration}ms`);
    }
    
    return agent;
  }
}
```

#### SubTask 1.5.4: Agno ëª¨ë‹ˆí„°ë§ í†µí•©
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/agno/monitoring_integration.py
from agno.monitoring import AgnoMonitor
import prometheus_client
from typing import Dict, Any

class AgnoMonitoringIntegration:
    def __init__(self):
        self.agno_monitor = AgnoMonitor()
        self.setup_prometheus_metrics()
        
    def setup_prometheus_metrics(self):
        """Prometheus ë©”íŠ¸ë¦­ ì„¤ì •"""
        
        # ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤í™” ì‹œê°„
        self.instantiation_time = prometheus_client.Histogram(
            'agno_agent_instantiation_seconds',
            'Time to instantiate an Agno agent',
            buckets=(0.000001, 0.000003, 0.00001, 0.0001, 0.001)
        )
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        self.memory_usage = prometheus_client.Gauge(
            'agno_agent_memory_bytes',
            'Memory usage per agent in bytes'
        )
        
        # í™œì„± ì—ì´ì „íŠ¸ ìˆ˜
        self.active_agents = prometheus_client.Gauge(
            'agno_active_agents_total',
            'Total number of active agents'
        )
        
        # ì—ëŸ¬ìœ¨
        self.error_rate = prometheus_client.Counter(
            'agno_errors_total',
            'Total number of errors',
            ['error_type']
        )
    
    async def collect_metrics(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        metrics = await self.agno_monitor.get_metrics()
        
        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self.instantiation_time.observe(
            metrics.get('instantiation_time_us', 0) / 1_000_000
        )
        self.memory_usage.set(
            metrics.get('memory_per_agent_kb', 0) * 1024
        )
        self.active_agents.set(
            metrics.get('active_agents', 0)
        )
        
        # Agno ëŒ€ì‹œë³´ë“œë¡œ ì „ì†¡
        await self.send_to_agno_dashboard(metrics)
        
        return metrics
    
    async def send_to_agno_dashboard(
        self, 
        metrics: Dict[str, Any]
    ) -> None:
        """Agno ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œë¡œ ë©”íŠ¸ë¦­ ì „ì†¡"""
        
        # agno.com ìœ¼ë¡œ ë©”íŠ¸ë¦­ ì „ì†¡
        await self.agno_monitor.send_metrics({
            'timestamp': datetime.utcnow().isoformat(),
            'project_id': os.getenv('AGNO_PROJECT_ID'),
            'metrics': metrics,
            'metadata': {
                'environment': os.getenv('ENVIRONMENT', 'development'),
                'version': os.getenv('APP_VERSION', '1.0.0')
            }
        })
```

ì´ë ‡ê²Œ Phase 1ì˜ ì²˜ìŒ 5ê°œ Tasks (20ê°œ SubTasks)ì— ëŒ€í•œ ìƒì„¸í•œ ì‘ì—…ì§€ì‹œì„œë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. 

ë‚˜ë¨¸ì§€ 15ê°œ Tasks (Task 1.6 ~ Task 1.20)ë„ ê³„ì† ì‘ì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? ê° TaskëŠ” 4ê°œì˜ SubTasksë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ë‹¤ìŒê³¼ ê°™ì€ ì˜ì—­ì„ ë‹¤ë£¹ë‹ˆë‹¤:

- **Task 1.6-1.8**: ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬, LLM í†µí•©, ë©”ëª¨ë¦¬ ê´€ë¦¬
- **Task 1.9-1.11**: Bedrock ëŸ°íƒ€ì„, ì„¸ì…˜ ê´€ë¦¬, ë³´ì•ˆ
- **Task 1.12-1.14**: ë°ì´í„°ë² ì´ìŠ¤, ìºì‹±, ë©”ì‹œì§•
- **Task 1.15-1.17**: ë¡œê¹…, ì—ëŸ¬ ì²˜ë¦¬, ì„¤ì • ê´€ë¦¬
- **Task 1.18-1.20**: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸, í†µí•© í…ŒìŠ¤íŠ¸, CI/CD

### Task 1.6: ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ

#### SubTask 1.6.1: í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì—”ì§„
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/multimodal/text_processor.py
from agno.io import TextProcessor
from typing import Dict, List, Any
import tiktoken

class MultiModalTextProcessor:
    def __init__(self):
        self.processor = TextProcessor()
        self.tokenizers = self.load_tokenizers()
        self.preprocessors = self.load_preprocessors()
        
    async def process_text(
        self, 
        text: str, 
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        
        # 1. ì „ì²˜ë¦¬
        cleaned_text = await self.preprocess(text, options)
        
        # 2. í† í¬ë‚˜ì´ì§•
        tokens = await self.tokenize(cleaned_text, options.get('model'))
        
        # 3. ì²­í‚¹ (ê¸´ í…ìŠ¤íŠ¸ ë¶„í• )
        chunks = await self.chunk_text(
            cleaned_text, 
            tokens,
            options.get('max_tokens', 4096)
        )
        
        # 4. ì„ë² ë”© (ì„ íƒì )
        embeddings = None
        if options.get('generate_embeddings'):
            embeddings = await self.generate_embeddings(chunks)
        
        return {
            'original': text,
            'processed': cleaned_text,
            'tokens': tokens,
            'token_count': len(tokens),
            'chunks': chunks,
            'embeddings': embeddings
        }
    
    async def preprocess(
        self, 
        text: str, 
        options: Dict[str, Any]
    ) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        processed = text
        
        # ì •ê·œí™”
        if options.get('normalize'):
            processed = self.normalize_text(processed)
        
        # ë¯¼ê°ì •ë³´ ë§ˆìŠ¤í‚¹
        if options.get('mask_pii'):
            processed = await self.mask_sensitive_info(processed)
        
        # ì–¸ì–´ ê°ì§€ ë° ë²ˆì—­
        if options.get('translate'):
            language = await self.detect_language(processed)
            if language != options.get('target_language', 'en'):
                processed = await self.translate_text(
                    processed, 
                    language, 
                    options.get('target_language', 'en')
                )
        
        return processed
    
    async def chunk_text(
        self, 
        text: str, 
        tokens: List[int], 
        max_tokens: int
    ) -> List[str]:
        """ìŠ¤ë§ˆíŠ¸ í…ìŠ¤íŠ¸ ì²­í‚¹"""
        if len(tokens) <= max_tokens:
            return [text]
        
        chunks = []
        
        # ë¬¸ì¥ ê²½ê³„ ê¸°ë°˜ ì²­í‚¹
        sentences = self.split_sentences(text)
        current_chunk = []
        current_tokens = 0
        
        for sentence in sentences:
            sentence_tokens = self.count_tokens(sentence)
            
            if current_tokens + sentence_tokens > max_tokens:
                if current_chunk:
                    chunks.append(' '.join(current_chunk))
                current_chunk = [sentence]
                current_tokens = sentence_tokens
            else:
                current_chunk.append(sentence)
                current_tokens += sentence_tokens
        
        if current_chunk:
            chunks.append(' '.join(current_chunk))
        
        return chunks
```

#### SubTask 1.6.2: ì´ë¯¸ì§€ ì²˜ë¦¬ ì—”ì§„
**ë‹´ë‹¹ì**: ML ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/multimodal/image-processor.ts
import { ImageProcessor } from 'agno';
import sharp from 'sharp';
import * as tf from '@tensorflow/tfjs-node';

interface ImageProcessingOptions {
  resize?: { width: number; height: number };
  format?: 'jpeg' | 'png' | 'webp';
  quality?: number;
  extractText?: boolean;
  generateCaption?: boolean;
  detectObjects?: boolean;
}

class MultiModalImageProcessor {
  private processor: ImageProcessor;
  private ocrModel: any;
  private captionModel: any;
  private objectDetectionModel: any;
  
  constructor() {
    this.processor = new ImageProcessor();
    this.loadModels();
  }
  
  private async loadModels(): Promise<void> {
    // OCR ëª¨ë¸ ë¡œë“œ
    if (process.env.ENABLE_OCR === 'true') {
      this.ocrModel = await this.loadOCRModel();
    }
    
    // ìº¡ì…˜ ìƒì„± ëª¨ë¸ ë¡œë“œ
    if (process.env.ENABLE_CAPTION === 'true') {
      this.captionModel = await this.loadCaptionModel();
    }
    
    // ê°ì²´ ê²€ì¶œ ëª¨ë¸ ë¡œë“œ
    if (process.env.ENABLE_OBJECT_DETECTION === 'true') {
      this.objectDetectionModel = await tf.loadGraphModel(
        'https://tfhub.dev/tensorflow/tfjs-model/ssd_mobilenet_v2/1/default/1'
      );
    }
  }
  
  async processImage(
    imageBuffer: Buffer,
    options: ImageProcessingOptions
  ): Promise<any> {
    const results: any = {
      metadata: await this.extractMetadata(imageBuffer),
      processed: null
    };
    
    // ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•
    let processedBuffer = imageBuffer;
    if (options.resize) {
      processedBuffer = await sharp(imageBuffer)
        .resize(options.resize.width, options.resize.height)
        .toBuffer();
    }
    
    // í¬ë§· ë³€í™˜
    if (options.format) {
      processedBuffer = await sharp(processedBuffer)
        .toFormat(options.format, { quality: options.quality || 85 })
        .toBuffer();
    }
    
    results.processed = processedBuffer;
    
    // OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
    if (options.extractText && this.ocrModel) {
      results.extractedText = await this.extractText(processedBuffer);
    }
    
    // ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±
    if (options.generateCaption && this.captionModel) {
      results.caption = await this.generateCaption(processedBuffer);
    }
    
    // ê°ì²´ ê²€ì¶œ
    if (options.detectObjects && this.objectDetectionModel) {
      results.detectedObjects = await this.detectObjects(processedBuffer);
    }
    
    return results;
  }
  
  private async extractText(imageBuffer: Buffer): Promise<string> {
    // Tesseract.js ë˜ëŠ” ë‹¤ë¥¸ OCR ì—”ì§„ ì‚¬ìš©
    const Tesseract = require('tesseract.js');
    
    const { data: { text } } = await Tesseract.recognize(
      imageBuffer,
      'eng',
      {
        logger: m => console.log(m)
      }
    );
    
    return text;
  }
  
  private async generateCaption(imageBuffer: Buffer): Promise<string> {
    // ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
    const imageTensor = await this.imageToTensor(imageBuffer);
    
    // ìº¡ì…˜ ëª¨ë¸ ì‹¤í–‰
    const caption = await this.captionModel.generate(imageTensor);
    
    return caption;
  }
}
```

#### SubTask 1.6.3: ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ì²˜ë¦¬ ì—”ì§„
**ë‹´ë‹¹ì**: ë©€í‹°ë¯¸ë””ì–´ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 20ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/multimodal/audio_video_processor.py
import ffmpeg
import whisper
from typing import Dict, Any, Optional
import numpy as np

class AudioVideoProcessor:
    def __init__(self):
        self.whisper_model = whisper.load_model("base")
        self.ffmpeg_path = self.verify_ffmpeg()
        
    async def process_audio(
        self, 
        audio_path: str, 
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì˜¤ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        
        results = {
            'duration': None,
            'format': None,
            'transcript': None,
            'summary': None
        }
        
        # ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = await self.extract_audio_metadata(audio_path)
        results['duration'] = metadata['duration']
        results['format'] = metadata['format']
        
        # ìŒì„± ì¸ì‹ (STT)
        if options.get('transcribe', True):
            transcript = await self.transcribe_audio(audio_path)
            results['transcript'] = transcript
            
            # ìš”ì•½ ìƒì„±
            if options.get('summarize') and transcript:
                results['summary'] = await self.summarize_transcript(
                    transcript
                )
        
        # ì˜¤ë””ì˜¤ ë¶„ì„
        if options.get('analyze'):
            results['analysis'] = await self.analyze_audio(audio_path)
        
        return results
    
    async def transcribe_audio(self, audio_path: str) -> Dict[str, Any]:
        """Whisperë¥¼ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹"""
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = whisper.load_audio(audio_path)
        audio = whisper.pad_or_trim(audio)
        
        # ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒì„±
        mel = whisper.log_mel_spectrogram(audio).to(
            self.whisper_model.device
        )
        
        # ì–¸ì–´ ê°ì§€
        _, probs = self.whisper_model.detect_language(mel)
        detected_language = max(probs, key=probs.get)
        
        # ì „ì‚¬
        options = whisper.DecodingOptions(
            language=detected_language,
            fp16=False
        )
        result = whisper.decode(self.whisper_model, mel, options)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ì „ì‚¬
        full_result = self.whisper_model.transcribe(
            audio_path,
            language=detected_language,
            task='transcribe',
            verbose=False
        )
        
        return {
            'text': full_result['text'],
            'segments': full_result['segments'],
            'language': detected_language
        }
    
    async def process_video(
        self, 
        video_path: str, 
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        
        results = {
            'metadata': await self.extract_video_metadata(video_path),
            'frames': None,
            'audio_track': None,
            'scenes': None
        }
        
        # í‚¤ í”„ë ˆì„ ì¶”ì¶œ
        if options.get('extract_frames'):
            results['frames'] = await self.extract_key_frames(
                video_path,
                options.get('frame_count', 10)
            )
        
        # ì˜¤ë””ì˜¤ íŠ¸ë™ ì¶”ì¶œ ë° ì²˜ë¦¬
        if options.get('process_audio'):
            audio_path = await self.extract_audio_track(video_path)
            results['audio_track'] = await self.process_audio(
                audio_path,
                options.get('audio_options', {})
            )
        
        # ì”¬ ê°ì§€
        if options.get('detect_scenes'):
            results['scenes'] = await self.detect_scenes(video_path)
        
        return results
    
    async def extract_key_frames(
        self, 
        video_path: str, 
        frame_count: int
    ) -> List[np.ndarray]:
        """ë¹„ë””ì˜¤ì—ì„œ í‚¤ í”„ë ˆì„ ì¶”ì¶œ"""
        
        # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        probe = ffmpeg.probe(video_path)
        video_info = next(
            s for s in probe['streams'] 
            if s['codec_type'] == 'video'
        )
        
        duration = float(probe['format']['duration'])
        
        # ê· ë“± ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ ì¶”ì¶œ
        frames = []
        for i in range(frame_count):
            time = (duration / frame_count) * i
            
            out, _ = (
                ffmpeg
                .input(video_path, ss=time)
                .output('pipe:', vframes=1, format='rawvideo', pix_fmt='rgb24')
                .run(capture_stdout=True, quiet=True)
            )
            
            frame = np.frombuffer(out, np.uint8).reshape([
                int(video_info['height']),
                int(video_info['width']),
                3
            ])
            
            frames.append(frame)
        
        return frames
```

#### SubTask 1.6.4: í†µí•© ë©€í‹°ëª¨ë‹¬ API
**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/multimodal/unified-api.ts
interface MultiModalInput {
  type: 'text' | 'image' | 'audio' | 'video' | 'mixed';
  data: any;
  metadata?: any;
  options?: any;
}

interface MultiModalOutput {
  processed: any;
  insights: any[];
  recommendations?: any[];
  confidence: number;
}

class UnifiedMultiModalAPI {
  private textProcessor: MultiModalTextProcessor;
  private imageProcessor: MultiModalImageProcessor;
  private audioVideoProcessor: AudioVideoProcessor;
  
  constructor() {
    this.textProcessor = new MultiModalTextProcessor();
    this.imageProcessor = new MultiModalImageProcessor();
    this.audioVideoProcessor = new AudioVideoProcessor();
  }
  
  async process(input: MultiModalInput): Promise<MultiModalOutput> {
    switch (input.type) {
      case 'text':
        return await this.processText(input);
      case 'image':
        return await this.processImage(input);
      case 'audio':
        return await this.processAudio(input);
      case 'video':
        return await this.processVideo(input);
      case 'mixed':
        return await this.processMixed(input);
      default:
        throw new Error(`Unsupported input type: ${input.type}`);
    }
  }
  
  private async processMixed(
    input: MultiModalInput
  ): Promise<MultiModalOutput> {
    // ë³µí•© ëª¨ë‹¬ ì²˜ë¦¬
    const results = await Promise.all(
      input.data.map(async (item: any) => {
        return await this.process({
          type: item.type,
          data: item.data,
          options: item.options
        });
      })
    );
    
    // ê²°ê³¼ í†µí•©
    const insights = this.combineInsights(results);
    const recommendations = this.generateRecommendations(insights);
    
    return {
      processed: results,
      insights,
      recommendations,
      confidence: this.calculateConfidence(results)
    };
  }
  
  private combineInsights(results: MultiModalOutput[]): any[] {
    // ê° ëª¨ë‹¬ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ í†µí•©
    const insights = [];
    
    for (const result of results) {
      insights.push(...result.insights);
    }
    
    // ì¤‘ë³µ ì œê±° ë° ìš°ì„ ìˆœìœ„ ì •ë ¬
    return this.deduplicateAndPrioritize(insights);
  }
}
```

---

### Task 1.7: LLM ëª¨ë¸ í†µí•© ë ˆì´ì–´

#### SubTask 1.7.1: ëª¨ë¸ í”„ë¡œë°”ì´ë” ì¶”ìƒí™”
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/llm/model_provider_abstract.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional, AsyncIterator
from dataclasses import dataclass

@dataclass
class ModelConfig:
    name: str
    provider: str
    max_tokens: int
    temperature: float
    top_p: float
    frequency_penalty: float
    presence_penalty: float
    stop_sequences: List[str]

@dataclass
class ModelResponse:
    text: str
    tokens_used: int
    finish_reason: str
    metadata: Dict[str, Any]

class ModelProvider(ABC):
    """ëª¨ë“  LLM í”„ë¡œë°”ì´ë”ì˜ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config: ModelConfig):
        self.config = config
        self.client = None
        
    @abstractmethod
    async def initialize(self) -> None:
        """í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”"""
        pass
    
    @abstractmethod
    async def generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> ModelResponse:
        """í…ìŠ¤íŠ¸ ìƒì„±"""
        pass
    
    @abstractmethod
    async def stream_generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> AsyncIterator[str]:
        """ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ìƒì„±"""
        pass
    
    @abstractmethod
    async def embed(
        self, 
        texts: List[str]
    ) -> List[List[float]]:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        pass
    
    @abstractmethod
    def estimate_tokens(self, text: str) -> int:
        """í† í° ìˆ˜ ì¶”ì •"""
        pass
    
    @abstractmethod
    def get_cost_estimate(
        self, 
        input_tokens: int, 
        output_tokens: int
    ) -> float:
        """ë¹„ìš© ì¶”ì •"""
        pass

class ModelProviderFactory:
    """ëª¨ë¸ í”„ë¡œë°”ì´ë” íŒ©í† ë¦¬"""
    
    _providers: Dict[str, type] = {}
    
    @classmethod
    def register(cls, name: str, provider_class: type) -> None:
        """í”„ë¡œë°”ì´ë” ë“±ë¡"""
        cls._providers[name] = provider_class
    
    @classmethod
    def create(
        cls, 
        provider_name: str, 
        config: ModelConfig
    ) -> ModelProvider:
        """í”„ë¡œë°”ì´ë” ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        if provider_name not in cls._providers:
            raise ValueError(f"Unknown provider: {provider_name}")
        
        provider_class = cls._providers[provider_name]
        return provider_class(config)
```

#### SubTask 1.7.2: 25+ ëª¨ë¸ í”„ë¡œë°”ì´ë” êµ¬í˜„
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 24ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/llm/providers/openai_provider.py
import openai
from typing import AsyncIterator

class OpenAIProvider(ModelProvider):
    """OpenAI ëª¨ë¸ í”„ë¡œë°”ì´ë”"""
    
    async def initialize(self) -> None:
        self.client = openai.AsyncOpenAI(
            api_key=os.getenv("OPENAI_API_KEY")
        )
    
    async def generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> ModelResponse:
        options = options or {}
        
        response = await self.client.chat.completions.create(
            model=self.config.name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=options.get('max_tokens', self.config.max_tokens),
            temperature=options.get('temperature', self.config.temperature),
            top_p=options.get('top_p', self.config.top_p),
            frequency_penalty=options.get(
                'frequency_penalty', 
                self.config.frequency_penalty
            ),
            presence_penalty=options.get(
                'presence_penalty', 
                self.config.presence_penalty
            ),
            stop=options.get('stop', self.config.stop_sequences)
        )
        
        choice = response.choices[0]
        return ModelResponse(
            text=choice.message.content,
            tokens_used=response.usage.total_tokens,
            finish_reason=choice.finish_reason,
            metadata={
                'model': response.model,
                'created': response.created
            }
        )
    
    async def stream_generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> AsyncIterator[str]:
        options = options or {}
        
        stream = await self.client.chat.completions.create(
            model=self.config.name,
            messages=[{"role": "user", "content": prompt}],
            stream=True,
            **options
        )
        
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content

# backend/src/llm/providers/anthropic_provider.py
import anthropic

class AnthropicProvider(ModelProvider):
    """Anthropic Claude í”„ë¡œë°”ì´ë”"""
    
    async def initialize(self) -> None:
        self.client = anthropic.AsyncAnthropic(
            api_key=os.getenv("ANTHROPIC_API_KEY")
        )
    
    async def generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> ModelResponse:
        response = await self.client.messages.create(
            model=self.config.name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=self.config.max_tokens
        )
        
        return ModelResponse(
            text=response.content[0].text,
            tokens_used=response.usage.input_tokens + response.usage.output_tokens,
            finish_reason=response.stop_reason,
            metadata={'model': response.model}
        )

# backend/src/llm/providers/bedrock_provider.py
import boto3
import json

class BedrockProvider(ModelProvider):
    """AWS Bedrock í”„ë¡œë°”ì´ë”"""
    
    async def initialize(self) -> None:
        self.client = boto3.client(
            'bedrock-runtime',
            region_name=os.getenv('AWS_REGION')
        )
    
    async def generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> ModelResponse:
        # Bedrock API í˜¸ì¶œ
        body = json.dumps({
            "prompt": prompt,
            "max_tokens": self.config.max_tokens,
            "temperature": self.config.temperature,
            "top_p": self.config.top_p
        })
        
        response = self.client.invoke_model(
            modelId=self.config.name,
            body=body,
            accept='application/json',
            contentType='application/json'
        )
        
        result = json.loads(response['body'].read())
        
        return ModelResponse(
            text=result['completion'],
            tokens_used=result.get('token_count', 0),
            finish_reason=result.get('stop_reason', 'stop'),
            metadata={'model_id': self.config.name}
        )

# ì¶”ê°€ í”„ë¡œë°”ì´ë”ë“¤...
# - HuggingFaceProvider
# - CohereProvider
# - AI21Provider
# - GooglePaLMProvider
# - AlephAlphaProvider
# ... ì´ 25+ í”„ë¡œë°”ì´ë”
```

**í”„ë¡œë°”ì´ë” ë“±ë¡**:
```python
# backend/src/llm/providers/__init__.py

# ëª¨ë“  í”„ë¡œë°”ì´ë” ë“±ë¡
ModelProviderFactory.register('openai', OpenAIProvider)
ModelProviderFactory.register('anthropic', AnthropicProvider)
ModelProviderFactory.register('bedrock', BedrockProvider)
ModelProviderFactory.register('huggingface', HuggingFaceProvider)
ModelProviderFactory.register('cohere', CohereProvider)
ModelProviderFactory.register('ai21', AI21Provider)
ModelProviderFactory.register('google', GooglePaLMProvider)
# ... 25+ í”„ë¡œë°”ì´ë” ë“±ë¡
```

#### SubTask 1.7.3: ëª¨ë¸ ì„ íƒ ë° ë¼ìš°íŒ… ì—”ì§„
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/llm/model-router.ts
interface ModelCapabilities {
  contextLength: number;
  supportedLanguages: string[];
  specialties: string[];
  costPerToken: number;
  latency: 'low' | 'medium' | 'high';
  availability: number;  // 0-1
}

interface RoutingCriteria {
  taskType: string;
  requiredContext: number;
  targetLanguage?: string;
  maxCost?: number;
  maxLatency?: 'low' | 'medium' | 'high';
  requiredCapabilities?: string[];
}

class ModelRouter {
  private modelRegistry: Map<string, ModelCapabilities> = new Map();
  private performanceHistory: Map<string, any[]> = new Map();
  
  constructor() {
    this.initializeModelRegistry();
  }
  
  private initializeModelRegistry(): void {
    // ëª¨ë¸ ëŠ¥ë ¥ ë“±ë¡
    this.modelRegistry.set('gpt-4', {
      contextLength: 128000,
      supportedLanguages: ['all'],
      specialties: ['reasoning', 'coding', 'analysis'],
      costPerToken: 0.00003,
      latency: 'medium',
      availability: 0.99
    });
    
    this.modelRegistry.set('claude-3-opus', {
      contextLength: 200000,
      supportedLanguages: ['all'],
      specialties: ['long-context', 'analysis', 'creative'],
      costPerToken: 0.000015,
      latency: 'low',
      availability: 0.98
    });
    
    // ... 25+ ëª¨ë¸ ë“±ë¡
  }
  
  async selectModel(criteria: RoutingCriteria): Promise<string> {
    const candidates = this.filterCandidates(criteria);
    
    if (candidates.length === 0) {
      throw new Error('No suitable model found for criteria');
    }
    
    // ì ìˆ˜ ê³„ì‚°
    const scores = await this.scoreModels(candidates, criteria);
    
    // ìµœì  ëª¨ë¸ ì„ íƒ
    const bestModel = this.selectBestModel(scores);
    
    // ì„ íƒ ê¸°ë¡
    await this.recordSelection(bestModel, criteria);
    
    return bestModel;
  }
  
  private filterCandidates(criteria: RoutingCriteria): string[] {
    const candidates = [];
    
    for (const [model, capabilities] of this.modelRegistry) {
      // ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸
      if (capabilities.contextLength < criteria.requiredContext) {
        continue;
      }
      
      // ì–¸ì–´ ì§€ì› í™•ì¸
      if (criteria.targetLanguage && 
          !capabilities.supportedLanguages.includes('all') &&
          !capabilities.supportedLanguages.includes(criteria.targetLanguage)) {
        continue;
      }
      
      // ì§€ì—°ì‹œê°„ ìš”êµ¬ì‚¬í•­ í™•ì¸
      if (criteria.maxLatency) {
        const latencyOrder = ['low', 'medium', 'high'];
        if (latencyOrder.indexOf(capabilities.latency) > 
            latencyOrder.indexOf(criteria.maxLatency)) {
          continue;
        }
      }
      
      candidates.push(model);
    }
    
    return candidates;
  }
  
  private async scoreModels(
    candidates: string[], 
    criteria: RoutingCriteria
  ): Promise<Map<string, number>> {
    const scores = new Map<string, number>();
    
    for (const model of candidates) {
      const capabilities = this.modelRegistry.get(model)!;
      let score = 0;
      
      // ì „ë¬¸ì„± ì ìˆ˜
      const specialtyScore = this.calculateSpecialtyScore(
        capabilities.specialties,
        criteria.taskType
      );
      score += specialtyScore * 0.3;
      
      // ë¹„ìš© ì ìˆ˜
      if (criteria.maxCost) {
        const costScore = 1 - (capabilities.costPerToken / criteria.maxCost);
        score += Math.max(0, costScore) * 0.2;
      }
      
      // ì„±ëŠ¥ ì´ë ¥ ì ìˆ˜
      const performanceScore = await this.getPerformanceScore(model);
      score += performanceScore * 0.3;
      
      // ê°€ìš©ì„± ì ìˆ˜
      score += capabilities.availability * 0.2;
      
      scores.set(model, score);
    }
    
    return scores;
  }
}
```

#### SubTask 1.7.4: ëª¨ë¸ í´ë°± ë° ë¶€í•˜ ë¶„ì‚°
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/llm/fallback_manager.py
from typing import List, Dict, Any
import asyncio
from datetime import datetime, timedelta

class ModelFallbackManager:
    def __init__(self):
        self.health_checker = ModelHealthChecker()
        self.load_balancer = ModelLoadBalancer()
        self.fallback_chains = self.define_fallback_chains()
        
    def define_fallback_chains(self) -> Dict[str, List[str]]:
        """ëª¨ë¸ë³„ í´ë°± ì²´ì¸ ì •ì˜"""
        return {
            'gpt-4': ['gpt-4-turbo', 'claude-3-opus', 'gpt-3.5-turbo'],
            'claude-3-opus': ['claude-3-sonnet', 'gpt-4', 'claude-2.1'],
            'bedrock-claude': ['bedrock-titan', 'claude-3-opus', 'gpt-4'],
            # ... ëª¨ë“  ëª¨ë¸ì— ëŒ€í•œ í´ë°± ì²´ì¸
        }
    
    async def execute_with_fallback(
        self,
        primary_model: str,
        prompt: str,
        options: Dict[str, Any]
    ) -> ModelResponse:
        """í´ë°± ë¡œì§ì„ í¬í•¨í•œ ëª¨ë¸ ì‹¤í–‰"""
        
        # í´ë°± ì²´ì¸ ê°€ì ¸ì˜¤ê¸°
        fallback_chain = [primary_model] + self.fallback_chains.get(
            primary_model, 
            []
        )
        
        last_error = None
        
        for model in fallback_chain:
            try:
                # ëª¨ë¸ í—¬ìŠ¤ ì²´í¬
                if not await self.health_checker.is_healthy(model):
                    continue
                
                # ë¡œë“œ ë°¸ëŸ°ì‹± í™•ì¸
                if not await self.load_balancer.can_handle_request(model):
                    continue
                
                # ëª¨ë¸ ì‹¤í–‰
                provider = ModelProviderFactory.create(
                    model.split('-')[0],  # í”„ë¡œë°”ì´ë” ì¶”ì¶œ
                    ModelConfig(name=model, **options)
                )
                
                await provider.initialize()
                response = await provider.generate(prompt, options)
                
                # ì„±ê³µ ê¸°ë¡
                await self.record_success(model)
                
                return response
                
            except Exception as e:
                last_error = e
                await self.record_failure(model, e)
                
                # ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ì¸ì§€ í™•ì¸
                if not self.is_retryable_error(e):
                    raise
                
                continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨
        raise Exception(
            f"All models in fallback chain failed. Last error: {last_error}"
        )
    
    def is_retryable_error(self, error: Exception) -> bool:
        """ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ì¸ì§€ í™•ì¸"""
        retryable_errors = [
            'rate_limit',
            'timeout',
            'service_unavailable',
            'internal_server_error'
        ]
        
        error_message = str(error).lower()
        return any(err in error_message for err in retryable_errors)

class ModelLoadBalancer:
    def __init__(self):
        self.request_counts = defaultdict(int)
        self.rate_limits = self.load_rate_limits()
        
    async def can_handle_request(self, model: str) -> bool:
        """ëª¨ë¸ì´ ì¶”ê°€ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸"""
        
        current_count = self.request_counts[model]
        rate_limit = self.rate_limits.get(model, float('inf'))
        
        # í˜„ì¬ ë¶€í•˜ í™•ì¸
        if current_count >= rate_limit * 0.8:  # 80% ì„ê³„ê°’
            return False
        
        # ë¶„ì‚° ë¶€í•˜ í™•ì¸ (Redis ì‚¬ìš©)
        distributed_count = await self.get_distributed_count(model)
        if distributed_count >= rate_limit:
            return False
        
        return True
    
    async def get_distributed_count(self, model: str) -> int:
        """ë¶„ì‚° í™˜ê²½ì—ì„œì˜ ì „ì²´ ìš”ì²­ ìˆ˜ í™•ì¸"""
        # Redisë¥¼ ì‚¬ìš©í•œ ë¶„ì‚° ì¹´ìš´í„°
        key = f"model_request_count:{model}"
        count = await redis_client.get(key)
        return int(count) if count else 0
```

---

### Task 1.8: ë©”ëª¨ë¦¬ ë° ìƒíƒœ ê´€ë¦¬

#### SubTask 1.8.1: ê³„ì¸µì  ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/memory/hierarchical_memory.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List
import redis
import sqlite3
import json

class MemoryLayer(ABC):
    """ë©”ëª¨ë¦¬ ë ˆì´ì–´ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def get(self, key: str) -> Optional[Any]:
        pass
    
    @abstractmethod
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        pass
    
    @abstractmethod
    async def delete(self, key: str) -> None:
        pass
    
    @abstractmethod
    async def clear(self) -> None:
        pass

class WorkingMemory(MemoryLayer):
    """ë‹¨ê¸° ì‘ì—… ë©”ëª¨ë¦¬ (In-Memory)"""
    
    def __init__(self, max_size: int = 1000):
        self.memory: Dict[str, Any] = {}
        self.max_size = max_size
        self.access_count: Dict[str, int] = {}
        
    async def get(self, key: str) -> Optional[Any]:
        if key in self.memory:
            self.access_count[key] = self.access_count.get(key, 0) + 1
            return self.memory[key]
        return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        # LRU ì •ì±…ìœ¼ë¡œ ë©”ëª¨ë¦¬ ê´€ë¦¬
        if len(self.memory) >= self.max_size:
            await self.evict_lru()
        
        self.memory[key] = value
        self.access_count[key] = 1
        
        if ttl:
            # TTL êµ¬í˜„
            asyncio.create_task(self.expire_key(key, ttl))
    
    async def evict_lru(self) -> None:
        """LRU ì •ì±…ìœ¼ë¡œ í•­ëª© ì œê±°"""
        if not self.access_count:
            return
        
        lru_key = min(self.access_count, key=self.access_count.get)
        del self.memory[lru_key]
        del self.access_count[lru_key]

class ShortTermMemory(MemoryLayer):
    """ë‹¨ê¸° ë©”ëª¨ë¦¬ (Redis)"""
    
    def __init__(self):
        self.redis_client = redis.Redis(
            host=os.getenv('REDIS_HOST'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            decode_responses=True
        )
        
    async def get(self, key: str) -> Optional[Any]:
        value = self.redis_client.get(key)
        if value:
            return json.loads(value)
        return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        serialized = json.dumps(value)
        if ttl:
            self.redis_client.setex(key, ttl, serialized)
        else:
            self.redis_client.set(key, serialized)

class LongTermMemory(MemoryLayer):
    """ì¥ê¸° ë©”ëª¨ë¦¬ (SQLite/DynamoDB)"""
    
    def __init__(self, db_path: str = "memory.db"):
        self.db_path = db_path
        self.init_db()
        
    def init_db(self):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS memory (
                key TEXT PRIMARY KEY,
                value TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                access_count INTEGER DEFAULT 0
            )
        ''')
        conn.commit()
        conn.close()
    
    async def get(self, key: str) -> Optional[Any]:
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute(
            'SELECT value FROM memory WHERE key = ?',
            (key,)
        )
        result = cursor.fetchone()
        
        if result:
            # ì ‘ê·¼ íšŸìˆ˜ ì—…ë°ì´íŠ¸
            cursor.execute(
                'UPDATE memory SET access_count = access_count + 1 WHERE key = ?',
                (key,)
            )
            conn.commit()
            
            value = json.loads(result[0])
            conn.close()
            return value
        
        conn.close()
        return None

class HierarchicalMemorySystem:
    """ê³„ì¸µì  ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.working_memory = WorkingMemory()
        self.short_term_memory = ShortTermMemory()
        self.long_term_memory = LongTermMemory()
        
        # ë©”ëª¨ë¦¬ ì •ì±…
        self.promotion_threshold = 5  # ìŠ¹ê²© ì„ê³„ê°’
        self.demotion_threshold = 30  # ê°•ë“± ì„ê³„ê°’ (ì¼)
    
    async def remember(
        self, 
        key: str, 
        value: Any, 
        importance: str = 'normal'
    ) -> None:
        """ì¤‘ìš”ë„ì— ë”°ë¼ ì ì ˆí•œ ë©”ëª¨ë¦¬ ë ˆì´ì–´ì— ì €ì¥"""
        
        if importance == 'critical':
            # ëª¨ë“  ë ˆì´ì–´ì— ì €ì¥
            await self.working_memory.set(key, value)
            await self.short_term_memory.set(key, value, ttl=86400)  # 1ì¼
            await self.long_term_memory.set(key, value)
        elif importance == 'high':
            # ë‹¨ê¸° ë° ì¥ê¸° ë©”ëª¨ë¦¬ì— ì €ì¥
            await self.short_term_memory.set(key, value, ttl=3600)  # 1ì‹œê°„
            await self.long_term_memory.set(key, value)
        else:
            # ì‘ì—… ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥
            await self.working_memory.set(key, value)
    
    async def recall(self, key: str) -> Optional[Any]:
        """ê³„ì¸µì ìœ¼ë¡œ ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        
        # 1. ì‘ì—… ë©”ëª¨ë¦¬ í™•ì¸
        value = await self.working_memory.get(key)
        if value is not None:
            return value
        
        # 2. ë‹¨ê¸° ë©”ëª¨ë¦¬ í™•ì¸
        value = await self.short_term_memory.get(key)
        if value is not None:
            # ì‘ì—… ë©”ëª¨ë¦¬ë¡œ ìŠ¹ê²©
            await self.working_memory.set(key, value)
            return value
        
        # 3. ì¥ê¸° ë©”ëª¨ë¦¬ í™•ì¸
        value = await self.long_term_memory.get(key)
        if value is not None:
            # ë‹¨ê¸° ë©”ëª¨ë¦¬ë¡œ ìŠ¹ê²©
            await self.short_term_memory.set(key, value, ttl=3600)
            await self.working_memory.set(key, value)
            return value
        
        return None
```

#### SubTask 1.8.2: ì—ì´ì „íŠ¸ ìƒíƒœ ì§€ì†ì„± ê´€ë¦¬
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/memory/agent-state-manager.ts
interface AgentState {
  agentId: string;
  sessionId: string;
  context: Map<string, any>;
  memory: any;
  lastActivity: Date;
  checkpoints: Checkpoint[];
}

interface Checkpoint {
  id: string;
  timestamp: Date;
  state: any;
  metadata: any;
}

class AgentStateManager {
  private stateStore: StateStore;
  private compressionEngine: CompressionEngine;
  private encryptionService: EncryptionService;
  
  constructor() {
    this.stateStore = new DynamoDBStateStore();
    this.compressionEngine = new CompressionEngine();
    this.encryptionService = new EncryptionService();
  }
  
  async saveState(
    agentId: string,
    state: AgentState
  ): Promise<void> {
    // ìƒíƒœ ì§ë ¬í™”
    const serialized = this.serializeState(state);
    
    // ì••ì¶•
    const compressed = await this.compressionEngine.compress(serialized);
    
    // ì•”í˜¸í™” (ë¯¼ê°í•œ ë°ì´í„° ë³´í˜¸)
    const encrypted = await this.encryptionService.encrypt(compressed);
    
    // ì €ì¥
    await this.stateStore.save({
      agentId,
      sessionId: state.sessionId,
      data: encrypted,
      timestamp: new Date(),
      ttl: this.calculateTTL(state)
    });
    
    // ì²´í¬í¬ì¸íŠ¸ ìƒì„±
    if (this.shouldCreateCheckpoint(state)) {
      await this.createCheckpoint(agentId, state);
    }
  }
  
  async loadState(
    agentId: string,
    sessionId?: string
  ): Promise<AgentState | null> {
    // ìƒíƒœ ì¡°íšŒ
    const encryptedState = await this.stateStore.load(agentId, sessionId);
    if (!encryptedState) return null;
    
    // ë³µí˜¸í™”
    const compressed = await this.encryptionService.decrypt(
      encryptedState.data
    );
    
    // ì••ì¶• í•´ì œ
    const serialized = await this.compressionEngine.decompress(compressed);
    
    // ì—­ì§ë ¬í™”
    const state = this.deserializeState(serialized);
    
    // ìƒíƒœ ê²€ì¦
    if (!this.validateState(state)) {
      throw new Error('Invalid agent state');
    }
    
    return state;
  }
  
  private shouldCreateCheckpoint(state: AgentState): boolean {
    // ì²´í¬í¬ì¸íŠ¸ ìƒì„± ì¡°ê±´
    const lastCheckpoint = state.checkpoints[state.checkpoints.length - 1];
    if (!lastCheckpoint) return true;
    
    const timeSinceLastCheckpoint = 
      Date.now() - lastCheckpoint.timestamp.getTime();
    
    // 5ë¶„ë§ˆë‹¤ ë˜ëŠ” ì¤‘ìš” ë³€ê²½ì‚¬í•­ ì‹œ
    return timeSinceLastCheckpoint > 5 * 60 * 1000 ||
           this.hasSignificantChanges(state, lastCheckpoint.state);
  }
  
  async createCheckpoint(
    agentId: string,
    state: AgentState
  ): Promise<void> {
    const checkpoint: Checkpoint = {
      id: generateId(),
      timestamp: new Date(),
      state: this.cloneState(state),
      metadata: {
        memorySize: JSON.stringify(state.memory).length,
        contextKeys: Array.from(state.context.keys())
      }
    };
    
    state.checkpoints.push(checkpoint);
    
    // ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬
    if (state.checkpoints.length > 10) {
      state.checkpoints = this.pruneCheckpoints(state.checkpoints);
    }
  }
  
  private pruneCheckpoints(checkpoints: Checkpoint[]): Checkpoint[] {
    // ìµœê·¼ 5ê°œ + ì‹œê°„ë³„ ëŒ€í‘œ ì²´í¬í¬ì¸íŠ¸ ìœ ì§€
    const recent = checkpoints.slice(-5);
    const hourly = this.selectHourlyCheckpoints(checkpoints.slice(0, -5));
    
    return [...hourly, ...recent];
  }
}
```

#### SubTask 1.8.3: ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/memory/context_manager.py
from typing import Dict, List, Any, Optional
import numpy as np
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ContextEntry:
    key: str
    value: Any
    timestamp: datetime
    relevance_score: float
    access_count: int
    source: str
    metadata: Dict[str, Any]

class ContextManager:
    def __init__(self, max_context_size: int = 10000):
        self.context: Dict[str, ContextEntry] = {}
        self.max_context_size = max_context_size
        self.relevance_calculator = RelevanceCalculator()
        self.context_compressor = ContextCompressor()
        
    async def add_context(
        self,
        key: str,
        value: Any,
        source: str = 'user',
        metadata: Optional[Dict[str, Any]] = None
    ) -> None:
        """ì»¨í…ìŠ¤íŠ¸ì— ì •ë³´ ì¶”ê°€"""
        
        # ì¤‘ë³µ í‚¤ ì²˜ë¦¬
        if key in self.context:
            await self.merge_context(key, value, metadata)
            return
        
        # ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ê´€ë¦¬
        if len(self.context) >= self.max_context_size:
            await self.compress_context()
        
        # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
        relevance_score = await self.relevance_calculator.calculate(
            key, value, self.context
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ì—”íŠ¸ë¦¬ ìƒì„±
        entry = ContextEntry(
            key=key,
            value=value,
            timestamp=datetime.utcnow(),
            relevance_score=relevance_score,
            access_count=0,
            source=source,
            metadata=metadata or {}
        )
        
        self.context[key] = entry
    
    async def get_relevant_context(
        self,
        query: str,
        max_items: int = 10
    ) -> List[ContextEntry]:
        """ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ì»¨í…ìŠ¤íŠ¸ í•­ëª© ë°˜í™˜"""
        
        # ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ í•­ëª©ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
        scores = []
        for key, entry in self.context.items():
            score = await self.relevance_calculator.calculate_query_relevance(
                query, entry
            )
            scores.append((score, entry))
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        scores.sort(key=lambda x: x[0], reverse=True)
        
        # ìƒìœ„ í•­ëª© ë°˜í™˜
        relevant_entries = [entry for _, entry in scores[:max_items]]
        
        # ì ‘ê·¼ íšŸìˆ˜ ì—…ë°ì´íŠ¸
        for entry in relevant_entries:
            entry.access_count += 1
        
        return relevant_entries
    
    async def compress_context(self) -> None:
        """ì»¨í…ìŠ¤íŠ¸ ì••ì¶•"""
        
        # 1. ë‚®ì€ ê´€ë ¨ì„± í•­ëª© ì œê±°
        relevance_threshold = np.percentile(
            [e.relevance_score for e in self.context.values()],
            25  # í•˜ìœ„ 25% ì œê±°
        )
        
        # 2. ì˜¤ë˜ëœ í•­ëª© ì œê±°
        current_time = datetime.utcnow()
        age_threshold = timedelta(hours=24)
        
        # 3. ì ‘ê·¼í•˜ì§€ ì•Šì€ í•­ëª© ì œê±°
        access_threshold = 2
        
        items_to_remove = []
        for key, entry in self.context.items():
            if (entry.relevance_score < relevance_threshold and
                entry.access_count < access_threshold and
                current_time - entry.timestamp > age_threshold):
                items_to_remove.append(key)
        
        # ì œê±°
        for key in items_to_remove:
            del self.context[key]
        
        # 4. ìœ ì‚¬í•œ í•­ëª© ë³‘í•©
        await self.merge_similar_entries()
    
    async def merge_similar_entries(self) -> None:
        """ìœ ì‚¬í•œ ì»¨í…ìŠ¤íŠ¸ í•­ëª© ë³‘í•©"""
        
        # ì„ë² ë”© ìƒì„±
        embeddings = {}
        for key, entry in self.context.items():
            embeddings[key] = await self.generate_embedding(entry.value)
        
        # í´ëŸ¬ìŠ¤í„°ë§
        clusters = self.cluster_embeddings(embeddings)
        
        # ê° í´ëŸ¬ìŠ¤í„° ë³‘í•©
        for cluster in clusters:
            if len(cluster) > 1:
                merged_entry = await self.merge_entries(
                    [self.context[key] for key in cluster]
                )
                
                # ì²« ë²ˆì§¸ í‚¤ë¡œ ë³‘í•©ëœ ì—”íŠ¸ë¦¬ ì €ì¥
                self.context[cluster[0]] = merged_entry
                
                # ë‚˜ë¨¸ì§€ ì œê±°
                for key in cluster[1:]:
                    del self.context[key]

class RelevanceCalculator:
    """ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°ê¸°"""
    
    def __init__(self):
        self.embedding_model = self.load_embedding_model()
        
    async def calculate(
        self,
        key: str,
        value: Any,
        existing_context: Dict[str, ContextEntry]
    ) -> float:
        """ìƒˆ í•­ëª©ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        
        # ê¸°ë³¸ ì ìˆ˜
        base_score = 0.5
        
        # ìµœê·¼ì„± ê°€ì¤‘ì¹˜
        recency_weight = 1.0  # ìƒˆ í•­ëª©ì€ ìµœëŒ€ ê°€ì¤‘ì¹˜
        
        # ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ì™€ì˜ ì—°ê´€ì„±
        if existing_context:
            similarities = await self.calculate_similarities(
                value, existing_context
            )
            coherence_score = np.mean(similarities) if similarities else 0
        else:
            coherence_score = 0.5
        
        # ìµœì¢… ì ìˆ˜
        relevance_score = (
            base_score * 0.3 +
            recency_weight * 0.3 +
            coherence_score * 0.4
        )
        
        return min(1.0, relevance_score)
```

#### SubTask 1.8.4: ë©”ëª¨ë¦¬ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/memory/garbage-collector.ts
interface GCPolicy {
  maxMemoryMB: number;
  maxAge: number;  // ì¼
  minRelevance: number;
  gcInterval: number;  // ì´ˆ
}

class MemoryGarbageCollector {
  private policy: GCPolicy;
  private isRunning: boolean = false;
  private gcTimer: NodeJS.Timer | null = null;
  
  constructor(policy: GCPolicy) {
    this.policy = policy;
  }
  
  start(): void {
    if (this.isRunning) return;
    
    this.isRunning = true;
    this.gcTimer = setInterval(
      () => this.runGarbageCollection(),
      this.policy.gcInterval * 1000
    );
    
    console.log('Memory garbage collector started');
  }
  
  stop(): void {
    if (this.gcTimer) {
      clearInterval(this.gcTimer);
      this.gcTimer = null;
    }
    this.isRunning = false;
    console.log('Memory garbage collector stopped');
  }
  
  private async runGarbageCollection(): Promise<void> {
    console.log('Starting garbage collection...');
    
    const startTime = Date.now();
    const stats = {
      itemsChecked: 0,
      itemsRemoved: 0,
      memoryFreed: 0
    };
    
    try {
      // 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
      const memoryUsage = await this.getMemoryUsage();
      if (memoryUsage < this.policy.maxMemoryMB * 0.8) {
        // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì„ê³„ê°’ ì´í•˜ë©´ ìŠ¤í‚µ
        return;
      }
      
      // 2. ê° ë©”ëª¨ë¦¬ ë ˆì´ì–´ ì •ë¦¬
      await this.cleanWorkingMemory(stats);
      await this.cleanShortTermMemory(stats);
      await this.cleanLongTermMemory(stats);
      
      // 3. ì••ì¶• ì‹¤í–‰
      await this.compactMemory();
      
      // 4. í†µê³„ ê¸°ë¡
      const duration = Date.now() - startTime;
      await this.recordGCStats({
        ...stats,
        duration,
        timestamp: new Date()
      });
      
      console.log(`GC completed: removed ${stats.itemsRemoved} items, ` +
                  `freed ${stats.memoryFreed}MB in ${duration}ms`);
      
    } catch (error) {
      console.error('Garbage collection failed:', error);
    }
  }
  
  private async cleanWorkingMemory(stats: any): Promise<void> {
    const workingMemory = MemoryManager.getWorkingMemory();
    const items = await workingMemory.getAllItems();
    
    for (const [key, item] of items) {
      stats.itemsChecked++;
      
      // ì œê±° ì¡°ê±´ í™•ì¸
      if (this.shouldRemove(item)) {
        const size = this.calculateItemSize(item);
        await workingMemory.delete(key);
        
        stats.itemsRemoved++;
        stats.memoryFreed += size;
      }
    }
  }
  
  private shouldRemove(item: any): boolean {
    // ë‚˜ì´ í™•ì¸
    const age = Date.now() - item.timestamp;
    if (age > this.policy.maxAge * 24 * 60 * 60 * 1000) {
      return true;
    }
    
    // ê´€ë ¨ì„± í™•ì¸
    if (item.relevance < this.policy.minRelevance) {
      return true;
    }
    
    // ì ‘ê·¼ ë¹ˆë„ í™•ì¸
    const accessRate = item.accessCount / (age / 1000 / 60);  // ë¶„ë‹¹ ì ‘ê·¼
    if (accessRate < 0.01) {  // ë¶„ë‹¹ 0.01íšŒ ë¯¸ë§Œ
      return true;
    }
    
    return false;
  }
  
  private async compactMemory(): Promise<void> {
    // ë©”ëª¨ë¦¬ ì¡°ê°í™” ì •ë¦¬
    if (global.gc) {
      global.gc();
    }
    
    // ìºì‹œ ì¬êµ¬ì„±
    await this.reorganizeCaches();
  }
}
```

---

### Task 1.9: AgentCore ëŸ°íƒ€ì„ êµ¬ì„±

#### SubTask 1.9.1: AWS Bedrock AgentCore í”„ë¡œë¹„ì €ë‹
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```yaml
# infrastructure/cloudformation/agentcore-runtime.yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: 'AWS Bedrock AgentCore Runtime Infrastructure'

Parameters:
  EnvironmentName:
    Type: String
    Default: production
    AllowedValues:
      - development
      - staging
      - production
  
  RuntimeInstanceType:
    Type: String
    Default: ml.g5.2xlarge
    Description: Instance type for AgentCore runtime

Resources:
  # AgentCore ëŸ°íƒ€ì„ ì—­í• 
  AgentCoreRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${EnvironmentName}-agentcore-runtime-role
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - bedrock.amazonaws.com
                - lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: AgentCorePolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - bedrock:*
                  - s3:GetObject
                  - s3:PutObject
                  - dynamodb:GetItem
                  - dynamodb:PutItem
                  - dynamodb:Query
                  - dynamodb:Scan
                Resource: '*'

  # AgentCore ëŸ°íƒ€ì„ ì„¤ì •
  AgentCoreRuntime:
    Type: AWS::Bedrock::AgentCoreRuntime
    Properties:
      RuntimeName: !Sub ${EnvironmentName}-t-developer-runtime
      RuntimeConfiguration:
        InstanceType: !Ref RuntimeInstanceType
        MaxConcurrentSessions: 1000
        SessionTimeout: 28800  # 8ì‹œê°„
        MemoryConfiguration:
          MaxMemoryPerAgent: 512  # MB
          TotalRuntimeMemory: 32768  # 32GB
        NetworkConfiguration:
          SubnetIds: !Ref PrivateSubnets
          SecurityGroupIds:
            - !Ref AgentCoreSecurityGroup
      RoleArn: !GetAtt AgentCoreRole.Arn
      Tags:
        - Key: Environment
          Value: !Ref EnvironmentName
        - Key: Application
          Value: T-Developer

  # ë³´ì•ˆ ê·¸ë£¹
  AgentCoreSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub ${EnvironmentName}-agentcore-sg
      GroupDescription: Security group for AgentCore runtime
      VpcId: !Ref VPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          SourceSecurityGroupId: !Ref ApplicationSecurityGroup
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0

  # Auto Scaling ì„¤ì •
  AgentCoreAutoScaling:
    Type: AWS::ApplicationAutoScaling::ScalableTarget
    Properties:
      MaxCapacity: 10
      MinCapacity: 2
      ResourceId: !Sub runtime/${AgentCoreRuntime}
      RoleARN: !GetAtt AgentCoreRole.Arn
      ScalableDimension: bedrock:runtime:InstanceCount
      ServiceNamespace: bedrock

  # ìŠ¤ì¼€ì¼ë§ ì •ì±…
  AgentCoreScalingPolicy:
    Type: AWS::ApplicationAutoScaling::ScalingPolicy
    Properties:
      PolicyName: !Sub ${EnvironmentName}-agentcore-scaling-policy
      PolicyType: TargetTrackingScaling
      ScalingTargetId: !Ref AgentCoreAutoScaling
      TargetTrackingScalingPolicyConfiguration:
        PredefinedMetricSpecification:
          PredefinedMetricType: BedrockRuntimeCPUUtilization
        TargetValue: 70.0
        ScaleInCooldown: 300
        ScaleOutCooldown: 60

Outputs:
  AgentCoreRuntimeId:
    Description: AgentCore Runtime ID
    Value: !Ref AgentCoreRuntime
    Export:
      Name: !Sub ${EnvironmentName}-agentcore-runtime-id
  
  AgentCoreEndpoint:
    Description: AgentCore Runtime Endpoint
    Value: !GetAtt AgentCoreRuntime.Endpoint
    Export:
      Name: !Sub ${EnvironmentName}-agentcore-endpoint
```

**Terraform ë²„ì „**:
```hcl
# infrastructure/terraform/agentcore-runtime.tf
resource "aws_bedrock_agent_core_runtime" "main" {
  name = "${var.environment}-t-developer-runtime"
  
  runtime_configuration {
    instance_type           = var.runtime_instance_type
    max_concurrent_sessions = 1000
    session_timeout_seconds = 28800  # 8ì‹œê°„
    
    memory_configuration {
      max_memory_per_agent_mb = 512
      total_runtime_memory_gb = 32
    }
    
    network_configuration {
      subnet_ids         = var.private_subnet_ids
      security_group_ids = [aws_security_group.agentcore.id]
    }
  }
  
  role_arn = aws_iam_role.agentcore.arn
  
  tags = {
    Environment = var.environment
    Application = "T-Developer"
  }
}
```

#### SubTask 1.9.2: ëŸ°íƒ€ì„ í™˜ê²½ ìµœì í™”
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/runtime/agentcore_optimizer.py
import boto3
from typing import Dict, Any
import json

class AgentCoreOptimizer:
    def __init__(self):
        self.bedrock_client = boto3.client('bedrock-agent-runtime')
        self.cloudwatch = boto3.client('cloudwatch')
        self.optimization_rules = self.load_optimization_rules()
        
    async def optimize_runtime(
        self, 
        runtime_id: str
    ) -> Dict[str, Any]:
        """AgentCore ëŸ°íƒ€ì„ ìµœì í™”"""
        
        # í˜„ì¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        metrics = await self.collect_runtime_metrics(runtime_id)
        
        # ìµœì í™” í•„ìš” ì—¬ë¶€ íŒë‹¨
        optimizations_needed = self.analyze_metrics(metrics)
        
        if not optimizations_needed:
            return {"status": "optimal", "metrics": metrics}
        
        # ìµœì í™” ì‹¤í–‰
        optimization_results = []
        
        for optimization in optimizations_needed:
            result = await self.apply_optimization(
                runtime_id, 
                optimization
            )
            optimization_results.append(result)
        
        return {
            "status": "optimized",
            "optimizations": optimization_results,
            "metrics": metrics
        }
    
    async def collect_runtime_metrics(
        self, 
        runtime_id: str
    ) -> Dict[str, Any]:
        """ëŸ°íƒ€ì„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        # CloudWatch ë©”íŠ¸ë¦­ ì¡°íšŒ
        response = self.cloudwatch.get_metric_statistics(
            Namespace='AWS/Bedrock',
            MetricName='RuntimeUtilization',
            Dimensions=[
                {
                    'Name': 'RuntimeId',
                    'Value': runtime_id
                }
            ],
            StartTime=datetime.utcnow() - timedelta(hours=1),
            EndTime=datetime.utcnow(),
            Period=300,
            Statistics=['Average', 'Maximum']
        )
        
        # ì¶”ê°€ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        metrics = {
            'cpu_utilization': self.get_metric_value(response, 'Average'),
            'memory_utilization': await self.get_memory_utilization(runtime_id),
            'session_count': await self.get_active_sessions(runtime_id),
            'average_latency': await self.get_average_latency(runtime_id),
            'error_rate': await self.get_error_rate(runtime_id)
        }
        
        return metrics
    
    def analyze_metrics(
        self, 
        metrics: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ë©”íŠ¸ë¦­ ë¶„ì„ ë° ìµœì í™” ì œì•ˆ"""
        
        optimizations = []
        
        # CPU ìµœì í™”
        if metrics['cpu_utilization'] > 80:
            optimizations.append({
                'type': 'scale_out',
                'reason': 'High CPU utilization',
                'target_value': 70
            })
        elif metrics['cpu_utilization'] < 20:
            optimizations.append({
                'type': 'scale_in',
                'reason': 'Low CPU utilization',
                'target_value': 40
            })
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        if metrics['memory_utilization'] > 85:
            optimizations.append({
                'type': 'increase_memory',
                'reason': 'High memory utilization',
                'recommended_increase': '25%'
            })
        
        # ë ˆì´í„´ì‹œ ìµœì í™”
        if metrics['average_latency'] > 500:  # 500ms
            optimizations.append({
                'type': 'optimize_caching',
                'reason': 'High latency detected',
                'target_latency': 200
            })
        
        return optimizations
    
    async def apply_optimization(
        self,
        runtime_id: str,
        optimization: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ìµœì í™” ì ìš©"""
        
        if optimization['type'] == 'scale_out':
            return await self.scale_runtime(runtime_id, 'out')
        elif optimization['type'] == 'scale_in':
            return await self.scale_runtime(runtime_id, 'in')
        elif optimization['type'] == 'increase_memory':
            return await self.adjust_memory(runtime_id, optimization)
        elif optimization['type'] == 'optimize_caching':
            return await self.optimize_caching(runtime_id)
        
        return {"status": "unknown_optimization_type"}
```

#### SubTask 1.9.3: ëŸ°íƒ€ì„ ëª¨ë‹ˆí„°ë§ ì„¤ì •
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/runtime/monitoring-setup.ts
interface MonitoringConfig {
  runtimeId: string;
  metrics: MetricConfig[];
  alarms: AlarmConfig[];
  dashboards: DashboardConfig[];
}

interface MetricConfig {
  name: string;
  namespace: string;
  dimensions: Record<string, string>;
  statistic: 'Average' | 'Sum' | 'Maximum' | 'Minimum';
  period: number;
}

class RuntimeMonitoringSetup {
  private cloudWatch: CloudWatch;
  private sns: SNS;
  
  constructor() {
    this.cloudWatch = new CloudWatch();
    this.sns = new SNS();
  }
  
  async setupMonitoring(config: MonitoringConfig): Promise<void> {
    // 1. ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ìƒì„±
    await this.createCustomMetrics(config.metrics);
    
    // 2. CloudWatch ì•ŒëŒ ì„¤ì •
    await this.createAlarms(config.alarms);
    
    // 3. ëŒ€ì‹œë³´ë“œ ìƒì„±
    await this.createDashboard(config.dashboards);
    
    // 4. ë¡œê·¸ ê·¸ë£¹ ì„¤ì •
    await this.setupLogging(config.runtimeId);
    
    // 5. X-Ray íŠ¸ë ˆì´ì‹± í™œì„±í™”
    await this.enableXRayTracing(config.runtimeId);
  }
  
  private async createCustomMetrics(
    metrics: MetricConfig[]
  ): Promise<void> {
    for (const metric of metrics) {
      const putMetricParams = {
        Namespace: metric.namespace,
        MetricData: [
          {
            MetricName: metric.name,
            Dimensions: Object.entries(metric.dimensions).map(
              ([name, value]) => ({ Name: name, Value: value })
            ),
            Timestamp: new Date(),
            Unit: 'None'
          }
        ]
      };
      
      await this.cloudWatch.putMetricData(putMetricParams).promise();
    }
  }
  
  private async createAlarms(alarms: AlarmConfig[]): Promise<void> {
    for (const alarm of alarms) {
      const alarmParams = {
        AlarmName: alarm.name,
        ComparisonOperator: alarm.comparisonOperator,
        EvaluationPeriods: alarm.evaluationPeriods,
        MetricName: alarm.metricName,
        Namespace: alarm.namespace,
        Period: alarm.period,
        Statistic: alarm.statistic,
        Threshold: alarm.threshold,
        ActionsEnabled: true,
        AlarmActions: [alarm.snsTopicArn],
        AlarmDescription: alarm.description,
        Dimensions: alarm.dimensions
      };
      
      await this.cloudWatch.putMetricAlarm(alarmParams).promise();
    }
  }
  
  private async createDashboard(
    dashboards: DashboardConfig[]
  ): Promise<void> {
    for (const dashboard of dashboards) {
      const widgets = this.createDashboardWidgets(dashboard);
      
      const dashboardBody = {
        widgets: widgets
      };
      
      await this.cloudWatch.putDashboard({
        DashboardName: dashboard.name,
        DashboardBody: JSON.stringify(dashboardBody)
      }).promise();
    }
  }
  
  private createDashboardWidgets(
    dashboard: DashboardConfig
  ): any[] {
    return [
      // CPU ì‚¬ìš©ë¥  ìœ„ì ¯
      {
        type: 'metric',
        properties: {
          metrics: [
            ['AWS/Bedrock', 'CPUUtilization', 'RuntimeId', dashboard.runtimeId]
          ],
          period: 300,
          stat: 'Average',
          region: process.env.AWS_REGION,
          title: 'CPU Utilization'
        }
      },
      // ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ìœ„ì ¯
      {
        type: 'metric',
        properties: {
          metrics: [
            ['AWS/Bedrock', 'MemoryUtilization', 'RuntimeId', dashboard.runtimeId]
          ],
          period: 300,
          stat: 'Average',
          region: process.env.AWS_REGION,
          title: 'Memory Utilization'
        }
      },
      // í™œì„± ì„¸ì…˜ ìˆ˜
      {
        type: 'metric',
        properties: {
          metrics: [
            ['AWS/Bedrock', 'ActiveSessions', 'RuntimeId', dashboard.runtimeId]
          ],
          period: 60,
          stat: 'Sum',
          region: process.env.AWS_REGION,
          title: 'Active Sessions'
        }
      },
      // ì—ëŸ¬ìœ¨
      {
        type: 'metric',
        properties: {
          metrics: [
            ['AWS/Bedrock', 'Errors', 'RuntimeId', dashboard.runtimeId],
            ['AWS/Bedrock', 'Invocations', 'RuntimeId', dashboard.runtimeId]
          ],
          period: 300,
          stat: 'Sum',
          region: process.env.AWS_REGION,
          title: 'Error Rate',
          yAxis: {
            left: {
              label: 'Count'
            }
          }
        }
      }
    ];
  }
}
```

#### SubTask 1.9.4: ê³ ê°€ìš©ì„± ë° ì¬í•´ë³µêµ¬ ì„¤ì •
**ë‹´ë‹¹ì**: ì¸í”„ë¼ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/runtime/high_availability.py
from typing import Dict, List, Any
import asyncio

class HighAvailabilityManager:
    def __init__(self):
        self.primary_region = os.getenv('AWS_PRIMARY_REGION', 'us-east-1')
        self.dr_regions = os.getenv('AWS_DR_REGIONS', 'us-west-2,eu-west-1').split(',')
        self.health_checker = HealthChecker()
        self.failover_manager = FailoverManager()
        
    async def setup_multi_region_deployment(self) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ë¦¬ì „ ë°°í¬ ì„¤ì •"""
        
        deployment_results = {
            'primary': None,
            'dr_regions': []
        }
        
        # 1. ê¸°ë³¸ ë¦¬ì „ ì„¤ì •
        primary_result = await self.deploy_runtime(
            self.primary_region,
            is_primary=True
        )
        deployment_results['primary'] = primary_result
        
        # 2. DR ë¦¬ì „ ì„¤ì •
        for region in self.dr_regions:
            dr_result = await self.deploy_runtime(
                region,
                is_primary=False
            )
            deployment_results['dr_regions'].append({
                'region': region,
                'result': dr_result
            })
        
        # 3. í¬ë¡œìŠ¤ ë¦¬ì „ ë³µì œ ì„¤ì •
        await self.setup_cross_region_replication()
        
        # 4. ê¸€ë¡œë²Œ ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì •
        await self.setup_global_load_balancer()
        
        return deployment_results
    
    async def deploy_runtime(
        self,
        region: str,
        is_primary: bool
    ) -> Dict[str, Any]:
        """ë¦¬ì „ë³„ ëŸ°íƒ€ì„ ë°°í¬"""
        
        bedrock_client = boto3.client(
            'bedrock-agent-runtime',
            region_name=region
        )
        
        # CloudFormation ìŠ¤íƒ ë°°í¬
        cf_client = boto3.client('cloudformation', region_name=region)
        
        stack_name = f"agentcore-runtime-{region}"
        template_body = self.get_runtime_template(is_primary)
        
        try:
            response = cf_client.create_stack(
                StackName=stack_name,
                TemplateBody=template_body,
                Parameters=[
                    {
                        'ParameterKey': 'IsPrimaryRegion',
                        'ParameterValue': str(is_primary)
                    },
                    {
                        'ParameterKey': 'ReplicationRegions',
                        'ParameterValue': ','.join(self.dr_regions)
                    }
                ],
                Capabilities=['CAPABILITY_IAM']
            )
            
            # ìŠ¤íƒ ìƒì„± ëŒ€ê¸°
            waiter = cf_client.get_waiter('stack_create_complete')
            waiter.wait(StackName=stack_name)
            
            # ëŸ°íƒ€ì„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            stack_outputs = self.get_stack_outputs(cf_client, stack_name)
            
            return {
                'status': 'success',
                'region': region,
                'runtime_id': stack_outputs['RuntimeId'],
                'endpoint': stack_outputs['RuntimeEndpoint']
            }
            
        except Exception as e:
            return {
                'status': 'failed',
                'region': region,
                'error': str(e)
            }
    
    async def setup_cross_region_replication(self) -> None:
        """í¬ë¡œìŠ¤ ë¦¬ì „ ë°ì´í„° ë³µì œ ì„¤ì •"""
        
        # DynamoDB ê¸€ë¡œë²Œ í…Œì´ë¸” ì„¤ì •
        dynamodb = boto3.client('dynamodb')
        
        tables = [
            'agent-states',
            'agent-sessions',
            'agent-checkpoints'
        ]
        
        for table_name in tables:
            try:
                response = dynamodb.update_table(
                    TableName=table_name,
                    ReplicaUpdates=[
                        {
                            'Create': {
                                'RegionName': region,
                                'GlobalSecondaryIndexes': []
                            }
                        } for region in self.dr_regions
                    ]
                )
            except Exception as e:
                print(f"Failed to setup replication for {table_name}: {e}")
    
    async def implement_health_checks(self) -> None:
        """í—¬ìŠ¤ì²´í¬ êµ¬í˜„"""
        
        while True:
            try:
                # ëª¨ë“  ë¦¬ì „ í—¬ìŠ¤ì²´í¬
                health_status = {}
                
                # Primary ë¦¬ì „ ì²´í¬
                primary_health = await self.health_checker.check_runtime(
                    self.primary_region
                )
                health_status['primary'] = primary_health
                
                # DR ë¦¬ì „ ì²´í¬
                for region in self.dr_regions:
                    dr_health = await self.health_checker.check_runtime(region)
                    health_status[region] = dr_health
                
                # ì¥ì•  ê°ì§€ ì‹œ í˜ì¼ì˜¤ë²„
                if not primary_health['healthy']:
                    await self.initiate_failover()
                
                # ë©”íŠ¸ë¦­ ê¸°ë¡
                await self.record_health_metrics(health_status)
                
            except Exception as e:
                print(f"Health check error: {e}")
            
            await asyncio.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬
    
    async def initiate_failover(self) -> None:
        """í˜ì¼ì˜¤ë²„ ì‹¤í–‰"""
        
        print("Initiating failover process...")
        
        # 1. ê°€ì¥ ê±´ê°•í•œ DR ë¦¬ì „ ì„ íƒ
        healthiest_region = await self.select_healthiest_dr_region()
        
        if not healthiest_region:
            raise Exception("No healthy DR region available")
        
        # 2. DNS ì—…ë°ì´íŠ¸
        await self.update_dns_routing(healthiest_region)
        
        # 3. ìƒˆ Primary ìŠ¹ê²©
        await self.promote_to_primary(healthiest_region)
        
        # 4. ì•Œë¦¼ ë°œì†¡
        await self.send_failover_notification(healthiest_region)
        
        print(f"Failover completed to {healthiest_region}")
```

---

ê³„ì†í•´ì„œ ë‚˜ë¨¸ì§€ Tasksë¥¼ ì‘ì„±í• ê¹Œìš”? ë‹¤ìŒì€:

- **Task 1.10**: ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ
- **Task 1.11**: ë³´ì•ˆ ë° ì¸ì¦ ë ˆì´ì–´
- **Task 1.12-1.14**: ë°ì´í„°ë² ì´ìŠ¤, ìºì‹±, ë©”ì‹œì§•
- **Task 1.15-1.17**: ë¡œê¹…, ì—ëŸ¬ì²˜ë¦¬, ì„¤ì •ê´€ë¦¬
- **Task 1.18-1.20**: ì„±ëŠ¥í…ŒìŠ¤íŠ¸, í†µí•©í…ŒìŠ¤íŠ¸, CI/CD

í”„ë¡œì íŠ¸ ì§€ì‹ì„ í™•ì¸í•˜ì—¬ Task 1.10ë¶€í„° ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.í”„ë¡œì íŠ¸ ì§€ì‹ì„ í™•ì¸í•œ ê²°ê³¼, Phase 1ì˜ ì „ì²´ Task êµ¬ì¡°ë¥¼ íŒŒì•…í–ˆìŠµë‹ˆë‹¤. ì´ì œ Task 1.10 (ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ)ì˜ SubTask 1.10.1ë¶€í„° ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.

# Phase 1: ì½”ì–´ ì¸í”„ë¼ êµ¬ì¶• - SubTask Documentation (Task 1.10ë¶€í„°)

## Task 1.10: ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ

### SubTask 1.10.1: ì¥ê¸° ì‹¤í–‰ ì„¸ì…˜ ì•„í‚¤í…ì²˜ ì„¤ê³„
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: Bedrock AgentCoreì˜ 8ì‹œê°„ ì„¸ì…˜ ì§€ì›ì„ ìœ„í•œ ì•ˆì •ì ì¸ ì„¸ì…˜ ê´€ë¦¬ ì•„í‚¤í…ì²˜ ì„¤ê³„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/session/architecture/session-manager.ts
import { DynamoDBClient } from '@aws-sdk/client-dynamodb';
import { DynamoDBDocumentClient } from '@aws-sdk/lib-dynamodb';
import { Redis } from 'ioredis';
import { EventEmitter } from 'events';

export interface SessionConfig {
  maxDuration: number; // ìµœëŒ€ 8ì‹œê°„ (28800ì´ˆ)
  heartbeatInterval: number; // 30ì´ˆ
  persistenceInterval: number; // 5ë¶„
  maxConcurrentSessions: number;
  sessionTimeout: number;
}

export interface Session {
  sessionId: string;
  userId: string;
  projectId: string;
  agentInstances: Map<string, AgentInstance>;
  startTime: Date;
  lastActivity: Date;
  state: SessionState;
  metadata: SessionMetadata;
  checkpoints: Checkpoint[];
}

export interface SessionState {
  status: 'active' | 'paused' | 'resuming' | 'terminating' | 'completed';
  currentPhase: string;
  progress: number;
  context: Record<string, any>;
  memorySnapshot: MemorySnapshot;
}

export interface MemorySnapshot {
  workingMemory: Record<string, any>;
  longTermMemory: Record<string, any>;
  agentStates: Map<string, any>;
  timestamp: Date;
}

export class SessionManager extends EventEmitter {
  private dynamoClient: DynamoDBDocumentClient;
  private redis: Redis;
  private sessions: Map<string, Session>;
  private heartbeatTimers: Map<string, NodeJS.Timer>;
  
  constructor(
    private config: SessionConfig,
    dynamoClient: DynamoDBClient,
    redis: Redis
  ) {
    super();
    this.dynamoClient = DynamoDBDocumentClient.from(dynamoClient);
    this.redis = redis;
    this.sessions = new Map();
    this.heartbeatTimers = new Map();
    
    this.initializeSessionRecovery();
  }
  
  async createSession(params: CreateSessionParams): Promise<Session> {
    // ì„¸ì…˜ ìˆ˜ ì œí•œ í™•ì¸
    if (this.sessions.size >= this.config.maxConcurrentSessions) {
      throw new Error('Maximum concurrent sessions reached');
    }
    
    const session: Session = {
      sessionId: this.generateSessionId(),
      userId: params.userId,
      projectId: params.projectId,
      agentInstances: new Map(),
      startTime: new Date(),
      lastActivity: new Date(),
      state: {
        status: 'active',
        currentPhase: 'initialization',
        progress: 0,
        context: {},
        memorySnapshot: {
          workingMemory: {},
          longTermMemory: {},
          agentStates: new Map(),
          timestamp: new Date()
        }
      },
      metadata: {
        clientInfo: params.clientInfo,
        sessionType: params.sessionType,
        features: params.enabledFeatures
      },
      checkpoints: []
    };
    
    // DynamoDBì— ì„¸ì…˜ ì €ì¥
    await this.persistSession(session);
    
    // Redisì— í™œì„± ì„¸ì…˜ ìºì‹±
    await this.cacheSession(session);
    
    // ë©”ëª¨ë¦¬ì— ì €ì¥
    this.sessions.set(session.sessionId, session);
    
    // í•˜íŠ¸ë¹„íŠ¸ ì‹œì‘
    this.startHeartbeat(session.sessionId);
    
    // ìë™ ì²´í¬í¬ì¸íŠ¸ ì‹œì‘
    this.startAutoCheckpoint(session.sessionId);
    
    this.emit('session:created', session);
    
    return session;
  }
  
  private startHeartbeat(sessionId: string): void {
    const timer = setInterval(async () => {
      try {
        await this.updateHeartbeat(sessionId);
      } catch (error) {
        console.error(`Heartbeat failed for session ${sessionId}:`, error);
        await this.handleSessionFailure(sessionId);
      }
    }, this.config.heartbeatInterval * 1000);
    
    this.heartbeatTimers.set(sessionId, timer);
  }
  
  private async updateHeartbeat(sessionId: string): Promise<void> {
    const session = this.sessions.get(sessionId);
    if (!session) return;
    
    session.lastActivity = new Date();
    
    // Redis ì—…ë°ì´íŠ¸
    await this.redis.setex(
      `session:heartbeat:${sessionId}`,
      this.config.sessionTimeout,
      JSON.stringify({
        timestamp: session.lastActivity,
        status: session.state.status
      })
    );
    
    // ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ì²´í¬
    const duration = Date.now() - session.startTime.getTime();
    if (duration > this.config.maxDuration * 1000) {
      await this.gracefulTerminate(sessionId);
    }
  }
}
```

**ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨**:
```mermaid
graph TB
    Client[Client Application]
    
    subgraph "Session Layer"
        SM[Session Manager]
        SQ[Session Queue]
        SC[Session Cache]
    end
    
    subgraph "Persistence"
        DDB[(DynamoDB)]
        Redis[(Redis)]
        S3[(S3 Checkpoints)]
    end
    
    subgraph "Agent Runtime"
        AR[Agent Runtime]
        AM[Agent Memory]
        AS[Agent State]
    end
    
    Client --> SM
    SM --> SQ
    SM --> SC
    SC --> Redis
    SM --> DDB
    SM --> AR
    AR --> AM
    AR --> AS
    AS --> S3
```

### SubTask 1.10.2: ì„¸ì…˜ ìƒíƒœ ì§€ì†ì„± ë©”ì»¤ë‹ˆì¦˜
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì„¸ì…˜ ìƒíƒœë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ë³µêµ¬í•  ìˆ˜ ìˆëŠ” ì§€ì†ì„± ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/session/persistence/session-persistence.ts
import { S3Client, PutObjectCommand, GetObjectCommand } from '@aws-sdk/client-s3';
import { compress, decompress } from 'lz4js';
import crypto from 'crypto';

export class SessionPersistenceManager {
  private s3Client: S3Client;
  private checkpointBucket: string;
  
  constructor(
    s3Client: S3Client,
    checkpointBucket: string
  ) {
    this.s3Client = s3Client;
    this.checkpointBucket = checkpointBucket;
  }
  
  async createCheckpoint(
    session: Session,
    checkpointType: 'auto' | 'manual' | 'recovery'
  ): Promise<Checkpoint> {
    const checkpoint: Checkpoint = {
      id: this.generateCheckpointId(),
      sessionId: session.sessionId,
      timestamp: new Date(),
      type: checkpointType,
      state: await this.captureSessionState(session),
      metadata: {
        size: 0,
        compressed: true,
        encryption: 'AES-256-GCM'
      }
    };
    
    // ìƒíƒœ ì§ë ¬í™” ë° ì••ì¶•
    const serialized = JSON.stringify(checkpoint.state);
    const compressed = await this.compressData(serialized);
    
    // ì•”í˜¸í™”
    const encrypted = await this.encryptData(compressed);
    
    // S3ì— ì €ì¥
    const key = `checkpoints/${session.sessionId}/${checkpoint.id}.checkpoint`;
    await this.s3Client.send(new PutObjectCommand({
      Bucket: this.checkpointBucket,
      Key: key,
      Body: encrypted,
      Metadata: {
        sessionId: session.sessionId,
        checkpointId: checkpoint.id,
        timestamp: checkpoint.timestamp.toISOString(),
        type: checkpointType
      }
    }));
    
    checkpoint.metadata.size = encrypted.length;
    
    // DynamoDBì— ì²´í¬í¬ì¸íŠ¸ ë©”íƒ€ë°ì´í„° ì €ì¥
    await this.saveCheckpointMetadata(checkpoint);
    
    return checkpoint;
  }
  
  async restoreFromCheckpoint(
    checkpointId: string,
    sessionId: string
  ): Promise<SessionState> {
    // S3ì—ì„œ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    const key = `checkpoints/${sessionId}/${checkpointId}.checkpoint`;
    const response = await this.s3Client.send(new GetObjectCommand({
      Bucket: this.checkpointBucket,
      Key: key
    }));
    
    const encrypted = await response.Body.transformToByteArray();
    
    // ë³µí˜¸í™”
    const compressed = await this.decryptData(encrypted);
    
    // ì••ì¶• í•´ì œ
    const decompressed = await this.decompressData(compressed);
    
    // ì—­ì§ë ¬í™”
    const state = JSON.parse(decompressed);
    
    // ìƒíƒœ ê²€ì¦
    await this.validateSessionState(state);
    
    return state;
  }
  
  private async captureSessionState(session: Session): Promise<SessionState> {
    // ì—ì´ì „íŠ¸ ìƒíƒœ ìˆ˜ì§‘
    const agentStates = new Map();
    for (const [agentId, instance] of session.agentInstances) {
      agentStates.set(agentId, await instance.captureState());
    }
    
    // ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ· ìƒì„±
    const memorySnapshot: MemorySnapshot = {
      workingMemory: await this.captureWorkingMemory(session),
      longTermMemory: await this.captureLongTermMemory(session),
      agentStates: agentStates,
      timestamp: new Date()
    };
    
    return {
      status: session.state.status,
      currentPhase: session.state.currentPhase,
      progress: session.state.progress,
      context: { ...session.state.context },
      memorySnapshot: memorySnapshot
    };
  }
  
  async cleanupOldCheckpoints(
    sessionId: string,
    retentionDays: number = 7
  ): Promise<void> {
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays);
    
    // ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì¡°íšŒ
    const oldCheckpoints = await this.queryOldCheckpoints(
      sessionId,
      cutoffDate
    );
    
    // S3ì—ì„œ ì‚­ì œ
    for (const checkpoint of oldCheckpoints) {
      const key = `checkpoints/${sessionId}/${checkpoint.id}.checkpoint`;
      await this.s3Client.send(new DeleteObjectCommand({
        Bucket: this.checkpointBucket,
        Key: key
      }));
    }
    
    // ë©”íƒ€ë°ì´í„° ì‚­ì œ
    await this.deleteCheckpointMetadata(oldCheckpoints);
  }
}
```

### SubTask 1.10.3: ì„¸ì…˜ ë³µêµ¬ ë° ì¬ê°œ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: ì¤‘ë‹¨ëœ ì„¸ì…˜ì„ ì•ˆì „í•˜ê²Œ ë³µêµ¬í•˜ê³  ì¬ê°œí•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/session/recovery/session-recovery.ts
export class SessionRecoveryService {
  private sessionManager: SessionManager;
  private persistenceManager: SessionPersistenceManager;
  private recoveryQueue: PriorityQueue<RecoveryTask>;
  
  constructor(
    sessionManager: SessionManager,
    persistenceManager: SessionPersistenceManager
  ) {
    this.sessionManager = sessionManager;
    this.persistenceManager = persistenceManager;
    this.recoveryQueue = new PriorityQueue();
    
    this.startRecoveryWorker();
  }
  
  async recoverSession(
    sessionId: string,
    recoveryOptions?: RecoveryOptions
  ): Promise<Session> {
    try {
      // 1. ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
      const checkpoint = await this.findLatestValidCheckpoint(sessionId);
      if (!checkpoint) {
        throw new Error(`No valid checkpoint found for session ${sessionId}`);
      }
      
      // 2. ì„¸ì…˜ ìƒíƒœ ë³µì›
      const sessionState = await this.persistenceManager.restoreFromCheckpoint(
        checkpoint.id,
        sessionId
      );
      
      // 3. ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ì¬ìƒì„±
      const agentInstances = await this.recreateAgentInstances(
        sessionState.memorySnapshot.agentStates
      );
      
      // 4. ì„¸ì…˜ ì¬êµ¬ì„±
      const recoveredSession = await this.reconstructSession(
        sessionId,
        sessionState,
        agentInstances
      );
      
      // 5. ìƒíƒœ ê²€ì¦
      await this.validateRecoveredSession(recoveredSession);
      
      // 6. ì„¸ì…˜ ì¬ê°œ
      await this.resumeSession(recoveredSession);
      
      this.emit('session:recovered', {
        sessionId,
        checkpointId: checkpoint.id,
        recoveryTime: Date.now()
      });
      
      return recoveredSession;
      
    } catch (error) {
      this.emit('session:recovery:failed', {
        sessionId,
        error: error.message
      });
      throw error;
    }
  }
  
  private async recreateAgentInstances(
    agentStates: Map<string, any>
  ): Promise<Map<string, AgentInstance>> {
    const instances = new Map();
    
    for (const [agentId, state] of agentStates) {
      try {
        const instance = await this.recreateAgent(agentId, state);
        instances.set(agentId, instance);
      } catch (error) {
        console.error(`Failed to recreate agent ${agentId}:`, error);
        // ì—ì´ì „íŠ¸ ì¬ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìƒíƒœë¡œ ìƒì„±
        const fallbackInstance = await this.createFallbackAgent(agentId);
        instances.set(agentId, fallbackInstance);
      }
    }
    
    return instances;
  }
  
  private async resumeSession(session: Session): Promise<void> {
    // 1. ì„¸ì…˜ ìƒíƒœë¥¼ 'resuming'ìœ¼ë¡œ ë³€ê²½
    session.state.status = 'resuming';
    
    // 2. ì—ì´ì „íŠ¸ ì›Œë°ì—…
    await this.warmupAgents(session.agentInstances);
    
    // 3. ì»¨í…ìŠ¤íŠ¸ ë³µì›
    await this.restoreContext(session);
    
    // 4. ì§„í–‰ ìƒí™© ë™ê¸°í™”
    await this.syncProgress(session);
    
    // 5. ì„¸ì…˜ í™œì„±í™”
    session.state.status = 'active';
    session.lastActivity = new Date();
    
    // 6. í•˜íŠ¸ë¹„íŠ¸ ì¬ì‹œì‘
    this.sessionManager.startHeartbeat(session.sessionId);
  }
  
  async handleCrashRecovery(): Promise<void> {
    // ì‹œìŠ¤í…œ ì¬ì‹œì‘ ì‹œ í˜¸ì¶œë˜ëŠ” ë©”ì„œë“œ
    // ëª¨ë“  ë¯¸ì™„ë£Œ ì„¸ì…˜ ë³µêµ¬ ì‹œë„
    
    const incompleteSessions = await this.findIncompleteSessions();
    
    for (const sessionInfo of incompleteSessions) {
      const recoveryTask: RecoveryTask = {
        sessionId: sessionInfo.sessionId,
        priority: this.calculateRecoveryPriority(sessionInfo),
        attempts: 0,
        maxAttempts: 3,
        nextAttempt: new Date()
      };
      
      this.recoveryQueue.enqueue(recoveryTask);
    }
  }
  
  private startRecoveryWorker(): void {
    setInterval(async () => {
      if (this.recoveryQueue.isEmpty()) return;
      
      const task = this.recoveryQueue.dequeue();
      if (!task) return;
      
      try {
        await this.recoverSession(task.sessionId);
      } catch (error) {
        task.attempts++;
        
        if (task.attempts < task.maxAttempts) {
          // ì¬ì‹œë„ ìŠ¤ì¼€ì¤„ë§ (ì§€ìˆ˜ ë°±ì˜¤í”„)
          task.nextAttempt = new Date(
            Date.now() + Math.pow(2, task.attempts) * 60000
          );
          this.recoveryQueue.enqueue(task);
        } else {
          // ë³µêµ¬ ì‹¤íŒ¨ ì²˜ë¦¬
          await this.handleRecoveryFailure(task.sessionId);
        }
      }
    }, 10000); // 10ì´ˆë§ˆë‹¤ ì‹¤í–‰
  }
}
```

### SubTask 1.10.4: ì„¸ì…˜ ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„
**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì„¸ì…˜ ìƒíƒœì™€ ì„±ëŠ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/session/monitoring/session-monitor.ts
import { MetricsCollector } from '../../metrics/collector';
import { AlertManager } from '../../alerts/manager';

export interface SessionMetrics {
  sessionId: string;
  duration: number;
  memoryUsage: number;
  cpuUsage: number;
  agentCount: number;
  checkpointCount: number;
  errorRate: number;
  throughput: number;
}

export class SessionMonitor {
  private metricsCollector: MetricsCollector;
  private alertManager: AlertManager;
  private metricsInterval: NodeJS.Timer;
  
  constructor(
    metricsCollector: MetricsCollector,
    alertManager: AlertManager
  ) {
    this.metricsCollector = metricsCollector;
    this.alertManager = alertManager;
  }
  
  startMonitoring(session: Session): void {
    const intervalId = setInterval(async () => {
      try {
        const metrics = await this.collectSessionMetrics(session);
        await this.analyzeMetrics(metrics);
        await this.checkThresholds(metrics);
      } catch (error) {
        console.error(`Monitoring error for session ${session.sessionId}:`, error);
      }
    }, 30000); // 30ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
    
    this.metricsInterval = intervalId;
  }
  
  private async collectSessionMetrics(session: Session): Promise<SessionMetrics> {
    const metrics: SessionMetrics = {
      sessionId: session.sessionId,
      duration: Date.now() - session.startTime.getTime(),
      memoryUsage: await this.getMemoryUsage(session),
      cpuUsage: await this.getCPUUsage(session),
      agentCount: session.agentInstances.size,
      checkpointCount: session.checkpoints.length,
      errorRate: await this.calculateErrorRate(session),
      throughput: await this.calculateThroughput(session)
    };
    
    // Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    this.metricsCollector.gauge('session_duration_seconds', 
      metrics.duration / 1000, 
      { sessionId: session.sessionId }
    );
    
    this.metricsCollector.gauge('session_memory_bytes',
      metrics.memoryUsage,
      { sessionId: session.sessionId }
    );
    
    this.metricsCollector.gauge('session_agent_count',
      metrics.agentCount,
      { sessionId: session.sessionId }
    );
    
    return metrics;
  }
  
  private async checkThresholds(metrics: SessionMetrics): Promise<void> {
    // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì„ê³„ê°’ ì²´í¬
    if (metrics.memoryUsage > 2 * 1024 * 1024 * 1024) { // 2GB
      await this.alertManager.sendAlert({
        severity: 'warning',
        title: 'High Memory Usage in Session',
        message: `Session ${metrics.sessionId} is using ${Math.round(metrics.memoryUsage / 1024 / 1024)}MB of memory`,
        metadata: metrics
      });
    }
    
    // ì„¸ì…˜ ì§€ì† ì‹œê°„ ì²´í¬
    if (metrics.duration > 7 * 60 * 60 * 1000) { // 7ì‹œê°„
      await this.alertManager.sendAlert({
        severity: 'info',
        title: 'Long Running Session',
        message: `Session ${metrics.sessionId} has been running for ${Math.round(metrics.duration / 1000 / 60 / 60)} hours`,
        metadata: metrics
      });
    }
    
    // ì—ëŸ¬ìœ¨ ì²´í¬
    if (metrics.errorRate > 0.05) { // 5%
      await this.alertManager.sendAlert({
        severity: 'warning',
        title: 'High Error Rate',
        message: `Session ${metrics.sessionId} has ${Math.round(metrics.errorRate * 100)}% error rate`,
        metadata: metrics
      });
    }
  }
  
  async generateSessionReport(sessionId: string): Promise<SessionReport> {
    const historicalMetrics = await this.metricsCollector.queryRange(
      'session_*',
      { sessionId },
      '-24h',
      'now'
    );
    
    return {
      sessionId,
      summary: {
        totalDuration: this.calculateTotalDuration(historicalMetrics),
        averageMemoryUsage: this.calculateAverageMemory(historicalMetrics),
        peakMemoryUsage: this.calculatePeakMemory(historicalMetrics),
        totalAgentsCreated: this.countTotalAgents(historicalMetrics),
        checkpointStats: this.analyzeCheckpoints(historicalMetrics),
        performanceScore: this.calculatePerformanceScore(historicalMetrics)
      },
      timeline: this.generateTimeline(historicalMetrics),
      recommendations: this.generateRecommendations(historicalMetrics)
    };
  }
}

// ì„¸ì…˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ API
export class SessionAnalyticsDashboard {
  async getActiveSessions(): Promise<SessionSummary[]> {
    const sessions = await this.sessionManager.getActiveSessions();
    
    return Promise.all(sessions.map(async session => ({
      sessionId: session.sessionId,
      userId: session.userId,
      projectId: session.projectId,
      startTime: session.startTime,
      duration: Date.now() - session.startTime.getTime(),
      status: session.state.status,
      progress: session.state.progress,
      agentCount: session.agentInstances.size,
      lastActivity: session.lastActivity,
      healthStatus: await this.calculateHealthStatus(session)
    })));
  }
  
  async getSessionTrends(timeRange: string): Promise<TrendData> {
    const metrics = await this.metricsCollector.queryRange(
      'session_*',
      {},
      timeRange,
      'now'
    );
    
    return {
      sessionCount: this.extractTrend(metrics, 'session_count'),
      averageDuration: this.extractTrend(metrics, 'session_duration_seconds'),
      memoryUsage: this.extractTrend(metrics, 'session_memory_bytes'),
      errorRate: this.extractTrend(metrics, 'session_error_rate'),
      throughput: this.extractTrend(metrics, 'session_throughput')
    };
  }
}
```

## Task 1.11: ë³´ì•ˆ ë° ì¸ì¦ ë ˆì´ì–´

### SubTask 1.11.1: JWT ê¸°ë°˜ ì¸ì¦ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë³´ì•ˆ ì „ë¬¸ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì•ˆì „í•œ JWT ê¸°ë°˜ ì¸ì¦ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/auth/jwt-auth.ts
import jwt from 'jsonwebtoken';
import { JWK, JWS } from 'node-jose';
import crypto from 'crypto';

export interface TokenPayload {
  userId: string;
  sessionId: string;
  projectId?: string;
  roles: string[];
  permissions: string[];
  iat: number;
  exp: number;
  jti: string;
}

export class JWTAuthService {
  private keyStore: JWK.KeyStore;
  private activeTokens: Map<string, TokenInfo>;
  private blacklist: Set<string>;
  
  constructor(
    private config: AuthConfig
  ) {
    this.keyStore = JWK.createKeyStore();
    this.activeTokens = new Map();
    this.blacklist = new Set();
    
    this.initializeKeys();
  }
  
  private async initializeKeys(): Promise<void> {
    // RSA í‚¤ ìŒ ìƒì„±
    await this.keyStore.generate('RSA', 2048, {
      alg: 'RS256',
      use: 'sig',
      kid: this.generateKeyId()
    });
    
    // í‚¤ ë¡œí…Œì´ì…˜ ìŠ¤ì¼€ì¤„ ì„¤ì •
    this.scheduleKeyRotation();
  }
  
  async generateToken(
    user: User,
    session: Session,
    options?: TokenOptions
  ): Promise<AuthToken> {
    const tokenId = crypto.randomUUID();
    const now = Math.floor(Date.now() / 1000);
    
    const payload: TokenPayload = {
      userId: user.id,
      sessionId: session.sessionId,
      projectId: session.projectId,
      roles: user.roles,
      permissions: await this.resolvePermissions(user),
      iat: now,
      exp: now + (options?.expiresIn || 3600), // ê¸°ë³¸ 1ì‹œê°„
      jti: tokenId
    };
    
    // JWT ìƒì„±
    const key = this.keyStore.all()[0];
    const token = await JWS.createSign({
      format: 'compact',
      fields: {
        typ: 'JWT',
        kid: key.kid
      }
    }, key)
    .update(JSON.stringify(payload))
    .final();
    
    // ë¦¬í”„ë ˆì‹œ í† í° ìƒì„±
    const refreshToken = await this.generateRefreshToken(user, session);
    
    // í† í° ì •ë³´ ì €ì¥
    this.activeTokens.set(tokenId, {
      userId: user.id,
      sessionId: session.sessionId,
      issuedAt: new Date(),
      expiresAt: new Date(payload.exp * 1000),
      refreshToken: refreshToken.id
    });
    
    return {
      accessToken: token.toString(),
      refreshToken: refreshToken.token,
      tokenType: 'Bearer',
      expiresIn: payload.exp - payload.iat
    };
  }
  
  async verifyToken(token: string): Promise<TokenPayload> {
    try {
      // ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬
      const decoded = jwt.decode(token) as any;
      if (this.blacklist.has(decoded?.jti)) {
        throw new Error('Token has been revoked');
      }
      
      // ì„œëª… ê²€ì¦
      const result = await JWS.createVerify(this.keyStore)
        .verify(token);
      
      const payload = JSON.parse(result.payload.toString());
      
      // ë§Œë£Œ ì‹œê°„ ì²´í¬
      if (payload.exp < Math.floor(Date.now() / 1000)) {
        throw new Error('Token has expired');
      }
      
      // ì¶”ê°€ ê²€ì¦
      await this.performAdditionalValidation(payload);
      
      return payload;
      
    } catch (error) {
      throw new AuthenticationError('Invalid token', error);
    }
  }
  
  async refreshAccessToken(refreshToken: string): Promise<AuthToken> {
    const refreshPayload = await this.verifyRefreshToken(refreshToken);
    
    // ì‚¬ìš©ì ë° ì„¸ì…˜ í™•ì¸
    const user = await this.userService.findById(refreshPayload.userId);
    const session = await this.sessionManager.getSession(refreshPayload.sessionId);
    
    if (!user || !session) {
      throw new Error('Invalid refresh token');
    }
    
    // ìƒˆ ì•¡ì„¸ìŠ¤ í† í° ìƒì„±
    return this.generateToken(user, session);
  }
  
  async revokeToken(tokenId: string): Promise<void> {
    this.blacklist.add(tokenId);
    this.activeTokens.delete(tokenId);
    
    // Redisì— ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë™ê¸°í™”
    await this.redis.sadd('token:blacklist', tokenId);
    await this.redis.expire('token:blacklist', 86400); // 24ì‹œê°„
  }
  
  private async performAdditionalValidation(payload: TokenPayload): Promise<void> {
    // IP ì£¼ì†Œ ê²€ì¦
    if (this.config.validateIP) {
      const tokenIP = await this.redis.get(`token:ip:${payload.jti}`);
      if (tokenIP && tokenIP !== this.getCurrentIP()) {
        throw new Error('IP address mismatch');
      }
    }
    
    // ì„¸ì…˜ ìœ íš¨ì„± ê²€ì¦
    const session = await this.sessionManager.getSession(payload.sessionId);
    if (!session || session.state.status !== 'active') {
      throw new Error('Invalid session');
    }
  }
}
```
### SubTask 1.11.2: ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´ (RBAC)
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: ì„¸ë°€í•œ ê¶Œí•œ ê´€ë¦¬ë¥¼ ìœ„í•œ RBAC ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/rbac/rbac-system.ts
export interface Role {
  id: string;
  name: string;
  description: string;
  permissions: Permission[];
  inherits?: string[]; // ìƒì†ë°›ëŠ” ë‹¤ë¥¸ ì—­í• ë“¤
  conditions?: RoleCondition[];
  priority: number;
}

export interface Permission {
  id: string;
  resource: string;
  action: string;
  effect: 'allow' | 'deny';
  conditions?: PermissionCondition[];
}

export interface RoleCondition {
  type: 'time' | 'ip' | 'attribute';
  operator: 'equals' | 'contains' | 'between' | 'regex';
  value: any;
}

export class RBACService {
  private roleCache: Map<string, Role>;
  private permissionCache: Map<string, Permission>;
  private userRoleCache: LRUCache<string, string[]>;
  
  constructor(
    private dynamoClient: DynamoDBDocumentClient,
    private redis: Redis
  ) {
    this.roleCache = new Map();
    this.permissionCache = new Map();
    this.userRoleCache = new LRUCache({ max: 10000 });
    
    this.initializeDefaultRoles();
  }
  
  private async initializeDefaultRoles(): Promise<void> {
    const defaultRoles: Role[] = [
      {
        id: 'admin',
        name: 'Administrator',
        description: 'Full system access',
        permissions: [
          {
            id: 'admin-all',
            resource: '*',
            action: '*',
            effect: 'allow'
          }
        ],
        priority: 100
      },
      {
        id: 'developer',
        name: 'Developer',
        description: 'Standard developer access',
        permissions: [
          {
            id: 'project-manage',
            resource: 'project:*',
            action: 'create|read|update|delete',
            effect: 'allow',
            conditions: [{
              type: 'attribute',
              operator: 'equals',
              value: { projectOwner: '${userId}' }
            }]
          },
          {
            id: 'agent-execute',
            resource: 'agent:*',
            action: 'execute|monitor',
            effect: 'allow'
          }
        ],
        priority: 50
      },
      {
        id: 'viewer',
        name: 'Viewer',
        description: 'Read-only access',
        permissions: [
          {
            id: 'read-only',
            resource: '*',
            action: 'read|list',
            effect: 'allow'
          }
        ],
        priority: 10
      }
    ];
    
    for (const role of defaultRoles) {
      await this.createRole(role);
    }
  }
  
  async checkPermission(
    userId: string,
    resource: string,
    action: string,
    context?: PermissionContext
  ): Promise<boolean> {
    // 1. ì‚¬ìš©ì ì—­í•  ì¡°íšŒ
    const userRoles = await this.getUserRoles(userId);
    
    // 2. ì—­í• ë³„ ê¶Œí•œ ìˆ˜ì§‘
    const permissions = await this.collectPermissions(userRoles);
    
    // 3. ê¶Œí•œ í‰ê°€
    return this.evaluatePermissions(
      permissions,
      resource,
      action,
      context
    );
  }
  
  private async collectPermissions(roleIds: string[]): Promise<Permission[]> {
    const allPermissions: Permission[] = [];
    const processedRoles = new Set<string>();
    
    const processRole = async (roleId: string) => {
      if (processedRoles.has(roleId)) return;
      processedRoles.add(roleId);
      
      const role = await this.getRole(roleId);
      if (!role) return;
      
      // ì§ì ‘ ê¶Œí•œ ì¶”ê°€
      allPermissions.push(...role.permissions);
      
      // ìƒì†ëœ ì—­í•  ì²˜ë¦¬
      if (role.inherits) {
        for (const inheritedRoleId of role.inherits) {
          await processRole(inheritedRoleId);
        }
      }
    };
    
    for (const roleId of roleIds) {
      await processRole(roleId);
    }
    
    // ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì •ë ¬
    return allPermissions.sort((a, b) => {
      const roleA = this.roleCache.get(a.id);
      const roleB = this.roleCache.get(b.id);
      return (roleB?.priority || 0) - (roleA?.priority || 0);
    });
  }
  
  private evaluatePermissions(
    permissions: Permission[],
    resource: string,
    action: string,
    context?: PermissionContext
  ): boolean {
    let decision: boolean | null = null;
    
    for (const permission of permissions) {
      // ë¦¬ì†ŒìŠ¤ ë§¤ì¹­
      if (!this.matchResource(permission.resource, resource)) {
        continue;
      }
      
      // ì•¡ì…˜ ë§¤ì¹­
      if (!this.matchAction(permission.action, action)) {
        continue;
      }
      
      // ì¡°ê±´ í‰ê°€
      if (permission.conditions) {
        const conditionsMet = this.evaluateConditions(
          permission.conditions,
          context
        );
        if (!conditionsMet) continue;
      }
      
      // ëª…ì‹œì  ê±°ë¶€ëŠ” í•­ìƒ ìš°ì„ 
      if (permission.effect === 'deny') {
        return false;
      }
      
      // í—ˆìš© ê¶Œí•œ ë°œê²¬
      if (permission.effect === 'allow') {
        decision = true;
      }
    }
    
    return decision === true;
  }
  
  async createPolicy(
    name: string,
    statements: PolicyStatement[]
  ): Promise<Policy> {
    const policy: Policy = {
      id: crypto.randomUUID(),
      name,
      version: '1.0',
      statements,
      createdAt: new Date(),
      updatedAt: new Date()
    };
    
    // DynamoDBì— ì €ì¥
    await this.dynamoClient.send(new PutCommand({
      TableName: 'Policies',
      Item: policy
    }));
    
    return policy;
  }
  
  // ë™ì  ê¶Œí•œ í‰ê°€
  async evaluateDynamicPermission(
    userId: string,
    request: PermissionRequest
  ): Promise<PermissionDecision> {
    const startTime = Date.now();
    
    // ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
    const context = await this.buildContext(userId, request);
    
    // ì ìš© ê°€ëŠ¥í•œ ì •ì±… ì°¾ê¸°
    const applicablePolicies = await this.findApplicablePolicies(
      userId,
      request.resource,
      context
    );
    
    // ì •ì±… í‰ê°€
    const decisions = await Promise.all(
      applicablePolicies.map(policy => 
        this.evaluatePolicy(policy, request, context)
      )
    );
    
    // ìµœì¢… ê²°ì •
    const finalDecision = this.combineDecisions(decisions);
    
    // ê°ì‚¬ ë¡œê·¸
    await this.auditLog.log({
      userId,
      resource: request.resource,
      action: request.action,
      decision: finalDecision,
      evaluationTime: Date.now() - startTime,
      policies: applicablePolicies.map(p => p.id)
    });
    
    return finalDecision;
  }
}

// RBAC ë¯¸ë“¤ì›¨ì–´
export function rbacMiddleware(
  resource: string | ((req: Request) => string),
  action: string | ((req: Request) => string)
) {
  return async (req: Request, res: Response, next: NextFunction) => {
    try {
      const userId = req.user?.id;
      if (!userId) {
        return res.status(401).json({ error: 'Unauthorized' });
      }
      
      const resourceName = typeof resource === 'function' 
        ? resource(req) 
        : resource;
      const actionName = typeof action === 'function' 
        ? action(req) 
        : action;
        
      const hasPermission = await rbacService.checkPermission(
        userId,
        resourceName,
        actionName,
        {
          ip: req.ip,
          userAgent: req.headers['user-agent'],
          requestId: req.id,
          resourceId: req.params.id
        }
      );
      
      if (!hasPermission) {
        return res.status(403).json({ 
          error: 'Forbidden',
          message: `Insufficient permissions for ${actionName} on ${resourceName}`
        });
      }
      
      next();
    } catch (error) {
      next(error);
    }
  };
}
```

### SubTask 1.11.3: API ë³´ì•ˆ ê°•í™”
**ë‹´ë‹¹ì**: ë³´ì•ˆ ì „ë¬¸ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: API ë ˆë²¨ì—ì„œì˜ ì¢…í•©ì ì¸ ë³´ì•ˆ ê°•í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/api/api-security.ts
import rateLimit from 'express-rate-limit';
import helmet from 'helmet';
import { createHash, createHmac } from 'crypto';

export class APISecurityManager {
  private rateLimiters: Map<string, any>;
  private apiKeyStore: Map<string, APIKey>;
  
  constructor(
    private config: SecurityConfig,
    private redis: Redis
  ) {
    this.rateLimiters = new Map();
    this.apiKeyStore = new Map();
    
    this.initializeRateLimiters();
  }
  
  private initializeRateLimiters(): void {
    // ê¸°ë³¸ rate limiter
    this.rateLimiters.set('default', rateLimit({
      windowMs: 15 * 60 * 1000, // 15ë¶„
      max: 100, // ìš”ì²­ ìˆ˜
      standardHeaders: true,
      legacyHeaders: false,
      store: new RedisStore({
        client: this.redis,
        prefix: 'rl:default:'
      }),
      handler: (req, res) => {
        res.status(429).json({
          error: 'Too Many Requests',
          message: 'Rate limit exceeded',
          retryAfter: req.rateLimit.resetTime
        });
      }
    }));
    
    // ì—„ê²©í•œ rate limiter (ë¯¼ê°í•œ ì—”ë“œí¬ì¸íŠ¸ìš©)
    this.rateLimiters.set('strict', rateLimit({
      windowMs: 15 * 60 * 1000,
      max: 10,
      skipSuccessfulRequests: false,
      store: new RedisStore({
        client: this.redis,
        prefix: 'rl:strict:'
      })
    }));
    
    // API í‚¤ë³„ rate limiter
    this.rateLimiters.set('apikey', rateLimit({
      windowMs: 60 * 1000, // 1ë¶„
      max: (req) => {
        const apiKey = this.extractAPIKey(req);
        const keyInfo = this.apiKeyStore.get(apiKey);
        return keyInfo?.rateLimit || 60;
      },
      keyGenerator: (req) => {
        return this.extractAPIKey(req) || req.ip;
      },
      store: new RedisStore({
        client: this.redis,
        prefix: 'rl:apikey:'
      })
    }));
  }
  
  // API í‚¤ ê´€ë¦¬
  async generateAPIKey(
    userId: string,
    name: string,
    permissions: string[]
  ): Promise<APIKeyResponse> {
    const key = this.generateSecureKey();
    const hashedKey = this.hashAPIKey(key);
    
    const apiKeyInfo: APIKey = {
      id: crypto.randomUUID(),
      userId,
      name,
      hashedKey,
      permissions,
      rateLimit: 60, // ë¶„ë‹¹ ìš”ì²­ ìˆ˜
      createdAt: new Date(),
      lastUsed: null,
      expiresAt: new Date(Date.now() + 365 * 24 * 60 * 60 * 1000), // 1ë…„
      metadata: {}
    };
    
    // DynamoDBì— ì €ì¥
    await this.saveAPIKey(apiKeyInfo);
    
    // ìºì‹œì— ì €ì¥
    this.apiKeyStore.set(hashedKey, apiKeyInfo);
    
    return {
      apiKey: key, // ì›ë³¸ í‚¤ëŠ” ì´ë•Œë§Œ ë°˜í™˜
      keyId: apiKeyInfo.id,
      name: apiKeyInfo.name,
      permissions: apiKeyInfo.permissions,
      expiresAt: apiKeyInfo.expiresAt
    };
  }
  
  // ìš”ì²­ ì„œëª… ê²€ì¦
  async verifyRequestSignature(
    req: Request,
    secret: string
  ): Promise<boolean> {
    const signature = req.headers['x-signature'] as string;
    if (!signature) return false;
    
    const timestamp = req.headers['x-timestamp'] as string;
    if (!timestamp) return false;
    
    // íƒ€ì„ìŠ¤íƒ¬í”„ ê²€ì¦ (5ë¶„ ì´ë‚´)
    const requestTime = parseInt(timestamp);
    const currentTime = Date.now();
    if (Math.abs(currentTime - requestTime) > 300000) {
      return false;
    }
    
    // ì„œëª… í˜ì´ë¡œë“œ ìƒì„±
    const payload = this.createSignaturePayload(req, timestamp);
    
    // HMAC ì„œëª… ìƒì„±
    const expectedSignature = createHmac('sha256', secret)
      .update(payload)
      .digest('hex');
      
    // íƒ€ì´ë° ê³µê²© ë°©ì§€ë¥¼ ìœ„í•œ ì•ˆì „í•œ ë¹„êµ
    return this.secureCompare(signature, expectedSignature);
  }
  
  // CORS ì„¤ì •
  getCORSOptions(): cors.CorsOptions {
    return {
      origin: (origin, callback) => {
        // í—ˆìš©ëœ ë„ë©”ì¸ í™•ì¸
        if (!origin || this.isAllowedOrigin(origin)) {
          callback(null, true);
        } else {
          callback(new Error('CORS policy violation'));
        }
      },
      credentials: true,
      methods: ['GET', 'POST', 'PUT', 'DELETE', 'PATCH'],
      allowedHeaders: [
        'Content-Type',
        'Authorization',
        'X-Request-ID',
        'X-API-Key',
        'X-Signature',
        'X-Timestamp'
      ],
      exposedHeaders: [
        'X-Request-ID',
        'X-RateLimit-Limit',
        'X-RateLimit-Remaining',
        'X-RateLimit-Reset'
      ],
      maxAge: 86400 // 24ì‹œê°„
    };
  }
  
  // ë³´ì•ˆ í—¤ë” ì„¤ì •
  getSecurityHeaders(): any {
    return helmet({
      contentSecurityPolicy: {
        directives: {
          defaultSrc: ["'self'"],
          scriptSrc: ["'self'", "'unsafe-inline'"],
          styleSrc: ["'self'", "'unsafe-inline'"],
          imgSrc: ["'self'", "data:", "https:"],
          connectSrc: ["'self'"],
          fontSrc: ["'self'"],
          objectSrc: ["'none'"],
          mediaSrc: ["'self'"],
          frameSrc: ["'none'"]
        }
      },
      crossOriginEmbedderPolicy: true,
      crossOriginOpenerPolicy: true,
      crossOriginResourcePolicy: { policy: "cross-origin" },
      dnsPrefetchControl: true,
      frameguard: { action: 'deny' },
      hidePoweredBy: true,
      hsts: {
        maxAge: 31536000,
        includeSubDomains: true,
        preload: true
      },
      ieNoOpen: true,
      noSniff: true,
      originAgentCluster: true,
      permittedCrossDomainPolicies: false,
      referrerPolicy: { policy: "strict-origin-when-cross-origin" },
      xssFilter: true
    });
  }
  
  // SQL Injection ë°©ì§€
  sanitizeInput(input: any): any {
    if (typeof input === 'string') {
      // SQL ì˜ˆì•½ì–´ ë° ìœ„í—˜í•œ íŒ¨í„´ ì œê±°
      return input
        .replace(/['";\\]/g, '')
        .replace(/--/g, '')
        .replace(/\/\*/g, '')
        .replace(/\*\//g, '')
        .replace(/xp_/gi, '')
        .replace(/sp_/gi, '');
    }
    
    if (Array.isArray(input)) {
      return input.map(item => this.sanitizeInput(item));
    }
    
    if (typeof input === 'object' && input !== null) {
      const sanitized: any = {};
      for (const [key, value] of Object.entries(input)) {
        sanitized[this.sanitizeInput(key)] = this.sanitizeInput(value);
      }
      return sanitized;
    }
    
    return input;
  }
  
  // API ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´ ì²´ì¸
  getSecurityMiddleware(): RequestHandler[] {
    return [
      // 1. ë³´ì•ˆ í—¤ë”
      this.getSecurityHeaders(),
      
      // 2. CORS
      cors(this.getCORSOptions()),
      
      // 3. Body í¬ê¸° ì œí•œ
      express.json({ limit: '10mb' }),
      express.urlencoded({ extended: true, limit: '10mb' }),
      
      // 4. Rate limiting
      this.rateLimiters.get('default'),
      
      // 5. API í‚¤ ê²€ì¦
      this.apiKeyMiddleware.bind(this),
      
      // 6. ìš”ì²­ ì„œëª… ê²€ì¦ (ì„ íƒì )
      this.signatureMiddleware.bind(this),
      
      // 7. ì…ë ¥ ê²€ì¦ ë° ì‚´ê· 
      this.inputValidationMiddleware.bind(this),
      
      // 8. ê°ì‚¬ ë¡œê¹…
      this.auditLoggingMiddleware.bind(this)
    ];
  }
}
```

### SubTask 1.11.4: ë°ì´í„° ì•”í˜¸í™” ë° ë³´ì•ˆ ì €ì¥ì†Œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ë¯¼ê°í•œ ë°ì´í„°ì˜ ì•”í˜¸í™” ë° ì•ˆì „í•œ ì €ì¥ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/encryption/data-encryption.ts
import { KMSClient, GenerateDataKeyCommand, DecryptCommand } from '@aws-sdk/client-kms';
import crypto from 'crypto';

export class DataEncryptionService {
  private kmsClient: KMSClient;
  private dataKeyCache: LRUCache<string, Buffer>;
  
  constructor(
    private config: EncryptionConfig
  ) {
    this.kmsClient = new KMSClient({
      region: config.awsRegion
    });
    this.dataKeyCache = new LRUCache({
      max: 100,
      ttl: 1000 * 60 * 60 // 1ì‹œê°„
    });
  }
  
  // í•„ë“œ ë ˆë²¨ ì•”í˜¸í™”
  async encryptField(
    plaintext: string,
    context?: EncryptionContext
  ): Promise<EncryptedField> {
    // ë°ì´í„° í‚¤ ìƒì„± ë˜ëŠ” ìºì‹œì—ì„œ ê°€ì ¸ì˜¤ê¸°
    const dataKey = await this.getOrGenerateDataKey(context);
    
    // AES-256-GCMìœ¼ë¡œ ì•”í˜¸í™”
    const iv = crypto.randomBytes(16);
    const cipher = crypto.createCipheriv(
      'aes-256-gcm',
      dataKey.plaintext,
      iv
    );
    
    const encrypted = Buffer.concat([
      cipher.update(plaintext, 'utf8'),
      cipher.final()
    ]);
    
    const authTag = cipher.getAuthTag();
    
    return {
      ciphertext: encrypted.toString('base64'),
      iv: iv.toString('base64'),
      authTag: authTag.toString('base64'),
      keyId: dataKey.keyId,
      algorithm: 'AES-256-GCM',
      context
    };
  }
  
  async decryptField(
    encryptedField: EncryptedField
  ): Promise<string> {
    // ë°ì´í„° í‚¤ ë³µí˜¸í™”
    const dataKey = await this.decryptDataKey(
      encryptedField.keyId,
      encryptedField.context
    );
    
    // AES-256-GCMìœ¼ë¡œ ë³µí˜¸í™”
    const decipher = crypto.createDecipheriv(
      'aes-256-gcm',
      dataKey,
      Buffer.from(encryptedField.iv, 'base64')
    );
    
    decipher.setAuthTag(
      Buffer.from(encryptedField.authTag, 'base64')
    );
    
    const decrypted = Buffer.concat([
      decipher.update(
        Buffer.from(encryptedField.ciphertext, 'base64')
      ),
      decipher.final()
    ]);
    
    return decrypted.toString('utf8');
  }
  
  // íˆ¬ëª…í•œ ì•”í˜¸í™” ë˜í¼
  createEncryptedModel<T extends object>(
    model: T,
    encryptedFields: string[]
  ): EncryptedModel<T> {
    return new Proxy(model, {
      get: async (target, prop) => {
        if (encryptedFields.includes(prop as string)) {
          const encryptedValue = target[prop];
          if (encryptedValue && typeof encryptedValue === 'object') {
            return await this.decryptField(encryptedValue);
          }
        }
        return target[prop];
      },
      
      set: async (target, prop, value) => {
        if (encryptedFields.includes(prop as string)) {
          target[prop] = await this.encryptField(value);
        } else {
          target[prop] = value;
        }
        return true;
      }
    }) as EncryptedModel<T>;
  }
  
  // íŒŒì¼ ì•”í˜¸í™”
  async encryptFile(
    filePath: string,
    outputPath: string
  ): Promise<FileEncryptionResult> {
    const dataKey = await this.getOrGenerateDataKey();
    
    // ìŠ¤íŠ¸ë¦¼ ì•”í˜¸í™”
    const iv = crypto.randomBytes(16);
    const cipher = crypto.createCipheriv(
      'aes-256-gcm',
      dataKey.plaintext,
      iv
    );
    
    const input = fs.createReadStream(filePath);
    const output = fs.createWriteStream(outputPath);
    
    // ë©”íƒ€ë°ì´í„° í—¤ë” ì‘ì„±
    const header = {
      version: 1,
      keyId: dataKey.keyId,
      iv: iv.toString('base64'),
      algorithm: 'AES-256-GCM'
    };
    
    output.write(JSON.stringify(header) + '\n');
    
    // íŒŒì¼ ì•”í˜¸í™”
    return new Promise((resolve, reject) => {
      input
        .pipe(cipher)
        .pipe(output)
        .on('finish', () => {
          const authTag = cipher.getAuthTag();
          
          // ì¸ì¦ íƒœê·¸ ì¶”ê°€
          fs.appendFileSync(outputPath, '\n' + authTag.toString('base64'));
          
          resolve({
            encryptedPath: outputPath,
            keyId: dataKey.keyId,
            size: fs.statSync(outputPath).size,
            checksum: this.calculateChecksum(outputPath)
          });
        })
        .on('error', reject);
    });
  }
  
  // ë³´ì•ˆ í‚¤ ì €ì¥ì†Œ
  async storeSecureSecret(
    name: string,
    value: string,
    options?: SecretOptions
  ): Promise<void> {
    // AWS Secrets Manager ì‚¬ìš©
    const client = new SecretsManagerClient({
      region: this.config.awsRegion
    });
    
    const encrypted = await this.encryptField(value, {
      purpose: 'secret-storage',
      name
    });
    
    await client.send(new CreateSecretCommand({
      Name: `t-developer/${this.config.environment}/${name}`,
      SecretString: JSON.stringify(encrypted),
      Tags: [
        { Key: 'Application', Value: 'T-Developer' },
        { Key: 'Environment', Value: this.config.environment },
        { Key: 'Encrypted', Value: 'true' }
      ],
      KmsKeyId: this.config.kmsKeyId
    }));
  }
  
  // ë³´ì•ˆ ê°ì‚¬ ë¡œê·¸
  async logSecurityEvent(event: SecurityEvent): Promise<void> {
    const encryptedEvent = {
      ...event,
      sensitiveData: event.sensitiveData 
        ? await this.encryptField(
            JSON.stringify(event.sensitiveData),
            { purpose: 'audit-log' }
          )
        : undefined,
      timestamp: new Date().toISOString(),
      environment: this.config.environment
    };
    
    // CloudWatch Logsì— ì•”í˜¸í™”ëœ ë¡œê·¸ ì „ì†¡
    await this.cloudWatchClient.send(new PutLogEventsCommand({
      logGroupName: `/aws/t-developer/security/${this.config.environment}`,
      logStreamName: `security-events-${new Date().toISOString().split('T')[0]}`,
      logEvents: [{
        timestamp: Date.now(),
        message: JSON.stringify(encryptedEvent)
      }]
    }));
  }
}

// ì•”í˜¸í™”ëœ DynamoDB í…Œì´ë¸” ë˜í¼
export class EncryptedDynamoDBTable {
  constructor(
    private tableName: string,
    private encryptionService: DataEncryptionService,
    private encryptedAttributes: string[]
  ) {}
  
  async putItem(item: Record<string, any>): Promise<void> {
    const encryptedItem = { ...item };
    
    // ì§€ì •ëœ ì†ì„± ì•”í˜¸í™”
    for (const attr of this.encryptedAttributes) {
      if (item[attr] !== undefined) {
        encryptedItem[attr] = await this.encryptionService.encryptField(
          typeof item[attr] === 'string' 
            ? item[attr] 
            : JSON.stringify(item[attr])
        );
      }
    }
    
    await this.dynamoClient.send(new PutCommand({
      TableName: this.tableName,
      Item: encryptedItem
    }));
  }
  
  async getItem(key: Record<string, any>): Promise<any> {
    const response = await this.dynamoClient.send(new GetCommand({
      TableName: this.tableName,
      Key: key
    }));
    
    if (!response.Item) return null;
    
    const decryptedItem = { ...response.Item };
    
    // ì•”í˜¸í™”ëœ ì†ì„± ë³µí˜¸í™”
    for (const attr of this.encryptedAttributes) {
      if (decryptedItem[attr] && typeof decryptedItem[attr] === 'object') {
        const decrypted = await this.encryptionService.decryptField(
          decryptedItem[attr]
        );
        
        try {
          decryptedItem[attr] = JSON.parse(decrypted);
        } catch {
          decryptedItem[attr] = decrypted;
        }
      }
    }
    
    return decryptedItem;
  }
}
```


## Task 1.12: DynamoDB ì—°ê²° ì„¤ì •

### SubTask 1.12.1: DynamoDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ë° ì—°ê²° í’€
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: íš¨ìœ¨ì ì¸ DynamoDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ë° ì—°ê²° ê´€ë¦¬

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/data/dynamodb/client.ts
import { 
  DynamoDBClient, 
  DynamoDBClientConfig,
  RetryStrategy 
} from '@aws-sdk/client-dynamodb';
import { 
  DynamoDBDocumentClient,
  TranslateConfig 
} from '@aws-sdk/lib-dynamodb';
import { NodeHttpHandler } from '@aws-sdk/node-http-handler';
import { Agent } from 'https';

export interface DynamoDBConnectionConfig {
  region: string;
  endpoint?: string;
  maxRetries?: number;
  maxSockets?: number;
  keepAlive?: boolean;
  connectionTimeout?: number;
  requestTimeout?: number;
}

export class DynamoDBConnectionManager {
  private clients: Map<string, DynamoDBDocumentClient>;
  private metrics: ConnectionMetrics;
  
  constructor(
    private config: DynamoDBConnectionConfig
  ) {
    this.clients = new Map();
    this.metrics = new ConnectionMetrics();
    
    this.initializePrimaryClient();
  }
  
  private initializePrimaryClient(): void {
    // HTTPS Agent ì„¤ì • (ì—°ê²° ì¬ì‚¬ìš©)
    const agent = new Agent({
      maxSockets: this.config.maxSockets || 50,
      keepAlive: this.config.keepAlive ?? true,
      keepAliveMsecs: 1000,
      rejectUnauthorized: true
    });
    
    // ì‚¬ìš©ì ì •ì˜ ì¬ì‹œë„ ì „ëµ
    const retryStrategy: RetryStrategy = {
      mode: 'adaptive',
      maxAttempts: this.config.maxRetries || 3,
      retryDecider: (error: any) => {
        // ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ íŒë‹¨
        if (error.name === 'ProvisionedThroughputExceededException' ||
            error.name === 'ThrottlingException' ||
            error.name === 'ServiceUnavailable' ||
            error.statusCode === 503) {
          return true;
        }
        return false;
      },
      delayDecider: (delayBase: number, attempts: number) => {
        // ì§€ìˆ˜ ë°±ì˜¤í”„ with jitter
        const delay = Math.min(
          delayBase * Math.pow(2, attempts) + Math.random() * 1000,
          20000 // ìµœëŒ€ 20ì´ˆ
        );
        return delay;
      }
    };
    
    // DynamoDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    const clientConfig: DynamoDBClientConfig = {
      region: this.config.region,
      endpoint: this.config.endpoint,
      maxAttempts: this.config.maxRetries || 3,
      requestHandler: new NodeHttpHandler({
        httpsAgent: agent,
        connectionTimeout: this.config.connectionTimeout || 3000,
        requestTimeout: this.config.requestTimeout || 5000
      }),
      retryStrategy
    };
    
    // ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    const baseClient = new DynamoDBClient(clientConfig);
    
    // Document í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    const translateConfig: TranslateConfig = {
      marshallOptions: {
        convertEmptyValues: false,
        removeUndefinedValues: true,
        convertClassInstanceToMap: true
      },
      unmarshallOptions: {
        wrapNumbers: false
      }
    };
    
    const docClient = DynamoDBDocumentClient.from(
      baseClient,
      translateConfig
    );
    
    // í´ë¼ì´ì–¸íŠ¸ ì¸í„°ì…‰í„° ì¶”ê°€
    this.addClientInterceptors(docClient);
    
    this.clients.set('primary', docClient);
  }
  
  private addClientInterceptors(client: DynamoDBDocumentClient): void {
    // ìš”ì²­ ì¸í„°ì…‰í„°
    client.middlewareStack.add(
      (next) => async (args) => {
        const start = Date.now();
        
        try {
          // ìš”ì²­ ë¡œê¹…
          this.logRequest(args);
          
          // ë©”íŠ¸ë¦­ ìˆ˜ì§‘
          this.metrics.incrementRequests();
          
          const result = await next(args);
          
          // ì„±ê³µ ë©”íŠ¸ë¦­
          this.metrics.recordLatency(Date.now() - start);
          this.metrics.incrementSuccess();
          
          return result;
          
        } catch (error) {
          // ì—ëŸ¬ ë©”íŠ¸ë¦­
          this.metrics.incrementErrors(error.name);
          
          // ì—ëŸ¬ ë¡œê¹…
          this.logError(error, args);
          
          throw error;
        }
      },
      {
        step: 'finalizeRequest',
        name: 'metricsMiddleware',
        tags: ['METRICS']
      }
    );
  }
  
  // ì½ê¸° ì „ìš© ë³µì œë³¸ í´ë¼ì´ì–¸íŠ¸
  async getReadReplicaClient(): Promise<DynamoDBDocumentClient> {
    if (!this.clients.has('read-replica')) {
      const replicaConfig = {
        ...this.config,
        region: this.config.readReplicaRegion || this.config.region
      };
      
      const replicaClient = this.createClient(replicaConfig);
      this.clients.set('read-replica', replicaClient);
    }
    
    return this.clients.get('read-replica')!;
  }
  
  // íŠ¸ëœì­ì…˜ ì „ìš© í´ë¼ì´ì–¸íŠ¸
  getTransactionClient(): DynamoDBDocumentClient {
    if (!this.clients.has('transaction')) {
      const txConfig = {
        ...this.config,
        maxRetries: 5, // íŠ¸ëœì­ì…˜ì€ ë” ë§ì€ ì¬ì‹œë„
        requestTimeout: 10000 // ë” ê¸´ íƒ€ì„ì•„ì›ƒ
      };
      
      const txClient = this.createClient(txConfig);
      this.clients.set('transaction', txClient);
    }
    
    return this.clients.get('transaction')!;
  }
  
  // ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§
  async healthCheck(): Promise<HealthCheckResult> {
    const results: HealthCheckResult = {
      status: 'healthy',
      clients: {},
      metrics: this.metrics.getSummary()
    };
    
    for (const [name, client] of this.clients) {
      try {
        // ê°„ë‹¨í•œ DescribeTable í˜¸ì¶œë¡œ ì—°ê²° í™•ì¸
        const start = Date.now();
        await client.send(new DescribeTableCommand({
          TableName: 'HealthCheck'
        }));
        
        results.clients[name] = {
          status: 'healthy',
          latency: Date.now() - start
        };
      } catch (error) {
        results.clients[name] = {
          status: 'unhealthy',
          error: error.message
        };
        results.status = 'degraded';
      }
    }
    
    return results;
  }
  
  // ì—°ê²° í’€ í†µê³„
  getConnectionStats(): ConnectionStats {
    return {
      activeConnections: this.clients.size,
      totalRequests: this.metrics.totalRequests,
      successRate: this.metrics.getSuccessRate(),
      averageLatency: this.metrics.getAverageLatency(),
      errorsByType: this.metrics.getErrorBreakdown()
    };
  }
}

// ì—°ê²° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
class ConnectionMetrics {
  private requests = 0;
  private successes = 0;
  private errors = new Map<string, number>();
  private latencies: number[] = [];
  private windowStart = Date.now();
  
  incrementRequests(): void {
    this.requests++;
  }
  
  incrementSuccess(): void {
    this.successes++;
  }
  
  incrementErrors(errorType: string): void {
    this.errors.set(errorType, (this.errors.get(errorType) || 0) + 1);
  }
  
  recordLatency(ms: number): void {
    this.latencies.push(ms);
    
    // ìŠ¬ë¼ì´ë”© ìœˆë„ìš° (ìµœê·¼ 1000ê°œë§Œ ìœ ì§€)
    if (this.latencies.length > 1000) {
      this.latencies.shift();
    }
  }
  
  getSummary(): MetricsSummary {
    const now = Date.now();
    const duration = (now - this.windowStart) / 1000; // ì´ˆ
    
    return {
      requestsPerSecond: this.requests / duration,
      successRate: this.requests > 0 ? this.successes / this.requests : 1,
      averageLatency: this.getAverageLatency(),
      p95Latency: this.getPercentileLatency(95),
      p99Latency: this.getPercentileLatency(99),
      errorRate: this.requests > 0 
        ? (this.requests - this.successes) / this.requests 
        : 0,
      uptime: duration
    };
  }
  
  private getPercentileLatency(percentile: number): number {
    if (this.latencies.length === 0) return 0;
    
    const sorted = [...this.latencies].sort((a, b) => a - b);
    const index = Math.ceil((percentile / 100) * sorted.length) - 1;
    return sorted[index];
  }
}
```

### SubTask 1.12.2: ë‹¨ì¼ í…Œì´ë¸” ì„¤ê³„ íŒ¨í„´ êµ¬í˜„
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: DynamoDB ë‹¨ì¼ í…Œì´ë¸” ì„¤ê³„ íŒ¨í„´ì„ í™œìš©í•œ íš¨ìœ¨ì ì¸ ë°ì´í„° ëª¨ë¸ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/data/dynamodb/single-table-design.ts
export interface TableDesign {
  tableName: string;
  partitionKey: string;
  sortKey: string;
  gsiDefinitions: GSIDefinition[];
  lsiDefinitions: LSIDefinition[];
}

export class SingleTableDesign {
  private readonly TABLE_NAME = 'T-Developer-Main';
  
  // ì—”í‹°í‹° íƒ€ì… ì •ì˜
  private readonly EntityTypes = {
    USER: 'USER',
    PROJECT: 'PROJECT',
    AGENT: 'AGENT',
    SESSION: 'SESSION',
    EXECUTION: 'EXECUTION',
    COMPONENT: 'COMPONENT',
    TEMPLATE: 'TEMPLATE',
    METRICS: 'METRICS'
  } as const;
  
  // í‚¤ ìƒì„± ì „ëµ
  generateKeys(entityType: string, entityId: string): KeySchema {
    switch (entityType) {
      case this.EntityTypes.USER:
        return {
          PK: `USER#${entityId}`,
          SK: `METADATA#${entityId}`
        };
        
      case this.EntityTypes.PROJECT:
        return {
          PK: `PROJECT#${entityId}`,
          SK: `METADATA#${entityId}`
        };
        
      case this.EntityTypes.AGENT:
        return {
          PK: `AGENT#${entityId}`,
          SK: `CONFIG#${entityId}`
        };
        
      case this.EntityTypes.SESSION:
        return {
          PK: `SESSION#${entityId}`,
          SK: `DETAILS#${new Date().toISOString()}`
        };
        
      default:
        throw new Error(`Unknown entity type: ${entityType}`);
    }
  }
  
  // ê´€ê³„ ëª¨ë¸ë§
  generateRelationshipKeys(
    parentType: string,
    parentId: string,
    childType: string,
    childId: string
  ): KeySchema {
    return {
      PK: `${parentType}#${parentId}`,
      SK: `${childType}#${childId}`
    };
  }
  
  // GSI í‚¤ ìƒì„±
  generateGSIKeys(indexName: string, entity: any): GSIKeySchema {
    switch (indexName) {
      case 'GSI1': // ì‚¬ìš©ìë³„ ì¡°íšŒ
        return {
          GSI1PK: `USER#${entity.userId}`,
          GSI1SK: `${entity.entityType}#${entity.createdAt}`
        };
        
      case 'GSI2': // í”„ë¡œì íŠ¸ë³„ ì¡°íšŒ
        return {
          GSI2PK: `PROJECT#${entity.projectId}`,
          GSI2SK: `${entity.entityType}#${entity.updatedAt}`
        };
        
      case 'GSI3': // ìƒíƒœë³„ ì¡°íšŒ
        return {
          GSI3PK: `STATUS#${entity.status}`,
          GSI3SK: `${entity.entityType}#${entity.id}`
        };
        
      default:
        return {};
    }
  }
  
  // ì ‘ê·¼ íŒ¨í„´ êµ¬í˜„
  async implementAccessPatterns(): Promise<AccessPatternImplementation[]> {
    return [
      // 1. ì‚¬ìš©ìì˜ ëª¨ë“  í”„ë¡œì íŠ¸ ì¡°íšŒ
      {
        name: 'GetProjectsByUser',
        index: 'GSI1',
        keyCondition: 'GSI1PK = :userId AND begins_with(GSI1SK, :prefix)',
        implementation: async (userId: string) => {
          return await this.query({
            IndexName: 'GSI1',
            KeyConditionExpression: 'GSI1PK = :pk AND begins_with(GSI1SK, :sk)',
            ExpressionAttributeValues: {
              ':pk': `USER#${userId}`,
              ':sk': 'PROJECT#'
            }
          });
        }
      },
      
      // 2. í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¡°íšŒ
      {
        name: 'GetExecutionsByProject',
        index: 'GSI2',
        keyCondition: 'GSI2PK = :projectId AND begins_with(GSI2SK, :prefix)',
        implementation: async (projectId: string, dateRange?: DateRange) => {
          let keyCondition = 'GSI2PK = :pk';
          const values: any = { ':pk': `PROJECT#${projectId}` };
          
          if (dateRange) {
            keyCondition += ' AND GSI2SK BETWEEN :start AND :end';
            values[':start'] = `EXECUTION#${dateRange.start}`;
            values[':end'] = `EXECUTION#${dateRange.end}`;
          } else {
            keyCondition += ' AND begins_with(GSI2SK, :sk)';
            values[':sk'] = 'EXECUTION#';
          }
          
          return await this.query({
            IndexName: 'GSI2',
            KeyConditionExpression: keyCondition,
            ExpressionAttributeValues: values,
            ScanIndexForward: false // ìµœì‹ ìˆœ
          });
        }
      },
      
      // 3. ê³„ì¸µì  ë°ì´í„° ì¡°íšŒ (í”„ë¡œì íŠ¸ > ì»´í¬ë„ŒíŠ¸ > ì„œë¸Œì»´í¬ë„ŒíŠ¸)
      {
        name: 'GetProjectHierarchy',
        index: 'Primary',
        keyCondition: 'PK = :projectId',
        implementation: async (projectId: string) => {
          const items = await this.query({
            KeyConditionExpression: 'PK = :pk',
            ExpressionAttributeValues: {
              ':pk': `PROJECT#${projectId}`
            }
          });
          
          // ê³„ì¸µ êµ¬ì¡°ë¡œ ì¬êµ¬ì„±
          return this.buildHierarchy(items);
        }
      }
    ];
  }
  
  // íŠ¸ëœì­ì…˜ íŒ¨í„´
  async createProjectWithComponents(
    project: Project,
    components: Component[]
  ): Promise<void> {
    const transactItems: TransactWriteItem[] = [];
    
    // í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„°
    transactItems.push({
      Put: {
        TableName: this.TABLE_NAME,
        Item: {
          ...this.generateKeys(this.EntityTypes.PROJECT, project.id),
          ...this.generateGSIKeys('GSI1', project),
          ...this.generateGSIKeys('GSI2', project),
          entityType: this.EntityTypes.PROJECT,
          ...project,
          createdAt: new Date().toISOString()
        }
      }
    });
    
    // ì»´í¬ë„ŒíŠ¸ë“¤
    for (const component of components) {
      // ì»´í¬ë„ŒíŠ¸ ë©”íƒ€ë°ì´í„°
      transactItems.push({
        Put: {
          TableName: this.TABLE_NAME,
          Item: {
            PK: `PROJECT#${project.id}`,
            SK: `COMPONENT#${component.id}`,
            ...this.generateGSIKeys('GSI2', { 
              ...component, 
              projectId: project.id 
            }),
            entityType: this.EntityTypes.COMPONENT,
            ...component
          }
        }
      });
      
      // ì»´í¬ë„ŒíŠ¸ ê´€ê³„
      transactItems.push({
        Put: {
          TableName: this.TABLE_NAME,
          Item: {
            PK: `COMPONENT#${component.id}`,
            SK: `METADATA#${component.id}`,
            entityType: this.EntityTypes.COMPONENT,
            projectId: project.id,
            ...component
          }
        }
      });
    }
    
    // ì›ìì  ì‹¤í–‰
    await this.docClient.send(new TransactWriteCommand({
      TransactItems: transactItems
    }));
  }
  
  // íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì¡°íšŒ
  async batchGetRelatedEntities(
    entityId: string,
    entityType: string,
    relationTypes: string[]
  ): Promise<Map<string, any[]>> {
    const results = new Map<string, any[]>();
    
    // ë³‘ë ¬ ì¿¼ë¦¬ ì‹¤í–‰
    const queries = relationTypes.map(relationType => 
      this.query({
        KeyConditionExpression: 'PK = :pk AND begins_with(SK, :sk)',
        ExpressionAttributeValues: {
          ':pk': `${entityType}#${entityId}`,
          ':sk': `${relationType}#`
        }
      })
    );
    
    const queryResults = await Promise.all(queries);
    
    // ê²°ê³¼ ë§¤í•‘
    relationTypes.forEach((relationType, index) => {
      results.set(relationType, queryResults[index]);
    });
    
    return results;
  }
  
  // ìŠ¤íŒŒìŠ¤ ì¸ë±ìŠ¤ í™œìš©
  async createSparseIndex(
    attributeName: string,
    entities: any[]
  ): Promise<void> {
    const updates = entities
      .filter(entity => entity[attributeName] !== undefined)
      .map(entity => ({
        Update: {
          TableName: this.TABLE_NAME,
          Key: this.generateKeys(entity.entityType, entity.id),
          UpdateExpression: 'SET #attr = :value, GSI4PK = :gsi4pk, GSI4SK = :gsi4sk',
          ExpressionAttributeNames: {
            '#attr': attributeName
          },
          ExpressionAttributeValues: {
            ':value': entity[attributeName],
            ':gsi4pk': `${attributeName.toUpperCase()}#${entity[attributeName]}`,
            ':gsi4sk': `${entity.entityType}#${entity.id}`
          }
        }
      }));
    
    // ë°°ì¹˜ ì—…ë°ì´íŠ¸
    for (let i = 0; i < updates.length; i += 25) {
      const batch = updates.slice(i, i + 25);
      await this.docClient.send(new TransactWriteCommand({
        TransactItems: batch
      }));
    }
  }
}

// ì¿¼ë¦¬ ë¹Œë”
export class DynamoQueryBuilder {
  private params: any = {
    TableName: '',
    KeyConditionExpression: '',
    ExpressionAttributeValues: {},
    ExpressionAttributeNames: {}
  };
  
  table(name: string): this {
    this.params.TableName = name;
    return this;
  }
  
  index(name: string): this {
    this.params.IndexName = name;
    return this;
  }
  
  where(attribute: string, operator: string, value: any): this {
    const placeholder = `:${attribute.toLowerCase()}`;
    
    switch (operator) {
      case '=':
        this.params.KeyConditionExpression = `${attribute} = ${placeholder}`;
        break;
      case 'begins_with':
        this.params.KeyConditionExpression = `begins_with(${attribute}, ${placeholder})`;
        break;
      case 'between':
        const [start, end] = value;
        this.params.KeyConditionExpression = `${attribute} BETWEEN :start AND :end`;
        this.params.ExpressionAttributeValues[':start'] = start;
        this.params.ExpressionAttributeValues[':end'] = end;
        return this;
    }
    
    this.params.ExpressionAttributeValues[placeholder] = value;
    return this;
  }
  
  filter(expression: string, values: Record<string, any>): this {
    this.params.FilterExpression = expression;
    Object.assign(this.params.ExpressionAttributeValues, values);
    return this;
  }
  
  limit(count: number): this {
    this.params.Limit = count;
    return this;
  }
  
  orderBy(ascending: boolean = true): this {
    this.params.ScanIndexForward = ascending;
    return this;
  }
  
  build(): QueryCommandInput {
    return this.params;
  }
}
```

### SubTask 1.12.3: ì¿¼ë¦¬ ìµœì í™” ë° ì¸ë±ì‹± ì „ëµ
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: DynamoDB ì¿¼ë¦¬ ì„±ëŠ¥ ìµœì í™” ë° íš¨ìœ¨ì ì¸ ì¸ë±ì‹± ì „ëµ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/data/dynamodb/query-optimizer.ts
export class DynamoDBQueryOptimizer {
  private queryCache: LRUCache<string, CachedQuery>;
  private hotPartitionDetector: HotPartitionDetector;
  
  constructor(
    private tableDesign: SingleTableDesign,
    private metrics: MetricsCollector
  ) {
    this.queryCache = new LRUCache({ 
      max: 1000,
      ttl: 1000 * 60 * 5 // 5ë¶„
    });
    this.hotPartitionDetector = new HotPartitionDetector();
  }
  
  // ì¿¼ë¦¬ ìµœì í™”
  async optimizeQuery(
    originalQuery: QueryCommandInput
  ): Promise<OptimizedQuery> {
    const queryHash = this.hashQuery(originalQuery);
    
    // ìºì‹œ í™•ì¸
    const cached = this.queryCache.get(queryHash);
    if (cached && cached.isValid()) {
      return cached.optimizedQuery;
    }
    
    // ì¿¼ë¦¬ ë¶„ì„
    const analysis = await this.analyzeQuery(originalQuery);
    
    // ìµœì í™” ì „ëµ ì ìš©
    const optimized = await this.applyOptimizations(
      originalQuery,
      analysis
    );
    
    // ìºì‹œ ì €ì¥
    this.queryCache.set(queryHash, {
      originalQuery,
      optimizedQuery: optimized,
      analysis,
      timestamp: Date.now()
    });
    
    return optimized;
  }
  
  private async analyzeQuery(
    query: QueryCommandInput
  ): Promise<QueryAnalysis> {
    const analysis: QueryAnalysis = {
      estimatedItemCount: 0,
      estimatedRCU: 0,
      indexEfficiency: 0,
      partitionKeyDistribution: 'unknown',
      suggestions: []
    };
    
    // 1. ì˜ˆìƒ ì•„ì´í…œ ìˆ˜ ì¶”ì •
    const stats = await this.getTableStatistics(query.TableName);
    analysis.estimatedItemCount = this.estimateItemCount(query, stats);
    
    // 2. RCU ê³„ì‚°
    analysis.estimatedRCU = this.calculateRCU(
      analysis.estimatedItemCount,
      this.getAverageItemSize(query.TableName)
    );
    
    // 3. ì¸ë±ìŠ¤ íš¨ìœ¨ì„± í‰ê°€
    if (query.IndexName) {
      analysis.indexEfficiency = await this.evaluateIndexEfficiency(
        query.TableName,
        query.IndexName,
        query.KeyConditionExpression
      );
    }
    
    // 4. íŒŒí‹°ì…˜ í‚¤ ë¶„í¬ ë¶„ì„
    analysis.partitionKeyDistribution = 
      await this.analyzePartitionKeyDistribution(query);
    
    // 5. ìµœì í™” ì œì•ˆ ìƒì„±
    analysis.suggestions = this.generateOptimizationSuggestions(analysis);
    
    return analysis;
  }
  
  private async applyOptimizations(
    query: QueryCommandInput,
    analysis: QueryAnalysis
  ): Promise<OptimizedQuery> {
    let optimized = { ...query };
    
    // 1. í”„ë¡œì ì…˜ ìµœì í™”
    if (!optimized.ProjectionExpression) {
      optimized = this.addOptimalProjection(optimized, analysis);
    }
    
    // 2. í˜ì´ì§€ë„¤ì´ì…˜ ìµœì í™”
    if (analysis.estimatedItemCount > 100) {
      optimized = this.optimizePagination(optimized);
    }
    
    // 3. ë³‘ë ¬ ì¿¼ë¦¬ ì „ëµ
    if (analysis.estimatedRCU > 1000) {
      return this.createParallelQueryStrategy(optimized, analysis);
    }
    
    // 4. í•« íŒŒí‹°ì…˜ íšŒí”¼
    if (analysis.partitionKeyDistribution === 'hot') {
      optimized = await this.applyHotPartitionMitigation(optimized);
    }
    
    return {
      query: optimized,
      strategy: 'single',
      estimatedCost: analysis.estimatedRCU
    };
  }
  
  // ë³‘ë ¬ ì¿¼ë¦¬ ì „ëµ
  private createParallelQueryStrategy(
    query: QueryCommandInput,
    analysis: QueryAnalysis
  ): ParallelQueryStrategy {
    const segments = this.calculateOptimalSegments(analysis.estimatedRCU);
    
    return {
      query,
      strategy: 'parallel',
      segments,
      queries: Array.from({ length: segments }, (_, i) => ({
        ...query,
        Segment: i,
        TotalSegments: segments
      })),
      estimatedCost: analysis.estimatedRCU,
      execute: async () => {
        const results = await Promise.all(
          this.queries.map(q => 
            this.docClient.send(new QueryCommand(q))
          )
        );
        
        // ê²°ê³¼ ë³‘í•©
        return {
          Items: results.flatMap(r => r.Items || []),
          Count: results.reduce((sum, r) => sum + (r.Count || 0), 0),
          ScannedCount: results.reduce((sum, r) => sum + (r.ScannedCount || 0), 0)
        };
      }
    };
  }
  
  // ì ì‘í˜• ì¿¼ë¦¬ ì‹¤í–‰
  async executeAdaptiveQuery(
    query: QueryCommandInput,
    options?: AdaptiveQueryOptions
  ): Promise<QueryResult> {
    const startTime = Date.now();
    let result: QueryResult;
    
    try {
      // ì¿¼ë¦¬ ìµœì í™”
      const optimized = await this.optimizeQuery(query);
      
      // ì‹¤í–‰
      if (optimized.strategy === 'parallel') {
        result = await optimized.execute();
      } else {
        result = await this.docClient.send(
          new QueryCommand(optimized.query)
        );
      }
      
      // ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
      this.collectQueryMetrics({
        query,
        optimized,
        result,
        duration: Date.now() - startTime
      });
      
      // í•™ìŠµ ë° ì ì‘
      await this.learnFromExecution(query, result, optimized);
      
      return result;
      
    } catch (error) {
      // ì—ëŸ¬ ì²˜ë¦¬ ë° í´ë°± ì „ëµ
      if (error.name === 'ProvisionedThroughputExceededException') {
        return await this.handleThrottling(query, options);
      }
      throw error;
    }
  }
  
  // ì¸ë±ìŠ¤ ì¶”ì²œ ì‹œìŠ¤í…œ
  async recommendIndexes(
    accessPatterns: AccessPattern[]
  ): Promise<IndexRecommendation[]> {
    const recommendations: IndexRecommendation[] = [];
    
    // í˜„ì¬ ì¸ë±ìŠ¤ ì‚¬ìš© íŒ¨í„´ ë¶„ì„
    const currentUsage = await this.analyzeCurrentIndexUsage();
    
    // ê° ì ‘ê·¼ íŒ¨í„´ ë¶„ì„
    for (const pattern of accessPatterns) {
      const coverage = this.calculateIndexCoverage(pattern, currentUsage);
      
      if (coverage < 0.8) { // 80% ë¯¸ë§Œ ì»¤ë²„ë¦¬ì§€
        const recommendation = this.generateIndexRecommendation(
          pattern,
          currentUsage
        );
        
        if (recommendation) {
          recommendations.push(recommendation);
        }
      }
    }
    
    // ì¤‘ë³µ ì œê±° ë° ìš°ì„ ìˆœìœ„ ì •ë ¬
    return this.prioritizeRecommendations(recommendations);
  }
  
  // ì¿¼ë¦¬ ë¹„ìš© ì˜ˆì¸¡
  async estimateQueryCost(
    query: QueryCommandInput,
    expectedFrequency: number
  ): Promise<QueryCostEstimate> {
    const analysis = await this.analyzeQuery(query);
    
    const hourlyCost = analysis.estimatedRCU * expectedFrequency;
    const monthlyCost = hourlyCost * 24 * 30;
    
    return {
      rcuPerQuery: analysis.estimatedRCU,
      expectedQueriesPerHour: expectedFrequency,
      hourlyRCU: hourlyCost,
      monthlyRCU: monthlyCost,
      estimatedMonthlyCost: this.calculateDynamoDBCost(monthlyCost),
      optimizationPotential: this.calculateOptimizationPotential(analysis),
      recommendations: analysis.suggestions
    };
  }
}

// í•« íŒŒí‹°ì…˜ ê°ì§€ê¸°
class HotPartitionDetector {
  private partitionMetrics: Map<string, PartitionMetrics>;
  
  constructor() {
    this.partitionMetrics = new Map();
  }
  
  async detectHotPartitions(
    tableName: string,
    timeWindow: number = 300000 // 5ë¶„
  ): Promise<HotPartition[]> {
    const metrics = await this.collectPartitionMetrics(tableName);
    const threshold = this.calculateDynamicThreshold(metrics);
    
    const hotPartitions: HotPartition[] = [];
    
    for (const [partitionKey, metric] of metrics) {
      if (metric.requestRate > threshold) {
        hotPartitions.push({
          partitionKey,
          requestRate: metric.requestRate,
          throttleRate: metric.throttleRate,
          suggestions: this.generateMitigationSuggestions(metric)
        });
      }
    }
    
    return hotPartitions;
  }
  
  private generateMitigationSuggestions(
    metric: PartitionMetrics
  ): string[] {
    const suggestions: string[] = [];
    
    if (metric.requestRate > 3000) {
      suggestions.push('Consider sharding this partition key');
    }
    
    if (metric.throttleRate > 0.05) {
      suggestions.push('Implement exponential backoff');
      suggestions.push('Consider using DynamoDB auto-scaling');
    }
    
    if (metric.burstiness > 0.8) {
      suggestions.push('Implement request smoothing');
      suggestions.push('Use SQS to buffer requests');
    }
    
    return suggestions;
  }
}
```

### SubTask 1.12.4: ë°ì´í„° ì¼ê´€ì„± ë° íŠ¸ëœì­ì…˜ ê´€ë¦¬
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: DynamoDBì—ì„œ ë°ì´í„° ì¼ê´€ì„±ì„ ë³´ì¥í•˜ê³  ë³µì¡í•œ íŠ¸ëœì­ì…˜ì„ ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/data/dynamodb/transaction-manager.ts
export class DynamoDBTransactionManager {
  private pendingTransactions: Map<string, PendingTransaction>;
  private transactionLog: TransactionLog;
  
  constructor(
    private docClient: DynamoDBDocumentClient,
    private tableName: string
  ) {
    this.pendingTransactions = new Map();
    this.transactionLog = new TransactionLog(docClient);
  }
  
  // ë¶„ì‚° íŠ¸ëœì­ì…˜ êµ¬í˜„ (Saga íŒ¨í„´)
  async executeSaga<T>(
    sagaDefinition: SagaDefinition<T>
  ): Promise<SagaResult<T>> {
    const sagaId = crypto.randomUUID();
    const saga: Saga<T> = {
      id: sagaId,
      status: 'pending',
      steps: sagaDefinition.steps,
      compensations: [],
      startedAt: new Date(),
      context: sagaDefinition.initialContext || {} as T
    };
    
    // íŠ¸ëœì­ì…˜ ë¡œê·¸ ì‹œì‘
    await this.transactionLog.logStart(saga);
    
    try {
      // ê° ìŠ¤í… ì‹¤í–‰
      for (let i = 0; i < saga.steps.length; i++) {
        const step = saga.steps[i];
        
        try {
          // ìŠ¤í… ì‹¤í–‰
          const result = await this.executeStep(step, saga.context);
          
          // ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
          saga.context = { ...saga.context, ...result };
          
          // ë³´ìƒ íŠ¸ëœì­ì…˜ ê¸°ë¡
          if (step.compensation) {
            saga.compensations.push({
              stepIndex: i,
              compensation: step.compensation,
              context: { ...saga.context }
            });
          }
          
          // ì§„í–‰ ìƒí™© ë¡œê¹…
          await this.transactionLog.logProgress(sagaId, i, 'completed');
          
        } catch (error) {
          // ìŠ¤í… ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
          await this.rollbackSaga(saga, i, error);
          throw error;
        }
      }
      
      // ì„±ê³µ ì™„ë£Œ
      saga.status = 'completed';
      await this.transactionLog.logComplete(saga);
      
      return {
        success: true,
        sagaId,
        result: saga.context
      };
      
    } catch (error) {
      saga.status = 'failed';
      await this.transactionLog.logFailure(saga, error);
      
      return {
        success: false,
        sagaId,
        error: error.message
      };
    }
  }
  
  private async rollbackSaga<T>(
    saga: Saga<T>,
    failedStepIndex: number,
    error: Error
  ): Promise<void> {
    console.log(`Rolling back saga ${saga.id} from step ${failedStepIndex}`);
    
    // ì—­ìˆœìœ¼ë¡œ ë³´ìƒ íŠ¸ëœì­ì…˜ ì‹¤í–‰
    for (let i = saga.compensations.length - 1; i >= 0; i--) {
      const compensation = saga.compensations[i];
      
      try {
        await this.executeCompensation(
          compensation.compensation,
          compensation.context
        );
        
        await this.transactionLog.logCompensation(
          saga.id,
          compensation.stepIndex,
          'completed'
        );
      } catch (compensationError) {
        // ë³´ìƒ ì‹¤íŒ¨ëŠ” ë¡œê¹…í•˜ê³  ê³„ì† ì§„í–‰
        await this.transactionLog.logCompensation(
          saga.id,
          compensation.stepIndex,
          'failed',
          compensationError
        );
      }
    }
  }
  
  // ì¡°ê±´ë¶€ íŠ¸ëœì­ì…˜
  async conditionalTransaction(
    operations: ConditionalOperation[]
  ): Promise<TransactionResult> {
    const transactItems: TransactWriteItem[] = [];
    
    for (const op of operations) {
      const item = this.buildTransactItem(op);
      transactItems.push(item);
    }
    
    try {
      await this.docClient.send(new TransactWriteCommand({
        TransactItems: transactItems,
        ClientRequestToken: crypto.randomUUID()
      }));
      
      return { success: true };
      
    } catch (error) {
      if (error.name === 'TransactionCanceledException') {
        // ì–´ë–¤ ì¡°ê±´ì´ ì‹¤íŒ¨í–ˆëŠ”ì§€ ë¶„ì„
        const failures = this.analyzeTransactionFailure(
          error.CancellationReasons
        );
        
        return {
          success: false,
          failures,
          error: 'Transaction cancelled due to condition failures'
        };
      }
      throw error;
    }
  }
  
  // ë‚™ê´€ì  ë™ì‹œì„± ì œì–´
  async optimisticUpdate<T>(
    key: DynamoDBKey,
    updateFn: (current: T) => T,
    options?: OptimisticOptions
  ): Promise<T> {
    const maxRetries = options?.maxRetries || 3;
    let attempts = 0;
    
    while (attempts < maxRetries) {
      try {
        // í˜„ì¬ ê°’ ì¡°íšŒ
        const current = await this.getItem(key);
        if (!current) {
          throw new Error('Item not found');
        }
        
        // ë²„ì „ í™•ì¸
        const currentVersion = current.version || 0;
        
        // ì—…ë°ì´íŠ¸ ì ìš©
        const updated = updateFn(current as T);
        
        // ì¡°ê±´ë¶€ ì—…ë°ì´íŠ¸
        await this.docClient.send(new UpdateCommand({
          TableName: this.tableName,
          Key: key,
          UpdateExpression: 'SET #data = :data, #version = :newVersion',
          ConditionExpression: '#version = :currentVersion',
          ExpressionAttributeNames: {
            '#data': 'data',
            '#version': 'version'
          },
          ExpressionAttributeValues: {
            ':data': updated,
            ':newVersion': currentVersion + 1,
            ':currentVersion': currentVersion
          }
        }));
        
        return updated;
        
      } catch (error) {
        if (error.name === 'ConditionalCheckFailedException') {
          attempts++;
          
          if (attempts >= maxRetries) {
            throw new Error('Optimistic lock failed after max retries');
          }
          
          // ì§€ìˆ˜ ë°±ì˜¤í”„
          await this.delay(Math.pow(2, attempts) * 100);
          continue;
        }
        throw error;
      }
    }
  }
  
  // ì´ë²¤íŠ¸ ì†Œì‹± íŒ¨í„´
  async appendEvent(
    aggregateId: string,
    event: DomainEvent
  ): Promise<void> {
    const eventItem = {
      PK: `AGGREGATE#${aggregateId}`,
      SK: `EVENT#${event.timestamp}#${event.id}`,
      aggregateId,
      eventId: event.id,
      eventType: event.type,
      eventData: event.data,
      timestamp: event.timestamp,
      version: event.version,
      metadata: event.metadata
    };
    
    // ì´ë²¤íŠ¸ ì €ì¥
    await this.docClient.send(new PutCommand({
      TableName: this.tableName,
      Item: eventItem,
      ConditionExpression: 'attribute_not_exists(SK)'
    }));
    
    // ìŠ¤ëƒ…ìƒ· ì²´í¬
    await this.checkAndCreateSnapshot(aggregateId);
  }
  
  // ì¼ê´€ì„± ê²€ì¦
  async validateConsistency(
    entityId: string,
    rules: ConsistencyRule[]
  ): Promise<ConsistencyValidation> {
    const validation: ConsistencyValidation = {
      entityId,
      timestamp: new Date(),
      valid: true,
      violations: []
    };
    
    for (const rule of rules) {
      try {
        const result = await this.executeConsistencyRule(entityId, rule);
        
        if (!result.valid) {
          validation.valid = false;
          validation.violations.push({
            rule: rule.name,
            message: result.message,
            severity: rule.severity,
            data: result.data
          });
        }
      } catch (error) {
        validation.valid = false;
        validation.violations.push({
          rule: rule.name,
          message: `Rule execution failed: ${error.message}`,
          severity: 'error'
        });
      }
    }
    
    // ê²€ì¦ ê²°ê³¼ ë¡œê¹…
    await this.logConsistencyCheck(validation);
    
    return validation;
  }
  
  // ë¶„ì‚° ì ê¸ˆ
  async acquireDistributedLock(
    resourceId: string,
    ttl: number = 30000
  ): Promise<DistributedLock> {
    const lockId = crypto.randomUUID();
    const expiresAt = Date.now() + ttl;
    
    try {
      await this.docClient.send(new PutCommand({
        TableName: this.tableName,
        Item: {
          PK: `LOCK#${resourceId}`,
          SK: 'ACTIVE',
          lockId,
          owner: process.env.INSTANCE_ID || 'unknown',
          acquiredAt: Date.now(),
          expiresAt,
          ttl: Math.floor(expiresAt / 1000)
        },
        ConditionExpression: 'attribute_not_exists(PK) OR expiresAt < :now',
        ExpressionAttributeValues: {
          ':now': Date.now()
        }
      }));
      
      return {
        lockId,
        resourceId,
        acquired: true,
        expiresAt,
        release: async () => {
          await this.releaseLock(resourceId, lockId);
        },
        extend: async (additionalTtl: number) => {
          await this.extendLock(resourceId, lockId, additionalTtl);
        }
      };
      
    } catch (error) {
      if (error.name === 'ConditionalCheckFailedException') {
        return {
          lockId: null,
          resourceId,
          acquired: false,
          error: 'Resource is already locked'
        };
      }
      throw error;
    }
  }
}

// íŠ¸ëœì­ì…˜ ë¡œê·¸
class TransactionLog {
  constructor(private docClient: DynamoDBDocumentClient) {}
  
  async logStart<T>(saga: Saga<T>): Promise<void> {
    await this.docClient.send(new PutCommand({
      TableName: 'TransactionLogs',
      Item: {
        PK: `SAGA#${saga.id}`,
        SK: `LOG#${new Date().toISOString()}`,
        type: 'start',
        sagaId: saga.id,
        steps: saga.steps.map(s => s.name),
        timestamp: new Date().toISOString()
      }
    }));
  }
  
  async queryTransactionHistory(
    sagaId: string
  ): Promise<TransactionHistory> {
    const result = await this.docClient.send(new QueryCommand({
      TableName: 'TransactionLogs',
      KeyConditionExpression: 'PK = :pk',
      ExpressionAttributeValues: {
        ':pk': `SAGA#${sagaId}`
      },
      ScanIndexForward: true
    }));
    
    return {
      sagaId,
      events: result.Items || [],
      duration: this.calculateDuration(result.Items),
      status: this.determineStatus(result.Items)
    };
  }
}
```

## Task 1.13: ìºì‹± ì‹œìŠ¤í…œ êµ¬ì¶•

### SubTask 1.13.1: Redis í´ëŸ¬ìŠ¤í„° ì„¤ì •
**ë‹´ë‹¹ì**: ì¸í”„ë¼ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ê³ ê°€ìš©ì„± Redis í´ëŸ¬ìŠ¤í„° êµ¬ì„± ë° ì—°ê²° ì„¤ì •

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/cache/redis/cluster-manager.ts
import Redis, { Cluster, ClusterOptions } from 'ioredis';
import { EventEmitter } from 'events';

export interface RedisClusterConfig {
  nodes: RedisNode[];
  options: ClusterOptions;
  healthCheckInterval: number;
  connectionPoolSize: number;
}

export interface RedisNode {
  host: string;
  port: number;
  role?: 'master' | 'slave';
}

export class RedisClusterManager extends EventEmitter {
  private cluster: Cluster;
  private healthChecker: NodeJS.Timer;
  private connectionPool: Map<string, Redis>;
  
  constructor(private config: RedisClusterConfig) {
    super();
    this.connectionPool = new Map();
    this.initializeCluster();
  }
  
  private initializeCluster(): void {
    const clusterOptions: ClusterOptions = {
      ...this.config.options,
      clusterRetryStrategy: (times) => {
        if (times > 3) {
          this.emit('error', new Error('Redis cluster connection failed'));
          return null;
        }
        return Math.min(times * 100, 3000);
      },
      enableReadyCheck: true,
      enableOfflineQueue: true,
      maxRetriesPerRequest: 3,
      
      // ì—°ê²° í’€ ì„¤ì •
      connectionPoolSize: this.config.connectionPoolSize,
      slotsRefreshTimeout: 2000,
      
      // ì„±ëŠ¥ ìµœì í™”
      lazyConnect: false,
      readOnly: true, // ì½ê¸° ì¿¼ë¦¬ë¥¼ ìŠ¬ë ˆì´ë¸Œë¡œ ë¼ìš°íŒ…
      
      // ëª¨ë‹ˆí„°ë§
      sentinelRetryStrategy: (times) => Math.min(times * 50, 500)
    };
    
    // í´ëŸ¬ìŠ¤í„° ìƒì„±
    this.cluster = new Cluster(
      this.config.nodes.map(node => ({
        host: node.host,
        port: node.port
      })),
      clusterOptions
    );
    
    this.setupEventHandlers();
    this.startHealthMonitoring();
  }
  
  private setupEventHandlers(): void {
    this.cluster.on('connect', () => {
      console.log('Redis cluster connected');
      this.emit('connected');
    });
    
    this.cluster.on('ready', () => {
      console.log('Redis cluster ready');
      this.emit('ready');
    });
    
    this.cluster.on('error', (error) => {
      console.error('Redis cluster error:', error);
      this.emit('error', error);
    });
    
    this.cluster.on('node error', (error, node) => {
      console.error(`Redis node error on ${node}:`, error);
      this.emit('nodeError', { error, node });
    });
    
    this.cluster.on('+node', (node) => {
      console.log(`New Redis node added: ${node}`);
      this.emit('nodeAdded', node);
    });
    
    this.cluster.on('-node', (node) => {
      console.log(`Redis node removed: ${node}`);
      this.emit('nodeRemoved', node);
    });
  }
  
  // í—¬ìŠ¤ ì²´í¬ ëª¨ë‹ˆí„°ë§
  private startHealthMonitoring(): void {
    this.healthChecker = setInterval(async () => {
      try {
        const health = await this.performHealthCheck();
        this.emit('healthCheck', health);
        
        if (!health.healthy) {
          await this.handleUnhealthyCluster(health);
        }
      } catch (error) {
        console.error('Health check failed:', error);
      }
    }, this.config.healthCheckInterval);
  }
  
  private async performHealthCheck(): Promise<ClusterHealth> {
    const nodes = this.cluster.nodes('all');
    const health: ClusterHealth = {
      healthy: true,
      totalNodes: nodes.length,
      healthyNodes: 0,
      unhealthyNodes: 0,
      nodeStatuses: []
    };
    
    // ê° ë…¸ë“œ ìƒíƒœ í™•ì¸
    for (const node of nodes) {
      try {
        const start = Date.now();
        await node.ping();
        const latency = Date.now() - start;
        
        const info = await node.info();
        const role = this.parseRole(info);
        const memory = this.parseMemoryUsage(info);
        
        health.nodeStatuses.push({
          address: `${node.options.host}:${node.options.port}`,
          status: 'healthy',
          role,
          latency,
          memoryUsage: memory,
          connectedClients: this.parseConnectedClients(info)
        });
        
        health.healthyNodes++;
        
      } catch (error) {
        health.nodeStatuses.push({
          address: `${node.options.host}:${node.options.port}`,
          status: 'unhealthy',
          error: error.message
        });
        
        health.unhealthyNodes++;
        health.healthy = false;
      }
    }
    
    return health;
  }
  
  // íŒŒí‹°ì…˜ ê¸°ë°˜ ìºì‹±
  async getPartitionedCache(
    partition: string
  ): Promise<PartitionedCache> {
    const poolKey = `partition:${partition}`;
    
    if (!this.connectionPool.has(poolKey)) {
      const connection = this.cluster.duplicate();
      this.connectionPool.set(poolKey, connection);
    }
    
    return new PartitionedCache(
      this.connectionPool.get(poolKey)!,
      partition
    );
  }
  
  // ìºì‹œ ì›Œë°
  async warmCache(
    keys: string[],
    loader: (keys: string[]) => Promise<Map<string, any>>
  ): Promise<WarmingResult> {
    const result: WarmingResult = {
      totalKeys: keys.length,
      warmedKeys: 0,
      failedKeys: 0,
      duration: 0
    };
    
    const start = Date.now();
    const batchSize = 100;
    
    // ë°°ì¹˜ ì²˜ë¦¬
    for (let i = 0; i < keys.length; i += batchSize) {
      const batch = keys.slice(i, i + batchSize);
      
      try {
        // ë°ì´í„° ë¡œë“œ
        const data = await loader(batch);
        
        // Redis íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì €ì¥
        const pipeline = this.cluster.pipeline();
        
        for (const [key, value] of data) {
          pipeline.setex(
            key,
            3600, // 1ì‹œê°„ TTL
            JSON.stringify(value)
          );
          result.warmedKeys++;
        }
        
        await pipeline.exec();
        
      } catch (error) {
        console.error('Cache warming batch failed:', error);
        result.failedKeys += batch.length;
      }
    }
    
    result.duration = Date.now() - start;
    return result;
  }
  
  // ì§€ëŠ¥í˜• ìºì‹œ ë¬´íš¨í™”
  async intelligentInvalidation(
    pattern: string,
    strategy: InvalidationStrategy
  ): Promise<void> {
    switch (strategy) {
      case 'immediate':
        await this.immediateInvalidation(pattern);
        break;
        
      case 'lazy':
        await this.lazyInvalidation(pattern);
        break;
        
      case 'scheduled':
        await this.scheduleInvalidation(pattern);
        break;
        
      case 'cascade':
        await this.cascadeInvalidation(pattern);
        break;
    }
  }
  
  // ë¶„ì‚° ìºì‹œ ë™ê¸°í™”
  async syncAcrossNodes(
    key: string,
    value: any,
    options?: SyncOptions
  ): Promise<void> {
    const nodes = this.cluster.nodes('master');
    const promises: Promise<any>[] = [];
    
    for (const node of nodes) {
      const promise = node.setex(
        key,
        options?.ttl || 3600,
        JSON.stringify(value)
      );
      promises.push(promise);
    }
    
    // ì¼ê´€ì„± ë ˆë²¨ì— ë”°ë¥¸ ì²˜ë¦¬
    if (options?.consistency === 'strong') {
      await Promise.all(promises);
    } else if (options?.consistency === 'eventual') {
      // ë¹„ë™ê¸° ì²˜ë¦¬
      Promise.all(promises).catch(error => {
        console.error('Cache sync failed:', error);
      });
    }
  }
}

// íŒŒí‹°ì…˜ëœ ìºì‹œ êµ¬í˜„
class PartitionedCache {
  constructor(
    private redis: Redis,
    private partition: string
  ) {}
  
  private getKey(key: string): string {
    return `${this.partition}:${key}`;
  }
  
  async get<T>(key: string): Promise<T | null> {
    const value = await this.redis.get(this.getKey(key));
    return value ? JSON.parse(value) : null;
  }
  
  async set<T>(
    key: string,
    value: T,
    ttl?: number
  ): Promise<void> {
    const serialized = JSON.stringify(value);
    
    if (ttl) {
      await this.redis.setex(this.getKey(key), ttl, serialized);
    } else {
      await this.redis.set(this.getKey(key), serialized);
    }
  }
  
  async mget<T>(keys: string[]): Promise<Map<string, T>> {
    const fullKeys = keys.map(k => this.getKey(k));
    const values = await this.redis.mget(...fullKeys);
    
    const result = new Map<string, T>();
    keys.forEach((key, index) => {
      if (values[index]) {
        result.set(key, JSON.parse(values[index]!));
      }
    });
    
    return result;
  }
  
  async delete(pattern: string): Promise<number> {
    const keys = await this.redis.keys(this.getKey(pattern));
    if (keys.length === 0) return 0;
    
    return await this.redis.del(...keys);
  }
}
```


### SubTask 1.13.2: ìºì‹± ì „ëµ ë° íŒ¨í„´ êµ¬í˜„
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: íš¨ìœ¨ì ì¸ ìºì‹± ì „ëµê³¼ ë‹¤ì–‘í•œ ìºì‹± íŒ¨í„´ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/cache/strategies/caching-strategies.ts
export interface CacheStrategy {
  get<T>(key: string, fetcher?: () => Promise<T>): Promise<T | null>;
  set<T>(key: string, value: T, options?: CacheOptions): Promise<void>;
  invalidate(key: string | string[]): Promise<void>;
  refresh<T>(key: string, fetcher: () => Promise<T>): Promise<T>;
}

// Cache-Aside (Lazy Loading) íŒ¨í„´
export class CacheAsideStrategy implements CacheStrategy {
  constructor(
    private cache: RedisCache,
    private config: CacheConfig
  ) {}
  
  async get<T>(
    key: string, 
    fetcher?: () => Promise<T>
  ): Promise<T | null> {
    // 1. ìºì‹œì—ì„œ ì¡°íšŒ
    const cached = await this.cache.get<T>(key);
    if (cached !== null) {
      this.metrics.recordHit(key);
      return cached;
    }
    
    this.metrics.recordMiss(key);
    
    // 2. fetcherê°€ ìˆìœ¼ë©´ ë°ì´í„° ë¡œë“œ í›„ ìºì‹±
    if (fetcher) {
      const data = await fetcher();
      await this.set(key, data);
      return data;
    }
    
    return null;
  }
  
  async set<T>(
    key: string, 
    value: T, 
    options?: CacheOptions
  ): Promise<void> {
    const ttl = options?.ttl || this.config.defaultTTL;
    const compressed = await this.compress(value);
    
    await this.cache.set(key, compressed, {
      ttl,
      tags: options?.tags
    });
  }
}

// Write-Through íŒ¨í„´
export class WriteThroughStrategy implements CacheStrategy {
  constructor(
    private cache: RedisCache,
    private dataStore: DataStore
  ) {}
  
  async set<T>(
    key: string,
    value: T,
    options?: CacheOptions
  ): Promise<void> {
    // 1. ë°ì´í„° ìŠ¤í† ì–´ì— ë¨¼ì € ì €ì¥
    await this.dataStore.save(key, value);
    
    // 2. ìºì‹œì— ì €ì¥
    await this.cache.set(key, value, options);
    
    // 3. ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”
    await this.invalidateRelated(key, value);
  }
  
  private async invalidateRelated(
    key: string,
    value: any
  ): Promise<void> {
    const relations = this.analyzeRelations(key, value);
    
    for (const pattern of relations) {
      await this.cache.invalidatePattern(pattern);
    }
  }
}

// Write-Behind (Write-Back) íŒ¨í„´
export class WriteBehindStrategy implements CacheStrategy {
  private writeQueue: WriteQueue;
  private batchProcessor: NodeJS.Timer;
  
  constructor(
    private cache: RedisCache,
    private dataStore: DataStore,
    private config: WriteBehindConfig
  ) {
    this.writeQueue = new WriteQueue();
    this.startBatchProcessor();
  }
  
  async set<T>(
    key: string,
    value: T,
    options?: CacheOptions
  ): Promise<void> {
    // 1. ì¦‰ì‹œ ìºì‹œì— ì €ì¥
    await this.cache.set(key, value, options);
    
    // 2. ì“°ê¸° íì— ì¶”ê°€
    this.writeQueue.enqueue({
      key,
      value,
      timestamp: Date.now(),
      attempts: 0
    });
  }
  
  private startBatchProcessor(): void {
    this.batchProcessor = setInterval(async () => {
      const batch = this.writeQueue.dequeueBatch(
        this.config.batchSize
      );
      
      if (batch.length > 0) {
        await this.processBatch(batch);
      }
    }, this.config.flushInterval);
  }
  
  private async processBatch(
    batch: WriteQueueItem[]
  ): Promise<void> {
    try {
      // ë°°ì¹˜ ì“°ê¸°
      await this.dataStore.batchSave(
        batch.map(item => ({
          key: item.key,
          value: item.value
        }))
      );
      
      // ì„±ê³µ ë©”íŠ¸ë¦­
      this.metrics.recordBatchSuccess(batch.length);
      
    } catch (error) {
      // ì‹¤íŒ¨í•œ í•­ëª© ì¬ì‹œë„ íì— ì¶”ê°€
      for (const item of batch) {
        item.attempts++;
        
        if (item.attempts < this.config.maxRetries) {
          this.writeQueue.enqueueRetry(item);
        } else {
          // ë°ë“œë ˆí„° íë¡œ ì´ë™
          await this.moveToDeadLetter(item);
        }
      }
      
      this.metrics.recordBatchFailure(batch.length);
    }
  }
}

// ê³„ì¸µì  ìºì‹± ì „ëµ
export class TieredCachingStrategy implements CacheStrategy {
  private tiers: CacheTier[];
  
  constructor(tiers: CacheTier[]) {
    this.tiers = tiers.sort((a, b) => a.priority - b.priority);
  }
  
  async get<T>(
    key: string,
    fetcher?: () => Promise<T>
  ): Promise<T | null> {
    // ê° ê³„ì¸µì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ì¡°íšŒ
    for (let i = 0; i < this.tiers.length; i++) {
      const tier = this.tiers[i];
      const value = await tier.cache.get<T>(key);
      
      if (value !== null) {
        // ìƒìœ„ ê³„ì¸µì— í”„ë¡œëª¨ì…˜
        await this.promoteToUpperTiers(key, value, i);
        return value;
      }
    }
    
    // ëª¨ë“  ê³„ì¸µì—ì„œ missì¸ ê²½ìš°
    if (fetcher) {
      const value = await fetcher();
      await this.populateAllTiers(key, value);
      return value;
    }
    
    return null;
  }
  
  private async promoteToUpperTiers<T>(
    key: string,
    value: T,
    foundTierIndex: number
  ): Promise<void> {
    // ë°œê²¬ëœ ê³„ì¸µë³´ë‹¤ ìƒìœ„ ê³„ì¸µì— ë°ì´í„° ë³µì‚¬
    const promotions = [];
    
    for (let i = 0; i < foundTierIndex; i++) {
      const tier = this.tiers[i];
      promotions.push(
        tier.cache.set(key, value, {
          ttl: tier.ttl
        })
      );
    }
    
    await Promise.all(promotions);
  }
}

// ì ì‘í˜• ìºì‹± ì „ëµ
export class AdaptiveCachingStrategy implements CacheStrategy {
  private accessPatterns: AccessPatternAnalyzer;
  private strategies: Map<string, CacheStrategy>;
  
  constructor(
    private cache: RedisCache,
    private config: AdaptiveConfig
  ) {
    this.accessPatterns = new AccessPatternAnalyzer();
    this.strategies = new Map();
    this.initializeStrategies();
  }
  
  async get<T>(
    key: string,
    fetcher?: () => Promise<T>
  ): Promise<T | null> {
    // ì ‘ê·¼ íŒ¨í„´ ë¶„ì„
    const pattern = await this.accessPatterns.analyze(key);
    
    // ìµœì  ì „ëµ ì„ íƒ
    const strategy = this.selectOptimalStrategy(pattern);
    
    // ì „ëµ ì‹¤í–‰
    return strategy.get(key, fetcher);
  }
  
  private selectOptimalStrategy(
    pattern: AccessPattern
  ): CacheStrategy {
    // ì½ê¸°ê°€ ë§ì€ íŒ¨í„´
    if (pattern.readWriteRatio > 10) {
      return this.strategies.get('cache-aside')!;
    }
    
    // ì“°ê¸°ê°€ ë§ì€ íŒ¨í„´
    if (pattern.writeFrequency > 100) {
      return this.strategies.get('write-behind')!;
    }
    
    // ì¼ê´€ì„±ì´ ì¤‘ìš”í•œ íŒ¨í„´
    if (pattern.consistencyRequirement === 'strong') {
      return this.strategies.get('write-through')!;
    }
    
    // ê¸°ë³¸ ì „ëµ
    return this.strategies.get('cache-aside')!;
  }
  
  // TTL ìë™ ì¡°ì •
  async optimizeTTL(key: string): Promise<number> {
    const stats = await this.accessPatterns.getKeyStats(key);
    
    // ì ‘ê·¼ ë¹ˆë„ì— ë”°ë¥¸ TTL ê³„ì‚°
    const accessFrequency = stats.accessCount / stats.timeWindow;
    const updateFrequency = stats.updateCount / stats.timeWindow;
    
    if (accessFrequency > 100 && updateFrequency < 1) {
      // ìì£¼ ì½íˆê³  ê±°ì˜ ì—…ë°ì´íŠ¸ë˜ì§€ ì•ŠìŒ
      return 3600 * 24; // 24ì‹œê°„
    } else if (accessFrequency > 10 && updateFrequency < 10) {
      // ë³´í†µ ë¹ˆë„
      return 3600; // 1ì‹œê°„
    } else {
      // ìì£¼ ë³€ê²½ë¨
      return 300; // 5ë¶„
    }
  }
}

// ìºì‹œ ì›Œë° ì „ëµ
export class CacheWarmingStrategy {
  private scheduler: CronJob;
  
  constructor(
    private cache: RedisCache,
    private dataSource: DataSource
  ) {}
  
  // ì˜ˆì¸¡ ê¸°ë°˜ ì›Œë°
  async predictiveWarming(): Promise<void> {
    const predictions = await this.predictNextPeriodKeys();
    
    for (const prediction of predictions) {
      if (prediction.probability > 0.7) {
        const data = await this.dataSource.load(prediction.key);
        await this.cache.set(prediction.key, data, {
          ttl: prediction.expectedDuration
        });
      }
    }
  }
  
  // ìŠ¤ì¼€ì¤„ ê¸°ë°˜ ì›Œë°
  scheduleWarming(
    pattern: string,
    schedule: string,
    loader: () => Promise<Map<string, any>>
  ): void {
    this.scheduler = new CronJob(schedule, async () => {
      try {
        const data = await loader();
        
        const pipeline = this.cache.pipeline();
        for (const [key, value] of data) {
          pipeline.setex(key, 3600, JSON.stringify(value));
        }
        
        await pipeline.exec();
        
        console.log(`Warmed ${data.size} keys for pattern: ${pattern}`);
      } catch (error) {
        console.error('Cache warming failed:', error);
      }
    });
    
    this.scheduler.start();
  }
}

// ìºì‹œ ì¼ê´€ì„± ê´€ë¦¬
export class CacheConsistencyManager {
  private invalidationQueue: InvalidationQueue;
  
  constructor(
    private cache: RedisCache,
    private pubsub: RedisPubSub
  ) {
    this.invalidationQueue = new InvalidationQueue();
    this.setupInvalidationHandlers();
  }
  
  // ì´ë²¤íŠ¸ ê¸°ë°˜ ë¬´íš¨í™”
  private setupInvalidationHandlers(): void {
    this.pubsub.subscribe('data:updated', async (event) => {
      await this.handleDataUpdate(event);
    });
    
    this.pubsub.subscribe('data:deleted', async (event) => {
      await this.handleDataDeletion(event);
    });
  }
  
  private async handleDataUpdate(
    event: DataUpdateEvent
  ): Promise<void> {
    // ì§ì ‘ ê´€ë ¨ í‚¤ ë¬´íš¨í™”
    await this.cache.delete(event.primaryKey);
    
    // ì¢…ì† í‚¤ ë¬´íš¨í™”
    const dependencies = await this.findDependencies(event.primaryKey);
    await this.cache.deleteMany(dependencies);
    
    // íƒœê·¸ ê¸°ë°˜ ë¬´íš¨í™”
    if (event.tags) {
      for (const tag of event.tags) {
        await this.cache.invalidateByTag(tag);
      }
    }
  }
  
  // ë¶„ì‚° í™˜ê²½ì—ì„œì˜ ì¼ê´€ì„±
  async ensureConsistency(
    operation: ConsistencyOperation
  ): Promise<void> {
    const lock = await this.acquireLock(operation.key);
    
    try {
      // 1. ëª¨ë“  ë…¸ë“œì—ì„œ ìºì‹œ ë¬´íš¨í™”
      await this.broadcastInvalidation(operation.key);
      
      // 2. ë°ì´í„° ì—…ë°ì´íŠ¸
      await operation.execute();
      
      // 3. ìºì‹œ ì¬êµ¬ì¶• (ì„ íƒì )
      if (operation.rebuild) {
        const data = await operation.rebuild();
        await this.cache.set(operation.key, data);
      }
    } finally {
      await lock.release();
    }
  }
}
```

### SubTask 1.13.3: ìºì‹œ ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„
**ë‹´ë‹¹ì**: ë°ì´í„° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ìºì‹œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„ ë„êµ¬ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/cache/monitoring/cache-monitor.ts
export class CacheMonitor {
  private metrics: CacheMetrics;
  private analyzer: CacheAnalyzer;
  private alertManager: AlertManager;
  
  constructor(
    private cache: RedisCache,
    private config: MonitorConfig
  ) {
    this.metrics = new CacheMetrics();
    this.analyzer = new CacheAnalyzer();
    this.alertManager = new AlertManager();
    
    this.startMonitoring();
  }
  
  private startMonitoring(): void {
    // ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    setInterval(() => this.collectMetrics(), 
      this.config.metricsInterval
    );
    
    // ë¶„ì„ ì‹¤í–‰
    setInterval(() => this.runAnalysis(), 
      this.config.analysisInterval
    );
  }
  
  private async collectMetrics(): Promise<void> {
    const stats = await this.cache.info();
    
    // íˆíŠ¸ìœ¨ ê³„ì‚°
    const hitRate = this.calculateHitRate(stats);
    this.metrics.gauge('cache.hit_rate', hitRate);
    
    // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    const memoryUsage = this.parseMemoryUsage(stats);
    this.metrics.gauge('cache.memory_used_bytes', memoryUsage.used);
    this.metrics.gauge('cache.memory_rss_bytes', memoryUsage.rss);
    
    // ì—°ê²° ìˆ˜
    this.metrics.gauge('cache.connected_clients', 
      stats.connected_clients
    );
    
    // ëª…ë ¹ì–´ ì²˜ë¦¬ìœ¨
    this.metrics.counter('cache.commands_processed', 
      stats.total_commands_processed
    );
    
    // í‚¤ í†µê³„
    const keyStats = await this.collectKeyStatistics();
    this.metrics.gauge('cache.total_keys', keyStats.totalKeys);
    this.metrics.gauge('cache.expired_keys', keyStats.expiredKeys);
    this.metrics.gauge('cache.evicted_keys', keyStats.evictedKeys);
  }
  
  private async runAnalysis(): Promise<void> {
    const analysis = await this.analyzer.analyze({
      hitRate: await this.getAverageHitRate(),
      memoryUsage: await this.getMemoryTrend(),
      keyDistribution: await this.analyzeKeyDistribution(),
      performanceMetrics: await this.getPerformanceMetrics()
    });
    
    // ì´ìƒ ê°ì§€
    if (analysis.anomalies.length > 0) {
      await this.handleAnomalies(analysis.anomalies);
    }
    
    // ìµœì í™” ì œì•ˆ
    if (analysis.suggestions.length > 0) {
      await this.applySuggestions(analysis.suggestions);
    }
  }
  
  // ìºì‹œ íˆíŠ¸ìœ¨ ë¶„ì„
  async analyzeHitRate(
    timeRange: TimeRange
  ): Promise<HitRateAnalysis> {
    const metrics = await this.metrics.query({
      metric: 'cache.hit_rate',
      start: timeRange.start,
      end: timeRange.end,
      step: '1m'
    });
    
    return {
      average: this.calculateAverage(metrics),
      min: Math.min(...metrics.map(m => m.value)),
      max: Math.max(...metrics.map(m => m.value)),
      trend: this.calculateTrend(metrics),
      volatility: this.calculateVolatility(metrics),
      recommendations: this.generateHitRateRecommendations(metrics)
    };
  }
  
  // ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ ë¶„ì„
  async analyzeMemoryPattern(): Promise<MemoryAnalysis> {
    const memoryData = await this.collectMemoryData();
    
    return {
      currentUsage: memoryData.current,
      peakUsage: memoryData.peak,
      averageObjectSize: memoryData.totalMemory / memoryData.totalKeys,
      fragmentationRatio: memoryData.rss / memoryData.used,
      evictionRisk: this.calculateEvictionRisk(memoryData),
      recommendations: this.generateMemoryRecommendations(memoryData)
    };
  }
  
  // í‚¤ ìˆ˜ëª… ë¶„ì„
  async analyzeKeyLifecycle(): Promise<KeyLifecycleAnalysis> {
    const sample = await this.sampleKeys(1000);
    const lifecycles: KeyLifecycle[] = [];
    
    for (const key of sample) {
      const ttl = await this.cache.ttl(key);
      const idleTime = await this.cache.idletime(key);
      const accessCount = await this.getKeyAccessCount(key);
      
      lifecycles.push({
        key,
        ttl,
        idleTime,
        accessCount,
        efficiency: this.calculateKeyEfficiency(
          ttl, 
          idleTime, 
          accessCount
        )
      });
    }
    
    return {
      averageTTL: this.average(lifecycles.map(l => l.ttl)),
      averageIdleTime: this.average(lifecycles.map(l => l.idleTime)),
      inefficientKeys: lifecycles.filter(l => l.efficiency < 0.3),
      recommendations: this.generateLifecycleRecommendations(lifecycles)
    };
  }
  
  // ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ë°ì´í„°
  async getDashboardData(): Promise<CacheDashboard> {
    const [
      currentStats,
      hitRateTrend,
      memoryTrend,
      topKeys,
      slowCommands
    ] = await Promise.all([
      this.getCurrentStats(),
      this.getHitRateTrend('-1h'),
      this.getMemoryTrend('-1h'),
      this.getTopKeys(10),
      this.getSlowCommands(10)
    ]);
    
    return {
      overview: {
        hitRate: currentStats.hitRate,
        memoryUsage: currentStats.memoryUsage,
        totalKeys: currentStats.totalKeys,
        connectedClients: currentStats.connectedClients,
        opsPerSecond: currentStats.opsPerSecond
      },
      charts: {
        hitRateTrend,
        memoryTrend,
        commandDistribution: await this.getCommandDistribution()
      },
      insights: {
        topKeys,
        slowCommands,
        anomalies: await this.getRecentAnomalies(),
        recommendations: await this.getCurrentRecommendations()
      }
    };
  }
  
  // ìºì‹œ ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±
  async generatePerformanceReport(
    period: ReportPeriod
  ): Promise<PerformanceReport> {
    const report: PerformanceReport = {
      period,
      summary: await this.generateSummary(period),
      metrics: {
        availability: await this.calculateAvailability(period),
        performance: await this.analyzePerformance(period),
        efficiency: await this.analyzeEfficiency(period),
        cost: await this.estimateCost(period)
      },
      incidents: await this.getIncidents(period),
      optimizations: await this.getAppliedOptimizations(period),
      recommendations: await this.generateRecommendations(period)
    };
    
    return report;
  }
}

// ìºì‹œ ì´ìƒ ê°ì§€
export class CacheAnomalyDetector {
  private baseline: BaselineMetrics;
  private detector: AnomalyDetector;
  
  constructor(private config: AnomalyConfig) {
    this.baseline = new BaselineMetrics();
    this.detector = new AnomalyDetector(config);
  }
  
  async detectAnomalies(
    metrics: CacheMetrics
  ): Promise<Anomaly[]> {
    const anomalies: Anomaly[] = [];
    
    // íˆíŠ¸ìœ¨ ì´ìƒ
    if (this.isAnomalous(metrics.hitRate, this.baseline.hitRate)) {
      anomalies.push({
        type: 'hit_rate',
        severity: this.calculateSeverity(
          metrics.hitRate, 
          this.baseline.hitRate
        ),
        value: metrics.hitRate,
        baseline: this.baseline.hitRate,
        timestamp: new Date()
      });
    }
    
    // ë©”ëª¨ë¦¬ ìŠ¤íŒŒì´í¬
    if (metrics.memoryUsage > this.baseline.memoryUsage * 1.5) {
      anomalies.push({
        type: 'memory_spike',
        severity: 'high',
        value: metrics.memoryUsage,
        baseline: this.baseline.memoryUsage,
        timestamp: new Date()
      });
    }
    
    // ì‘ë‹µ ì‹œê°„ ì €í•˜
    if (metrics.avgResponseTime > this.baseline.avgResponseTime * 2) {
      anomalies.push({
        type: 'slow_response',
        severity: 'medium',
        value: metrics.avgResponseTime,
        baseline: this.baseline.avgResponseTime,
        timestamp: new Date()
      });
    }
    
    return anomalies;
  }
  
  // ML ê¸°ë°˜ ì´ìƒ ê°ì§€
  async mlAnomalyDetection(
    timeseries: TimeseriesData
  ): Promise<MLAnomaly[]> {
    // Isolation Forest ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
    const anomalies = await this.detector.detectWithIsolationForest(
      timeseries,
      {
        contamination: 0.1,
        nEstimators: 100
      }
    );
    
    return anomalies.map(a => ({
      ...a,
      confidence: a.anomalyScore,
      suggestion: this.generateSuggestion(a)
    }));
  }
}
```

### SubTask 1.13.4: ë¶„ì‚° ìºì‹± ë° ìƒ¤ë”©
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: ëŒ€ê·œëª¨ ë¶„ì‚° í™˜ê²½ì—ì„œì˜ ìºì‹± ë° ìƒ¤ë”© ì „ëµ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/cache/distributed/sharding-manager.ts
export class CacheShardingManager {
  private shards: Map<string, CacheShard>;
  private consistentHash: ConsistentHash;
  private rebalancer: ShardRebalancer;
  
  constructor(
    private config: ShardingConfig,
    private clusterManager: RedisClusterManager
  ) {
    this.shards = new Map();
    this.consistentHash = new ConsistentHash(config.virtualNodes);
    this.rebalancer = new ShardRebalancer();
    
    this.initializeShards();
  }
  
  private async initializeShards(): Promise<void> {
    for (const shardConfig of this.config.shards) {
      const shard = new CacheShard({
        id: shardConfig.id,
        nodes: shardConfig.nodes,
        weight: shardConfig.weight,
        replicationFactor: shardConfig.replicationFactor
      });
      
      await shard.initialize();
      this.shards.set(shard.id, shard);
      
      // Consistent hashingì— ìƒ¤ë“œ ì¶”ê°€
      this.consistentHash.addNode(shard.id, shard.weight);
    }
  }
  
  // í‚¤ë¥¼ ìƒ¤ë“œì— ë§¤í•‘
  getShard(key: string): CacheShard {
    const shardId = this.consistentHash.getNode(key);
    const shard = this.shards.get(shardId);
    
    if (!shard) {
      throw new Error(`Shard not found for key: ${key}`);
    }
    
    return shard;
  }
  
  // ë¶„ì‚° get ì—°ì‚°
  async get<T>(key: string): Promise<T | null> {
    const shard = this.getShard(key);
    
    try {
      return await shard.get<T>(key);
    } catch (error) {
      // ì¥ì•  ì¡°ì¹˜: ë‹¤ë¥¸ ìƒ¤ë“œì—ì„œ ì‹œë„
      if (this.config.enableFailover) {
        return await this.getWithFailover<T>(key, shard.id);
      }
      throw error;
    }
  }
  
  // ë¶„ì‚° set ì—°ì‚°
  async set<T>(
    key: string, 
    value: T, 
    options?: DistributedCacheOptions
  ): Promise<void> {
    const shard = this.getShard(key);
    
    // ë³µì œ ì„¤ì •
    if (options?.replication) {
      await this.setWithReplication(key, value, options);
    } else {
      await shard.set(key, value, options);
    }
  }
  
  // ë³µì œë¥¼ í†µí•œ ê³ ê°€ìš©ì„±
  private async setWithReplication<T>(
    key: string,
    value: T,
    options: DistributedCacheOptions
  ): Promise<void> {
    const primaryShard = this.getShard(key);
    const replicaShards = this.getReplicaShards(
      primaryShard.id,
      options.replication!
    );
    
    // ë³‘ë ¬ë¡œ ëª¨ë“  ìƒ¤ë“œì— ì €ì¥
    const promises = [
      primaryShard.set(key, value, options),
      ...replicaShards.map(shard => 
        shard.set(key, value, { ...options, isReplica: true })
      )
    ];
    
    const results = await Promise.allSettled(promises);
    
    // ìµœì†Œ ì„±ê³µ ê°œìˆ˜ í™•ì¸
    const successCount = results.filter(r => 
      r.status === 'fulfilled'
    ).length;
    
    if (successCount < options.minReplicas!) {
      throw new Error(
        `Insufficient replicas: ${successCount}/${options.minReplicas}`
      );
    }
  }
  
  // ìƒ¤ë“œ ë¦¬ë°¸ëŸ°ì‹±
  async rebalanceShards(
    strategy: RebalanceStrategy = 'gradual'
  ): Promise<RebalanceResult> {
    const plan = await this.rebalancer.createPlan(
      this.shards,
      this.consistentHash
    );
    
    switch (strategy) {
      case 'immediate':
        return await this.immediateRebalance(plan);
        
      case 'gradual':
        return await this.gradualRebalance(plan);
        
      case 'scheduled':
        return await this.scheduleRebalance(plan);
    }
  }
  
  private async gradualRebalance(
    plan: RebalancePlan
  ): Promise<RebalanceResult> {
    const result: RebalanceResult = {
      movedKeys: 0,
      duration: 0,
      errors: []
    };
    
    const start = Date.now();
    
    for (const migration of plan.migrations) {
      try {
        // í‚¤ ë§ˆì´ê·¸ë ˆì´ì…˜
        const keys = await this.scanKeys(
          migration.sourceShard,
          migration.keyPattern
        );
        
        for (const batch of this.batchKeys(keys, 100)) {
          await this.migrateKeyBatch(
            batch,
            migration.sourceShard,
            migration.targetShard
          );
          
          result.movedKeys += batch.length;
          
          // ì†ë„ ì œí•œ
          await this.delay(this.config.rebalanceDelay);
        }
        
      } catch (error) {
        result.errors.push({
          migration,
          error: error.message
        });
      }
    }
    
    result.duration = Date.now() - start;
    return result;
  }
  
  // ì§€ëŠ¥í˜• ìƒ¤ë”© ì „ëµ
  async optimizeSharding(): Promise<ShardingOptimization> {
    const metrics = await this.collectShardMetrics();
    const analysis = this.analyzeShardDistribution(metrics);
    
    const optimization: ShardingOptimization = {
      currentDistribution: analysis.distribution,
      recommendations: [],
      estimatedImprovement: 0
    };
    
    // í•«ìŠ¤íŒŸ ê°ì§€
    const hotspots = analysis.shards.filter(s => 
      s.load > analysis.averageLoad * 1.5
    );
    
    for (const hotspot of hotspots) {
      optimization.recommendations.push({
        type: 'split_shard',
        shard: hotspot.id,
        reason: 'High load detected',
        expectedImprovement: 0.3
      });
    }
    
    // ì–¸ë”ìœ í‹¸ë¼ì´ì¦ˆë“œ ìƒ¤ë“œ
    const underutilized = analysis.shards.filter(s => 
      s.load < analysis.averageLoad * 0.5
    );
    
    if (underutilized.length >= 2) {
      optimization.recommendations.push({
        type: 'merge_shards',
        shards: underutilized.map(s => s.id),
        reason: 'Low utilization',
        expectedImprovement: 0.2
      });
    }
    
    return optimization;
  }
}

// ìƒ¤ë“œ êµ¬í˜„
class CacheShard {
  private primary: Redis;
  private replicas: Redis[];
  private healthChecker: HealthChecker;
  
  constructor(private config: ShardConfig) {
    this.replicas = [];
    this.healthChecker = new HealthChecker();
  }
  
  async initialize(): Promise<void> {
    // ì£¼ ë…¸ë“œ ì—°ê²°
    this.primary = await this.connectToNode(
      this.config.nodes[0]
    );
    
    // ë³µì œ ë…¸ë“œ ì—°ê²°
    for (let i = 1; i < this.config.nodes.length; i++) {
      const replica = await this.connectToNode(
        this.config.nodes[i]
      );
      this.replicas.push(replica);
    }
    
    // í—¬ìŠ¤ ì²´í¬ ì‹œì‘
    this.startHealthCheck();
  }
  
  async get<T>(key: string): Promise<T | null> {
    // ì½ê¸°ëŠ” ë³µì œë³¸ì—ì„œë„ ê°€ëŠ¥ (ë¶€í•˜ ë¶„ì‚°)
    const node = this.selectReadNode();
    
    try {
      const value = await node.get(key);
      return value ? JSON.parse(value) : null;
    } catch (error) {
      // ì¥ì•  ì¡°ì¹˜
      return await this.getWithFailover(key);
    }
  }
  
  private selectReadNode(): Redis {
    // ë¼ìš´ë“œ ë¡œë¹ˆ ë˜ëŠ” ìµœì†Œ ì—°ê²° ìˆ˜ ê¸°ë°˜ ì„ íƒ
    if (this.config.readPreference === 'primary') {
      return this.primary;
    }
    
    // ê±´ê°•í•œ ë…¸ë“œ ì¤‘ì—ì„œ ì„ íƒ
    const healthyNodes = [
      this.primary,
      ...this.replicas
    ].filter(node => this.healthChecker.isHealthy(node));
    
    return this.loadBalancer.select(healthyNodes);
  }
  
  // ì§€ë¦¬ì  ë¶„ì‚° ìºì‹±
  async geoDistributedSet(
    key: string,
    value: any,
    geoOptions: GeoDistributionOptions
  ): Promise<void> {
    const regions = geoOptions.regions || ['primary'];
    const promises: Promise<void>[] = [];
    
    for (const region of regions) {
      const regionalShard = this.getRegionalShard(region);
      
      promises.push(
        regionalShard.set(key, value, {
          ttl: geoOptions.ttl,
          tags: [...(geoOptions.tags || []), `region:${region}`]
        })
      );
    }
    
    // ì¿¼ëŸ¼ ê¸°ë°˜ ì„±ê³µ í™•ì¸
    const results = await Promise.allSettled(promises);
    const successCount = results.filter(r => 
      r.status === 'fulfilled'
    ).length;
    
    const requiredQuorum = Math.ceil(regions.length * 0.51);
    
    if (successCount < requiredQuorum) {
      throw new Error(
        `Geo-distributed write failed: ${successCount}/${requiredQuorum}`
      );
    }
  }
}

// Consistent Hashing êµ¬í˜„
class ConsistentHash {
  private ring: Map<number, string>;
  private sortedKeys: number[];
  
  constructor(
    private virtualNodes: number = 150
  ) {
    this.ring = new Map();
    this.sortedKeys = [];
  }
  
  addNode(nodeId: string, weight: number = 1): void {
    const nodeCount = this.virtualNodes * weight;
    
    for (let i = 0; i < nodeCount; i++) {
      const virtualNodeId = `${nodeId}:${i}`;
      const hash = this.hashFunction(virtualNodeId);
      
      this.ring.set(hash, nodeId);
    }
    
    this.sortedKeys = Array.from(this.ring.keys()).sort((a, b) => a - b);
  }
  
  removeNode(nodeId: string): void {
    const keysToRemove: number[] = [];
    
    for (const [hash, node] of this.ring) {
      if (node === nodeId) {
        keysToRemove.push(hash);
      }
    }
    
    keysToRemove.forEach(key => this.ring.delete(key));
    this.sortedKeys = Array.from(this.ring.keys()).sort((a, b) => a - b);
  }
  
  getNode(key: string): string {
    if (this.ring.size === 0) {
      throw new Error('No nodes available');
    }
    
    const hash = this.hashFunction(key);
    
    // ì´ì§„ ê²€ìƒ‰ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ë…¸ë“œ ì°¾ê¸°
    let left = 0;
    let right = this.sortedKeys.length - 1;
    
    while (left < right) {
      const mid = Math.floor((left + right) / 2);
      if (this.sortedKeys[mid] < hash) {
        left = mid + 1;
      } else {
        right = mid;
      }
    }
    
    // ìˆœí™˜ êµ¬ì¡°ì´ë¯€ë¡œ ëì— ë„ë‹¬í•˜ë©´ ì²˜ìŒìœ¼ë¡œ
    const selectedKey = left === this.sortedKeys.length 
      ? this.sortedKeys[0] 
      : this.sortedKeys[left];
      
    return this.ring.get(selectedKey)!;
  }
  
  private hashFunction(key: string): number {
    // MurmurHash3 êµ¬í˜„
    return murmur.v3(key);
  }
}
```

## Task 1.14: ë©”ì‹œì§• í ì‹œìŠ¤í…œ

### SubTask 1.14.1: SQS/EventBridge í†µí•©
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: AWS SQSì™€ EventBridgeë¥¼ í™œìš©í•œ ë¹„ë™ê¸° ë©”ì‹œì§• ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/messaging/aws/messaging-service.ts
import { 
  SQSClient, 
  SendMessageCommand,
  ReceiveMessageCommand,
  DeleteMessageCommand 
} from '@aws-sdk/client-sqs';
import { 
  EventBridgeClient,
  PutEventsCommand 
} from '@aws-sdk/client-eventbridge';

export interface MessagingConfig {
  sqs: SQSConfig;
  eventBridge: EventBridgeConfig;
  dlq: DeadLetterQueueConfig;
}

export class AWSMessagingService {
  private sqsClient: SQSClient;
  private eventBridgeClient: EventBridgeClient;
  private queues: Map<string, QueueConfig>;
  private consumers: Map<string, QueueConsumer>;
  
  constructor(private config: MessagingConfig) {
    this.sqsClient = new SQSClient({
      region: config.sqs.region,
      maxAttempts: 3
    });
    
    this.eventBridgeClient = new EventBridgeClient({
      region: config.eventBridge.region
    });
    
    this.queues = new Map();
    this.consumers = new Map();
    
    this.initializeQueues();
  }
  
  private async initializeQueues(): Promise<void> {
    // ì—ì´ì „íŠ¸ ì‹¤í–‰ í
    await this.createQueue('agent-execution', {
      visibilityTimeout: 300, // 5ë¶„
      messageRetentionPeriod: 86400, // 24ì‹œê°„
      fifo: true,
      contentBasedDeduplication: true,
      dlq: {
        maxReceiveCount: 3
      }
    });
    
    // í”„ë¡œì íŠ¸ ë¹Œë“œ í
    await this.createQueue('project-build', {
      visibilityTimeout: 600, // 10ë¶„
      messageRetentionPeriod: 172800, // 48ì‹œê°„
      fifo: false,
      dlq: {
        maxReceiveCount: 2
      }
    });
    
    // ì•Œë¦¼ í
    await this.createQueue('notifications', {
      visibilityTimeout: 30,
      messageRetentionPeriod: 3600, // 1ì‹œê°„
      fifo: false
    });
  }
  
  // ë©”ì‹œì§€ ì „ì†¡
  async sendMessage<T>(
    queueName: string,
    message: T,
    options?: SendMessageOptions
  ): Promise<string> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue not found: ${queueName}`);
    }
    
    const messageBody = JSON.stringify({
      data: message,
      timestamp: new Date().toISOString(),
      correlationId: options?.correlationId || crypto.randomUUID(),
      metadata: options?.metadata
    });
    
    const command = new SendMessageCommand({
      QueueUrl: queue.url,
      MessageBody: messageBody,
      MessageGroupId: options?.messageGroupId,
      MessageDeduplicationId: options?.deduplicationId || 
        this.generateDeduplicationId(messageBody),
      MessageAttributes: this.buildMessageAttributes(options),
      DelaySeconds: options?.delaySeconds
    });
    
    const response = await this.sqsClient.send(command);
    
    // ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    this.metrics.incrementMessagesSent(queueName);
    
    return response.MessageId!;
  }
  
  // ë°°ì¹˜ ë©”ì‹œì§€ ì „ì†¡
  async sendBatchMessages<T>(
    queueName: string,
    messages: T[],
    options?: BatchSendOptions
  ): Promise<BatchSendResult> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue not found: ${queueName}`);
    }
    
    const results: BatchSendResult = {
      successful: [],
      failed: []
    };
    
    // 10ê°œì”© ë°°ì¹˜ ì²˜ë¦¬ (SQS ì œí•œ)
    for (let i = 0; i < messages.length; i += 10) {
      const batch = messages.slice(i, i + 10);
      const entries = batch.map((message, index) => ({
        Id: `${i + index}`,
        MessageBody: JSON.stringify({
          data: message,
          timestamp: new Date().toISOString(),
          batchId: options?.batchId
        }),
        MessageGroupId: options?.messageGroupId,
        MessageDeduplicationId: this.generateDeduplicationId(
          JSON.stringify(message)
        )
      }));
      
      const response = await this.sqsClient.send(
        new SendMessageBatchCommand({
          QueueUrl: queue.url,
          Entries: entries
        })
      );
      
      results.successful.push(
        ...response.Successful.map(s => s.Id)
      );
      
      if (response.Failed) {
        results.failed.push(...response.Failed);
      }
    }
    
    return results;
  }
  
  // ë©”ì‹œì§€ ì†Œë¹„ì ë“±ë¡
  registerConsumer<T>(
    queueName: string,
    handler: MessageHandler<T>,
    options?: ConsumerOptions
  ): void {
    const consumer = new QueueConsumer({
      queueName,
      sqsClient: this.sqsClient,
      handler,
      options: {
        batchSize: options?.batchSize || 10,
        visibilityTimeout: options?.visibilityTimeout || 30,
        waitTimeSeconds: options?.waitTimeSeconds || 20,
        maxRetries: options?.maxRetries || 3
      }
    });
    
    consumer.start();
    this.consumers.set(queueName, consumer);
  }
  
  // EventBridge ì´ë²¤íŠ¸ ë°œí–‰
  async publishEvent(
    event: DomainEvent,
    options?: EventOptions
  ): Promise<void> {
    const eventDetail = {
      version: '1.0',
      id: event.id || crypto.randomUUID(),
      source: `t-developer.${event.source}`,
      type: event.type,
      timestamp: event.timestamp || new Date().toISOString(),
      data: event.data,
      metadata: {
        correlationId: event.correlationId,
        causationId: event.causationId,
        userId: event.userId,
        ...event.metadata
      }
    };
    
    const command = new PutEventsCommand({
      Entries: [{
        EventBusName: this.config.eventBridge.busName,
        Source: eventDetail.source,
        DetailType: event.type,
        Detail: JSON.stringify(eventDetail),
        Time: new Date(eventDetail.timestamp),
        Resources: options?.resources
      }]
    });
    
    await this.eventBridgeClient.send(command);
    
    // ì´ë²¤íŠ¸ ë¡œê¹…
    await this.eventLogger.log(eventDetail);
  }
  
  // ì´ë²¤íŠ¸ ê·œì¹™ ìƒì„±
  async createEventRule(
    rule: EventRule
  ): Promise<void> {
    const putRuleCommand = new PutRuleCommand({
      Name: rule.name,
      Description: rule.description,
      EventPattern: JSON.stringify({
        source: rule.sources,
        'detail-type': rule.detailTypes,
        detail: rule.detailFilter
      }),
      State: 'ENABLED',
      EventBusName: this.config.eventBridge.busName
    });
    
    await this.eventBridgeClient.send(putRuleCommand);
    
    // íƒ€ê²Ÿ ì¶”ê°€
    if (rule.targets) {
      await this.addRuleTargets(rule.name, rule.targets);
    }
  }
  
  // Dead Letter Queue ì²˜ë¦¬
  async processDeadLetters(
    queueName: string,
    processor: DeadLetterProcessor
  ): Promise<ProcessingResult> {
    const dlqName = `${queueName}-dlq`;
    const messages = await this.receiveMessages(dlqName, {
      maxMessages: 10,
      waitTimeSeconds: 5
    });
    
    const results: ProcessingResult = {
      processed: 0,
      requeued: 0,
      discarded: 0,
      failed: 0
    };
    
    for (const message of messages) {
      try {
        const action = await processor.process(message);
        
        switch (action) {
          case 'requeue':
            await this.sendMessage(queueName, message.body);
            await this.deleteMessage(dlqName, message.receiptHandle);
            results.requeued++;
            break;
            
          case 'discard':
            await this.deleteMessage(dlqName, message.receiptHandle);
            results.discarded++;
            break;
            
          case 'retry':
            // ë©”ì‹œì§€ë¥¼ DLQì— ë‚¨ê²¨ë‘ 
            results.failed++;
            break;
        }
        
        results.processed++;
        
      } catch (error) {
        console.error('DLQ processing error:', error);
        results.failed++;
      }
    }
    
    return results;
  }
}

// í ì†Œë¹„ì êµ¬í˜„
class QueueConsumer {
  private isRunning: boolean = false;
  private processingCount: number = 0;
  
  constructor(
    private config: ConsumerConfig
  ) {}
  
  async start(): Promise<void> {
    this.isRunning = true;
    this.consumeMessages();
  }
  
  async stop(): Promise<void> {
    this.isRunning = false;
    
    // ì²˜ë¦¬ ì¤‘ì¸ ë©”ì‹œì§€ ì™„ë£Œ ëŒ€ê¸°
    while (this.processingCount > 0) {
      await this.delay(100);
    }
  }
  
  private async consumeMessages(): Promise<void> {
    while (this.isRunning) {
      try {
        const messages = await this.receiveMessages();
        
        if (messages.length > 0) {
          await this.processMessages(messages);
        }
      } catch (error) {
        console.error('Consumer error:', error);
        await this.delay(5000); // ì—ëŸ¬ ì‹œ 5ì´ˆ ëŒ€ê¸°
      }
    }
  }
  
  private async processMessages(
    messages: Message[]
  ): Promise<void> {
    const promises = messages.map(message => 
      this.processMessage(message)
    );
    
    await Promise.allSettled(promises);
  }
  
  private async processMessage(
    message: Message
  ): Promise<void> {
    this.processingCount++;
    
    try {
      const body = JSON.parse(message.Body);
      
      // í•¸ë“¤ëŸ¬ ì‹¤í–‰
      await this.config.handler(body.data, {
        messageId: message.MessageId,
        receiptHandle: message.ReceiptHandle,
        attributes: message.MessageAttributes,
        metadata: body.metadata
      });
      
      // ì„±ê³µ ì‹œ ë©”ì‹œì§€ ì‚­ì œ
      await this.deleteMessage(message.ReceiptHandle);
      
    } catch (error) {
      // ì—ëŸ¬ ì²˜ë¦¬
      await this.handleProcessingError(message, error);
    } finally {
      this.processingCount--;
    }
  }
  
  private async handleProcessingError(
    message: Message,
    error: Error
  ): Promise<void> {
    const retryCount = parseInt(
      message.Attributes?.ApproximateReceiveCount || '0'
    );
    
    if (retryCount < this.config.options.maxRetries) {
      // ì¬ì‹œë„ë¥¼ ìœ„í•´ ë©”ì‹œì§€ë¥¼ íì— ë‚¨ê¹€
      console.log(
        `Message ${message.MessageId} will be retried. ` +
        `Attempt ${retryCount + 1}/${this.config.options.maxRetries}`
      );
    } else {
      // ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ - DLQë¡œ ì´ë™
      console.error(
        `Message ${message.MessageId} exceeded max retries. ` +
        `Moving to DLQ.`
      );
    }
    
    // ì—ëŸ¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    this.metrics.incrementProcessingErrors(
      this.config.queueName,
      error.name
    );
  }
}
```

### SubTask 1.14.2: Pub/Sub íŒ¨í„´ êµ¬í˜„
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ì´ë²¤íŠ¸ ê¸°ë°˜ Pub/Sub íŒ¨í„´ì„ í™œìš©í•œ ì‹¤ì‹œê°„ í†µì‹  êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/messaging/pubsub/pubsub-service.ts
import { 
  SNSClient, 
  CreateTopicCommand,
  PublishCommand,
  SubscribeCommand 
} from '@aws-sdk/client-sns';
import { Redis } from 'ioredis';
import { EventEmitter } from 'events';

export interface PubSubConfig {
  provider: 'sns' | 'redis' | 'eventbridge';
  sns?: SNSConfig;
  redis?: RedisConfig;
}

export class PubSubService {
  private publishers: Map<string, Publisher> = new Map();
  private subscribers: Map<string, Subscriber[]> = new Map();
  private localEmitter: EventEmitter = new EventEmitter();
  
  constructor(private config: PubSubConfig) {
    this.initialize();
  }
  
  private async initialize(): Promise<void> {
    switch (this.config.provider) {
      case 'sns':
        await this.initializeSNS();
        break;
      case 'redis':
        await this.initializeRedis();
        break;
      case 'eventbridge':
        await this.initializeEventBridge();
        break;
    }
  }
  
  // í† í”½ ìƒì„±
  async createTopic(topicName: string): Promise<string> {
    const topic = await this.getOrCreateTopic(topicName);
    
    // ë¡œì»¬ ì´ë²¤íŠ¸ ì—ë¯¸í„°ì—ë„ ë“±ë¡
    this.localEmitter.setMaxListeners(
      this.localEmitter.getMaxListeners() + 10
    );
    
    return topic.arn || topic.id;
  }
  
  // ë©”ì‹œì§€ ë°œí–‰
  async publish<T>(
    topicName: string,
    message: T,
    attributes?: Record<string, any>
  ): Promise<void> {
    const topic = await this.getOrCreateTopic(topicName);
    
    const payload: PublishPayload = {
      id: crypto.randomUUID(),
      timestamp: new Date().toISOString(),
      topic: topicName,
      data: message,
      attributes,
      version: '1.0'
    };
    
    // í”„ë¡œë°”ì´ë”ë³„ ë°œí–‰
    await this.publishToProvider(topic, payload);
    
    // ë¡œì»¬ êµ¬ë…ìì—ê²Œë„ ì „ë‹¬
    this.localEmitter.emit(topicName, payload);
    
    // ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    this.metrics.incrementPublished(topicName);
  }
  
  // êµ¬ë… ë“±ë¡
  async subscribe<T>(
    topicName: string,
    handler: MessageHandler<T>,
    options?: SubscribeOptions
  ): Promise<Subscription> {
    const subscription = new Subscription({
      id: crypto.randomUUID(),
      topic: topicName,
      handler,
      options: {
        maxRetries: options?.maxRetries || 3,
        deadLetterTopic: options?.deadLetterTopic,
        filter: options?.filter
      }
    });
    
    // êµ¬ë…ì ë“±ë¡
    if (!this.subscribers.has(topicName)) {
      this.subscribers.set(topicName, []);
    }
    this.subscribers.get(topicName)!.push(subscription);
    
    // í”„ë¡œë°”ì´ë”ë³„ êµ¬ë… ì„¤ì •
    await this.subscribeToProvider(topicName, subscription);
    
    // ë¡œì»¬ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
    this.localEmitter.on(topicName, async (payload) => {
      await this.handleMessage(subscription, payload);
    });
    
    return subscription;
  }
  
  // ë©”ì‹œì§€ í•„í„°ë§
  private async applyMessageFilter(
    message: any,
    filter?: MessageFilter
  ): Promise<boolean> {
    if (!filter) return true;
    
    // ì†ì„± ê¸°ë°˜ í•„í„°ë§
    if (filter.attributes) {
      for (const [key, value] of Object.entries(filter.attributes)) {
        if (message.attributes?.[key] !== value) {
          return false;
        }
      }
    }
    
    // ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§
    if (filter.contentFilter) {
      return await filter.contentFilter(message.data);
    }
    
    return true;
  }
  
  // Redis Pub/Sub êµ¬í˜„
  private async initializeRedis(): Promise<void> {
    const publisher = new Redis(this.config.redis);
    const subscriber = new Redis(this.config.redis);
    
    subscriber.on('message', async (channel, message) => {
      try {
        const payload = JSON.parse(message);
        await this.distributeToSubscribers(channel, payload);
      } catch (error) {
        console.error('Redis message parsing error:', error);
      }
    });
    
    this.redisPublisher = publisher;
    this.redisSubscriber = subscriber;
  }
}

// ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ ë˜í¼
class MessageHandlerWrapper {
  constructor(
    private handler: MessageHandler<any>,
    private options: HandlerOptions
  ) {}
  
  async handle(message: any): Promise<void> {
    let retries = 0;
    const maxRetries = this.options.maxRetries || 3;
    
    while (retries <= maxRetries) {
      try {
        await this.handler(message);
        return;
      } catch (error) {
        retries++;
        
        if (retries > maxRetries) {
          await this.sendToDeadLetter(message, error);
          throw error;
        }
        
        // ì§€ìˆ˜ ë°±ì˜¤í”„
        await this.delay(Math.pow(2, retries) * 1000);
      }
    }
  }
  
  private async sendToDeadLetter(
    message: any,
    error: any
  ): Promise<void> {
    if (this.options.deadLetterTopic) {
      await this.publishToDeadLetter({
        originalMessage: message,
        error: error.message,
        timestamp: new Date().toISOString(),
        retries: this.options.maxRetries
      });
    }
  }
}
```

### SubTask 1.14.3: ë©”ì‹œì§€ ë¼ìš°íŒ… ë° í•„í„°ë§
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 6ì‹œê°„

**ëª©í‘œ**: ë³µì¡í•œ ë©”ì‹œì§€ ë¼ìš°íŒ… ê·œì¹™ê³¼ í•„í„°ë§ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/messaging/routing/message-router.ts
export interface RoutingRule {
  id: string;
  name: string;
  source: string | string[];
  destination: string | string[];
  filter?: MessageFilter;
  transform?: MessageTransformer;
  priority: number;
  enabled: boolean;
}

export class MessageRouter {
  private rules: Map<string, RoutingRule> = new Map();
  private ruleEngine: RuleEngine;
  
  constructor() {
    this.ruleEngine = new RuleEngine();
    this.loadRoutingRules();
  }
  
  // ë¼ìš°íŒ… ê·œì¹™ ì¶”ê°€
  async addRule(rule: RoutingRule): Promise<void> {
    // ê·œì¹™ ìœ íš¨ì„± ê²€ì¦
    await this.validateRule(rule);
    
    // ê·œì¹™ ì €ì¥
    this.rules.set(rule.id, rule);
    
    // ê·œì¹™ ì—”ì§„ì— ë“±ë¡
    await this.ruleEngine.registerRule({
      id: rule.id,
      condition: this.buildCondition(rule),
      action: this.buildAction(rule),
      priority: rule.priority
    });
  }
  
  // ë©”ì‹œì§€ ë¼ìš°íŒ…
  async routeMessage(
    message: Message,
    context: RoutingContext
  ): Promise<RoutingResult> {
    const startTime = Date.now();
    const results: RoutingDecision[] = [];
    
    try {
      // 1. ì ìš© ê°€ëŠ¥í•œ ê·œì¹™ ì°¾ê¸°
      const applicableRules = await this.findApplicableRules(
        message,
        context
      );
      
      // 2. ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì •ë ¬
      const sortedRules = applicableRules.sort(
        (a, b) => b.priority - a.priority
      );
      
      // 3. ê·œì¹™ ì ìš©
      for (const rule of sortedRules) {
        const decision = await this.applyRule(rule, message, context);
        results.push(decision);
        
        // ì²´ì¸ ì¤‘ë‹¨ ì¡°ê±´ í™•ì¸
        if (decision.stopProcessing) {
          break;
        }
      }
      
      // 4. ë¼ìš°íŒ… ì‹¤í–‰
      await this.executeRouting(results, message);
      
      return {
        success: true,
        decisions: results,
        processingTime: Date.now() - startTime
      };
      
    } catch (error) {
      return {
        success: false,
        error: error.message,
        decisions: results,
        processingTime: Date.now() - startTime
      };
    }
  }
  
  // ì»¨í…ì¸  ê¸°ë°˜ ë¼ìš°íŒ…
  private async applyContentBasedRouting(
    message: Message,
    rule: RoutingRule
  ): Promise<string[]> {
    const destinations: string[] = [];
    
    // JSON Path ê¸°ë°˜ í•„í„°ë§
    if (rule.filter?.jsonPath) {
      const matches = JSONPath.query(
        message.data,
        rule.filter.jsonPath
      );
      
      if (matches.length > 0) {
        destinations.push(...this.resolveDestinations(rule.destination));
      }
    }
    
    // ì •ê·œì‹ ê¸°ë°˜ í•„í„°ë§
    if (rule.filter?.regex) {
      const content = JSON.stringify(message.data);
      const regex = new RegExp(rule.filter.regex, 'g');
      
      if (regex.test(content)) {
        destinations.push(...this.resolveDestinations(rule.destination));
      }
    }
    
    // ì»¤ìŠ¤í…€ í•¨ìˆ˜ ê¸°ë°˜ í•„í„°ë§
    if (rule.filter?.customFunction) {
      const shouldRoute = await rule.filter.customFunction(message);
      
      if (shouldRoute) {
        destinations.push(...this.resolveDestinations(rule.destination));
      }
    }
    
    return destinations;
  }
  
  // ë©”ì‹œì§€ ë³€í™˜
  private async transformMessage(
    message: Message,
    transformer: MessageTransformer
  ): Promise<Message> {
    if (transformer.type === 'template') {
      return this.applyTemplate(message, transformer.template);
    }
    
    if (transformer.type === 'function') {
      return await transformer.function(message);
    }
    
    if (transformer.type === 'mapping') {
      return this.applyMapping(message, transformer.mapping);
    }
    
    return message;
  }
}

// ë¼ìš°íŒ… ì—”ì§„
class RuleEngine {
  private rules: CompiledRule[] = [];
  
  async registerRule(rule: EngineRule): Promise<void> {
    const compiled = await this.compileRule(rule);
    this.rules.push(compiled);
    
    // ê·œì¹™ ìµœì í™”
    this.optimizeRules();
  }
  
  async evaluate(
    message: Message,
    context: RoutingContext
  ): Promise<EvaluationResult[]> {
    const results: EvaluationResult[] = [];
    
    for (const rule of this.rules) {
      const result = await this.evaluateRule(rule, message, context);
      
      if (result.matched) {
        results.push(result);
      }
    }
    
    return results;
  }
  
  private async compileRule(rule: EngineRule): Promise<CompiledRule> {
    // ê·œì¹™ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì»´íŒŒì¼
    const conditionFn = this.compileCondition(rule.condition);
    const actionFn = this.compileAction(rule.action);
    
    return {
      id: rule.id,
      evaluate: conditionFn,
      execute: actionFn,
      priority: rule.priority,
      metadata: rule.metadata
    };
  }
}
```

### SubTask 1.14.4: ë©”ì‹œì§€ ë³´ì¥ì„± ë° íŠ¸ëœì­ì…˜
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ë©”ì‹œì§€ ì „ë‹¬ ë³´ì¥ì„±ê³¼ ë¶„ì‚° íŠ¸ëœì­ì…˜ ì§€ì›

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/messaging/reliability/message-guarantees.ts
export class ReliableMessaging {
  private messageStore: MessageStore;
  private transactionManager: TransactionManager;
  private acknowledgmentTracker: AcknowledgmentTracker;
  
  constructor() {
    this.messageStore = new MessageStore();
    this.transactionManager = new TransactionManager();
    this.acknowledgmentTracker = new AcknowledgmentTracker();
  }
  
  // At-least-once ì „ë‹¬ ë³´ì¥
  async sendWithGuarantee(
    message: Message,
    options: GuaranteeOptions
  ): Promise<SendResult> {
    const messageId = crypto.randomUUID();
    const transaction = await this.transactionManager.begin();
    
    try {
      // 1. ë©”ì‹œì§€ ì €ì¥ (ì•„ì›ƒë°•ìŠ¤ íŒ¨í„´)
      await this.messageStore.save({
        id: messageId,
        message,
        status: 'pending',
        attempts: 0,
        maxAttempts: options.maxAttempts || 3,
        timestamp: new Date()
      });
      
      // 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì‹¤í–‰
      if (options.businessLogic) {
        await options.businessLogic(transaction);
      }
      
      // 3. íŠ¸ëœì­ì…˜ ì»¤ë°‹
      await transaction.commit();
      
      // 4. ë©”ì‹œì§€ ë°œì†¡ ì‹œë„
      const sendResult = await this.attemptSend(messageId);
      
      return {
        messageId,
        status: sendResult.success ? 'sent' : 'queued',
        timestamp: new Date()
      };
      
    } catch (error) {
      await transaction.rollback();
      throw error;
    }
  }
  
  // Exactly-once ì „ë‹¬ ë³´ì¥ (ë©±ë“±ì„±)
  async sendExactlyOnce(
    message: Message,
    idempotencyKey: string
  ): Promise<SendResult> {
    // ì¤‘ë³µ í™•ì¸
    const existing = await this.messageStore.findByIdempotencyKey(
      idempotencyKey
    );
    
    if (existing) {
      return {
        messageId: existing.id,
        status: 'duplicate',
        timestamp: existing.timestamp
      };
    }
    
    // ìƒˆ ë©”ì‹œì§€ ì²˜ë¦¬
    return await this.sendWithGuarantee(message, {
      idempotencyKey,
      maxAttempts: 5,
      businessLogic: async (tx) => {
        await this.messageStore.saveIdempotencyKey(
          idempotencyKey,
          message.id,
          tx
        );
      }
    });
  }
  
  // ì•„ì›ƒë°•ìŠ¤ í”„ë¡œì„¸ì„œ
  async processOutbox(): Promise<void> {
    const pendingMessages = await this.messageStore.getPending({
      limit: 100,
      maxAge: 3600000 // 1ì‹œê°„
    });
    
    for (const record of pendingMessages) {
      try {
        const result = await this.attemptSend(record.id);
        
        if (result.success) {
          await this.messageStore.markSent(record.id);
        } else if (record.attempts >= record.maxAttempts) {
          await this.messageStore.markFailed(record.id);
          await this.handleFailedMessage(record);
        } else {
          await this.messageStore.incrementAttempts(record.id);
        }
        
      } catch (error) {
        console.error(`Outbox processing error for ${record.id}:`, error);
      }
    }
  }
  
  // ë¶„ì‚° íŠ¸ëœì­ì…˜ (Saga íŒ¨í„´)
  async executeSaga<T>(
    saga: SagaDefinition<T>
  ): Promise<SagaResult<T>> {
    const sagaId = crypto.randomUUID();
    const executedSteps: ExecutedStep[] = [];
    
    try {
      // ì „ì§„ ë‹¨ê³„ ì‹¤í–‰
      for (const step of saga.steps) {
        const stepResult = await this.executeStep(step, saga.context);
        
        executedSteps.push({
          stepId: step.id,
          result: stepResult,
          timestamp: new Date()
        });
        
        // ìƒíƒœ ì €ì¥
        await this.saveSagaState(sagaId, executedSteps);
        
        // ë³´ìƒ íŠ¸ëœì­ì…˜ ë“±ë¡
        if (step.compensate) {
          await this.registerCompensation(sagaId, step);
        }
      }
      
      return {
        success: true,
        sagaId,
        result: saga.onComplete(executedSteps)
      };
      
    } catch (error) {
      // ë³´ìƒ íŠ¸ëœì­ì…˜ ì‹¤í–‰
      await this.compensateSaga(sagaId, executedSteps);
      
      return {
        success: false,
        sagaId,
        error: error.message,
        compensated: true
      };
    }
  }
  
  // ë©”ì‹œì§€ ìˆœì„œ ë³´ì¥
  async sendOrdered(
    messages: Message[],
    partitionKey: string
  ): Promise<void> {
    const queue = await this.getOrderedQueue(partitionKey);
    
    for (const message of messages) {
      await queue.enqueue({
        ...message,
        sequenceNumber: await this.getNextSequence(partitionKey),
        partitionKey
      });
    }
  }
}

// íŠ¸ëœì­ì…˜ ë¡œê·¸
class TransactionLog {
  async append(entry: LogEntry): Promise<void> {
    await this.storage.append({
      ...entry,
      timestamp: new Date(),
      checksum: this.calculateChecksum(entry)
    });
  }
  
  async replay(fromSequence: number): Promise<LogEntry[]> {
    const entries = await this.storage.readFrom(fromSequence);
    
    // ì²´í¬ì„¬ ê²€ì¦
    for (const entry of entries) {
      if (!this.verifyChecksum(entry)) {
        throw new Error(`Corrupted log entry: ${entry.sequence}`);
      }
    }
    
    return entries;
  }
}
```
## Task 1.15: ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§

### SubTask 1.15.1: êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: CloudWatchì™€ í†µí•©ëœ êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/logging/structured-logger.ts
import winston from 'winston';
import { CloudWatchLogs } from '@aws-sdk/client-cloudwatch-logs';
import { performance } from 'perf_hooks';

export interface LogContext {
  userId?: string;
  projectId?: string;
  agentId?: string;
  correlationId?: string;
  sessionId?: string;
  traceId?: string;
  spanId?: string;
}

export class StructuredLogger {
  private logger: winston.Logger;
  private cloudwatch: CloudWatchLogs;
  private context: LogContext = {};
  private performanceMarks: Map<string, number> = new Map();
  
  constructor(private config: LoggerConfig) {
    this.cloudwatch = new CloudWatchLogs({
      region: config.aws.region
    });
    
    this.logger = winston.createLogger({
      level: config.logLevel || 'info',
      format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.errors({ stack: true }),
        winston.format.json(),
        winston.format.printf(info => {
          return JSON.stringify({
            ...this.enrichLog(info),
            ...this.context
          });
        })
      ),
      transports: this.createTransports()
    });
  }
  
  // ë¡œê·¸ ê°•í™”
  private enrichLog(info: any): any {
    return {
      timestamp: new Date().toISOString(),
      level: info.level,
      message: info.message,
      service: this.config.serviceName,
      environment: process.env.NODE_ENV,
      version: process.env.APP_VERSION,
      hostname: process.env.HOSTNAME,
      pid: process.pid,
      ...this.extractMetadata(info)
    };
  }
  
  // ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
  setContext(context: Partial<LogContext>): void {
    this.context = { ...this.context, ...context };
  }
  
  // ì—ì´ì „íŠ¸ ì‹¤í–‰ ë¡œê¹…
  logAgentExecution(
    agentId: string,
    event: AgentExecutionEvent
  ): void {
    this.logger.info('Agent execution', {
      agentId,
      event: event.type,
      duration: event.duration,
      status: event.status,
      input: this.sanitizeInput(event.input),
      output: this.sanitizeOutput(event.output),
      metadata: {
        modelUsed: event.modelUsed,
        tokensUsed: event.tokensUsed,
        cost: event.cost
      }
    });
  }
  
  // ì„±ëŠ¥ ì¸¡ì •
  startTimer(label: string): void {
    this.performanceMarks.set(label, performance.now());
  }
  
  endTimer(label: string, metadata?: any): void {
    const startTime = this.performanceMarks.get(label);
    if (!startTime) return;
    
    const duration = performance.now() - startTime;
    this.performanceMarks.delete(label);
    
    this.logger.info('Performance measurement', {
      label,
      duration,
      unit: 'ms',
      ...metadata
    });
  }
  
  // ì—ëŸ¬ ë¡œê¹…
  logError(error: Error, context?: any): void {
    this.logger.error('Error occurred', {
      error: {
        name: error.name,
        message: error.message,
        stack: error.stack,
        ...this.extractErrorMetadata(error)
      },
      context
    });
  }
  
  // CloudWatch Logs í†µí•©
  private createCloudWatchTransport(): winston.transport {
    return new CloudWatchTransport({
      logGroupName: `/aws/t-developer/${this.config.environment}`,
      logStreamName: `${this.config.serviceName}-${new Date().toISOString().split('T')[0]}`,
      cloudwatch: this.cloudwatch,
      messageFormatter: (info) => JSON.stringify(info),
      retentionInDays: 30
    });
  }
  
  // ë¡œê·¸ ì§‘ê³„ ë° ë¶„ì„
  async queryLogs(
    query: LogQuery
  ): Promise<LogQueryResult> {
    const params = {
      logGroupName: `/aws/t-developer/${this.config.environment}`,
      startTime: query.startTime.getTime(),
      endTime: query.endTime.getTime(),
      queryString: this.buildInsightsQuery(query),
      limit: query.limit || 1000
    };
    
    const result = await this.cloudwatch.startQuery(params);
    
    // ì¿¼ë¦¬ ì™„ë£Œ ëŒ€ê¸°
    return await this.waitForQueryCompletion(result.queryId!);
  }
  
  // CloudWatch Insights ì¿¼ë¦¬ ë¹Œë”
  private buildInsightsQuery(query: LogQuery): string {
    const conditions: string[] = [];
    
    if (query.level) {
      conditions.push(`level = "${query.level}"`);
    }
    
    if (query.agentId) {
      conditions.push(`agentId = "${query.agentId}"`);
    }
    
    if (query.searchText) {
      conditions.push(`message like /${query.searchText}/`);
    }
    
    const whereClause = conditions.length > 0 
      ? `| filter ${conditions.join(' and ')}` 
      : '';
    
    return `
      fields @timestamp, level, message, agentId, duration
      | sort @timestamp desc
      ${whereClause}
      | limit ${query.limit || 1000}
    `;
  }
}

// ë¡œê·¸ ì „ì†¡ ë²„í¼
class LogBuffer {
  private buffer: LogEntry[] = [];
  private timer?: NodeJS.Timeout;
  
  constructor(
    private maxSize: number = 100,
    private flushInterval: number = 5000
  ) {
    this.startFlushTimer();
  }
  
  add(entry: LogEntry): void {
    this.buffer.push(entry);
    
    if (this.buffer.length >= this.maxSize) {
      this.flush();
    }
  }
  
  private async flush(): Promise<void> {
    if (this.buffer.length === 0) return;
    
    const entries = [...this.buffer];
    this.buffer = [];
    
    try {
      await this.sendToCloudWatch(entries);
    } catch (error) {
      // ì‹¤íŒ¨í•œ ë¡œê·¸ëŠ” ë‹¤ì‹œ ë²„í¼ì— ì¶”ê°€
      this.buffer.unshift(...entries);
    }
  }
}
```

### SubTask 1.15.2: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: CloudWatch Metricsì™€ Prometheus í†µí•© ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/monitoring/metrics-collector.ts
import { CloudWatch } from '@aws-sdk/client-cloudwatch';
import { Counter, Gauge, Histogram, Registry } from 'prom-client';
import { EventEmitter } from 'events';

export class MetricsCollector {
  private cloudwatch: CloudWatch;
  private registry: Registry;
  private customMetrics: Map<string, any> = new Map();
  private aggregator: MetricAggregator;
  
  constructor(private config: MetricsConfig) {
    this.cloudwatch = new CloudWatch({ region: config.aws.region });
    this.registry = new Registry();
    this.aggregator = new MetricAggregator();
    
    this.initializeDefaultMetrics();
  }
  
  private initializeDefaultMetrics(): void {
    // ì—ì´ì „íŠ¸ ë©”íŠ¸ë¦­
    this.createMetric('agent_executions_total', 'counter', {
      help: 'Total number of agent executions',
      labelNames: ['agent_type', 'status']
    });
    
    this.createMetric('agent_execution_duration', 'histogram', {
      help: 'Agent execution duration in seconds',
      labelNames: ['agent_type'],
      buckets: [0.1, 0.5, 1, 2, 5, 10, 30, 60]
    });
    
    this.createMetric('active_agents', 'gauge', {
      help: 'Number of active agents',
      labelNames: ['agent_type']
    });
    
    // ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
    this.createMetric('api_requests_total', 'counter', {
      help: 'Total API requests',
      labelNames: ['method', 'endpoint', 'status_code']
    });
    
    this.createMetric('database_connections', 'gauge', {
      help: 'Active database connections'
    });
    
    // ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
    this.createMetric('projects_created_total', 'counter', {
      help: 'Total projects created',
      labelNames: ['project_type']
    });
  }
  
  // ë©”íŠ¸ë¦­ ê¸°ë¡
  async recordMetric(
    name: string,
    value: number,
    labels?: Record<string, string>,
    unit?: MetricUnit
  ): Promise<void> {
    // Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    const metric = this.customMetrics.get(name);
    if (metric) {
      if (metric instanceof Counter) {
        metric.inc(labels, value);
      } else if (metric instanceof Gauge) {
        metric.set(labels, value);
      } else if (metric instanceof Histogram) {
        metric.observe(labels, value);
      }
    }
    
    // CloudWatch ë©”íŠ¸ë¦­ ì „ì†¡
    await this.sendToCloudWatch({
      MetricName: name,
      Value: value,
      Unit: unit || 'None',
      Dimensions: this.convertLabelsToDimensions(labels),
      Timestamp: new Date()
    });
  }
  
  // ì—ì´ì „íŠ¸ ì‹¤í–‰ ë©”íŠ¸ë¦­
  async recordAgentExecution(
    agentType: string,
    duration: number,
    status: 'success' | 'failure',
    metadata?: AgentExecutionMetadata
  ): Promise<void> {
    // ì‹¤í–‰ íšŸìˆ˜
    await this.recordMetric(
      'agent_executions_total',
      1,
      { agent_type: agentType, status }
    );
    
    // ì‹¤í–‰ ì‹œê°„
    await this.recordMetric(
      'agent_execution_duration',
      duration,
      { agent_type: agentType },
      'Seconds'
    );
    
    // í† í° ì‚¬ìš©ëŸ‰
    if (metadata?.tokensUsed) {
      await this.recordMetric(
        'llm_tokens_used',
        metadata.tokensUsed,
        { 
          agent_type: agentType,
          model: metadata.model 
        }
      );
    }
    
    // ë¹„ìš©
    if (metadata?.cost) {
      await this.recordMetric(
        'agent_execution_cost',
        metadata.cost,
        { agent_type: agentType },
        'USD'
      );
    }
  }
  
  // ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ë°ì´í„°
  async getDashboardMetrics(): Promise<DashboardData> {
    const metrics = await this.aggregator.aggregate([
      'agent_executions_total',
      'agent_execution_duration',
      'active_agents',
      'api_requests_total',
      'error_rate'
    ]);
    
    return {
      timestamp: new Date(),
      summary: {
        totalExecutions: metrics.agent_executions_total,
        averageDuration: metrics.agent_execution_duration_avg,
        activeAgents: metrics.active_agents,
        errorRate: metrics.error_rate
      },
      timeSeries: await this.getTimeSeriesData(),
      topAgents: await this.getTopAgentsByUsage(),
      alerts: await this.getActiveAlerts()
    };
  }
  
  // CloudWatch ì•ŒëŒ ì„¤ì •
  async createAlarm(
    name: string,
    config: AlarmConfig
  ): Promise<void> {
    await this.cloudwatch.putMetricAlarm({
      AlarmName: `t-developer-${name}`,
      ComparisonOperator: config.comparisonOperator,
      EvaluationPeriods: config.evaluationPeriods,
      MetricName: config.metricName,
      Namespace: 'T-Developer',
      Period: config.period,
      Statistic: config.statistic,
      Threshold: config.threshold,
      ActionsEnabled: true,
      AlarmActions: config.alarmActions,
      AlarmDescription: config.description,
      Dimensions: config.dimensions
    });
  }
}

// ë©”íŠ¸ë¦­ ì§‘ê³„
class MetricAggregator {
  private cache: Map<string, AggregatedMetric> = new Map();
  
  async aggregate(
    metricNames: string[]
  ): Promise<Record<string, any>> {
    const results: Record<string, any> = {};
    
    for (const name of metricNames) {
      const cached = this.cache.get(name);
      
      if (cached && this.isCacheValid(cached)) {
        results[name] = cached.value;
      } else {
        const value = await this.computeMetric(name);
        this.cache.set(name, {
          value,
          timestamp: Date.now()
        });
        results[name] = value;
      }
    }
    
    return results;
  }
  
  private async computeMetric(name: string): Promise<any> {
    // ë©”íŠ¸ë¦­ë³„ ê³„ì‚° ë¡œì§
    switch (name) {
      case 'error_rate':
        return await this.calculateErrorRate();
      case 'agent_execution_duration_avg':
        return await this.calculateAverageExecutionTime();
      default:
        return await this.getLatestValue(name);
    }
  }
}
```

### SubTask 1.15.3: ë¶„ì‚° ì¶”ì  ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: AWS X-Ray ê¸°ë°˜ ë¶„ì‚° ì¶”ì  ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/monitoring/distributed-tracing.ts
import AWSXRay from 'aws-xray-sdk-core';
import { Subsegment, Segment } from 'aws-xray-sdk-core';
import { AsyncLocalStorage } from 'async_hooks';

export class DistributedTracing {
  private asyncLocalStorage: AsyncLocalStorage<TraceContext>;
  private samplingRules: SamplingRule[];
  
  constructor(private config: TracingConfig) {
    this.asyncLocalStorage = new AsyncLocalStorage();
    this.samplingRules = config.samplingRules || this.getDefaultRules();
    
    // X-Ray ì„¤ì •
    AWSXRay.config([
      AWSXRay.plugins.ECSPlugin,
      AWSXRay.plugins.EC2Plugin
    ]);
    
    if (config.captureHTTPS) {
      AWSXRay.captureHTTPsGlobal(require('http'));
      AWSXRay.captureHTTPsGlobal(require('https'));
    }
    
    if (config.captureAWS) {
      AWSXRay.captureAWS(require('aws-sdk'));
    }
  }
  
  // íŠ¸ë ˆì´ìŠ¤ ì‹œì‘
  startTrace(
    name: string,
    metadata?: any
  ): TraceContext {
    const segment = new AWSXRay.Segment(name);
    
    // ìƒ˜í”Œë§ ê²°ì •
    const shouldSample = this.shouldSample(name, metadata);
    segment.trace_id = shouldSample ? 
      AWSXRay.utils.generateTraceID() : 
      AWSXRay.utils.generateNotTraceID();
    
    // ë©”íƒ€ë°ì´í„° ì¶”ê°€
    if (metadata) {
      segment.addMetadata('request', metadata);
    }
    
    const context: TraceContext = {
      segment,
      traceId: segment.trace_id,
      startTime: Date.now()
    };
    
    this.asyncLocalStorage.enterWith(context);
    
    return context;
  }
  
  // ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¶”ì 
  async traceAgentExecution<T>(
    agentId: string,
    agentType: string,
    operation: () => Promise<T>
  ): Promise<T> {
    const context = this.getCurrentContext();
    if (!context) {
      return await operation();
    }
    
    const subsegment = context.segment.addNewSubsegment(
      `agent-${agentType}`
    );
    
    subsegment.addAnnotation('agent_id', agentId);
    subsegment.addAnnotation('agent_type', agentType);
    
    try {
      const startTime = Date.now();
      const result = await operation();
      
      subsegment.addMetadata('execution', {
        duration: Date.now() - startTime,
        success: true
      });
      
      subsegment.close();
      return result;
      
    } catch (error) {
      subsegment.addError(error);
      subsegment.close(error);
      throw error;
    }
  }
  
  // LLM í˜¸ì¶œ ì¶”ì 
  async traceLLMCall<T>(
    model: string,
    provider: string,
    operation: () => Promise<T>
  ): Promise<T> {
    const subsegment = this.createSubsegment('llm-call');
    
    subsegment.addAnnotation('model', model);
    subsegment.addAnnotation('provider', provider);
    
    const startTime = Date.now();
    
    try {
      const result = await operation();
      
      // LLM íŠ¹í™” ë©”íŠ¸ë¦­
      subsegment.addMetadata('llm', {
        model,
        provider,
        duration: Date.now() - startTime,
        tokens: (result as any).usage?.total_tokens,
        cost: this.calculateCost(model, (result as any).usage)
      });
      
      subsegment.close();
      return result;
      
    } catch (error) {
      subsegment.addError(error);
      subsegment.close(error);
      throw error;
    }
  }
  
  // ì»¤ìŠ¤í…€ ìŠ¤íŒ¬ ìƒì„±
  createSpan(name: string, attributes?: SpanAttributes): Span {
    const context = this.getCurrentContext();
    if (!context) {
      throw new Error('No active trace context');
    }
    
    const span = new Span(name, context.segment);
    
    if (attributes) {
      Object.entries(attributes).forEach(([key, value]) => {
        span.setAttribute(key, value);
      });
    }
    
    return span;
  }
  
  // ë¶„ì‚° ì‹œìŠ¤í…œ ê°„ ì „íŒŒ
  injectTraceHeaders(headers: Record<string, string>): void {
    const context = this.getCurrentContext();
    if (!context) return;
    
    headers['X-Amzn-Trace-Id'] = context.segment.trace_id;
    headers['X-Trace-Parent'] = this.generateTraceParent(context);
  }
  
  extractTraceHeaders(
    headers: Record<string, string>
  ): TraceContext | null {
    const traceId = headers['X-Amzn-Trace-Id'] || 
                   headers['x-amzn-trace-id'];
    
    if (!traceId) return null;
    
    const segment = AWSXRay.utils.processTraceData(traceId);
    
    return {
      segment,
      traceId,
      startTime: Date.now()
    };
  }
  
  // íŠ¸ë ˆì´ìŠ¤ ë¶„ì„
  async analyzeTrace(traceId: string): Promise<TraceAnalysis> {
    const xray = new AWS.XRay();
    
    const traceResult = await xray.getTraceSummaries({
      TraceIds: [traceId],
      TimeRangeType: 'TraceId'
    }).promise();
    
    if (!traceResult.TraceSummaries?.length) {
      throw new Error('Trace not found');
    }
    
    const segments = await xray.getTraceGraph({
      TraceId: traceId
    }).promise();
    
    return this.analyzeTraceGraph(segments.Services || []);
  }
  
  // ì„±ëŠ¥ ì´ìƒ ê°ì§€
  private analyzeTraceGraph(services: any[]): TraceAnalysis {
    const analysis: TraceAnalysis = {
      totalDuration: 0,
      criticalPath: [],
      bottlenecks: [],
      errors: []
    };
    
    // í¬ë¦¬í‹°ì»¬ íŒ¨ìŠ¤ ë¶„ì„
    const criticalPath = this.findCriticalPath(services);
    analysis.criticalPath = criticalPath;
    
    // ë³‘ëª© ì§€ì  ì°¾ê¸°
    services.forEach(service => {
      if (service.ResponseTimeHistogram) {
        const p95 = this.calculatePercentile(
          service.ResponseTimeHistogram,
          0.95
        );
        
        if (p95 > this.config.bottleneckThreshold) {
          analysis.bottlenecks.push({
            service: service.Name,
            p95Duration: p95,
            callCount: service.ResponseTimeHistogram.TotalCount
          });
        }
      }
    });
    
    return analysis;
  }
}

// íŠ¸ë ˆì´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
export class TraceContextManager {
  private static instance: TraceContextManager;
  private storage: AsyncLocalStorage<TraceContext>;
  
  private constructor() {
    this.storage = new AsyncLocalStorage();
  }
  
  static getInstance(): TraceContextManager {
    if (!this.instance) {
      this.instance = new TraceContextManager();
    }
    return this.instance;
  }
  
  run<T>(context: TraceContext, fn: () => T): T {
    return this.storage.run(context, fn);
  }
  
  getContext(): TraceContext | undefined {
    return this.storage.getStore();
  }
}
```

### SubTask 1.15.4: í†µí•© ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/monitoring/dashboard/monitoring-dashboard.ts
export class MonitoringDashboard {
  private metricsCollector: MetricsCollector;
  private logQuerier: LogQuerier;
  private traceAnalyzer: TraceAnalyzer;
  private alertManager: AlertManager;
  
  constructor() {
    this.metricsCollector = new MetricsCollector();
    this.logQuerier = new LogQuerier();
    this.traceAnalyzer = new TraceAnalyzer();
    this.alertManager = new AlertManager();
  }
  
  // ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì§‘ê³„
  async getDashboardData(
    timeRange: TimeRange
  ): Promise<DashboardData> {
    const [metrics, logs, traces, alerts] = await Promise.all([
      this.getMetricsSummary(timeRange),
      this.getLogsSummary(timeRange),
      this.getTracesSummary(timeRange),
      this.getActiveAlerts()
    ]);
    
    return {
      overview: this.generateOverview(metrics),
      agentPerformance: await this.getAgentPerformance(timeRange),
      systemHealth: await this.getSystemHealth(),
      recentErrors: logs.errors.slice(0, 10),
      activeAlerts: alerts,
      traces: traces.recentTraces,
      costAnalysis: await this.getCostAnalysis(timeRange)
    };
  }
  
  // ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë¶„ì„
  async getAgentPerformance(
    timeRange: TimeRange
  ): Promise<AgentPerformanceData> {
    const agentMetrics = await this.metricsCollector.query({
      namespace: 'T-Developer/Agents',
      metricName: 'ExecutionTime',
      dimensions: [{ Name: 'AgentType', Value: '*' }],
      statistics: ['Average', 'Maximum', 'SampleCount'],
      period: 300, // 5ë¶„
      startTime: timeRange.start,
      endTime: timeRange.end
    });
    
    const agentErrors = await this.logQuerier.query({
      query: 'level="error" AND agentId exists',
      timeRange,
      aggregation: {
        field: 'agentId',
        type: 'count'
      }
    });
    
    return {
      executionStats: this.processAgentMetrics(agentMetrics),
      errorRates: this.calculateErrorRates(agentErrors),
      topPerformers: this.identifyTopPerformers(agentMetrics),
      recommendations: this.generatePerformanceRecommendations(
        agentMetrics,
        agentErrors
      )
    };
  }
  
  // ì‹¤ì‹œê°„ ì•Œë¦¼ ìŠ¤íŠ¸ë¦¼
  async *streamAlerts(): AsyncGenerator<Alert> {
    const eventSource = new EventSource('/api/monitoring/alerts/stream');
    
    for await (const event of eventSource) {
      const alert = JSON.parse(event.data);
      
      // ì•Œë¦¼ ìš°ì„ ìˆœìœ„ í‰ê°€
      alert.priority = this.evaluateAlertPriority(alert);
      
      // ìƒê´€ê´€ê³„ ë¶„ì„
      alert.correlatedEvents = await this.findCorrelatedEvents(alert);
      
      yield alert;
    }
  }
  
  // ë¹„ìš© ë¶„ì„
  async getCostAnalysis(
    timeRange: TimeRange
  ): Promise<CostAnalysis> {
    const usage = await this.metricsCollector.query({
      namespace: 'T-Developer/Usage',
      metricNames: [
        'LLMTokensUsed',
        'AgentExecutions',
        'StorageUsed',
        'DataTransfer'
      ],
      timeRange
    });
    
    const costs = {
      llm: this.calculateLLMCost(usage.LLMTokensUsed),
      compute: this.calculateComputeCost(usage.AgentExecutions),
      storage: this.calculateStorageCost(usage.StorageUsed),
      network: this.calculateNetworkCost(usage.DataTransfer)
    };
    
    return {
      total: Object.values(costs).reduce((a, b) => a + b, 0),
      breakdown: costs,
      trend: await this.getCostTrend(timeRange),
      projections: this.projectMonthlyCost(costs, timeRange),
      optimizationSuggestions: this.generateCostOptimizations(usage)
    };
  }
  
  // ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬
  async getSystemHealth(): Promise<SystemHealth> {
    const checks = await Promise.all([
      this.checkAPIHealth(),
      this.checkDatabaseHealth(),
      this.checkCacheHealth(),
      this.checkQueueHealth(),
      this.checkAgentHealth()
    ]);
    
    const overallHealth = checks.every(c => c.status === 'healthy') 
      ? 'healthy' 
      : checks.some(c => c.status === 'critical') 
        ? 'critical' 
        : 'degraded';
    
    return {
      status: overallHealth,
      components: checks,
      lastChecked: new Date(),
      uptime: process.uptime(),
      incidents: await this.getRecentIncidents()
    };
  }
}

// ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìŠ¤íŠ¸ë¦¬ë°
export class MetricsStreamer {
  private websocketServer: WebSocketServer;
  private subscribers: Map<string, Set<WebSocket>> = new Map();
  
  async streamMetrics(
    metricName: string,
    interval: number = 1000
  ): void {
    setInterval(async () => {
      const value = await this.getMetricValue(metricName);
      const data = {
        metric: metricName,
        value,
        timestamp: Date.now()
      };
      
      this.broadcast(metricName, data);
    }, interval);
  }
  
  private broadcast(channel: string, data: any): void {
    const subscribers = this.subscribers.get(channel);
    if (!subscribers) return;
    
    const message = JSON.stringify(data);
    
    subscribers.forEach(ws => {
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(message);
      }
    });
  }
}
```

## Task 1.16: ì—ëŸ¬ ì²˜ë¦¬ í”„ë ˆì„ì›Œí¬

### SubTask 1.16.1: ì¤‘ì•™í™”ëœ ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì²´ê³„ì ì¸ ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/errors/error-handler.ts
export abstract class BaseError extends Error {
  public readonly id: string;
  public readonly timestamp: Date;
  public readonly isOperational: boolean;
  public readonly statusCode: number;
  public readonly context?: any;
  
  constructor(
    message: string,
    statusCode: number,
    isOperational: boolean = true,
    context?: any
  ) {
    super(message);
    this.id = crypto.randomUUID();
    this.timestamp = new Date();
    this.statusCode = statusCode;
    this.isOperational = isOperational;
    this.context = context;
    
    Error.captureStackTrace(this, this.constructor);
  }
  
  toJSON(): ErrorResponse {
    return {
      id: this.id,
      name: this.name,
      message: this.message,
      statusCode: this.statusCode,
      timestamp: this.timestamp,
      context: this.sanitizeContext()
    };
  }
  
  private sanitizeContext(): any {
    // ë¯¼ê°í•œ ì •ë³´ ì œê±°
    if (!this.context) return undefined;
    
    const sanitized = { ...this.context };
    const sensitiveKeys = ['password', 'token', 'apiKey', 'secret'];
    
    sensitiveKeys.forEach(key => {
      if (key in sanitized) {
        sanitized[key] = '[REDACTED]';
      }
    });
    
    return sanitized;
  }
}

// ì—ëŸ¬ íƒ€ì…ë³„ í´ë˜ìŠ¤
export class ValidationError extends BaseError {
  constructor(message: string, field?: string, value?: any) {
    super(message, 400, true, { field, value });
    this.name = 'ValidationError';
  }
}

export class AuthenticationError extends BaseError {
  constructor(message: string = 'Authentication failed') {
    super(message, 401, true);
    this.name = 'AuthenticationError';
  }
}

export class AuthorizationError extends BaseError {
  constructor(resource: string, action: string) {
    super(
      `Not authorized to ${action} ${resource}`,
      403,
      true,
      { resource, action }
    );
    this.name = 'AuthorizationError';
  }
}

export class NotFoundError extends BaseError {
  constructor(resource: string, identifier?: string) {
    super(
      `${resource} not found${identifier ? `: ${identifier}` : ''}`,
      404,
      true,
      { resource, identifier }
    );
    this.name = 'NotFoundError';
  }
}

export class ConflictError extends BaseError {
  constructor(message: string, conflictingResource?: any) {
    super(message, 409, true, { conflictingResource });
    this.name = 'ConflictError';
  }
}

export class RateLimitError extends BaseError {
  constructor(limit: number, window: string, retryAfter?: number) {
    super(
      `Rate limit exceeded: ${limit} requests per ${window}`,
      429,
      true,
      { limit, window, retryAfter }
    );
    this.name = 'RateLimitError';
  }
}

export class ExternalServiceError extends BaseError {
  constructor(service: string, originalError?: any) {
    super(
      `External service error: ${service}`,
      502,
      true,
      { service, originalError: originalError?.message }
    );
    this.name = 'ExternalServiceError';
  }
}

// ì¤‘ì•™ ì—ëŸ¬ í•¸ë“¤ëŸ¬
export class ErrorHandler {
  private errorLogger: ErrorLogger;
  private alertManager: AlertManager;
  private errorRecovery: ErrorRecovery;
  
  constructor() {
    this.errorLogger = new ErrorLogger();
    this.alertManager = new AlertManager();
    this.errorRecovery = new ErrorRecovery();
  }
  
  async handle(error: Error, context?: ErrorContext): Promise<void> {
    // ì—ëŸ¬ ë¶„ë¥˜
    const errorType = this.classifyError(error);
    
    // ë¡œê¹…
    await this.errorLogger.log(error, {
      ...context,
      type: errorType,
      severity: this.determineSeverity(error)
    });
    
    // ìš´ì˜ ì—ëŸ¬ vs í”„ë¡œê·¸ë˜ë° ì—ëŸ¬
    if (error instanceof BaseError && error.isOperational) {
      await this.handleOperationalError(error, context);
    } else {
      await this.handleProgrammerError(error, context);
    }
    
    // ë³µêµ¬ ì‹œë„
    if (this.errorRecovery.canRecover(error)) {
      await this.errorRecovery.attempt(error, context);
    }
  }
  
  private async handleOperationalError(
    error: BaseError,
    context?: ErrorContext
  ): Promise<void> {
    // ë©”íŠ¸ë¦­ ê¸°ë¡
    await this.recordErrorMetric(error);
    
    // í•„ìš”ì‹œ ì•Œë¦¼
    if (this.shouldAlert(error)) {
      await this.alertManager.send({
        level: 'warning',
        title: `Operational Error: ${error.name}`,
        message: error.message,
        context
      });
    }
  }
  
  private async handleProgrammerError(
    error: Error,
    context?: ErrorContext
  ): Promise<void> {
    // ì‹¬ê°í•œ ì—ëŸ¬ë¡œ ì²˜ë¦¬
    await this.errorLogger.logCritical(error, context);
    
    // ì¦‰ì‹œ ì•Œë¦¼
    await this.alertManager.sendCritical({
      title: 'Programmer Error Detected',
      error,
      context,
      recommendation: 'Immediate investigation required'
    });
    
    // ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    if (this.shouldShutdown(error)) {
      await this.gracefulShutdown();
    }
  }
  
  // ì—ëŸ¬ ì§‘ê³„ ë° ë¶„ì„
  async analyzeErrors(
    timeRange: TimeRange
  ): Promise<ErrorAnalysis> {
    const errors = await this.errorLogger.query(timeRange);
    
    return {
      total: errors.length,
      byType: this.groupByType(errors),
      byService: this.groupByService(errors),
      trends: this.analyzeTrends(errors),
      patterns: await this.detectPatterns(errors),
      recommendations: this.generateRecommendations(errors)
    };
  }
}

// ì—ëŸ¬ ë³µêµ¬ ì „ëµ
export class ErrorRecovery {
  private strategies: Map<string, RecoveryStrategy> = new Map();
  
  constructor() {
    this.registerDefaultStrategies();
  }
  
  private registerDefaultStrategies(): void {
    // ì¬ì‹œë„ ì „ëµ
    this.strategies.set('retry', new RetryStrategy({
      maxAttempts: 3,
      backoffMultiplier: 2,
      maxBackoffTime: 30000
    }));
    
    // í´ë°± ì „ëµ
    this.strategies.set('fallback', new FallbackStrategy());
    
    // ì„œí‚· ë¸Œë ˆì´ì»¤
    this.strategies.set('circuit-breaker', new CircuitBreakerStrategy({
      threshold: 5,
      timeout: 60000,
      resetTimeout: 120000
    }));
  }
  
  async attempt(
    error: Error,
    context?: ErrorContext
  ): Promise<RecoveryResult> {
    const strategy = this.selectStrategy(error);
    
    if (!strategy) {
      return { recovered: false, reason: 'No recovery strategy available' };
    }
    
    try {
      const result = await strategy.recover(error, context);
      
      if (result.recovered) {
        await this.logRecovery(error, strategy, result);
      }
      
      return result;
      
    } catch (recoveryError) {
      return {
        recovered: false,
        reason: 'Recovery failed',
        error: recoveryError
      };
    }
  }
}
```

### SubTask 1.16.2: ì—ëŸ¬ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ìë™í™”ëœ ì—ëŸ¬ ë³µêµ¬ ë° ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/errors/recovery-strategies.ts
export abstract class RecoveryStrategy {
  abstract canRecover(error: Error): boolean;
  abstract recover(
    error: Error,
    context?: any
  ): Promise<RecoveryResult>;
}

// ì¬ì‹œë„ ì „ëµ
export class RetryStrategy extends RecoveryStrategy {
  private attemptCounts: Map<string, number> = new Map();
  
  constructor(private config: RetryConfig) {
    super();
  }
  
  canRecover(error: Error): boolean {
    // ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ íŒë‹¨
    const retryableErrors = [
      'ETIMEDOUT',
      'ECONNRESET',
      'ENOTFOUND',
      'ECONNREFUSED',
      'EAI_AGAIN'
    ];
    
    if (error instanceof ExternalServiceError) {
      return true;
    }
    
    if (error instanceof RateLimitError) {
      return true;
    }
    
    return retryableErrors.some(code => 
      error.message.includes(code)
    );
  }
  
  async recover(
    error: Error,
    context?: any
  ): Promise<RecoveryResult> {
    const key = this.getRetryKey(error, context);
    const attempts = this.attemptCounts.get(key) || 0;
    
    if (attempts >= this.config.maxAttempts) {
      return {
        recovered: false,
        reason: 'Max retry attempts exceeded'
      };
    }
    
    // ë°±ì˜¤í”„ ê³„ì‚°
    const delay = this.calculateBackoff(attempts);
    
    // ì¬ì‹œë„ ì „ ëŒ€ê¸°
    await this.delay(delay);
    
    try {
      // ì›ë˜ ì‘ì—… ì¬ì‹¤í–‰
      const result = await context.operation();
      
      // ì„±ê³µì‹œ ì¹´ìš´í„° ì´ˆê¸°í™”
      this.attemptCounts.delete(key);
      
      return {
        recovered: true,
        result,
        attempts: attempts + 1
      };
      
    } catch (retryError) {
      // ì¬ì‹œë„ ì‹¤íŒ¨
      this.attemptCounts.set(key, attempts + 1);
      
      // ê³„ì† ì¬ì‹œë„í• ì§€ ê²°ì •
      if (attempts + 1 < this.config.maxAttempts) {
        return await this.recover(retryError, context);
      }
      
      return {
        recovered: false,
        reason: 'Retry failed',
        error: retryError
      };
    }
  }
  
  private calculateBackoff(attempt: number): number {
    const exponentialDelay = Math.pow(
      this.config.backoffMultiplier,
      attempt
    ) * 1000;
    
    const jitteredDelay = exponentialDelay * (0.5 + Math.random() * 0.5);
    
    return Math.min(jitteredDelay, this.config.maxBackoffTime);
  }
}

// ì„œí‚· ë¸Œë ˆì´ì»¤ íŒ¨í„´
export class CircuitBreaker {
  private state: 'closed' | 'open' | 'half-open' = 'closed';
  private failures: number = 0;
  private lastFailureTime?: Date;
  private successCount: number = 0;
  
  constructor(private config: CircuitBreakerConfig) {}
  
  async execute<T>(
    operation: () => Promise<T>
  ): Promise<T> {
    // ì„œí‚· ìƒíƒœ í™•ì¸
    if (this.state === 'open') {
      if (this.shouldAttemptReset()) {
        this.state = 'half-open';
      } else {
        throw new Error('Circuit breaker is open');
      }
    }
    
    try {
      const result = await operation();
      
      // ì„±ê³µ ì²˜ë¦¬
      this.onSuccess();
      
      return result;
      
    } catch (error) {
      // ì‹¤íŒ¨ ì²˜ë¦¬
      this.onFailure();
      
      throw error;
    }
  }
  
  private onSuccess(): void {
    this.failures = 0;
    
    if (this.state === 'half-open') {
      this.successCount++;
      
      if (this.successCount >= this.config.successThreshold) {
        this.state = 'closed';
        this.successCount = 0;
      }
    }
  }
  
  private onFailure(): void {
    this.failures++;
    this.lastFailureTime = new Date();
    
    if (this.state === 'half-open') {
      this.state = 'open';
      this.successCount = 0;
    } else if (this.failures >= this.config.threshold) {
      this.state = 'open';
    }
  }
  
  private shouldAttemptReset(): boolean {
    if (!this.lastFailureTime) return false;
    
    const timeSinceLastFailure = 
      Date.now() - this.lastFailureTime.getTime();
    
    return timeSinceLastFailure >= this.config.resetTimeout;
  }
}

// í´ë°± ì „ëµ
export class FallbackStrategy extends RecoveryStrategy {
  private fallbackHandlers: Map<string, FallbackHandler> = new Map();
  
  registerFallback(
    errorType: string,
    handler: FallbackHandler
  ): void {
    this.fallbackHandlers.set(errorType, handler);
  }
  
  canRecover(error: Error): boolean {
    return this.fallbackHandlers.has(error.constructor.name) ||
           this.fallbackHandlers.has('default');
  }
  
  async recover(
    error: Error,
    context?: any
  ): Promise<RecoveryResult> {
    const handler = this.fallbackHandlers.get(error.constructor.name) ||
                   this.fallbackHandlers.get('default');
    
    if (!handler) {
      return {
        recovered: false,
        reason: 'No fallback handler available'
      };
    }
    
    try {
      const fallbackResult = await handler(error, context);
      
      return {
        recovered: true,
        result: fallbackResult,
        fallback: true
      };
      
    } catch (fallbackError) {
      return {
        recovered: false,
        reason: 'Fallback failed',
        error: fallbackError
      };
    }
  }
}

// ì—ëŸ¬ ë³µêµ¬ ì¡°ì •ì
export class RecoveryOrchestrator {
  private strategies: RecoveryStrategy[] = [];
  private circuitBreakers: Map<string, CircuitBreaker> = new Map();
  
  async orchestrateRecovery(
    error: Error,
    context: RecoveryContext
  ): Promise<RecoveryResult> {
    // ì„œí‚· ë¸Œë ˆì´ì»¤ í™•ì¸
    const breaker = this.getCircuitBreaker(context.service);
    
    try {
      return await breaker.execute(async () => {
        // ì ìš© ê°€ëŠ¥í•œ ì „ëµ ì°¾ê¸°
        for (const strategy of this.strategies) {
          if (strategy.canRecover(error)) {
            const result = await strategy.recover(error, context);
            
            if (result.recovered) {
              return result;
            }
          }
        }
        
        throw error;
      });
      
    } catch (error) {
      // ëª¨ë“  ë³µêµ¬ ì‹œë„ ì‹¤íŒ¨
      return {
        recovered: false,
        reason: 'All recovery strategies failed',
        error
      };
    }
  }
  
  private getCircuitBreaker(service: string): CircuitBreaker {
    if (!this.circuitBreakers.has(service)) {
      this.circuitBreakers.set(service, new CircuitBreaker({
        threshold: 5,
        resetTimeout: 60000,
        successThreshold: 3
      }));
    }
    
    return this.circuitBreakers.get(service)!;
  }
}
```

### SubTask 1.16.3: ì—ëŸ¬ ë¡œê¹… ë° ë¶„ì„
**ë‹´ë‹¹ì**: ë°ì´í„° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ìƒì„¸í•œ ì—ëŸ¬ ë¡œê¹… ë° íŒ¨í„´ ë¶„ì„ ì‹œìŠ¤í…œ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/errors/error-analytics.ts
export class ErrorAnalytics {
  private errorStore: ErrorStore;
  private patternDetector: PatternDetector;
  private anomalyDetector: AnomalyDetector;
  
  constructor() {
    this.errorStore = new ErrorStore();
    this.patternDetector = new PatternDetector();
    this.anomalyDetector = new AnomalyDetector();
  }
  
  // ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
  async analyzePatterns(
    timeRange: TimeRange
  ): Promise<ErrorPatternAnalysis> {
    const errors = await this.errorStore.query({
      startTime: timeRange.start,
      endTime: timeRange.end,
      includeStackTrace: true
    });
    
    // ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ í´ëŸ¬ìŠ¤í„°ë§
    const stackClusters = await this.clusterByStackTrace(errors);
    
    // ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„
    const temporalPatterns = await this.analyzeTemporalPatterns(errors);
    
    // ìƒê´€ê´€ê³„ ë¶„ì„
    const correlations = await this.findCorrelations(errors);
    
    return {
      clusters: stackClusters,
      temporalPatterns,
      correlations,
      insights: this.generateInsights(stackClusters, temporalPatterns)
    };
  }
  
  // ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ í´ëŸ¬ìŠ¤í„°ë§
  private async clusterByStackTrace(
    errors: ErrorRecord[]
  ): Promise<StackCluster[]> {
    const clusters: Map<string, StackCluster> = new Map();
    
    for (const error of errors) {
      const signature = this.generateStackSignature(error.stackTrace);
      
      if (!clusters.has(signature)) {
        clusters.set(signature, {
          signature,
          count: 0,
          errors: [],
          firstSeen: error.timestamp,
          lastSeen: error.timestamp,
          affectedServices: new Set()
        });
      }
      
      const cluster = clusters.get(signature)!;
      cluster.count++;
      cluster.errors.push(error);
      cluster.lastSeen = error.timestamp;
      cluster.affectedServices.add(error.service);
    }
    
    // ì¤‘ìš”ë„ ê³„ì‚°
    return Array.from(clusters.values())
      .map(cluster => ({
        ...cluster,
        severity: this.calculateClusterSeverity(cluster),
        trend: this.calculateTrend(cluster.errors)
      }))
      .sort((a, b) => b.severity - a.severity);
  }
  
  // ì—ëŸ¬ ì˜ˆì¸¡ ëª¨ë¸
  async predictErrors(
    horizon: number
  ): Promise<ErrorPrediction[]> {
    const historicalData = await this.errorStore.getHistoricalData({
      days: 30
    });
    
    // ì‹œê³„ì—´ ë¶„ì„
    const timeSeries = this.createTimeSeries(historicalData);
    
    // ARIMA ëª¨ë¸ ì ìš©
    const model = new ARIMAModel(timeSeries);
    await model.fit();
    
    // ì˜ˆì¸¡
    const predictions = model.predict(horizon);
    
    return predictions.map((value, index) => ({
      timestamp: new Date(Date.now() + index * 3600000),
      predictedCount: Math.round(value),
      confidence: model.getConfidenceInterval(index),
      factors: this.identifyRiskFactors(historicalData)
    }));
  }
  
  // ì—ëŸ¬ ì˜í–¥ë„ ë¶„ì„
  async analyzeImpact(
    error: ErrorRecord
  ): Promise<ErrorImpact> {
    // ì˜í–¥ë°›ëŠ” ì‚¬ìš©ì ìˆ˜
    const affectedUsers = await this.countAffectedUsers(error);
    
    // ì˜í–¥ë°›ëŠ” ì„œë¹„ìŠ¤
    const affectedServices = await this.traceAffectedServices(error);
    
    // ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ë„
    const businessImpact = await this.calculateBusinessImpact(error);
    
    // ë³µêµ¬ ì‹œê°„ ì˜ˆì¸¡
    const estimatedRecoveryTime = await this.estimateRecoveryTime(error);
    
    return {
      users: affectedUsers,
      services: affectedServices,
      businessImpact,
      estimatedRecoveryTime,
      severity: this.calculateSeverity(
        affectedUsers,
        affectedServices,
        businessImpact
      ),
      recommendations: this.generateRecommendations(error)
    };
  }
  
  // ì‹¤ì‹œê°„ ì´ìƒ ê°ì§€
  async detectAnomalies(
    metrics: ErrorMetrics
  ): Promise<Anomaly[]> {
    const anomalies: Anomaly[] = [];
    
    // ì—ëŸ¬ìœ¨ ìŠ¤íŒŒì´í¬ ê°ì§€
    if (metrics.errorRate > this.anomalyDetector.getThreshold('errorRate')) {
      anomalies.push({
        type: 'error_rate_spike',
        severity: 'high',
        value: metrics.errorRate,
        threshold: this.anomalyDetector.getThreshold('errorRate'),
        timestamp: new Date()
      });
    }
    
    // ìƒˆë¡œìš´ ì—ëŸ¬ íƒ€ì… ê°ì§€
    const newErrorTypes = await this.detectNewErrorTypes(metrics);
    if (newErrorTypes.length > 0) {
      anomalies.push({
        type: 'new_error_types',
        severity: 'medium',
        value: newErrorTypes,
        timestamp: new Date()
      });
    }
    
    // ì—ëŸ¬ íŒ¨í„´ ë³€í™” ê°ì§€
    const patternChanges = await this.detectPatternChanges(metrics);
    if (patternChanges.significant) {
      anomalies.push({
        type: 'pattern_change',
        severity: 'medium',
        value: patternChanges,
        timestamp: new Date()
      });
    }
    
    return anomalies;
  }
}

// ì—ëŸ¬ ë¦¬í¬íŠ¸ ìƒì„±
export class ErrorReporter {
  async generateReport(
    timeRange: TimeRange,
    options: ReportOptions
  ): Promise<ErrorReport> {
    const analytics = new ErrorAnalytics();
    
    const [patterns, predictions, topErrors] = await Promise.all([
      analytics.analyzePatterns(timeRange),
      analytics.predictErrors(24), // 24ì‹œê°„ ì˜ˆì¸¡
      this.getTopErrors(timeRange)
    ]);
    
    return {
      summary: {
        totalErrors: topErrors.reduce((sum, e) => sum + e.count, 0),
        errorRate: this.calculateErrorRate(topErrors),
        mttr: await this.calculateMTTR(timeRange),
        trends: patterns.temporalPatterns
      },
      topErrors: topErrors.map(error => ({
        ...error,
        impact: await analytics.analyzeImpact(error),
        resolution: await this.getResolutionStatus(error)
      })),
      patterns: patterns.clusters,
      predictions,
      recommendations: this.generateRecommendations(patterns, predictions),
      generatedAt: new Date()
    };
  }
}
```

### SubTask 1.16.4: ì—ëŸ¬ ì•Œë¦¼ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 6ì‹œê°„

**ëª©í‘œ**: ì§€ëŠ¥ì ì¸ ì—ëŸ¬ ì•Œë¦¼ ë° ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì‹œìŠ¤í…œ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/errors/error-alerting.ts
export class ErrorAlertingSystem {
  private channels: Map<string, AlertChannel> = new Map();
  private rules: AlertRule[] = [];
  private suppressionRules: SuppressionRule[] = [];
  private escalationPolicy: EscalationPolicy;
  
  constructor() {
    this.initializeChannels();
    this.loadAlertRules();
    this.escalationPolicy = new EscalationPolicy();
  }
  
  private initializeChannels(): void {
    // Slack ì±„ë„
    this.channels.set('slack', new SlackAlertChannel({
      webhookUrl: process.env.SLACK_WEBHOOK_URL,
      defaultChannel: '#alerts'
    }));
    
    // Email ì±„ë„
    this.channels.set('email', new EmailAlertChannel({
      smtp: {
        host: process.env.SMTP_HOST,
        port: 587,
        secure: false
      }
    }));
    
    // PagerDuty ì±„ë„
    this.channels.set('pagerduty', new PagerDutyAlertChannel({
      apiKey: process.env.PAGERDUTY_API_KEY,
      serviceId: process.env.PAGERDUTY_SERVICE_ID
    }));
    
    // SMS ì±„ë„
    this.channels.set('sms', new SMSAlertChannel({
      twilioAccountSid: process.env.TWILIO_ACCOUNT_SID,
      twilioAuthToken: process.env.TWILIO_AUTH_TOKEN
    }));
  }
  
  // ì—ëŸ¬ ì•Œë¦¼ ì²˜ë¦¬
  async handleError(error: ErrorRecord): Promise<void> {
    // ì–µì œ ê·œì¹™ í™•ì¸
    if (this.shouldSuppress(error)) {
      await this.logSuppression(error);
      return;
    }
    
    // ì ìš© ê°€ëŠ¥í•œ ê·œì¹™ ì°¾ê¸°
    const matchingRules = this.findMatchingRules(error);
    
    // ì•Œë¦¼ ê·¸ë£¹í™”
    const groupKey = this.generateGroupKey(error);
    const shouldGroup = await this.shouldGroupAlert(groupKey, error);
    
    if (shouldGroup) {
      await this.updateAlertGroup(groupKey, error);
    } else {
      // ìƒˆ ì•Œë¦¼ ìƒì„±
      const alert = await this.createAlert(error, matchingRules);
      
      // ì±„ë„ë³„ ì „ì†¡
      await this.sendAlert(alert);
      
      // ì—ìŠ¤ì»¬ë ˆì´ì…˜ ìŠ¤ì¼€ì¤„ë§
      if (alert.severity >= 'high') {
        await this.scheduleEscalation(alert);
      }
    }
  }
  
  // ì§€ëŠ¥ì ì¸ ì•Œë¦¼ ê·œì¹™
  private findMatchingRules(error: ErrorRecord): AlertRule[] {
    return this.rules.filter(rule => {
      // ì—ëŸ¬ íƒ€ì… ë§¤ì¹­
      if (rule.errorTypes && !rule.errorTypes.includes(error.type)) {
        return false;
      }
      
      // ì„œë¹„ìŠ¤ ë§¤ì¹­
      if (rule.services && !rule.services.includes(error.service)) {
        return false;
      }
      
      // ì‹¬ê°ë„ ë§¤ì¹­
      if (rule.minSeverity && error.severity < rule.minSeverity) {
        return false;
      }
      
      // ì»¤ìŠ¤í…€ ì¡°ê±´
      if (rule.customCondition) {
        return rule.customCondition(error);
      }
      
      return true;
    });
  }
  
  // ì•Œë¦¼ ê·¸ë£¹í™”
  private async shouldGroupAlert(
    groupKey: string,
    error: ErrorRecord
  ): Promise<boolean> {
    const existingGroup = await this.getAlertGroup(groupKey);
    
    if (!existingGroup) return false;
    
    // ì‹œê°„ ìœˆë„ìš° í™•ì¸
    const timeSinceFirst = Date.now() - existingGroup.firstAlert.getTime();
    if (timeSinceFirst > 3600000) return false; // 1ì‹œê°„
    
    // ê·¸ë£¹ í¬ê¸° ì œí•œ
    if (existingGroup.count >= 100) return false;
    
    return true;
  }
  
  // ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì²˜ë¦¬
  async scheduleEscalation(alert: Alert): Promise<void> {
    const escalationSteps = this.escalationPolicy.getSteps(alert.severity);
    
    for (const [index, step] of escalationSteps.entries()) {
      setTimeout(async () => {
        // ì•Œë¦¼ì´ í•´ê²°ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if (await this.isResolved(alert.id)) {
          return;
        }
        
        // ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì‹¤í–‰
        await this.escalate(alert, step);
        
      }, step.delayMinutes * 60 * 1000);
    }
  }
  
  private async escalate(
    alert: Alert,
    step: EscalationStep
  ): Promise<void> {
    // ë‹´ë‹¹ì ì°¾ê¸°
    const responders = await this.getResponders(step.level);
    
    // ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì•Œë¦¼ ì „ì†¡
    const escalationAlert = {
      ...alert,
      escalationLevel: step.level,
      responders,
      message: `[ESCALATED] ${alert.message}`
    };
    
    // ê³ ê¸‰ ì±„ë„ë¡œ ì „ì†¡
    for (const channel of step.channels) {
      await this.channels.get(channel)?.send(escalationAlert);
    }
    
    // ì—ìŠ¤ì»¬ë ˆì´ì…˜ ê¸°ë¡
    await this.logEscalation(alert, step);
  }
  
  // ì•Œë¦¼ ì–µì œ ê·œì¹™
  private shouldSuppress(error: ErrorRecord): boolean {
    for (const rule of this.suppressionRules) {
      // ì‹œê°„ ê¸°ë°˜ ì–µì œ
      if (rule.schedule && !this.isInSchedule(rule.schedule)) {
        continue;
      }
      
      // ì¡°ê±´ ê¸°ë°˜ ì–µì œ
      if (rule.condition(error)) {
        return true;
      }
    }
    
    return false;
  }
  
  // ì•Œë¦¼ í…œí”Œë¦¿
  private formatAlert(
    error: ErrorRecord,
    template: AlertTemplate
  ): FormattedAlert {
    const context = {
      error,
      timestamp: new Date().toISOString(),
      environment: process.env.NODE_ENV,
      service: error.service,
      dashboard: `${process.env.DASHBOARD_URL}/errors/${error.id}`
    };
    
    return {
      title: this.renderTemplate(template.title, context),
      message: this.renderTemplate(template.message, context),
      fields: template.fields?.map(field => ({
        name: field.name,
        value: this.renderTemplate(field.value, context),
        inline: field.inline
      })),
      actions: template.actions,
      priority: error.severity
    };
  }
}

// ì•Œë¦¼ ì±„ë„ êµ¬í˜„
export abstract class AlertChannel {
  abstract send(alert: Alert): Promise<void>;
  abstract test(): Promise<boolean>;
}

export class SlackAlertChannel extends AlertChannel {
  constructor(private config: SlackConfig) {
    super();
  }
  
  async send(alert: Alert): Promise<void> {
    const message = {
      text: alert.title,
      attachments: [{
        color: this.getSeverityColor(alert.severity),
        fields: alert.fields,
        ts: Math.floor(Date.now() / 1000)
      }],
      blocks: this.createBlocks(alert)
    };
    
    await axios.post(this.config.webhookUrl, message);
  }
  
  private createBlocks(alert: Alert): any[] {
    return [
      {
        type: 'header',
        text: {
          type: 'plain_text',
          text: alert.title
        }
      },
      {
        type: 'section',
        text: {
          type: 'mrkdwn',
          text: alert.message
        }
      },
      {
        type: 'actions',
        elements: alert.actions?.map(action => ({
          type: 'button',
          text: {
            type: 'plain_text',
            text: action.label
          },
          url: action.url,
          style: action.style
        }))
      }
    ];
  }
}
```

## Task 1.17: ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ

### SubTask 1.17.1: í™˜ê²½ë³„ ì„¤ì • ê´€ë¦¬
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ì•ˆì „í•œ í™˜ê²½ë³„ ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/config/configuration-manager.ts
import { SSMClient, GetParameterCommand } from '@aws-sdk/client-ssm';
import { SecretsManagerClient, GetSecretValueCommand } from '@aws-sdk/client-secrets-manager';

export class ConfigurationManager {
  private ssmClient: SSMClient;
  private secretsClient: SecretsManagerClient;
  private cache: Map<string, CachedConfig> = new Map();
  private validators: Map<string, ConfigValidator> = new Map();
  
  constructor(private config: ConfigManagerOptions) {
    this.ssmClient = new SSMClient({ region: config.region });
    this.secretsClient = new SecretsManagerClient({ region: config.region });
    
    this.registerDefaultValidators();
  }
  
  // ì„¤ì • ìŠ¤í‚¤ë§ˆ ì •ì˜
  defineSchema(schema: ConfigSchema): void {
    Object.entries(schema).forEach(([key, definition]) => {
      this.validators.set(key, new ConfigValidator(definition));
    });
  }
  
  // ì„¤ì • ë¡œë“œ
  async loadConfiguration(): Promise<Configuration> {
    const environment = process.env.NODE_ENV || 'development';
    
    // ê¸°ë³¸ ì„¤ì •
    const baseConfig = await this.loadBaseConfig();
    
    // í™˜ê²½ë³„ ì„¤ì •
    const envConfig = await this.loadEnvironmentConfig(environment);
    
    // AWS Parameter Store
    const parameterConfig = await this.loadParameterStoreConfig();
    
    // AWS Secrets Manager
    const secrets = await this.loadSecrets();
    
    // ë³‘í•© ë° ê²€ì¦
    const mergedConfig = this.mergeConfigurations(
      baseConfig,
      envConfig,
      parameterConfig,
      secrets
    );
    
    await this.validateConfiguration(mergedConfig);
    
    return mergedConfig;
  }
  
  // Parameter Store ì„¤ì •
  private async loadParameterStoreConfig(): Promise<any> {
    const prefix = `/${this.config.applicationName}/${process.env.NODE_ENV}`;
    const parameters = await this.getParametersByPath(prefix);
    
    const config: any = {};
    
    for (const param of parameters) {
      const key = param.Name!.replace(prefix + '/', '').replace(/\//g, '.');
      const value = this.parseParameterValue(param.Value!, param.Type);
      
      this.setNestedProperty(config, key, value);
    }
    
    return config;
  }
  
  // Secrets Manager í†µí•©
  private async loadSecrets(): Promise<any> {
    const secretIds = [
      'database-credentials',
      'api-keys',
      'jwt-secret',
      'encryption-keys'
    ];
    
    const secrets: any = {};
    
    for (const secretId of secretIds) {
      try {
        const secretName = `${this.config.applicationName}/${process.env.NODE_ENV}/${secretId}`;
        const secret = await this.getSecret(secretName);
        
        Object.assign(secrets, secret);
      } catch (error) {
        if (error.name !== 'ResourceNotFoundException') {
          throw error;
        }
      }
    }
    
    return secrets;
  }
  
  // ë™ì  ì„¤ì • ì—…ë°ì´íŠ¸
  async watchForChanges(
    callback: (changes: ConfigChange[]) => void
  ): Promise<void> {
    // EventBridge ê·œì¹™ ì„¤ì •
    await this.setupParameterChangeListener();
    
    // í´ë§ ê¸°ë°˜ ê°ì‹œ (ë°±ì—…)
    setInterval(async () => {
      const changes = await this.detectChanges();
      
      if (changes.length > 0) {
        callback(changes);
      }
    }, this.config.pollInterval || 60000);
  }
  
  // ì„¤ì • ê²€ì¦
  private async validateConfiguration(
    config: Configuration
  ): Promise<void> {
    const errors: ValidationError[] = [];
    
    for (const [key, validator] of this.validators) {
      const value = this.getNestedProperty(config, key);
      const result = await validator.validate(value);
      
      if (!result.valid) {
        errors.push({
          key,
          value,
          errors: result.errors
        });
      }
    }
    
    if (errors.length > 0) {
      throw new ConfigurationError('Configuration validation failed', errors);
    }
  }
  
  // íƒ€ì… ì•ˆì „ ì„¤ì • ì ‘ê·¼
  get<T>(key: string, defaultValue?: T): T {
    const value = this.getNestedProperty(this.currentConfig, key);
    
    if (value === undefined) {
      if (defaultValue !== undefined) {
        return defaultValue;
      }
      
      throw new Error(`Configuration key not found: ${key}`);
    }
    
    return value as T;
  }
  
  // ì„¤ì • ì•”í˜¸í™”
  private async encryptSensitiveValues(
    config: any
  ): Promise<any> {
    const encrypted = { ...config };
    
    const sensitiveKeys = [
      'database.password',
      'apiKeys',
      'jwt.secret',
      'encryption.key'
    ];
    
    for (const key of sensitiveKeys) {
      const value = this.getNestedProperty(encrypted, key);
      
      if (value) {
        const encryptedValue = await this.encrypt(value);
        this.setNestedProperty(encrypted, key, encryptedValue);
      }
    }
    
    return encrypted;
  }
}

// ì„¤ì • ìŠ¤í‚¤ë§ˆ ë¹Œë”
export class ConfigSchemaBuilder {
  private schema: ConfigSchema = {};
  
  string(key: string, options?: StringOptions): this {
    this.schema[key] = {
      type: 'string',
      ...options
    };
    return this;
  }
  
  number(key: string, options?: NumberOptions): this {
    this.schema[key] = {
      type: 'number',
      ...options
    };
    return this;
  }
  
  boolean(key: string, options?: BooleanOptions): this {
    this.schema[key] = {
      type: 'boolean',
      ...options
    };
    return this;
  }
  
  object(key: string, schema: ConfigSchema): this {
    this.schema[key] = {
      type: 'object',
      properties: schema
    };
    return this;
  }
  
  array(key: string, itemType: SchemaType): this {
    this.schema[key] = {
      type: 'array',
      items: itemType
    };
    return this;
  }
  
  build(): ConfigSchema {
    return this.schema;
  }
}

// í™˜ê²½ë³„ ì„¤ì • íŒŒì¼
export const configSchema = new ConfigSchemaBuilder()
  .object('server', {
    port: { type: 'number', min: 1, max: 65535, default: 3000 },
    host: { type: 'string', default: '0.0.0.0' }
  })
  .object('database', {
    host: { type: 'string', required: true },
    port: { type: 'number', default: 5432 },
    name: { type: 'string', required: true },
    user: { type: 'string', required: true },
    password: { type: 'string', required: true, sensitive: true }
  })
  .object('redis', {
    url: { type: 'string', format: 'url', required: true }
  })
  .object('aws', {
    region: { type: 'string', required: true },
    credentials: { type: 'object', required: false }
  })
  .object('logging', {
    level: { type: 'string', enum: ['debug', 'info', 'warn', 'error'] },
    format: { type: 'string', enum: ['json', 'text'] }
  })
  .build();
```

### SubTask 1.17.2: ê¸°ëŠ¥ í”Œë˜ê·¸ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ë™ì  ê¸°ëŠ¥ í”Œë˜ê·¸ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/config/feature-flags.ts
export class FeatureFlagManager {
  private flags: Map<string, FeatureFlag> = new Map();
  private evaluator: FlagEvaluator;
  private storage: FlagStorage;
  private cache: FlagCache;
  
  constructor(config: FeatureFlagConfig) {
    this.evaluator = new FlagEvaluator();
    this.storage = new DynamoDBFlagStorage(config.tableName);
    this.cache = new RedisFlagCache(config.redis);
    
    this.initialize();
  }
  
  // í”Œë˜ê·¸ ì •ì˜
  async defineFlag(flag: FeatureFlagDefinition): Promise<void> {
    const featureFlag: FeatureFlag = {
      ...flag,
      id: crypto.randomUUID(),
      createdAt: new Date(),
      updatedAt: new Date(),
      version: 1
    };
    
    await this.storage.save(featureFlag);
    await this.cache.invalidate(flag.key);
    
    this.flags.set(flag.key, featureFlag);
  }
  
  // í”Œë˜ê·¸ í‰ê°€
  async evaluate(
    key: string,
    context: EvaluationContext
  ): Promise<boolean> {
    // ìºì‹œ í™•ì¸
    const cached = await this.cache.get(key, context);
    if (cached !== null) {
      return cached;
    }
    
    // í”Œë˜ê·¸ ë¡œë“œ
    const flag = await this.getFlag(key);
    if (!flag) {
      return false;
    }
    
    // í‰ê°€ ê·œì¹™ ì ìš©
    const result = await this.evaluator.evaluate(flag, context);
    
    // ìºì‹œ ì €ì¥
    await this.cache.set(key, context, result, flag.cacheTTL);
    
    // ë©”íŠ¸ë¦­ ê¸°ë¡
    await this.recordEvaluation(key, context, result);
    
    return result;
  }
  
  // ë³µì¡í•œ í‰ê°€ ê·œì¹™
  private async evaluateRules(
    flag: FeatureFlag,
    context: EvaluationContext
  ): Promise<boolean> {
    // ê¸€ë¡œë²Œ í™œì„±í™” í™•ì¸
    if (!flag.enabled) {
      return false;
    }
    
    // íƒ€ê²ŸíŒ… ê·œì¹™ í‰ê°€
    for (const rule of flag.rules) {
      if (await this.matchesRule(rule, context)) {
        return rule.enabled;
      }
    }
    
    // ì ì§„ì  ë¡¤ì•„ì›ƒ
    if (flag.rollout) {
      return this.evaluateRollout(flag.rollout, context);
    }
    
    return flag.defaultValue;
  }
  
  // ê·œì¹™ ë§¤ì¹­
  private async matchesRule(
    rule: TargetingRule,
    context: EvaluationContext
  ): Promise<boolean> {
    switch (rule.type) {
      case 'user':
        return this.matchesUserRule(rule, context);
        
      case 'segment':
        return await this.matchesSegmentRule(rule, context);
        
      case 'percentage':
        return this.matchesPercentageRule(rule, context);
        
      case 'schedule':
        return this.matchesScheduleRule(rule);
        
      case 'custom':
        return await rule.customEvaluator(context);
        
      default:
        return false;
    }
  }
  
  // ì‚¬ìš©ì ì„¸ê·¸ë¨¼íŠ¸ ê·œì¹™
  private async matchesSegmentRule(
    rule: SegmentRule,
    context: EvaluationContext
  ): Promise<boolean> {
    const userSegments = await this.getUserSegments(context.userId);
    
    return rule.segments.some(segment => 
      userSegments.includes(segment)
    );
  }
  
  // ì ì§„ì  ë¡¤ì•„ì›ƒ
  private evaluateRollout(
    rollout: RolloutConfig,
    context: EvaluationContext
  ): boolean {
    const hash = this.hashContext(
      rollout.salt + context.userId
    );
    
    const bucket = hash % 100;
    
    return bucket < rollout.percentage;
  }
  
  // A/B í…ŒìŠ¤íŠ¸ ì§€ì›
  async getVariant(
    experimentKey: string,
    context: EvaluationContext
  ): Promise<Variant> {
    const experiment = await this.getExperiment(experimentKey);
    
    if (!experiment || !experiment.active) {
      return { key: 'control', value: null };
    }
    
    // ì‚¬ìš©ì í• ë‹¹
    const assignment = await this.getOrCreateAssignment(
      experiment,
      context
    );
    
    return experiment.variants[assignment.variantIndex];
  }
  
  // í”Œë˜ê·¸ ëª¨ë‹ˆí„°ë§
  async getUsageMetrics(
    flagKey: string,
    timeRange: TimeRange
  ): Promise<FlagMetrics> {
    const evaluations = await this.storage.queryEvaluations({
      flagKey,
      startTime: timeRange.start,
      endTime: timeRange.end
    });
    
    return {
      totalEvaluations: evaluations.length,
      trueEvaluations: evaluations.filter(e => e.result).length,
      falseEvaluations: evaluations.filter(e => !e.result).length,
      uniqueUsers: new Set(evaluations.map(e => e.userId)).size,
      evaluationsByHour: this.groupByHour(evaluations),
      performanceP95: this.calculatePercentile(
        evaluations.map(e => e.duration),
        0.95
      )
    };
  }
}

// í”Œë˜ê·¸ í‰ê°€ê¸°
export class FlagEvaluator {
  async evaluate(
    flag: FeatureFlag,
    context: EvaluationContext
  ): Promise<boolean> {
    const startTime = performance.now();
    
    try {
      // í•„ìˆ˜ ì¡°ê±´ í™•ì¸
      if (flag.prerequisites) {
        for (const prereq of flag.prerequisites) {
          const prereqResult = await this.evaluatePrerequisite(
            prereq,
            context
          );
          
          if (!prereqResult) {
            return false;
          }
        }
      }
      
      // ë©”ì¸ í‰ê°€
      const result = await this.evaluateFlag(flag, context);
      
      // í‰ê°€ ì‹œê°„ ê¸°ë¡
      const duration = performance.now() - startTime;
      await this.recordPerformance(flag.key, duration);
      
      return result;
      
    } catch (error) {
      // ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
      console.error(`Flag evaluation error: ${flag.key}`, error);
      return flag.defaultValue;
    }
  }
}

// í”Œë˜ê·¸ UI ê´€ë¦¬
export class FeatureFlagUI {
  async renderDashboard(): Promise<DashboardData> {
    const flags = await this.getAllFlags();
    const metrics = await this.getOverallMetrics();
    
    return {
      flags: flags.map(flag => ({
        ...flag,
        usage: metrics[flag.key] || { evaluations: 0 }
      })),
      summary: {
        totalFlags: flags.length,
        activeFlags: flags.filter(f => f.enabled).length,
        experimentsRunning: flags.filter(f => f.experiment).length
      },
      recentChanges: await this.getRecentChanges()
    };
  }
}
```

### SubTask 1.17.3: ì‹œí¬ë¦¿ ê´€ë¦¬
**ë‹´ë‹¹ì**: ë³´ì•ˆ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì•ˆì „í•œ ì‹œí¬ë¦¿ ê´€ë¦¬ ë° ë¡œí…Œì´ì…˜ ì‹œìŠ¤í…œ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/config/secrets-manager.ts
export class SecretsManager {
  private secretsClient: SecretsManagerClient;
  private kmsClient: KMSClient;
  private cache: SecretCache;
  private rotationScheduler: RotationScheduler;
  
  constructor(private config: SecretsConfig) {
    this.secretsClient = new SecretsManagerClient({
      region: config.region
    });
    
    this.kmsClient = new KMSClient({
      region: config.region
    });
    
    this.cache = new SecretCache({
      ttl: config.cacheTTL || 3600000 // 1ì‹œê°„
    });
    
    this.rotationScheduler = new RotationScheduler();
  }
  
  // ì‹œí¬ë¦¿ ìƒì„±
  async createSecret(
    name: string,
    value: any,
    options?: CreateSecretOptions
  ): Promise<string> {
    const secretString = typeof value === 'string' 
      ? value 
      : JSON.stringify(value);
    
    const command = new CreateSecretCommand({
      Name: this.getSecretName(name),
      SecretString: secretString,
      Description: options?.description,
      KmsKeyId: options?.kmsKeyId || this.config.defaultKmsKeyId,
      Tags: [
        { Key: 'Application', Value: this.config.applicationName },
        { Key: 'Environment', Value: process.env.NODE_ENV },
        ...(options?.tags || [])
      ]
    });
    
    const response = await this.secretsClient.send(command);
    
    // ìë™ ë¡œí…Œì´ì…˜ ì„¤ì •
    if (options?.enableRotation) {
      await this.enableRotation(
        response.ARN!,
        options.rotationRules
      );
    }
    
    return response.ARN!;
  }
  
  // ì‹œí¬ë¦¿ ì¡°íšŒ
  async getSecret<T = any>(name: string): Promise<T> {
    // ìºì‹œ í™•ì¸
    const cached = this.cache.get<T>(name);
    if (cached) {
      return cached;
    }
    
    try {
      const command = new GetSecretValueCommand({
        SecretId: this.getSecretName(name),
        VersionStage: 'AWSCURRENT'
      });
      
      const response = await this.secretsClient.send(command);
      
      let secretValue: T;
      
      if (response.SecretString) {
        try {
          secretValue = JSON.parse(response.SecretString) as T;
        } catch {
          secretValue = response.SecretString as any;
        }
      } else if (response.SecretBinary) {
        secretValue = Buffer.from(response.SecretBinary) as any;
      } else {
        throw new Error('Secret has no value');
      }
      
      // ìºì‹œ ì €ì¥
      this.cache.set(name, secretValue);
      
      return secretValue;
      
    } catch (error) {
      if (error.name === 'ResourceNotFoundException') {
        throw new Error(`Secret not found: ${name}`);
      }
      throw error;
    }
  }
  
  // ì‹œí¬ë¦¿ ë¡œí…Œì´ì…˜
  async rotateSecret(
    name: string,
    newValue: any
  ): Promise<void> {
    const secretName = this.getSecretName(name);
    
    // ìƒˆ ë²„ì „ ìƒì„±
    await this.secretsClient.send(new PutSecretValueCommand({
      SecretId: secretName,
      SecretString: typeof newValue === 'string' 
        ? newValue 
        : JSON.stringify(newValue),
      VersionStages: ['AWSPENDING']
    }));
    
    // ê²€ì¦
    const isValid = await this.validateNewSecret(secretName, newValue);
    
    if (!isValid) {
      throw new Error('Secret validation failed');
    }
    
    // ë²„ì „ ìŠ¹ê²©
    await this.promoteSecretVersion(secretName);
    
    // ìºì‹œ ë¬´íš¨í™”
    this.cache.delete(name);
    
    // ì˜ì¡´ ì„œë¹„ìŠ¤ ì•Œë¦¼
    await this.notifyDependentServices(name);
  }
  
  // ìë™ ë¡œí…Œì´ì…˜ ì„¤ì •
  async enableRotation(
    secretArn: string,
    rules: RotationRules
  ): Promise<void> {
    const lambdaArn = await this.createRotationLambda(rules);
    
    await this.secretsClient.send(new RotateSecretCommand({
      SecretId: secretArn,
      RotationLambdaARN: lambdaArn,
      RotationRules: {
        AutomaticallyAfterDays: rules.rotationDays || 30
      }
    }));
    
    // ë¡œí…Œì´ì…˜ ìŠ¤ì¼€ì¤„ ë“±ë¡
    this.rotationScheduler.schedule({
      secretArn,
      rules,
      nextRotation: this.calculateNextRotation(rules)
    });
  }
  
  // ì‹œí¬ë¦¿ ì•”í˜¸í™”
  async encryptValue(
    plaintext: string,
    context?: EncryptionContext
  ): Promise<string> {
    const command = new EncryptCommand({
      KeyId: this.config.defaultKmsKeyId,
      Plaintext: Buffer.from(plaintext),
      EncryptionContext: context
    });
    
    const response = await this.kmsClient.send(command);
    
    return Buffer.from(response.CiphertextBlob!).toString('base64');
  }
  
  // ì‹œí¬ë¦¿ ë³µí˜¸í™”
  async decryptValue(
    ciphertext: string,
    context?: EncryptionContext
  ): Promise<string> {
    const command = new DecryptCommand({
      CiphertextBlob: Buffer.from(ciphertext, 'base64'),
      EncryptionContext: context
    });
    
    const response = await this.kmsClient.send(command);
    
    return Buffer.from(response.Plaintext!).toString();
  }
  
  // ì‹œí¬ë¦¿ ê°ì‚¬
  async auditSecretAccess(
    secretName: string,
    timeRange: TimeRange
  ): Promise<SecretAuditLog[]> {
    const events = await this.queryCloudTrail({
      eventName: 'GetSecretValue',
      resourceName: this.getSecretName(secretName),
      startTime: timeRange.start,
      endTime: timeRange.end
    });
    
    return events.map(event => ({
      timestamp: new Date(event.eventTime),
      user: event.userIdentity.principalId,
      sourceIP: event.sourceIPAddress,
      userAgent: event.userAgent,
      success: !event.errorCode,
      errorCode: event.errorCode,
      errorMessage: event.errorMessage
    }));
  }
}

// ì‹œí¬ë¦¿ ë¡œí…Œì´ì…˜ í•¸ë“¤ëŸ¬
export class SecretRotationHandler {
  async rotate(event: RotationEvent): Promise<void> {
    const { Step, SecretId, VersionId } = event;
    
    switch (Step) {
      case 'createSecret':
        await this.createNewSecret(SecretId, VersionId);
        break;
        
      case 'setSecret':
        await this.setSecretInService(SecretId, VersionId);
        break;
        
      case 'testSecret':
        await this.testSecretConnection(SecretId, VersionId);
        break;
        
      case 'finishSecret':
        await this.finishSecretRotation(SecretId, VersionId);
        break;
    }
  }
  
  private async createNewSecret(
    secretId: string,
    versionId: string
  ): Promise<void> {
    // í˜„ì¬ ì‹œí¬ë¦¿ ê°€ì ¸ì˜¤ê¸°
    const currentSecret = await this.getCurrentSecret(secretId);
    
    // ìƒˆ ì‹œí¬ë¦¿ ìƒì„±
    const newSecret = await this.generateNewSecret(currentSecret);
    
    // ì €ì¥
    await this.storeSecret(secretId, versionId, newSecret);
  }
  
  private async generateNewSecret(
    current: any
  ): Promise<any> {
    if (current.password) {
      // ìƒˆ ë¹„ë°€ë²ˆí˜¸ ìƒì„±
      current.password = await this.generateSecurePassword();
    }
    
    if (current.apiKey) {
      // ìƒˆ API í‚¤ ìƒì„±
      current.apiKey = await this.generateAPIKey();
    }
    
    return current;
  }
}
```

### SubTask 1.17.4: ì„¤ì • ê°ì‚¬ ë° ë²„ì „ ê´€ë¦¬
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 6ì‹œê°„

**ëª©í‘œ**: ì„¤ì • ë³€ê²½ ì¶”ì  ë° ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ

**êµ¬í˜„ ë‚´ìš©**:

```typescript
// backend/src/config/config-audit.ts
export class ConfigurationAudit {
  private auditStore: AuditStore;
  private versionControl: ConfigVersionControl;
  private diffEngine: DiffEngine;
  
  constructor() {
    this.auditStore = new DynamoDBAuditStore();
    this.versionControl = new ConfigVersionControl();
    this.diffEngine = new DiffEngine();
  }
  
  // ì„¤ì • ë³€ê²½ ì¶”ì 
  async trackChange(
    change: ConfigChange
  ): Promise<void> {
    const auditEntry: ConfigAuditEntry = {
      id: crypto.randomUUID(),
      timestamp: new Date(),
      user: change.user || 'system',
      action: change.action,
      resource: change.resource,
      environment: process.env.NODE_ENV,
      changes: await this.calculateDiff(change),
      metadata: {
        source: change.source,
        reason: change.reason,
        approvedBy: change.approvedBy,
        ticketNumber: change.ticketNumber
      }
    };
    
    // ê°ì‚¬ ë¡œê·¸ ì €ì¥
    await this.auditStore.save(auditEntry);
    
    // ë²„ì „ ìƒì„±
    await this.versionControl.createVersion({
      config: change.newValue,
      auditId: auditEntry.id,
      tags: change.tags
    });
    
    // ì•Œë¦¼ ì „ì†¡
    if (this.shouldNotify(change)) {
      await this.sendNotification(auditEntry);
    }
  }
  
  // ì„¤ì • ë²„ì „ ê´€ë¦¬
  async createSnapshot(
    name: string,
    description?: string
  ): Promise<ConfigSnapshot> {
    const currentConfig = await this.getCurrentConfiguration();
    
    const snapshot: ConfigSnapshot = {
      id: crypto.randomUUID(),
      name,
      description,
      timestamp: new Date(),
      environment: process.env.NODE_ENV,
      configuration: currentConfig,
      checksum: this.calculateChecksum(currentConfig)
    };
    
    await this.versionControl.saveSnapshot(snapshot);
    
    return snapshot;
  }
  
  // ì„¤ì • ë¡¤ë°±
  async rollback(
    targetVersion: string,
    reason: string
  ): Promise<RollbackResult> {
    const rollbackPlan = await this.createRollbackPlan(targetVersion);
    
    // ë¡¤ë°± ì „ ê²€ì¦
    const validation = await this.validateRollback(rollbackPlan);
    if (!validation.safe) {
      throw new Error(`Rollback validation failed: ${validation.reason}`);
    }
    
    // ë°±ì—… ìƒì„±
    const backup = await this.createSnapshot(
      `pre-rollback-${Date.now()}`,
      'Automatic backup before rollback'
    );
    
    try {
      // ë¡¤ë°± ì‹¤í–‰
      for (const step of rollbackPlan.steps) {
        await this.executeRollbackStep(step);
      }
      
      // ë¡¤ë°± ê°ì‚¬ ê¸°ë¡
      await this.trackChange({
        action: 'rollback',
        resource: 'configuration',
        oldValue: backup.configuration,
        newValue: rollbackPlan.targetConfiguration,
        reason,
        metadata: {
          rollbackFrom: backup.id,
          rollbackTo: targetVersion
        }
      });
      
      return {
        success: true,
        fromVersion: backup.id,
        toVersion: targetVersion,
        changesApplied: rollbackPlan.steps.length
      };
      
    } catch (error) {
      // ë¡¤ë°± ì‹¤íŒ¨ ì‹œ ë³µêµ¬
      await this.restoreFromSnapshot(backup.id);
      throw error;
    }
  }
  
  // ì„¤ì • ë¹„êµ
  async compareVersions(
    version1: string,
    version2: string
  ): Promise<ConfigComparison> {
    const [config1, config2] = await Promise.all([
      this.versionControl.getVersion(version1),
      this.versionControl.getVersion(version2)
    ]);
    
    const differences = this.diffEngine.compare(
      config1.configuration,
      config2.configuration
    );
    
    return {
      version1: {
        id: version1,
        timestamp: config1.timestamp
      },
      version2: {
        id: version2,
        timestamp: config2.timestamp
      },
      differences,
      summary: this.summarizeDifferences(differences)
    };
  }
  
  // ë³€ê²½ ì´ë ¥ ì¡°íšŒ
  async getChangeHistory(
    options: HistoryOptions
  ): Promise<ChangeHistory> {
    const entries = await this.auditStore.query({
      environment: options.environment,
      startTime: options.startTime,
      endTime: options.endTime,
      user: options.user,
      resource: options.resource
    });
    
    return {
      entries: entries.map(entry => ({
        ...entry,
        diff: this.formatDiff(entry.changes)
      })),
      timeline: this.createTimeline(entries),
      statistics: this.calculateStatistics(entries)
    };
  }
  
  // ì»´í”Œë¼ì´ì–¸ìŠ¤ ë¦¬í¬íŠ¸
  async generateComplianceReport(
    period: TimePeriod
  ): Promise<ComplianceReport> {
    const changes = await this.getChangeHistory({
      startTime: period.start,
      endTime: period.end
    });
    
    const unauthorizedChanges = changes.entries.filter(
      entry => !entry.metadata.approvedBy
    );
    
    const sensitiveChanges = changes.entries.filter(
      entry => this.isSensitiveChange(entry)
    );
    
    return {
      period,
      totalChanges: changes.entries.length,
      unauthorizedChanges: unauthorizedChanges.length,
      sensitiveChanges: sensitiveChanges.length,
      changesByUser: this.groupByUser(changes.entries),
      changesByResource: this.groupByResource(changes.entries),
      complianceScore: this.calculateComplianceScore(changes),
      recommendations: this.generateRecommendations(changes)
    };
  }
}

// ì„¤ì • ë²„ì „ ì œì–´
export class ConfigVersionControl {
  private storage: VersionStorage;
  private compressor: Compressor;
  
  async createVersion(
    data: VersionData
  ): Promise<ConfigVersion> {
    const version: ConfigVersion = {
      id: this.generateVersionId(),
      timestamp: new Date(),
      configuration: data.config,
      compressed: await this.compressor.compress(data.config),
      checksum: this.calculateChecksum(data.config),
      auditId: data.auditId,
      tags: data.tags || [],
      size: JSON.stringify(data.config).length
    };
    
    await this.storage.save(version);
    
    // ì˜¤ë˜ëœ ë²„ì „ ì •ë¦¬
    await this.pruneOldVersions();
    
    return version;
  }
  
  async getVersion(versionId: string): Promise<ConfigVersion> {
    const version = await this.storage.get(versionId);
    
    if (!version) {
      throw new Error(`Version not found: ${versionId}`);
    }
    
    // ì••ì¶• í•´ì œ
    if (version.compressed) {
      version.configuration = await this.compressor.decompress(
        version.compressed
      );
    }
    
    // ì²´í¬ì„¬ ê²€ì¦
    const expectedChecksum = this.calculateChecksum(version.configuration);
    if (expectedChecksum !== version.checksum) {
      throw new Error('Version integrity check failed');
    }
    
    return version;
  }
  
  private generateVersionId(): string {
    const timestamp = Date.now().toString(36);
    const random = Math.random().toString(36).substring(2, 8);
    return `v${timestamp}-${random}`;
  }
}
```

## Task 1.18: ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë„êµ¬

### SubTask 1.18.1: ì—ì´ì „íŠ¸ ì„±ëŠ¥ ì¸¡ì •
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/benchmarks/agent-benchmark.ts
export class AgentBenchmark {
  private metrics: MetricsCollector;
  private profiler: Profiler;
  private loadGenerator: LoadGenerator;
  
  constructor() {
    this.metrics = new MetricsCollector();
    this.profiler = new Profiler();
    this.loadGenerator = new LoadGenerator();
  }
  
  // ì—ì´ì „íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
  async benchmarkAgent(
    agentType: string,
    config: BenchmarkConfig
  ): Promise<BenchmarkResult> {
    const agent = await this.createAgent(agentType);
    const results: PerformanceMetric[] = [];
    
    // ì›Œë°ì—…
    await this.warmup(agent, config.warmupIterations);
    
    // ë©”ì¸ ë²¤ì¹˜ë§ˆí¬
    for (let i = 0; i < config.iterations; i++) {
      const metric = await this.measureSingleExecution(
        agent,
        config.testData[i % config.testData.length]
      );
      
      results.push(metric);
      
      // ì¿¨ë‹¤ìš´
      if (config.cooldownMs) {
        await this.delay(config.cooldownMs);
      }
    }
    
    // ê²°ê³¼ ë¶„ì„
    return this.analyzeResults(results, config);
  }
  
  // ë‹¨ì¼ ì‹¤í–‰ ì¸¡ì •
  private async measureSingleExecution(
    agent: Agent,
    testData: any
  ): Promise<PerformanceMetric> {
    const startMemory = process.memoryUsage();
    const startCpu = process.cpuUsage();
    const startTime = performance.now();
    
    // í”„ë¡œíŒŒì¼ë§ ì‹œì‘
    this.profiler.start();
    
    try {
      // ì—ì´ì „íŠ¸ ì‹¤í–‰
      const result = await agent.execute(testData);
      
      // ì¸¡ì • ì¢…ë£Œ
      const endTime = performance.now();
      const endCpu = process.cpuUsage(startCpu);
      const endMemory = process.memoryUsage();
      
      const profile = this.profiler.stop();
      
      return {
        duration: endTime - startTime,
        cpu: {
          user: endCpu.user / 1000, // ë§ˆì´í¬ë¡œì´ˆ -> ë°€ë¦¬ì´ˆ
          system: endCpu.system / 1000
        },
        memory: {
          heapUsed: endMemory.heapUsed - startMemory.heapUsed,
          external: endMemory.external - startMemory.external,
          rss: endMemory.rss - startMemory.rss
        },
        profile,
        success: true,
        result
      };
      
    } catch (error) {
      return {
        duration: performance.now() - startTime,
        cpu: process.cpuUsage(startCpu),
        memory: process.memoryUsage(),
        profile: this.profiler.stop(),
        success: false,
        error: error.message
      };
    }
  }
  
  // ë¶€í•˜ í…ŒìŠ¤íŠ¸
  async loadTest(
    agentType: string,
    config: LoadTestConfig
  ): Promise<LoadTestResult> {
    const results: ConcurrencyResult[] = [];
    
    // ë™ì‹œì„± ë ˆë²¨ë³„ í…ŒìŠ¤íŠ¸
    for (const concurrency of config.concurrencyLevels) {
      const result = await this.testConcurrency(
        agentType,
        concurrency,
        config
      );
      
      results.push(result);
      
      // ë‹¤ìŒ ë ˆë²¨ ì „ íœ´ì‹
      await this.delay(5000);
    }
    
    return {
      results,
      maxThroughput: this.findMaxThroughput(results),
      optimalConcurrency: this.findOptimalConcurrency(results),
      bottlenecks: await this.identifyBottlenecks(results)
    };
  }
  
  // ë™ì‹œì„± í…ŒìŠ¤íŠ¸
  private async testConcurrency(
    agentType: string,
    concurrency: number,
    config: LoadTestConfig
  ): Promise<ConcurrencyResult> {
    const startTime = Date.now();
    const metrics: PerformanceMetric[] = [];
    const errors: Error[] = [];
    
    // ë¶€í•˜ ìƒì„±
    const load = await this.loadGenerator.generate({
      concurrency,
      duration: config.duration,
      rampUp: config.rampUp,
      targetRPS: config.targetRPS
    });
    
    // ìš”ì²­ ì‹¤í–‰
    const promises = load.requests.map(async (request) => {
      try {
        const metric = await this.measureSingleExecution(
          await this.createAgent(agentType),
          request.data
        );
        metrics.push(metric);
      } catch (error) {
        errors.push(error);
      }
    });
    
    await Promise.all(promises);
    
    const duration = Date.now() - startTime;
    
    return {
      concurrency,
      duration,
      requests: metrics.length,
      errors: errors.length,
      throughput: (metrics.length / duration) * 1000,
      latency: this.calculateLatencyStats(metrics),
      resourceUsage: this.calculateResourceStats(metrics)
    };
  }
  
  // ë¹„êµ ë²¤ì¹˜ë§ˆí¬
  async compareAgents(
    agentTypes: string[],
    config: BenchmarkConfig
  ): Promise<ComparisonResult> {
    const results: Map<string, BenchmarkResult> = new Map();
    
    // ê° ì—ì´ì „íŠ¸ ë²¤ì¹˜ë§ˆí¬
    for (const agentType of agentTypes) {
      const result = await this.benchmarkAgent(agentType, config);
      results.set(agentType, result);
    }
    
    // ë¹„êµ ë¶„ì„
    return {
      agents: Object.fromEntries(results),
      comparison: {
        fastest: this.findFastest(results),
        mostEfficient: this.findMostEfficient(results),
        mostScalable: this.findMostScalable(results)
      },
      recommendations: this.generateRecommendations(results)
    };
  }
  
  // ê²°ê³¼ ë¶„ì„
  private analyzeResults(
    metrics: PerformanceMetric[],
    config: BenchmarkConfig
  ): BenchmarkResult {
    const durations = metrics.map(m => m.duration);
    const successRate = metrics.filter(m => m.success).length / metrics.length;
    
    return {
      summary: {
        iterations: metrics.length,
        successRate,
        totalDuration: durations.reduce((a, b) => a + b, 0)
      },
      latency: {
        min: Math.min(...durations),
        max: Math.max(...durations),
        mean: this.mean(durations),
        median: this.median(durations),
        p95: this.percentile(durations, 0.95),
        p99: this.percentile(durations, 0.99),
        stdDev: this.standardDeviation(durations)
      },
      throughput: {
        rps: metrics.length / (this.sum(durations) / 1000),
        successfulRps: (metrics.filter(m => m.success).length) / 
                      (this.sum(durations) / 1000)
      },
      resources: {
        cpu: this.aggregateCPU(metrics),
        memory: this.aggregateMemory(metrics)
      },
      profile: this.aggregateProfiles(metrics.map(m => m.profile))
    };
  }
}

// ì„±ëŠ¥ í”„ë¡œíŒŒì¼ëŸ¬
export class Profiler {
  private samples: ProfileSample[] = [];
  private interval?: NodeJS.Timer;
  
  start(): void {
    this.samples = [];
    
    // CPU í”„ë¡œíŒŒì¼ë§
    this.interval = setInterval(() => {
      this.samples.push({
        timestamp: Date.now(),
        cpu: process.cpuUsage(),
        memory: process.memoryUsage(),
        eventLoop: this.measureEventLoop()
      });
    }, 10); // 10ms ê°„ê²©
  }
  
  stop(): Profile {
    if (this.interval) {
      clearInterval(this.interval);
    }
    
    return this.analyzeProfile(this.samples);
  }
  
  private analyzeProfile(samples: ProfileSample[]): Profile {
    const functionCalls = this.extractFunctionCalls();
    const hotspots = this.identifyHotspots(functionCalls);
    
    return {
      duration: samples[samples.length - 1].timestamp - samples[0].timestamp,
      samples: samples.length,
      hotspots,
      eventLoop: {
        avgDelay: this.mean(samples.map(s => s.eventLoop.delay)),
        maxDelay: Math.max(...samples.map(s => s.eventLoop.delay))
      },
      recommendations: this.generateOptimizations(hotspots)
    };
  }
}
```

### SubTask 1.18.2: ì‹œìŠ¤í…œ ë¶€í•˜ í…ŒìŠ¤íŠ¸
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ì‹œìŠ¤í…œ ì „ì²´ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ë„êµ¬ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/benchmarks/load-testing.ts
export class SystemLoadTester {
  private scenarios: Map<string, LoadScenario> = new Map();
  private monitors: SystemMonitor[] = [];
  private reporter: LoadTestReporter;
  
  constructor() {
    this.reporter = new LoadTestReporter();
    this.initializeMonitors();
    this.loadScenarios();
  }
  
  // ë¶€í•˜ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜
  defineScenario(scenario: LoadScenario): void {
    this.scenarios.set(scenario.name, scenario);
  }
  
  // ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
  async runLoadTest(
    scenarioName: string,
    options: LoadTestOptions
  ): Promise<LoadTestReport> {
    const scenario = this.scenarios.get(scenarioName);
    if (!scenario) {
      throw new Error(`Scenario not found: ${scenarioName}`);
    }
    
    // í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„
    await this.prepareEnvironment(options);
    
    // ëª¨ë‹ˆí„°ë§ ì‹œì‘
    this.startMonitoring();
    
    try {
      // ë¶€í•˜ ìƒì„±
      const results = await this.executeScenario(scenario, options);
      
      // ê²°ê³¼ ìˆ˜ì§‘
      const systemMetrics = await this.collectSystemMetrics();
      
      // ë¦¬í¬íŠ¸ ìƒì„±
      return this.reporter.generate({
        scenario,
        results,
        systemMetrics,
        duration: results.duration,
        timestamp: new Date()
      });
      
    } finally {
      // ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
      this.stopMonitoring();
      
      // í™˜ê²½ ì •ë¦¬
      await this.cleanupEnvironment();
    }
  }
  
  // ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
  private async executeScenario(
    scenario: LoadScenario,
    options: LoadTestOptions
  ): Promise<ScenarioResult> {
    const virtualUsers: VirtualUser[] = [];
    const results: RequestResult[] = [];
    const startTime = Date.now();
    
    // ê°€ìƒ ì‚¬ìš©ì ìƒì„±
    for (let i = 0; i < scenario.users; i++) {
      const user = new VirtualUser({
        id: i,
        scenario: scenario.userJourney,
        thinkTime: scenario.thinkTime
      });
      
      virtualUsers.push(user);
    }
    
    // ë¨í”„ì—…
    await this.rampUp(virtualUsers, scenario.rampUp);
    
    // ë©”ì¸ í…ŒìŠ¤íŠ¸
    const testPromises = virtualUsers.map(async (user) => {
      const userResults = await user.execute(options.duration);
      results.push(...userResults);
    });
    
    await Promise.all(testPromises);
    
    // ë¨í”„ë‹¤ìš´
    await this.rampDown(virtualUsers, scenario.rampDown);
    
    return {
      duration: Date.now() - startTime,
      totalRequests: results.length,
      successfulRequests: results.filter(r => r.success).length,
      failedRequests: results.filter(r => !r.success).length,
      results,
      throughput: this.calculateThroughput(results),
      latency: this.calculateLatencyDistribution(results),
      errors: this.categorizeErrors(results)
    };
  }
  
  // ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸
  async stressTest(
    config: StressTestConfig
  ): Promise<StressTestResult> {
    const results: StressPhaseResult[] = [];
    let breakingPoint: number | null = null;
    
    for (const phase of config.phases) {
      console.log(`Starting stress phase: ${phase.users} users`);
      
      const phaseResult = await this.runStressPhase(phase);
      results.push(phaseResult);
      
      // Breaking point í™•ì¸
      if (this.hasReachedBreakingPoint(phaseResult)) {
        breakingPoint = phase.users;
        break;
      }
      
      // ë‹¤ìŒ ë‹¨ê³„ ì „ ì•ˆì •í™”
      await this.stabilize(config.stabilizationTime);
    }
    
    return {
      phases: results,
      breakingPoint,
      maxCapacity: this.calculateMaxCapacity(results),
      bottlenecks: await this.identifyBottlenecks(results),
      recommendations: this.generateScalingRecommendations(results)
    };
  }
  
  // ìŠ¤íŒŒì´í¬ í…ŒìŠ¤íŠ¸
  async spikeTest(
    config: SpikeTestConfig
  ): Promise<SpikeTestResult> {
    const baselineLoad = config.baselineUsers;
    const spikeLoad = config.spikeUsers;
    
    // ë² ì´ìŠ¤ë¼ì¸ ì„¤ì •
    const baseline = await this.establishBaseline(baselineLoad);
    
    // ìŠ¤íŒŒì´í¬ ìƒì„±
    const spikeStart = Date.now();
    const spike = await this.generateSpike(spikeLoad, config.spikeDuration);
    
    // ë³µêµ¬ ëª¨ë‹ˆí„°ë§
    const recovery = await this.monitorRecovery(baselineLoad);
    
    return {
      baseline,
      spike: {
        ...spike,
        responseTime: Date.now() - spikeStart
      },
      recovery: {
        ...recovery,
        time: recovery.duration,
        successful: recovery.metrics.similar(baseline.metrics)
      },
      analysis: {
        handled: spike.successRate > config.acceptableSuccessRate,
        recoveryTime: recovery.duration,
        impact: this.calculateImpact(baseline, spike, recovery)
      }
    };
  }
  
  // ë‚´êµ¬ì„± í…ŒìŠ¤íŠ¸
  async enduranceTest(
    config: EnduranceTestConfig
  ): Promise<EnduranceTestResult> {
    const checkpoints: EnduranceCheckpoint[] = [];
    const issues: PerformanceIssue[] = [];
    
    const startTime = Date.now();
    let running = true;
    
    // ì¥ê¸° ì‹¤í–‰
    const testPromise = this.runContinuousLoad(config.load);
    
    // ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸
    const checkInterval = setInterval(async () => {
      const checkpoint = await this.captureCheckpoint();
      checkpoints.push(checkpoint);
      
      // ì„±ëŠ¥ ì €í•˜ ê°ì§€
      const degradation = this.detectDegradation(checkpoints);
      if (degradation) {
        issues.push(degradation);
      }
      
      // ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€
      const memoryLeak = this.detectMemoryLeak(checkpoints);
      if (memoryLeak) {
        issues.push(memoryLeak);
      }
      
      // ì¢…ë£Œ ì¡°ê±´ í™•ì¸
      if (Date.now() - startTime >= config.duration) {
        running = false;
        clearInterval(checkInterval);
      }
    }, config.checkpointInterval);
    
    await testPromise;
    
    return {
      duration: Date.now() - startTime,
      checkpoints,
      issues,
      stability: this.assessStability(checkpoints),
      memoryLeaks: issues.filter(i => i.type === 'memory_leak'),
      performanceDegradation: issues.filter(i => i.type === 'degradation')
    };
  }
}

// ê°€ìƒ ì‚¬ìš©ì
export class VirtualUser {
  private session: UserSession;
  private client: TestClient;
  
  constructor(private config: VirtualUserConfig) {
    this.session = new UserSession();
    this.client = new TestClient();
  }
  
  async execute(duration: number): Promise<RequestResult[]> {
    const results: RequestResult[] = [];
    const endTime = Date.now() + duration;
    
    while (Date.now() < endTime) {
      for (const action of this.config.scenario) {
        const result = await this.executeAction(action);
        results.push(result);
        
        // Think time
        if (this.config.thinkTime) {
          await this.delay(this.randomThinkTime());
        }
      }
    }
    
    return results;
  }
  
  private async executeAction(
    action: UserAction
  ): Promise<RequestResult> {
    const startTime = Date.now();
    
    try {
      const response = await this.client.request({
        method: action.method,
        url: action.url,
        headers: this.session.getHeaders(),
        body: this.prepareBody(action.body)
      });
      
      return {
        action: action.name,
        success: response.status < 400,
        duration: Date.now() - startTime,
        statusCode: response.status,
        size: response.data.length
      };
      
    } catch (error) {
      return {
        action: action.name,
        success: false,
        duration: Date.now() - startTime,
        error: error.message
      };
    }
  }
}
```

### SubTask 1.18.3: ë©”ëª¨ë¦¬ ë° ë¦¬ì†ŒìŠ¤ í”„ë¡œíŒŒì¼ë§
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ìƒì„¸í•œ ë©”ëª¨ë¦¬ ë° ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ë¶„ì„ ë„êµ¬

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/benchmarks/resource-profiling.ts
export class ResourceProfiler {
  private heapSnapshots: HeapSnapshot[] = [];
  private gcEvents: GCEvent[] = [];
  private resourceSamples: ResourceSample[] = [];
  
  constructor() {
    this.setupGCTracking();
    this.setupMemoryTracking();
  }
  
  // ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§
  async profileMemory(
    operation: () => Promise<void>,
    options?: ProfileOptions
  ): Promise<MemoryProfile> {
    // ì´ˆê¸° ìŠ¤ëƒ…ìƒ·
    const beforeSnapshot = await this.takeHeapSnapshot('before');
    const beforeMemory = process.memoryUsage();
    
    // GC ê°•ì œ ì‹¤í–‰
    if (global.gc) {
      global.gc();
    }
    
    // ì‘ì—… ì‹¤í–‰
    const startTime = Date.now();
    await operation();
    const duration = Date.now() - startTime;
    
    // ìµœì¢… ìŠ¤ëƒ…ìƒ·
    const afterSnapshot = await this.takeHeapSnapshot('after');
    const afterMemory = process.memoryUsage();
    
    // ë¶„ì„
    const analysis = await this.analyzeHeapDiff(
      beforeSnapshot,
      afterSnapshot
    );
    
    return {
      duration,
      memory: {
        before: beforeMemory,
        after: afterMemory,
        delta: {
          heapUsed: afterMemory.heapUsed - beforeMemory.heapUsed,
          external: afterMemory.external - beforeMemory.external,
          arrayBuffers: afterMemory.arrayBuffers - beforeMemory.arrayBuffers
        }
      },
      heap: analysis,
      gcEvents: this.gcEvents.filter(
        e => e.timestamp >= startTime && e.timestamp <= startTime + duration
      ),
      leaks: await this.detectMemoryLeaks(analysis)
    };
  }
  
  // í™ ìŠ¤ëƒ…ìƒ· ë¶„ì„
  private async analyzeHeapDiff(
    before: HeapSnapshot,
    after: HeapSnapshot
  ): Promise<HeapAnalysis> {
    const diff = await this.compareSnapshots(before, after);
    
    return {
      totalSizeDelta: after.totalSize - before.totalSize,
      objectCountDelta: after.objectCount - before.objectCount,
      largestGrowth: this.findLargestGrowth(diff),
      retainedObjects: this.findRetainedObjects(diff),
      suspiciousPatterns: this.detectSuspiciousPatterns(diff),
      constructors: this.analyzeConstructors(diff)
    };
  }
  
  // ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€
  async detectMemoryLeaks(
    analysis: HeapAnalysis
  ): Promise<MemoryLeak[]> {
    const leaks: MemoryLeak[] = [];
    
    // ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê°ì²´
    for (const constructor of analysis.constructors) {
      if (this.isLeakPattern(constructor)) {
        leaks.push({
          type: 'growing_objects',
          constructor: constructor.name,
          instances: constructor.count,
          retainedSize: constructor.retainedSize,
          severity: this.calculateLeakSeverity(constructor)
        });
      }
    }
    
    // ìˆœí™˜ ì°¸ì¡°
    const circularRefs = await this.findCircularReferences(analysis);
    leaks.push(...circularRefs.map(ref => ({
      type: 'circular_reference',
      path: ref.path,
      retainedSize: ref.size,
      severity: 'medium'
    })));
    
    // ë¶„ë¦¬ëœ DOM ë…¸ë“œ
    const detachedNodes = this.findDetachedDOMNodes(analysis);
    if (detachedNodes.length > 0) {
      leaks.push({
        type: 'detached_dom',
        count: detachedNodes.length,
        retainedSize: detachedNodes.reduce((sum, n) => sum + n.size, 0),
        severity: 'high'
      });
    }
    
    return leaks;
  }
  
  // CPU í”„ë¡œíŒŒì¼ë§
  async profileCPU(
    operation: () => Promise<void>,
    duration: number
  ): Promise<CPUProfile> {
    const profiler = new CpuProfiler();
    
    // í”„ë¡œíŒŒì¼ë§ ì‹œì‘
    profiler.startProfiling('cpu-profile');
    
    // ìƒ˜í”Œë§
    const samples: CPUSample[] = [];
    const sampleInterval = setInterval(() => {
      samples.push({
        timestamp: Date.now(),
        usage: process.cpuUsage(),
        activeHandles: process._getActiveHandles().length,
        activeRequests: process._getActiveRequests().length
      });
    }, 100);
    
    // ì‘ì—… ì‹¤í–‰
    await operation();
    
    // í”„ë¡œíŒŒì¼ë§ ì¤‘ì§€
    clearInterval(sampleInterval);
    const profile = profiler.stopProfiling('cpu-profile');
    
    return {
      profile: profile.serialize(),
      samples,
      analysis: {
        hotFunctions: this.identifyHotFunctions(profile),
        callTree: this.buildCallTree(profile),
        timeSpent: this.calculateTimeSpent(profile)
      }
    };
  }
  
  // ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ì¶”ì 
  async trackResourceUsage(
    operation: () => Promise<void>
  ): Promise<ResourceUsageReport> {
    const tracker = new ResourceTracker();
    
    tracker.start();
    
    try {
      await operation();
    } finally {
      tracker.stop();
    }
    
    const usage = tracker.getUsage();
    
    return {
      cpu: {
        user: usage.cpu.user,
        system: usage.cpu.system,
        percent: usage.cpu.percent
      },
      memory: {
        peak: usage.memory.peak,
        average: usage.memory.average,
        allocations: usage.memory.allocations
      },
      io: {
        reads: usage.io.reads,
        writes: usage.io.writes,
        bytesRead: usage.io.bytesRead,
        bytesWritten: usage.io.bytesWritten
      },
      network: {
        sent: usage.network.sent,
        received: usage.network.received,
        connections: usage.network.connections
      },
      handles: {
        files: usage.handles.files,
        sockets: usage.handles.sockets,
        timers: usage.handles.timers
      }
    };
  }
  
  // ë³‘ëª© ì§€ì  ì‹ë³„
  async identifyBottlenecks(): Promise<Bottleneck[]> {
    const bottlenecks: Bottleneck[] = [];
    
    // CPU ë³‘ëª©
    const cpuBottlenecks = await this.findCPUBottlenecks();
    bottlenecks.push(...cpuBottlenecks);
    
    // ë©”ëª¨ë¦¬ ë³‘ëª©
    const memoryBottlenecks = await this.findMemoryBottlenecks();
    bottlenecks.push(...memoryBottlenecks);
    
    // I/O ë³‘ëª©
    const ioBottlenecks = await this.findIOBottlenecks();
    bottlenecks.push(...ioBottlenecks);
    
    // ì´ë²¤íŠ¸ ë£¨í”„ ë³‘ëª©
    const eventLoopBottlenecks = await this.findEventLoopBottlenecks();
    bottlenecks.push(...eventLoopBottlenecks);
    
    return bottlenecks.sort((a, b) => b.impact - a.impact);
  }
}

// ë¦¬ì†ŒìŠ¤ ì¶”ì ê¸°
class ResourceTracker {
  private samples: ResourceSample[] = [];
  private interval?: NodeJS.Timer;
  private startTime?: number;
  private handles: HandleTracker;
  
  constructor() {
    this.handles = new HandleTracker();
  }
  
  start(): void {
    this.startTime = Date.now();
    this.samples = [];
    
    // ì´ˆê¸° ìƒíƒœ ê¸°ë¡
    this.recordSample();
    
    // ì£¼ê¸°ì  ìƒ˜í”Œë§
    this.interval = setInterval(() => {
      this.recordSample();
    }, 50); // 50ms ê°„ê²©
  }
  
  stop(): void {
    if (this.interval) {
      clearInterval(this.interval);
    }
    
    // ìµœì¢… ìƒ˜í”Œ
    this.recordSample();
  }
  
  private recordSample(): void {
    const memory = process.memoryUsage();
    const cpu = process.cpuUsage();
    
    this.samples.push({
      timestamp: Date.now(),
      cpu,
      memory,
      handles: this.handles.count(),
      eventLoop: this.measureEventLoopLag()
    });
  }
  
  getUsage(): ResourceUsage {
    return {
      duration: Date.now() - this.startTime!,
      samples: this.samples,
      cpu: this.aggregateCPU(),
      memory: this.aggregateMemory(),
      io: this.aggregateIO(),
      network: this.aggregateNetwork(),
      handles: this.aggregateHandles()
    };
  }
}
```

### SubTask 1.18.4: ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŒ…
**ë‹´ë‹¹ì**: ë°ì´í„° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 6ì‹œê°„

**ëª©í‘œ**: ì¢…í•©ì ì¸ ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/benchmarks/benchmark-reporter.ts
export class BenchmarkReporter {
  private visualizer: DataVisualizer;
  private analyzer: ResultAnalyzer;
  private formatter: ReportFormatter;
  
  constructor() {
    this.visualizer = new DataVisualizer();
    this.analyzer = new ResultAnalyzer();
    this.formatter = new ReportFormatter();
  }
  
  // ì¢…í•© ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ ìƒì„±
  async generateReport(
    results: BenchmarkResults,
    options: ReportOptions
  ): Promise<BenchmarkReport> {
    // ë°ì´í„° ë¶„ì„
    const analysis = await this.analyzer.analyze(results);
    
    // ì‹œê°í™” ìƒì„±
    const visualizations = await this.createVisualizations(results, analysis);
    
    // ë¦¬í¬íŠ¸ êµ¬ì„±
    const report: BenchmarkReport = {
      metadata: {
        timestamp: new Date(),
        environment: await this.getEnvironmentInfo(),
        configuration: results.config,
        duration: results.duration
      },
      summary: this.generateSummary(analysis),
      performance: {
        latency: analysis.latency,
        throughput: analysis.throughput,
        concurrency: analysis.concurrency,
        scalability: analysis.scalability
      },
      resources: {
        cpu: analysis.cpu,
        memory: analysis.memory,
        io: analysis.io,
        network: analysis.network
      },
      comparisons: await this.generateComparisons(results),
      bottlenecks: analysis.bottlenecks,
      recommendations: await this.generateRecommendations(analysis),
      visualizations,
      raw_data: options.includeRawData ? results : undefined
    };
    
    // í¬ë§·íŒ…
    return this.formatReport(report, options.format);
  }
  
  // ì‹œê°í™” ìƒì„±
  private async createVisualizations(
    results: BenchmarkResults,
    analysis: Analysis
  ): Promise<Visualizations> {
    return {
      latencyDistribution: await this.visualizer.createLatencyHistogram(
        results.latencies
      ),
      throughputTimeline: await this.visualizer.createThroughputChart(
        results.throughput
      ),
      resourceUsage: await this.visualizer.createResourceChart({
        cpu: analysis.cpu.timeline,
        memory: analysis.memory.timeline
      }),
      comparisonMatrix: await this.visualizer.createComparisonMatrix(
        analysis.comparisons
      ),
      performanceHeatmap: await this.visualizer.createHeatmap(
        analysis.performance
      )
    };
  }
  
  // ì‹¤í–‰ ìš”ì•½ ìƒì„±
  private generateSummary(analysis: Analysis): BenchmarkSummary {
    return {
      overview: this.createOverview(analysis),
      keyFindings: this.extractKeyFindings(analysis),
      performance: {
        grade: this.calculatePerformanceGrade(analysis),
        score: this.calculatePerformanceScore(analysis),
        percentile: this.calculatePercentile(analysis)
      },
      issues: this.identifyIssues(analysis),
      improvements: this.suggestImprovements(analysis)
    };
  }
  
  // ë¹„êµ ë¶„ì„
  private async generateComparisons(
    results: BenchmarkResults
  ): Promise<Comparison[]> {
    const comparisons: Comparison[] = [];
    
    // ì´ì „ ê²°ê³¼ì™€ ë¹„êµ
    if (results.baseline) {
      comparisons.push({
        type: 'baseline',
        name: 'vs Baseline',
        metrics: this.compareMetrics(results.current, results.baseline),
        improvement: this.calculateImprovement(
          results.current,
          results.baseline
        )
      });
    }
    
    // ëª©í‘œì™€ ë¹„êµ
    if (results.targets) {
      comparisons.push({
        type: 'target',
        name: 'vs Targets',
        metrics: this.compareToTargets(results.current, results.targets),
        achievement: this.calculateAchievement(
          results.current,
          results.targets
        )
      });
    }
    
    // ì—…ê³„ í‘œì¤€ê³¼ ë¹„êµ
    const industryBenchmarks = await this.getIndustryBenchmarks();
    comparisons.push({
      type: 'industry',
      name: 'vs Industry Standards',
      metrics: this.compareToIndustry(results.current, industryBenchmarks),
      percentile: this.calculateIndustryPercentile(results.current)
    });
    
    return comparisons;
  }
  
  // ê¶Œì¥ì‚¬í•­ ìƒì„±
  private async generateRecommendations(
    analysis: Analysis
  ): Promise<Recommendation[]> {
    const recommendations: Recommendation[] = [];
    
    // ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­
    if (analysis.latency.p95 > 1000) {
      recommendations.push({
        category: 'performance',
        priority: 'high',
        title: 'High Latency Detected',
        description: 'P95 latency exceeds 1 second',
        actions: [
          'Profile slow operations',
          'Implement caching',
          'Optimize database queries'
        ],
        impact: 'Could reduce latency by 40-60%'
      });
    }
    
    // í™•ì¥ì„± ê¶Œì¥ì‚¬í•­
    if (analysis.scalability.degradation > 0.2) {
      recommendations.push({
        category: 'scalability',
        priority: 'medium',
        title: 'Scalability Issues',
        description: 'Performance degrades significantly under load',
        actions: [
          'Implement connection pooling',
          'Add horizontal scaling',
          'Optimize concurrent operations'
        ],
        impact: 'Could improve throughput by 30-50%'
      });
    }
    
    // ë¦¬ì†ŒìŠ¤ ìµœì í™” ê¶Œì¥ì‚¬í•­
    if (analysis.memory.leaks.length > 0) {
      recommendations.push({
        category: 'resources',
        priority: 'high',
        title: 'Memory Leaks Detected',
        description: `Found ${analysis.memory.leaks.length} potential memory leaks`,
        actions: [
          'Fix identified memory leaks',
          'Implement proper cleanup',
          'Add memory monitoring'
        ],
        impact: 'Could reduce memory usage by 20-40%'
      });
    }
    
    return recommendations;
  }
  
  // ë¦¬í¬íŠ¸ í¬ë§·íŒ…
  private async formatReport(
    report: BenchmarkReport,
    format: ReportFormat
  ): Promise<any> {
    switch (format) {
      case 'html':
        return this.formatter.toHTML(report);
        
      case 'pdf':
        return await this.formatter.toPDF(report);
        
      case 'json':
        return this.formatter.toJSON(report);
        
      case 'markdown':
        return this.formatter.toMarkdown(report);
        
      case 'csv':
        return this.formatter.toCSV(report);
        
      default:
        return report;
    }
  }
}

// ë²¤ì¹˜ë§ˆí¬ ëŒ€ì‹œë³´ë“œ
export class BenchmarkDashboard {
  async render(results: BenchmarkResults[]): Promise<DashboardView> {
    const trends = this.analyzeTrends(results);
    const current = results[results.length - 1];
    
    return {
      currentPerformance: {
        latency: current.latency,
        throughput: current.throughput,
        errorRate: current.errorRate
      },
      trends: {
        latency: trends.latency,
        throughput: trends.throughput,
        resources: trends.resources
      },
      alerts: this.generateAlerts(current, trends),
      history: this.formatHistory(results),
      recommendations: await this.generateDashboardRecommendations(
        current,
        trends
      )
    };
  }
}
```

## Task 1.19: í†µí•© í…ŒìŠ¤íŠ¸ í™˜ê²½

### SubTask 1.19.1: E2E í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬
**ë‹´ë‹¹ì**: QA ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: í¬ê´„ì ì¸ End-to-End í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/testing/e2e-framework.ts
export class E2ETestFramework {
  private testSuites: Map<string, TestSuite> = new Map();
  private testEnvironment: TestEnvironment;
  private testRunner: TestRunner;
  private reporter: TestReporter;
  
  constructor(config: E2EConfig) {
    this.testEnvironment = new TestEnvironment(config);
    this.testRunner = new TestRunner();
    this.reporter = new TestReporter();
  }
  
  // í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì •ì˜
  defineSuite(name: string, suite: TestSuite): void {
    this.testSuites.set(name, suite);
  }
  
  // E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰
  async runTests(options?: TestOptions): Promise<TestResults> {
    // í™˜ê²½ ì¤€ë¹„
    await this.testEnvironment.setup();
    
    const results: TestResult[] = [];
    const startTime = Date.now();
    
    try {
      // í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰
      for (const [name, suite] of this.testSuites) {
        if (options?.suites && !options.suites.includes(name)) {
          continue;
        }
        
        const suiteResult = await this.runSuite(suite, options);
        results.push(...suiteResult.tests);
      }
      
      // ê²°ê³¼ ì§‘ê³„
      const summary = this.summarizeResults(results);
      
      // ë¦¬í¬íŠ¸ ìƒì„±
      const report = await this.reporter.generate({
        results,
        summary,
        duration: Date.now() - startTime,
        environment: await this.testEnvironment.getInfo()
      });
      
      return {
        success: summary.failed === 0,
        summary,
        report,
        results: options?.verbose ? results : undefined
      };
      
    } finally {
      // í™˜ê²½ ì •ë¦¬
      await this.testEnvironment.teardown();
    }
  }
  
  // ì—ì´ì „íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸
  async testAgentIntegration(
    agentType: string,
    scenarios: IntegrationScenario[]
  ): Promise<IntegrationTestResult> {
    const agent = await this.createTestAgent(agentType);
    const results: ScenarioResult[] = [];
    
    for (const scenario of scenarios) {
      const result = await this.runIntegrationScenario(
        agent,
        scenario
      );
      
      results.push(result);
    }
    
    return {
      agent: agentType,
      scenarios: results,
      coverage: await this.calculateIntegrationCoverage(results),
      issues: this.identifyIntegrationIssues(results)
    };
  }
  
  // ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í…ŒìŠ¤íŠ¸
  private async runIntegrationScenario(
    agent: Agent,
    scenario: IntegrationScenario
  ): Promise<ScenarioResult> {
    const context = new TestContext();
    const steps: StepResult[] = [];
    
    // ì‚¬ì „ ì¡°ê±´ ì„¤ì •
    await this.setupPreconditions(scenario.preconditions, context);
    
    // ì‹œë‚˜ë¦¬ì˜¤ ë‹¨ê³„ ì‹¤í–‰
    for (const step of scenario.steps) {
      const stepResult = await this.executeStep(
        agent,
        step,
        context
      );
      
      steps.push(stepResult);
      
      if (!stepResult.success && step.critical) {
        break;
      }
    }
    
    // ì‚¬í›„ ì¡°ê±´ ê²€ì¦
    const postconditions = await this.verifyPostconditions(
      scenario.postconditions,
      context
    );
    
    return {
      scenario: scenario.name,
      success: steps.every(s => s.success) && postconditions.valid,
      steps,
      postconditions,
      duration: steps.reduce((sum, s) => sum + s.duration, 0)
    };
  }
  
  // API í†µí•© í…ŒìŠ¤íŠ¸
  async testAPIIntegration(): Promise<APITestResult> {
    const apiTester = new APITester({
      baseURL: process.env.API_BASE_URL,
      timeout: 30000
    });
    
    const endpoints = await this.discoverEndpoints();
    const results: EndpointTestResult[] = [];
    
    for (const endpoint of endpoints) {
      // ì •ìƒ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
      const normalCases = await apiTester.testNormalCases(endpoint);
      
      // ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
      const edgeCases = await apiTester.testEdgeCases(endpoint);
      
      // ì—ëŸ¬ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
      const errorCases = await apiTester.testErrorCases(endpoint);
      
      // ë³´ì•ˆ í…ŒìŠ¤íŠ¸
      const securityTests = await apiTester.testSecurity(endpoint);
      
      results.push({
        endpoint,
        normalCases,
        edgeCases,
        errorCases,
        securityTests,
        performance: await apiTester.testPerformance(endpoint)
      });
    }
    
    return {
      endpoints: results,
      coverage: this.calculateAPICoverage(results),
      issues: this.identifyAPIIssues(results),
      documentation: await this.validateAPIDocumentation(endpoints)
    };
  }
  
  // ë°ì´í„° ì¼ê´€ì„± í…ŒìŠ¤íŠ¸
  async testDataConsistency(): Promise<ConsistencyTestResult> {
    const consistencyChecker = new DataConsistencyChecker();
    
    // íŠ¸ëœì­ì…˜ ì¼ê´€ì„±
    const transactionTests = await consistencyChecker.testTransactions({
      scenarios: [
        'concurrent_updates',
        'rollback_handling',
        'distributed_transactions'
      ]
    });
    
    // ìºì‹œ ì¼ê´€ì„±
    const cacheTests = await consistencyChecker.testCache({
      scenarios: [
        'cache_invalidation',
        'cache_synchronization',
        'stale_data_handling'
      ]
    });
    
    // ì´ë²¤íŠ¸ ì¼ê´€ì„±
    const eventTests = await consistencyChecker.testEvents({
      scenarios: [
        'event_ordering',
        'event_delivery',
        'event_replay'
      ]
    });
    
    return {
      transactions: transactionTests,
      cache: cacheTests,
      events: eventTests,
      overall: this.assessOverallConsistency([
        transactionTests,
        cacheTests,
        eventTests
      ])
    };
  }
}

// í…ŒìŠ¤íŠ¸ í™˜ê²½ ê´€ë¦¬
export class TestEnvironment {
  private services: Map<string, TestService> = new Map();
  private data: TestDataManager;
  
  constructor(private config: E2EConfig) {
    this.data = new TestDataManager();
  }
  
  async setup(): Promise<void> {
    // í…ŒìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„
    await this.setupTestDatabase();
    
    // í…ŒìŠ¤íŠ¸ ì„œë¹„ìŠ¤ ì‹œì‘
    await this.startTestServices();
    
    // ì´ˆê¸° ë°ì´í„° ì‹œë”©
    await this.seedTestData();
    
    // ëª¨ì˜ ì„œë¹„ìŠ¤ ì„¤ì •
    await this.setupMocks();
  }
  
  private async setupTestDatabase(): Promise<void> {
    // í…ŒìŠ¤íŠ¸ DB ìƒì„±
    await this.createTestDB();
    
    // ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜
    await this.runMigrations();
    
    // ì¸ë±ìŠ¤ ìƒì„±
    await this.createIndexes();
  }
  
  private async startTestServices(): Promise<void> {
    // API ì„œë²„
    this.services.set('api', await this.startAPIServer());
    
    // ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤
    this.services.set('agents', await this.startAgentService());
    
    // ë©”ì‹œì§• ì„œë¹„ìŠ¤
    this.services.set('messaging', await this.startMessagingService());
    
    // ìºì‹œ ì„œë¹„ìŠ¤
    this.services.set('cache', await this.startCacheService());
  }
}

// í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬
export class TestDataManager {
  private fixtures: Map<string, any> = new Map();
  private generators: Map<string, DataGenerator> = new Map();
  
  async seed(type: string, count: number): Promise<any[]> {
    const generator = this.generators.get(type);
    if (!generator) {
      throw new Error(`No generator for type: ${type}`);
    }
    
    const data = [];
    for (let i = 0; i < count; i++) {
      data.push(await generator.generate());
    }
    
    return data;
  }
  
  async cleanup(): Promise<void> {
    // í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬
    await this.truncateTables();
    
    // ìºì‹œ í´ë¦¬ì–´
    await this.clearCache();
    
    // íŒŒì¼ ì •ë¦¬
    await this.cleanupFiles();
  }
}
```

### SubTask 1.19.2: ëª¨ì˜ ì„œë¹„ìŠ¤ ë° ìŠ¤í…
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: í…ŒìŠ¤íŠ¸ìš© ëª¨ì˜ ì„œë¹„ìŠ¤ ë° ìŠ¤í… ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/testing/mock-services.ts
export class MockServiceManager {
  private mocks: Map<string, MockService> = new Map();
  private stubs: Map<string, Stub> = new Map();
  private recordings: Map<string, Recording> = new Map();
  
  // ëª¨ì˜ ì„œë¹„ìŠ¤ ìƒì„±
  createMock<T>(
    serviceName: string,
    implementation: Partial<T>
  ): MockService<T> {
    const mock = new MockService<T>(serviceName, implementation);
    this.mocks.set(serviceName, mock);
    
    return mock;
  }
  
  // LLM ëª¨ì˜ ì„œë¹„ìŠ¤
  createLLMMock(): MockLLMService {
    return new MockLLMService({
      responses: {
        'gpt-4': {
          default: {
            choices: [{
              message: {
                content: 'Mock GPT-4 response',
                role: 'assistant'
              }
            }],
            usage: {
              prompt_tokens: 10,
              completion_tokens: 20,
              total_tokens: 30
            }
          }
        },
        'claude-3': {
          default: {
            content: 'Mock Claude response',
            usage: {
              input_tokens: 15,
              output_tokens: 25
            }
          }
        }
      },
      latency: {
        min: 100,
        max: 500
      }
    });
  }
  
  // AWS ì„œë¹„ìŠ¤ ëª¨ì˜
  createAWSMocks(): AWSMocks {
    return {
      dynamodb: this.createDynamoDBMock(),
      s3: this.createS3Mock(),
      sqs: this.createSQSMock(),
      eventbridge: this.createEventBridgeMock(),
      bedrock: this.createBedrockMock()
    };
  }
  
  private createDynamoDBMock(): MockDynamoDB {
    const tables = new Map<string, Map<string, any>>();
    
    return {
      getItem: jest.fn(async (params) => {
        const table = tables.get(params.TableName);
        if (!table) return { Item: null };
        
        const key = JSON.stringify(params.Key);
        return { Item: table.get(key) };
      }),
      
      putItem: jest.fn(async (params) => {
        let table = tables.get(params.TableName);
        if (!table) {
          table = new Map();
          tables.set(params.TableName, table);
        }
        
        const key = JSON.stringify(params.Key);
        table.set(key, params.Item);
        
        return {};
      }),
      
      query: jest.fn(async (params) => {
        const table = tables.get(params.TableName);
        if (!table) return { Items: [] };
        
        // ê°„ë‹¨í•œ ì¿¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        const items = Array.from(table.values()).filter(item => {
          // í‚¤ ì¡°ê±´ í‰ê°€
          return true; // ì‹¤ì œ êµ¬í˜„ í•„ìš”
        });
        
        return { Items: items };
      })
    };
  }
  
  // ìŠ¤í… ìƒì„±
  createStub<T>(
    target: T,
    method: keyof T
  ): Stub<T> {
    const stub = new Stub(target, method);
    this.stubs.set(`${target.constructor.name}.${String(method)}`, stub);
    
    return stub;
  }
  
  // ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ëª¨í‚¹
  async mockHTTPRequests(): Promise<void> {
    nock.disableNetConnect();
    nock.enableNetConnect('localhost');
    
    // ì™¸ë¶€ API ëª¨í‚¹
    nock('https://api.openai.com')
      .post('/v1/chat/completions')
      .reply(200, this.getOpenAIResponse());
    
    nock('https://api.anthropic.com')
      .post('/v1/messages')
      .reply(200, this.getAnthropicResponse());
    
    // ì›¹í›… ëª¨í‚¹
    nock('https://webhook.site')
      .post(/.*/)
      .reply(200, { success: true });
  }
  
  // ë ˆì½”ë”© ë° ì¬ìƒ
  async startRecording(name: string): Promise<void> {
    const recording = new Recording(name);
    this.recordings.set(name, recording);
    
    // ëª¨ë“  ì™¸ë¶€ í˜¸ì¶œ ê¸°ë¡
    recording.intercept({
      http: true,
      database: true,
      cache: true,
      messaging: true
    });
  }
  
  async stopRecording(name: string): Promise<RecordingData> {
    const recording = this.recordings.get(name);
    if (!recording) {
      throw new Error(`Recording not found: ${name}`);
    }
    
    const data = recording.stop();
    this.recordings.delete(name);
    
    // ë ˆì½”ë”© ë°ì´í„° ì €ì¥
    await this.saveRecording(name, data);
    
    return data;
  }
  
  async replay(recordingName: string): Promise<void> {
    const data = await this.loadRecording(recordingName);
    
    // HTTP ìš”ì²­ ì¬ìƒ
    for (const request of data.httpRequests) {
      nock(request.host)
        .intercept(request.path, request.method)
        .reply(request.response.status, request.response.body);
    }
    
    // DB ì¿¼ë¦¬ ì¬ìƒ
    for (const query of data.dbQueries) {
      this.mocks.get('database')?.when(query.method)
        .withArgs(query.args)
        .returns(query.result);
    }
  }
}

// ëª¨ì˜ LLM ì„œë¹„ìŠ¤
export class MockLLMService {
  private responses: Map<string, any> = new Map();
  private callHistory: LLMCall[] = [];
  
  constructor(private config: MockLLMConfig) {
    this.setupDefaultResponses();
  }
  
  async complete(params: CompletionParams): Promise<CompletionResponse> {
    // í˜¸ì¶œ ê¸°ë¡
    this.callHistory.push({
      timestamp: Date.now(),
      model: params.model,
      messages: params.messages,
      parameters: params
    });
    
    // ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
    await this.simulateLatency();
    
    // ì‘ë‹µ ë°˜í™˜
    const response = this.getResponse(params);
    
    // í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚°
    const usage = this.calculateUsage(params, response);
    
    return {
      ...response,
      usage,
      model: params.model,
      created: Date.now()
    };
  }
  
  // íŠ¹ì • ì‘ë‹µ ì„¤ì •
  whenCalled(matcher: CallMatcher): ResponseBuilder {
    return {
      thenReturn: (response: any) => {
        this.responses.set(
          this.matcherToKey(matcher),
          response
        );
      },
      thenThrow: (error: Error) => {
        this.responses.set(
          this.matcherToKey(matcher),
          { error }
        );
      }
    };
  }
  
  // í˜¸ì¶œ ê²€ì¦
  verify(): CallVerifier {
    return {
      called: (times?: number) => {
        if (times !== undefined) {
          expect(this.callHistory.length).toBe(times);
        } else {
          expect(this.callHistory.length).toBeGreaterThan(0);
        }
      },
      
      calledWith: (expectedParams: Partial<CompletionParams>) => {
        const matching = this.callHistory.find(call =>
          this.paramsMatch(call.parameters, expectedParams)
        );
        
        expect(matching).toBeDefined();
      },
      
      notCalled: () => {
        expect(this.callHistory.length).toBe(0);
      }
    };
  }
  
  getCallHistory(): LLMCall[] {
    return [...this.callHistory];
  }
  
  reset(): void {
    this.callHistory = [];
    this.responses.clear();
    this.setupDefaultResponses();
  }
}

// í…ŒìŠ¤íŠ¸ ë”ë¸” íŒ©í† ë¦¬
export class TestDoubleFactory {
  // ìŠ¤íŒŒì´ ìƒì„±
  createSpy<T>(target: T): SpyObject<T> {
    const spy = {} as SpyObject<T>;
    
    Object.getOwnPropertyNames(target).forEach(prop => {
      if (typeof target[prop] === 'function') {
        spy[prop] = jest.fn(target[prop]);
      }
    });
    
    return spy;
  }
  
  // í˜ì´í¬ ê°ì²´ ìƒì„±
  createFake<T>(
    interfaceName: string,
    implementation: Partial<T>
  ): T {
    const handler: ProxyHandler<Partial<T>> = {
      get(target, prop) {
        if (prop in target) {
          return target[prop];
        }
        
        // ë©”ì„œë“œ ìë™ ìƒì„±
        if (typeof prop === 'string') {
          return jest.fn().mockImplementation(() => {
            throw new Error(
              `Method ${prop} not implemented in fake ${interfaceName}`
            );
          });
        }
      }
    };
    
    return new Proxy(implementation, handler) as T;
  }
  
  // ë”ë¯¸ ë°ì´í„° ìƒì„±
  createDummy(type: string): any {
    switch (type) {
      case 'user':
        return {
          id: faker.datatype.uuid(),
          email: faker.internet.email(),
          name: faker.name.fullName()
        };
        
      case 'project':
        return {
          id: faker.datatype.uuid(),
          name: faker.company.name(),
          description: faker.lorem.paragraph()
        };
        
      case 'agent':
        return {
          id: faker.datatype.uuid(),
          type: faker.helpers.arrayElement(['code', 'test', 'review']),
          status: 'ready'
        };
        
      default:
        return {};
    }
  }
}
```

### SubTask 1.19.3: í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬
**ë‹´ë‹¹ì**: ë°ì´í„° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: íš¨ìœ¨ì ì¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ë° ê´€ë¦¬ ì‹œìŠ¤í…œ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/testing/test-data-manager.ts
export class TestDataFactory {
  private builders: Map<string, DataBuilder> = new Map();
  private sequences: Map<string, number> = new Map();
  private faker: Faker;
  
  constructor() {
    this.faker = faker;
    this.registerDefaultBuilders();
  }
  
  // ë°ì´í„° ë¹Œë” ë“±ë¡
  register<T>(name: string, builder: DataBuilder<T>): void {
    this.builders.set(name, builder);
  }
  
  // íŒ©í† ë¦¬ ë©”ì„œë“œ
  async create<T>(
    type: string,
    overrides?: Partial<T>
  ): Promise<T> {
    const builder = this.builders.get(type);
    if (!builder) {
      throw new Error(`No builder registered for type: ${type}`);
    }
    
    const sequence = this.getNextSequence(type);
    const data = await builder.build({
      sequence,
      faker: this.faker,
      factory: this
    });
    
    return { ...data, ...overrides };
  }
  
  // ë°°ì¹˜ ìƒì„±
  async createBatch<T>(
    type: string,
    count: number,
    overrides?: Partial<T>[]
  ): Promise<T[]> {
    const items: T[] = [];
    
    for (let i = 0; i < count; i++) {
      const item = await this.create(
        type,
        overrides?.[i]
      );
      items.push(item);
    }
    
    return items;
  }
  
  // ê´€ê³„í˜• ë°ì´í„° ìƒì„±
  async createWithRelations<T>(
    type: string,
    relations: RelationDefinition[]
  ): Promise<T> {
    const mainEntity = await this.create(type);
    
    for (const relation of relations) {
      if (relation.type === 'hasMany') {
        mainEntity[relation.field] = await this.createBatch(
          relation.target,
          relation.count || 3,
          relation.overrides
        );
      } else if (relation.type === 'hasOne') {
        mainEntity[relation.field] = await this.create(
          relation.target,
          relation.overrides
        );
      }
    }
    
    return mainEntity;
  }
  
  // ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ë°ì´í„° ìƒì„±
  async createScenario(
    scenarioName: string
  ): Promise<ScenarioData> {
    const scenario = this.scenarios.get(scenarioName);
    if (!scenario) {
      throw new Error(`Scenario not found: ${scenarioName}`);
    }
    
    const data: ScenarioData = {
      name: scenarioName,
      entities: {}
    };
    
    // ì‹œë‚˜ë¦¬ì˜¤ ë‹¨ê³„ë³„ ì‹¤í–‰
    for (const step of scenario.steps) {
      const entities = await this.executeStep(step, data);
      Object.assign(data.entities, entities);
    }
    
    return data;
  }
  
  // ê¸°ë³¸ ë¹Œë” ë“±ë¡
  private registerDefaultBuilders(): void {
    // ì‚¬ìš©ì ë¹Œë”
    this.register('user', {
      build: async ({ faker, sequence }) => ({
        id: `user-${sequence}`,
        email: faker.internet.email(),
        name: faker.name.fullName(),
        role: faker.helpers.arrayElement(['admin', 'user', 'guest']),
        createdAt: faker.date.past(),
        settings: {
          theme: faker.helpers.arrayElement(['light', 'dark']),
          notifications: faker.datatype.boolean()
        }
      })
    });
    
    // í”„ë¡œì íŠ¸ ë¹Œë”
    this.register('project', {
      build: async ({ faker, sequence, factory }) => ({
        id: `project-${sequence}`,
        name: faker.company.catchPhrase(),
        description: faker.lorem.paragraph(),
        type: faker.helpers.arrayElement(['web', 'mobile', 'desktop']),
        status: faker.helpers.arrayElement(['active', 'completed', 'archived']),
        owner: await factory.create('user'),
        technologies: faker.helpers.arrayElements([
          'React', 'Node.js', 'Python', 'AWS', 'Docker'
        ], 3),
        createdAt: faker.date.past()
      })
    });
    
    // ì—ì´ì „íŠ¸ ì‹¤í–‰ ë¹Œë”
    this.register('agentExecution', {
      build: async ({ faker, sequence }) => ({
        id: `execution-${sequence}`,
        agentType: faker.helpers.arrayElement([
          'CodeAgent', 'TestAgent', 'ReviewAgent'
        ]),
        status: faker.helpers.arrayElement([
          'pending', 'running', 'completed', 'failed'
        ]),
        input: {
          task: faker.lorem.sentence(),
          parameters: {}
        },
        output: faker.datatype.boolean() ? {
          result: faker.lorem.paragraph(),
          artifacts: []
        } : null,
        metrics: {
          duration: faker.datatype.number({ min: 100, max: 5000 }),
          tokensUsed: faker.datatype.number({ min: 100, max: 10000 }),
          cost: faker.datatype.float({ min: 0.01, max: 1.0 })
        },
        startedAt: faker.date.recent(),
        completedAt: faker.date.recent()
      })
    });
  }
}

// í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‹œë”
export class TestDataSeeder {
  private db: TestDatabase;
  private factory: TestDataFactory;
  
  constructor() {
    this.db = new TestDatabase();
    this.factory = new TestDataFactory();
  }
  
  // ê¸°ë³¸ ì‹œë“œ ë°ì´í„°
  async seedBasicData(): Promise<void> {
    // ì‹œìŠ¤í…œ ì‚¬ìš©ì
    await this.seedSystemUsers();
    
    // ê¸°ë³¸ í”„ë¡œì íŠ¸
    await this.seedSampleProjects();
    
    // ì—ì´ì „íŠ¸ ì„¤ì •
    await this.seedAgentConfigurations();
    
    // ê¶Œí•œ ë° ì—­í• 
    await this.seedPermissions();
  }
  
  // ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš© ëŒ€ëŸ‰ ë°ì´í„°
  async seedPerformanceData(scale: 'small' | 'medium' | 'large'): Promise<void> {
    const counts = {
      small: { users: 100, projects: 50, executions: 1000 },
      medium: { users: 1000, projects: 500, executions: 10000 },
      large: { users: 10000, projects: 5000, executions: 100000 }
    };
    
    const config = counts[scale];
    
    // ë°°ì¹˜ ì‚½ì…
    await this.batchInsert('users', config.users);
    await this.batchInsert('projects', config.projects);
    await this.batchInsert('executions', config.executions);
  }
  
  // íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°
  async seedScenario(scenarioName: string): Promise<void> {
    const scenarios = {
      'multi-agent-workflow': async () => {
        // ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ë°ì´í„°
        const project = await this.factory.create('project');
        const agents = await this.factory.createBatch('agent', 5);
        const workflow = await this.createWorkflow(project, agents);
        
        return { project, agents, workflow };
      },
      
      'concurrent-executions': async () => {
        // ë™ì‹œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ë°ì´í„°
        const users = await this.factory.createBatch('user', 10);
        const executions = [];
        
        for (const user of users) {
          const userExecutions = await this.factory.createBatch(
            'agentExecution',
            20,
            { userId: user.id }
          );
          executions.push(...userExecutions);
        }
        
        return { users, executions };
      },
      
      'error-scenarios': async () => {
        // ì—ëŸ¬ ìƒí™© í…ŒìŠ¤íŠ¸ ë°ì´í„°
        const failedExecutions = await this.factory.createBatch(
          'agentExecution',
          50,
          {
            status: 'failed',
            error: {
              code: faker.helpers.arrayElement([
                'TIMEOUT', 'RATE_LIMIT', 'INVALID_INPUT'
              ]),
              message: faker.lorem.sentence()
            }
          }
        );
        
        return { failedExecutions };
      }
    };
    
    const scenarioFunc = scenarios[scenarioName];
    if (!scenarioFunc) {
      throw new Error(`Unknown scenario: ${scenarioName}`);
    }
    
    await scenarioFunc();
  }
  
  // ë°ì´í„° ì •ë¦¬
  async cleanup(options?: CleanupOptions): Promise<void> {
    if (options?.preserveSystemData) {
      // ì‹œìŠ¤í…œ ë°ì´í„° ì œì™¸í•˜ê³  ì •ë¦¬
      await this.db.truncate({
        except: ['system_users', 'permissions', 'roles']
      });
    } else {
      // ì „ì²´ ì •ë¦¬
      await this.db.truncateAll();
    }
    
    // ì‹œí€€ìŠ¤ ë¦¬ì…‹
    await this.db.resetSequences();
    
    // ìºì‹œ í´ë¦¬ì–´
    await this.clearTestCache();
  }
}

// í…ŒìŠ¤íŠ¸ ë°ì´í„° ìŠ¤ëƒ…ìƒ·
export class TestDataSnapshot {
  private snapshots: Map<string, SnapshotData> = new Map();
  
  // ìŠ¤ëƒ…ìƒ· ìƒì„±
  async create(name: string): Promise<void> {
    const data = await this.captureCurrentState();
    
    this.snapshots.set(name, {
      name,
      timestamp: new Date(),
      data,
      checksum: this.calculateChecksum(data)
    });
  }
  
  // ìŠ¤ëƒ…ìƒ· ë³µì›
  async restore(name: string): Promise<void> {
    const snapshot = this.snapshots.get(name);
    if (!snapshot) {
      throw new Error(`Snapshot not found: ${name}`);
    }
    
    // í˜„ì¬ ë°ì´í„° ì •ë¦¬
    await this.cleanup();
    
    // ìŠ¤ëƒ…ìƒ· ë°ì´í„° ë³µì›
    await this.restoreData(snapshot.data);
    
    // ë¬´ê²°ì„± ê²€ì¦
    await this.verifyIntegrity(snapshot);
  }
  
  // ìŠ¤ëƒ…ìƒ· ë¹„êµ
  async compare(
    snapshot1: string,
    snapshot2: string
  ): Promise<SnapshotDiff> {
    const snap1 = this.snapshots.get(snapshot1);
    const snap2 = this.snapshots.get(snapshot2);
    
    if (!snap1 || !snap2) {
      throw new Error('Snapshot not found');
    }
    
    return this.calculateDiff(snap1.data, snap2.data);
  }
}
```

### SubTask 1.19.4: í…ŒìŠ¤íŠ¸ ìë™í™” íŒŒì´í”„ë¼ì¸
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: CI/CD í†µí•© í…ŒìŠ¤íŠ¸ ìë™í™” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/testing/test-automation-pipeline.ts
export class TestAutomationPipeline {
  private stages: TestStage[] = [];
  private hooks: PipelineHooks;
  private reporter: PipelineReporter;
  
  constructor(config: PipelineConfig) {
    this.hooks = new PipelineHooks();
    this.reporter = new PipelineReporter(config.reporting);
    
    this.initializeStages(config);
  }
  
  // íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
  async run(
    trigger: PipelineTrigger
  ): Promise<PipelineResult> {
    const execution: PipelineExecution = {
      id: crypto.randomUUID(),
      trigger,
      startTime: new Date(),
      stages: [],
      status: 'running'
    };
    
    try {
      // ì‚¬ì „ í›… ì‹¤í–‰
      await this.hooks.beforePipeline(execution);
      
      // ìŠ¤í…Œì´ì§€ë³„ ì‹¤í–‰
      for (const stage of this.stages) {
        const stageResult = await this.runStage(stage, execution);
        execution.stages.push(stageResult);
        
        if (!stageResult.success && stage.critical) {
          execution.status = 'failed';
          break;
        }
      }
      
      if (execution.status === 'running') {
        execution.status = 'success';
      }
      
      // ì‚¬í›„ í›… ì‹¤í–‰
      await this.hooks.afterPipeline(execution);
      
      // ë¦¬í¬íŠ¸ ìƒì„±
      const report = await this.reporter.generate(execution);
      
      return {
        execution,
        report,
        artifacts: await this.collectArtifacts(execution)
      };
      
    } catch (error) {
      execution.status = 'error';
      execution.error = error;
      
      await this.hooks.onError(execution, error);
      
      throw error;
      
    } finally {
      execution.endTime = new Date();
      
      // ê²°ê³¼ ì €ì¥
      await this.saveExecution(execution);
      
      // ì•Œë¦¼ ì „ì†¡
      await this.sendNotifications(execution);
    }
  }
  
  // ìŠ¤í…Œì´ì§€ ì‹¤í–‰
  private async runStage(
    stage: TestStage,
    execution: PipelineExecution
  ): Promise<StageResult> {
    const result: StageResult = {
      stage: stage.name,
      startTime: new Date(),
      tests: [],
      success: true
    };
    
    try {
      // ë³‘ë ¬ ì‹¤í–‰ ì„¤ì •
      const concurrency = stage.parallel ? stage.maxConcurrency || 5 : 1;
      const queue = new PQueue({ concurrency });
      
      // í…ŒìŠ¤íŠ¸ ì‹¤í–‰
      const testPromises = stage.tests.map(test =>
        queue.add(() => this.runTest(test, stage))
      );
      
      const testResults = await Promise.all(testPromises);
      result.tests = testResults;
      
      // ì„±ê³µ ì—¬ë¶€ íŒë‹¨
      result.success = this.evaluateStageSuccess(
        testResults,
        stage.successCriteria
      );
      
    } catch (error) {
      result.success = false;
      result.error = error;
      
    } finally {
      result.endTime = new Date();
      result.duration = result.endTime.getTime() - result.startTime.getTime();
    }
    
    return result;
  }
  
  // ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
  private async runTest(
    test: TestDefinition,
    stage: TestStage
  ): Promise<TestResult> {
    const startTime = Date.now();
    
    try {
      // í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„
      const environment = await this.prepareTestEnvironment(
        test,
        stage
      );
      
      // í…ŒìŠ¤íŠ¸ ì‹¤í–‰
      const runner = this.getTestRunner(test.type);
      const result = await runner.run(test, environment);
      
      return {
        test: test.name,
        success: result.passed,
        duration: Date.now() - startTime,
        metrics: result.metrics,
        coverage: result.coverage,
        artifacts: result.artifacts
      };
      
    } catch (error) {
      return {
        test: test.name,
        success: false,
        duration: Date.now() - startTime,
        error: error.message,
        stackTrace: error.stack
      };
    }
  }
  
  // í…ŒìŠ¤íŠ¸ ë³‘ë ¬í™” ìµœì í™”
  async optimizeParallelization(
    historicalData: HistoricalTestData
  ): Promise<ParallelizationPlan> {
    const analyzer = new TestDurationAnalyzer();
    
    // í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œê°„ ë¶„ì„
    const durations = analyzer.analyze(historicalData);
    
    // ìµœì  ê·¸ë£¹í™”
    const groups = this.groupTestsOptimally(durations);
    
    // ë¦¬ì†ŒìŠ¤ í• ë‹¹ ê³„íš
    const resourcePlan = this.planResourceAllocation(groups);
    
    return {
      groups,
      resourcePlan,
      estimatedDuration: this.estimateTotalDuration(groups),
      recommendations: this.generateOptimizationRecommendations(
        durations,
        groups
      )
    };
  }
  
  // í…ŒìŠ¤íŠ¸ ì˜í–¥ ë¶„ì„
  async analyzeTestImpact(
    changes: CodeChanges
  ): Promise<TestImpactAnalysis> {
    const impactAnalyzer = new TestImpactAnalyzer();
    
    // ë³€ê²½ëœ ì½”ë“œ ë¶„ì„
    const affectedModules = await impactAnalyzer.findAffectedModules(
      changes
    );
    
    // ì˜í–¥ë°›ëŠ” í…ŒìŠ¤íŠ¸ ì‹ë³„
    const affectedTests = await impactAnalyzer.findAffectedTests(
      affectedModules
    );
    
    // ìš°ì„ ìˆœìœ„ ê²°ì •
    const prioritizedTests = this.prioritizeTests(
      affectedTests,
      changes
    );
    
    return {
      affectedModules,
      affectedTests,
      prioritizedTests,
      skipSafeTests: await this.identifySkipSafeTests(
        affectedTests,
        changes
      ),
      estimatedSavings: this.calculateTimeSavings(
        affectedTests,
        prioritizedTests
      )
    };
  }
}

// ì§€ì†ì  í…ŒìŠ¤íŠ¸ ëª¨ë‹ˆí„°
export class ContinuousTestMonitor {
  private metrics: TestMetricsCollector;
  private analyzer: TestAnalyzer;
  private alerter: TestAlerter;
  
  // í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  async collectMetrics(
    execution: PipelineExecution
  ): Promise<TestMetrics> {
    return {
      duration: this.calculateDuration(execution),
      passRate: this.calculatePassRate(execution),
      coverage: await this.aggregateCoverage(execution),
      flakiness: await this.calculateFlakiness(execution),
      performance: await this.analyzePerformance(execution)
    };
  }
  
  // í…ŒìŠ¤íŠ¸ íŠ¸ë Œë“œ ë¶„ì„
  async analyzeTrends(
    timeRange: TimeRange
  ): Promise<TestTrends> {
    const executions = await this.getExecutions(timeRange);
    
    return {
      durationTrend: this.analyzeDurationTrend(executions),
      passRateTrend: this.analyzePassRateTrend(executions),
      coverageTrend: this.analyzeCoverageTrend(executions),
      flakyTests: await this.identifyFlakyTests(executions),
      slowTests: this.identifySlowTests(executions),
      failurePatterns: await this.analyzeFailurePatterns(executions)
    };
  }
  
  // í…ŒìŠ¤íŠ¸ ìƒíƒœ ëŒ€ì‹œë³´ë“œ
  async getDashboardData(): Promise<TestDashboard> {
    const latestExecution = await this.getLatestExecution();
    const trends = await this.analyzeTrends({ days: 30 });
    const health = await this.assessTestHealth();
    
    return {
      current: {
        status: latestExecution.status,
        passRate: this.calculatePassRate(latestExecution),
        duration: this.calculateDuration(latestExecution),
        coverage: await this.getCoverage(latestExecution)
      },
      trends,
      health,
      alerts: await this.getActiveAlerts(),
      recommendations: await this.generateRecommendations(
        latestExecution,
        trends,
        health
      )
    };
  }
}

// í…ŒìŠ¤íŠ¸ ë¦¬í¬í„°
export class TestReporter {
  // í…ŒìŠ¤íŠ¸ ê²°ê³¼ í¬ë§·íŒ…
  async formatResults(
    results: TestResults,
    format: ReportFormat
  ): Promise<string> {
    switch (format) {
      case 'junit':
        return this.toJUnit(results);
        
      case 'html':
        return await this.toHTML(results);
        
      case 'json':
        return JSON.stringify(results, null, 2);
        
      case 'markdown':
        return this.toMarkdown(results);
        
      case 'slack':
        return this.toSlackMessage(results);
        
      default:
        throw new Error(`Unknown format: ${format}`);
    }
  }
  
  // JUnit XML í¬ë§·
  private toJUnit(results: TestResults): string {
    const xml = builder.create('testsuites');
    
    xml.att('tests', results.total);
    xml.att('failures', results.failed);
    xml.att('errors', results.errors);
    xml.att('time', results.duration / 1000);
    
    for (const suite of results.suites) {
      const suiteXml = xml.ele('testsuite');
      suiteXml.att('name', suite.name);
      suiteXml.att('tests', suite.tests.length);
      
      for (const test of suite.tests) {
        const testXml = suiteXml.ele('testcase');
        testXml.att('name', test.name);
        testXml.att('time', test.duration / 1000);
        
        if (!test.success) {
          const failure = testXml.ele('failure');
          failure.att('message', test.error?.message || 'Test failed');
          failure.txt(test.error?.stack || '');
        }
      }
    }
    
    return xml.end({ pretty: true });
  }
}
```

## Task 1.20: CI/CD íŒŒì´í”„ë¼ì¸ ê¸°ì´ˆ

### SubTask 1.20.1: ë¹Œë“œ ìë™í™”
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: ìë™í™”ëœ ë¹Œë“œ ì‹œìŠ¤í…œ êµ¬ì¶•

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// infrastructure/ci-cd/build-automation.ts
export class BuildAutomation {
  private builders: Map<string, Builder> = new Map();
  private cache: BuildCache;
  private registry: ArtifactRegistry;
  
  constructor(config: BuildConfig) {
    this.cache = new BuildCache(config.cache);
    this.registry = new ArtifactRegistry(config.registry);
    
    this.registerBuilders();
  }
  
  // ë¹Œë“œ ì‹¤í–‰
  async build(
    project: Project,
    options: BuildOptions
  ): Promise<BuildResult> {
    const buildId = crypto.randomUUID();
    const startTime = Date.now();
    
    try {
      // ë¹Œë“œ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
      const context = await this.prepareBuildContext(project, options);
      
      // ì˜ì¡´ì„± í™•ì¸
      await this.checkDependencies(context);
      
      // ìºì‹œ ì²´í¬
      const cached = await this.checkCache(context);
      if (cached && !options.force) {
        return {
          buildId,
          success: true,
          cached: true,
          artifacts: cached.artifacts,
          duration: Date.now() - startTime
        };
      }
      
      // ë¹Œë“œ ë‹¨ê³„ ì‹¤í–‰
      const artifacts = await this.executeBuildStages(context);
      
      // ì•„í‹°íŒ©íŠ¸ ì €ì¥
      await this.saveArtifacts(buildId, artifacts);
      
      // ìºì‹œ ì—…ë°ì´íŠ¸
      await this.updateCache(context, artifacts);
      
      return {
        buildId,
        success: true,
        artifacts,
        duration: Date.now() - startTime,
        metrics: await this.collectBuildMetrics(context)
      };
      
    } catch (error) {
      return {
        buildId,
        success: false,
        error: error.message,
        duration: Date.now() - startTime
      };
    }
  }
  
  // ë¹Œë“œ ë‹¨ê³„ ì‹¤í–‰
  private async executeBuildStages(
    context: BuildContext
  ): Promise<BuildArtifacts> {
    const artifacts: BuildArtifacts = {
      binaries: [],
      images: [],
      packages: [],
      reports: []
    };
    
    // ì»´íŒŒì¼
    if (context.stages.includes('compile')) {
      const compiled = await this.compile(context);
      artifacts.binaries.push(...compiled);
    }
    
    // í…ŒìŠ¤íŠ¸
    if (context.stages.includes('test')) {
      const testReport = await this.runTests(context);
      artifacts.reports.push(testReport);
    }
    
    // íŒ¨í‚¤ì§•
    if (context.stages.includes('package')) {
      const packages = await this.package(context);
      artifacts.packages.push(...packages);
    }
    
    // ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¹Œë“œ
    if (context.stages.includes('containerize')) {
      const images = await this.buildContainerImages(context);
      artifacts.images.push(...images);
    }
    
    return artifacts;
  }
  
  // ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¹Œë“œ
  private async buildContainerImages(
    context: BuildContext
  ): Promise<ContainerImage[]> {
    const images: ContainerImage[] = [];
    
    for (const service of context.services) {
      const dockerfile = path.join(
        context.root,
        service.dockerfile || 'Dockerfile'
      );
      
      // ë¹Œë“œ ì¸ì ì¤€ë¹„
      const buildArgs = {
        VERSION: context.version,
        BUILD_DATE: new Date().toISOString(),
        VCS_REF: context.gitCommit,
        ...service.buildArgs
      };
      
      // ì´ë¯¸ì§€ ë¹Œë“œ
      const image = await this.docker.build({
        context: context.root,
        dockerfile,
        tags: this.generateImageTags(service, context),
        buildArgs,
        target: service.target,
        cache: !context.options.noCache
      });
      
      // ë³´ì•ˆ ìŠ¤ìº”
      if (context.options.securityScan) {
        await this.scanImage(image);
      }
      
      images.push(image);
    }
    
    return images;
  }
  
  // ë¹Œë“œ ìµœì í™”
  async optimizeBuild(
    project: Project
  ): Promise<BuildOptimization> {
    const analysis = await this.analyzeBuildProcess(project);
    
    return {
      recommendations: [
        ...this.suggestCacheOptimizations(analysis),
        ...this.suggestParallelization(analysis),
        ...this.suggestDependencyOptimizations(analysis)
      ],
      estimatedImprovement: this.estimateImprovement(analysis),
      implementation: this.generateOptimizedConfig(analysis)
    };
  }
}

// ë¹Œë“œ íŒŒì´í”„ë¼ì¸
export class BuildPipeline {
  private stages: BuildStage[] = [];
  private hooks: BuildHooks;
  
  // íŒŒì´í”„ë¼ì¸ ì •ì˜
  define(config: PipelineConfig): void {
    this.stages = config.stages.map(stage => ({
      name: stage.name,
      condition: stage.when,
      steps: stage.steps,
      environment: stage.environment,
      timeout: stage.timeout || 300000 // 5ë¶„
    }));
  }
  
  // íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
  async execute(
    trigger: BuildTrigger
  ): Promise<PipelineResult> {
    const execution: PipelineExecution = {
      id: crypto.randomUUID(),
      trigger,
      startTime: new Date(),
      stages: []
    };
    
    try {
      // ì „ì²˜ë¦¬
      await this.hooks.beforePipeline(execution);
      
      // ë‹¨ê³„ë³„ ì‹¤í–‰
      for (const stage of this.stages) {
        if (await this.shouldRunStage(stage, execution)) {
          const result = await this.runStage(stage, execution);
          execution.stages.push(result);
          
          if (!result.success && stage.critical) {
            break;
          }
        }
      }
      
      // í›„ì²˜ë¦¬
      await this.hooks.afterPipeline(execution);
      
      return {
        execution,
        success: execution.stages.every(s => s.success),
        artifacts: this.collectArtifacts(execution)
      };
      
    } catch (error) {
      await this.hooks.onError(execution, error);
      throw error;
    }
  }
}

// Dockerfile ìƒì„±ê¸°
export class DockerfileGenerator {
  generate(config: ServiceConfig): string {
    const lines: string[] = [];
    
    // ë² ì´ìŠ¤ ì´ë¯¸ì§€
    lines.push(`FROM ${config.baseImage} AS base`);
    lines.push('WORKDIR /app');
    
    // ì˜ì¡´ì„± ì„¤ì¹˜ (ìºì‹œ ìµœì í™”)
    if (config.type === 'node') {
      lines.push('COPY package*.json ./');
      lines.push('RUN npm ci --only=production');
    } else if (config.type === 'python') {
      lines.push('COPY requirements.txt ./');
      lines.push('RUN pip install --no-cache-dir -r requirements.txt');
    }
    
    // ì†ŒìŠ¤ ë³µì‚¬
    lines.push('COPY . .');
    
    // ë¹Œë“œ ë‹¨ê³„
    if (config.buildCommand) {
      lines.push(`FROM base AS builder`);
      lines.push(`RUN ${config.buildCommand}`);
    }
    
    // í”„ë¡œë•ì…˜ ì´ë¯¸ì§€
    lines.push(`FROM ${config.runtimeImage || config.baseImage} AS production`);
    lines.push('WORKDIR /app');
    
    // ëŸ°íƒ€ì„ ì˜ì¡´ì„±ë§Œ ë³µì‚¬
    if (config.buildCommand) {
      lines.push(`COPY --from=builder /app/dist ./dist`);
    }
    lines.push(`COPY --from=base /app/node_modules ./node_modules`);
    
    // í—¬ìŠ¤ì²´í¬
    if (config.healthcheck) {
      lines.push(`HEALTHCHECK --interval=30s --timeout=3s --start-period=40s \\`);
      lines.push(`  CMD ${config.healthcheck}`);
    }
    
    // ì‹¤í–‰
    lines.push(`EXPOSE ${config.port || 3000}`);
    lines.push(`CMD ["${config.command}"]`);
    
    return lines.join('\n');
  }
}
```

### SubTask 1.20.2: ë°°í¬ íŒŒì´í”„ë¼ì¸
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ìë™í™”ëœ ë°°í¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// infrastructure/ci-cd/deployment-pipeline.ts
export class DeploymentPipeline {
  private deployers: Map<string, Deployer> = new Map();
  private validator: DeploymentValidator;
  private rollback: RollbackManager;
  
  constructor(config: DeploymentConfig) {
    this.validator = new DeploymentValidator();
    this.rollback = new RollbackManager();
    
    this.registerDeployers(config);
  }
  
  // ë°°í¬ ì‹¤í–‰
  async deploy(
    release: Release,
    environment: Environment,
    strategy: DeploymentStrategy
  ): Promise<DeploymentResult> {
    const deployment: Deployment = {
      id: crypto.randomUUID(),
      release,
      environment,
      strategy,
      startTime: new Date(),
      status: 'pending'
    };
    
    try {
      // ì‚¬ì „ ê²€ì¦
      await this.validator.validateDeployment(deployment);
      
      // ë°°í¬ ì „ëµ ì‹¤í–‰
      const result = await this.executeStrategy(deployment);
      
      // ë°°í¬ ê²€ì¦
      await this.verifyDeployment(deployment);
      
      deployment.status = 'success';
      deployment.endTime = new Date();
      
      return {
        deployment,
        success: true,
        services: result.services,
        metrics: await this.collectDeploymentMetrics(deployment)
      };
      
    } catch (error) {
      deployment.status = 'failed';
      deployment.error = error;
      
      // ë¡¤ë°± ì‹¤í–‰
      if (strategy.autoRollback) {
        await this.rollback.execute(deployment);
      }
      
      throw error;
    }
  }
  
  // ë°°í¬ ì „ëµ ì‹¤í–‰
  private async executeStrategy(
    deployment: Deployment
  ): Promise<StrategyResult> {
    const strategy = deployment.strategy;
    
    switch (strategy.type) {
      case 'rolling':
        return await this.rollingDeployment(deployment);
        
      case 'blue-green':
        return await this.blueGreenDeployment(deployment);
        
      case 'canary':
        return await this.canaryDeployment(deployment);
        
      case 'recreate':
        return await this.recreateDeployment(deployment);
        
      default:
        throw new Error(`Unknown strategy: ${strategy.type}`);
    }
  }
  
  // ë¡¤ë§ ë°°í¬
  private async rollingDeployment(
    deployment: Deployment
  ): Promise<StrategyResult> {
    const instances = await this.getInstances(deployment.environment);
    const batchSize = deployment.strategy.batchSize || 1;
    const results: ServiceDeployment[] = [];
    
    // ë°°ì¹˜ë³„ ë°°í¬
    for (let i = 0; i < instances.length; i += batchSize) {
      const batch = instances.slice(i, i + batchSize);
      
      // íŠ¸ë˜í”½ ì°¨ë‹¨
      await this.drainTraffic(batch);
      
      // ìƒˆ ë²„ì „ ë°°í¬
      const deployed = await this.deployToBatch(batch, deployment);
      
      // í—¬ìŠ¤ì²´í¬
      await this.waitForHealthy(deployed);
      
      // íŠ¸ë˜í”½ ë³µêµ¬
      await this.enableTraffic(deployed);
      
      results.push(...deployed);
      
      // ë°°ì¹˜ ê°„ ëŒ€ê¸°
      if (i + batchSize < instances.length) {
        await this.delay(deployment.strategy.batchDelay || 30000);
      }
    }
    
    return { services: results };
  }
  
  // Blue-Green ë°°í¬
  private async blueGreenDeployment(
    deployment: Deployment
  ): Promise<StrategyResult> {
    // Green í™˜ê²½ ì¤€ë¹„
    const greenEnv = await this.prepareGreenEnvironment(deployment);
    
    // Greenì— ë°°í¬
    await this.deployToEnvironment(greenEnv, deployment);
    
    // Green í™˜ê²½ ê²€ì¦
    await this.validateEnvironment(greenEnv);
    
    // íŠ¸ë˜í”½ ì „í™˜
    await this.switchTraffic({
      from: 'blue',
      to: 'green',
      percentage: 100
    });
    
    // Blue í™˜ê²½ ëŒ€ê¸° (ë¡¤ë°± ëŒ€ë¹„)
    await this.delay(deployment.strategy.validationPeriod || 300000);
    
    // Blue í™˜ê²½ ì •ë¦¬
    await this.cleanupBlueEnvironment();
    
    return {
      services: greenEnv.services,
      switchTime: new Date()
    };
  }
  
  // Canary ë°°í¬
  private async canaryDeployment(
    deployment: Deployment
  ): Promise<StrategyResult> {
    const stages = deployment.strategy.stages || [
      { percentage: 10, duration: 300000 },
      { percentage: 50, duration: 300000 },
      { percentage: 100, duration: 0 }
    ];
    
    // Canary ì¸ìŠ¤í„´ìŠ¤ ë°°í¬
    const canaryInstances = await this.deployCanary(deployment);
    
    // ë‹¨ê³„ë³„ íŠ¸ë˜í”½ ì¦ê°€
    for (const stage of stages) {
      // íŠ¸ë˜í”½ ë¼ìš°íŒ… ì—…ë°ì´íŠ¸
      await this.updateTrafficSplit({
        canary: stage.percentage,
        stable: 100 - stage.percentage
      });
      
      // ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§
      const metrics = await this.monitorCanary(
        canaryInstances,
        stage.duration
      );
      
      // ì„±ê³µ ê¸°ì¤€ í‰ê°€
      if (!this.evaluateCanaryMetrics(metrics)) {
        throw new Error('Canary deployment failed metrics evaluation');
      }
    }
    
    return {
      services: canaryInstances,
      stages: stages.map((s, i) => ({
        ...s,
        completed: true
      }))
    };
  }
  
  // ë°°í¬ ê²€ì¦
  private async verifyDeployment(
    deployment: Deployment
  ): Promise<void> {
    const checks: HealthCheck[] = [
      {
        name: 'service-health',
        check: () => this.checkServiceHealth(deployment)
      },
      {
        name: 'dependencies',
        check: () => this.checkDependencies(deployment)
      },
      {
        name: 'smoke-tests',
        check: () => this.runSmokeTests(deployment)
      },
      {
        name: 'metrics',
        check: () => this.checkMetrics(deployment)
      }
    ];
    
    for (const check of checks) {
      const result = await check.check();
      
      if (!result.healthy) {
        throw new Error(`Verification failed: ${check.name}`);
      }
    }
  }
}

// í™˜ê²½ ê´€ë¦¬
export class EnvironmentManager {
  private environments: Map<string, Environment> = new Map();
  
  // í™˜ê²½ í”„ë¡œë¹„ì €ë‹
  async provision(
    name: string,
    config: EnvironmentConfig
  ): Promise<Environment> {
    // ì¸í”„ë¼ ìƒì„±
    const infrastructure = await this.createInfrastructure(config);
    
    // ë„¤íŠ¸ì›Œí‚¹ ì„¤ì •
    await this.setupNetworking(infrastructure);
    
    // ë³´ì•ˆ ì„¤ì •
    await this.configureSecurity(infrastructure);
    
    // ëª¨ë‹ˆí„°ë§ ì„¤ì •
    await this.setupMonitoring(infrastructure);
    
    const environment: Environment = {
      name,
      infrastructure,
      config,
      status: 'ready',
      createdAt: new Date()
    };
    
    this.environments.set(name, environment);
    
    return environment;
  }
  
  // í™˜ê²½ ë³µì œ
  async clone(
    source: string,
    target: string
  ): Promise<Environment> {
    const sourceEnv = this.environments.get(source);
    if (!sourceEnv) {
      throw new Error(`Source environment not found: ${source}`);
    }
    
    // ì„¤ì • ë³µì‚¬
    const config = { ...sourceEnv.config };
    
    // ìƒˆ í™˜ê²½ ìƒì„±
    return await this.provision(target, config);
  }
}

// ë°°í¬ ìë™í™” ìŠ¤í¬ë¦½íŠ¸
export class DeploymentAutomation {
  // GitHub Actions ì›Œí¬í”Œë¡œìš° ìƒì„±
  generateGitHubWorkflow(config: WorkflowConfig): string {
    return `
name: Deploy to ${config.environment}

on:
  push:
    branches: [${config.branch}]
  workflow_dispatch:

env:
  AWS_REGION: ${config.aws.region}
  ECR_REPOSITORY: ${config.ecr.repository}

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: \${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: \${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: \${{ env.AWS_REGION }}
    
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1
    
    - name: Build and push image
      env:
        ECR_REGISTRY: \${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: \${{ github.sha }}
      run: |
        docker build -t \$ECR_REGISTRY/\$ECR_REPOSITORY:\$IMAGE_TAG .
        docker push \$ECR_REGISTRY/\$ECR_REPOSITORY:\$IMAGE_TAG
    
    - name: Deploy to ECS
      run: |
        aws ecs update-service \\
          --cluster ${config.ecs.cluster} \\
          --service ${config.ecs.service} \\
          --force-new-deployment
`;
  }
}
```

### SubTask 1.20.3: ë²„ì „ ê´€ë¦¬ ì „ëµ
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 6ì‹œê°„

**ëª©í‘œ**: ì²´ê³„ì ì¸ ë²„ì „ ê´€ë¦¬ ë° ë¦´ë¦¬ì¦ˆ ì „ëµ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// infrastructure/ci-cd/version-management.ts
export class VersionManager {
  private strategy: VersioningStrategy;
  private registry: VersionRegistry;
  
  constructor(config: VersionConfig) {
    this.strategy = this.createStrategy(config.strategy);
    this.registry = new VersionRegistry(config.storage);
  }
  
  // ë²„ì „ ìƒì„±
  async createVersion(
    type: ReleaseType,
    metadata?: VersionMetadata
  ): Promise<Version> {
    const currentVersion = await this.getCurrentVersion();
    const newVersion = this.strategy.increment(currentVersion, type);
    
    const version: Version = {
      version: newVersion,
      type,
      timestamp: new Date(),
      commit: await this.getGitCommit(),
      branch: await this.getGitBranch(),
      metadata: {
        ...metadata,
        buildNumber: await this.getNextBuildNumber(),
        author: await this.getAuthor()
      }
    };
    
    // ë²„ì „ ê²€ì¦
    await this.validateVersion(version);
    
    // ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì €ì¥
    await this.registry.save(version);
    
    // Git íƒœê·¸ ìƒì„±
    if (config.createGitTag) {
      await this.createGitTag(version);
    }
    
    return version;
  }
  
  // ì‹œë§¨í‹± ë²„ì €ë‹
  private createSemanticStrategy(): SemanticVersioning {
    return {
      increment(current: string, type: ReleaseType): string {
        const [major, minor, patch] = current.split('.').map(Number);
        
        switch (type) {
          case 'major':
            return `${major + 1}.0.0`;
            
          case 'minor':
            return `${major}.${minor + 1}.0`;
            
          case 'patch':
            return `${major}.${minor}.${patch + 1}`;
            
          case 'prerelease':
            return `${major}.${minor}.${patch}-rc.${Date.now()}`;
            
          default:
            throw new Error(`Unknown release type: ${type}`);
        }
      }
    };
  }
  
  // ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸ ìƒì„±
  async generateReleaseNotes(
    fromVersion: string,
    toVersion: string
  ): Promise<ReleaseNotes> {
    // ì»¤ë°‹ ìˆ˜ì§‘
    const commits = await this.getCommitsBetween(fromVersion, toVersion);
    
    // ë³€ê²½ì‚¬í•­ ë¶„ë¥˜
    const changes = this.categorizeChanges(commits);
    
    // PR ë° ì´ìŠˆ ì—°ê²°
    const linkedItems = await this.linkPRsAndIssues(commits);
    
    // ì»¨íŠ¸ë¦¬ë·°í„° ìˆ˜ì§‘
    const contributors = this.extractContributors(commits);
    
    return {
      version: toVersion,
      date: new Date(),
      changes: {
        features: changes.features,
        fixes: changes.fixes,
        breaking: changes.breaking,
        deprecated: changes.deprecated
      },
      linkedItems,
      contributors,
      markdown: this.formatAsMarkdown(changes, linkedItems, contributors)
    };
  }
  
  // ë²„ì „ íƒœê¹… ì „ëµ
  async applyTaggingStrategy(
    version: Version
  ): Promise<Tags> {
    const tags: Tags = {
      version: version.version,
      latest: await this.isLatestVersion(version),
      stable: version.type !== 'prerelease',
      environment: this.determineEnvironment(version)
    };
    
    // ì¶”ê°€ íƒœê·¸
    if (version.metadata?.tags) {
      Object.assign(tags, version.metadata.tags);
    }
    
    return tags;
  }
}

// ë¦´ë¦¬ì¦ˆ ê´€ë¦¬
export class ReleaseManager {
  private versions: VersionManager;
  private artifacts: ArtifactManager;
  private changelog: ChangelogGenerator;
  
  // ë¦´ë¦¬ì¦ˆ ìƒì„±
  async createRelease(
    config: ReleaseConfig
  ): Promise<Release> {
    // ë²„ì „ ìƒì„±
    const version = await this.versions.createVersion(
      config.type,
      config.metadata
    );
    
    // ì•„í‹°íŒ©íŠ¸ ìˆ˜ì§‘
    const artifacts = await this.artifacts.collect(version);
    
    // ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸ ìƒì„±
    const releaseNotes = await this.versions.generateReleaseNotes(
      config.previousVersion,
      version.version
    );
    
    // ì²´ì¸ì§€ë¡œê·¸ ì—…ë°ì´íŠ¸
    await this.changelog.update(version, releaseNotes);
    
    const release: Release = {
      id: crypto.randomUUID(),
      version,
      artifacts,
      releaseNotes,
      status: 'draft',
      createdAt: new Date()
    };
    
    // ë¦´ë¦¬ì¦ˆ ê²€ì¦
    await this.validateRelease(release);
    
    return release;
  }
  
  // ë¦´ë¦¬ì¦ˆ ìŠ¹ê²©
  async promote(
    release: Release,
    toEnvironment: string
  ): Promise<Promotion> {
    // ìŠ¹ê²© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    await this.validatePromotion(release, toEnvironment);
    
    // ìŠ¹ì¸ í™•ì¸
    if (this.requiresApproval(toEnvironment)) {
      await this.waitForApproval(release, toEnvironment);
    }
    
    // ì•„í‹°íŒ©íŠ¸ ë³µì‚¬
    await this.artifacts.copyToEnvironment(
      release.artifacts,
      toEnvironment
    );
    
    // ì„¤ì • ì—…ë°ì´íŠ¸
    await this.updateEnvironmentConfig(
      toEnvironment,
      release.version
    );
    
    return {
      release,
      fromEnvironment: release.environment,
      toEnvironment,
      promotedAt: new Date(),
      promotedBy: await this.getCurrentUser()
    };
  }
}

// Git í”Œë¡œìš° ìë™í™”
export class GitFlowAutomation {
  // ë¸Œëœì¹˜ ì „ëµ
  async implementBranchStrategy(
    strategy: BranchStrategy
  ): Promise<void> {
    switch (strategy) {
      case 'git-flow':
        await this.setupGitFlow();
        break;
        
      case 'github-flow':
        await this.setupGitHubFlow();
        break;
        
      case 'gitlab-flow':
        await this.setupGitLabFlow();
        break;
    }
  }
  
  // Git Flow ì„¤ì •
  private async setupGitFlow(): Promise<void> {
    // ê¸°ë³¸ ë¸Œëœì¹˜ ìƒì„±
    await this.createBranch('develop', 'main');
    
    // ë¸Œëœì¹˜ ë³´í˜¸ ê·œì¹™
    await this.protectBranch('main', {
      requirePullRequest: true,
      requireReviews: 2,
      dismissStaleReviews: true,
      requireUpToDate: true,
      restrictions: {
        users: [],
        teams: ['release-managers']
      }
    });
    
    await this.protectBranch('develop', {
      requirePullRequest: true,
      requireReviews: 1,
      requireUpToDate: true
    });
    
    // í›… ì„¤ì •
    await this.setupGitHooks({
      'pre-commit': this.validateCommitMessage,
      'pre-push': this.runPrePushChecks
    });
  }
  
  // ìë™ ë³‘í•©
  async autoMerge(
    pr: PullRequest,
    strategy: MergeStrategy
  ): Promise<MergeResult> {
    // ë³‘í•© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    const checks = await this.runMergeChecks(pr);
    
    if (!checks.passed) {
      return {
        success: false,
        reason: checks.failureReason
      };
    }
    
    // ë³‘í•© ì‹¤í–‰
    switch (strategy) {
      case 'merge':
        return await this.mergePR(pr);
        
      case 'squash':
        return await this.squashAndMerge(pr);
        
      case 'rebase':
        return await this.rebaseAndMerge(pr);
    }
  }
}
```

### SubTask 1.20.4: ëª¨ë‹ˆí„°ë§ í†µí•©
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ëª©í‘œ**: CI/CD íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// infrastructure/ci-cd/pipeline-monitoring.ts
export class PipelineMonitoring {
  private metrics: MetricsCollector;
  private tracer: DistributedTracer;
  private alertManager: AlertManager;
  
  constructor(config: MonitoringConfig) {
    this.metrics = new MetricsCollector(config.metrics);
    this.tracer = new DistributedTracer(config.tracing);
    this.alertManager = new AlertManager(config.alerts);
  }
  
  // íŒŒì´í”„ë¼ì¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  async collectPipelineMetrics(
    execution: PipelineExecution
  ): Promise<PipelineMetrics> {
    return {
      duration: this.calculateDuration(execution),
      stages: await this.collectStageMetrics(execution.stages),
      resources: await this.collectResourceMetrics(execution),
      costs: await this.calculateCosts(execution),
      quality: await this.assessQuality(execution)
    };
  }
  
  // ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
  async getDashboardData(): Promise<DashboardData> {
    const current = await this.getCurrentExecutions();
    const history = await this.getExecutionHistory({ hours: 24 });
    const trends = await this.analyzeTrends(history);
    
    return {
      current: {
        running: current.filter(e => e.status === 'running'),
        queued: current.filter(e => e.status === 'queued'),
        recent: history.slice(0, 10)
      },
      metrics: {
        successRate: this.calculateSuccessRate(history),
        averageDuration: this.calculateAverageDuration(history),
        throughput: this.calculateThroughput(history),
        mttr: await this.calculateMTTR(history)
      },
      trends: {
        duration: trends.duration,
        successRate: trends.successRate,
        frequency: trends.frequency
      },
      alerts: await this.getActiveAlerts(),
      recommendations: await this.generateRecommendations(trends)
    };
  }
  
  // íŒŒì´í”„ë¼ì¸ ì¶”ì 
  async tracePipeline(
    execution: PipelineExecution
  ): Promise<TraceData> {
    const trace = this.tracer.startTrace('pipeline', {
      executionId: execution.id,
      trigger: execution.trigger
    });
    
    // ìŠ¤í…Œì´ì§€ë³„ ì¶”ì 
    for (const stage of execution.stages) {
      const span = trace.createSpan('stage', {
        name: stage.name,
        parallel: stage.parallel
      });
      
      try {
        await this.traceStage(stage, span);
        span.finish();
      } catch (error) {
        span.finishWithError(error);
        throw error;
      }
    }
    
    trace.finish();
    
    return {
      traceId: trace.id,
      spans: trace.getSpans(),
      waterfall: this.generateWaterfall(trace),
      criticalPath: this.findCriticalPath(trace)
    };
  }
  
  // ì´ìƒ ê°ì§€
  async detectAnomalies(
    metrics: PipelineMetrics
  ): Promise<Anomaly[]> {
    const anomalies: Anomaly[] = [];
    
    // ì‹¤í–‰ ì‹œê°„ ì´ìƒ
    if (metrics.duration > this.getThreshold('duration')) {
      anomalies.push({
        type: 'slow_pipeline',
        severity: 'warning',
        value: metrics.duration,
        threshold: this.getThreshold('duration'),
        recommendation: 'Investigate slow stages'
      });
    }
    
    // ì‹¤íŒ¨ìœ¨ ì´ìƒ
    const failureRate = this.calculateFailureRate(metrics);
    if (failureRate > this.getThreshold('failureRate')) {
      anomalies.push({
        type: 'high_failure_rate',
        severity: 'critical',
        value: failureRate,
        threshold: this.getThreshold('failureRate'),
        recommendation: 'Check recent changes and logs'
      });
    }
    
    // ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ì´ìƒ
    if (metrics.resources.cpu > this.getThreshold('cpu')) {
      anomalies.push({
        type: 'high_cpu_usage',
        severity: 'warning',
        value: metrics.resources.cpu,
        threshold: this.getThreshold('cpu'),
        recommendation: 'Consider scaling or optimization'
      });
    }
    
    return anomalies;
  }
  
  // ì•Œë¦¼ ì„¤ì •
  async configureAlerts(): Promise<void> {
    // íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ ì•Œë¦¼
    await this.alertManager.createRule({
      name: 'pipeline_failure',
      condition: 'status == "failed"',
      severity: 'critical',
      channels: ['slack', 'email'],
      template: {
        title: 'Pipeline Failed: {{pipeline.name}}',
        message: 'Pipeline {{execution.id}} failed at stage {{failed_stage}}'
      }
    });
    
    // ì„±ëŠ¥ ì €í•˜ ì•Œë¦¼
    await this.alertManager.createRule({
      name: 'performance_degradation',
      condition: 'duration > average_duration * 1.5',
      severity: 'warning',
      channels: ['slack'],
      template: {
        title: 'Pipeline Performance Degradation',
        message: 'Pipeline taking 50% longer than average'
      }
    });
    
    // ë¹„ìš© ì´ˆê³¼ ì•Œë¦¼
    await this.alertManager.createRule({
      name: 'cost_overrun',
      condition: 'monthly_cost > budget * 0.8',
      severity: 'warning',
      channels: ['email'],
      template: {
        title: 'CI/CD Cost Alert',
        message: 'Monthly costs at 80% of budget'
      }
    });
  }
  
  // íŒŒì´í”„ë¼ì¸ ìµœì í™” ì œì•ˆ
  async generateOptimizations(
    analysis: PipelineAnalysis
  ): Promise<Optimization[]> {
    const optimizations: Optimization[] = [];
    
    // ë³‘ë ¬í™” ê¸°íšŒ
    const parallelizable = this.findParallelizableStages(analysis);
    if (parallelizable.length > 0) {
      optimizations.push({
        type: 'parallelization',
        impact: 'high',
        description: 'Parallelize independent stages',
        stages: parallelizable,
        estimatedImprovement: '30-40% reduction in duration'
      });
    }
    
    // ìºì‹± ê°œì„ 
    const cacheableSteps = this.findCacheableSteps(analysis);
    if (cacheableSteps.length > 0) {
      optimizations.push({
        type: 'caching',
        impact: 'medium',
        description: 'Implement caching for dependencies',
        steps: cacheableSteps,
        estimatedImprovement: '20-30% reduction in build time'
      });
    }
    
    // í…ŒìŠ¤íŠ¸ ìµœì í™”
    if (analysis.testDuration > analysis.totalDuration * 0.5) {
      optimizations.push({
        type: 'test_optimization',
        impact: 'high',
        description: 'Optimize test execution',
        recommendations: [
          'Run tests in parallel',
          'Implement test impact analysis',
          'Use test result caching'
        ],
        estimatedImprovement: '40-50% reduction in test time'
      });
    }
    
    return optimizations;
  }
}

// íŒŒì´í”„ë¼ì¸ ë¶„ì„ê¸°
export class PipelineAnalyzer {
  // íŒŒì´í”„ë¼ì¸ íš¨ìœ¨ì„± ë¶„ì„
  async analyzeEfficiency(
    executions: PipelineExecution[]
  ): Promise<EfficiencyReport> {
    const metrics = await this.calculateEfficiencyMetrics(executions);
    
    return {
      overall: {
        efficiency: metrics.efficiency,
        utilization: metrics.utilization,
        waste: metrics.waste
      },
      stages: await this.analyzeStageEfficiency(executions),
      bottlenecks: await this.identifyBottlenecks(executions),
      recommendations: this.generateEfficiencyRecommendations(metrics)
    };
  }
  
  // ë¹„ìš© ë¶„ì„
  async analyzeCosts(
    period: TimePeriod
  ): Promise<CostAnalysis> {
    const usage = await this.collectUsageData(period);
    
    return {
      total: this.calculateTotalCost(usage),
      breakdown: {
        compute: this.calculateComputeCost(usage),
        storage: this.calculateStorageCost(usage),
        network: this.calculateNetworkCost(usage),
        tools: this.calculateToolingCost(usage)
      },
      trends: await this.analyzeCostTrends(period),
      optimization: await this.findCostOptimizations(usage),
      forecast: await this.forecastCosts(usage)
    };
  }
}

// CI/CD ë©”íŠ¸ë¦­ ë¦¬í¬í„°
export class CICDReporter {
  async generateReport(
    period: ReportPeriod
  ): Promise<CICDReport> {
    const data = await this.collectReportData(period);
    
    return {
      summary: {
        totalPipelines: data.executions.length,
        successRate: this.calculateSuccessRate(data.executions),
        averageDuration: this.calculateAverageDuration(data.executions),
        deployments: data.deployments.length
      },
      pipelines: {
        mostRun: this.findMostRunPipelines(data),
        slowest: this.findSlowestPipelines(data),
        mostFailed: this.findMostFailedPipelines(data)
      },
      trends: {
        frequency: this.analyzeBuildFrequency(data),
        duration: this.analyzeDurationTrends(data),
        success: this.analyzeSuccessTrends(data)
      },
      costs: await this.analyzePeriodCosts(period),
      recommendations: await this.generateRecommendations(data)
    };
  }
}
```

ì´ë ‡ê²Œ Phase 1ì˜ 20ê°œ Tasks (ê° 4ê°œì˜ SubTasks)ê°€ ëª¨ë‘ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! 

ì „ì²´ êµ¬í˜„ ë‚´ìš©:
- **Task 1.1-1.4**: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´
- **Task 1.5-1.8**: Agno Framework í†µí•©
- **Task 1.9-1.11**: Bedrock ëŸ°íƒ€ì„ í™˜ê²½
- **Task 1.12-1.14**: ë°ì´í„° ì¸í”„ë¼
- **Task 1.15-1.17**: ì‹œìŠ¤í…œ ì¸í”„ë¼
- **Task 1.18-1.20**: í…ŒìŠ¤íŠ¸ ë° CI/CD

ê° TaskëŠ” ì‹¤ì œ êµ¬í˜„ ê°€ëŠ¥í•œ ìƒì„¸ ì½”ë“œì™€ í•¨ê»˜ ì‘ì„±ë˜ì—ˆìœ¼ë©°, AWS ì„œë¹„ìŠ¤ë“¤ê³¼ì˜ í†µí•©, ì—ëŸ¬ ì²˜ë¦¬, ëª¨ë‹ˆí„°ë§, ì„±ëŠ¥ ìµœì í™” ë“±ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.