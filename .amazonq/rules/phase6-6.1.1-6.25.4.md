í”„ë¡œì íŠ¸ ì§€ì‹ì„ í™•ì¸í•˜ì—¬ Phase 6ì˜ API ê²Œì´íŠ¸ì›¨ì´ êµ¬ì¶• (Tasks 6.1-6.5)ì— ëŒ€í•œ SubTask ë¦¬ìŠ¤íŠ¸ì™€ ì‘ì—…ì§€ì‹œì„œë¥¼ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.## Phase 6: API ê²Œì´íŠ¸ì›¨ì´ êµ¬ì¶• (Tasks 6.1-6.5) - SubTask ë¦¬ìŠ¤íŠ¸ ë° ì‘ì—…ì§€ì‹œì„œ

### ğŸ“‹ SubTask ì „ì²´ ë¦¬ìŠ¤íŠ¸

#### Task 6.1: API Gateway ì•„í‚¤í…ì²˜ ì„¤ê³„
- **SubTask 6.1.1**: ê²Œì´íŠ¸ì›¨ì´ íŒ¨í„´ ì„ íƒ ë° ì„¤ê³„
- **SubTask 6.1.2**: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í†µí•© ì•„í‚¤í…ì²˜
- **SubTask 6.1.3**: ê²Œì´íŠ¸ì›¨ì´ ê³„ì¸µ êµ¬ì¡° ì„¤ê³„
- **SubTask 6.1.4**: ê³ ê°€ìš©ì„± ë° ì¥ì•  ë³µêµ¬ ì„¤ê³„

#### Task 6.2: ë¼ìš°íŒ… ë° ì—”ë“œí¬ì¸íŠ¸ ê´€ë¦¬
- **SubTask 6.2.1**: ë™ì  ë¼ìš°íŒ… ì—”ì§„ êµ¬í˜„
- **SubTask 6.2.2**: ì—”ë“œí¬ì¸íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì‹œìŠ¤í…œ
- **SubTask 6.2.3**: ê²½ë¡œ ë§¤ì¹­ ë° íŒŒë¼ë¯¸í„° ì²˜ë¦¬
- **SubTask 6.2.4**: ë¼ìš°íŒ… ê·œì¹™ ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤

#### Task 6.3: ìš”ì²­/ì‘ë‹µ ë³€í™˜ ë ˆì´ì–´
- **SubTask 6.3.1**: ìš”ì²­ íŒŒì„œ ë° ê²€ì¦ê¸°
- **SubTask 6.3.2**: í”„ë¡œí† ì½œ ë³€í™˜ ì—”ì§„
- **SubTask 6.3.3**: ì‘ë‹µ í¬ë§·í„° ë° ì••ì¶•
- **SubTask 6.3.4**: ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸

#### Task 6.4: API ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ
- **SubTask 6.4.1**: ë²„ì „ ë¼ìš°íŒ… ì „ëµ êµ¬í˜„
- **SubTask 6.4.2**: í•˜ìœ„ í˜¸í™˜ì„± ê´€ë¦¬
- **SubTask 6.4.3**: ë²„ì „ ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬
- **SubTask 6.4.4**: ë²„ì „ë³„ ë¬¸ì„œ ìë™ ìƒì„±

#### Task 6.5: ê²Œì´íŠ¸ì›¨ì´ ë¡œë“œ ë°¸ëŸ°ì‹±
- **SubTask 6.5.1**: ë¡œë“œ ë°¸ëŸ°ì‹± ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
- **SubTask 6.5.2**: í—¬ìŠ¤ ì²´í¬ ë° ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬
- **SubTask 6.5.3**: íŠ¸ë˜í”½ ë¶„ì‚° ì •ì±… ì—”ì§„
- **SubTask 6.5.4**: ìë™ ìŠ¤ì¼€ì¼ë§ í†µí•©

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 6.1: API Gateway ì•„í‚¤í…ì²˜ ì„¤ê³„

#### SubTask 6.1.1: ê²Œì´íŠ¸ì›¨ì´ íŒ¨í„´ ì„ íƒ ë° ì„¤ê³„

**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api-gateway/architecture/gateway-pattern.ts
export enum GatewayPattern {
  BFF = 'Backend for Frontend',
  API_AGGREGATION = 'API Aggregation',
  PROXY = 'Simple Proxy',
  HYBRID = 'Hybrid Pattern'
}

export interface GatewayArchitecture {
  pattern: GatewayPattern;
  layers: GatewayLayer[];
  components: GatewayComponent[];
  integrations: ServiceIntegration[];
}

export class GatewayArchitectureDesigner {
  private pattern: GatewayPattern;
  private config: GatewayConfig;
  
  constructor(config: GatewayConfig) {
    this.config = config;
    this.pattern = this.selectOptimalPattern();
  }
  
  private selectOptimalPattern(): GatewayPattern {
    // T-Developerì˜ 9ê°œ ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ìµœì  íŒ¨í„´ ì„ íƒ
    if (this.config.clientTypes.length > 1) {
      return GatewayPattern.BFF; // ë‹¤ì–‘í•œ í´ë¼ì´ì–¸íŠ¸ ì§€ì›
    }
    if (this.config.services.length > 5) {
      return GatewayPattern.API_AGGREGATION; // ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì§‘í•©
    }
    return GatewayPattern.HYBRID;
  }
  
  async designArchitecture(): Promise<GatewayArchitecture> {
    return {
      pattern: this.pattern,
      layers: [
        {
          name: 'Security Layer',
          responsibilities: ['Authentication', 'Authorization', 'Rate Limiting'],
          components: ['JWT Validator', 'OAuth Provider', 'Rate Limiter']
        },
        {
          name: 'Routing Layer',
          responsibilities: ['Path Matching', 'Load Balancing', 'Service Discovery'],
          components: ['Router', 'Load Balancer', 'Service Registry']
        },
        {
          name: 'Transformation Layer',
          responsibilities: ['Request Transformation', 'Response Aggregation', 'Protocol Translation'],
          components: ['Request Parser', 'Response Formatter', 'Protocol Adapter']
        },
        {
          name: 'Integration Layer',
          responsibilities: ['Service Communication', 'Circuit Breaking', 'Retry Logic'],
          components: ['HTTP Client', 'Circuit Breaker', 'Retry Manager']
        }
      ],
      components: this.defineComponents(),
      integrations: this.defineIntegrations()
    };
  }
  
  private defineComponents(): GatewayComponent[] {
    return [
      {
        name: 'Agent Orchestrator',
        type: 'Core',
        description: '9ê°œ ì—ì´ì „íŠ¸ ê°„ í†µì‹  ì¡°ì •',
        interfaces: ['REST', 'GraphQL', 'WebSocket']
      },
      {
        name: 'Request Router',
        type: 'Routing',
        description: 'ìš”ì²­ì„ ì ì ˆí•œ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…',
        interfaces: ['HTTP', 'WebSocket']
      },
      {
        name: 'Response Aggregator',
        type: 'Processing',
        description: 'ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ì‘ë‹µ ì§‘ê³„',
        interfaces: ['JSON', 'Protocol Buffers']
      }
    ];
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] 9ê°œ ì—ì´ì „íŠ¸ í†µí•© ì§€ì›
- [ ] í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜
- [ ] ì„±ëŠ¥ ìµœì í™” ê³ ë ¤
- [ ] ì¥ì•  ê²©ë¦¬ ì„¤ê³„

#### SubTask 6.1.2: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í†µí•© ì•„í‚¤í…ì²˜

**ë‹´ë‹¹ì**: í†µí•© ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api_gateway/integration/microservice_integration.py
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import asyncio
from enum import Enum

@dataclass
class ServiceEndpoint:
    name: str
    url: str
    health_check: str
    timeout: int
    retry_policy: RetryPolicy
    circuit_breaker_config: CircuitBreakerConfig

class ServiceIntegrationType(Enum):
    SYNCHRONOUS = "sync"
    ASYNCHRONOUS = "async"
    EVENT_DRIVEN = "event"
    STREAMING = "stream"

class MicroserviceIntegrator:
    """9ê°œ ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ í†µí•© ê´€ë¦¬"""
    
    def __init__(self):
        self.services = self._initialize_services()
        self.discovery_client = ServiceDiscoveryClient()
        self.circuit_breakers = {}
        self.connection_pools = {}
        
    def _initialize_services(self) -> Dict[str, ServiceEndpoint]:
        """T-Developer ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        return {
            'nl_input': ServiceEndpoint(
                name='NL Input Agent',
                url='http://nl-input-service:8001',
                health_check='/health',
                timeout=30000,
                retry_policy=RetryPolicy(max_attempts=3, backoff='exponential'),
                circuit_breaker_config=CircuitBreakerConfig(
                    failure_threshold=5,
                    timeout=60000,
                    half_open_requests=3
                )
            ),
            'ui_selection': ServiceEndpoint(
                name='UI Selection Agent',
                url='http://ui-selection-service:8002',
                health_check='/health',
                timeout=20000,
                retry_policy=RetryPolicy(max_attempts=2),
                circuit_breaker_config=CircuitBreakerConfig()
            ),
            'parser': ServiceEndpoint(
                name='Parser Agent',
                url='http://parser-service:8003',
                health_check='/health',
                timeout=25000,
                retry_policy=RetryPolicy(max_attempts=3),
                circuit_breaker_config=CircuitBreakerConfig()
            ),
            # ... ë‚˜ë¨¸ì§€ 6ê°œ ì—ì´ì „íŠ¸
        }
    
    async def integrate_service(
        self, 
        service_name: str,
        integration_type: ServiceIntegrationType
    ) -> ServiceConnection:
        """ì„œë¹„ìŠ¤ í†µí•© ì„¤ì •"""
        
        service = self.services.get(service_name)
        if not service:
            raise ServiceNotFoundError(f"Service {service_name} not found")
        
        # ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ë¡œ ì‹¤ì œ ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
        actual_endpoint = await self.discovery_client.discover(service_name)
        if actual_endpoint:
            service.url = actual_endpoint
        
        # Circuit Breaker ì„¤ì •
        if service_name not in self.circuit_breakers:
            self.circuit_breakers[service_name] = CircuitBreaker(
                service.circuit_breaker_config
            )
        
        # Connection Pool ì„¤ì •
        if service_name not in self.connection_pools:
            self.connection_pools[service_name] = ConnectionPool(
                max_connections=100,
                min_connections=10,
                connection_timeout=5000
            )
        
        # í†µí•© íƒ€ì…ë³„ ì„¤ì •
        if integration_type == ServiceIntegrationType.STREAMING:
            return await self._setup_streaming_connection(service)
        elif integration_type == ServiceIntegrationType.EVENT_DRIVEN:
            return await self._setup_event_connection(service)
        else:
            return await self._setup_http_connection(service)
    
    async def _setup_streaming_connection(
        self, 
        service: ServiceEndpoint
    ) -> StreamingConnection:
        """WebSocket/SSE ìŠ¤íŠ¸ë¦¬ë° ì—°ê²°"""
        return StreamingConnection(
            url=service.url.replace('http://', 'ws://') + '/stream',
            heartbeat_interval=30000,
            reconnect_policy=ReconnectPolicy(
                max_attempts=5,
                initial_delay=1000,
                max_delay=30000
            )
        )
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ëª¨ë“  ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ í†µí•©
- [ ] ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ êµ¬í˜„
- [ ] Circuit Breaker íŒ¨í„´ ì ìš©
- [ ] Connection Pool ê´€ë¦¬

#### SubTask 6.1.3: ê²Œì´íŠ¸ì›¨ì´ ê³„ì¸µ êµ¬ì¡° ì„¤ê³„

**ë‹´ë‹¹ì**: ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api-gateway/layers/layer-architecture.ts
export interface LayerDefinition {
  name: string;
  order: number;
  responsibilities: string[];
  middlewares: Middleware[];
  errorHandlers: ErrorHandler[];
}

export class GatewayLayerArchitecture {
  private layers: Map<string, LayerDefinition>;
  
  constructor() {
    this.layers = new Map();
    this.initializeLayers();
  }
  
  private initializeLayers(): void {
    // 1. ì§„ì…ì  ê³„ì¸µ
    this.addLayer({
      name: 'Entry Layer',
      order: 1,
      responsibilities: [
        'Request reception',
        'Initial validation',
        'Request ID generation',
        'Request logging'
      ],
      middlewares: [
        new RequestIdMiddleware(),
        new RequestLoggerMiddleware(),
        new RequestValidationMiddleware()
      ],
      errorHandlers: [
        new BadRequestHandler(),
        new ValidationErrorHandler()
      ]
    });
    
    // 2. ë³´ì•ˆ ê³„ì¸µ
    this.addLayer({
      name: 'Security Layer',
      order: 2,
      responsibilities: [
        'Authentication',
        'Authorization',
        'Rate limiting',
        'DDoS protection'
      ],
      middlewares: [
        new AuthenticationMiddleware(),
        new AuthorizationMiddleware(),
        new RateLimitMiddleware(),
        new DDoSProtectionMiddleware()
      ],
      errorHandlers: [
        new UnauthorizedHandler(),
        new ForbiddenHandler(),
        new RateLimitExceededHandler()
      ]
    });
    
    // 3. ë³€í™˜ ê³„ì¸µ
    this.addLayer({
      name: 'Transformation Layer',
      order: 3,
      responsibilities: [
        'Request transformation',
        'Protocol conversion',
        'Data validation',
        'Schema validation'
      ],
      middlewares: [
        new RequestTransformerMiddleware(),
        new ProtocolConverterMiddleware(),
        new SchemaValidatorMiddleware()
      ],
      errorHandlers: [
        new TransformationErrorHandler(),
        new SchemaValidationErrorHandler()
      ]
    });
    
    // 4. ë¼ìš°íŒ… ê³„ì¸µ
    this.addLayer({
      name: 'Routing Layer',
      order: 4,
      responsibilities: [
        'Path matching',
        'Service resolution',
        'Load balancing',
        'Request forwarding'
      ],
      middlewares: [
        new PathMatcherMiddleware(),
        new ServiceResolverMiddleware(),
        new LoadBalancerMiddleware(),
        new RequestForwarderMiddleware()
      ],
      errorHandlers: [
        new ServiceNotFoundHandler(),
        new ServiceUnavailableHandler()
      ]
    });
    
    // 5. í†µí•© ê³„ì¸µ
    this.addLayer({
      name: 'Integration Layer',
      order: 5,
      responsibilities: [
        'Service communication',
        'Response aggregation',
        'Error handling',
        'Retry logic'
      ],
      middlewares: [
        new ServiceClientMiddleware(),
        new ResponseAggregatorMiddleware(),
        new RetryMiddleware(),
        new CircuitBreakerMiddleware()
      ],
      errorHandlers: [
        new ServiceTimeoutHandler(),
        new CircuitOpenHandler()
      ]
    });
    
    // 6. ì‘ë‹µ ê³„ì¸µ
    this.addLayer({
      name: 'Response Layer',
      order: 6,
      responsibilities: [
        'Response formatting',
        'Response caching',
        'Compression',
        'Response logging'
      ],
      middlewares: [
        new ResponseFormatterMiddleware(),
        new ResponseCacheMiddleware(),
        new CompressionMiddleware(),
        new ResponseLoggerMiddleware()
      ],
      errorHandlers: [
        new InternalServerErrorHandler(),
        new GenericErrorHandler()
      ]
    });
  }
  
  async processRequest(request: GatewayRequest): Promise<GatewayResponse> {
    let context = new RequestContext(request);
    
    // ìˆœì„œëŒ€ë¡œ ê° ê³„ì¸µ ì²˜ë¦¬
    const sortedLayers = Array.from(this.layers.values())
      .sort((a, b) => a.order - b.order);
    
    for (const layer of sortedLayers) {
      try {
        context = await this.processLayer(layer, context);
      } catch (error) {
        return await this.handleLayerError(layer, error, context);
      }
    }
    
    return context.response;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ëª…í™•í•œ ê³„ì¸µ ë¶„ë¦¬
- [ ] ê° ê³„ì¸µ ì±…ì„ ì •ì˜
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ
- [ ] ë¯¸ë“¤ì›¨ì–´ ì²´ì¸ êµ¬ì„±

#### SubTask 6.1.4: ê³ ê°€ìš©ì„± ë° ì¥ì•  ë³µêµ¬ ì„¤ê³„

**ë‹´ë‹¹ì**: ì¸í”„ë¼ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api_gateway/ha/high_availability.py
from typing import List, Dict, Optional, Set
import asyncio
from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class HAConfiguration:
    """ê³ ê°€ìš©ì„± êµ¬ì„±"""
    cluster_size: int = 3
    min_healthy_nodes: int = 2
    health_check_interval: int = 5000  # ms
    failover_timeout: int = 30000  # ms
    data_sync_interval: int = 1000  # ms
    leader_election_timeout: int = 5000  # ms

class HighAvailabilityManager:
    """API Gateway ê³ ê°€ìš©ì„± ê´€ë¦¬"""
    
    def __init__(self, config: HAConfiguration):
        self.config = config
        self.cluster_nodes: Dict[str, GatewayNode] = {}
        self.leader_node: Optional[str] = None
        self.state_store = DistributedStateStore()
        self.health_monitor = HealthMonitor()
        self.failover_manager = FailoverManager()
        
    async def initialize_cluster(self) -> None:
        """HA í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™”"""
        
        # 1. í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ì´ˆê¸°í™”
        for i in range(self.config.cluster_size):
            node = GatewayNode(
                id=f"gateway-node-{i}",
                role=NodeRole.FOLLOWER,
                status=NodeStatus.INITIALIZING
            )
            self.cluster_nodes[node.id] = node
            
        # 2. ë¦¬ë” ì„ ì¶œ
        await self.elect_leader()
        
        # 3. ìƒíƒœ ë™ê¸°í™” ì‹œì‘
        asyncio.create_task(self.sync_cluster_state())
        
        # 4. í—¬ìŠ¤ ì²´í¬ ì‹œì‘
        asyncio.create_task(self.monitor_health())
        
    async def elect_leader(self) -> None:
        """ë¦¬ë” ë…¸ë“œ ì„ ì¶œ (Raft ì•Œê³ ë¦¬ì¦˜)"""
        
        election = LeaderElection(
            nodes=list(self.cluster_nodes.values()),
            timeout=self.config.leader_election_timeout
        )
        
        leader_id = await election.elect()
        self.leader_node = leader_id
        
        # ë¦¬ë” ë…¸ë“œ ì—­í•  ì—…ë°ì´íŠ¸
        if leader_id in self.cluster_nodes:
            self.cluster_nodes[leader_id].role = NodeRole.LEADER
            
        # ì´ë²¤íŠ¸ ë°œìƒ
        await self.emit_event(LeaderElectedEvent(leader_id))
        
    async def handle_node_failure(self, failed_node_id: str) -> None:
        """ë…¸ë“œ ì¥ì•  ì²˜ë¦¬"""
        
        failed_node = self.cluster_nodes.get(failed_node_id)
        if not failed_node:
            return
            
        # 1. ë…¸ë“œ ìƒíƒœ ì—…ë°ì´íŠ¸
        failed_node.status = NodeStatus.FAILED
        failed_node.last_failure = datetime.now()
        
        # 2. ë¦¬ë” ë…¸ë“œ ì¥ì•  ì‹œ ì¬ì„ ì¶œ
        if failed_node_id == self.leader_node:
            await self.elect_leader()
            
        # 3. íŠ¸ë˜í”½ ì¬ë¶„ë°°
        await self.redistribute_traffic(failed_node_id)
        
        # 4. ì¥ì•  ë³µêµ¬ ì‹œì‘
        asyncio.create_task(self.recover_failed_node(failed_node_id))
        
    async def redistribute_traffic(self, excluded_node: str) -> None:
        """íŠ¸ë˜í”½ ì¬ë¶„ë°°"""
        
        healthy_nodes = [
            node for node_id, node in self.cluster_nodes.items()
            if node_id != excluded_node and node.status == NodeStatus.HEALTHY
        ]
        
        if len(healthy_nodes) < self.config.min_healthy_nodes:
            # ìµœì†Œ ë…¸ë“œ ìˆ˜ ë¯¸ë‹¬ ì‹œ ê²½ê³ 
            await self.emit_alert(ClusterDegradedAlert(
                healthy_count=len(healthy_nodes),
                required_count=self.config.min_healthy_nodes
            ))
            
        # ë¡œë“œ ë°¸ëŸ°ì„œ ì—…ë°ì´íŠ¸
        await self.update_load_balancer(healthy_nodes)
        
    async def recover_failed_node(self, node_id: str) -> None:
        """ì¥ì•  ë…¸ë“œ ë³µêµ¬"""
        
        recovery_strategy = NodeRecoveryStrategy(
            max_attempts=5,
            backoff_multiplier=2,
            initial_delay=5000
        )
        
        attempt = 0
        while attempt < recovery_strategy.max_attempts:
            try:
                # 1. ë…¸ë“œ ì¬ì‹œì‘
                await self.restart_node(node_id)
                
                # 2. í—¬ìŠ¤ ì²´í¬
                if await self.health_monitor.check_node(node_id):
                    # 3. í´ëŸ¬ìŠ¤í„° ì¬í•©ë¥˜
                    await self.rejoin_cluster(node_id)
                    
                    # 4. ìƒíƒœ ë™ê¸°í™”
                    await self.sync_node_state(node_id)
                    
                    # 5. íŠ¸ë˜í”½ ì¬í™œì„±í™”
                    await self.enable_traffic(node_id)
                    
                    return
                    
            except Exception as e:
                attempt += 1
                delay = recovery_strategy.get_delay(attempt)
                await asyncio.sleep(delay / 1000)
                
        # ë³µêµ¬ ì‹¤íŒ¨ ì‹œ ë…¸ë“œ ì œê±°
        await self.remove_node(node_id)
        
    async def sync_cluster_state(self) -> None:
        """í´ëŸ¬ìŠ¤í„° ìƒíƒœ ë™ê¸°í™”"""
        
        while True:
            try:
                # ë¶„ì‚° ìƒíƒœ ì €ì¥ì†Œ ë™ê¸°í™”
                state = await self.collect_cluster_state()
                await self.state_store.update(state)
                
                # ê° ë…¸ë“œì— ìƒíƒœ ì „íŒŒ
                await self.propagate_state(state)
                
            except Exception as e:
                await self.handle_sync_error(e)
                
            await asyncio.sleep(self.config.data_sync_interval / 1000)
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] í´ëŸ¬ìŠ¤í„° êµ¬ì„± ë° ê´€ë¦¬
- [ ] ë¦¬ë” ì„ ì¶œ ë©”ì»¤ë‹ˆì¦˜
- [ ] ìë™ ì¥ì•  ë³µêµ¬
- [ ] ìƒíƒœ ë™ê¸°í™” ì „ëµ

---

### Task 6.2: ë¼ìš°íŒ… ë° ì—”ë“œí¬ì¸íŠ¸ ê´€ë¦¬

#### SubTask 6.2.1: ë™ì  ë¼ìš°íŒ… ì—”ì§„ êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api-gateway/routing/dynamic-router.ts
export interface Route {
  id: string;
  path: string;
  method: string | string[];
  handler: RouteHandler;
  middleware?: Middleware[];
  metadata?: RouteMetadata;
  priority?: number;
  constraints?: RouteConstraints;
}

export class DynamicRoutingEngine {
  private routes: Map<string, Route> = new Map();
  private routeTree: RadixTree<Route>;
  private dynamicRoutes: Set<string> = new Set();
  
  constructor() {
    this.routeTree = new RadixTree();
    this.initializeDefaultRoutes();
  }
  
  async addRoute(route: Route): Promise<void> {
    // ê²½ë¡œ ì •ê·œí™”
    const normalizedPath = this.normalizePath(route.path);
    
    // ê²½ë¡œ íŠ¸ë¦¬ì— ì¶”ê°€
    this.routeTree.insert(normalizedPath, route);
    
    // ë¼ìš°íŠ¸ ë§µì— ì¶”ê°€
    this.routes.set(route.id, route);
    
    // ë™ì  ë¼ìš°íŠ¸ í‘œì‹œ
    if (this.isDynamicRoute(route)) {
      this.dynamicRoutes.add(route.id);
    }
    
    // ë¼ìš°íŠ¸ ìºì‹œ ë¬´íš¨í™”
    await this.invalidateRouteCache();
  }
  
  async removeRoute(routeId: string): Promise<void> {
    const route = this.routes.get(routeId);
    if (!route) return;
    
    // íŠ¸ë¦¬ì—ì„œ ì œê±°
    this.routeTree.remove(route.path);
    
    // ë§µì—ì„œ ì œê±°
    this.routes.delete(routeId);
    this.dynamicRoutes.delete(routeId);
    
    // ìºì‹œ ë¬´íš¨í™”
    await this.invalidateRouteCache();
  }
  
  async match(request: IncomingRequest): Promise<RouteMatch | null> {
    const path = request.path;
    const method = request.method;
    
    // 1. ì •í™•í•œ ë§¤ì¹­ ì‹œë„
    let matches = this.routeTree.lookup(path);
    
    // 2. ì™€ì¼ë“œì¹´ë“œ ë§¤ì¹­
    if (!matches.length) {
      matches = this.routeTree.lookupWildcard(path);
    }
    
    // 3. ë©”ì„œë“œ í•„í„°ë§
    matches = matches.filter(route => 
      this.matchMethod(route, method)
    );
    
    // 4. ì œì•½ ì¡°ê±´ ê²€ì¦
    matches = await this.validateConstraints(matches, request);
    
    // 5. ìš°ì„ ìˆœìœ„ ì •ë ¬
    matches.sort((a, b) => (b.priority || 0) - (a.priority || 0));
    
    if (matches.length === 0) {
      return null;
    }
    
    const selectedRoute = matches[0];
    
    // 6. íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    const params = this.extractParams(selectedRoute.path, path);
    
    return {
      route: selectedRoute,
      params,
      query: request.query,
      metadata: await this.enrichMetadata(selectedRoute, request)
    };
  }
  
  private extractParams(pattern: string, path: string): Record<string, string> {
    const params: Record<string, string> = {};
    
    // /users/:id/posts/:postId í˜•ì‹ íŒŒì‹±
    const patternParts = pattern.split('/');
    const pathParts = path.split('/');
    
    for (let i = 0; i < patternParts.length; i++) {
      const part = patternParts[i];
      if (part.startsWith(':')) {
        const paramName = part.substring(1);
        params[paramName] = pathParts[i];
      }
    }
    
    return params;
  }
  
  async updateRouteHandler(routeId: string, handler: RouteHandler): Promise<void> {
    const route = this.routes.get(routeId);
    if (!route) {
      throw new RouteNotFoundError(routeId);
    }
    
    // í•¸ë“¤ëŸ¬ ì—…ë°ì´íŠ¸
    route.handler = handler;
    
    // íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
    this.routeTree.update(route.path, route);
    
    // ë™ì  ë¼ìš°íŠ¸ í‘œì‹œ
    this.dynamicRoutes.add(routeId);
    
    // ì´ë²¤íŠ¸ ë°œìƒ
    await this.emit('route:updated', { routeId, route });
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë™ì  ë¼ìš°íŠ¸ ì¶”ê°€/ì œê±°
- [ ] íš¨ìœ¨ì ì¸ ê²½ë¡œ ë§¤ì¹­
- [ ] íŒŒë¼ë¯¸í„° ì¶”ì¶œ
- [ ] ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë¼ìš°íŒ…

---

## Task 6.2: ë¼ìš°íŒ… ë° ì—”ë“œí¬ì¸íŠ¸ ê´€ë¦¬ (ê³„ì†)

### SubTask 6.2.2: ì—”ë“œí¬ì¸íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì‹œìŠ¤í…œ

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api_gateway/registry/endpoint_registry.py
from typing import Dict, List, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime
import asyncio
from enum import Enum

@dataclass
class EndpointDefinition:
    """ì—”ë“œí¬ì¸íŠ¸ ì •ì˜"""
    id: str
    service: str  # ë‹´ë‹¹ ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤
    path: str
    method: str
    version: str
    deprecated: bool = False
    deprecation_date: Optional[datetime] = None
    replacement: Optional[str] = None
    documentation: Optional[str] = None
    rate_limit: Optional[RateLimit] = None
    auth_required: bool = True
    scopes: List[str] = field(default_factory=list)
    tags: Set[str] = field(default_factory=set)
    metadata: Dict[str, Any] = field(default_factory=dict)

class EndpointRegistry:
    """T-Developer ì—ì´ì „íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬"""
    
    def __init__(self):
        self.endpoints: Dict[str, EndpointDefinition] = {}
        self.service_endpoints: Dict[str, List[str]] = {}
        self.version_map: Dict[str, Set[str]] = {}
        self.deprecated_endpoints: Set[str] = set()
        self.watchers: List[EndpointWatcher] = []
        
    async def register_endpoint(self, endpoint: EndpointDefinition) -> None:
        """ì—”ë“œí¬ì¸íŠ¸ ë“±ë¡"""
        
        # 1. ìœ íš¨ì„± ê²€ì¦
        await self.validate_endpoint(endpoint)
        
        # 2. ì¤‘ë³µ ì²´í¬
        if self.is_duplicate(endpoint):
            raise DuplicateEndpointError(f"Endpoint {endpoint.path} already exists")
        
        # 3. ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì¶”ê°€
        self.endpoints[endpoint.id] = endpoint
        
        # 4. ì„œë¹„ìŠ¤ë³„ ì¸ë±ì‹±
        if endpoint.service not in self.service_endpoints:
            self.service_endpoints[endpoint.service] = []
        self.service_endpoints[endpoint.service].append(endpoint.id)
        
        # 5. ë²„ì „ë³„ ì¸ë±ì‹±
        if endpoint.version not in self.version_map:
            self.version_map[endpoint.version] = set()
        self.version_map[endpoint.version].add(endpoint.id)
        
        # 6. Deprecated ì¶”ì 
        if endpoint.deprecated:
            self.deprecated_endpoints.add(endpoint.id)
            
        # 7. ê°ì‹œì ì•Œë¦¼
        await self.notify_watchers('endpoint_registered', endpoint)
        
    async def discover_endpoints(
        self, 
        filters: Optional[EndpointFilter] = None
    ) -> List[EndpointDefinition]:
        """ì—”ë“œí¬ì¸íŠ¸ ê²€ìƒ‰"""
        
        results = list(self.endpoints.values())
        
        if filters:
            # ì„œë¹„ìŠ¤ í•„í„°
            if filters.service:
                results = [e for e in results if e.service == filters.service]
                
            # ë²„ì „ í•„í„°
            if filters.version:
                results = [e for e in results if e.version == filters.version]
                
            # íƒœê·¸ í•„í„°
            if filters.tags:
                results = [e for e in results if filters.tags.issubset(e.tags)]
                
            # Deprecated ì œì™¸
            if filters.exclude_deprecated:
                results = [e for e in results if not e.deprecated]
                
            # ì¸ì¦ í•„ìš” ì—¬ë¶€
            if filters.auth_required is not None:
                results = [e for e in results if e.auth_required == filters.auth_required]
                
        return results
    
    async def get_service_endpoints(self, service: str) -> List[EndpointDefinition]:
        """íŠ¹ì • ì„œë¹„ìŠ¤ì˜ ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸"""
        
        endpoint_ids = self.service_endpoints.get(service, [])
        return [self.endpoints[eid] for eid in endpoint_ids if eid in self.endpoints]
    
    async def update_endpoint(
        self, 
        endpoint_id: str, 
        updates: Dict[str, Any]
    ) -> EndpointDefinition:
        """ì—”ë“œí¬ì¸íŠ¸ ì—…ë°ì´íŠ¸"""
        
        if endpoint_id not in self.endpoints:
            raise EndpointNotFoundError(f"Endpoint {endpoint_id} not found")
            
        endpoint = self.endpoints[endpoint_id]
        
        # í—ˆìš©ëœ í•„ë“œë§Œ ì—…ë°ì´íŠ¸
        allowed_fields = {
            'documentation', 'rate_limit', 'auth_required', 
            'scopes', 'tags', 'metadata', 'deprecated', 
            'deprecation_date', 'replacement'
        }
        
        for field, value in updates.items():
            if field in allowed_fields:
                setattr(endpoint, field, value)
                
        # Deprecated ìƒíƒœ ì—…ë°ì´íŠ¸
        if 'deprecated' in updates:
            if updates['deprecated']:
                self.deprecated_endpoints.add(endpoint_id)
            else:
                self.deprecated_endpoints.discard(endpoint_id)
                
        # ë³€ê²½ ì•Œë¦¼
        await self.notify_watchers('endpoint_updated', endpoint)
        
        return endpoint
    
    async def deprecate_endpoint(
        self, 
        endpoint_id: str,
        deprecation_date: datetime,
        replacement: Optional[str] = None
    ) -> None:
        """ì—”ë“œí¬ì¸íŠ¸ Deprecation"""
        
        await self.update_endpoint(endpoint_id, {
            'deprecated': True,
            'deprecation_date': deprecation_date,
            'replacement': replacement
        })
        
        # Deprecation ì•Œë¦¼
        endpoint = self.endpoints[endpoint_id]
        await self.notify_watchers('endpoint_deprecated', endpoint)
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì—”ë“œí¬ì¸íŠ¸ ë“±ë¡/ì¡°íšŒ/ì—…ë°ì´íŠ¸
- [ ] ì„œë¹„ìŠ¤ë³„ ê·¸ë£¹í•‘
- [ ] ë²„ì „ ê´€ë¦¬
- [ ] Deprecation ì²˜ë¦¬

### SubTask 6.2.3: ê²½ë¡œ ë§¤ì¹­ ë° íŒŒë¼ë¯¸í„° ì²˜ë¦¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api-gateway/routing/path-matcher.ts
export class PathMatcher {
  private patterns: Map<string, CompiledPattern> = new Map();
  private cache: LRUCache<string, MatchResult>;
  
  constructor() {
    this.cache = new LRUCache({ max: 10000 });
  }
  
  compile(pattern: string): CompiledPattern {
    // ìºì‹œ í™•ì¸
    if (this.patterns.has(pattern)) {
      return this.patterns.get(pattern)!;
    }
    
    const compiled = this.compilePattern(pattern);
    this.patterns.set(pattern, compiled);
    return compiled;
  }
  
  private compilePattern(pattern: string): CompiledPattern {
    // íŒŒë¼ë¯¸í„° íŒ¨í„´ ë¶„ì„
    // /users/:id/posts/:postId -> /users/([^/]+)/posts/([^/]+)
    
    const segments: PathSegment[] = [];
    const params: string[] = [];
    let regexStr = '^';
    
    const parts = pattern.split('/').filter(p => p.length > 0);
    
    for (const part of parts) {
      if (part.startsWith(':')) {
        // íŒŒë¼ë¯¸í„°
        const paramName = part.substring(1);
        params.push(paramName);
        segments.push({
          type: 'param',
          name: paramName,
          pattern: '([^/]+)'
        });
        regexStr += '/([^/]+)';
      } else if (part === '*') {
        // ì™€ì¼ë“œì¹´ë“œ
        segments.push({
          type: 'wildcard',
          pattern: '.*'
        });
        regexStr += '/.*';
      } else if (part.includes('*')) {
        // ë¶€ë¶„ ì™€ì¼ë“œì¹´ë“œ (ì˜ˆ: *.json)
        const escapedPart = part.replace('*', '.*');
        segments.push({
          type: 'pattern',
          pattern: escapedPart
        });
        regexStr += '/' + escapedPart;
      } else {
        // ì •ì  ì„¸ê·¸ë¨¼íŠ¸
        segments.push({
          type: 'static',
          value: part
        });
        regexStr += '/' + this.escapeRegex(part);
      }
    }
    
    regexStr += '$';
    
    return {
      original: pattern,
      regex: new RegExp(regexStr),
      segments,
      params,
      priority: this.calculatePriority(segments)
    };
  }
  
  match(path: string, pattern: string | CompiledPattern): MatchResult | null {
    // ìºì‹œ í™•ì¸
    const cacheKey = `${path}:${typeof pattern === 'string' ? pattern : pattern.original}`;
    if (this.cache.has(cacheKey)) {
      return this.cache.get(cacheKey)!;
    }
    
    const compiled = typeof pattern === 'string' 
      ? this.compile(pattern) 
      : pattern;
    
    const matches = path.match(compiled.regex);
    
    if (!matches) {
      this.cache.set(cacheKey, null);
      return null;
    }
    
    // íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    const params: Record<string, string> = {};
    for (let i = 0; i < compiled.params.length; i++) {
      params[compiled.params[i]] = decodeURIComponent(matches[i + 1]);
    }
    
    const result: MatchResult = {
      matched: true,
      pattern: compiled.original,
      path,
      params,
      wildcards: this.extractWildcards(path, compiled, matches)
    };
    
    this.cache.set(cacheKey, result);
    return result;
  }
  
  matchBest(path: string, patterns: string[]): MatchResult | null {
    const candidates: Array<{
      result: MatchResult;
      priority: number;
    }> = [];
    
    for (const pattern of patterns) {
      const result = this.match(path, pattern);
      if (result) {
        const compiled = this.compile(pattern);
        candidates.push({
          result,
          priority: compiled.priority
        });
      }
    }
    
    if (candidates.length === 0) {
      return null;
    }
    
    // ìš°ì„ ìˆœìœ„ê°€ ê°€ì¥ ë†’ì€ ê²ƒ ì„ íƒ
    candidates.sort((a, b) => b.priority - a.priority);
    return candidates[0].result;
  }
  
  private calculatePriority(segments: PathSegment[]): number {
    let priority = 0;
    
    for (const segment of segments) {
      switch (segment.type) {
        case 'static':
          priority += 1000;  // ì •ì  ì„¸ê·¸ë¨¼íŠ¸ ìš°ì„ 
          break;
        case 'param':
          priority += 100;   // íŒŒë¼ë¯¸í„°
          break;
        case 'pattern':
          priority += 10;    // íŒ¨í„´ ë§¤ì¹­
          break;
        case 'wildcard':
          priority += 1;     // ì™€ì¼ë“œì¹´ë“œ ìµœí•˜ìœ„
          break;
      }
    }
    
    return priority;
  }
}

// íŒŒë¼ë¯¸í„° ì²˜ë¦¬ê¸°
export class ParameterProcessor {
  private validators: Map<string, ParameterValidator> = new Map();
  private transformers: Map<string, ParameterTransformer> = new Map();
  
  async processParameters(
    params: Record<string, string>,
    schema: ParameterSchema
  ): Promise<ProcessedParameters> {
    const processed: ProcessedParameters = {
      values: {},
      errors: []
    };
    
    for (const [name, value] of Object.entries(params)) {
      const paramSchema = schema.parameters[name];
      
      if (!paramSchema) {
        // ìŠ¤í‚¤ë§ˆì— ì •ì˜ë˜ì§€ ì•Šì€ íŒŒë¼ë¯¸í„°
        if (schema.strict) {
          processed.errors.push({
            param: name,
            error: 'Unknown parameter'
          });
        }
        continue;
      }
      
      try {
        // 1. íƒ€ì… ë³€í™˜
        let converted = await this.convertType(value, paramSchema.type);
        
        // 2. ê²€ì¦
        if (paramSchema.validators) {
          for (const validatorName of paramSchema.validators) {
            const validator = this.validators.get(validatorName);
            if (validator) {
              await validator.validate(converted, paramSchema);
            }
          }
        }
        
        // 3. ë³€í™˜
        if (paramSchema.transformer) {
          const transformer = this.transformers.get(paramSchema.transformer);
          if (transformer) {
            converted = await transformer.transform(converted);
          }
        }
        
        processed.values[name] = converted;
        
      } catch (error) {
        processed.errors.push({
          param: name,
          error: error.message
        });
      }
    }
    
    // í•„ìˆ˜ íŒŒë¼ë¯¸í„° ì²´í¬
    for (const [name, paramSchema] of Object.entries(schema.parameters)) {
      if (paramSchema.required && !(name in processed.values)) {
        processed.errors.push({
          param: name,
          error: 'Required parameter missing'
        });
      }
    }
    
    return processed;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] íš¨ìœ¨ì ì¸ ê²½ë¡œ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜
- [ ] íŒŒë¼ë¯¸í„° ì¶”ì¶œ ë° ê²€ì¦
- [ ] ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë§¤ì¹­
- [ ] ìºì‹± ë©”ì»¤ë‹ˆì¦˜

### SubTask 6.2.4: ë¼ìš°íŒ… ê·œì¹™ ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤

**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api_gateway/routing/rule_manager.py
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from enum import Enum
import json

@dataclass
class RoutingRule:
    """ë¼ìš°íŒ… ê·œì¹™"""
    id: str
    name: str
    description: str
    condition: RuleCondition
    action: RuleAction
    priority: int
    enabled: bool = True
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)

class RoutingRuleManager:
    """ë¼ìš°íŒ… ê·œì¹™ ê´€ë¦¬"""
    
    def __init__(self):
        self.rules: Dict[str, RoutingRule] = {}
        self.rule_engine = RuleEngine()
        self.rule_store = RuleStore()
        self.audit_logger = AuditLogger()
        
    async def create_rule(self, rule_spec: Dict[str, Any]) -> RoutingRule:
        """ë¼ìš°íŒ… ê·œì¹™ ìƒì„±"""
        
        # 1. ê·œì¹™ ìƒì„±
        rule = RoutingRule(
            id=generate_rule_id(),
            name=rule_spec['name'],
            description=rule_spec.get('description', ''),
            condition=self.parse_condition(rule_spec['condition']),
            action=self.parse_action(rule_spec['action']),
            priority=rule_spec.get('priority', 100),
            enabled=rule_spec.get('enabled', True)
        )
        
        # 2. ìœ íš¨ì„± ê²€ì¦
        await self.validate_rule(rule)
        
        # 3. ì¶©ëŒ ê²€ì‚¬
        conflicts = await self.check_conflicts(rule)
        if conflicts:
            raise RuleConflictError(f"Rule conflicts with: {conflicts}")
        
        # 4. ì €ì¥
        self.rules[rule.id] = rule
        await self.rule_store.save(rule)
        
        # 5. ì—”ì§„ì— ë“±ë¡
        await self.rule_engine.register(rule)
        
        # 6. ê°ì‚¬ ë¡œê·¸
        await self.audit_logger.log('rule_created', {
            'rule_id': rule.id,
            'name': rule.name,
            'user': get_current_user()
        })
        
        return rule
    
    async def update_rule(
        self, 
        rule_id: str, 
        updates: Dict[str, Any]
    ) -> RoutingRule:
        """ë¼ìš°íŒ… ê·œì¹™ ì—…ë°ì´íŠ¸"""
        
        if rule_id not in self.rules:
            raise RuleNotFoundError(f"Rule {rule_id} not found")
        
        rule = self.rules[rule_id]
        original = copy.deepcopy(rule)
        
        # ì—…ë°ì´íŠ¸ ì ìš©
        for field, value in updates.items():
            if hasattr(rule, field):
                setattr(rule, field, value)
        
        rule.updated_at = datetime.now()
        
        # ìœ íš¨ì„± ì¬ê²€ì¦
        await self.validate_rule(rule)
        
        # ì—”ì§„ ì—…ë°ì´íŠ¸
        await self.rule_engine.update(rule)
        
        # ì €ì¥
        await self.rule_store.save(rule)
        
        # ê°ì‚¬ ë¡œê·¸
        await self.audit_logger.log('rule_updated', {
            'rule_id': rule.id,
            'changes': self.diff_rules(original, rule),
            'user': get_current_user()
        })
        
        return rule
    
    async def evaluate_rules(
        self, 
        request: IncomingRequest
    ) -> List[RuleEvaluation]:
        """ìš”ì²­ì— ëŒ€í•œ ê·œì¹™ í‰ê°€"""
        
        evaluations = []
        
        # í™œì„±í™”ëœ ê·œì¹™ë§Œ í‰ê°€
        active_rules = [
            rule for rule in self.rules.values() 
            if rule.enabled
        ]
        
        # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬
        active_rules.sort(key=lambda r: r.priority, reverse=True)
        
        for rule in active_rules:
            evaluation = await self.rule_engine.evaluate(rule, request)
            evaluations.append(evaluation)
            
            # ì²« ë²ˆì§¸ ë§¤ì¹­ ê·œì¹™ì—ì„œ ì¤‘ë‹¨ (ì„¤ì •ì— ë”°ë¼)
            if evaluation.matched and rule.action.stop_on_match:
                break
        
        return evaluations
    
    async def import_rules(self, rules_json: str) -> List[RoutingRule]:
        """ê·œì¹™ ì¼ê´„ ê°€ì ¸ì˜¤ê¸°"""
        
        try:
            rules_data = json.loads(rules_json)
        except json.JSONDecodeError as e:
            raise InvalidRuleFormatError(f"Invalid JSON: {e}")
        
        imported_rules = []
        
        for rule_spec in rules_data:
            try:
                rule = await self.create_rule(rule_spec)
                imported_rules.append(rule)
            except Exception as e:
                # ê°œë³„ ê·œì¹™ ì‹¤íŒ¨ ì‹œ ê³„ì† ì§„í–‰
                await self.audit_logger.log('rule_import_failed', {
                    'rule_name': rule_spec.get('name'),
                    'error': str(e)
                })
        
        return imported_rules
    
    async def export_rules(
        self, 
        rule_ids: Optional[List[str]] = None
    ) -> str:
        """ê·œì¹™ ë‚´ë³´ë‚´ê¸°"""
        
        if rule_ids:
            rules_to_export = [
                self.rules[rid] for rid in rule_ids 
                if rid in self.rules
            ]
        else:
            rules_to_export = list(self.rules.values())
        
        export_data = []
        
        for rule in rules_to_export:
            export_data.append({
                'name': rule.name,
                'description': rule.description,
                'condition': self.serialize_condition(rule.condition),
                'action': self.serialize_action(rule.action),
                'priority': rule.priority,
                'enabled': rule.enabled,
                'metadata': rule.metadata
            })
        
        return json.dumps(export_data, indent=2)

# ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤ API
class RoutingRuleAPI:
    """ë¼ìš°íŒ… ê·œì¹™ ê´€ë¦¬ REST API"""
    
    def __init__(self, manager: RoutingRuleManager):
        self.manager = manager
        self.router = APIRouter(prefix="/api/routing-rules")
        self.setup_routes()
    
    def setup_routes(self):
        """API ë¼ìš°íŠ¸ ì„¤ì •"""
        
        @self.router.get("/")
        async def list_rules(
            enabled: Optional[bool] = None,
            skip: int = 0,
            limit: int = 100
        ):
            """ê·œì¹™ ëª©ë¡ ì¡°íšŒ"""
            rules = list(self.manager.rules.values())
            
            if enabled is not None:
                rules = [r for r in rules if r.enabled == enabled]
            
            return {
                'rules': rules[skip:skip+limit],
                'total': len(rules)
            }
        
        @self.router.post("/")
        async def create_rule(rule_spec: Dict[str, Any]):
            """ê·œì¹™ ìƒì„±"""
            rule = await self.manager.create_rule(rule_spec)
            return {'rule': rule, 'message': 'Rule created successfully'}
        
        @self.router.put("/{rule_id}")
        async def update_rule(rule_id: str, updates: Dict[str, Any]):
            """ê·œì¹™ ì—…ë°ì´íŠ¸"""
            rule = await self.manager.update_rule(rule_id, updates)
            return {'rule': rule, 'message': 'Rule updated successfully'}
        
        @self.router.delete("/{rule_id}")
        async def delete_rule(rule_id: str):
            """ê·œì¹™ ì‚­ì œ"""
            await self.manager.delete_rule(rule_id)
            return {'message': 'Rule deleted successfully'}
        
        @self.router.post("/test")
        async def test_rules(test_request: Dict[str, Any]):
            """ê·œì¹™ í…ŒìŠ¤íŠ¸"""
            request = create_mock_request(test_request)
            evaluations = await self.manager.evaluate_rules(request)
            return {'evaluations': evaluations}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ê·œì¹™ CRUD ì‘ì—…
- [ ] ê·œì¹™ í‰ê°€ ì—”ì§„
- [ ] ê°€ì ¸ì˜¤ê¸°/ë‚´ë³´ë‚´ê¸°
- [ ] ê´€ë¦¬ API êµ¬í˜„

---

## Task 6.3: ìš”ì²­/ì‘ë‹µ ë³€í™˜ ë ˆì´ì–´

### SubTask 6.3.1: ìš”ì²­ íŒŒì„œ ë° ê²€ì¦ê¸°

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api-gateway/transformation/request-parser.ts
export interface ParsedRequest {
  headers: Record<string, string>;
  params: Record<string, any>;
  query: Record<string, any>;
  body: any;
  cookies: Record<string, string>;
  metadata: RequestMetadata;
}

export class RequestParser {
  private validators: Map<string, Validator> = new Map();
  private parsers: Map<string, Parser> = new Map();
  
  constructor() {
    this.initializeParsers();
    this.initializeValidators();
  }
  
  private initializeParsers(): void {
    // JSON íŒŒì„œ
    this.parsers.set('application/json', new JSONParser());
    
    // XML íŒŒì„œ
    this.parsers.set('application/xml', new XMLParser());
    
    // Form íŒŒì„œ
    this.parsers.set('application/x-www-form-urlencoded', new FormParser());
    
    // Multipart íŒŒì„œ
    this.parsers.set('multipart/form-data', new MultipartParser());
    
    // GraphQL íŒŒì„œ
    this.parsers.set('application/graphql', new GraphQLParser());
    
    // Protocol Buffers íŒŒì„œ
    this.parsers.set('application/protobuf', new ProtobufParser());
  }
  
  async parse(request: IncomingRequest): Promise<ParsedRequest> {
    const contentType = request.headers['content-type'] || 'application/json';
    const parser = this.selectParser(contentType);
    
    // 1. í—¤ë” íŒŒì‹±
    const headers = this.parseHeaders(request.headers);
    
    // 2. ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° íŒŒì‹±
    const query = this.parseQueryParams(request.url);
    
    // 3. ê²½ë¡œ íŒŒë¼ë¯¸í„° íŒŒì‹±
    const params = request.params || {};
    
    // 4. ì¿ í‚¤ íŒŒì‹±
    const cookies = this.parseCookies(request.headers.cookie);
    
    // 5. ë°”ë”” íŒŒì‹±
    let body = null;
    if (request.body) {
      body = await parser.parse(request.body);
    }
    
    // 6. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    const metadata = this.extractMetadata(request);
    
    return {
      headers,
      params,
      query,
      body,
      cookies,
      metadata
    };
  }
  
  async validate(
    parsedRequest: ParsedRequest,
    schema: ValidationSchema
  ): Promise<ValidationResult> {
    const errors: ValidationError[] = [];
    
    // í—¤ë” ê²€ì¦
    if (schema.headers) {
      const headerErrors = await this.validateHeaders(
        parsedRequest.headers,
        schema.headers
      );
      errors.push(...headerErrors);
    }
    
    // íŒŒë¼ë¯¸í„° ê²€ì¦
    if (schema.params) {
      const paramErrors = await this.validateParams(
        parsedRequest.params,
        schema.params
      );
      errors.push(...paramErrors);
    }
    
    // ì¿¼ë¦¬ ê²€ì¦
    if (schema.query) {
      const queryErrors = await this.validateQuery(
        parsedRequest.query,
        schema.query
      );
      errors.push(...queryErrors);
    }
    
    // ë°”ë”” ê²€ì¦
    if (schema.body) {
      const bodyErrors = await this.validateBody(
        parsedRequest.body,
        schema.body
      );
      errors.push(...bodyErrors);
    }
    
    return {
      valid: errors.length === 0,
      errors,
      sanitized: await this.sanitize(parsedRequest, schema)
    };
  }
  
  private async sanitize(
    request: ParsedRequest,
    schema: ValidationSchema
  ): Promise<ParsedRequest> {
    const sanitized = { ...request };
    
    // XSS ë°©ì§€
    if (schema.sanitize?.xss) {
      sanitized.body = this.sanitizeXSS(request.body);
      sanitized.params = this.sanitizeXSS(request.params);
      sanitized.query = this.sanitizeXSS(request.query);
    }
    
    // SQL Injection ë°©ì§€
    if (schema.sanitize?.sql) {
      sanitized.params = this.sanitizeSQL(request.params);
      sanitized.query = this.sanitizeSQL(request.query);
    }
    
    // íƒ€ì… ê°•ì œ ë³€í™˜
    if (schema.coerce) {
      sanitized.body = await this.coerceTypes(request.body, schema.body);
      sanitized.params = await this.coerceTypes(request.params, schema.params);
      sanitized.query = await this.coerceTypes(request.query, schema.query);
    }
    
    return sanitized;
  }
}

// ìš”ì²­ ê²€ì¦ê¸°
export class RequestValidator {
  private ajv: Ajv;
  private schemas: Map<string, any> = new Map();
  
  constructor() {
    this.ajv = new Ajv({
      allErrors: true,
      coerceTypes: true,
      removeAdditional: true
    });
    
    // ì»¤ìŠ¤í…€ í¬ë§· ì¶”ê°€
    this.ajv.addFormat('email', /^[^\s@]+@[^\s@]+\.[^\s@]+$/);
    this.ajv.addFormat('uuid', /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i);
    this.ajv.addFormat('iso8601', /^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}(\.\d{3})?Z?$/);
  }
  
  async validateRequest(
    request: ParsedRequest,
    endpointSchema: EndpointSchema
  ): Promise<ValidationResult> {
    const errors: ValidationError[] = [];
    
    // OpenAPI ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ê²€ì¦
    if (endpointSchema.openapi) {
      const openApiErrors = await this.validateOpenAPI(
        request,
        endpointSchema.openapi
      );
      errors.push(...openApiErrors);
    }
    
    // ì»¤ìŠ¤í…€ ê²€ì¦ ê·œì¹™
    if (endpointSchema.customValidators) {
      for (const validator of endpointSchema.customValidators) {
        const customErrors = await validator.validate(request);
        errors.push(...customErrors);
      }
    }
    
    // ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦
    if (endpointSchema.businessRules) {
      const ruleErrors = await this.validateBusinessRules(
        request,
        endpointSchema.businessRules
      );
      errors.push(...ruleErrors);
    }
    
    return {
      valid: errors.length === 0,
      errors,
      warnings: await this.checkWarnings(request, endpointSchema)
    };
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ì½˜í…ì¸  íƒ€ì… íŒŒì‹±
- [ ] ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ê²€ì¦
- [ ] ë³´ì•ˆ ì‚´ê·  ì²˜ë¦¬
- [ ] ì—ëŸ¬ ìƒì„¸ ì •ë³´

### SubTask 6.3.2: í”„ë¡œí† ì½œ ë³€í™˜ ì—”ì§„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api_gateway/transformation/protocol_converter.py
from typing import Any, Dict, Optional, Union
from abc import ABC, abstractmethod
import json
import xml.etree.ElementTree as ET
from google.protobuf import message as protobuf_message

class ProtocolConverter(ABC):
    """í”„ë¡œí† ì½œ ë³€í™˜ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def convert(self, data: Any, target_format: str) -> Any:
        pass

class UniversalProtocolConverter:
    """ë²”ìš© í”„ë¡œí† ì½œ ë³€í™˜ ì—”ì§„"""
    
    def __init__(self):
        self.converters = self._initialize_converters()
        self.schema_registry = SchemaRegistry()
        
    def _initialize_converters(self) -> Dict[str, Dict[str, ProtocolConverter]]:
        """ë³€í™˜ê¸° ì´ˆê¸°í™”"""
        return {
            'json': {
                'xml': JSONToXMLConverter(),
                'protobuf': JSONToProtobufConverter(),
                'graphql': JSONToGraphQLConverter(),
                'msgpack': JSONToMsgPackConverter(),
                'yaml': JSONToYAMLConverter()
            },
            'xml': {
                'json': XMLToJSONConverter(),
                'protobuf': XMLToProtobufConverter(),
                'graphql': XMLToGraphQLConverter()
            },
            'protobuf': {
                'json': ProtobufToJSONConverter(),
                'xml': ProtobufToXMLConverter(),
                'graphql': ProtobufToGraphQLConverter()
            },
            'graphql': {
                'json': GraphQLToJSONConverter(),
                'xml': GraphQLToXMLConverter(),
                'protobuf': GraphQLToProtobufConverter()
            }
        }
    
    async def convert(
        self,
        data: Any,
        source_format: str,
        target_format: str,
        schema: Optional[Any] = None
    ) -> ConversionResult:
        """í”„ë¡œí† ì½œ ë³€í™˜ ì‹¤í–‰"""
        
        if source_format == target_format:
            return ConversionResult(
                success=True,
                data=data,
                format=target_format
            )
        
        # ì§ì ‘ ë³€í™˜ ê°€ëŠ¥ í™•ì¸
        if source_format in self.converters and target_format in self.converters[source_format]:
            converter = self.converters[source_format][target_format]
            
            try:
                converted_data = await converter.convert(data, target_format)
                
                # ìŠ¤í‚¤ë§ˆ ê²€ì¦
                if schema:
                    await self.validate_against_schema(converted_data, schema, target_format)
                
                return ConversionResult(
                    success=True,
                    data=converted_data,
                    format=target_format,
                    metadata={'direct_conversion': True}
                )
                
            except Exception as e:
                return ConversionResult(
                    success=False,
                    error=str(e),
                    format=target_format
                )
        
        # ê°„ì ‘ ë³€í™˜ (ì¤‘ê°„ í˜•ì‹ ì‚¬ìš©)
        return await self.convert_via_intermediate(
            data, source_format, target_format, schema
        )
    
    async def convert_via_intermediate(
        self,
        data: Any,
        source_format: str,
        target_format: str,
        schema: Optional[Any] = None
    ) -> ConversionResult:
        """ì¤‘ê°„ í˜•ì‹ì„ í†µí•œ ë³€í™˜"""
        
        # JSONì„ ì¤‘ê°„ í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©
        intermediate_format = 'json'
        
        # 1ë‹¨ê³„: source -> intermediate
        if source_format != intermediate_format:
            intermediate_result = await self.convert(
                data, source_format, intermediate_format
            )
            
            if not intermediate_result.success:
                return intermediate_result
                
            intermediate_data = intermediate_result.data
        else:
            intermediate_data = data
        
        # 2ë‹¨ê³„: intermediate -> target
        final_result = await self.convert(
            intermediate_data, intermediate_format, target_format, schema
        )
        
        if final_result.success:
            final_result.metadata['via_intermediate'] = intermediate_format
        
        return final_result

class JSONToProtobufConverter(ProtocolConverter):
    """JSON to Protocol Buffers ë³€í™˜"""
    
    async def convert(self, json_data: Dict, target_format: str) -> bytes:
        # ìŠ¤í‚¤ë§ˆ ë¡œë“œ
        proto_schema = await self.load_proto_schema(json_data.get('__schema__'))
        
        # ë©”ì‹œì§€ ìƒì„±
        message_class = self.get_message_class(proto_schema)
        message = message_class()
        
        # JSON ë°ì´í„°ë¥¼ Protobuf ë©”ì‹œì§€ë¡œ ë³€í™˜
        self.populate_message(message, json_data)
        
        # ì§ë ¬í™”
        return message.SerializeToString()
    
    def populate_message(
        self,
        message: protobuf_message.Message,
        data: Dict[str, Any]
    ) -> None:
        """Protobuf ë©”ì‹œì§€ ì±„ìš°ê¸°"""
        
        for field, value in data.items():
            if field.startswith('__'):  # ë©”íƒ€ë°ì´í„° ìŠ¤í‚µ
                continue
                
            if hasattr(message, field):
                field_descriptor = message.DESCRIPTOR.fields_by_name.get(field)
                
                if field_descriptor:
                    if field_descriptor.label == field_descriptor.LABEL_REPEATED:
                        # ë°˜ë³µ í•„ë“œ
                        repeated_field = getattr(message, field)
                        for item in value:
                            if field_descriptor.type == field_descriptor.TYPE_MESSAGE:
                                sub_message = repeated_field.add()
                                self.populate_message(sub_message, item)
                            else:
                                repeated_field.append(item)
                    elif field_descriptor.type == field_descriptor.TYPE_MESSAGE:
                        # ì¤‘ì²© ë©”ì‹œì§€
                        sub_message = getattr(message, field)
                        self.populate_message(sub_message, value)
                    else:
                        # ë‹¨ìˆœ í•„ë“œ
                        setattr(message, field, value)

class GraphQLConverter:
    """GraphQL ë³€í™˜ ì²˜ë¦¬"""
    
    async def convert_request(
        self,
        graphql_request: Dict[str, Any]
    ) -> RESTRequest:
        """GraphQL ìš”ì²­ì„ RESTë¡œ ë³€í™˜"""
        
        query = graphql_request.get('query')
        variables = graphql_request.get('variables', {})
        operation_name = graphql_request.get('operationName')
        
        # GraphQL íŒŒì‹±
        parsed = self.parse_graphql(query)
        
        # ì‘ì—… íƒ€ì… í™•ì¸
        operation = self.get_operation(parsed, operation_name)
        
        if operation.type == 'query':
            return self.convert_query_to_rest(operation, variables)
        elif operation.type == 'mutation':
            return self.convert_mutation_to_rest(operation, variables)
        elif operation.type == 'subscription':
            return self.convert_subscription_to_websocket(operation, variables)
        
    def convert_query_to_rest(
        self,
        operation: GraphQLOperation,
        variables: Dict
    ) -> RESTRequest:
        """GraphQL ì¿¼ë¦¬ë¥¼ REST GETìœ¼ë¡œ ë³€í™˜"""
        
        # í•„ë“œ ì„ íƒì„ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ ë³€í™˜
        fields = self.extract_fields(operation.selection_set)
        
        return RESTRequest(
            method='GET',
            path=f"/api/{operation.name}",
            query_params={
                **variables,
                'fields': ','.join(fields)
            }
        )
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ í”„ë¡œí† ì½œ ì§€ì›
- [ ] ì–‘ë°©í–¥ ë³€í™˜
- [ ] ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ë³€í™˜
- [ ] ì¤‘ê°„ í˜•ì‹ í™œìš©

### SubTask 6.3.3: ì‘ë‹µ í¬ë§·í„° ë° ì••ì¶•

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api-gateway/transformation/response-formatter.ts
export class ResponseFormatter {
  private formatters: Map<string, Formatter> = new Map();
  private compressors: Map<string, Compressor> = new Map();
  
  constructor() {
    this.initializeFormatters();
    this.initializeCompressors();
  }
  
  private initializeFormatters(): void {
    this.formatters.set('json', new JSONFormatter());
    this.formatters.set('xml', new XMLFormatter());
    this.formatters.set('html', new HTMLFormatter());
    this.formatters.set('csv', new CSVFormatter());
    this.formatters.set('yaml', new YAMLFormatter());
  }
  
  private initializeCompressors(): void {
    this.compressors.set('gzip', new GzipCompressor());
    this.compressors.set('deflate', new DeflateCompressor());
    this.compressors.set('br', new BrotliCompressor());
    this.compressors.set('zstd', new ZstdCompressor());
  }
  
  async format(
    data: any,
    options: FormattingOptions
  ): Promise<FormattedResponse> {
    // 1. ì‘ë‹µ êµ¬ì¡° ì •ê·œí™”
    const normalized = this.normalizeResponse(data, options);
    
    // 2. í¬ë§· ì„ íƒ
    const format = options.format || 'json';
    const formatter = this.formatters.get(format);
    
    if (!formatter) {
      throw new UnsupportedFormatError(`Format ${format} not supported`);
    }
    
    // 3. í¬ë§·íŒ… ì‹¤í–‰
    let formatted = await formatter.format(normalized, options);
    
    // 4. í›„ì²˜ë¦¬
    if (options.prettify) {
      formatted = await this.prettify(formatted, format);
    }
    
    // 5. ì••ì¶•
    if (options.compress) {
      formatted = await this.compress(formatted, options.compress);
    }
    
    return {
      data: formatted,
      contentType: formatter.getContentType(),
      encoding: options.compress?.algorithm,
      size: this.calculateSize(formatted)
    };
  }
  
  private normalizeResponse(
    data: any,
    options: FormattingOptions
  ): NormalizedResponse {
    // í‘œì¤€ ì‘ë‹µ êµ¬ì¡°
    const normalized: NormalizedResponse = {
      success: true,
      data: null,
      metadata: {},
      timestamp: new Date().toISOString()
    };
    
    // ë°ì´í„° ì²˜ë¦¬
    if (data instanceof Error) {
      normalized.success = false;
      normalized.error = {
        code: data.code || 'INTERNAL_ERROR',
        message: data.message,
        details: options.includeStackTrace ? data.stack : undefined
      };
    } else {
      normalized.data = data;
    }
    
    // ë©”íƒ€ë°ì´í„° ì¶”ê°€
    if (options.includeMetadata) {
      normalized.metadata = {
        version: options.apiVersion,
        requestId: options.requestId,
        processingTime: options.processingTime,
        ...options.customMetadata
      };
    }
    
    // í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´
    if (options.pagination) {
      normalized.pagination = {
        page: options.pagination.page,
        limit: options.pagination.limit,
        total: options.pagination.total,
        hasNext: options.pagination.hasNext,
        hasPrev: options.pagination.hasPrev
      };
    }
    
    return normalized;
  }
  
  async compress(
    data: Buffer | string,
    compression: CompressionOptions
  ): Promise<Buffer> {
    const algorithm = compression.algorithm || 'gzip';
    const compressor = this.compressors.get(algorithm);
    
    if (!compressor) {
      throw new UnsupportedCompressionError(`Compression ${algorithm} not supported`);
    }
    
    const input = Buffer.isBuffer(data) ? data : Buffer.from(data);
    
    // ì••ì¶• ì„ê³„ê°’ ì²´í¬
    if (input.length < (compression.threshold || 1024)) {
      return input; // ì‘ì€ ë°ì´í„°ëŠ” ì••ì¶•í•˜ì§€ ì•ŠìŒ
    }
    
    const compressed = await compressor.compress(input, {
      level: compression.level || 6,
      strategy: compression.strategy
    });
    
    // ì••ì¶• íš¨ìœ¨ ì²´í¬
    const ratio = compressed.length / input.length;
    if (ratio > 0.9) {
      // ì••ì¶• íš¨ê³¼ê°€ ë¯¸ë¯¸í•˜ë©´ ì›ë³¸ ë°˜í™˜
      return input;
    }
    
    return compressed;
  }
}

// ì ì‘í˜• ì‘ë‹µ í¬ë§¤í„°
export class AdaptiveResponseFormatter {
  private formatter: ResponseFormatter;
  private analyzer: ClientAnalyzer;
  
  async formatForClient(
    data: any,
    request: IncomingRequest
  ): Promise<FormattedResponse> {
    // í´ë¼ì´ì–¸íŠ¸ ë¶„ì„
    const clientProfile = await this.analyzer.analyze(request);
    
    // ìµœì  í¬ë§· ì„ íƒ
    const format = this.selectOptimalFormat(clientProfile, request);
    
    // ì••ì¶• ì „ëµ ê²°ì •
    const compression = this.selectCompression(clientProfile, request);
    
    // í¬ë§·íŒ… ì˜µì…˜ êµ¬ì„±
    const options: FormattingOptions = {
      format,
      compress: compression,
      prettify: clientProfile.isDevelopment,
      includeMetadata: clientProfile.requiresMetadata,
      apiVersion: request.headers['api-version'] || 'v1',
      requestId: request.id,
      processingTime: Date.now() - request.startTime
    };
    
    return await this.formatter.format(data, options);
  }
  
  private selectOptimalFormat(
    profile: ClientProfile,
    request: IncomingRequest
  ): string {
    // Accept í—¤ë” í™•ì¸
    const accept = request.headers['accept'];
    
    if (accept) {
      // í´ë¼ì´ì–¸íŠ¸ ì„ í˜¸ë„ ë°˜ì˜
      const preferred = this.parseAcceptHeader(accept);
      for (const format of preferred) {
        if (this.formatter.supports(format)) {
          return format;
        }
      }
    }
    
    // í´ë¼ì´ì–¸íŠ¸ íƒ€ì…ë³„ ê¸°ë³¸ í¬ë§·
    switch (profile.type) {
      case 'browser':
        return 'json';
      case 'mobile':
        return 'json'; // ë˜ëŠ” protobuf
      case 'api':
        return profile.preferredFormat || 'json';
      default:
        return 'json';
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ì‘ë‹µ í¬ë§· ì§€ì›
- [ ] íš¨ìœ¨ì ì¸ ì••ì¶• ì•Œê³ ë¦¬ì¦˜
- [ ] ì ì‘í˜• í¬ë§· ì„ íƒ
- [ ] ì„±ëŠ¥ ìµœì í™”

### SubTask 6.3.4: ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api_gateway/transformation/data_pipeline.py
from typing import List, Any, Callable, Optional
from dataclasses import dataclass
import asyncio

@dataclass
class PipelineStage:
    """íŒŒì´í”„ë¼ì¸ ìŠ¤í…Œì´ì§€"""
    name: str
    transformer: Callable
    condition: Optional[Callable] = None
    error_handler: Optional[Callable] = None
    parallel: bool = False
    timeout: Optional[float] = None

class DataTransformationPipeline:
    """ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.stages: List[PipelineStage] = []
        self.context = PipelineContext()
        self.metrics = PipelineMetrics()
        
    def add_stage(self, stage: PipelineStage) -> 'DataTransformationPipeline':
        """ìŠ¤í…Œì´ì§€ ì¶”ê°€"""
        self.stages.append(stage)
        return self
        
    async def execute(self, data: Any) -> PipelineResult:
        """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        result = PipelineResult(
            input_data=data,
            output_data=data,
            stages_executed=[],
            errors=[],
            metrics={}
        )
        
        current_data = data
        
        for stage in self.stages:
            # ì¡°ê±´ ì²´í¬
            if stage.condition and not await stage.condition(current_data, self.context):
                continue
                
            try:
                # íƒ€ì„ì•„ì›ƒ ì„¤ì •
                if stage.timeout:
                    current_data = await asyncio.wait_for(
                        self.execute_stage(stage, current_data),
                        timeout=stage.timeout
                    )
                else:
                    current_data = await self.execute_stage(stage, current_data)
                    
                result.stages_executed.append(stage.name)
                
            except asyncio.TimeoutError:
                error = StageTimeoutError(f"Stage {stage.name} timed out")
                result.errors.append(error)
                
                if stage.error_handler:
                    current_data = await stage.error_handler(current_data, error)
                else:
                    raise error
                    
            except Exception as e:
                error = StageExecutionError(f"Stage {stage.name} failed: {e}")
                result.errors.append(error)
                
                if stage.error_handler:
                    current_data = await stage.error_handler(current_data, e)
                else:
                    raise error
        
        result.output_data = current_data
        result.metrics = await self.metrics.collect()
        
        return result
    
    async def execute_stage(
        self,
        stage: PipelineStage,
        data: Any
    ) -> Any:
        """ë‹¨ì¼ ìŠ¤í…Œì´ì§€ ì‹¤í–‰"""
        
        start_time = asyncio.get_event_loop().time()
        
        try:
            if stage.parallel and isinstance(data, list):
                # ë³‘ë ¬ ì²˜ë¦¬
                tasks = [stage.transformer(item, self.context) for item in data]
                transformed = await asyncio.gather(*tasks)
            else:
                # ìˆœì°¨ ì²˜ë¦¬
                transformed = await stage.transformer(data, self.context)
            
            # ë©”íŠ¸ë¦­ ê¸°ë¡
            elapsed = asyncio.get_event_loop().time() - start_time
            await self.metrics.record_stage_execution(stage.name, elapsed)
            
            return transformed
            
        except Exception as e:
            await self.metrics.record_stage_error(stage.name, e)
            raise

# ì‚¬ì „ ì •ì˜ëœ ë³€í™˜ ìŠ¤í…Œì´ì§€
class CommonTransformers:
    """ê³µí†µ ë³€í™˜ê¸° ëª¨ìŒ"""
    
    @staticmethod
    async def validate_schema(data: Any, context: PipelineContext) -> Any:
        """ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
        schema = context.get('schema')
        if schema:
            validator = SchemaValidator(schema)
            validator.validate(data)
        return data
    
    @staticmethod
    async def enrich_data(data: Any, context: PipelineContext) -> Any:
        """ë°ì´í„° ë³´ê°•"""
        enrichments = context.get('enrichments', {})
        
        if isinstance(data, dict):
            data.update(enrichments)
        elif isinstance(data, list):
            for item in data:
                if isinstance(item, dict):
                    item.update(enrichments)
        
        return data
    
    @staticmethod
    async def filter_fields(data: Any, context: PipelineContext) -> Any:
        """í•„ë“œ í•„í„°ë§"""
        allowed_fields = context.get('allowed_fields')
        
        if not allowed_fields:
            return data
        
        def filter_dict(d: dict) -> dict:
            return {k: v for k, v in d.items() if k in allowed_fields}
        
        if isinstance(data, dict):
            return filter_dict(data)
        elif isinstance(data, list):
            return [filter_dict(item) if isinstance(item, dict) else item for item in data]
        
        return data
    
    @staticmethod
    async def transform_keys(data: Any, context: PipelineContext) -> Any:
        """í‚¤ ë³€í™˜ (camelCase <-> snake_case)"""
        transform_type = context.get('key_transform', 'camel_to_snake')
        
        def to_camel_case(snake_str: str) -> str:
            components = snake_str.split('_')
            return components[0] + ''.join(x.title() for x in components[1:])
        
        def to_snake_case(camel_str: str) -> str:
            import re
            s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', camel_str)
            return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()
        
        transformer = to_snake_case if transform_type == 'camel_to_snake' else to_camel_case
        
        def transform_dict(d: dict) -> dict:
            return {transformer(k): v for k, v in d.items()}
        
        if isinstance(data, dict):
            return transform_dict(data)
        elif isinstance(data, list):
            return [transform_dict(item) if isinstance(item, dict) else item for item in data]
        
        return data

# íŒŒì´í”„ë¼ì¸ ë¹Œë”
class PipelineBuilder:
    """íŒŒì´í”„ë¼ì¸ êµ¬ì„± ë¹Œë”"""
    
    def __init__(self):
        self.pipeline = DataTransformationPipeline()
        
    def validate(self, schema: Any) -> 'PipelineBuilder':
        """ê²€ì¦ ìŠ¤í…Œì´ì§€ ì¶”ê°€"""
        self.pipeline.add_stage(PipelineStage(
            name='validation',
            transformer=CommonTransformers.validate_schema
        ))
        self.pipeline.context.set('schema', schema)
        return self
        
    def enrich(self, enrichments: Dict) -> 'PipelineBuilder':
        """ë³´ê°• ìŠ¤í…Œì´ì§€ ì¶”ê°€"""
        self.pipeline.add_stage(PipelineStage(
            name='enrichment',
            transformer=CommonTransformers.enrich_data
        ))
        self.pipeline.context.set('enrichments', enrichments)
        return self
        
    def filter(self, fields: List[str]) -> 'PipelineBuilder':
        """í•„í„° ìŠ¤í…Œì´ì§€ ì¶”ê°€"""
        self.pipeline.add_stage(PipelineStage(
            name='filtering',
            transformer=CommonTransformers.filter_fields
        ))
        self.pipeline.context.set('allowed_fields', fields)
        return self
        
    def custom(
        self,
        name: str,
        transformer: Callable,
        **kwargs
    ) -> 'PipelineBuilder':
        """ì»¤ìŠ¤í…€ ìŠ¤í…Œì´ì§€ ì¶”ê°€"""
        self.pipeline.add_stage(PipelineStage(
            name=name,
            transformer=transformer,
            **kwargs
        ))
        return self
        
    def build(self) -> DataTransformationPipeline:
        """íŒŒì´í”„ë¼ì¸ ë¹Œë“œ"""
        return self.pipeline
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ìœ ì—°í•œ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
- [ ] ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬
- [ ] ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘

---

## Task 6.4: API ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ

### SubTask 6.4.1: ë²„ì „ ë¼ìš°íŒ… ì „ëµ êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api-gateway/versioning/version-router.ts
export enum VersioningStrategy {
  URL_PATH = 'url_path',      // /api/v1/users
  HEADER = 'header',           // API-Version: 1.0
  QUERY_PARAM = 'query_param', // /api/users?version=1
  CONTENT_TYPE = 'content_type' // application/vnd.api+json;version=1
}

export class VersionRouter {
  private strategies: Map<VersioningStrategy, VersionExtractor>;
  private versionMap: Map<string, VersionedEndpoint[]>;
  private defaultVersion: string;
  
  constructor(config: VersioningConfig) {
    this.strategies = this.initializeStrategies();
    this.versionMap = new Map();
    this.defaultVersion = config.defaultVersion || 'v1';
  }
  
  private initializeStrategies(): Map<VersioningStrategy, VersionExtractor> {
    const strategies = new Map();
    
    // URL ê²½ë¡œ ê¸°ë°˜
    strategies.set(VersioningStrategy.URL_PATH, {
      extract: (request: Request) => {
        const match = request.path.match(/\/api\/v(\d+(?:\.\d+)?)/);
        return match ? `v${match[1]}` : null;
      },
      rewrite: (request: Request, version: string) => {
        request.path = request.path.replace(/\/api\/v\d+(?:\.\d+)?/, `/api/${version}`);
      }
    });
    
    // í—¤ë” ê¸°ë°˜
    strategies.set(VersioningStrategy.HEADER, {
      extract: (request: Request) => {
        return request.headers['api-version'] || request.headers['x-api-version'];
      },
      rewrite: (request: Request, version: string) => {
        request.headers['x-resolved-version'] = version;
      }
    });
    
    // ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ê¸°ë°˜
    strategies.set(VersioningStrategy.QUERY_PARAM, {
      extract: (request: Request) => {
        return request.query.version || request.query.v;
      },
      rewrite: (request: Request, version: string) => {
        delete request.query.version;
        delete request.query.v;
      }
    });
    
    // Content-Type ê¸°ë°˜
    strategies.set(VersioningStrategy.CONTENT_TYPE, {
      extract: (request: Request) => {
        const contentType = request.headers['content-type'];
        const match = contentType?.match(/version=(\d+(?:\.\d+)?)/);
        return match ? `v${match[1]}` : null;
      },
      rewrite: (request: Request, version: string) => {
        // Content-Typeì—ì„œ ë²„ì „ ì •ë³´ ì œê±°
        if (request.headers['content-type']) {
          request.headers['content-type'] = 
            request.headers['content-type'].replace(/;version=\d+(?:\.\d+)?/, '');
        }
      }
    });
    
    return strategies;
  }
  
  async route(request: Request): Promise<VersionedEndpoint> {
    // 1. ë²„ì „ ì¶”ì¶œ
    const version = this.extractVersion(request) || this.defaultVersion;
    
    // 2. ë²„ì „ ê²€ì¦
    if (!this.isValidVersion(version)) {
      throw new InvalidVersionError(`Invalid API version: ${version}`);
    }
    
    // 3. ì—”ë“œí¬ì¸íŠ¸ ë§¤ì¹­
    const endpoint = await this.matchEndpoint(request, version);
    
    if (!endpoint) {
      // í´ë°± ë²„ì „ ì‹œë„
      const fallbackVersion = this.getFallbackVersion(version);
      if (fallbackVersion) {
        return await this.matchEndpoint(request, fallbackVersion);
      }
      
      throw new EndpointNotFoundError(
        `Endpoint not found for version ${version}`
      );
    }
    
    // 4. ìš”ì²­ ë³€í™˜
    await this.transformRequest(request, version, endpoint);
    
    return endpoint;
  }
  
  private extractVersion(request: Request): string | null {
    // ì„¤ì •ëœ ì „ëµ ìˆœì„œëŒ€ë¡œ ì‹œë„
    for (const [strategy, extractor] of this.strategies) {
      const version = extractor.extract(request);
      if (version) {
        return this.normalizeVersion(version);
      }
    }
    
    return null;
  }
  
  private normalizeVersion(version: string): string {
    // v1, 1.0, v1.0 ë“±ì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    if (!version.startsWith('v')) {
      version = `v${version}`;
    }
    
    // ë©”ì´ì € ë²„ì „ë§Œ ìˆìœ¼ë©´ .0 ì¶”ê°€
    if (!version.includes('.')) {
      version += '.0';
    }
    
    return version;
  }
  
  async registerEndpoint(
    version: string,
    endpoint: VersionedEndpoint
  ): Promise<void> {
    if (!this.versionMap.has(version)) {
      this.versionMap.set(version, []);
    }
    
    const endpoints = this.versionMap.get(version)!;
    
    // ì¤‘ë³µ ì²´í¬
    const existing = endpoints.find(e => 
      e.path === endpoint.path && e.method === endpoint.method
    );
    
    if (existing) {
      throw new DuplicateEndpointError(
        `Endpoint ${endpoint.method} ${endpoint.path} already exists for version ${version}`
      );
    }
    
    endpoints.push(endpoint);
    
    // ë²„ì „ ê°„ í˜¸í™˜ì„± ì²´í¬
    await this.checkCompatibility(version, endpoint);
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ë²„ì „ ì§€ì • ë°©ì‹
- [ ] ë²„ì „ ì¶”ì¶œ ë° ê²€ì¦
- [ ] í´ë°± ë©”ì»¤ë‹ˆì¦˜
- [ ] ë²„ì „ë³„ ë¼ìš°íŒ…

### SubTask 6.4.2: í•˜ìœ„ í˜¸í™˜ì„± ê´€ë¦¬

**ë‹´ë‹¹ì**: API ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api_gateway/versioning/compatibility_manager.py
from typing import Dict, List, Optional, Set
from dataclasses import dataclass
from enum import Enum

class BreakingChangeType(Enum):
    """Breaking Change ìœ í˜•"""
    REMOVED_FIELD = "removed_field"
    RENAMED_FIELD = "renamed_field"
    TYPE_CHANGED = "type_changed"
    REQUIRED_FIELD_ADDED = "required_field_added"
    REMOVED_ENDPOINT = "removed_endpoint"
    METHOD_CHANGED = "method_changed"
    AUTHENTICATION_CHANGED = "auth_changed"

@dataclass
class CompatibilityRule:
    """í˜¸í™˜ì„± ê·œì¹™"""
    source_version: str
    target_version: str
    change_type: BreakingChangeType
    transformation: Optional[Callable] = None
    migration_guide: Optional[str] = None

class BackwardCompatibilityManager:
    """í•˜ìœ„ í˜¸í™˜ì„± ê´€ë¦¬ì"""
    
    def __init__(self):
        self.compatibility_matrix: Dict[str, Dict[str, List[CompatibilityRule]]] = {}
        self.version_chain: List[str] = []
        self.deprecation_policy = DeprecationPolicy()
        
    async def check_compatibility(
        self,
        from_version: str,
        to_version: str,
        endpoint: EndpointDefinition
    ) -> CompatibilityReport:
        """ë²„ì „ ê°„ í˜¸í™˜ì„± ì²´í¬"""
        
        report = CompatibilityReport(
            from_version=from_version,
            to_version=to_version,
            endpoint=endpoint.path,
            compatible=True,
            breaking_changes=[],
            warnings=[],
            migration_required=False
        )
        
        # ë²„ì „ ì²´ì¸ì—ì„œ ìœ„ì¹˜ í™•ì¸
        from_idx = self.version_chain.index(from_version)
        to_idx = self.version_chain.index(to_version)
        
        if from_idx >= to_idx:
            # ë™ì¼ ë²„ì „ì´ê±°ë‚˜ ë‹¤ìš´ê·¸ë ˆì´ë“œ
            return report
        
        # ë³€ê²½ ì‚¬í•­ ìˆ˜ì§‘
        for version_idx in range(from_idx, to_idx):
            current = self.version_chain[version_idx]
            next_version = self.version_chain[version_idx + 1]
            
            changes = await self.get_changes(current, next_version, endpoint)
            
            for change in changes:
                if change.is_breaking:
                    report.compatible = False
                    report.breaking_changes.append(change)
                    report.migration_required = True
                else:
                    report.warnings.append(change)
        
        # ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if report.migration_required:
            report.auto_migration_available = await self.can_auto_migrate(
                report.breaking_changes
            )
        
        return report
    
    async def apply_compatibility_layer(
        self,
        request: Request,
        source_version: str,
        target_version: str
    ) -> Request:
        """í˜¸í™˜ì„± ë ˆì´ì–´ ì ìš©"""
        
        # í˜¸í™˜ì„± ê·œì¹™ ì¡°íšŒ
        rules = self.get_compatibility_rules(source_version, target_version)
        
        transformed_request = request
        
        for rule in rules:
            if rule.transformation:
                transformed_request = await rule.transformation(transformed_request)
            else:
                transformed_request = await self.apply_default_transformation(
                    transformed_request,
                    rule
                )
        
        # í—¤ë”ì— ë³€í™˜ ì •ë³´ ì¶”ê°€
        transformed_request.headers['X-API-Compatibility-Applied'] = 'true'
        transformed_request.headers['X-Original-Version'] = source_version
        transformed_request.headers['X-Target-Version'] = target_version
        
        return transformed_request
    
    async def apply_default_transformation(
        self,
        request: Request,
        rule: CompatibilityRule
    ) -> Request:
        """ê¸°ë³¸ ë³€í™˜ ì ìš©"""
        
        if rule.change_type == BreakingChangeType.RENAMED_FIELD:
            # í•„ë“œ ì´ë¦„ ë³€ê²½
            if rule.old_name in request.body:
                request.body[rule.new_name] = request.body.pop(rule.old_name)
                
        elif rule.change_type == BreakingChangeType.TYPE_CHANGED:
            # íƒ€ì… ë³€í™˜
            if rule.field_name in request.body:
                request.body[rule.field_name] = await self.convert_type(
                    request.body[rule.field_name],
                    rule.old_type,
                    rule.new_type
                )
                
        elif rule.change_type == BreakingChangeType.REMOVED_FIELD:
            # ì œê±°ëœ í•„ë“œ ì²˜ë¦¬
            if rule.field_name in request.body:
                # ê²½ê³  ë¡œê·¸
                await self.log_compatibility_warning(
                    f"Field {rule.field_name} is deprecated in {rule.target_version}"
                )
                # í•„ë“œ ì œê±°
                del request.body[rule.field_name]
                
        elif rule.change_type == BreakingChangeType.REQUIRED_FIELD_ADDED:
            # ìƒˆë¡œìš´ í•„ìˆ˜ í•„ë“œ ì¶”ê°€
            if rule.field_name not in request.body:
                request.body[rule.field_name] = rule.default_value
        
        return request

class DeprecationManager:
    """Deprecation ê´€ë¦¬"""
    
    def __init__(self):
        self.deprecations: Dict[str, DeprecationInfo] = {}
        self.sunset_policy = SunsetPolicy()
        
    async def deprecate_feature(
        self,
        feature_id: str,
        version: str,
        deprecation_date: datetime,
        sunset_date: datetime,
        replacement: Optional[str] = None,
        migration_guide: Optional[str] = None
    ) -> None:
        """ê¸°ëŠ¥ Deprecation ë“±ë¡"""
        
        deprecation = DeprecationInfo(
            feature_id=feature_id,
            deprecated_in_version=version,
            deprecation_date=deprecation_date,
            sunset_date=sunset_date,
            replacement=replacement,
            migration_guide=migration_guide,
            warnings_sent=0
        )
        
        self.deprecations[feature_id] = deprecation
        
        # ì•Œë¦¼ ìŠ¤ì¼€ì¤„ë§
        await self.schedule_deprecation_notices(deprecation)
    
    async def check_deprecation(
        self,
        feature_id: str,
        request: Request
    ) -> Optional[DeprecationWarning]:
        """Deprecation ì²´í¬"""
        
        if feature_id not in self.deprecations:
            return None
        
        deprecation = self.deprecations[feature_id]
        
        # Sunset ë‚ ì§œ í™•ì¸
        if datetime.now() >= deprecation.sunset_date:
            raise FeatureSunsetError(
                f"Feature {feature_id} has been sunset as of {deprecation.sunset_date}"
            )
        
        # Deprecation ê²½ê³  ìƒì„±
        warning = DeprecationWarning(
            feature=feature_id,
            message=f"This feature is deprecated and will be removed on {deprecation.sunset_date}",
            deprecated_since=deprecation.deprecation_date,
            sunset_date=deprecation.sunset_date,
            replacement=deprecation.replacement,
            migration_guide=deprecation.migration_guide
        )
        
        # ì‘ë‹µ í—¤ë”ì— ê²½ê³  ì¶”ê°€
        request.response_headers['Deprecation'] = 'true'
        request.response_headers['Sunset'] = deprecation.sunset_date.isoformat()
        
        if deprecation.replacement:
            request.response_headers['Link'] = f'<{deprecation.replacement}>; rel="successor-version"'
        
        # ê²½ê³  ì¹´ìš´íŠ¸ ì¦ê°€
        deprecation.warnings_sent += 1
        
        return warning
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] Breaking change ê°ì§€
- [ ] ìë™ í˜¸í™˜ì„± ë³€í™˜
- [ ] Deprecation ê´€ë¦¬
- [ ] ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### SubTask 6.4.3: ë²„ì „ ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api-gateway/versioning/migration-tool.ts
export class VersionMigrationTool {
  private migrationStrategies: Map<string, MigrationStrategy>;
  private validator: MigrationValidator;
  private rollbackManager: RollbackManager;
  
  constructor() {
    this.migrationStrategies = new Map();
    this.validator = new MigrationValidator();
    this.rollbackManager = new RollbackManager();
    this.initializeStrategies();
  }
  
  async createMigrationPlan(
    fromVersion: string,
    toVersion: string,
    scope: MigrationScope
  ): Promise<MigrationPlan> {
    // 1. ë³€ê²½ ì‚¬í•­ ë¶„ì„
    const changes = await this.analyzeChanges(fromVersion, toVersion);
    
    // 2. ì˜í–¥ í‰ê°€
    const impact = await this.assessImpact(changes, scope);
    
    // 3. ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¨ê³„ ìƒì„±
    const steps = this.generateMigrationSteps(changes, impact);
    
    // 4. ê²€ì¦ ê³„íš ìˆ˜ë¦½
    const validationPlan = this.createValidationPlan(steps);
    
    // 5. ë¡¤ë°± ê³„íš ìˆ˜ë¦½
    const rollbackPlan = await this.rollbackManager.createPlan(steps);
    
    return {
      id: generateMigrationId(),
      fromVersion,
      toVersion,
      scope,
      changes,
      impact,
      steps,
      validationPlan,
      rollbackPlan,
      estimatedDuration: this.estimateDuration(steps),
      risk: this.assessRisk(impact)
    };
  }
  
  async executeMigration(
    plan: MigrationPlan,
    options: MigrationOptions = {}
  ): Promise<MigrationResult> {
    const result = new MigrationResult();
    result.planId = plan.id;
    result.startTime = new Date();
    
    try {
      // 1. Pre-migration ê²€ì¦
      await this.validator.validatePreConditions(plan);
      
      // 2. ë°±ì—… ìƒì„±
      if (options.createBackup) {
        result.backupId = await this.createBackup(plan);
      }
      
      // 3. ë‹¨ê³„ë³„ ì‹¤í–‰
      for (const step of plan.steps) {
        try {
          await this.executeStep(step, result);
          
          // ì¤‘ê°„ ê²€ì¦
          if (options.validateAfterEachStep) {
            await this.validator.validateStep(step, result);
          }
          
        } catch (error) {
          result.failedStep = step;
          result.error = error;
          
          if (options.rollbackOnError) {
            await this.rollback(plan, result);
          }
          
          throw error;
        }
      }
      
      // 4. Post-migration ê²€ì¦
      await this.validator.validatePostConditions(plan, result);
      
      // 5. ì •ë¦¬ ì‘ì—…
      await this.cleanup(plan, result);
      
      result.success = true;
      result.endTime = new Date();
      
    } catch (error) {
      result.success = false;
      result.error = error;
      result.endTime = new Date();
    }
    
    return result;
  }
  
  private async executeStep(
    step: MigrationStep,
    result: MigrationResult
  ): Promise<void> {
    const stepResult = new StepResult();
    stepResult.stepId = step.id;
    stepResult.startTime = new Date();
    
    try {
      // ì „ëµ ì„ íƒ
      const strategy = this.migrationStrategies.get(step.type);
      if (!strategy) {
        throw new Error(`Unknown migration step type: ${step.type}`);
      }
      
      // ì‹¤í–‰
      await strategy.execute(step, result.context);
      
      stepResult.success = true;
      
    } catch (error) {
      stepResult.success = false;
      stepResult.error = error;
      throw error;
      
    } finally {
      stepResult.endTime = new Date();
      result.steps.push(stepResult);
    }
  }
  
  async generateMigrationScript(
    plan: MigrationPlan,
    format: 'sql' | 'json' | 'yaml'
  ): Promise<string> {
    const script = new MigrationScriptBuilder();
    
    // í—¤ë” ì¶”ê°€
    script.addHeader({
      planId: plan.id,
      fromVersion: plan.fromVersion,
      toVersion: plan.toVersion,
      generated: new Date(),
      estimatedDuration: plan.estimatedDuration
    });
    
    // ë‹¨ê³„ë³„ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    for (const step of plan.steps) {
      const stepScript = await this.generateStepScript(step, format);
      script.addStep(stepScript);
    }
    
    // ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€
    script.addValidation(plan.validationPlan);
    
    // ë¡¤ë°± ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€
    script.addRollback(plan.rollbackPlan);
    
    return script.build(format);
  }
}

// ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ í´ë¼ì´ì–¸íŠ¸ ìƒì„±ê¸°
export class MigrationClientGenerator {
  async generateClient(
    plan: MigrationPlan,
    language: 'typescript' | 'python' | 'java'
  ): Promise<string> {
    const template = this.getTemplate(language);
    
    return template.render({
      planId: plan.id,
      fromVersion: plan.fromVersion,
      toVersion: plan.toVersion,
      endpoints: plan.changes.endpoints,
      models: plan.changes.models,
      transformations: this.generateTransformations(plan.changes, language)
    });
  }
  
  private generateTransformations(
    changes: VersionChanges,
    language: string
  ): string {
    // ì–¸ì–´ë³„ ë³€í™˜ ì½”ë“œ ìƒì„±
    switch (language) {
      case 'typescript':
        return this.generateTypeScriptTransformations(changes);
      case 'python':
        return this.generatePythonTransformations(changes);
      case 'java':
        return this.generateJavaTransformations(changes);
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìˆ˜ë¦½
- [ ] ë‹¨ê³„ë³„ ì‹¤í–‰
- [ ] ë¡¤ë°± ë©”ì»¤ë‹ˆì¦˜
- [ ] í´ë¼ì´ì–¸íŠ¸ ì½”ë“œ ìƒì„±

### SubTask 6.4.4: ë²„ì „ë³„ ë¬¸ì„œ ìë™ ìƒì„±

**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api_gateway/versioning/doc_generator.py
class VersionedDocumentationGenerator:
    """ë²„ì „ë³„ API ë¬¸ì„œ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.template_engine = TemplateEngine()
        self.schema_generator = SchemaGenerator()
        self.change_tracker = ChangeTracker()
        
    async def generate_documentation(
        self,
        version: str,
        endpoints: List[VersionedEndpoint],
        options: DocGenerationOptions
    ) -> Documentation:
        """ë²„ì „ë³„ ë¬¸ì„œ ìƒì„±"""
        
        doc = Documentation(
            version=version,
            generated_at=datetime.now(),
            format=options.format
        )
        
        # 1. ê°œìš” ì„¹ì…˜
        doc.overview = await self.generate_overview(version, endpoints)
        
        # 2. ë³€ê²½ ì‚¬í•­ ì„¹ì…˜
        if options.include_changelog:
            doc.changelog = await self.generate_changelog(version)
        
        # 3. ì—”ë“œí¬ì¸íŠ¸ ë¬¸ì„œ
        doc.endpoints = await self.document_endpoints(endpoints, options)
        
        # 4. ëª¨ë¸/ìŠ¤í‚¤ë§ˆ ë¬¸ì„œ
        doc.schemas = await self.generate_schemas(endpoints)
        
        # 5. ì˜ˆì œ ì½”ë“œ
        if options.include_examples:
            doc.examples = await self.generate_examples(endpoints, options.languages)
        
        # 6. ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ
        if options.include_migration:
            doc.migration_guide = await self.generate_migration_guide(version)
        
        # 7. OpenAPI/Swagger ìŠ¤í™
        if options.generate_openapi:
            doc.openapi_spec = await self.generate_openapi_spec(version, endpoints)
        
        return doc
    
    async def generate_changelog(self, version: str) -> Changelog:
        """ë³€ê²½ ë¡œê·¸ ìƒì„±"""
        
        changelog = Changelog(version=version)
        
        # ì´ì „ ë²„ì „ê³¼ ë¹„êµ
        previous_version = self.get_previous_version(version)
        
        if previous_version:
            changes = await self.change_tracker.get_changes(
                previous_version,
                version
            )
            
            # ë³€ê²½ ì‚¬í•­ ë¶„ë¥˜
            changelog.breaking_changes = [
                c for c in changes if c.is_breaking
            ]
            
            changelog.new_features = [
                c for c in changes if c.type == ChangeType.ADDED
            ]
            
            changelog.improvements = [
                c for c in changes if c.type == ChangeType.IMPROVED
            ]
            
            changelog.deprecations = [
                c for c in changes if c.type == ChangeType.DEPRECATED
            ]
            
            changelog.bug_fixes = [
                c for c in changes if c.type == ChangeType.FIXED
            ]
        
        return changelog
    
    async def generate_interactive_docs(
        self,
        version: str,
        endpoints: List[VersionedEndpoint]
    ) -> str:
        """ì¸í„°ë™í‹°ë¸Œ ë¬¸ì„œ ìƒì„± (Swagger UI ìŠ¤íƒ€ì¼)"""
        
        html_template = """
<!DOCTYPE html>
<html>
<head>
    <title>T-Developer API v{version}</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swagger-ui-dist/swagger-ui.css">
    <style>
        .version-selector {{
            position: fixed;
            top: 10px;
            right: 10px;
            z-index: 1000;
        }}
        .deprecated {{
            opacity: 0.6;
            text-decoration: line-through;
        }}
        .new-endpoint {{
            background: #e8f5e9;
        }}
        .breaking-change {{
            background: #ffebee;
        }}
    </style>
</head>
<body>
    <div class="version-selector">
        <select id="version-select" onchange="switchVersion(this.value)">
            {version_options}
        </select>
    </div>
    
    <div id="swagger-ui"></div>
    
    <script src="https://cdn.jsdelivr.net/npm/swagger-ui-dist/swagger-ui-bundle.js"></script>
    <script>
        const spec = {openapi_spec};
        
        window.ui = SwaggerUIBundle({{
            spec: spec,
            dom_id: '#swagger-ui',
            deepLinking: true,
            presets: [
                SwaggerUIBundle.presets.apis,
                SwaggerUIBundle.SwaggerUIStandalonePreset
            ],
            plugins: [
                SwaggerUIBundle.plugins.DownloadUrl
            ],
            layout: "StandaloneLayout",
            onComplete: function() {{
                // ì»¤ìŠ¤í…€ ìŠ¤íƒ€ì¼ ì ìš©
                markDeprecatedEndpoints();
                highlightNewEndpoints();
                showBreakingChanges();
            }}
        }});
        
        function switchVersion(version) {{
            window.location.href = `/docs/api/${{version}}`;
        }}
        
        function markDeprecatedEndpoints() {{
            {deprecation_script}
        }}
        
        function highlightNewEndpoints() {{
            {new_endpoints_script}
        }}
        
        function showBreakingChanges() {{
            {breaking_changes_script}
        }}
    </script>
</body>
</html>
        """
        
        # OpenAPI ìŠ¤í™ ìƒì„±
        openapi_spec = await self.generate_openapi_spec(version, endpoints)
        
        # ë²„ì „ ì˜µì…˜ ìƒì„±
        version_options = self.generate_version_options(version)
        
        # ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        deprecation_script = self.generate_deprecation_script(endpoints)
        new_endpoints_script = self.generate_new_endpoints_script(endpoints)
        breaking_changes_script = self.generate_breaking_changes_script(version)
        
        return html_template.format(
            version=version,
            version_options=version_options,
            openapi_spec=json.dumps(openapi_spec),
            deprecation_script=deprecation_script,
            new_endpoints_script=new_endpoints_script,
            breaking_changes_script=breaking_changes_script
        )
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë²„ì „ë³„ ë¬¸ì„œ ìƒì„±
- [ ] ë³€ê²½ ë¡œê·¸ ìë™í™”
- [ ] OpenAPI ìŠ¤í™ ìƒì„±
- [ ] ì¸í„°ë™í‹°ë¸Œ ë¬¸ì„œ

---

## Task 6.5: ê²Œì´íŠ¸ì›¨ì´ ë¡œë“œ ë°¸ëŸ°ì‹±

### SubTask 6.5.1: ë¡œë“œ ë°¸ëŸ°ì‹± ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„

**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api-gateway/loadbalancing/algorithms.ts
export interface LoadBalancingAlgorithm {
  name: string;
  selectServer(servers: Server[], request?: Request): Server;
  updateServerStats(server: Server, response: Response): void;
}

// Round Robin ì•Œê³ ë¦¬ì¦˜
export class RoundRobinAlgorithm implements LoadBalancingAlgorithm {
  name = 'round-robin';
  private currentIndex = 0;
  
  selectServer(servers: Server[]): Server {
    const server = servers[this.currentIndex];
    this.currentIndex = (this.currentIndex + 1) % servers.length;
    return server;
  }
  
  updateServerStats(server: Server, response: Response): void {
    // Round Robinì€ í†µê³„ ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš”
  }
}

// Weighted Round Robin
export class WeightedRoundRobinAlgorithm implements LoadBalancingAlgorithm {
  name = 'weighted-round-robin';
  private currentWeights: Map<string, number> = new Map();
  
  selectServer(servers: Server[]): Server {
    // ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì„ íƒ
    let totalWeight = 0;
    let selectedServer: Server | null = null;
    
    for (const server of servers) {
      const currentWeight = this.currentWeights.get(server.id) || 0;
      const effectiveWeight = currentWeight + server.weight;
      
      this.currentWeights.set(server.id, effectiveWeight);
      totalWeight += server.weight;
      
      if (!selectedServer || effectiveWeight > this.currentWeights.get(selectedServer.id)!) {
        selectedServer = server;
      }
    }
    
    if (selectedServer) {
      this.currentWeights.set(
        selectedServer.id,
        this.currentWeights.get(selectedServer.id)! - totalWeight
      );
    }
    
    return selectedServer!;
  }
  
  updateServerStats(server: Server, response: Response): void {
    // ì‘ë‹µ ì‹œê°„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì¡°ì •
    if (response.time > server.targetResponseTime * 2) {
      server.weight = Math.max(1, server.weight - 1);
    } else if (response.time < server.targetResponseTime * 0.5) {
      server.weight = Math.min(10, server.weight + 1);
    }
  }
}

// Least Connections
export class LeastConnectionsAlgorithm implements LoadBalancingAlgorithm {
  name = 'least-connections';
  private connections: Map<string, number> = new Map();
  
  selectServer(servers: Server[]): Server {
    let minConnections = Infinity;
    let selectedServer: Server | null = null;
    
    for (const server of servers) {
      const connections = this.connections.get(server.id) || 0;
      
      if (connections < minConnections) {
        minConnections = connections;
        selectedServer = server;
      }
    }
    
    if (selectedServer) {
      this.connections.set(
        selectedServer.id,
        (this.connections.get(selectedServer.id) || 0) + 1
      );
    }
    
    return selectedServer!;
  }
  
  updateServerStats(server: Server, response: Response): void {
    // ì—°ê²° ì™„ë£Œ ì‹œ ì¹´ìš´íŠ¸ ê°ì†Œ
    const current = this.connections.get(server.id) || 0;
    this.connections.set(server.id, Math.max(0, current - 1));
  }
}

// IP Hash (Sticky Session)
export class IPHashAlgorithm implements LoadBalancingAlgorithm {
  name = 'ip-hash';
  
  selectServer(servers: Server[], request: Request): Server {
    const ip = request.clientIP;
    const hash = this.hashIP(ip);
    const index = hash % servers.length;
    return servers[index];
  }
  
  private hashIP(ip: string): number {
    let hash = 0;
    for (let i = 0; i < ip.length; i++) {
      hash = ((hash << 5) - hash) + ip.charCodeAt(i);
      hash = hash & hash; // Convert to 32-bit integer
    }
    return Math.abs(hash);
  }
  
  updateServerStats(server: Server, response: Response): void {
    // IP HashëŠ” í†µê³„ ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš”
  }
}

// Adaptive Load Balancing
export class AdaptiveLoadBalancer implements LoadBalancingAlgorithm {
  name = 'adaptive';
  private metrics: ServerMetrics;
  private predictor: LoadPredictor;
  
  constructor() {
    this.metrics = new ServerMetrics();
    this.predictor = new LoadPredictor();
  }
  
  selectServer(servers: Server[], request: Request): Server {
    // 1. í˜„ì¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    const currentMetrics = servers.map(s => ({
      server: s,
      cpu: this.metrics.getCPU(s.id),
      memory: this.metrics.getMemory(s.id),
      responseTime: this.metrics.getAvgResponseTime(s.id),
      errorRate: this.metrics.getErrorRate(s.id),
      activeConnections: this.metrics.getActiveConnections(s.id)
    }));
    
    // 2. ë¶€í•˜ ì˜ˆì¸¡
    const predictions = currentMetrics.map(m => ({
      ...m,
      predictedLoad: this.predictor.predict(m, request)
    }));
    
    // 3. ìŠ¤ì½”ì–´ ê³„ì‚°
    const scores = predictions.map(p => ({
      server: p.server,
      score: this.calculateScore(p)
    }));
    
    // 4. ìµœì  ì„œë²„ ì„ íƒ
    scores.sort((a, b) => b.score - a.score);
    return scores[0].server;
  }
  
  private calculateScore(metrics: any): number {
    // ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìŠ¤ì½”ì–´ ê³„ì‚°
    const weights = {
      cpu: 0.3,
      memory: 0.2,
      responseTime: 0.3,
      errorRate: 0.1,
      connections: 0.1
    };
    
    return (
      (100 - metrics.cpu) * weights.cpu +
      (100 - metrics.memory) * weights.memory +
      (1000 / (metrics.responseTime + 1)) * weights.responseTime +
      (100 - metrics.errorRate) * weights.errorRate +
      (100 / (metrics.activeConnections + 1)) * weights.connections
    );
  }
  
  updateServerStats(server: Server, response: Response): void {
    this.metrics.update(server.id, {
      responseTime: response.time,
      success: response.status < 500,
      timestamp: Date.now()
    });
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
- [ ] ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì •
- [ ] ì„¸ì…˜ ìœ ì§€ ì§€ì›
- [ ] ì ì‘í˜• ë¡œë“œ ë°¸ëŸ°ì‹±

### SubTask 6.5.2: í—¬ìŠ¤ ì²´í¬ ë° ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬

**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api_gateway/loadbalancing/health_check.py
class HealthChecker:
    """ì„œë¹„ìŠ¤ í—¬ìŠ¤ ì²´í¬"""
    
    def __init__(self, config: HealthCheckConfig):
        self.config = config
        self.health_status: Dict[str, ServiceHealth] = {}
        self.check_tasks: Dict[str, asyncio.Task] = {}
        
    async def start_monitoring(self, services: List[Service]) -> None:
        """í—¬ìŠ¤ ì²´í¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        
        for service in services:
            if service.id not in self.check_tasks:
                task = asyncio.create_task(
                    self.monitor_service(service)
                )
                self.check_tasks[service.id] = task
    
    async def monitor_service(self, service: Service) -> None:
        """ê°œë³„ ì„œë¹„ìŠ¤ ëª¨ë‹ˆí„°ë§"""
        
        consecutive_failures = 0
        consecutive_successes = 0
        
        while True:
            try:
                # í—¬ìŠ¤ ì²´í¬ ì‹¤í–‰
                health = await self.check_health(service)
                
                if health.is_healthy:
                    consecutive_successes += 1
                    consecutive_failures = 0
                    
                    if consecutive_successes >= self.config.healthy_threshold:
                        await self.mark_healthy(service)
                else:
                    consecutive_failures += 1
                    consecutive_successes = 0
                    
                    if consecutive_failures >= self.config.unhealthy_threshold:
                        await self.mark_unhealthy(service)
                
                # ìƒíƒœ ì—…ë°ì´íŠ¸
                self.health_status[service.id] = health
                
            except Exception as e:
                await self.handle_check_error(service, e)
                
            await asyncio.sleep(self.config.interval)
    
    async def check_health(self, service: Service) -> ServiceHealth:
        """í—¬ìŠ¤ ì²´í¬ ì‹¤í–‰"""
        
        health = ServiceHealth(
            service_id=service.id,
            timestamp=datetime.now()
        )
        
        # HTTP í—¬ìŠ¤ ì²´í¬
        if service.health_check_type == 'http':
            health = await self.http_health_check(service, health)
            
        # TCP í—¬ìŠ¤ ì²´í¬
        elif service.health_check_type == 'tcp':
            health = await self.tcp_health_check(service, health)
            
        # ì»¤ìŠ¤í…€ í—¬ìŠ¤ ì²´í¬
        elif service.health_check_type == 'custom':
            health = await self.custom_health_check(service, health)
        
        return health
    
    async def http_health_check(
        self,
        service: Service,
        health: ServiceHealth
    ) -> ServiceHealth:
        """HTTP í—¬ìŠ¤ ì²´í¬"""
        
        try:
            start_time = time.time()
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{service.url}{service.health_check_path}",
                    timeout=aiohttp.ClientTimeout(total=self.config.timeout)
                ) as response:
                    
                    health.response_time = time.time() - start_time
                    health.status_code = response.status
                    
                    if response.status == 200:
                        # ìƒì„¸ í—¬ìŠ¤ ì •ë³´ íŒŒì‹±
                        if response.content_type == 'application/json':
                            data = await response.json()
                            health.details = data
                            health.is_healthy = data.get('healthy', True)
                        else:
                            health.is_healthy = True
                    else:
                        health.is_healthy = False
                        
        except asyncio.TimeoutError:
            health.is_healthy = False
            health.error = 'Health check timeout'
            
        except Exception as e:
            health.is_healthy = False
            health.error = str(e)
        
        return health

class ServiceDiscovery:
    """ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬"""
    
    def __init__(self, provider: str = 'consul'):
        self.provider = self.init_provider(provider)
        self.cache = ServiceCache()
        self.watchers: List[ServiceWatcher] = []
        
    async def register_service(self, service: Service) -> None:
        """ì„œë¹„ìŠ¤ ë“±ë¡"""
        
        registration = ServiceRegistration(
            id=service.id,
            name=service.name,
            address=service.address,
            port=service.port,
            tags=service.tags,
            meta=service.metadata,
            health_check=HealthCheckDefinition(
                type=service.health_check_type,
                path=service.health_check_path,
                interval=service.health_check_interval,
                timeout=service.health_check_timeout
            )
        )
        
        await self.provider.register(registration)
        await self.cache.add(service)
        await self.notify_watchers('service_registered', service)
    
    async def discover_services(
        self,
        service_name: Optional[str] = None,
        tags: Optional[List[str]] = None
    ) -> List[Service]:
        """ì„œë¹„ìŠ¤ ê²€ìƒ‰"""
        
        # ìºì‹œ í™•ì¸
        cached = await self.cache.get(service_name, tags)
        if cached and not self.cache.is_stale(service_name):
            return cached
        
        # Providerì—ì„œ ì¡°íšŒ
        services = await self.provider.discover(service_name, tags)
        
        # ìºì‹œ ì—…ë°ì´íŠ¸
        await self.cache.update(service_name, services)
        
        return services
    
    async def watch_services(
        self,
        callback: Callable,
        service_name: Optional[str] = None
    ) -> ServiceWatcher:
        """ì„œë¹„ìŠ¤ ë³€ê²½ ê°ì‹œ"""
        
        watcher = ServiceWatcher(
            callback=callback,
            service_name=service_name
        )
        
        self.watchers.append(watcher)
        
        # Provider ê°ì‹œ ì‹œì‘
        await self.provider.watch(
            service_name,
            lambda changes: self.handle_changes(changes, watcher)
        )
        
        return watcher
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ í—¬ìŠ¤ ì²´í¬ ë°©ì‹
- [ ] ì„œë¹„ìŠ¤ ìë™ ë“±ë¡/í•´ì œ
- [ ] ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ ê°ì‹œ
- [ ] ìºì‹± ë©”ì»¤ë‹ˆì¦˜

### SubTask 6.5.3: íŠ¸ë˜í”½ ë¶„ì‚° ì •ì±… ì—”ì§„

**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api-gateway/loadbalancing/traffic-policy.ts
export interface TrafficPolicy {
  id: string;
  name: string;
  conditions: PolicyCondition[];
  actions: PolicyAction[];
  priority: number;
  enabled: boolean;
}

export class TrafficPolicyEngine {
  private policies: Map<string, TrafficPolicy> = new Map();
  private policyEvaluator: PolicyEvaluator;
  private actionExecutor: ActionExecutor;
  
  constructor() {
    this.policyEvaluator = new PolicyEvaluator();
    this.actionExecutor = new ActionExecutor();
    this.initializeDefaultPolicies();
  }
  
  private initializeDefaultPolicies(): void {
    // Canary ë°°í¬ ì •ì±…
    this.addPolicy({
      id: 'canary-deployment',
      name: 'Canary Deployment Policy',
      conditions: [
        {
          type: 'header',
          field: 'x-canary',
          operator: 'equals',
          value: 'true'
        }
      ],
      actions: [
        {
          type: 'route',
          target: 'canary-servers',
          weight: 100
        }
      ],
      priority: 100,
      enabled: true
    });
    
    // A/B í…ŒìŠ¤íŒ… ì •ì±…
    this.addPolicy({
      id: 'ab-testing',
      name: 'A/B Testing Policy',
      conditions: [
        {
          type: 'cookie',
          field: 'experiment-group',
          operator: 'exists'
        }
      ],
      actions: [
        {
          type: 'split',
          splits: [
            { group: 'A', weight: 50, target: 'version-a' },
            { group: 'B', weight: 50, target: 'version-b' }
          ]
        }
      ],
      priority: 90,
      enabled: true
    });
    
    // ì§€ì—­ ê¸°ë°˜ ë¼ìš°íŒ…
    this.addPolicy({
      id: 'geo-routing',
      name: 'Geographic Routing Policy',
      conditions: [
        {
          type: 'geo',
          field: 'country',
          operator: 'in',
          value: ['KR', 'JP', 'CN']
        }
      ],
      actions: [
        {
          type: 'route',
          target: 'asia-servers',
          weight: 100
        }
      ],
      priority: 80,
      enabled: true
    });
  }
  
  async evaluatePolicies(
    request: Request,
    availableServers: Server[]
  ): Promise<RoutingDecision> {
    // í™œì„±í™”ëœ ì •ì±…ì„ ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬
    const activePolicies = Array.from(this.policies.values())
      .filter(p => p.enabled)
      .sort((a, b) => b.priority - a.priority);
    
    for (const policy of activePolicies) {
      // ì¡°ê±´ í‰ê°€
      const matches = await this.policyEvaluator.evaluate(
        policy.conditions,
        request
      );
      
      if (matches) {
        // ì•¡ì…˜ ì‹¤í–‰
        const decision = await this.actionExecutor.execute(
          policy.actions,
          request,
          availableServers
        );
        
        if (decision) {
          return {
            ...decision,
            appliedPolicy: policy.id
          };
        }
      }
    }
    
    // ê¸°ë³¸ ë¼ìš°íŒ… ê²°ì •
    return {
      servers: availableServers,
      strategy: 'default',
      appliedPolicy: 'none'
    };
  }
  
  async addDynamicPolicy(
    policy: TrafficPolicy,
    validateConflicts: boolean = true
  ): Promise<void> {
    if (validateConflicts) {
      const conflicts = await this.detectConflicts(policy);
      if (conflicts.length > 0) {
        throw new PolicyConflictError(
          `Policy conflicts detected: ${conflicts.join(', ')}`
        );
      }
    }
    
    this.policies.set(policy.id, policy);
    await this.reorderPolicies();
  }
}

// íŠ¸ë˜í”½ ì‰ì´í•‘
export class TrafficShaper {
  private rateLimiters: Map<string, RateLimiter> = new Map();
  private throttlers: Map<string, Throttler> = new Map();
  
  async shapeTraffic(
    request: Request,
    policy: TrafficShapingPolicy
  ): Promise<ShapingResult> {
    const result = new ShapingResult();
    
    // 1. Rate Limiting
    if (policy.rateLimit) {
      const limiter = this.getRateLimiter(policy.rateLimit);
      const allowed = await limiter.tryAcquire(request);
      
      if (!allowed) {
        result.rejected = true;
        result.reason = 'rate_limit_exceeded';
        result.retryAfter = limiter.getRetryAfter();
        return result;
      }
    }
    
    // 2. Throttling
    if (policy.throttle) {
      const throttler = this.getThrottler(policy.throttle);
      const delay = await throttler.calculateDelay(request);
      
      if (delay > 0) {
        result.delayed = true;
        result.delay = delay;
        await this.delay(delay);
      }
    }
    
    // 3. Burst Control
    if (policy.burstControl) {
      const burstAllowed = await this.checkBurst(request, policy.burstControl);
      if (!burstAllowed) {
        result.rejected = true;
        result.reason = 'burst_limit_exceeded';
        return result;
      }
    }
    
    // 4. Circuit Breaking
    if (policy.circuitBreaker) {
      const circuit = this.getCircuitBreaker(policy.circuitBreaker);
      if (circuit.isOpen()) {
        result.rejected = true;
        result.reason = 'circuit_open';
        result.fallback = policy.circuitBreaker.fallback;
        return result;
      }
    }
    
    result.allowed = true;
    return result;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì •ì±… ê¸°ë°˜ ë¼ìš°íŒ…
- [ ] íŠ¸ë˜í”½ ì‰ì´í•‘
- [ ] A/B í…ŒìŠ¤íŒ… ì§€ì›
- [ ] Circuit Breaker íŒ¨í„´

### SubTask 6.5.4: ìë™ ìŠ¤ì¼€ì¼ë§ í†µí•©

**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api_gateway/loadbalancing/auto_scaling.py
class AutoScalingManager:
    """ìë™ ìŠ¤ì¼€ì¼ë§ ê´€ë¦¬"""
    
    def __init__(self, config: AutoScalingConfig):
        self.config = config
        self.metrics_collector = MetricsCollector()
        self.scaling_engine = ScalingEngine()
        self.cloud_provider = self.init_cloud_provider()
        
    async def monitor_and_scale(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ë° ìŠ¤ì¼€ì¼ë§ ë£¨í”„"""
        
        while True:
            try:
                # 1. ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                metrics = await self.collect_metrics()
                
                # 2. ìŠ¤ì¼€ì¼ë§ ê²°ì •
                decision = await self.make_scaling_decision(metrics)
                
                # 3. ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰
                if decision.action != ScalingAction.NONE:
                    await self.execute_scaling(decision)
                
                # 4. ì¿¨ë‹¤ìš´ ê¸°ê°„
                await asyncio.sleep(self.config.evaluation_period)
                
            except Exception as e:
                await self.handle_scaling_error(e)
    
    async def make_scaling_decision(
        self,
        metrics: SystemMetrics
    ) -> ScalingDecision:
        """ìŠ¤ì¼€ì¼ë§ ê²°ì •"""
        
        decision = ScalingDecision(
            action=ScalingAction.NONE,
            reason='',
            target_capacity=self.current_capacity
        )
        
        # CPU ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
        if self.config.cpu_scaling:
            if metrics.avg_cpu > self.config.scale_up_threshold:
                decision.action = ScalingAction.SCALE_UP
                decision.reason = f'CPU usage {metrics.avg_cpu}% > {self.config.scale_up_threshold}%'
                decision.target_capacity = self.calculate_scale_up_capacity()
                
            elif metrics.avg_cpu < self.config.scale_down_threshold:
                decision.action = ScalingAction.SCALE_DOWN
                decision.reason = f'CPU usage {metrics.avg_cpu}% < {self.config.scale_down_threshold}%'
                decision.target_capacity = self.calculate_scale_down_capacity()
        
        # ìš”ì²­ ìˆ˜ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
        if self.config.request_scaling:
            requests_per_instance = metrics.total_requests / self.current_capacity
            
            if requests_per_instance > self.config.max_requests_per_instance:
                decision.action = ScalingAction.SCALE_UP
                decision.reason = f'Requests per instance {requests_per_instance} > {self.config.max_requests_per_instance}'
                decision.target_capacity = math.ceil(
                    metrics.total_requests / self.config.target_requests_per_instance
                )
        
        # ì˜ˆì¸¡ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
        if self.config.predictive_scaling:
            predicted_load = await self.predict_future_load(metrics)
            
            if predicted_load > self.config.predictive_threshold:
                decision.action = ScalingAction.SCALE_UP
                decision.reason = f'Predicted load {predicted_load} > {self.config.predictive_threshold}'
                decision.target_capacity = self.calculate_predictive_capacity(predicted_load)
        
        # ì œì•½ ì¡°ê±´ í™•ì¸
        decision = self.apply_constraints(decision)
        
        return decision
    
    async def execute_scaling(self, decision: ScalingDecision) -> None:
        """ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰"""
        
        # 1. ìŠ¤ì¼€ì¼ë§ ì´ë²¤íŠ¸ ê¸°ë¡
        await self.log_scaling_event(decision)
        
        # 2. ì¸ìŠ¤í„´ìŠ¤ ì¡°ì •
        if decision.action == ScalingAction.SCALE_UP:
            await self.scale_up(decision.target_capacity)
        elif decision.action == ScalingAction.SCALE_DOWN:
            await self.scale_down(decision.target_capacity)
        
        # 3. ë¡œë“œ ë°¸ëŸ°ì„œ ì—…ë°ì´íŠ¸
        await self.update_load_balancer()
        
        # 4. í—¬ìŠ¤ ì²´í¬ ëŒ€ê¸°
        await self.wait_for_healthy_state()
        
        # 5. ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self.current_capacity = decision.target_capacity
        await self.metrics_collector.record_scaling(decision)
    
    async def scale_up(self, target_capacity: int) -> None:
        """ìŠ¤ì¼€ì¼ ì—… ì‹¤í–‰"""
        
        instances_to_add = target_capacity - self.current_capacity
        
        # ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘
        new_instances = await self.cloud_provider.launch_instances(
            count=instances_to_add,
            instance_type=self.config.instance_type,
            ami_id=self.config.ami_id,
            security_groups=self.config.security_groups,
            subnet_ids=self.config.subnet_ids,
            user_data=self.generate_user_data()
        )
        
        # ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” ëŒ€ê¸°
        await self.wait_for_instances_ready(new_instances)
        
        # ë¡œë“œ ë°¸ëŸ°ì„œì— ì¶”ê°€
        await self.register_instances(new_instances)
    
    async def scale_down(self, target_capacity: int) -> None:
        """ìŠ¤ì¼€ì¼ ë‹¤ìš´ ì‹¤í–‰"""
        
        instances_to_remove = self.current_capacity - target_capacity
        
        # ì œê±°í•  ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ
        instances = await self.select_instances_to_terminate(instances_to_remove)
        
        # ë¡œë“œ ë°¸ëŸ°ì„œì—ì„œ ì œê±°
        await self.deregister_instances(instances)
        
        # ì—°ê²° ë“œë ˆì´ë‹
        await self.drain_connections(instances)
        
        # ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ
        await self.cloud_provider.terminate_instances(instances)
    
    async def predict_future_load(
        self,
        current_metrics: SystemMetrics
    ) -> float:
        """ë¯¸ë˜ ë¶€í•˜ ì˜ˆì¸¡"""
        
        # ì‹œê³„ì—´ ë°ì´í„° ìˆ˜ì§‘
        historical_data = await self.metrics_collector.get_historical_metrics(
            duration=timedelta(hours=24)
        )
        
        # ML ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜ˆì¸¡
        predictor = LoadPredictor(model='lstm')
        predicted_load = predictor.predict(
            historical_data,
            forecast_horizon=timedelta(minutes=30)
        )
        
        return predicted_load
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ë§ íŠ¸ë¦¬ê±°
- [ ] ì˜ˆì¸¡ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
- [ ] í´ë¼ìš°ë“œ í”„ë¡œë°”ì´ë” í†µí•©
- [ ] ì•ˆì „í•œ ìŠ¤ì¼€ì¼ ë‹¤ìš´

---

## ğŸ“Š Phase 6 Task 6.1-6.5 ì™„ë£Œ í˜„í™©

### âœ… ì™„ë£Œëœ ì‘ì—…
- **Task 6.1**: API Gateway ì•„í‚¤í…ì²˜ ì„¤ê³„ (4 SubTasks)
- **Task 6.2**: ë¼ìš°íŒ… ë° ì—”ë“œí¬ì¸íŠ¸ ê´€ë¦¬ (4 SubTasks)
- **Task 6.3**: ìš”ì²­/ì‘ë‹µ ë³€í™˜ ë ˆì´ì–´ (4 SubTasks)
- **Task 6.4**: API ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ (4 SubTasks)
- **Task 6.5**: ê²Œì´íŠ¸ì›¨ì´ ë¡œë“œ ë°¸ëŸ°ì‹± (4 SubTasks)

### ğŸ“ˆ ì§„í–‰ë¥ 
- Tasks 6.1-6.5 ì§„í–‰ë¥ : 100%
- ì´ 20ê°œ SubTasks ì™„ë£Œ
- ì˜ˆìƒ ì†Œìš”ì‹œê°„: 240ì‹œê°„

### ğŸ¯ ì£¼ìš” ì„±ê³¼
1. **ì™„ì „í•œ API Gateway êµ¬ì¶•**
   - 9ê°œ ì—ì´ì „íŠ¸ í†µí•© ì§€ì›
   - ë‹¤ì–‘í•œ í”„ë¡œí† ì½œ ì§€ì›
   - ê³ ê°€ìš©ì„± ì•„í‚¤í…ì²˜

2. **ê³ ê¸‰ ë¼ìš°íŒ… ê¸°ëŠ¥**
   - ë™ì  ë¼ìš°íŒ… ì—”ì§„
   - ê²½ë¡œ ë§¤ì¹­ ë° íŒŒë¼ë¯¸í„° ì²˜ë¦¬
   - ë¼ìš°íŒ… ê·œì¹™ ê´€ë¦¬

3. **í”„ë¡œí† ì½œ ë³€í™˜**
   - ë‹¤ì–‘í•œ í¬ë§· ì§€ì›
   - ìš”ì²­/ì‘ë‹µ ë³€í™˜
   - ë°ì´í„° íŒŒì´í”„ë¼ì¸

4. **ë²„ì „ ê´€ë¦¬**
   - ë‹¤ì–‘í•œ ë²„ì „ ì „ëµ
   - í•˜ìœ„ í˜¸í™˜ì„± ê´€ë¦¬
   - ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜

5. **ë¡œë“œ ë°¸ëŸ°ì‹±**
   - ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜
   - í—¬ìŠ¤ ì²´í¬ ë° ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬
   - ìë™ ìŠ¤ì¼€ì¼ë§ í†µí•©

---
## Phase 6: RESTful API êµ¬í˜„ (Tasks 6.6-6.10) - SubTask ë¦¬ìŠ¤íŠ¸ ë° ì‘ì—…ì§€ì‹œì„œ

### ğŸ“‹ SubTask ì „ì²´ ë¦¬ìŠ¤íŠ¸

#### Task 6.6: REST ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„
- **SubTask 6.6.1**: RESTful ë¦¬ì†ŒìŠ¤ ëª¨ë¸ë§
- **SubTask 6.6.2**: URL êµ¬ì¡° ë° ë„¤ì´ë° ê·œì¹™
- **SubTask 6.6.3**: HTTP ë©”ì„œë“œ ë§¤í•‘
- **SubTask 6.6.4**: ë¦¬ì†ŒìŠ¤ ê´€ê³„ ë° ì¤‘ì²© êµ¬ì¡°

#### Task 6.7: CRUD ì‘ì—… êµ¬í˜„
- **SubTask 6.7.1**: Create ì‘ì—… êµ¬í˜„
- **SubTask 6.7.2**: Read ì‘ì—… êµ¬í˜„
- **SubTask 6.7.3**: Update ì‘ì—… êµ¬í˜„
- **SubTask 6.7.4**: Delete ì‘ì—… êµ¬í˜„

#### Task 6.8: í˜ì´ì§€ë„¤ì´ì…˜ ë° í•„í„°ë§
- **SubTask 6.8.1**: í˜ì´ì§€ë„¤ì´ì…˜ ì „ëµ êµ¬í˜„
- **SubTask 6.8.2**: í•„í„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•
- **SubTask 6.8.3**: ì •ë ¬ ë° ê²€ìƒ‰ ê¸°ëŠ¥
- **SubTask 6.8.4**: ì»¤ì„œ ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜

#### Task 6.9: ì‘ë‹µ í¬ë§· í‘œì¤€í™”
- **SubTask 6.9.1**: ì‘ë‹µ êµ¬ì¡° í‘œì¤€ ì •ì˜
- **SubTask 6.9.2**: HATEOAS êµ¬í˜„
- **SubTask 6.9.3**: ì½˜í…ì¸  í˜‘ìƒ ì²˜ë¦¬
- **SubTask 6.9.4**: ì‘ë‹µ ë©”íƒ€ë°ì´í„° ê´€ë¦¬

#### Task 6.10: RESTful ì—ëŸ¬ ì²˜ë¦¬
- **SubTask 6.10.1**: ì—ëŸ¬ ì‘ë‹µ í‘œì¤€í™”
- **SubTask 6.10.2**: HTTP ìƒíƒœ ì½”ë“œ ë§¤í•‘
- **SubTask 6.10.3**: ë¬¸ì œ ì„¸ë¶€ì‚¬í•­ (RFC 7807) êµ¬í˜„
- **SubTask 6.10.4**: ì—ëŸ¬ ë³µêµ¬ ë° ì¬ì‹œë„ ì „ëµ

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 6.6: REST ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„

#### SubTask 6.6.1: RESTful ë¦¬ì†ŒìŠ¤ ëª¨ë¸ë§

**ë‹´ë‹¹ì**: API ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api/rest/resource-modeling.ts
export interface Resource {
  id: string;
  type: string;
  attributes: Record<string, any>;
  relationships?: Record<string, Relationship>;
  links?: ResourceLinks;
  meta?: Record<string, any>;
}

export interface Relationship {
  data: ResourceIdentifier | ResourceIdentifier[];
  links?: RelationshipLinks;
  meta?: Record<string, any>;
}

export class ResourceModeler {
  private resources: Map<string, ResourceDefinition> = new Map();
  
  constructor() {
    this.initializeResources();
  }
  
  private initializeResources(): void {
    // T-Developer í•µì‹¬ ë¦¬ì†ŒìŠ¤ ì •ì˜
    
    // í”„ë¡œì íŠ¸ ë¦¬ì†ŒìŠ¤
    this.defineResource({
      name: 'project',
      plural: 'projects',
      attributes: [
        { name: 'name', type: 'string', required: true },
        { name: 'description', type: 'string' },
        { name: 'framework', type: 'string', enum: ['react', 'vue', 'angular'] },
        { name: 'status', type: 'string', enum: ['draft', 'active', 'completed'] },
        { name: 'createdAt', type: 'datetime', readonly: true },
        { name: 'updatedAt', type: 'datetime', readonly: true }
      ],
      relationships: [
        { name: 'owner', type: 'user', cardinality: 'one' },
        { name: 'components', type: 'component', cardinality: 'many' },
        { name: 'agents', type: 'agent-execution', cardinality: 'many' }
      ],
      actions: ['create', 'read', 'update', 'delete', 'generate', 'export']
    });
    
    // ì»´í¬ë„ŒíŠ¸ ë¦¬ì†ŒìŠ¤
    this.defineResource({
      name: 'component',
      plural: 'components',
      attributes: [
        { name: 'name', type: 'string', required: true },
        { name: 'type', type: 'string', required: true },
        { name: 'category', type: 'string' },
        { name: 'code', type: 'text' },
        { name: 'style', type: 'text' },
        { name: 'props', type: 'json' },
        { name: 'dependencies', type: 'array' },
        { name: 'version', type: 'string' }
      ],
      relationships: [
        { name: 'project', type: 'project', cardinality: 'one' },
        { name: 'parent', type: 'component', cardinality: 'one' },
        { name: 'children', type: 'component', cardinality: 'many' },
        { name: 'usedBy', type: 'component', cardinality: 'many' }
      ],
      actions: ['create', 'read', 'update', 'delete', 'duplicate', 'validate']
    });
    
    // ì—ì´ì „íŠ¸ ì‹¤í–‰ ë¦¬ì†ŒìŠ¤
    this.defineResource({
      name: 'agent-execution',
      plural: 'agent-executions',
      attributes: [
        { name: 'agentType', type: 'string', required: true },
        { name: 'status', type: 'string', enum: ['pending', 'running', 'completed', 'failed'] },
        { name: 'input', type: 'json' },
        { name: 'output', type: 'json' },
        { name: 'startedAt', type: 'datetime' },
        { name: 'completedAt', type: 'datetime' },
        { name: 'duration', type: 'number' },
        { name: 'error', type: 'json' }
      ],
      relationships: [
        { name: 'project', type: 'project', cardinality: 'one' },
        { name: 'triggeredBy', type: 'user', cardinality: 'one' },
        { name: 'dependsOn', type: 'agent-execution', cardinality: 'many' }
      ],
      actions: ['create', 'read', 'cancel', 'retry']
    });
    
    // ì‚¬ìš©ì ë¦¬ì†ŒìŠ¤
    this.defineResource({
      name: 'user',
      plural: 'users',
      attributes: [
        { name: 'email', type: 'string', required: true, unique: true },
        { name: 'name', type: 'string' },
        { name: 'role', type: 'string', enum: ['admin', 'developer', 'viewer'] },
        { name: 'preferences', type: 'json' },
        { name: 'lastLogin', type: 'datetime' }
      ],
      relationships: [
        { name: 'projects', type: 'project', cardinality: 'many' },
        { name: 'teams', type: 'team', cardinality: 'many' }
      ],
      actions: ['create', 'read', 'update', 'delete', 'authenticate']
    });
  }
  
  defineResource(definition: ResourceDefinition): void {
    this.resources.set(definition.name, definition);
    
    // ìë™ìœ¼ë¡œ collection ë¦¬ì†ŒìŠ¤ë„ ì •ì˜
    this.defineCollectionResource(definition);
    
    // ê´€ê³„ ê²€ì¦
    this.validateRelationships(definition);
  }
  
  generateResourceSchema(resourceName: string): JSONSchema {
    const definition = this.resources.get(resourceName);
    if (!definition) {
      throw new Error(`Resource ${resourceName} not found`);
    }
    
    const schema: JSONSchema = {
      $schema: 'http://json-schema.org/draft-07/schema#',
      type: 'object',
      title: definition.name,
      properties: {
        id: { type: 'string', format: 'uuid' },
        type: { type: 'string', const: definition.name }
      },
      required: ['id', 'type']
    };
    
    // ì†ì„± ìŠ¤í‚¤ë§ˆ ìƒì„±
    const attributesSchema: JSONSchema = {
      type: 'object',
      properties: {},
      required: []
    };
    
    for (const attr of definition.attributes) {
      attributesSchema.properties![attr.name] = this.attributeToSchema(attr);
      if (attr.required) {
        attributesSchema.required!.push(attr.name);
      }
    }
    
    schema.properties!.attributes = attributesSchema;
    
    // ê´€ê³„ ìŠ¤í‚¤ë§ˆ ìƒì„±
    if (definition.relationships.length > 0) {
      schema.properties!.relationships = this.relationshipsToSchema(definition.relationships);
    }
    
    return schema;
  }
}

// ë¦¬ì†ŒìŠ¤ ë³€í™˜ê¸°
export class ResourceTransformer {
  transform(entity: any, resourceType: string): Resource {
    const definition = this.getResourceDefinition(resourceType);
    
    const resource: Resource = {
      id: entity.id || entity._id || generateId(),
      type: resourceType,
      attributes: {},
      relationships: {},
      links: {
        self: `/api/${definition.plural}/${entity.id}`
      }
    };
    
    // ì†ì„± ë³€í™˜
    for (const attr of definition.attributes) {
      if (entity[attr.name] !== undefined) {
        resource.attributes[attr.name] = this.transformAttribute(
          entity[attr.name],
          attr
        );
      }
    }
    
    // ê´€ê³„ ë³€í™˜
    for (const rel of definition.relationships) {
      if (entity[rel.name]) {
        resource.relationships![rel.name] = this.transformRelationship(
          entity[rel.name],
          rel
        );
      }
    }
    
    return resource;
  }
  
  private transformRelationship(data: any, relationship: RelationshipDefinition): Relationship {
    if (relationship.cardinality === 'one') {
      return {
        data: {
          type: relationship.type,
          id: typeof data === 'object' ? data.id : data
        },
        links: {
          self: `/api/${relationship.type}s/${data.id || data}`,
          related: `/api/${this.currentResource}/relationships/${relationship.name}`
        }
      };
    } else {
      const items = Array.isArray(data) ? data : [data];
      return {
        data: items.map(item => ({
          type: relationship.type,
          id: typeof item === 'object' ? item.id : item
        })),
        links: {
          self: `/api/${this.currentResource}/relationships/${relationship.name}`,
          related: `/api/${this.currentResource}/${relationship.name}`
        }
      };
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë¦¬ì†ŒìŠ¤ ì •ì˜ ì™„ì„±ë„
- [ ] ê´€ê³„ ëª¨ë¸ë§ ì •í™•ì„±
- [ ] JSON Schema ìƒì„±
- [ ] ë³€í™˜ ë¡œì§ êµ¬í˜„

#### SubTask 6.6.2: URL êµ¬ì¡° ë° ë„¤ì´ë° ê·œì¹™

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api/rest/url_structure.py
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
import re

@dataclass
class URLPattern:
    """URL íŒ¨í„´ ì •ì˜"""
    pattern: str
    resource: str
    action: str
    method: str
    parameters: List[str]
    description: str

class RESTfulURLBuilder:
    """RESTful URL êµ¬ì¡° ë¹Œë”"""
    
    def __init__(self):
        self.base_path = "/api/v1"
        self.patterns: List[URLPattern] = []
        self.naming_rules = NamingRules()
        self.initialize_patterns()
    
    def initialize_patterns(self):
        """T-Developer API URL íŒ¨í„´ ì´ˆê¸°í™”"""
        
        # í”„ë¡œì íŠ¸ ê´€ë ¨ URL
        self.add_patterns([
            # Collection operations
            URLPattern(
                pattern="/projects",
                resource="project",
                action="list",
                method="GET",
                parameters=[],
                description="List all projects"
            ),
            URLPattern(
                pattern="/projects",
                resource="project",
                action="create",
                method="POST",
                parameters=[],
                description="Create a new project"
            ),
            
            # Instance operations
            URLPattern(
                pattern="/projects/{projectId}",
                resource="project",
                action="get",
                method="GET",
                parameters=["projectId"],
                description="Get a specific project"
            ),
            URLPattern(
                pattern="/projects/{projectId}",
                resource="project",
                action="update",
                method="PUT",
                parameters=["projectId"],
                description="Update a project"
            ),
            URLPattern(
                pattern="/projects/{projectId}",
                resource="project",
                action="partial_update",
                method="PATCH",
                parameters=["projectId"],
                description="Partially update a project"
            ),
            URLPattern(
                pattern="/projects/{projectId}",
                resource="project",
                action="delete",
                method="DELETE",
                parameters=["projectId"],
                description="Delete a project"
            ),
            
            # Nested resources
            URLPattern(
                pattern="/projects/{projectId}/components",
                resource="component",
                action="list",
                method="GET",
                parameters=["projectId"],
                description="List project components"
            ),
            URLPattern(
                pattern="/projects/{projectId}/components/{componentId}",
                resource="component",
                action="get",
                method="GET",
                parameters=["projectId", "componentId"],
                description="Get a specific component"
            ),
            
            # Custom actions
            URLPattern(
                pattern="/projects/{projectId}/generate",
                resource="project",
                action="generate",
                method="POST",
                parameters=["projectId"],
                description="Generate project code"
            ),
            URLPattern(
                pattern="/projects/{projectId}/export",
                resource="project",
                action="export",
                method="GET",
                parameters=["projectId"],
                description="Export project"
            ),
            
            # Agent executions
            URLPattern(
                pattern="/projects/{projectId}/agents/{agentType}/execute",
                resource="agent",
                action="execute",
                method="POST",
                parameters=["projectId", "agentType"],
                description="Execute an agent"
            ),
            URLPattern(
                pattern="/projects/{projectId}/agents/executions",
                resource="agent-execution",
                action="list",
                method="GET",
                parameters=["projectId"],
                description="List agent executions"
            )
        ])
        
        # ì»´í¬ë„ŒíŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ URL
        self.add_patterns([
            URLPattern(
                pattern="/components/library",
                resource="component",
                action="search",
                method="GET",
                parameters=[],
                description="Search component library"
            ),
            URLPattern(
                pattern="/components/library/{componentId}",
                resource="component",
                action="get",
                method="GET",
                parameters=["componentId"],
                description="Get library component"
            ),
            URLPattern(
                pattern="/components/library/{componentId}/fork",
                resource="component",
                action="fork",
                method="POST",
                parameters=["componentId"],
                description="Fork a library component"
            )
        ])
    
    def build_url(
        self,
        resource: str,
        action: str,
        params: Optional[Dict[str, str]] = None,
        query: Optional[Dict[str, str]] = None
    ) -> str:
        """URL ìƒì„±"""
        
        # íŒ¨í„´ ì°¾ê¸°
        pattern = self.find_pattern(resource, action)
        if not pattern:
            raise ValueError(f"No pattern found for {resource}.{action}")
        
        # URL êµ¬ì„±
        url = self.base_path + pattern.pattern
        
        # íŒŒë¼ë¯¸í„° ì¹˜í™˜
        if params:
            for param_name, param_value in params.items():
                placeholder = f"{{{param_name}}}"
                if placeholder in url:
                    url = url.replace(placeholder, str(param_value))
        
        # ì¿¼ë¦¬ ìŠ¤íŠ¸ë§ ì¶”ê°€
        if query:
            query_string = self.build_query_string(query)
            url += f"?{query_string}"
        
        return url
    
    def validate_url(self, url: str) -> Tuple[bool, Optional[str]]:
        """URL ìœ íš¨ì„± ê²€ì¦"""
        
        # ê¸°ë³¸ í˜•ì‹ ê²€ì¦
        if not url.startswith(self.base_path):
            return False, f"URL must start with {self.base_path}"
        
        # ë„¤ì´ë° ê·œì¹™ ê²€ì¦
        path = url[len(self.base_path):]
        segments = path.split('/')
        
        for segment in segments:
            if segment and not self.naming_rules.validate_segment(segment):
                return False, f"Invalid segment: {segment}"
        
        # íŒ¨í„´ ë§¤ì¹­ ê²€ì¦
        matched = False
        for pattern in self.patterns:
            if self.match_pattern(url, pattern):
                matched = True
                break
        
        if not matched:
            return False, "URL does not match any defined pattern"
        
        return True, None

class NamingRules:
    """ë„¤ì´ë° ê·œì¹™ ê´€ë¦¬"""
    
    def __init__(self):
        self.rules = {
            'case': 'kebab-case',  # kebab-case for URLs
            'plural': True,         # Use plural for collections
            'max_length': 50,       # Maximum segment length
            'allowed_chars': r'^[a-z0-9\-]+$'  # Allowed characters
        }
    
    def validate_segment(self, segment: str) -> bool:
        """ì„¸ê·¸ë¨¼íŠ¸ ìœ íš¨ì„± ê²€ì¦"""
        
        # íŒŒë¼ë¯¸í„°ëŠ” ì œì™¸
        if segment.startswith('{') and segment.endswith('}'):
            return True
        
        # ê¸¸ì´ ê²€ì¦
        if len(segment) > self.rules['max_length']:
            return False
        
        # ë¬¸ì ê²€ì¦
        if not re.match(self.rules['allowed_chars'], segment):
            return False
        
        # ì¼€ì´ìŠ¤ ê²€ì¦
        if self.rules['case'] == 'kebab-case':
            if segment != segment.lower():
                return False
            if '__' in segment or segment.startswith('-') or segment.endswith('-'):
                return False
        
        return True
    
    def format_resource_name(self, name: str, plural: bool = True) -> str:
        """ë¦¬ì†ŒìŠ¤ ì´ë¦„ í¬ë§·íŒ…"""
        
        # CamelCase to kebab-case
        formatted = re.sub('([A-Z]+)', r'-\1', name).lower()
        formatted = formatted.strip('-')
        
        # ë³µìˆ˜í˜• ë³€í™˜
        if plural and self.rules['plural']:
            formatted = self.pluralize(formatted)
        
        return formatted
    
    def pluralize(self, word: str) -> str:
        """ë‹¨ì–´ ë³µìˆ˜í˜• ë³€í™˜"""
        
        # íŠ¹ë³„ ê·œì¹™
        irregular = {
            'person': 'people',
            'child': 'children',
            'man': 'men',
            'woman': 'women',
            'foot': 'feet',
            'tooth': 'teeth',
            'goose': 'geese',
            'mouse': 'mice'
        }
        
        if word in irregular:
            return irregular[word]
        
        # ì¼ë°˜ ê·œì¹™
        if word.endswith('y') and word[-2] not in 'aeiou':
            return word[:-1] + 'ies'
        elif word.endswith(('s', 'ss', 'sh', 'ch', 'x', 'z')):
            return word + 'es'
        elif word.endswith('f'):
            return word[:-1] + 'ves'
        elif word.endswith('fe'):
            return word[:-2] + 'ves'
        else:
            return word + 's'

# URL ë¬¸ì„œ ìƒì„±ê¸°
class URLDocumentationGenerator:
    """URL êµ¬ì¡° ë¬¸ì„œ ìƒì„±"""
    
    def generate_documentation(self, patterns: List[URLPattern]) -> str:
        """ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ URL ë¬¸ì„œ ìƒì„±"""
        
        doc = "# API URL Structure\n\n"
        doc += "## Base URL\n"
        doc += "```\nhttps://api.t-developer.com/api/v1\n```\n\n"
        
        # ë¦¬ì†ŒìŠ¤ë³„ ê·¸ë£¹í•‘
        grouped = self.group_by_resource(patterns)
        
        for resource, resource_patterns in grouped.items():
            doc += f"## {resource.title()} Resource\n\n"
            
            for pattern in resource_patterns:
                doc += f"### {pattern.description}\n"
                doc += f"- **Method**: `{pattern.method}`\n"
                doc += f"- **URL**: `{pattern.pattern}`\n"
                
                if pattern.parameters:
                    doc += f"- **Parameters**: {', '.join(f'`{p}`' for p in pattern.parameters)}\n"
                
                doc += "\n"
                
                # ì˜ˆì œ ì¶”ê°€
                example_url = self.generate_example_url(pattern)
                doc += f"**Example**:\n```\n{pattern.method} {example_url}\n```\n\n"
        
        return doc
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] URL íŒ¨í„´ ì •ì˜
- [ ] ë„¤ì´ë° ê·œì¹™ ì ìš©
- [ ] URL ìœ íš¨ì„± ê²€ì¦
- [ ] ë¬¸ì„œ ìë™ ìƒì„±

#### SubTask 6.6.3: HTTP ë©”ì„œë“œ ë§¤í•‘

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api/rest/http-method-mapper.ts
export enum HTTPMethod {
  GET = 'GET',
  POST = 'POST',
  PUT = 'PUT',
  PATCH = 'PATCH',
  DELETE = 'DELETE',
  HEAD = 'HEAD',
  OPTIONS = 'OPTIONS'
}

export interface MethodMapping {
  method: HTTPMethod;
  action: string;
  description: string;
  idempotent: boolean;
  safe: boolean;
  requestBody: boolean;
  responseBody: boolean;
  cacheable: boolean;
}

export class HTTPMethodMapper {
  private mappings: Map<string, MethodMapping> = new Map();
  
  constructor() {
    this.initializeMappings();
  }
  
  private initializeMappings(): void {
    // í‘œì¤€ CRUD ë§¤í•‘
    this.addMapping({
      method: HTTPMethod.GET,
      action: 'retrieve',
      description: 'Retrieve resource(s)',
      idempotent: true,
      safe: true,
      requestBody: false,
      responseBody: true,
      cacheable: true
    });
    
    this.addMapping({
      method: HTTPMethod.POST,
      action: 'create',
      description: 'Create new resource',
      idempotent: false,
      safe: false,
      requestBody: true,
      responseBody: true,
      cacheable: false
    });
    
    this.addMapping({
      method: HTTPMethod.PUT,
      action: 'replace',
      description: 'Replace entire resource',
      idempotent: true,
      safe: false,
      requestBody: true,
      responseBody: true,
      cacheable: false
    });
    
    this.addMapping({
      method: HTTPMethod.PATCH,
      action: 'update',
      description: 'Partially update resource',
      idempotent: false,
      safe: false,
      requestBody: true,
      responseBody: true,
      cacheable: false
    });
    
    this.addMapping({
      method: HTTPMethod.DELETE,
      action: 'remove',
      description: 'Delete resource',
      idempotent: true,
      safe: false,
      requestBody: false,
      responseBody: false,
      cacheable: false
    });
    
    // íŠ¹ìˆ˜ ì‘ì—… ë§¤í•‘
    this.addMapping({
      method: HTTPMethod.HEAD,
      action: 'check',
      description: 'Check resource existence',
      idempotent: true,
      safe: true,
      requestBody: false,
      responseBody: false,
      cacheable: true
    });
    
    this.addMapping({
      method: HTTPMethod.OPTIONS,
      action: 'describe',
      description: 'Get allowed methods',
      idempotent: true,
      safe: true,
      requestBody: false,
      responseBody: true,
      cacheable: true
    });
  }
  
  mapActionToMethod(action: string, context?: ActionContext): HTTPMethod {
    // í‘œì¤€ ì•¡ì…˜ ë§¤í•‘
    const standardMappings: Record<string, HTTPMethod> = {
      'list': HTTPMethod.GET,
      'get': HTTPMethod.GET,
      'create': HTTPMethod.POST,
      'update': HTTPMethod.PUT,
      'patch': HTTPMethod.PATCH,
      'delete': HTTPMethod.DELETE,
      'search': HTTPMethod.GET,
      'filter': HTTPMethod.GET
    };
    
    // ì»¤ìŠ¤í…€ ì•¡ì…˜ ë§¤í•‘ (T-Developer íŠ¹í™”)
    const customMappings: Record<string, HTTPMethod> = {
      'generate': HTTPMethod.POST,    // ì½”ë“œ ìƒì„±
      'execute': HTTPMethod.POST,     // ì—ì´ì „íŠ¸ ì‹¤í–‰
      'analyze': HTTPMethod.POST,     // ë¶„ì„ ì‹¤í–‰
      'validate': HTTPMethod.POST,    // ê²€ì¦ ì‹¤í–‰
      'export': HTTPMethod.GET,       // ë‚´ë³´ë‚´ê¸°
      'import': HTTPMethod.POST,      // ê°€ì ¸ì˜¤ê¸°
      'duplicate': HTTPMethod.POST,   // ë³µì œ
      'fork': HTTPMethod.POST,        // í¬í¬
      'merge': HTTPMethod.POST,       // ë³‘í•©
      'preview': HTTPMethod.GET,      // ë¯¸ë¦¬ë³´ê¸°
      'download': HTTPMethod.GET,     // ë‹¤ìš´ë¡œë“œ
      'upload': HTTPMethod.POST       // ì—…ë¡œë“œ
    };
    
    // ìš°ì„ ìˆœìœ„: ì»¤ìŠ¤í…€ > í‘œì¤€
    if (customMappings[action]) {
      return customMappings[action];
    }
    
    if (standardMappings[action]) {
      return standardMappings[action];
    }
    
    // ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ë¡ 
    if (context) {
      return this.inferMethodFromContext(action, context);
    }
    
    // ê¸°ë³¸ê°’
    return HTTPMethod.POST;
  }
  
  private inferMethodFromContext(action: string, context: ActionContext): HTTPMethod {
    // ì•¡ì…˜ ì´ë¦„ ë¶„ì„
    const actionLower = action.toLowerCase();
    
    // ì½ê¸° ì‘ì—… íŒ¨í„´
    const readPatterns = ['get', 'fetch', 'retrieve', 'find', 'list', 'search', 'show', 'view'];
    if (readPatterns.some(pattern => actionLower.includes(pattern))) {
      return HTTPMethod.GET;
    }
    
    // ìƒì„± ì‘ì—… íŒ¨í„´
    const createPatterns = ['create', 'add', 'new', 'generate', 'build', 'make'];
    if (createPatterns.some(pattern => actionLower.includes(pattern))) {
      return HTTPMethod.POST;
    }
    
    // ì—…ë°ì´íŠ¸ ì‘ì—… íŒ¨í„´
    const updatePatterns = ['update', 'edit', 'modify', 'change', 'set'];
    if (updatePatterns.some(pattern => actionLower.includes(pattern))) {
      return context.partial ? HTTPMethod.PATCH : HTTPMethod.PUT;
    }
    
    // ì‚­ì œ ì‘ì—… íŒ¨í„´
    const deletePatterns = ['delete', 'remove', 'destroy', 'clear'];
    if (deletePatterns.some(pattern => actionLower.includes(pattern))) {
      return HTTPMethod.DELETE;
    }
    
    return HTTPMethod.POST;
  }
  
  validateMethodUsage(method: HTTPMethod, operation: Operation): ValidationResult {
    const errors: string[] = [];
    const warnings: string[] = [];
    
    const mapping = this.getMappingForMethod(method);
    
    // GET ë©”ì„œë“œ ê²€ì¦
    if (method === HTTPMethod.GET) {
      if (operation.requestBody && Object.keys(operation.requestBody).length > 0) {
        errors.push('GET requests should not have a request body');
      }
      if (operation.sideEffects) {
        errors.push('GET requests must be safe (no side effects)');
      }
    }
    
    // DELETE ë©”ì„œë“œ ê²€ì¦
    if (method === HTTPMethod.DELETE) {
      if (operation.responseBody && operation.responseBody !== '204 No Content') {
        warnings.push('DELETE requests typically return 204 No Content');
      }
    }
    
    // PUT vs PATCH ê²€ì¦
    if (method === HTTPMethod.PUT && operation.partial) {
      warnings.push('Consider using PATCH for partial updates');
    }
    
    if (method === HTTPMethod.PATCH && !operation.partial) {
      warnings.push('PATCH should be used for partial updates only');
    }
    
    // POST ë©±ë“±ì„± ê²½ê³ 
    if (method === HTTPMethod.POST && operation.idempotent) {
      warnings.push('POST is not idempotent by default, consider PUT');
    }
    
    // ìºì‹± ê²€ì¦
    if (operation.cacheable && !mapping?.cacheable) {
      errors.push(`${method} responses should not be cached`);
    }
    
    return {
      valid: errors.length === 0,
      errors,
      warnings
    };
  }
}

// ë©”ì„œë“œ ì˜¤ë²„ë¼ì´ë“œ í•¸ë“¤ëŸ¬
export class MethodOverrideHandler {
  private overrideHeaders = ['X-HTTP-Method-Override', 'X-Method-Override'];
  
  detectOverride(request: Request): HTTPMethod | null {
    // í—¤ë” ê¸°ë°˜ ì˜¤ë²„ë¼ì´ë“œ
    for (const header of this.overrideHeaders) {
      const overrideMethod = request.headers[header.toLowerCase()];
      if (overrideMethod) {
        return overrideMethod.toUpperCase() as HTTPMethod;
      }
    }
    
    // ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ê¸°ë°˜ ì˜¤ë²„ë¼ì´ë“œ
    if (request.query._method) {
      return request.query._method.toUpperCase() as HTTPMethod;
    }
    
    // POST ë³¸ë¬¸ ê¸°ë°˜ ì˜¤ë²„ë¼ì´ë“œ
    if (request.method === 'POST' && request.body?._method) {
      return request.body._method.toUpperCase() as HTTPMethod;
    }
    
    return null;
  }
  
  applyOverride(request: Request): Request {
    const override = this.detectOverride(request);
    
    if (override && this.isValidOverride(request.method, override)) {
      request.originalMethod = request.method;
      request.method = override;
      
      // ì˜¤ë²„ë¼ì´ë“œ ì •ë³´ ê¸°ë¡
      request.metadata.methodOverridden = true;
      request.metadata.originalMethod = request.originalMethod;
    }
    
    return request;
  }
  
  private isValidOverride(original: string, override: string): boolean {
    // POST ë©”ì„œë“œë§Œ ì˜¤ë²„ë¼ì´ë“œ í—ˆìš©
    if (original !== 'POST') {
      return false;
    }
    
    // ì•ˆì „í•˜ì§€ ì•Šì€ ë©”ì„œë“œë¡œë§Œ ì˜¤ë²„ë¼ì´ë“œ í—ˆìš©
    const allowedOverrides = ['PUT', 'PATCH', 'DELETE'];
    return allowedOverrides.includes(override);
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] í‘œì¤€ HTTP ë©”ì„œë“œ ë§¤í•‘
- [ ] ì»¤ìŠ¤í…€ ì•¡ì…˜ ì²˜ë¦¬
- [ ] ë©”ì„œë“œ ì‚¬ìš© ê²€ì¦
- [ ] ë©”ì„œë“œ ì˜¤ë²„ë¼ì´ë“œ ì§€ì›

#### SubTask 6.6.4: ë¦¬ì†ŒìŠ¤ ê´€ê³„ ë° ì¤‘ì²© êµ¬ì¡°

**ë‹´ë‹¹ì**: API ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api/rest/resource_relationships.py
from typing import List, Dict, Optional, Set
from dataclasses import dataclass
from enum import Enum

class RelationshipType(Enum):
    """ê´€ê³„ ìœ í˜•"""
    ONE_TO_ONE = "one-to-one"
    ONE_TO_MANY = "one-to-many"
    MANY_TO_ONE = "many-to-one"
    MANY_TO_MANY = "many-to-many"

@dataclass
class ResourceRelationship:
    """ë¦¬ì†ŒìŠ¤ ê´€ê³„ ì •ì˜"""
    name: str
    source_resource: str
    target_resource: str
    type: RelationshipType
    inverse_name: Optional[str] = None
    nested: bool = False
    embedded: bool = False
    cascade_delete: bool = False
    required: bool = False

class ResourceRelationshipManager:
    """ë¦¬ì†ŒìŠ¤ ê´€ê³„ ê´€ë¦¬"""
    
    def __init__(self):
        self.relationships: Dict[str, List[ResourceRelationship]] = {}
        self.initialize_relationships()
    
    def initialize_relationships(self):
        """T-Developer ë¦¬ì†ŒìŠ¤ ê´€ê³„ ì´ˆê¸°í™”"""
        
        # Project ê´€ê³„
        self.add_relationship(ResourceRelationship(
            name="owner",
            source_resource="project",
            target_resource="user",
            type=RelationshipType.MANY_TO_ONE,
            inverse_name="projects",
            required=True
        ))
        
        self.add_relationship(ResourceRelationship(
            name="components",
            source_resource="project",
            target_resource="component",
            type=RelationshipType.ONE_TO_MANY,
            inverse_name="project",
            nested=True,
            cascade_delete=True
        ))
        
        self.add_relationship(ResourceRelationship(
            name="executions",
            source_resource="project",
            target_resource="agent_execution",
            type=RelationshipType.ONE_TO_MANY,
            inverse_name="project",
            nested=True,
            cascade_delete=False
        ))
        
        # Component ê´€ê³„
        self.add_relationship(ResourceRelationship(
            name="parent",
            source_resource="component",
            target_resource="component",
            type=RelationshipType.MANY_TO_ONE,
            inverse_name="children",
            nested=False
        ))
        
        self.add_relationship(ResourceRelationship(
            name="dependencies",
            source_resource="component",
            target_resource="component",
            type=RelationshipType.MANY_TO_MANY,
            inverse_name="dependents",
            embedded=False
        ))
        
        # Agent Execution ê´€ê³„
        self.add_relationship(ResourceRelationship(
            name="triggered_by",
            source_resource="agent_execution",
            target_resource="user",
            type=RelationshipType.MANY_TO_ONE,
            inverse_name="triggered_executions",
            required=True
        ))
        
        self.add_relationship(ResourceRelationship(
            name="depends_on",
            source_resource="agent_execution",
            target_resource="agent_execution",
            type=RelationshipType.MANY_TO_MANY,
            inverse_name="dependent_executions"
        ))
    
    def generate_nested_routes(self, relationship: ResourceRelationship) -> List[Route]:
        """ì¤‘ì²© ë¼ìš°íŠ¸ ìƒì„±"""
        
        routes = []
        
        if not relationship.nested:
            return routes
        
        source_plural = self.pluralize(relationship.source_resource)
        target_plural = self.pluralize(relationship.target_resource)
        
        if relationship.type in [RelationshipType.ONE_TO_MANY, RelationshipType.MANY_TO_MANY]:
            # ì»¬ë ‰ì…˜ ë¼ìš°íŠ¸
            routes.extend([
                Route(
                    path=f"/{source_plural}/{{source_id}}/{relationship.name}",
                    method="GET",
                    handler=f"list_{relationship.name}",
                    description=f"List {relationship.name} of {relationship.source_resource}"
                ),
                Route(
                    path=f"/{source_plural}/{{source_id}}/{relationship.name}",
                    method="POST",
                    handler=f"add_{relationship.name}",
                    description=f"Add {relationship.name} to {relationship.source_resource}"
                )
            ])
            
            # ê°œë³„ ë¦¬ì†ŒìŠ¤ ë¼ìš°íŠ¸
            routes.extend([
                Route(
                    path=f"/{source_plural}/{{source_id}}/{relationship.name}/{{target_id}}",
                    method="GET",
                    handler=f"get_{relationship.name}_item",
                    description=f"Get specific {relationship.target_resource}"
                ),
                Route(
                    path=f"/{source_plural}/{{source_id}}/{relationship.name}/{{target_id}}",
                    method="PUT",
                    handler=f"update_{relationship.name}_item",
                    description=f"Update {relationship.target_resource}"
                ),
                Route(
                    path=f"/{source_plural}/{{source_id}}/{relationship.name}/{{target_id}}",
                    method="DELETE",
                    handler=f"remove_{relationship.name}_item",
                    description=f"Remove {relationship.target_resource}"
                )
            ])
        
        elif relationship.type == RelationshipType.ONE_TO_ONE:
            routes.extend([
                Route(
                    path=f"/{source_plural}/{{source_id}}/{relationship.name}",
                    method="GET",
                    handler=f"get_{relationship.name}",
                    description=f"Get {relationship.name} of {relationship.source_resource}"
                ),
                Route(
                    path=f"/{source_plural}/{{source_id}}/{relationship.name}",
                    method="PUT",
                    handler=f"set_{relationship.name}",
                    description=f"Set {relationship.name} for {relationship.source_resource}"
                ),
                Route(
                    path=f"/{source_plural}/{{source_id}}/{relationship.name}",
                    method="DELETE",
                    handler=f"remove_{relationship.name}",
                    description=f"Remove {relationship.name} from {relationship.source_resource}"
                )
            ])
        
        return routes
    
    def build_relationship_links(
        self,
        resource_type: str,
        resource_id: str
    ) -> Dict[str, str]:
        """ê´€ê³„ ë§í¬ ìƒì„±"""
        
        links = {}
        relationships = self.relationships.get(resource_type, [])
        
        for rel in relationships:
            if rel.nested:
                # ì¤‘ì²© ê´€ê³„ ë§í¬
                links[rel.name] = f"/api/{self.pluralize(resource_type)}/{resource_id}/{rel.name}"
            else:
                # ê´€ê³„ ë§í¬
                links[f"related_{rel.name}"] = f"/api/{self.pluralize(resource_type)}/{resource_id}/relationships/{rel.name}"
        
        return links

class NestedResourceHandler:
    """ì¤‘ì²© ë¦¬ì†ŒìŠ¤ ì²˜ë¦¬"""
    
    def __init__(self, relationship_manager: ResourceRelationshipManager):
        self.relationship_manager = relationship_manager
        self.max_nesting_depth = 3
    
    async def handle_nested_request(
        self,
        request: Request,
        path_segments: List[str]
    ) -> Response:
        """ì¤‘ì²© ìš”ì²­ ì²˜ë¦¬"""
        
        # ê²½ë¡œ ë¶„ì„
        resource_chain = self.parse_resource_chain(path_segments)
        
        # ê¹Šì´ ê²€ì¦
        if len(resource_chain) > self.max_nesting_depth:
            raise NestingDepthExceededError(
                f"Maximum nesting depth ({self.max_nesting_depth}) exceeded"
            )
        
        # ê´€ê³„ ê²€ì¦
        for i in range(len(resource_chain) - 1):
            parent = resource_chain[i]
            child = resource_chain[i + 1]
            
            if not self.validate_relationship(parent.resource_type, child.resource_type):
                raise InvalidRelationshipError(
                    f"No relationship between {parent.resource_type} and {child.resource_type}"
                )
        
        # ê¶Œí•œ ê²€ì¦
        await self.validate_access_chain(resource_chain, request.user)
        
        # ìš”ì²­ ì²˜ë¦¬
        return await self.process_nested_request(request, resource_chain)
    
    def parse_resource_chain(self, segments: List[str]) -> List[ResourceNode]:
        """ë¦¬ì†ŒìŠ¤ ì²´ì¸ íŒŒì‹±"""
        
        chain = []
        i = 0
        
        while i < len(segments):
            # ë¦¬ì†ŒìŠ¤ íƒ€ì…
            resource_type = self.singularize(segments[i])
            i += 1
            
            # ë¦¬ì†ŒìŠ¤ ID (ìˆëŠ” ê²½ìš°)
            resource_id = None
            if i < len(segments) and not self.is_resource_name(segments[i]):
                resource_id = segments[i]
                i += 1
            
            chain.append(ResourceNode(
                resource_type=resource_type,
                resource_id=resource_id
            ))
        
        return chain
    
    async def expand_relationships(
        self,
        resource: Dict,
        expand: List[str],
        depth: int = 1
    ) -> Dict:
        """ê´€ê³„ í™•ì¥"""
        
        if depth > self.max_nesting_depth:
            return resource
        
        expanded = resource.copy()
        
        for rel_name in expand:
            if '.' in rel_name:
                # ì¤‘ì²© í™•ì¥
                parts = rel_name.split('.', 1)
                primary = parts[0]
                nested = parts[1]
                
                # 1ì°¨ ê´€ê³„ í™•ì¥
                if primary not in expanded:
                    expanded[primary] = await self.load_relationship(
                        resource['type'],
                        resource['id'],
                        primary
                    )
                
                # ì¤‘ì²© ê´€ê³„ í™•ì¥
                if isinstance(expanded[primary], list):
                    for item in expanded[primary]:
                        await self.expand_relationships(item, [nested], depth + 1)
                else:
                    await self.expand_relationships(expanded[primary], [nested], depth + 1)
            else:
                # ë‹¨ìˆœ í™•ì¥
                expanded[rel_name] = await self.load_relationship(
                    resource['type'],
                    resource['id'],
                    rel_name
                )
        
        return expanded
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ê´€ê³„ ìœ í˜• ì •ì˜
- [ ] ì¤‘ì²© ë¼ìš°íŠ¸ ìƒì„±
- [ ] ê´€ê³„ ë§í¬ êµ¬ì„±
- [ ] ê´€ê³„ í™•ì¥ ì²˜ë¦¬

---

### Task 6.7: CRUD ì‘ì—… êµ¬í˜„

#### SubTask 6.7.1: Create ì‘ì—… êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api/rest/crud/create.ts
export interface CreateOperation<T> {
  validate(data: Partial<T>): Promise<ValidationResult>;
  preProcess(data: Partial<T>): Promise<T>;
  execute(data: T): Promise<T>;
  postProcess(created: T): Promise<T>;
  generateResponse(resource: T): Response;
}

export class CreateOperationHandler<T> implements CreateOperation<T> {
  constructor(
    private resourceType: string,
    private repository: Repository<T>,
    private validator: Validator<T>,
    private eventEmitter: EventEmitter
  ) {}
  
  async handle(request: Request): Promise<Response> {
    try {
      // 1. ìš”ì²­ ë°ì´í„° ì¶”ì¶œ
      const requestData = this.extractData(request);
      
      // 2. ìœ íš¨ì„± ê²€ì¦
      const validation = await this.validate(requestData);
      if (!validation.valid) {
        return this.errorResponse(400, validation.errors);
      }
      
      // 3. ì „ì²˜ë¦¬
      const processedData = await this.preProcess(requestData);
      
      // 4. ì¤‘ë³µ ì²´í¬
      await this.checkDuplicates(processedData);
      
      // 5. ìƒì„± ì‹¤í–‰
      const created = await this.execute(processedData);
      
      // 6. í›„ì²˜ë¦¬
      const finalResource = await this.postProcess(created);
      
      // 7. ì´ë²¤íŠ¸ ë°œìƒ
      await this.emitCreatedEvent(finalResource);
      
      // 8. ì‘ë‹µ ìƒì„±
      return this.generateResponse(finalResource);
      
    } catch (error) {
      return this.handleError(error);
    }
  }
  
  async validate(data: Partial<T>): Promise<ValidationResult> {
    // ìŠ¤í‚¤ë§ˆ ê²€ì¦
    const schemaValidation = await this.validator.validateSchema(data);
    if (!schemaValidation.valid) {
      return schemaValidation;
    }
    
    // í•„ìˆ˜ í•„ë“œ ê²€ì¦
    const requiredFields = this.getRequiredFields();
    const missingFields = requiredFields.filter(field => !(field in data));
    
    if (missingFields.length > 0) {
      return {
        valid: false,
        errors: missingFields.map(field => ({
          field,
          message: `${field} is required`
        }))
      };
    }
    
    // ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦
    return await this.validator.validateBusinessRules(data);
  }
  
  async preProcess(data: Partial<T>): Promise<T> {
    const processed = { ...data } as T;
    
    // ID ìƒì„±
    if (!processed['id']) {
      processed['id'] = generateUUID();
    }
    
    // íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
    const now = new Date();
    processed['createdAt'] = now;
    processed['updatedAt'] = now;
    
    // ê¸°ë³¸ê°’ ì„¤ì •
    const defaults = this.getDefaultValues();
    for (const [key, value] of Object.entries(defaults)) {
      if (!(key in processed)) {
        processed[key] = value;
      }
    }
    
    // ë°ì´í„° ì •ê·œí™”
    return this.normalizeData(processed);
  }
  
  async execute(data: T): Promise<T> {
    // íŠ¸ëœì­ì…˜ ì‹œì‘
    const transaction = await this.repository.beginTransaction();
    
    try {
      // ë¦¬ì†ŒìŠ¤ ìƒì„±
      const created = await this.repository.create(data, { transaction });
      
      // ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìƒì„±
      await this.createRelatedResources(created, transaction);
      
      // íŠ¸ëœì­ì…˜ ì»¤ë°‹
      await transaction.commit();
      
      return created;
      
    } catch (error) {
      // íŠ¸ëœì­ì…˜ ë¡¤ë°±
      await transaction.rollback();
      throw error;
    }
  }
  
  async postProcess(created: T): Promise<T> {
    // ê´€ê³„ ë¡œë“œ
    const withRelations = await this.loadRelationships(created);
    
    // ê³„ì‚° í•„ë“œ ì¶”ê°€
    const withComputedFields = this.addComputedFields(withRelations);
    
    // ìºì‹œ ì—…ë°ì´íŠ¸
    await this.updateCache(withComputedFields);
    
    // ê²€ìƒ‰ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
    await this.updateSearchIndex(withComputedFields);
    
    return withComputedFields;
  }
  
  generateResponse(resource: T): Response {
    return {
      status: 201,
      headers: {
        'Location': `/api/${this.resourceType}s/${resource['id']}`,
        'Content-Type': 'application/json'
      },
      body: {
        data: this.transformToResource(resource),
        links: {
          self: `/api/${this.resourceType}s/${resource['id']}`
        }
      }
    };
  }
  
  private async checkDuplicates(data: T): Promise<void> {
    const uniqueFields = this.getUniqueFields();
    
    for (const field of uniqueFields) {
      if (data[field]) {
        const existing = await this.repository.findOne({
          [field]: data[field]
        });
        
        if (existing) {
          throw new DuplicateResourceError(
            `${this.resourceType} with ${field}='${data[field]}' already exists`
          );
        }
      }
    }
  }
}

// ì¼ê´„ ìƒì„± í•¸ë“¤ëŸ¬
export class BulkCreateHandler<T> {
  constructor(
    private createHandler: CreateOperationHandler<T>,
    private batchSize: number = 100
  ) {}
  
  async handleBulk(request: Request): Promise<Response> {
    const items = request.body.data;
    
    if (!Array.isArray(items)) {
      return this.errorResponse(400, 'Request body must contain an array');
    }
    
    const results = {
      created: [],
      failed: []
    };
    
    // ë°°ì¹˜ ì²˜ë¦¬
    for (let i = 0; i < items.length; i += this.batchSize) {
      const batch = items.slice(i, i + this.batchSize);
      const batchResults = await this.processBatch(batch);
      
      results.created.push(...batchResults.created);
      results.failed.push(...batchResults.failed);
    }
    
    return {
      status: 207, // Multi-Status
      body: {
        data: results.created,
        errors: results.failed,
        meta: {
          total: items.length,
          created: results.created.length,
          failed: results.failed.length
        }
      }
    };
  }
  
  private async processBatch(items: Partial<T>[]): Promise<BatchResult> {
    const results = {
      created: [],
      failed: []
    };
    
    // ë³‘ë ¬ ì²˜ë¦¬
    const promises = items.map(async (item, index) => {
      try {
        const created = await this.createHandler.handle({
          body: item
        } as Request);
        
        return { success: true, data: created, index };
      } catch (error) {
        return { 
          success: false, 
          error: error.message,
          index,
          item 
        };
      }
    });
    
    const batchResults = await Promise.all(promises);
    
    for (const result of batchResults) {
      if (result.success) {
        results.created.push(result.data);
      } else {
        results.failed.push({
          index: result.index,
          item: result.item,
          error: result.error
        });
      }
    }
    
    return results;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì™„ì „í•œ ìƒì„± í”Œë¡œìš°
- [ ] ìœ íš¨ì„± ê²€ì¦
- [ ] íŠ¸ëœì­ì…˜ ì²˜ë¦¬
- [ ] ì¼ê´„ ìƒì„± ì§€ì›

---

### Task 6.7: CRUD ì‘ì—… êµ¬í˜„ (ê³„ì†)

#### SubTask 6.7.2: Read ì‘ì—… êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api/rest/crud/read.py
from typing import Optional, List, Dict, Any
from dataclasses import dataclass

@dataclass
class ReadOptions:
    """ì½ê¸° ì˜µì…˜"""
    fields: Optional[List[str]] = None  # ì„ íƒ í•„ë“œ
    expand: Optional[List[str]] = None  # í™•ì¥ ê´€ê³„
    include: Optional[List[str]] = None  # í¬í•¨ ë¦¬ì†ŒìŠ¤
    exclude: Optional[List[str]] = None  # ì œì™¸ í•„ë“œ

class ReadOperationHandler:
    """Read ì‘ì—… í•¸ë“¤ëŸ¬"""
    
    def __init__(self, resource_type: str, repository: Repository):
        self.resource_type = resource_type
        self.repository = repository
        self.cache_manager = CacheManager()
        self.field_selector = FieldSelector()
    
    async def get_single(self, resource_id: str, options: ReadOptions) -> Response:
        """ë‹¨ì¼ ë¦¬ì†ŒìŠ¤ ì¡°íšŒ"""
        
        try:
            # 1. ìºì‹œ í™•ì¸
            cache_key = self.build_cache_key(resource_id, options)
            cached = await self.cache_manager.get(cache_key)
            
            if cached:
                return self.create_response(cached, from_cache=True)
            
            # 2. ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
            resource = await self.repository.find_by_id(resource_id)
            
            if not resource:
                raise ResourceNotFoundError(
                    f"{self.resource_type} with id '{resource_id}' not found"
                )
            
            # 3. ê¶Œí•œ í™•ì¸
            await self.check_read_permission(resource)
            
            # 4. í•„ë“œ ì„ íƒ
            if options.fields:
                resource = self.field_selector.select(resource, options.fields)
            
            # 5. ê´€ê³„ í™•ì¥
            if options.expand:
                resource = await self.expand_relationships(resource, options.expand)
            
            # 6. í¬í•¨ ë¦¬ì†ŒìŠ¤ ë¡œë“œ
            if options.include:
                resource = await self.include_resources(resource, options.include)
            
            # 7. ì œì™¸ í•„ë“œ ì²˜ë¦¬
            if options.exclude:
                resource = self.field_selector.exclude(resource, options.exclude)
            
            # 8. ìºì‹œ ì €ì¥
            await self.cache_manager.set(cache_key, resource, ttl=300)
            
            # 9. ì‘ë‹µ ìƒì„±
            return self.create_response(resource)
            
        except Exception as e:
            return self.handle_error(e)
    
    async def get_collection(
        self,
        filters: Optional[Dict] = None,
        options: ReadOptions = None
    ) -> Response:
        """ì»¬ë ‰ì…˜ ì¡°íšŒ"""
        
        try:
            # 1. ì¿¼ë¦¬ êµ¬ì„±
            query = self.build_query(filters)
            
            # 2. ì´ ê°œìˆ˜ ì¡°íšŒ (í˜ì´ì§€ë„¤ì´ì…˜ìš©)
            total_count = await self.repository.count(query)
            
            # 3. ë¦¬ì†ŒìŠ¤ ì¡°íšŒ
            resources = await self.repository.find_many(query)
            
            # 4. ê¶Œí•œ í•„í„°ë§
            resources = await self.filter_by_permission(resources)
            
            # 5. í•„ë“œ ì²˜ë¦¬
            if options:
                resources = [
                    await self.process_resource(r, options) 
                    for r in resources
                ]
            
            # 6. ì‘ë‹µ ìƒì„±
            return self.create_collection_response(resources, total_count)
            
        except Exception as e:
            return self.handle_error(e)
    
    async def expand_relationships(
        self,
        resource: Dict,
        relationships: List[str]
    ) -> Dict:
        """ê´€ê³„ í™•ì¥"""
        
        expanded = resource.copy()
        
        for rel_path in relationships:
            # ì¤‘ì²© ê´€ê³„ ì²˜ë¦¬ (ì˜ˆ: author.profile)
            if '.' in rel_path:
                parts = rel_path.split('.')
                current = expanded
                
                for i, part in enumerate(parts[:-1]):
                    if part not in current:
                        current[part] = await self.load_relationship(
                            current['id'],
                            part
                        )
                    current = current[part]
                
                # ë§ˆì§€ë§‰ ê´€ê³„ ë¡œë“œ
                final_part = parts[-1]
                if current:
                    current[final_part] = await self.load_relationship(
                        current['id'],
                        final_part
                    )
            else:
                # ë‹¨ìˆœ ê´€ê³„
                expanded[rel_path] = await self.load_relationship(
                    resource['id'],
                    rel_path
                )
        
        return expanded
    
    async def include_resources(
        self,
        resource: Dict,
        includes: List[str]
    ) -> Dict:
        """ê´€ë ¨ ë¦¬ì†ŒìŠ¤ í¬í•¨"""
        
        included = []
        
        for include_path in includes:
            related = await self.load_related_resources(resource, include_path)
            included.extend(related)
        
        # JSON:API ìŠ¤íƒ€ì¼ ì‘ë‹µ
        return {
            'data': resource,
            'included': included
        }
    
    def create_response(
        self,
        resource: Dict,
        from_cache: bool = False
    ) -> Response:
        """ì‘ë‹µ ìƒì„±"""
        
        headers = {
            'Content-Type': 'application/json',
            'ETag': self.generate_etag(resource)
        }
        
        if from_cache:
            headers['X-Cache'] = 'HIT'
        else:
            headers['X-Cache'] = 'MISS'
        
        return Response(
            status=200,
            headers=headers,
            body={
                'data': self.transform_resource(resource),
                'links': self.generate_links(resource),
                'meta': self.generate_meta(resource)
            }
        )

class StreamingReadHandler:
    """ìŠ¤íŠ¸ë¦¬ë° ì½ê¸° í•¸ë“¤ëŸ¬"""
    
    def __init__(self, repository: Repository):
        self.repository = repository
        self.chunk_size = 100
    
    async def stream_collection(
        self,
        filters: Dict,
        options: ReadOptions
    ) -> AsyncIterator:
        """ëŒ€ìš©ëŸ‰ ì»¬ë ‰ì…˜ ìŠ¤íŠ¸ë¦¬ë°"""
        
        # ì»¤ì„œ ê¸°ë°˜ ì¡°íšŒ
        cursor = None
        
        while True:
            # ì²­í¬ ì¡°íšŒ
            chunk = await self.repository.find_many(
                filters,
                cursor=cursor,
                limit=self.chunk_size
            )
            
            if not chunk:
                break
            
            # ê° ë¦¬ì†ŒìŠ¤ ì²˜ë¦¬ ë° ì „ì†¡
            for resource in chunk:
                processed = await self.process_resource(resource, options)
                yield self.format_stream_item(processed)
            
            # ë‹¤ìŒ ì»¤ì„œ ì„¤ì •
            cursor = chunk[-1]['id']
    
    def format_stream_item(self, resource: Dict) -> bytes:
        """ìŠ¤íŠ¸ë¦¼ ì•„ì´í…œ í¬ë§·"""
        
        # NDJSON (Newline Delimited JSON) í˜•ì‹
        return json.dumps(resource).encode('utf-8') + b'\n'

class ConditionalReadHandler:
    """ì¡°ê±´ë¶€ ì½ê¸° í•¸ë“¤ëŸ¬"""
    
    async def handle_conditional_get(
        self,
        resource_id: str,
        if_none_match: Optional[str] = None,
        if_modified_since: Optional[datetime] = None
    ) -> Response:
        """ì¡°ê±´ë¶€ GET ì²˜ë¦¬"""
        
        # ë¦¬ì†ŒìŠ¤ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        metadata = await self.get_resource_metadata(resource_id)
        
        # ETag ê²€ì¦
        if if_none_match:
            current_etag = metadata['etag']
            if if_none_match == current_etag:
                return Response(
                    status=304,  # Not Modified
                    headers={'ETag': current_etag}
                )
        
        # ìˆ˜ì • ì‹œê°„ ê²€ì¦
        if if_modified_since:
            last_modified = metadata['updated_at']
            if last_modified <= if_modified_since:
                return Response(
                    status=304,  # Not Modified
                    headers={'Last-Modified': last_modified.isoformat()}
                )
        
        # ë³€ê²½ëœ ê²½ìš° ì „ì²´ ë¦¬ì†ŒìŠ¤ ë°˜í™˜
        resource = await self.get_resource(resource_id)
        
        return Response(
            status=200,
            headers={
                'ETag': metadata['etag'],
                'Last-Modified': metadata['updated_at'].isoformat()
            },
            body={'data': resource}
        )
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¨ì¼/ì»¬ë ‰ì…˜ ì¡°íšŒ
- [ ] í•„ë“œ ì„ íƒ ë° í™•ì¥
- [ ] ìºì‹± ì „ëµ
- [ ] ì¡°ê±´ë¶€ ì½ê¸° ì§€ì›

#### SubTask 6.7.3: Update ì‘ì—… êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api/rest/crud/update.ts
export interface UpdateOperation<T> {
  validateUpdate(id: string, data: Partial<T>): Promise<ValidationResult>;
  checkConcurrency(id: string, version: string): Promise<void>;
  applyUpdate(existing: T, updates: Partial<T>): T;
  executeUpdate(id: string, data: T): Promise<T>;
}

export class UpdateOperationHandler<T> implements UpdateOperation<T> {
  constructor(
    private resourceType: string,
    private repository: Repository<T>,
    private validator: Validator<T>,
    private auditLogger: AuditLogger
  ) {}
  
  async handlePut(request: Request): Promise<Response> {
    /**
     * PUT - ì „ì²´ êµì²´
     */
    const resourceId = request.params.id;
    const replacementData = request.body;
    
    try {
      // 1. ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì¡°íšŒ
      const existing = await this.repository.findById(resourceId);
      if (!existing) {
        // PUTì€ ë©±ë“±ì„±ì„ ìœ„í•´ ì—†ìœ¼ë©´ ìƒì„±í•  ìˆ˜ë„ ìˆìŒ
        if (this.config.allowPutCreate) {
          return await this.createWithPut(resourceId, replacementData);
        }
        throw new ResourceNotFoundError(`${this.resourceType} not found`);
      }
      
      // 2. ê¶Œí•œ í™•ì¸
      await this.checkUpdatePermission(existing);
      
      // 3. ì „ì²´ êµì²´ ë°ì´í„° ê²€ì¦
      const validation = await this.validator.validateComplete(replacementData);
      if (!validation.valid) {
        return this.errorResponse(400, validation.errors);
      }
      
      // 4. ë¶ˆë³€ í•„ë“œ ë³´ì¡´
      const preserved = this.preserveImmutableFields(existing, replacementData);
      
      // 5. ì—…ë°ì´íŠ¸ ì‹¤í–‰
      const updated = await this.executeReplace(resourceId, preserved);
      
      // 6. ê°ì‚¬ ë¡œê·¸
      await this.auditLogger.logUpdate(
        this.resourceType,
        resourceId,
        existing,
        updated,
        request.user
      );
      
      // 7. ì‘ë‹µ
      return this.createUpdateResponse(updated);
      
    } catch (error) {
      return this.handleError(error);
    }
  }
  
  async handlePatch(request: Request): Promise<Response> {
    /**
     * PATCH - ë¶€ë¶„ ì—…ë°ì´íŠ¸
     */
    const resourceId = request.params.id;
    const patchData = request.body;
    
    try {
      // 1. ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì¡°íšŒ
      const existing = await this.repository.findById(resourceId);
      if (!existing) {
        throw new ResourceNotFoundError(`${this.resourceType} not found`);
      }
      
      // 2. ë‚™ê´€ì  ì ê¸ˆ í™•ì¸
      if (request.headers['if-match']) {
        await this.checkConcurrency(resourceId, request.headers['if-match']);
      }
      
      // 3. ê¶Œí•œ í™•ì¸
      await this.checkUpdatePermission(existing);
      
      // 4. íŒ¨ì¹˜ ì‘ì—… íŒŒì‹±
      const operations = this.parsePatchOperations(patchData);
      
      // 5. ê° ì‘ì—… ê²€ì¦ ë° ì ìš©
      let updated = { ...existing };
      for (const operation of operations) {
        updated = await this.applyPatchOperation(updated, operation);
      }
      
      // 6. ìµœì¢… ê²€ì¦
      const validation = await this.validator.validate(updated);
      if (!validation.valid) {
        return this.errorResponse(400, validation.errors);
      }
      
      // 7. ì—…ë°ì´íŠ¸ ì‹¤í–‰
      const saved = await this.executeUpdate(resourceId, updated);
      
      // 8. ë³€ê²½ ì´ë²¤íŠ¸ ë°œìƒ
      await this.emitUpdateEvent(existing, saved);
      
      // 9. ì‘ë‹µ
      return this.createUpdateResponse(saved);
      
    } catch (error) {
      return this.handleError(error);
    }
  }
  
  private parsePatchOperations(patchData: any): PatchOperation[] {
    // JSON Patch (RFC 6902) ì§€ì›
    if (Array.isArray(patchData)) {
      return patchData.map(op => ({
        op: op.op,
        path: op.path,
        value: op.value,
        from: op.from
      }));
    }
    
    // JSON Merge Patch (RFC 7396) ì§€ì›
    return this.convertMergePatchToOperations(patchData);
  }
  
  private async applyPatchOperation(
    resource: T,
    operation: PatchOperation
  ): Promise<T> {
    switch (operation.op) {
      case 'add':
        return this.applyAdd(resource, operation.path, operation.value);
        
      case 'remove':
        return this.applyRemove(resource, operation.path);
        
      case 'replace':
        return this.applyReplace(resource, operation.path, operation.value);
        
      case 'move':
        return this.applyMove(resource, operation.from, operation.path);
        
      case 'copy':
        return this.applyCopy(resource, operation.from, operation.path);
        
      case 'test':
        const testResult = this.applyTest(resource, operation.path, operation.value);
        if (!testResult) {
          throw new PatchTestFailedError(`Test operation failed at ${operation.path}`);
        }
        return resource;
        
      default:
        throw new InvalidPatchOperationError(`Unknown operation: ${operation.op}`);
    }
  }
  
  private preserveImmutableFields(existing: T, replacement: T): T {
    const immutableFields = ['id', 'createdAt', 'createdBy'];
    const result = { ...replacement };
    
    for (const field of immutableFields) {
      if (field in existing) {
        result[field] = existing[field];
      }
    }
    
    // ì—…ë°ì´íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„
    result['updatedAt'] = new Date();
    
    return result;
  }
  
  async checkConcurrency(id: string, version: string): Promise<void> {
    const current = await this.repository.getVersion(id);
    
    if (current !== version) {
      throw new ConcurrencyError(
        'Resource has been modified',
        {
          currentVersion: current,
          providedVersion: version
        }
      );
    }
  }
}

// ì¼ê´„ ì—…ë°ì´íŠ¸ í•¸ë“¤ëŸ¬
export class BulkUpdateHandler<T> {
  constructor(
    private updateHandler: UpdateOperationHandler<T>,
    private batchSize: number = 50
  ) {}
  
  async handleBulkUpdate(request: Request): Promise<Response> {
    const updates = request.body.updates;
    
    if (!Array.isArray(updates)) {
      return this.errorResponse(400, 'Updates must be an array');
    }
    
    const results = {
      updated: [],
      failed: []
    };
    
    // íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì²˜ë¦¬
    const transaction = await this.repository.beginTransaction();
    
    try {
      for (const update of updates) {
        try {
          const updated = await this.updateHandler.handlePatch({
            params: { id: update.id },
            body: update.data,
            headers: request.headers
          } as Request);
          
          results.updated.push(updated);
        } catch (error) {
          results.failed.push({
            id: update.id,
            error: error.message
          });
        }
      }
      
      // ëª¨ë‘ ì„±ê³µí•œ ê²½ìš°ë§Œ ì»¤ë°‹
      if (results.failed.length === 0) {
        await transaction.commit();
      } else {
        await transaction.rollback();
        return this.errorResponse(400, {
          message: 'Bulk update failed',
          failed: results.failed
        });
      }
      
      return {
        status: 200,
        body: {
          data: results.updated,
          meta: {
            total: updates.length,
            updated: results.updated.length
          }
        }
      };
      
    } catch (error) {
      await transaction.rollback();
      throw error;
    }
  }
}

// ì¡°ê±´ë¶€ ì—…ë°ì´íŠ¸
export class ConditionalUpdateHandler<T> {
  async handleConditionalUpdate(
    id: string,
    updates: Partial<T>,
    conditions: UpdateConditions
  ): Promise<Response> {
    // ì¡°ê±´ ê²€ì¦
    const existing = await this.repository.findById(id);
    
    // If-Match í—¤ë” ê²€ì¦
    if (conditions.ifMatch && existing.etag !== conditions.ifMatch) {
      return {
        status: 412, // Precondition Failed
        headers: {
          'ETag': existing.etag
        },
        body: {
          error: 'ETag mismatch'
        }
      };
    }
    
    // If-Unmodified-Since ê²€ì¦
    if (conditions.ifUnmodifiedSince) {
      if (existing.updatedAt > conditions.ifUnmodifiedSince) {
        return {
          status: 412, // Precondition Failed
          headers: {
            'Last-Modified': existing.updatedAt.toISOString()
          },
          body: {
            error: 'Resource has been modified'
          }
        };
      }
    }
    
    // ì—…ë°ì´íŠ¸ ì‹¤í–‰
    const updated = await this.executeUpdate(id, updates);
    
    return {
      status: 200,
      headers: {
        'ETag': updated.etag,
        'Last-Modified': updated.updatedAt.toISOString()
      },
      body: {
        data: updated
      }
    };
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] PUT/PATCH ë©”ì„œë“œ êµ¬ë¶„
- [ ] JSON Patch ì§€ì›
- [ ] ë‚™ê´€ì  ì ê¸ˆ
- [ ] ì¼ê´„ ì—…ë°ì´íŠ¸

#### SubTask 6.7.4: Delete ì‘ì—… êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api/rest/crud/delete.py
class DeleteOperationHandler:
    """Delete ì‘ì—… í•¸ë“¤ëŸ¬"""
    
    def __init__(self, resource_type: str, repository: Repository):
        self.resource_type = resource_type
        self.repository = repository
        self.cascade_manager = CascadeDeleteManager()
        self.archive_manager = ArchiveManager()
    
    async def handle_delete(self, resource_id: str, options: DeleteOptions) -> Response:
        """ë¦¬ì†ŒìŠ¤ ì‚­ì œ"""
        
        try:
            # 1. ë¦¬ì†ŒìŠ¤ ì¡´ì¬ í™•ì¸
            resource = await self.repository.find_by_id(resource_id)
            if not resource:
                # ë©±ë“±ì„±ì„ ìœ„í•´ 404 ëŒ€ì‹  204 ë°˜í™˜ ê°€ëŠ¥
                if options.idempotent:
                    return Response(status=204)
                raise ResourceNotFoundError(f"{self.resource_type} not found")
            
            # 2. ê¶Œí•œ í™•ì¸
            await self.check_delete_permission(resource)
            
            # 3. ì‚­ì œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            await self.validate_deletion(resource)
            
            # 4. ì†Œí”„íŠ¸ ì‚­ì œ vs í•˜ë“œ ì‚­ì œ
            if options.soft_delete:
                result = await self.soft_delete(resource)
            else:
                result = await self.hard_delete(resource, options)
            
            # 5. ì‚­ì œ ì´ë²¤íŠ¸ ë°œìƒ
            await self.emit_delete_event(resource, options)
            
            # 6. ì‘ë‹µ ìƒì„±
            return self.create_delete_response(result, options)
            
        except Exception as e:
            return self.handle_error(e)
    
    async def soft_delete(self, resource: Dict) -> Dict:
        """ì†Œí”„íŠ¸ ì‚­ì œ"""
        
        # ì‚­ì œ ë§ˆí‚¹
        resource['deleted'] = True
        resource['deleted_at'] = datetime.now()
        resource['deleted_by'] = get_current_user()
        
        # ì—…ë°ì´íŠ¸
        updated = await self.repository.update(resource['id'], resource)
        
        # ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì²˜ë¦¬
        await self.handle_soft_delete_relations(resource)
        
        return updated
    
    async def hard_delete(self, resource: Dict, options: DeleteOptions) -> None:
        """í•˜ë“œ ì‚­ì œ"""
        
        # íŠ¸ëœì­ì…˜ ì‹œì‘
        transaction = await self.repository.begin_transaction()
        
        try:
            # 1. ì•„ì¹´ì´ë¸Œ (ì„ íƒì )
            if options.archive:
                await self.archive_manager.archive(resource)
            
            # 2. ì¢…ì† ë¦¬ì†ŒìŠ¤ ì²˜ë¦¬
            if options.cascade:
                await self.cascade_manager.delete_dependencies(
                    self.resource_type,
                    resource['id'],
                    transaction
                )
            else:
                # ì¢…ì†ì„± í™•ì¸
                dependencies = await self.check_dependencies(resource['id'])
                if dependencies:
                    raise DependencyConstraintError(
                        f"Cannot delete: {len(dependencies)} dependent resources exist"
                    )
            
            # 3. ë¦¬ì†ŒìŠ¤ ì‚­ì œ
            await self.repository.delete(resource['id'], transaction)
            
            # 4. ìºì‹œ ë¬´íš¨í™”
            await self.invalidate_cache(resource['id'])
            
            # 5. ê²€ìƒ‰ ì¸ë±ìŠ¤ ì œê±°
            await self.remove_from_search_index(resource['id'])
            
            # ì»¤ë°‹
            await transaction.commit()
            
        except Exception as e:
            await transaction.rollback()
            raise e
    
    async def validate_deletion(self, resource: Dict) -> None:
        """ì‚­ì œ ê°€ëŠ¥ ì—¬ë¶€ ê²€ì¦"""
        
        # ë³´í˜¸ëœ ë¦¬ì†ŒìŠ¤ í™•ì¸
        if resource.get('protected'):
            raise ProtectedResourceError(
                f"This {self.resource_type} is protected and cannot be deleted"
            )
        
        # ìƒíƒœ í™•ì¸
        if resource.get('status') in ['processing', 'active']:
            raise InvalidStateError(
                f"Cannot delete {self.resource_type} in {resource['status']} state"
            )
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦
        await self.validate_business_rules(resource)
    
    async def check_dependencies(self, resource_id: str) -> List[Dependency]:
        """ì¢…ì†ì„± í™•ì¸"""
        
        dependencies = []
        
        # ì •ì˜ëœ ê´€ê³„ í™•ì¸
        relationships = self.get_resource_relationships()
        
        for rel in relationships:
            if rel.cascade_delete:
                continue
                
            count = await self.repository.count_related(
                resource_id,
                rel.name
            )
            
            if count > 0:
                dependencies.append(Dependency(
                    type=rel.target_resource,
                    count=count,
                    relationship=rel.name
                ))
        
        return dependencies
    
    def create_delete_response(
        self,
        result: Optional[Dict],
        options: DeleteOptions
    ) -> Response:
        """ì‚­ì œ ì‘ë‹µ ìƒì„±"""
        
        if options.soft_delete and options.return_deleted:
            # ì†Œí”„íŠ¸ ì‚­ì œ ì‹œ ì‚­ì œëœ ë¦¬ì†ŒìŠ¤ ë°˜í™˜
            return Response(
                status=200,
                body={'data': result}
            )
        
        # ì¼ë°˜ì ìœ¼ë¡œ 204 No Content
        return Response(
            status=204,
            headers={'Content-Length': '0'}
        )

class BulkDeleteHandler:
    """ì¼ê´„ ì‚­ì œ í•¸ë“¤ëŸ¬"""
    
    def __init__(self, delete_handler: DeleteOperationHandler):
        self.delete_handler = delete_handler
        self.batch_size = 100
    
    async def handle_bulk_delete(
        self,
        resource_ids: List[str],
        options: DeleteOptions
    ) -> Response:
        """ì¼ê´„ ì‚­ì œ"""
        
        results = {
            'deleted': [],
            'failed': [],
            'skipped': []
        }
        
        # ì‚­ì œ ìˆœì„œ ê²°ì • (ì¢…ì†ì„± ê³ ë ¤)
        ordered_ids = await self.order_by_dependencies(resource_ids)
        
        # ë°°ì¹˜ ì²˜ë¦¬
        for batch in self.batch_iterator(ordered_ids, self.batch_size):
            batch_results = await self.process_batch(batch, options)
            
            results['deleted'].extend(batch_results['deleted'])
            results['failed'].extend(batch_results['failed'])
            results['skipped'].extend(batch_results['skipped'])
        
        return Response(
            status=207,  # Multi-Status
            body={
                'meta': {
                    'total': len(resource_ids),
                    'deleted': len(results['deleted']),
                    'failed': len(results['failed']),
                    'skipped': len(results['skipped'])
                },
                'data': results
            }
        )
    
    async def order_by_dependencies(
        self,
        resource_ids: List[str]
    ) -> List[str]:
        """ì¢…ì†ì„±ì— ë”°ë¥¸ ì‚­ì œ ìˆœì„œ ê²°ì •"""
        
        # ì¢…ì†ì„± ê·¸ë˜í”„ êµ¬ì„±
        graph = DependencyGraph()
        
        for resource_id in resource_ids:
            dependencies = await self.get_dependencies(resource_id)
            graph.add_node(resource_id, dependencies)
        
        # ìœ„ìƒ ì •ë ¬
        return graph.topological_sort()

class RecycleBinManager:
    """íœ´ì§€í†µ ê´€ë¦¬"""
    
    def __init__(self):
        self.retention_period = timedelta(days=30)
    
    async def move_to_recycle_bin(self, resource: Dict) -> None:
        """íœ´ì§€í†µìœ¼ë¡œ ì´ë™"""
        
        recycled = {
            'original_id': resource['id'],
            'resource_type': resource['type'],
            'resource_data': resource,
            'deleted_at': datetime.now(),
            'deleted_by': get_current_user(),
            'expires_at': datetime.now() + self.retention_period
        }
        
        await self.recycle_repository.create(recycled)
    
    async def restore_from_recycle_bin(
        self,
        recycle_id: str
    ) -> Dict:
        """íœ´ì§€í†µì—ì„œ ë³µì›"""
        
        recycled = await self.recycle_repository.find_by_id(recycle_id)
        
        if not recycled:
            raise ResourceNotFoundError("Recycled item not found")
        
        if datetime.now() > recycled['expires_at']:
            raise ExpiredResourceError("Recycled item has expired")
        
        # ì›ë³¸ ë³µì›
        restored = recycled['resource_data']
        restored['restored_at'] = datetime.now()
        restored['restored_by'] = get_current_user()
        
        # ì›ë³¸ ìœ„ì¹˜ë¡œ ë³µì›
        await self.repository.create(restored)
        
        # íœ´ì§€í†µì—ì„œ ì œê±°
        await self.recycle_repository.delete(recycle_id)
        
        return restored
    
    async def empty_recycle_bin(self) -> None:
        """íœ´ì§€í†µ ë¹„ìš°ê¸° (ë§Œë£Œëœ í•­ëª©)"""
        
        expired = await self.recycle_repository.find_expired()
        
        for item in expired:
            await self.recycle_repository.delete(item['id'])
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì†Œí”„íŠ¸/í•˜ë“œ ì‚­ì œ
- [ ] ì¢…ì†ì„± ì²˜ë¦¬
- [ ] ì¼ê´„ ì‚­ì œ
- [ ] íœ´ì§€í†µ ê¸°ëŠ¥

---

### Task 6.8: í˜ì´ì§€ë„¤ì´ì…˜ ë° í•„í„°ë§

#### SubTask 6.8.1: í˜ì´ì§€ë„¤ì´ì…˜ ì „ëµ êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api/rest/pagination/pagination-strategies.ts
export interface PaginationStrategy {
  paginate(query: Query, params: PaginationParams): Promise<PaginatedResult>;
  generateLinks(result: PaginatedResult, baseUrl: string): PaginationLinks;
  generateMetadata(result: PaginatedResult): PaginationMetadata;
}

// ì˜¤í”„ì…‹ ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜
export class OffsetPagination implements PaginationStrategy {
  constructor(
    private defaultLimit: number = 20,
    private maxLimit: number = 100
  ) {}
  
  async paginate(query: Query, params: PaginationParams): Promise<PaginatedResult> {
    // íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    const page = Math.max(1, params.page || 1);
    const limit = Math.min(this.maxLimit, params.limit || this.defaultLimit);
    const offset = (page - 1) * limit;
    
    // ì´ ê°œìˆ˜ ì¡°íšŒ
    const totalCount = await query.count();
    
    // ë°ì´í„° ì¡°íšŒ
    const items = await query
      .offset(offset)
      .limit(limit)
      .execute();
    
    // í˜ì´ì§€ ì •ë³´ ê³„ì‚°
    const totalPages = Math.ceil(totalCount / limit);
    const hasNext = page < totalPages;
    const hasPrev = page > 1;
    
    return {
      items,
      pagination: {
        page,
        limit,
        offset,
        totalCount,
        totalPages,
        hasNext,
        hasPrev
      }
    };
  }
  
  generateLinks(result: PaginatedResult, baseUrl: string): PaginationLinks {
    const { page, limit, totalPages, hasNext, hasPrev } = result.pagination;
    const links: PaginationLinks = {
      self: `${baseUrl}?page=${page}&limit=${limit}`
    };
    
    if (hasNext) {
      links.next = `${baseUrl}?page=${page + 1}&limit=${limit}`;
      links.last = `${baseUrl}?page=${totalPages}&limit=${limit}`;
    }
    
    if (hasPrev) {
      links.prev = `${baseUrl}?page=${page - 1}&limit=${limit}`;
      links.first = `${baseUrl}?page=1&limit=${limit}`;
    }
    
    return links;
  }
  
  generateMetadata(result: PaginatedResult): PaginationMetadata {
    return {
      pagination: {
        ...result.pagination,
        type: 'offset',
        pageSize: result.pagination.limit,
        currentPage: result.pagination.page
      }
    };
  }
}

// ì»¤ì„œ ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜
export class CursorPagination implements PaginationStrategy {
  constructor(
    private cursorField: string = 'id',
    private defaultLimit: number = 20
  ) {}
  
  async paginate(query: Query, params: PaginationParams): Promise<PaginatedResult> {
    const limit = params.limit || this.defaultLimit;
    const cursor = params.cursor;
    const direction = params.direction || 'next';
    
    // ì»¤ì„œ ê¸°ë°˜ ì¿¼ë¦¬
    let paginatedQuery = query.limit(limit + 1); // +1 for hasMore check
    
    if (cursor) {
      if (direction === 'next') {
        paginatedQuery = paginatedQuery.where(
          this.cursorField,
          '>',
          this.decodeCursor(cursor)
        );
      } else {
        paginatedQuery = paginatedQuery.where(
          this.cursorField,
          '<',
          this.decodeCursor(cursor)
        ).orderBy(this.cursorField, 'desc');
      }
    }
    
    // ë°ì´í„° ì¡°íšŒ
    const items = await paginatedQuery.execute();
    
    // ë‹¤ìŒ í˜ì´ì§€ ì¡´ì¬ ì—¬ë¶€
    const hasMore = items.length > limit;
    if (hasMore) {
      items.pop(); // Remove extra item
    }
    
    // ì»¤ì„œ ìƒì„±
    const startCursor = items.length > 0 
      ? this.encodeCursor(items[0][this.cursorField])
      : null;
    
    const endCursor = items.length > 0
      ? this.encodeCursor(items[items.length - 1][this.cursorField])
      : null;
    
    return {
      items,
      pagination: {
        limit,
        hasNextPage: hasMore && direction === 'next',
        hasPrevPage: hasMore && direction === 'prev',
        startCursor,
        endCursor
      }
    };
  }
  
  private encodeCursor(value: any): string {
    return Buffer.from(JSON.stringify({
      field: this.cursorField,
      value
    })).toString('base64');
  }
  
  private decodeCursor(cursor: string): any {
    const decoded = Buffer.from(cursor, 'base64').toString();
    return JSON.parse(decoded).value;
  }
  
  generateLinks(result: PaginatedResult, baseUrl: string): PaginationLinks {
    const links: PaginationLinks = {
      self: baseUrl
    };
    
    if (result.pagination.hasNextPage) {
      links.next = `${baseUrl}?cursor=${result.pagination.endCursor}&limit=${result.pagination.limit}`;
    }
    
    if (result.pagination.hasPrevPage) {
      links.prev = `${baseUrl}?cursor=${result.pagination.startCursor}&direction=prev&limit=${result.pagination.limit}`;
    }
    
    return links;
  }
}

// í‚¤ì…‹ í˜ì´ì§€ë„¤ì´ì…˜ (ì„±ëŠ¥ ìµœì í™”)
export class KeysetPagination implements PaginationStrategy {
  constructor(
    private sortFields: string[] = ['id'],
    private defaultLimit: number = 20
  ) {}
  
  async paginate(query: Query, params: PaginationParams): Promise<PaginatedResult> {
    const limit = params.limit || this.defaultLimit;
    const keyset = params.keyset ? this.parseKeyset(params.keyset) : null;
    
    // í‚¤ì…‹ ê¸°ë°˜ ì¿¼ë¦¬ êµ¬ì„±
    let paginatedQuery = query.limit(limit + 1);
    
    if (keyset) {
      // ë³µí•© í‚¤ ë¹„êµ
      const conditions = this.buildKeysetConditions(keyset);
      paginatedQuery = paginatedQuery.whereRaw(conditions);
    }
    
    // ì •ë ¬ ì ìš©
    for (const field of this.sortFields) {
      paginatedQuery = paginatedQuery.orderBy(field);
    }
    
    // ì‹¤í–‰
    const items = await paginatedQuery.execute();
    
    const hasMore = items.length > limit;
    if (hasMore) {
      items.pop();
    }
    
    // ë‹¤ìŒ í‚¤ì…‹ ìƒì„±
    const nextKeyset = hasMore && items.length > 0
      ? this.createKeyset(items[items.length - 1])
      : null;
    
    return {
      items,
      pagination: {
        limit,
        hasMore,
        nextKeyset
      }
    };
  }
  
  private buildKeysetConditions(keyset: any): string {
    // ë³µí•© í‚¤ ë¹„êµ ì¡°ê±´ ìƒì„±
    // (a, b, c) > (x, y, z) í˜•íƒœ
    const fields = this.sortFields;
    const values = fields.map(f => keyset[f]);
    
    return `(${fields.join(',')}) > (${values.map(() => '?').join(',')})`;
  }
  
  private createKeyset(item: any): string {
    const keyset = {};
    for (const field of this.sortFields) {
      keyset[field] = item[field];
    }
    return Buffer.from(JSON.stringify(keyset)).toString('base64');
  }
  
  private parseKeyset(keyset: string): any {
    return JSON.parse(Buffer.from(keyset, 'base64').toString());
  }
}

// ë¬´í•œ ìŠ¤í¬ë¡¤ ì§€ì›
export class InfiniteScrollPagination {
  private cursorPagination: CursorPagination;
  
  constructor() {
    this.cursorPagination = new CursorPagination();
  }
  
  async loadMore(
    query: Query,
    lastCursor: string | null,
    limit: number = 20
  ): Promise<InfiniteScrollResult> {
    const result = await this.cursorPagination.paginate(query, {
      cursor: lastCursor,
      limit
    });
    
    return {
      items: result.items,
      nextCursor: result.pagination.endCursor,
      hasMore: result.pagination.hasNextPage,
      meta: {
        loadedCount: result.items.length,
        timestamp: new Date()
      }
    };
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ í˜ì´ì§€ë„¤ì´ì…˜ ì „ëµ
- [ ] ì»¤ì„œ ê¸°ë°˜ êµ¬í˜„
- [ ] ë§í¬ ìƒì„±
- [ ] ë¬´í•œ ìŠ¤í¬ë¡¤ ì§€ì›

#### SubTask 6.8.2: í•„í„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api/rest/filtering/filter_system.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

class FilterOperator(Enum):
    """í•„í„° ì—°ì‚°ì"""
    EQUALS = "eq"
    NOT_EQUALS = "ne"
    GREATER_THAN = "gt"
    GREATER_THAN_OR_EQUAL = "gte"
    LESS_THAN = "lt"
    LESS_THAN_OR_EQUAL = "lte"
    IN = "in"
    NOT_IN = "nin"
    CONTAINS = "contains"
    STARTS_WITH = "starts"
    ENDS_WITH = "ends"
    REGEX = "regex"
    EXISTS = "exists"
    BETWEEN = "between"

@dataclass
class FilterDefinition:
    """í•„í„° ì •ì˜"""
    field: str
    operator: FilterOperator
    value: Any
    case_sensitive: bool = True
    data_type: Optional[str] = None

class FilterParser:
    """í•„í„° íŒŒì„œ"""
    
    def parse_filters(self, query_params: Dict) -> List[FilterDefinition]:
        """ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì—ì„œ í•„í„° íŒŒì‹±"""
        
        filters = []
        
        # ë‹¨ìˆœ í•„í„° (field=value)
        for key, value in query_params.items():
            if not self.is_filter_param(key):
                continue
            
            # ì—°ì‚°ì í¬í•¨ í•„í„° (field[operator]=value)
            if '[' in key and ']' in key:
                field, operator = self.parse_filter_key(key)
                filters.append(FilterDefinition(
                    field=field,
                    operator=FilterOperator(operator),
                    value=self.parse_filter_value(value)
                ))
            else:
                # ê¸°ë³¸ equals ì—°ì‚°ì
                filters.append(FilterDefinition(
                    field=key,
                    operator=FilterOperator.EQUALS,
                    value=value
                ))
        
        # ë³µí•© í•„í„° íŒŒì‹± (filter íŒŒë¼ë¯¸í„°)
        if 'filter' in query_params:
            complex_filters = self.parse_complex_filter(query_params['filter'])
            filters.extend(complex_filters)
        
        return filters
    
    def parse_complex_filter(self, filter_string: str) -> List[FilterDefinition]:
        """ë³µí•© í•„í„° ë¬¸ìì—´ íŒŒì‹±"""
        # ì˜ˆ: "status:active,created_at:>2024-01-01,tags:in:python,java"
        
        filters = []
        filter_parts = filter_string.split(',')
        
        for part in filter_parts:
            if ':' not in part:
                continue
            
            components = part.split(':')
            
            if len(components) == 2:
                # field:value
                field, value = components
                filters.append(FilterDefinition(
                    field=field,
                    operator=FilterOperator.EQUALS,
                    value=value
                ))
            elif len(components) == 3:
                # field:operator:value
                field, operator, value = components
                filters.append(FilterDefinition(
                    field=field,
                    operator=self.parse_operator(operator),
                    value=self.parse_value(value)
                ))
        
        return filters
    
    def parse_operator(self, op_string: str) -> FilterOperator:
        """ì—°ì‚°ì ë¬¸ìì—´ íŒŒì‹±"""
        
        operator_map = {
            '=': FilterOperator.EQUALS,
            '!=': FilterOperator.NOT_EQUALS,
            '>': FilterOperator.GREATER_THAN,
            '>=': FilterOperator.GREATER_THAN_OR_EQUAL,
            '<': FilterOperator.LESS_THAN,
            '<=': FilterOperator.LESS_THAN_OR_EQUAL,
            'in': FilterOperator.IN,
            'nin': FilterOperator.NOT_IN,
            'contains': FilterOperator.CONTAINS,
            'starts': FilterOperator.STARTS_WITH,
            'ends': FilterOperator.ENDS_WITH,
            'regex': FilterOperator.REGEX,
            'exists': FilterOperator.EXISTS,
            'between': FilterOperator.BETWEEN
        }
        
        return operator_map.get(op_string, FilterOperator.EQUALS)

class FilterBuilder:
    """í•„í„° ì¿¼ë¦¬ ë¹Œë”"""
    
    def __init__(self, allowed_fields: List[str]):
        self.allowed_fields = allowed_fields
        self.validators = FilterValidators()
    
    def build_query(
        self,
        base_query: Query,
        filters: List[FilterDefinition]
    ) -> Query:
        """í•„í„°ë¥¼ ì¿¼ë¦¬ì— ì ìš©"""
        
        query = base_query
        
        for filter_def in filters:
            # í•„ë“œ ê²€ì¦
            if filter_def.field not in self.allowed_fields:
                raise InvalidFilterFieldError(
                    f"Field '{filter_def.field}' is not filterable"
                )
            
            # ê°’ ê²€ì¦
            if not self.validators.validate(filter_def):
                raise InvalidFilterValueError(
                    f"Invalid value for filter {filter_def.field}"
                )
            
            # ì¿¼ë¦¬ ì ìš©
            query = self.apply_filter(query, filter_def)
        
        return query
    
    def apply_filter(self, query: Query, filter_def: FilterDefinition) -> Query:
        """ë‹¨ì¼ í•„í„° ì ìš©"""
        
        field = filter_def.field
        operator = filter_def.operator
        value = filter_def.value
        
        if operator == FilterOperator.EQUALS:
            return query.where(field, '=', value)
            
        elif operator == FilterOperator.NOT_EQUALS:
            return query.where(field, '!=', value)
            
        elif operator == FilterOperator.GREATER_THAN:
            return query.where(field, '>', value)
            
        elif operator == FilterOperator.GREATER_THAN_OR_EQUAL:
            return query.where(field, '>=', value)
            
        elif operator == FilterOperator.LESS_THAN:
            return query.where(field, '<', value)
            
        elif operator == FilterOperator.LESS_THAN_OR_EQUAL:
            return query.where(field, '<=', value)
            
        elif operator == FilterOperator.IN:
            values = value if isinstance(value, list) else [value]
            return query.where_in(field, values)
            
        elif operator == FilterOperator.NOT_IN:
            values = value if isinstance(value, list) else [value]
            return query.where_not_in(field, values)
            
        elif operator == FilterOperator.CONTAINS:
            return query.where(field, 'LIKE', f'%{value}%')
            
        elif operator == FilterOperator.STARTS_WITH:
            return query.where(field, 'LIKE', f'{value}%')
            
        elif operator == FilterOperator.ENDS_WITH:
            return query.where(field, 'LIKE', f'%{value}')
            
        elif operator == FilterOperator.REGEX:
            return query.where_raw(f"{field} REGEXP ?", [value])
            
        elif operator == FilterOperator.EXISTS:
            if value:
                return query.where_not_null(field)
            else:
                return query.where_null(field)
                
        elif operator == FilterOperator.BETWEEN:
            if isinstance(value, list) and len(value) == 2:
                return query.where_between(field, value[0], value[1])
            
        return query

class AdvancedFilterSystem:
    """ê³ ê¸‰ í•„í„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.parser = FilterParser()
        self.builder = FilterBuilder(self.get_allowed_fields())
        self.cache = FilterCache()
    
    async def apply_filters(
        self,
        request: Request,
        base_query: Query
    ) -> FilteredQuery:
        """ìš”ì²­ì—ì„œ í•„í„° ì¶”ì¶œ ë° ì ìš©"""
        
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = self.generate_cache_key(request.query)
        
        # ìºì‹œ í™•ì¸
        cached = await self.cache.get(cache_key)
        if cached:
            return cached
        
        # í•„í„° íŒŒì‹±
        filters = self.parser.parse_filters(request.query)
        
        # ì¤‘ì²© í•„í„° ì²˜ë¦¬
        if 'nested' in request.query:
            nested_filters = self.parse_nested_filters(request.query['nested'])
            filters.extend(nested_filters)
        
        # ë…¼ë¦¬ ì—°ì‚°ì ì²˜ë¦¬
        logical_op = request.query.get('op', 'AND')
        
        # ì¿¼ë¦¬ êµ¬ì„±
        if logical_op == 'OR':
            query = self.build_or_query(base_query, filters)
        else:
            query = self.build_and_query(base_query, filters)
        
        # ê²°ê³¼ ìºì‹±
        result = FilteredQuery(query=query, filters=filters)
        await self.cache.set(cache_key, result)
        
        return result
    
    def build_or_query(
        self,
        base_query: Query,
        filters: List[FilterDefinition]
    ) -> Query:
        """OR ì¡°ê±´ ì¿¼ë¦¬ êµ¬ì„±"""
        
        query = base_query
        or_conditions = []
        
        for filter_def in filters:
            condition = self.filter_to_condition(filter_def)
            or_conditions.append(condition)
        
        if or_conditions:
            query = query.where(lambda q: 
                q.where_any(or_conditions)
            )
        
        return query

class FacetedSearch:
    """íŒ¨ì‹¯ ê²€ìƒ‰"""
    
    async def generate_facets(
        self,
        base_query: Query,
        facet_fields: List[str]
    ) -> Dict[str, List[FacetValue]]:
        """íŒ¨ì‹¯ ìƒì„±"""
        
        facets = {}
        
        for field in facet_fields:
            # í•„ë“œë³„ ê³ ìœ  ê°’ê³¼ ê°œìˆ˜ ì¡°íšŒ
            facet_query = base_query.group_by(field).select(
                field,
                'COUNT(*) as count'
            )
            
            results = await facet_query.execute()
            
            facets[field] = [
                FacetValue(
                    value=row[field],
                    count=row['count'],
                    label=self.format_label(field, row[field])
                )
                for row in results
            ]
        
        return facets
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ í•„í„° ì—°ì‚°ì
- [ ] ë³µí•© í•„í„° ì§€ì›
- [ ] ë…¼ë¦¬ ì—°ì‚°ì (AND/OR)
- [ ] íŒ¨ì‹¯ ê²€ìƒ‰

#### SubTask 6.8.3: ì •ë ¬ ë° ê²€ìƒ‰ ê¸°ëŠ¥

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api/rest/search/search-sort.ts
export interface SortOptions {
  field: string;
  direction: 'asc' | 'desc';
  nullsFirst?: boolean;
  caseInsensitive?: boolean;
}

export class SortingHandler {
  private allowedSortFields: Set<string>;
  private defaultSort: SortOptions;
  
  constructor(config: SortConfig) {
    this.allowedSortFields = new Set(config.allowedFields);
    this.defaultSort = config.defaultSort || { field: 'id', direction: 'asc' };
  }
  
  parseSortParams(params: any): SortOptions[] {
    const sortOptions: SortOptions[] = [];
    
    // ë‹¨ì¼ ì •ë ¬ íŒŒë¼ë¯¸í„°
    if (params.sort) {
      const parsed = this.parseSortString(params.sort);
      sortOptions.push(...parsed);
    }
    
    // ë‹¤ì¤‘ ì •ë ¬ íŒŒë¼ë¯¸í„°
    if (params.sort_by && params.order) {
      sortOptions.push({
        field: params.sort_by,
        direction: params.order.toLowerCase() as 'asc' | 'desc'
      });
    }
    
    // ê¸°ë³¸ ì •ë ¬
    if (sortOptions.length === 0) {
      sortOptions.push(this.defaultSort);
    }
    
    return this.validateSortOptions(sortOptions);
  }
  
  private parseSortString(sortString: string): SortOptions[] {
    // í˜•ì‹: "field1:asc,field2:desc" ë˜ëŠ” "-field1,+field2"
    const sortOptions: SortOptions[] = [];
    const parts = sortString.split(',');
    
    for (const part of parts) {
      const trimmed = part.trim();
      
      if (trimmed.startsWith('-')) {
        sortOptions.push({
          field: trimmed.substring(1),
          direction: 'desc'
        });
      } else if (trimmed.startsWith('+')) {
        sortOptions.push({
          field: trimmed.substring(1),
          direction: 'asc'
        });
      } else if (trimmed.includes(':')) {
        const [field, direction] = trimmed.split(':');
        sortOptions.push({
          field,
          direction: direction.toLowerCase() as 'asc' | 'desc'
        });
      } else {
        sortOptions.push({
          field: trimmed,
          direction: 'asc'
        });
      }
    }
    
    return sortOptions;
  }
  
  private validateSortOptions(options: SortOptions[]): SortOptions[] {
    return options.filter(option => {
      if (!this.allowedSortFields.has(option.field)) {
        console.warn(`Sort field '${option.field}' is not allowed`);
        return false;
      }
      return true;
    });
  }
  
  applySort(query: Query, sortOptions: SortOptions[]): Query {
    let sortedQuery = query;
    
    for (const option of sortOptions) {
      sortedQuery = this.applySingleSort(sortedQuery, option);
    }
    
    return sortedQuery;
  }
  
  private applySingleSort(query: Query, option: SortOptions): Query {
    const direction = option.direction.toUpperCase();
    
    if (option.caseInsensitive) {
      // ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ëŠ” ì •ë ¬
      return query.orderByRaw(`LOWER(${option.field}) ${direction}`);
    }
    
    if (option.nullsFirst !== undefined) {
      // NULL ê°’ ì²˜ë¦¬
      const nullsOrder = option.nullsFirst ? 'NULLS FIRST' : 'NULLS LAST';
      return query.orderByRaw(`${option.field} ${direction} ${nullsOrder}`);
    }
    
    return query.orderBy(option.field, direction);
  }
}

// ì „ë¬¸ ê²€ìƒ‰
export class FullTextSearchHandler {
  private searchableFields: string[];
  private searchEngine: SearchEngine;
  
  constructor(config: SearchConfig) {
    this.searchableFields = config.searchableFields;
    this.searchEngine = this.initSearchEngine(config.engine);
  }
  
  async search(
    query: string,
    options: SearchOptions = {}
  ): Promise<SearchResult> {
    // ê²€ìƒ‰ì–´ ì „ì²˜ë¦¬
    const processedQuery = this.preprocessQuery(query);
    
    // ê²€ìƒ‰ ì‹¤í–‰
    const results = await this.searchEngine.search({
      query: processedQuery,
      fields: options.fields || this.searchableFields,
      fuzzy: options.fuzzy !== false,
      boost: options.boost || {},
      filters: options.filters || []
    });
    
    // í•˜ì´ë¼ì´íŒ…
    if (options.highlight) {
      results.items = this.addHighlighting(results.items, processedQuery);
    }
    
    // ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°
    if (options.includeScore) {
      results.items = this.calculateRelevanceScores(results.items, processedQuery);
    }
    
    return results;
  }
  
  private preprocessQuery(query: string): ProcessedQuery {
    // íŠ¹ìˆ˜ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
    let processed = this.escapeSpecialChars(query);
    
    // ë¶ˆìš©ì–´ ì œê±°
    processed = this.removeStopWords(processed);
    
    // ë™ì˜ì–´ í™•ì¥
    processed = this.expandSynonyms(processed);
    
    // ê²€ìƒ‰ ì—°ì‚°ì íŒŒì‹±
    const operators = this.parseOperators(processed);
    
    return {
      original: query,
      processed,
      tokens: this.tokenize(processed),
      operators
    };
  }
  
  private addHighlighting(items: any[], query: ProcessedQuery): any[] {
    return items.map(item => {
      const highlighted = { ...item };
      
      for (const field of this.searchableFields) {
        if (item[field] && typeof item[field] === 'string') {
          highlighted[`${field}_highlighted`] = this.highlightText(
            item[field],
            query.tokens
          );
        }
      }
      
      return highlighted;
    });
  }
  
  private highlightText(text: string, tokens: string[]): string {
    let highlighted = text;
    
    for (const token of tokens) {
      const regex = new RegExp(`(${token})`, 'gi');
      highlighted = highlighted.replace(regex, '<mark>$1</mark>');
    }
    
    return highlighted;
  }
}

// ë³µí•© ê²€ìƒ‰ ë° ì •ë ¬
export class AdvancedSearchSort {
  private sortHandler: SortingHandler;
  private searchHandler: FullTextSearchHandler;
  private filterBuilder: FilterBuilder;
  
  async executeAdvancedQuery(
    request: Request
  ): Promise<QueryResult> {
    const { q, filters, sort, page, limit } = request.query;
    
    // ê¸°ë³¸ ì¿¼ë¦¬
    let query = this.repository.createQuery();
    
    // 1. ì „ë¬¸ ê²€ìƒ‰ ì ìš©
    if (q) {
      const searchResults = await this.searchHandler.search(q);
      const ids = searchResults.items.map(item => item.id);
      query = query.whereIn('id', ids);
    }
    
    // 2. í•„í„° ì ìš©
    if (filters) {
      query = this.filterBuilder.build(query, filters);
    }
    
    // 3. ì •ë ¬ ì ìš©
    const sortOptions = this.sortHandler.parseSortParams({ sort });
    query = this.sortHandler.applySort(query, sortOptions);
    
    // 4. í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
    const paginated = await this.paginationHandler.paginate(query, {
      page,
      limit
    });
    
    // 5. ë¶€ê°€ ì •ë³´ ì¶”ê°€
    return {
      ...paginated,
      query: q,
      appliedFilters: filters,
      appliedSort: sortOptions
    };
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì¤‘ ì •ë ¬ ì§€ì›
- [ ] ì „ë¬¸ ê²€ìƒ‰ ê¸°ëŠ¥
- [ ] ê²€ìƒ‰ì–´ í•˜ì´ë¼ì´íŒ…
- [ ] ë³µí•© ì¿¼ë¦¬ ì²˜ë¦¬

#### SubTask 6.8.4: ì»¤ì„œ ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api/rest/pagination/cursor_pagination.py
from typing import Optional, List, Dict, Any, Tuple
import base64
import json
from datetime import datetime

class CursorPaginationHandler:
    """ì»¤ì„œ ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜ í•¸ë“¤ëŸ¬"""
    
    def __init__(
        self,
        order_fields: List[str],
        default_limit: int = 20,
        max_limit: int = 100
    ):
        self.order_fields = order_fields
        self.default_limit = default_limit
        self.max_limit = max_limit
    
    def encode_cursor(self, record: Dict[str, Any]) -> str:
        """ì»¤ì„œ ì¸ì½”ë”©"""
        
        cursor_data = {
            'values': {},
            'direction': 'forward',
            'timestamp': datetime.now().isoformat()
        }
        
        # ì •ë ¬ í•„ë“œ ê°’ ì¶”ì¶œ
        for field in self.order_fields:
            value = record.get(field)
            
            # íƒ€ì…ë³„ ì§ë ¬í™”
            if isinstance(value, datetime):
                cursor_data['values'][field] = value.isoformat()
            elif value is not None:
                cursor_data['values'][field] = value
        
        # Base64 ì¸ì½”ë”©
        json_str = json.dumps(cursor_data, separators=(',', ':'))
        return base64.urlsafe_b64encode(json_str.encode()).decode()
    
    def decode_cursor(self, cursor: str) -> Dict[str, Any]:
        """ì»¤ì„œ ë””ì½”ë”©"""
        
        try:
            json_str = base64.urlsafe_b64decode(cursor.encode()).decode()
            cursor_data = json.loads(json_str)
            
            # íƒ€ì… ë³µì›
            for field, value in cursor_data['values'].items():
                if field in self.date_fields:
                    cursor_data['values'][field] = datetime.fromisoformat(value)
            
            return cursor_data
            
        except Exception as e:
            raise InvalidCursorError(f"Invalid cursor: {e}")
    
    async def paginate_forward(
        self,
        query: Query,
        after_cursor: Optional[str] = None,
        first: int = None
    ) -> CursorPage:
        """ìˆœë°©í–¥ í˜ì´ì§€ë„¤ì´ì…˜"""
        
        limit = min(first or self.default_limit, self.max_limit)
        
        # ì»¤ì„œ ì¡°ê±´ ì ìš©
        if after_cursor:
            cursor_data = self.decode_cursor(after_cursor)
            query = self.apply_cursor_condition(query, cursor_data, 'after')
        
        # ì •ë ¬ ì ìš©
        for field in self.order_fields:
            query = query.order_by(field, 'ASC')
        
        # +1 ê°œ ì¡°íšŒ (hasNext í™•ì¸ìš©)
        items = await query.limit(limit + 1).execute()
        
        has_next = len(items) > limit
        if has_next:
            items = items[:-1]  # ë§ˆì§€ë§‰ ì•„ì´í…œ ì œê±°
        
        # ì—£ì§€ ìƒì„±
        edges = [
            {
                'node': item,
                'cursor': self.encode_cursor(item)
            }
            for item in items
        ]
        
        # í˜ì´ì§€ ì •ë³´
        page_info = {
            'hasNextPage': has_next,
            'hasPreviousPage': after_cursor is not None,
            'startCursor': edges[0]['cursor'] if edges else None,
            'endCursor': edges[-1]['cursor'] if edges else None
        }
        
        return CursorPage(
            edges=edges,
            pageInfo=page_info,
            totalCount=await self.get_total_count(query)
        )
    
    async def paginate_backward(
        self,
        query: Query,
        before_cursor: Optional[str] = None,
        last: int = None
    ) -> CursorPage:
        """ì—­ë°©í–¥ í˜ì´ì§€ë„¤ì´ì…˜"""
        
        limit = min(last or self.default_limit, self.max_limit)
        
        # ì»¤ì„œ ì¡°ê±´ ì ìš©
        if before_cursor:
            cursor_data = self.decode_cursor(before_cursor)
            query = self.apply_cursor_condition(query, cursor_data, 'before')
        
        # ì—­ë°©í–¥ ì •ë ¬
        for field in self.order_fields:
            query = query.order_by(field, 'DESC')
        
        # +1 ê°œ ì¡°íšŒ
        items = await query.limit(limit + 1).execute()
        
        has_prev = len(items) > limit
        if has_prev:
            items = items[:-1]
        
        # ìˆœì„œ ë³µì›
        items.reverse()
        
        # ì—£ì§€ ìƒì„±
        edges = [
            {
                'node': item,
                'cursor': self.encode_cursor(item)
            }
            for item in items
        ]
        
        # í˜ì´ì§€ ì •ë³´
        page_info = {
            'hasNextPage': before_cursor is not None,
            'hasPreviousPage': has_prev,
            'startCursor': edges[0]['cursor'] if edges else None,
            'endCursor': edges[-1]['cursor'] if edges else None
        }
        
        return CursorPage(
            edges=edges,
            pageInfo=page_info,
            totalCount=await self.get_total_count(query)
        )
    
    def apply_cursor_condition(
        self,
        query: Query,
        cursor_data: Dict,
        direction: str
    ) -> Query:
        """ì»¤ì„œ ì¡°ê±´ ì ìš©"""
        
        values = cursor_data['values']
        
        # ë³µí•© í‚¤ ë¹„êµ ì¡°ê±´ ìƒì„±
        conditions = []
        
        for i, field in enumerate(self.order_fields):
            if field not in values:
                break
            
            # ì´ì „ í•„ë“œë“¤ì€ ê°™ì•„ì•¼ í•¨
            for j in range(i):
                prev_field = self.order_fields[j]
                conditions.append(f"{prev_field} = {values[prev_field]}")
            
            # í˜„ì¬ í•„ë“œëŠ” ì»¤ì„œ ë°©í–¥ì— ë”°ë¼
            operator = '>' if direction == 'after' else '<'
            conditions.append(f"{field} {operator} {values[field]}")
        
        # OR ì¡°ê±´ìœ¼ë¡œ ê²°í•©
        where_clause = ' OR '.join(
            f"({' AND '.join(cond_group)})"
            for cond_group in conditions
        )
        
        return query.where_raw(where_clause)

class RelayStylePagination:
    """GraphQL Relay ìŠ¤íƒ€ì¼ í˜ì´ì§€ë„¤ì´ì…˜"""
    
    def __init__(self, cursor_handler: CursorPaginationHandler):
        self.cursor_handler = cursor_handler
    
    async def paginate(
        self,
        query: Query,
        args: RelayPaginationArgs
    ) -> Connection:
        """Relay ìŠ¤íƒ€ì¼ í˜ì´ì§€ë„¤ì´ì…˜"""
        
        # ì¸ì ê²€ì¦
        self.validate_args(args)
        
        # ìˆœë°©í–¥/ì—­ë°©í–¥ ê²°ì •
        if args.first is not None:
            page = await self.cursor_handler.paginate_forward(
                query,
                args.after,
                args.first
            )
        else:
            page = await self.cursor_handler.paginate_backward(
                query,
                args.before,
                args.last
            )
        
        return Connection(
            edges=page.edges,
            pageInfo=page.pageInfo,
            totalCount=page.totalCount
        )
    
    def validate_args(self, args: RelayPaginationArgs):
        """í˜ì´ì§€ë„¤ì´ì…˜ ì¸ì ê²€ì¦"""
        
        # firstì™€ last ë™ì‹œ ì‚¬ìš© ë¶ˆê°€
        if args.first is not None and args.last is not None:
            raise ValueError("Cannot use both 'first' and 'last'")
        
        # afterì™€ before ë™ì‹œ ì‚¬ìš© ë¶ˆê°€
        if args.after is not None and args.before is not None:
            raise ValueError("Cannot use both 'after' and 'before'")
        
        # ìŒìˆ˜ ë¶ˆê°€
        if args.first is not None and args.first < 0:
            raise ValueError("'first' must be non-negative")
        
        if args.last is not None and args.last < 0:
            raise ValueError("'last' must be non-negative")
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì»¤ì„œ ì¸ì½”ë”©/ë””ì½”ë”©
- [ ] ì–‘ë°©í–¥ í˜ì´ì§€ë„¤ì´ì…˜
- [ ] Relay ìŠ¤íƒ€ì¼ ì§€ì›
- [ ] ë³µí•© í‚¤ ì»¤ì„œ

---

### Task 6.9: ì‘ë‹µ í¬ë§· í‘œì¤€í™”

#### SubTask 6.9.1: ì‘ë‹µ êµ¬ì¡° í‘œì¤€ ì •ì˜

**ë‹´ë‹¹ì**: API ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api/rest/response/response-standards.ts
export interface StandardResponse<T = any> {
  success: boolean;
  data?: T;
  error?: ErrorDetail;
  meta?: ResponseMetadata;
  links?: ResponseLinks;
  included?: any[];
}

export interface ResponseMetadata {
  timestamp: string;
  version: string;
  requestId: string;
  processingTime?: number;
  pagination?: PaginationMeta;
  rateLimit?: RateLimitMeta;
}

export class ResponseFormatter {
  private config: ResponseConfig;
  
  constructor(config: ResponseConfig) {
    this.config = config;
  }
  
  formatSuccess<T>(
    data: T,
    options: ResponseOptions = {}
  ): StandardResponse<T> {
    const response: StandardResponse<T> = {
      success: true,
      data
    };
    
    // ë©”íƒ€ë°ì´í„° ì¶”ê°€
    if (this.config.includeMetadata) {
      response.meta = this.generateMetadata(options);
    }
    
    // ë§í¬ ì¶”ê°€
    if (options.links) {
      response.links = options.links;
    }
    
    // í¬í•¨ ë¦¬ì†ŒìŠ¤
    if (options.included) {
      response.included = options.included;
    }
    
    return response;
  }
  
  formatError(
    error: Error | ErrorDetail,
    options: ResponseOptions = {}
  ): StandardResponse {
    const errorDetail = this.normalizeError(error);
    
    const response: StandardResponse = {
      success: false,
      error: errorDetail
    };
    
    if (this.config.includeMetadata) {
      response.meta = this.generateMetadata(options);
    }
    
    return response;
  }
  
  formatCollection<T>(
    items: T[],
    pagination: PaginationMeta,
    options: ResponseOptions = {}
  ): StandardResponse<T[]> {
    const response = this.formatSuccess(items, options);
    
    if (!response.meta) {
      response.meta = {} as ResponseMetadata;
    }
    
    response.meta.pagination = pagination;
    
    return response;
  }
  
  private generateMetadata(options: ResponseOptions): ResponseMetadata {
    return {
      timestamp: new Date().toISOString(),
      version: this.config.apiVersion,
      requestId: options.requestId || generateRequestId(),
      processingTime: options.processingTime,
      rateLimit: options.rateLimit
    };
  }
  
  private normalizeError(error: Error | ErrorDetail): ErrorDetail {
    if (this.isErrorDetail(error)) {
      return error;
    }
    
    return {
      code: error.code || 'INTERNAL_ERROR',
      message: error.message,
      details: this.config.includeErrorDetails ? error.stack : undefined
    };
  }
}

// JSON:API í˜•ì‹
export class JSONAPIFormatter {
  format(resource: any, type: string): JSONAPIResponse {
    return {
      data: this.formatResource(resource, type),
      jsonapi: {
        version: '1.0'
      }
    };
  }
  
  private formatResource(resource: any, type: string): JSONAPIResource {
    const { id, ...attributes } = resource;
    
    return {
      type,
      id: String(id),
      attributes,
      relationships: this.extractRelationships(resource),
      links: {
        self: `/api/${type}s/${id}`
      }
    };
  }
  
  formatCollection(
    resources: any[],
    type: string,
    pagination?: PaginationMeta
  ): JSONAPIResponse {
    const response: JSONAPIResponse = {
      data: resources.map(r => this.formatResource(r, type)),
      jsonapi: {
        version: '1.0'
      }
    };
    
    if (pagination) {
      response.meta = { pagination };
      response.links = this.generatePaginationLinks(pagination);
    }
    
    return response;
  }
}

// HAL í˜•ì‹
export class HALFormatter {
  format(resource: any, type: string): HALResponse {
    return {
      ...resource,
      _links: this.generateLinks(resource, type),
      _embedded: this.extractEmbedded(resource)
    };
  }
  
  private generateLinks(resource: any, type: string): HALLinks {
    return {
      self: {
        href: `/api/${type}s/${resource.id}`
      },
      collection: {
        href: `/api/${type}s`
      }
    };
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] í‘œì¤€ ì‘ë‹µ êµ¬ì¡°
- [ ] JSON:API ì§€ì›
- [ ] HAL ì§€ì›
- [ ] ë©”íƒ€ë°ì´í„° í¬í•¨

#### SubTask 6.9.2: HATEOAS êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api/rest/response/hateoas.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class Link:
    """HATEOAS ë§í¬"""
    rel: str  # ê´€ê³„ íƒ€ì…
    href: str  # URL
    method: str = "GET"
    title: Optional[str] = None
    type: Optional[str] = None  # ë¯¸ë””ì–´ íƒ€ì…
    templated: bool = False
    deprecation: Optional[str] = None

class HATEOASBuilder:
    """HATEOAS ë§í¬ ë¹Œë”"""
    
    def __init__(self, base_url: str):
        self.base_url = base_url
        self.link_registry = LinkRegistry()
    
    def build_resource_links(
        self,
        resource_type: str,
        resource_id: str,
        context: Optional[Dict] = None
    ) -> List[Link]:
        """ë¦¬ì†ŒìŠ¤ ë§í¬ ìƒì„±"""
        
        links = []
        
        # Self ë§í¬
        links.append(Link(
            rel="self",
            href=f"{self.base_url}/{resource_type}s/{resource_id}",
            method="GET",
            title=f"Get {resource_type}"
        ))
        
        # Collection ë§í¬
        links.append(Link(
            rel="collection",
            href=f"{self.base_url}/{resource_type}s",
            method="GET",
            title=f"List {resource_type}s"
        ))
        
        # CRUD ì‘ì—… ë§í¬
        links.extend(self.build_crud_links(resource_type, resource_id))
        
        # ê´€ê³„ ë§í¬
        links.extend(self.build_relationship_links(resource_type, resource_id))
        
        # ì»¤ìŠ¤í…€ ì•¡ì…˜ ë§í¬
        links.extend(self.build_action_links(resource_type, resource_id, context))
        
        return links
    
    def build_crud_links(
        self,
        resource_type: str,
        resource_id: str
    ) -> List[Link]:
        """CRUD ì‘ì—… ë§í¬"""
        
        base_path = f"{self.base_url}/{resource_type}s/{resource_id}"
        
        return [
            Link(
                rel="update",
                href=base_path,
                method="PUT",
                title=f"Update {resource_type}"
            ),
            Link(
                rel="partial-update",
                href=base_path,
                method="PATCH",
                title=f"Partially update {resource_type}"
            ),
            Link(
                rel="delete",
                href=base_path,
                method="DELETE",
                title=f"Delete {resource_type}"
            )
        ]
    
    def build_relationship_links(
        self,
        resource_type: str,
        resource_id: str
    ) -> List[Link]:
        """ê´€ê³„ ë§í¬ ìƒì„±"""
        
        links = []
        relationships = self.link_registry.get_relationships(resource_type)
        
        for rel in relationships:
            # ê´€ê³„ ë¦¬ì†ŒìŠ¤ ë§í¬
            links.append(Link(
                rel=rel.name,
                href=f"{self.base_url}/{resource_type}s/{resource_id}/{rel.name}",
                method="GET",
                title=f"Get {rel.name} of {resource_type}"
            ))
            
            # ê´€ê³„ ê´€ë¦¬ ë§í¬
            if rel.mutable:
                links.append(Link(
                    rel=f"add-{rel.name}",
                    href=f"{self.base_url}/{resource_type}s/{resource_id}/relationships/{rel.name}",
                    method="POST",
                    title=f"Add {rel.name} to {resource_type}"
                ))
                
                links.append(Link(
                    rel=f"remove-{rel.name}",
                    href=f"{self.base_url}/{resource_type}s/{resource_id}/relationships/{rel.name}",
                    method="DELETE",
                    title=f"Remove {rel.name} from {resource_type}"
                ))
        
        return links
    
    def build_action_links(
        self,
        resource_type: str,
        resource_id: str,
        context: Optional[Dict] = None
    ) -> List[Link]:
        """ì»¤ìŠ¤í…€ ì•¡ì…˜ ë§í¬"""
        
        links = []
        actions = self.link_registry.get_actions(resource_type)
        
        for action in actions:
            # ì•¡ì…˜ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            if context and not self.is_action_allowed(action, context):
                continue
            
            link = Link(
                rel=action.name,
                href=f"{self.base_url}/{resource_type}s/{resource_id}/{action.name}",
                method=action.method,
                title=action.description
            )
            
            # í…œí”Œë¦¿ URL
            if action.parameters:
                link.href += "{?" + ",".join(action.parameters) + "}"
                link.templated = True
            
            links.append(link)
        
        return links

class HATEOASResponse:
    """HATEOAS ì‘ë‹µ ë˜í¼"""
    
    def __init__(self, data: Any, links: List[Link]):
        self.data = data
        self.links = links
    
    def to_dict(self) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ ë³€í™˜"""
        
        return {
            **self.data,
            "_links": self.format_links()
        }
    
    def format_links(self) -> Dict[str, Any]:
        """ë§í¬ í¬ë§·íŒ…"""
        
        formatted = {}
        
        for link in self.links:
            link_data = {
                "href": link.href,
                "method": link.method
            }
            
            if link.title:
                link_data["title"] = link.title
            
            if link.type:
                link_data["type"] = link.type
            
            if link.templated:
                link_data["templated"] = True
            
            if link.deprecation:
                link_data["deprecation"] = link.deprecation
            
            # ê°™ì€ relì´ ì—¬ëŸ¬ ê°œì¸ ê²½ìš° ë°°ì—´ë¡œ
            if link.rel in formatted:
                if not isinstance(formatted[link.rel], list):
                    formatted[link.rel] = [formatted[link.rel]]
                formatted[link.rel].append(link_data)
            else:
                formatted[link.rel] = link_data
        
        return formatted

class SmartLinkGenerator:
    """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë§í¬ ìƒì„±"""
    
    def generate_contextual_links(
        self,
        resource: Dict,
        user_context: UserContext
    ) -> List[Link]:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë§í¬ ìƒì„±"""
        
        links = []
        
        # ê¶Œí•œ ê¸°ë°˜ ë§í¬
        if user_context.has_permission('edit', resource):
            links.append(self.create_edit_link(resource))
        
        if user_context.has_permission('delete', resource):
            links.append(self.create_delete_link(resource))
        
        # ìƒíƒœ ê¸°ë°˜ ë§í¬
        state = resource.get('status')
        
        if state == 'draft':
            links.append(Link(
                rel="publish",
                href=f"/api/projects/{resource['id']}/publish",
                method="POST",
                title="Publish project"
            ))
        elif state == 'published':
            links.append(Link(
                rel="unpublish",
                href=f"/api/projects/{resource['id']}/unpublish",
                method="POST",
                title="Unpublish project"
            ))
        
        # ì›Œí¬í”Œë¡œìš° ë§í¬
        next_actions = self.get_workflow_actions(resource, user_context)
        for action in next_actions:
            links.append(Link(
                rel=f"workflow:{action.name}",
                href=f"/api/projects/{resource['id']}/workflow/{action.name}",
                method="POST",
                title=action.description
            ))
        
        return links
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] HATEOAS ë§í¬ ìƒì„±
- [ ] ê´€ê³„ ë§í¬ í¬í•¨
- [ ] ì•¡ì…˜ ë§í¬ ë™ì  ìƒì„±
- [ ] ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë§í¬

#### SubTask 6.9.3: ì½˜í…ì¸  í˜‘ìƒ ì²˜ë¦¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api/rest/response/content-negotiation.ts
export class ContentNegotiator {
  private formatters: Map<string, ResponseFormatter>;
  private defaultFormat: string = 'application/json';
  
  constructor() {
    this.initializeFormatters();
  }
  
  private initializeFormatters(): void {
    this.formatters = new Map([
      ['application/json', new JSONFormatter()],
      ['application/xml', new XMLFormatter()],
      ['application/hal+json', new HALFormatter()],
      ['application/vnd.api+json', new JSONAPIFormatter()],
      ['text/html', new HTMLFormatter()],
      ['text/csv', new CSVFormatter()],
      ['application/yaml', new YAMLFormatter()],
      ['application/msgpack', new MessagePackFormatter()]
    ]);
  }
  
  negotiate(request: Request): ContentType {
    // Accept í—¤ë” íŒŒì‹±
    const acceptHeader = request.headers['accept'];
    
    if (!acceptHeader) {
      return this.defaultFormat;
    }
    
    // ë¯¸ë””ì–´ íƒ€ì… íŒŒì‹± ë° ìš°ì„ ìˆœìœ„ ì •ë ¬
    const acceptedTypes = this.parseAcceptHeader(acceptHeader);
    
    // ì§€ì›í•˜ëŠ” í˜•ì‹ ì°¾ê¸°
    for (const type of acceptedTypes) {
      const formatter = this.findFormatter(type);
      if (formatter) {
        return type.mediaType;
      }
    }
    
    // ê¸°ë³¸ í˜•ì‹ ë°˜í™˜
    return this.defaultFormat;
  }
  
  private parseAcceptHeader(header: string): AcceptType[] {
    const types = header.split(',').map(part => {
      const [mediaType, ...params] = part.trim().split(';');
      
      let quality = 1.0;
      const qParam = params.find(p => p.trim().startsWith('q='));
      
      if (qParam) {
        quality = parseFloat(qParam.split('=')[1]);
      }
      
      return {
        mediaType: mediaType.trim(),
        quality,
        params
      };
    });
    
    // Quality ê°’ìœ¼ë¡œ ì •ë ¬
    return types.sort((a, b) => b.quality - a.quality);
  }
  
  async format(
    data: any,
    contentType: string,
    options: FormatOptions = {}
  ): Promise<FormattedResponse> {
    const formatter = this.formatters.get(contentType);
    
    if (!formatter) {
      throw new UnsupportedMediaTypeError(
        `Content type ${contentType} is not supported`
      );
    }
    
    const formatted = await formatter.format(data, options);
    
    return {
      contentType,
      body: formatted,
      headers: {
        'Content-Type': contentType
      }
    };
  }
}

// ì–¸ì–´ í˜‘ìƒ
export class LanguageNegotiator {
  private supportedLanguages: Set<string>;
  private defaultLanguage: string = 'en';
  
  constructor(languages: string[]) {
    this.supportedLanguages = new Set(languages);
  }
  
  negotiate(request: Request): string {
    const acceptLanguage = request.headers['accept-language'];
    
    if (!acceptLanguage) {
      return this.defaultLanguage;
    }
    
    const languages = this.parseAcceptLanguage(acceptLanguage);
    
    for (const lang of languages) {
      if (this.supportedLanguages.has(lang.code)) {
        return lang.code;
      }
      
      // ì–¸ì–´ ì½”ë“œë§Œ ì²´í¬ (ì˜ˆ: en-US -> en)
      const baseCode = lang.code.split('-')[0];
      if (this.supportedLanguages.has(baseCode)) {
        return baseCode;
      }
    }
    
    return this.defaultLanguage;
  }
  
  private parseAcceptLanguage(header: string): LanguagePreference[] {
    return header.split(',').map(part => {
      const [code, ...params] = part.trim().split(';');
      
      let quality = 1.0;
      const qParam = params.find(p => p.trim().startsWith('q='));
      
      if (qParam) {
        quality = parseFloat(qParam.split('=')[1]);
      }
      
      return { code: code.trim(), quality };
    }).sort((a, b) => b.quality - a.quality);
  }
}

// ì¸ì½”ë”© í˜‘ìƒ
export class EncodingNegotiator {
  private encoders: Map<string, Encoder>;
  
  constructor() {
    this.encoders = new Map([
      ['gzip', new GzipEncoder()],
      ['br', new BrotliEncoder()],
      ['deflate', new DeflateEncoder()],
      ['identity', new IdentityEncoder()]
    ]);
  }
  
  negotiate(request: Request): string[] {
    const acceptEncoding = request.headers['accept-encoding'];
    
    if (!acceptEncoding) {
      return ['identity'];
    }
    
    const encodings = acceptEncoding
      .split(',')
      .map(e => e.trim())
      .filter(e => this.encoders.has(e));
    
    return encodings.length > 0 ? encodings : ['identity'];
  }
  
  async encode(
    data: Buffer,
    encoding: string
  ): Promise<EncodedResponse> {
    const encoder = this.encoders.get(encoding);
    
    if (!encoder) {
      return {
        data,
        encoding: 'identity'
      };
    }
    
    const encoded = await encoder.encode(data);
    
    return {
      data: encoded,
      encoding,
      headers: {
        'Content-Encoding': encoding
      }
    };
  }
}

// í†µí•© ì½˜í…ì¸  í˜‘ìƒ ë¯¸ë“¤ì›¨ì–´
export class ContentNegotiationMiddleware {
  private contentNegotiator: ContentNegotiator;
  private languageNegotiator: LanguageNegotiator;
  private encodingNegotiator: EncodingNegotiator;
  
  async handle(request: Request, next: Handler): Promise<Response> {
    // í˜‘ìƒ ì‹¤í–‰
    const contentType = this.contentNegotiator.negotiate(request);
    const language = this.languageNegotiator.negotiate(request);
    const encodings = this.encodingNegotiator.negotiate(request);
    
    // ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
    request.negotiated = {
      contentType,
      language,
      encodings
    };
    
    // ë‹¤ìŒ í•¸ë“¤ëŸ¬ ì‹¤í–‰
    const response = await next(request);
    
    // ì‘ë‹µ ë³€í™˜
    if (response.data) {
      // ì–¸ì–´ ì ìš©
      const localizedData = await this.applyLocalization(
        response.data,
        language
      );
      
      // í¬ë§· ì ìš©
      const formatted = await this.contentNegotiator.format(
        localizedData,
        contentType
      );
      
      response.body = formatted.body;
      response.headers = {
        ...response.headers,
        ...formatted.headers,
        'Content-Language': language
      };
      
      // ì¸ì½”ë”© ì ìš©
      if (encodings[0] !== 'identity') {
        const encoded = await this.encodingNegotiator.encode(
          Buffer.from(response.body),
          encodings[0]
        );
        
        response.body = encoded.data;
        response.headers = {
          ...response.headers,
          ...encoded.headers
        };
      }
    }
    
    // Vary í—¤ë” ì¶”ê°€
    response.headers['Vary'] = 'Accept, Accept-Language, Accept-Encoding';
    
    return response;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] Accept í—¤ë” íŒŒì‹±
- [ ] ë‹¤ì–‘í•œ ì½˜í…ì¸  íƒ€ì… ì§€ì›
- [ ] ì–¸ì–´ í˜‘ìƒ
- [ ] ì¸ì½”ë”© í˜‘ìƒ

#### SubTask 6.9.4: ì‘ë‹µ ë©”íƒ€ë°ì´í„° ê´€ë¦¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api/rest/response/metadata_manager.py
class ResponseMetadataManager:
    """ì‘ë‹µ ë©”íƒ€ë°ì´í„° ê´€ë¦¬"""
    
    def __init__(self):
        self.metadata_providers = []
        self.register_default_providers()
    
    def register_default_providers(self):
        """ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì œê³µì ë“±ë¡"""
        
        self.add_provider(TimestampProvider())
        self.add_provider(VersionProvider())
        self.add_provider(RequestIdProvider())
        self.add_provider(ProcessingTimeProvider())
        self.add_provider(RateLimitProvider())
        self.add_provider(CacheProvider())
        self.add_provider(DebugProvider())
    
    async def generate_metadata(
        self,
        request: Request,
        response: Response,
        context: Dict
    ) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ìƒì„±"""
        
        metadata = {}
        
        for provider in self.metadata_providers:
            if provider.should_include(request, context):
                provider_meta = await provider.generate(request, response, context)
                metadata.update(provider_meta)
        
        return metadata

class TimestampProvider(MetadataProvider):
    """íƒ€ì„ìŠ¤íƒ¬í”„ ë©”íƒ€ë°ì´í„°"""
    
    async def generate(
        self,
        request: Request,
        response: Response,
        context: Dict
    ) -> Dict:
        return {
            'timestamp': datetime.now().isoformat(),
            'timezone': 'UTC'
        }

class ProcessingTimeProvider(MetadataProvider):
    """ì²˜ë¦¬ ì‹œê°„ ë©”íƒ€ë°ì´í„°"""
    
    async def generate(
        self,
        request: Request,
        response: Response,
        context: Dict
    ) -> Dict:
        start_time = context.get('start_time')
        
        if not start_time:
            return {}
        
        processing_time = (datetime.now() - start_time).total_seconds() * 1000
        
        return {
            'processingTime': {
                'total': processing_time,
                'unit': 'milliseconds',
                'breakdown': context.get('time_breakdown', {})
            }
        }

class RateLimitProvider(MetadataProvider):
    """Rate Limit ë©”íƒ€ë°ì´í„°"""
    
    async def generate(
        self,
        request: Request,
        response: Response,
        context: Dict
    ) -> Dict:
        rate_limit = context.get('rate_limit')
        
        if not rate_limit:
            return {}
        
        return {
            'rateLimit': {
                'limit': rate_limit.limit,
                'remaining': rate_limit.remaining,
                'reset': rate_limit.reset_at.isoformat(),
                'retryAfter': rate_limit.retry_after
            }
        }

class CacheProvider(MetadataProvider):
    """ìºì‹œ ë©”íƒ€ë°ì´í„°"""
    
    async def generate(
        self,
        request: Request,
        response: Response,
        context: Dict
    ) -> Dict:
        cache_info = context.get('cache_info')
        
        if not cache_info:
            return {}
        
        return {
            'cache': {
                'status': cache_info.status,  # HIT, MISS, BYPASS
                'ttl': cache_info.ttl,
                'age': cache_info.age,
                'tags': cache_info.tags
            }
        }

class DebugProvider(MetadataProvider):
    """ë””ë²„ê·¸ ë©”íƒ€ë°ì´í„°"""
    
    def should_include(self, request: Request, context: Dict) -> bool:
        """ê°œë°œ í™˜ê²½ì´ê±°ë‚˜ ë””ë²„ê·¸ ëª¨ë“œì¼ ë•Œë§Œ í¬í•¨"""
        
        return (
            context.get('environment') == 'development' or
            request.headers.get('X-Debug') == 'true'
        )
    
    async def generate(
        self,
        request: Request,
        response: Response,
        context: Dict
    ) -> Dict:
        return {
            'debug': {
                'query': context.get('executed_query'),
                'queryCount': context.get('query_count'),
                'memoryUsage': self.get_memory_usage(),
                'stackTrace': context.get('stack_trace'),
                'logs': context.get('debug_logs', [])
            }
        }

class ResponseEnricher:
    """ì‘ë‹µ ë³´ê°•"""
    
    def __init__(self):
        self.enrichers = []
    
    async def enrich(
        self,
        response: Dict,
        request: Request,
        context: Dict
    ) -> Dict:
        """ì‘ë‹µ ë°ì´í„° ë³´ê°•"""
        
        enriched = response.copy()
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        metadata = await self.metadata_manager.generate_metadata(
            request,
            response,
            context
        )
        
        if metadata:
            enriched['meta'] = metadata
        
        # í•˜ì´í¼ë¯¸ë””ì–´ ì¶”ê°€
        if context.get('include_links'):
            links = await self.link_generator.generate_links(
                response,
                request
            )
            enriched['links'] = links
        
        # ë²ˆì—­ ì ìš©
        if context.get('language'):
            enriched = await self.translator.translate(
                enriched,
                context['language']
            )
        
        # í•„ë“œ ë§ˆìŠ¤í‚¹
        if context.get('mask_sensitive'):
            enriched = self.mask_sensitive_fields(enriched)
        
        return enriched
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ë©”íƒ€ë°ì´í„° ì œê³µ
- [ ] ì¡°ê±´ë¶€ ë©”íƒ€ë°ì´í„° í¬í•¨
- [ ] ë””ë²„ê·¸ ì •ë³´ ê´€ë¦¬
- [ ] ì‘ë‹µ ë³´ê°• ê¸°ëŠ¥

---

### Task 6.10: RESTful ì—ëŸ¬ ì²˜ë¦¬

#### SubTask 6.10.1: ì—ëŸ¬ ì‘ë‹µ í‘œì¤€í™”

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api/rest/error/error-standards.ts
export interface StandardErrorResponse {
  success: false;
  error: ErrorDetail;
  meta?: ErrorMetadata;
}

export interface ErrorDetail {
  code: string;
  message: string;
  details?: any;
  field?: string;
  helpUrl?: string;
  timestamp?: string;
  traceId?: string;
}

export class ErrorResponseBuilder {
  private config: ErrorConfig;
  
  constructor(config: ErrorConfig) {
    this.config = config;
  }
  
  build(error: Error | AppError): StandardErrorResponse {
    const errorDetail = this.extractErrorDetail(error);
    
    const response: StandardErrorResponse = {
      success: false,
      error: errorDetail
    };
    
    // ë©”íƒ€ë°ì´í„° ì¶”ê°€
    if (this.config.includeMetadata) {
      response.meta = this.generateMetadata(error);
    }
    
    // ë¯¼ê°í•œ ì •ë³´ ì œê±°
    if (this.config.environment === 'production') {
      this.sanitizeError(response);
    }
    
    return response;
  }
  
  private extractErrorDetail(error: Error | AppError): ErrorDetail {
    if (this.isAppError(error)) {
      return {
        code: error.code,
        message: error.message,
        details: error.details,
        field: error.field,
        helpUrl: this.generateHelpUrl(error.code),
        timestamp: new Date().toISOString(),
        traceId: error.traceId || generateTraceId()
      };
    }
    
    // ì¼ë°˜ ì—ëŸ¬
    return {
      code: 'INTERNAL_ERROR',
      message: this.config.genericErrorMessage || 'An error occurred',
      timestamp: new Date().toISOString(),
      traceId: generateTraceId()
    };
  }
  
  private sanitizeError(response: StandardErrorResponse): void {
    // ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì œê±°
    delete response.error.details?.stack;
    
    // ë‚´ë¶€ ê²½ë¡œ ì •ë³´ ì œê±°
    if (response.error.details?.path) {
      response.error.details.path = this.sanitizePath(response.error.details.path);
    }
    
    // ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ì œê±°
    delete response.error.details?.query;
    delete response.error.details?.connection;
  }
}

// ë‹¤êµ­ì–´ ì—ëŸ¬ ë©”ì‹œì§€
export class LocalizedErrorMessages {
  private messages: Map<string, Map<string, string>>;
  
  constructor() {
    this.loadMessages();
  }
  
  private loadMessages(): void {
    this.messages = new Map([
      ['en', new Map([
        ['VALIDATION_ERROR', 'Validation failed'],
        ['NOT_FOUND', 'Resource not found'],
        ['UNAUTHORIZED', 'Authentication required'],
        ['FORBIDDEN', 'Access denied'],
        ['RATE_LIMIT', 'Too many requests'],
        ['INTERNAL_ERROR', 'Internal server error']
      ])],
      ['ko', new Map([
        ['VALIDATION_ERROR', 'ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨'],
        ['NOT_FOUND', 'ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'],
        ['UNAUTHORIZED', 'ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤'],
        ['FORBIDDEN', 'ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤'],
        ['RATE_LIMIT', 'ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤'],
        ['INTERNAL_ERROR', 'ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜']
      ])]
    ]);
  }
  
  getMessage(code: string, language: string = 'en'): string {
    const languageMessages = this.messages.get(language) || this.messages.get('en');
    return languageMessages?.get(code) || code;
  }
}

// êµ¬ì¡°í™”ëœ ê²€ì¦ ì—ëŸ¬
export class ValidationErrorFormatter {
  format(validationErrors: ValidationError[]): ErrorDetail {
    return {
      code: 'VALIDATION_ERROR',
      message: 'Validation failed',
      details: {
        errors: validationErrors.map(err => ({
          field: err.field,
          code: err.code,
          message: err.message,
          value: this.sanitizeValue(err.value)
        }))
      }
    };
  }
  
  private sanitizeValue(value: any): any {
    // ë¯¼ê°í•œ í•„ë“œ ë§ˆìŠ¤í‚¹
    if (typeof value === 'string' && value.length > 100) {
      return value.substring(0, 100) + '...';
    }
    return value;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] í‘œì¤€ ì—ëŸ¬ êµ¬ì¡°
- [ ] ë‹¤êµ­ì–´ ì§€ì›
- [ ] ë¯¼ê° ì •ë³´ ì œê±°
- [ ] ê²€ì¦ ì—ëŸ¬ í¬ë§·

#### SubTask 6.10.2: HTTP ìƒíƒœ ì½”ë“œ ë§¤í•‘

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api/rest/error/status_code_mapper.py
from enum import Enum
from typing import Dict, Type

class HTTPStatus(Enum):
    """HTTP ìƒíƒœ ì½”ë“œ"""
    
    # 2xx Success
    OK = 200
    CREATED = 201
    ACCEPTED = 202
    NO_CONTENT = 204
    PARTIAL_CONTENT = 206
    
    # 3xx Redirection
    MOVED_PERMANENTLY = 301
    FOUND = 302
    SEE_OTHER = 303
    NOT_MODIFIED = 304
    TEMPORARY_REDIRECT = 307
    PERMANENT_REDIRECT = 308
    
    # 4xx Client Error
    BAD_REQUEST = 400
    UNAUTHORIZED = 401
    PAYMENT_REQUIRED = 402
    FORBIDDEN = 403
    NOT_FOUND = 404
    METHOD_NOT_ALLOWED = 405
    NOT_ACCEPTABLE = 406
    REQUEST_TIMEOUT = 408
    CONFLICT = 409
    GONE = 410
    LENGTH_REQUIRED = 411
    PRECONDITION_FAILED = 412
    PAYLOAD_TOO_LARGE = 413
    URI_TOO_LONG = 414
    UNSUPPORTED_MEDIA_TYPE = 415
    RANGE_NOT_SATISFIABLE = 416
    EXPECTATION_FAILED = 417
    IM_A_TEAPOT = 418  # RFC 2324
    UNPROCESSABLE_ENTITY = 422
    LOCKED = 423
    TOO_EARLY = 425
    UPGRADE_REQUIRED = 426
    PRECONDITION_REQUIRED = 428
    TOO_MANY_REQUESTS = 429
    REQUEST_HEADER_FIELDS_TOO_LARGE = 431
    
    # 5xx Server Error
    INTERNAL_SERVER_ERROR = 500
    NOT_IMPLEMENTED = 501
    BAD_GATEWAY = 502
    SERVICE_UNAVAILABLE = 503
    GATEWAY_TIMEOUT = 504
    HTTP_VERSION_NOT_SUPPORTED = 505
    INSUFFICIENT_STORAGE = 507
    LOOP_DETECTED = 508
    NOT_EXTENDED = 510
    NETWORK_AUTHENTICATION_REQUIRED = 511

class StatusCodeMapper:
    """ì—ëŸ¬ ì½”ë“œë¥¼ HTTP ìƒíƒœ ì½”ë“œë¡œ ë§¤í•‘"""
    
    def __init__(self):
        self.mappings = self.initialize_mappings()
        self.custom_mappings = {}
    
    def initialize_mappings(self) -> Dict[str, int]:
        """ê¸°ë³¸ ë§¤í•‘ ì´ˆê¸°í™”"""
        
        return {
            # ê²€ì¦ ì—ëŸ¬
            'VALIDATION_ERROR': HTTPStatus.BAD_REQUEST.value,
            'INVALID_INPUT': HTTPStatus.BAD_REQUEST.value,
            'MISSING_FIELD': HTTPStatus.BAD_REQUEST.value,
            'INVALID_FORMAT': HTTPStatus.BAD_REQUEST.value,
            
            # ì¸ì¦/ì¸ê°€
            'AUTHENTICATION_REQUIRED': HTTPStatus.UNAUTHORIZED.value,
            'INVALID_CREDENTIALS': HTTPStatus.UNAUTHORIZED.value,
            'TOKEN_EXPIRED': HTTPStatus.UNAUTHORIZED.value,
            'ACCESS_DENIED': HTTPStatus.FORBIDDEN.value,
            'INSUFFICIENT_PERMISSIONS': HTTPStatus.FORBIDDEN.value,
            
            # ë¦¬ì†ŒìŠ¤ ì—ëŸ¬
            'RESOURCE_NOT_FOUND': HTTPStatus.NOT_FOUND.value,
            'ENDPOINT_NOT_FOUND': HTTPStatus.NOT_FOUND.value,
            'RESOURCE_ALREADY_EXISTS': HTTPStatus.CONFLICT.value,
            'RESOURCE_CONFLICT': HTTPStatus.CONFLICT.value,
            'RESOURCE_GONE': HTTPStatus.GONE.value,
            
            # ìš”ì²­ ì—ëŸ¬
            'METHOD_NOT_ALLOWED': HTTPStatus.METHOD_NOT_ALLOWED.value,
            'UNSUPPORTED_MEDIA_TYPE': HTTPStatus.UNSUPPORTED_MEDIA_TYPE.value,
            'NOT_ACCEPTABLE': HTTPStatus.NOT_ACCEPTABLE.value,
            'REQUEST_TOO_LARGE': HTTPStatus.PAYLOAD_TOO_LARGE.value,
            'RATE_LIMIT_EXCEEDED': HTTPStatus.TOO_MANY_REQUESTS.value,
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì—ëŸ¬
            'BUSINESS_RULE_VIOLATION': HTTPStatus.UNPROCESSABLE_ENTITY.value,
            'PRECONDITION_FAILED': HTTPStatus.PRECONDITION_FAILED.value,
            'OPERATION_NOT_ALLOWED': HTTPStatus.UNPROCESSABLE_ENTITY.value,
            
            # ì„œë²„ ì—ëŸ¬
            'INTERNAL_ERROR': HTTPStatus.INTERNAL_SERVER_ERROR.value,
            'SERVICE_UNAVAILABLE': HTTPStatus.SERVICE_UNAVAILABLE.value,
            'DEPENDENCY_ERROR': HTTPStatus.BAD_GATEWAY.value,
            'TIMEOUT': HTTPStatus.GATEWAY_TIMEOUT.value,
            'NOT_IMPLEMENTED': HTTPStatus.NOT_IMPLEMENTED.value
        }
    
    def map_error_to_status(self, error: AppError) -> int:
        """ì—ëŸ¬ë¥¼ ìƒíƒœ ì½”ë“œë¡œ ë§¤í•‘"""
        
        # ì»¤ìŠ¤í…€ ë§¤í•‘ í™•ì¸
        if error.code in self.custom_mappings:
            return self.custom_mappings[error.code]
        
        # ê¸°ë³¸ ë§¤í•‘ í™•ì¸
        if error.code in self.mappings:
            return self.mappings[error.code]
        
        # ì—ëŸ¬ íƒ€ì…ë³„ ê¸°ë³¸ê°’
        if isinstance(error, ValidationError):
            return HTTPStatus.BAD_REQUEST.value
        elif isinstance(error, AuthenticationError):
            return HTTPStatus.UNAUTHORIZED.value
        elif isinstance(error, AuthorizationError):
            return HTTPStatus.FORBIDDEN.value
        elif isinstance(error, NotFoundError):
            return HTTPStatus.NOT_FOUND.value
        elif isinstance(error, ConflictError):
            return HTTPStatus.CONFLICT.value
        elif isinstance(error, RateLimitError):
            return HTTPStatus.TOO_MANY_REQUESTS.value
        
        # ê¸°ë³¸ê°’
        return HTTPStatus.INTERNAL_SERVER_ERROR.value
    
    def add_custom_mapping(self, error_code: str, status_code: int):
        """ì»¤ìŠ¤í…€ ë§¤í•‘ ì¶”ê°€"""
        
        self.custom_mappings[error_code] = status_code
    
    def get_status_description(self, status_code: int) -> str:
        """ìƒíƒœ ì½”ë“œ ì„¤ëª…"""
        
        descriptions = {
            200: "OK - Request succeeded",
            201: "Created - Resource created successfully",
            204: "No Content - Request succeeded with no response body",
            400: "Bad Request - Invalid request syntax or parameters",
            401: "Unauthorized - Authentication required",
            403: "Forbidden - Access denied",
            404: "Not Found - Resource does not exist",
            409: "Conflict - Request conflicts with current state",
            422: "Unprocessable Entity - Request understood but invalid",
            429: "Too Many Requests - Rate limit exceeded",
            500: "Internal Server Error - Server encountered an error",
            503: "Service Unavailable - Server temporarily unavailable"
        }
        
        return descriptions.get(status_code, "Unknown status code")
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì™„ì „í•œ ìƒíƒœ ì½”ë“œ ë§¤í•‘
- [ ] ì—ëŸ¬ íƒ€ì…ë³„ ê¸°ë³¸ê°’
- [ ] ì»¤ìŠ¤í…€ ë§¤í•‘ ì§€ì›
- [ ] ìƒíƒœ ì½”ë“œ ì„¤ëª…

#### SubTask 6.10.3: ë¬¸ì œ ì„¸ë¶€ì‚¬í•­ (RFC 7807) êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/api/rest/error/problem-details.ts
export interface ProblemDetails {
  type?: string;      // URI reference
  title: string;      // Short summary
  status: number;     // HTTP status code
  detail?: string;    // Specific error details
  instance?: string;  // URI reference to specific occurrence
  [key: string]: any; // Additional members
}

export class ProblemDetailsBuilder {
  private problemTypes: Map<string, ProblemType>;
  
  constructor() {
    this.initializeProblemTypes();
  }
  
  private initializeProblemTypes(): void {
    this.problemTypes = new Map([
      ['validation-error', {
        type: 'https://api.t-developer.com/problems/validation-error',
        title: 'Validation Error',
        status: 400
      }],
      ['authentication-required', {
        type: 'https://api.t-developer.com/problems/authentication-required',
        title: 'Authentication Required',
        status: 401
      }],
      ['insufficient-balance', {
        type: 'https://api.t-developer.com/problems/insufficient-balance',
        title: 'Insufficient Balance',
        status: 402
      }],
      ['resource-not-found', {
        type: 'https://api.t-developer.com/problems/resource-not-found',
        title: 'Resource Not Found',
        status: 404
      }],
      ['rate-limit-exceeded', {
        type: 'https://api.t-developer.com/problems/rate-limit-exceeded',
        title: 'Rate Limit Exceeded',
        status: 429
      }]
    ]);
  }
  
  build(error: AppError, request?: Request): ProblemDetails {
    const problemType = this.problemTypes.get(error.problemType) || {
      title: 'Error',
      status: 500
    };
    
    const problem: ProblemDetails = {
      type: problemType.type,
      title: problemType.title,
      status: problemType.status,
      detail: error.message
    };
    
    // Instance URI
    if (request) {
      problem.instance = request.url;
    }
    
    // ì¶”ê°€ ì†ì„±
    this.addExtensions(problem, error);
    
    return problem;
  }
  
  private addExtensions(problem: ProblemDetails, error: AppError): void {
    // ê²€ì¦ ì—ëŸ¬ í™•ì¥
    if (error.type === 'validation' && error.validationErrors) {
      problem['errors'] = error.validationErrors.map(ve => ({
        field: ve.field,
        message: ve.message,
        code: ve.code
      }));
    }
    
    // Rate Limit í™•ì¥
    if (error.type === 'rate-limit') {
      problem['rate-limit'] = {
        limit: error.limit,
        remaining: error.remaining,
        reset: error.resetAt
      };
    }
    
    // íŠ¸ë ˆì´ì‹± ì •ë³´
    if (error.traceId) {
      problem['trace-id'] = error.traceId;
    }
    
    // ë„ì›€ë§ ë§í¬
    if (error.helpUrl) {
      problem['help'] = error.helpUrl;
    }
  }
}

// Problem Details ë¯¸ë“¤ì›¨ì–´
export class ProblemDetailsMiddleware {
  private builder: ProblemDetailsBuilder;
  private contentType = 'application/problem+json';
  
  constructor() {
    this.builder = new ProblemDetailsBuilder();
  }
  
  async handle(error: Error, request: Request): Promise<Response> {
    // AppErrorë¡œ ë³€í™˜
    const appError = this.toAppError(error);
    
    // Problem Details ìƒì„±
    const problemDetails = this.builder.build(appError, request);
    
    // ì‘ë‹µ ìƒì„±
    return {
      status: problemDetails.status,
      headers: {
        'Content-Type': this.contentType
      },
      body: problemDetails
    };
  }
  
  private toAppError(error: Error): AppError {
    if (error instanceof AppError) {
      return error;
    }
    
    // ì¼ë°˜ ì—ëŸ¬ë¥¼ AppErrorë¡œ ë³€í™˜
    return new AppError({
      code: 'INTERNAL_ERROR',
      message: error.message,
      problemType: 'internal-error'
    });
  }
}

// ì»¤ìŠ¤í…€ Problem Type ì •ì˜
export class CustomProblemType {
  constructor(
    private baseUrl: string = 'https://api.t-developer.com/problems'
  ) {}
  
  define(name: string, definition: ProblemTypeDefinition): string {
    const typeUrl = `${this.baseUrl}/${name}`;
    
    // ë¬¸ì„œ ìƒì„±
    this.generateDocumentation(typeUrl, definition);
    
    return typeUrl;
  }
  
  private generateDocumentation(
    typeUrl: string,
    definition: ProblemTypeDefinition
  ): void {
    const doc = `
# Problem Type: ${definition.title}

**URI**: ${typeUrl}
**Status**: ${definition.status}

## Description
${definition.description}

## Members
${this.documentMembers(definition.members)}

## Example
\`\`\`json
${JSON.stringify(definition.example, null, 2)}
\`\`\`
    `;
    
    // ë¬¸ì„œ ì €ì¥
    this.saveDocumentation(typeUrl, doc);
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] RFC 7807 ì¤€ìˆ˜
- [ ] Problem Type ì •ì˜
- [ ] í™•ì¥ í•„ë“œ ì§€ì›
- [ ] ë¬¸ì„œí™” ìë™ ìƒì„±

#### SubTask 6.10.4: ì—ëŸ¬ ë³µêµ¬ ë° ì¬ì‹œë„ ì „ëµ

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/api/rest/error/recovery_strategy.py
from typing import Optional, Callable, Any
import asyncio
from datetime import datetime, timedelta

class RetryStrategy:
    """ì¬ì‹œë„ ì „ëµ"""
    
    def __init__(
        self,
        max_attempts: int = 3,
        initial_delay: float = 1.0,
        max_delay: float = 60.0,
        exponential_base: float = 2.0,
        jitter: bool = True
    ):
        self.max_attempts = max_attempts
        self.initial_delay = initial_delay
        self.max_delay = max_delay
        self.exponential_base = exponential_base
        self.jitter = jitter
    
    def calculate_delay(self, attempt: int) -> float:
        """ì¬ì‹œë„ ì§€ì—° ì‹œê°„ ê³„ì‚°"""
        
        # Exponential backoff
        delay = self.initial_delay * (self.exponential_base ** attempt)
        
        # ìµœëŒ€ ì§€ì—° ì œí•œ
        delay = min(delay, self.max_delay)
        
        # Jitter ì¶”ê°€ (ëœë¤ì„±)
        if self.jitter:
            import random
            delay = delay * (0.5 + random.random())
        
        return delay
    
    def should_retry(self, error: Exception, attempt: int) -> bool:
        """ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •"""
        
        # ìµœëŒ€ ì‹œë„ íšŸìˆ˜ í™•ì¸
        if attempt >= self.max_attempts:
            return False
        
        # ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ì¸ì§€ í™•ì¸
        if not self.is_retryable(error):
            return False
        
        return True
    
    def is_retryable(self, error: Exception) -> bool:
        """ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ íŒë‹¨"""
        
        # ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬
        if isinstance(error, (ConnectionError, TimeoutError)):
            return True
        
        # HTTP ìƒíƒœ ì½”ë“œ ê¸°ë°˜
        if hasattr(error, 'status_code'):
            retryable_statuses = [
                408,  # Request Timeout
                429,  # Too Many Requests
                500,  # Internal Server Error
                502,  # Bad Gateway
                503,  # Service Unavailable
                504   # Gateway Timeout
            ]
            return error.status_code in retryable_statuses
        
        return False

class CircuitBreaker:
    """Circuit Breaker íŒ¨í„´"""
    
    def __init__(
        self,
        failure_threshold: int = 5,
        recovery_timeout: int = 60,
        expected_exception: type = Exception
    ):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.expected_exception = expected_exception
        
        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED
    
    async def call(self, func: Callable, *args, **kwargs) -> Any:
        """Circuit Breakerë¥¼ í†µí•œ í•¨ìˆ˜ í˜¸ì¶œ"""
        
        # OPEN ìƒíƒœ í™•ì¸
        if self.state == CircuitState.OPEN:
            if self.should_attempt_reset():
                self.state = CircuitState.HALF_OPEN
            else:
                raise CircuitOpenError("Circuit breaker is OPEN")
        
        try:
            # í•¨ìˆ˜ ì‹¤í–‰
            result = await func(*args, **kwargs)
            
            # ì„±ê³µ ì‹œ ì²˜ë¦¬
            self.on_success()
            
            return result
            
        except self.expected_exception as e:
            # ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬
            self.on_failure()
            raise e
    
    def on_success(self):
        """ì„±ê³µ ì‹œ ì²˜ë¦¬"""
        
        self.failure_count = 0
        
        if self.state == CircuitState.HALF_OPEN:
            self.state = CircuitState.CLOSED
    
    def on_failure(self):
        """ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬"""
        
        self.failure_count += 1
        self.last_failure_time = datetime.now()
        
        if self.failure_count >= self.failure_threshold:
            self.state = CircuitState.OPEN
    
    def should_attempt_reset(self) -> bool:
        """ë¦¬ì…‹ ì‹œë„ ì—¬ë¶€"""
        
        return (
            self.last_failure_time and
            datetime.now() - self.last_failure_time > 
            timedelta(seconds=self.recovery_timeout)
        )

class ErrorRecoveryManager:
    """ì—ëŸ¬ ë³µêµ¬ ê´€ë¦¬"""
    
    def __init__(self):
        self.retry_strategy = RetryStrategy()
        self.circuit_breakers = {}
        self.fallback_handlers = {}
    
    async def execute_with_recovery(
        self,
        func: Callable,
        *args,
        recovery_options: RecoveryOptions = None,
        **kwargs
    ) -> Any:
        """ë³µêµ¬ ì „ëµê³¼ í•¨ê»˜ ì‹¤í–‰"""
        
        options = recovery_options or RecoveryOptions()
        
        # Circuit Breaker ì ìš©
        if options.use_circuit_breaker:
            circuit_breaker = self.get_circuit_breaker(options.service_name)
            func = partial(circuit_breaker.call, func)
        
        # ì¬ì‹œë„ ë¡œì§
        last_error = None
        
        for attempt in range(options.max_retries + 1):
            try:
                return await func(*args, **kwargs)
                
            except Exception as e:
                last_error = e
                
                # ì¬ì‹œë„ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
                if not self.retry_strategy.should_retry(e, attempt):
                    break
                
                # ì¬ì‹œë„ ì§€ì—°
                delay = self.retry_strategy.calculate_delay(attempt)
                await asyncio.sleep(delay)
                
                # ë¡œê¹…
                await self.log_retry(func.__name__, attempt, e, delay)
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        if options.fallback:
            return await self.execute_fallback(
                options.fallback,
                last_error,
                *args,
                **kwargs
            )
        
        raise last_error
    
    async def execute_fallback(
        self,
        fallback: Callable,
        original_error: Exception,
        *args,
        **kwargs
    ) -> Any:
        """Fallback ì‹¤í–‰"""
        
        try:
            return await fallback(original_error, *args, **kwargs)
        except Exception as fallback_error:
            # Fallbackë„ ì‹¤íŒ¨í•œ ê²½ìš°
            raise FallbackError(
                "Fallback execution failed",
                original_error=original_error,
                fallback_error=fallback_error
            )
    
    def get_circuit_breaker(self, service_name: str) -> CircuitBreaker:
        """ì„œë¹„ìŠ¤ë³„ Circuit Breaker ì¡°íšŒ"""
        
        if service_name not in self.circuit_breakers:
            self.circuit_breakers[service_name] = CircuitBreaker()
        
        return self.circuit_breakers[service_name]

class CompensationHandler:
    """ë³´ìƒ íŠ¸ëœì­ì…˜ ì²˜ë¦¬"""
    
    def __init__(self):
        self.compensation_stack = []
    
    async def execute_with_compensation(
        self,
        operations: List[Operation]
    ) -> Any:
        """ë³´ìƒ ê°€ëŠ¥í•œ ì‘ì—… ì‹¤í–‰"""
        
        completed_operations = []
        
        try:
            # ìˆœì°¨ì ìœ¼ë¡œ ì‘ì—… ì‹¤í–‰
            for operation in operations:
                result = await operation.execute()
                completed_operations.append(operation)
                
                # ë³´ìƒ ì‘ì—… ë“±ë¡
                if operation.has_compensation:
                    self.compensation_stack.append(operation)
            
            return result
            
        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ë³´ìƒ ì‹¤í–‰
            await self.compensate(completed_operations)
            raise e
    
    async def compensate(self, operations: List[Operation]):
        """ë³´ìƒ ì‘ì—… ì‹¤í–‰"""
        
        # ì—­ìˆœìœ¼ë¡œ ë³´ìƒ ì‹¤í–‰
        for operation in reversed(operations):
            if operation.has_compensation:
                try:
                    await operation.compensate()
                except Exception as comp_error:
                    # ë³´ìƒ ì‹¤íŒ¨ ë¡œê¹…
                    await self.log_compensation_failure(
                        operation,
                        comp_error
                    )

class AdaptiveRetryStrategy:
    """ì ì‘í˜• ì¬ì‹œë„ ì „ëµ"""
    
    def __init__(self):
        self.success_rate_threshold = 0.8
        self.window_size = 100
        self.history = deque(maxlen=self.window_size)
    
    def update_strategy(self, success: bool):
        """ì „ëµ ì—…ë°ì´íŠ¸"""
        
        self.history.append(success)
        
        if len(self.history) >= self.window_size:
            success_rate = sum(self.history) / len(self.history)
            
            if success_rate < self.success_rate_threshold:
                # ì¬ì‹œë„ ê°„ê²© ì¦ê°€
                self.increase_delay()
            else:
                # ì¬ì‹œë„ ê°„ê²© ê°ì†Œ
                self.decrease_delay()
    
    def increase_delay(self):
        """ì§€ì—° ì‹œê°„ ì¦ê°€"""
        
        self.initial_delay = min(self.initial_delay * 1.5, self.max_delay)
        self.max_attempts = max(self.max_attempts - 1, 1)
    
    def decrease_delay(self):
        """ì§€ì—° ì‹œê°„ ê°ì†Œ"""
        
        self.initial_delay = max(self.initial_delay * 0.8, 0.1)
        self.max_attempts = min(self.max_attempts + 1, 10)

# ì—ëŸ¬ ë³µêµ¬ ë°ì½”ë ˆì´í„°
def with_retry(
    max_attempts: int = 3,
    delay: float = 1.0,
    exceptions: tuple = (Exception,)
):
    """ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            retry_strategy = RetryStrategy(
                max_attempts=max_attempts,
                initial_delay=delay
            )
            
            last_error = None
            
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except exceptions as e:
                    last_error = e
                    
                    if attempt < max_attempts - 1:
                        delay = retry_strategy.calculate_delay(attempt)
                        await asyncio.sleep(delay)
                    else:
                        raise e
            
            raise last_error
        
        return wrapper
    return decorator

def with_circuit_breaker(
    failure_threshold: int = 5,
    recovery_timeout: int = 60
):
    """Circuit Breaker ë°ì½”ë ˆì´í„°"""
    
    circuit_breaker = CircuitBreaker(
        failure_threshold=failure_threshold,
        recovery_timeout=recovery_timeout
    )
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            return await circuit_breaker.call(func, *args, **kwargs)
        return wrapper
    return decorator

class ErrorRecoveryMiddleware:
    """ì—ëŸ¬ ë³µêµ¬ ë¯¸ë“¤ì›¨ì–´"""
    
    def __init__(self):
        self.recovery_manager = ErrorRecoveryManager()
        self.metrics = RecoveryMetrics()
    
    async def handle(self, request: Request, next: Handler) -> Response:
        """ìš”ì²­ ì²˜ë¦¬ with ë³µêµ¬"""
        
        recovery_options = self.get_recovery_options(request)
        
        try:
            # ì •ìƒ ì²˜ë¦¬
            response = await self.recovery_manager.execute_with_recovery(
                next,
                request,
                recovery_options=recovery_options
            )
            
            # ì„±ê³µ ë©”íŠ¸ë¦­
            await self.metrics.record_success(request.path)
            
            return response
            
        except Exception as e:
            # ì‹¤íŒ¨ ë©”íŠ¸ë¦­
            await self.metrics.record_failure(request.path, e)
            
            # ì—ëŸ¬ ì‘ë‹µ ìƒì„±
            return self.create_error_response(e, request)
    
    def get_recovery_options(self, request: Request) -> RecoveryOptions:
        """ìš”ì²­ë³„ ë³µêµ¬ ì˜µì…˜"""
        
        # ì—”ë“œí¬ì¸íŠ¸ë³„ ì„¤ì •
        endpoint_config = self.get_endpoint_config(request.path)
        
        return RecoveryOptions(
            max_retries=endpoint_config.get('max_retries', 3),
            use_circuit_breaker=endpoint_config.get('circuit_breaker', True),
            fallback=endpoint_config.get('fallback'),
            timeout=endpoint_config.get('timeout', 30)
        )
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì¬ì‹œë„ ì „ëµ êµ¬í˜„
- [ ] Circuit Breaker íŒ¨í„´
- [ ] ë³´ìƒ íŠ¸ëœì­ì…˜
- [ ] ì ì‘í˜• ë³µêµ¬ ì „ëµ

---

## ğŸ“Š Phase 6 Tasks 6.6-6.10 ì™„ë£Œ í˜„í™©

### âœ… ì™„ë£Œëœ ì‘ì—…
- **Task 6.6**: REST ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„ (4 SubTasks)
  - RESTful ë¦¬ì†ŒìŠ¤ ëª¨ë¸ë§
  - URL êµ¬ì¡° ë° ë„¤ì´ë° ê·œì¹™
  - HTTP ë©”ì„œë“œ ë§¤í•‘
  - ë¦¬ì†ŒìŠ¤ ê´€ê³„ ë° ì¤‘ì²© êµ¬ì¡°

- **Task 6.7**: CRUD ì‘ì—… êµ¬í˜„ (4 SubTasks)
  - Create ì‘ì—… êµ¬í˜„
  - Read ì‘ì—… êµ¬í˜„
  - Update ì‘ì—… êµ¬í˜„
  - Delete ì‘ì—… êµ¬í˜„

- **Task 6.8**: í˜ì´ì§€ë„¤ì´ì…˜ ë° í•„í„°ë§ (4 SubTasks)
  - í˜ì´ì§€ë„¤ì´ì…˜ ì „ëµ êµ¬í˜„
  - í•„í„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•
  - ì •ë ¬ ë° ê²€ìƒ‰ ê¸°ëŠ¥
  - ì»¤ì„œ ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜

- **Task 6.9**: ì‘ë‹µ í¬ë§· í‘œì¤€í™” (4 SubTasks)
  - ì‘ë‹µ êµ¬ì¡° í‘œì¤€ ì •ì˜
  - HATEOAS êµ¬í˜„
  - ì½˜í…ì¸  í˜‘ìƒ ì²˜ë¦¬
  - ì‘ë‹µ ë©”íƒ€ë°ì´í„° ê´€ë¦¬

- **Task 6.10**: RESTful ì—ëŸ¬ ì²˜ë¦¬ (4 SubTasks)
  - ì—ëŸ¬ ì‘ë‹µ í‘œì¤€í™”
  - HTTP ìƒíƒœ ì½”ë“œ ë§¤í•‘
  - ë¬¸ì œ ì„¸ë¶€ì‚¬í•­ (RFC 7807) êµ¬í˜„
  - ì—ëŸ¬ ë³µêµ¬ ë° ì¬ì‹œë„ ì „ëµ

### ğŸ“ˆ ì§„í–‰ë¥ 
- Tasks 6.6-6.10 ì§„í–‰ë¥ : 100%
- ì´ 20ê°œ SubTasks ì™„ë£Œ
- ì˜ˆìƒ ì†Œìš”ì‹œê°„: 220ì‹œê°„

### ğŸ¯ ì£¼ìš” ì„±ê³¼

1. **ì™„ì „í•œ RESTful API êµ¬í˜„**
   - T-Developer 9ê°œ ì—ì´ì „íŠ¸ í†µí•©
   - í‘œì¤€ REST ì›ì¹™ ì¤€ìˆ˜
   - ë¦¬ì†ŒìŠ¤ ì¤‘ì‹¬ ì„¤ê³„

2. **ê³ ê¸‰ CRUD ê¸°ëŠ¥**
   - íŠ¸ëœì­ì…˜ ì²˜ë¦¬
   - ë‚™ê´€ì  ì ê¸ˆ
   - ì†Œí”„íŠ¸/í•˜ë“œ ì‚­ì œ
   - ì¼ê´„ ì‘ì—… ì§€ì›

3. **ê°•ë ¥í•œ ì¿¼ë¦¬ ê¸°ëŠ¥**
   - ë‹¤ì–‘í•œ í˜ì´ì§€ë„¤ì´ì…˜ ì „ëµ
   - ê³ ê¸‰ í•„í„°ë§ ì‹œìŠ¤í…œ
   - ì „ë¬¸ ê²€ìƒ‰ ë° ì •ë ¬
   - ì»¤ì„œ ê¸°ë°˜ ë¬´í•œ ìŠ¤í¬ë¡¤

4. **í‘œì¤€ ì¤€ìˆ˜ ì‘ë‹µ í¬ë§·**
   - JSON:API, HAL ì§€ì›
   - HATEOAS êµ¬í˜„
   - ì½˜í…ì¸  í˜‘ìƒ
   - í’ë¶€í•œ ë©”íƒ€ë°ì´í„°

5. **ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬**
   - RFC 7807 Problem Details
   - ì™„ì „í•œ HTTP ìƒíƒœ ì½”ë“œ ë§¤í•‘
   - Circuit Breaker íŒ¨í„´
   - ìë™ ì¬ì‹œë„ ë° ë³µêµ¬

### ğŸ“‹ ì „ì²´ Phase 6 ì§„í–‰ ìƒí™©
- **ì™„ë£Œëœ Tasks**: 10/15 (Tasks 6.1-6.10)
- **ì§„í–‰ë¥ **: 66.7%
- **ë‚¨ì€ Tasks**: 
  - Task 6.11: GraphQL API êµ¬í˜„
  - Task 6.12: WebSocket í†µì‹ 
  - Task 6.13: API ë¬¸ì„œí™”
  - Task 6.14: SDK ìƒì„±
  - Task 6.15: API ê²Œì´íŠ¸ì›¨ì´ í†µí•© í…ŒìŠ¤íŠ¸

### ğŸ”— ì—°ê´€ì„± ë° í†µí•© í¬ì¸íŠ¸

**ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í†µí•©**:
- 9ê°œ ì—ì´ì „íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ì™„ì„±
- ê° ì—ì´ì „íŠ¸ë³„ CRUD ì‘ì—…
- ì—ì´ì „íŠ¸ ì‹¤í–‰ ìƒíƒœ ì¶”ì 

**API Gateway ì—°ë™**:
- ë¼ìš°íŒ… ì—”ì§„ê³¼ REST ì—”ë“œí¬ì¸íŠ¸ ë§¤í•‘
- ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ í†µí•©
- ë¡œë“œ ë°¸ëŸ°ì‹± ì ìš©

**ë³´ì•ˆ ë° ì„±ëŠ¥**:
- Rate Limiting í†µí•©
- ìºì‹± ì „ëµ êµ¬í˜„
- ì¸ì¦/ì¸ê°€ ë¯¸ë“¤ì›¨ì–´

---
## Phase 6: GraphQL API êµ¬í˜„ & WebSocket í†µì‹  (Tasks 6.11-6.16) - SubTask ë¦¬ìŠ¤íŠ¸ ë° ì‘ì—…ì§€ì‹œì„œ

### ğŸ“‹ SubTask ì „ì²´ ë¦¬ìŠ¤íŠ¸

#### Task 6.11: GraphQL ìŠ¤í‚¤ë§ˆ ì •ì˜
- **SubTask 6.11.1**: íƒ€ì… ì‹œìŠ¤í…œ ë° ìŠ¤ì¹¼ë¼ ì •ì˜
- **SubTask 6.11.2**: ê°ì²´ íƒ€ì… ë° ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„
- **SubTask 6.11.3**: ì¿¼ë¦¬ ë° ë®¤í…Œì´ì…˜ ìŠ¤í‚¤ë§ˆ
- **SubTask 6.11.4**: ìŠ¤í‚¤ë§ˆ ìœ íš¨ì„± ê²€ì¦ ë° ìµœì í™”

#### Task 6.12: Resolver êµ¬í˜„
- **SubTask 6.12.1**: ì¿¼ë¦¬ ë¦¬ì¡¸ë²„ êµ¬í˜„
- **SubTask 6.12.2**: ë®¤í…Œì´ì…˜ ë¦¬ì¡¸ë²„ êµ¬í˜„
- **SubTask 6.12.3**: í•„ë“œ ë¦¬ì¡¸ë²„ ë° ê´€ê³„ ì²˜ë¦¬
- **SubTask 6.12.4**: DataLoader ë° ë°°ì¹˜ ì²˜ë¦¬

#### Task 6.13: Subscription ë° ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
- **SubTask 6.13.1**: Subscription ìŠ¤í‚¤ë§ˆ ì •ì˜
- **SubTask 6.13.2**: PubSub ì‹œìŠ¤í…œ êµ¬í˜„
- **SubTask 6.13.3**: ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ í•„í„°ë§
- **SubTask 6.13.4**: ì—°ê²° ê´€ë¦¬ ë° í™•ì¥ì„±

#### Task 6.14: WebSocket ì„œë²„ êµ¬í˜„
- **SubTask 6.14.1**: WebSocket ì„œë²„ ì´ˆê¸°í™”
- **SubTask 6.14.2**: ì—°ê²° í•¸ë“¤ë§ ë° ì¸ì¦
- **SubTask 6.14.3**: ë©”ì‹œì§€ í”„ë¡œí† ì½œ ì •ì˜
- **SubTask 6.14.4**: ì—°ê²° í’€ ê´€ë¦¬

#### Task 6.15: ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°
- **SubTask 6.15.1**: ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì•„í‚¤í…ì²˜
- **SubTask 6.15.2**: ì´ë²¤íŠ¸ ë°œí–‰ ì‹œìŠ¤í…œ
- **SubTask 6.15.3**: êµ¬ë… ê´€ë¦¬ ì‹œìŠ¤í…œ
- **SubTask 6.15.4**: ë°±í”„ë ˆì…” ë° íë¦„ ì œì–´

#### Task 6.16: ì–‘ë°©í–¥ í†µì‹  í”„ë¡œí† ì½œ
- **SubTask 6.16.1**: ë©”ì‹œì§€ í¬ë§· ì •ì˜
- **SubTask 6.16.2**: RPC over WebSocket
- **SubTask 6.16.3**: ìƒíƒœ ë™ê¸°í™” ë©”ì»¤ë‹ˆì¦˜
- **SubTask 6.16.4**: ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¬ì—°ê²° ì „ëµ

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 6.11: GraphQL ìŠ¤í‚¤ë§ˆ ì •ì˜

#### SubTask 6.11.1: íƒ€ì… ì‹œìŠ¤í…œ ë° ìŠ¤ì¹¼ë¼ ì •ì˜

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/graphql/schema/scalars.ts
import { GraphQLScalarType, Kind } from 'graphql';

// DateTime ìŠ¤ì¹¼ë¼ íƒ€ì…
export const DateTimeScalar = new GraphQLScalarType({
  name: 'DateTime',
  description: 'Date and time in ISO 8601 format',
  serialize(value: any): string {
    if (value instanceof Date) {
      return value.toISOString();
    }
    return value;
  },
  parseValue(value: any): Date {
    return new Date(value);
  },
  parseLiteral(ast): Date | null {
    if (ast.kind === Kind.STRING) {
      return new Date(ast.value);
    }
    return null;
  }
});

// JSON ìŠ¤ì¹¼ë¼ íƒ€ì…
export const JSONScalar = new GraphQLScalarType({
  name: 'JSON',
  description: 'Arbitrary JSON object',
  serialize(value: any): any {
    return value;
  },
  parseValue(value: any): any {
    return value;
  },
  parseLiteral(ast): any {
    switch (ast.kind) {
      case Kind.STRING:
      case Kind.BOOLEAN:
        return ast.value;
      case Kind.INT:
      case Kind.FLOAT:
        return parseFloat(ast.value);
      case Kind.OBJECT:
        return parseObject(ast);
      case Kind.LIST:
        return ast.values.map(parseLiteral);
      default:
        return null;
    }
  }
});

// UUID ìŠ¤ì¹¼ë¼ íƒ€ì…
export const UUIDScalar = new GraphQLScalarType({
  name: 'UUID',
  description: 'UUID v4',
  serialize(value: any): string {
    return value;
  },
  parseValue(value: any): string {
    if (!isValidUUID(value)) {
      throw new Error('Invalid UUID format');
    }
    return value;
  },
  parseLiteral(ast): string | null {
    if (ast.kind === Kind.STRING && isValidUUID(ast.value)) {
      return ast.value;
    }
    return null;
  }
});

// ì»¤ìŠ¤í…€ ìŠ¤ì¹¼ë¼: ComponentCode
export const ComponentCodeScalar = new GraphQLScalarType({
  name: 'ComponentCode',
  description: 'React/Vue/Angular component code',
  serialize(value: any): string {
    return value;
  },
  parseValue(value: any): string {
    // ì½”ë“œ ìœ íš¨ì„± ê²€ì¦
    validateComponentCode(value);
    return value;
  },
  parseLiteral(ast): string | null {
    if (ast.kind === Kind.STRING) {
      validateComponentCode(ast.value);
      return ast.value;
    }
    return null;
  }
});

// íŒŒì¼ ì—…ë¡œë“œ ìŠ¤ì¹¼ë¼
export const UploadScalar = new GraphQLScalarType({
  name: 'Upload',
  description: 'File upload',
  parseValue(value: any): any {
    return value; // Apollo Serverì˜ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
  },
  parseLiteral(ast): never {
    throw new Error('Upload literal unsupported');
  },
  serialize(): never {
    throw new Error('Upload serialization unsupported');
  }
});

// íƒ€ì… ì •ì˜ ìƒì„±ê¸°
export class TypeSystemBuilder {
  private customScalars: Map<string, GraphQLScalarType> = new Map();
  
  constructor() {
    this.registerDefaultScalars();
  }
  
  private registerDefaultScalars(): void {
    this.customScalars.set('DateTime', DateTimeScalar);
    this.customScalars.set('JSON', JSONScalar);
    this.customScalars.set('UUID', UUIDScalar);
    this.customScalars.set('ComponentCode', ComponentCodeScalar);
    this.customScalars.set('Upload', UploadScalar);
  }
  
  generateScalarDefinitions(): string {
    const scalars = Array.from(this.customScalars.keys());
    return scalars.map(name => `scalar ${name}`).join('\n');
  }
  
  getScalarResolvers(): Record<string, GraphQLScalarType> {
    const resolvers: Record<string, GraphQLScalarType> = {};
    
    this.customScalars.forEach((scalar, name) => {
      resolvers[name] = scalar;
    });
    
    return resolvers;
  }
}

// Enum íƒ€ì… ì •ì˜
export const EnumDefinitions = `
  enum ProjectStatus {
    DRAFT
    ACTIVE
    COMPLETED
    ARCHIVED
  }
  
  enum ComponentType {
    FUNCTIONAL
    CLASS
    HOOKS
    PROVIDER
    LAYOUT
  }
  
  enum AgentType {
    REQUIREMENTS_ANALYZER
    UI_GENERATOR
    COMPONENT_DESIGNER
    API_INTEGRATOR
    STATE_MANAGER
    ROUTE_CONFIGURATOR
    STYLE_OPTIMIZER
    TEST_GENERATOR
    DEPLOYMENT_PREPARER
  }
  
  enum SortOrder {
    ASC
    DESC
  }
  
  enum FilterOperator {
    EQ
    NE
    GT
    GTE
    LT
    LTE
    IN
    NIN
    CONTAINS
    STARTS_WITH
    ENDS_WITH
  }
`;

// Input íƒ€ì… ì •ì˜
export const InputTypeDefinitions = `
  input PaginationInput {
    page: Int
    limit: Int
    cursor: String
  }
  
  input SortInput {
    field: String!
    order: SortOrder!
  }
  
  input FilterInput {
    field: String!
    operator: FilterOperator!
    value: JSON!
  }
  
  input QueryOptions {
    pagination: PaginationInput
    sort: [SortInput!]
    filters: [FilterInput!]
  }
`;
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì»¤ìŠ¤í…€ ìŠ¤ì¹¼ë¼ íƒ€ì… ì •ì˜
- [ ] ìœ íš¨ì„± ê²€ì¦ ë¡œì§
- [ ] Enum íƒ€ì… ì™„ì„±ë„
- [ ] Input íƒ€ì… êµ¬ì¡°

#### SubTask 6.11.2: ê°ì²´ íƒ€ì… ë° ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```graphql
# backend/src/graphql/schema/types.graphql

# ì¸í„°í˜ì´ìŠ¤ ì •ì˜
interface Node {
  id: ID!
}

interface Timestamped {
  createdAt: DateTime!
  updatedAt: DateTime!
}

interface Owned {
  owner: User!
}

# í”„ë¡œì íŠ¸ íƒ€ì…
type Project implements Node & Timestamped & Owned {
  id: ID!
  name: String!
  description: String
  framework: String!
  status: ProjectStatus!
  owner: User!
  components: [Component!]!
  agents: [AgentExecution!]!
  settings: ProjectSettings!
  statistics: ProjectStatistics!
  createdAt: DateTime!
  updatedAt: DateTime!
}

type ProjectSettings {
  id: ID!
  project: Project!
  theme: JSON
  buildConfig: JSON
  deploymentConfig: JSON
  environmentVariables: [EnvironmentVariable!]!
}

type ProjectStatistics {
  componentCount: Int!
  linesOfCode: Int!
  lastBuildTime: DateTime
  buildStatus: String
  testCoverage: Float
}

# ì»´í¬ë„ŒíŠ¸ íƒ€ì…
type Component implements Node & Timestamped {
  id: ID!
  name: String!
  type: ComponentType!
  category: String
  code: ComponentCode!
  styles: String
  props: [PropDefinition!]!
  dependencies: [Dependency!]!
  parent: Component
  children: [Component!]!
  project: Project!
  version: String!
  createdAt: DateTime!
  updatedAt: DateTime!
}

type PropDefinition {
  name: String!
  type: String!
  required: Boolean!
  defaultValue: JSON
  description: String
}

type Dependency {
  name: String!
  version: String!
  type: String! # npm, component, asset
}

# ì—ì´ì „íŠ¸ ì‹¤í–‰ íƒ€ì…
type AgentExecution implements Node & Timestamped {
  id: ID!
  agent: AgentType!
  status: ExecutionStatus!
  input: JSON!
  output: JSON
  project: Project!
  triggeredBy: User!
  startedAt: DateTime
  completedAt: DateTime
  duration: Int
  error: ExecutionError
  logs: [ExecutionLog!]!
  createdAt: DateTime!
  updatedAt: DateTime!
}

type ExecutionError {
  code: String!
  message: String!
  details: JSON
  stackTrace: String
}

type ExecutionLog {
  timestamp: DateTime!
  level: String!
  message: String!
  data: JSON
}

# ì‚¬ìš©ì íƒ€ì…
type User implements Node & Timestamped {
  id: ID!
  email: String!
  name: String
  avatar: String
  role: UserRole!
  projects: [Project!]!
  executions: [AgentExecution!]!
  preferences: UserPreferences!
  createdAt: DateTime!
  updatedAt: DateTime!
}

type UserPreferences {
  theme: String!
  language: String!
  notifications: NotificationSettings!
  shortcuts: JSON
}

type NotificationSettings {
  email: Boolean!
  push: Boolean!
  inApp: Boolean!
  agentCompleted: Boolean!
  deploymentStatus: Boolean!
}

# í˜ì´ì§€ë„¤ì´ì…˜ íƒ€ì…
type PageInfo {
  hasNextPage: Boolean!
  hasPreviousPage: Boolean!
  startCursor: String
  endCursor: String
  totalCount: Int
}

type ProjectConnection {
  edges: [ProjectEdge!]!
  pageInfo: PageInfo!
}

type ProjectEdge {
  node: Project!
  cursor: String!
}

# Union íƒ€ì…
union SearchResult = Project | Component | User

# ì—ëŸ¬ íƒ€ì…
type ValidationError {
  field: String!
  message: String!
  code: String!
}

type MutationResponse {
  success: Boolean!
  message: String
  errors: [ValidationError!]
}
```

```python
# backend/src/graphql/schema/type_registry.py
from typing import Dict, List, Type
from graphql import GraphQLObjectType, GraphQLInterfaceType

class TypeRegistry:
    """GraphQL íƒ€ì… ë ˆì§€ìŠ¤íŠ¸ë¦¬"""
    
    def __init__(self):
        self.types: Dict[str, GraphQLObjectType] = {}
        self.interfaces: Dict[str, GraphQLInterfaceType] = {}
        self.resolvers: Dict[str, Dict[str, callable]] = {}
    
    def register_type(self, name: str, type_def: GraphQLObjectType):
        """íƒ€ì… ë“±ë¡"""
        self.types[name] = type_def
    
    def register_interface(self, name: str, interface: GraphQLInterfaceType):
        """ì¸í„°í˜ì´ìŠ¤ ë“±ë¡"""
        self.interfaces[name] = interface
    
    def register_resolver(self, type_name: str, field_name: str, resolver: callable):
        """ë¦¬ì¡¸ë²„ ë“±ë¡"""
        if type_name not in self.resolvers:
            self.resolvers[type_name] = {}
        self.resolvers[type_name][field_name] = resolver
    
    def get_type_map(self) -> Dict:
        """ì „ì²´ íƒ€ì… ë§µ ë°˜í™˜"""
        return {
            **self.types,
            **self.interfaces
        }

class TypeValidator:
    """íƒ€ì… ìœ íš¨ì„± ê²€ì¦"""
    
    def validate_schema(self, schema: str) -> List[str]:
        """ìŠ¤í‚¤ë§ˆ ìœ íš¨ì„± ê²€ì¦"""
        errors = []
        
        # ìˆœí™˜ ì°¸ì¡° ì²´í¬
        errors.extend(self.check_circular_references(schema))
        
        # í•„ìˆ˜ í•„ë“œ ì²´í¬
        errors.extend(self.check_required_fields(schema))
        
        # íƒ€ì… ì¼ê´€ì„± ì²´í¬
        errors.extend(self.check_type_consistency(schema))
        
        return errors
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„
- [ ] íƒ€ì… ê´€ê³„ ì •ì˜
- [ ] í˜ì´ì§€ë„¤ì´ì…˜ íƒ€ì…
- [ ] Union/Interface í™œìš©

#### SubTask 6.11.3: ì¿¼ë¦¬ ë° ë®¤í…Œì´ì…˜ ìŠ¤í‚¤ë§ˆ

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```graphql
# backend/src/graphql/schema/operations.graphql

type Query {
  # ë‹¨ì¼ ì¡°íšŒ
  project(id: ID!): Project
  component(id: ID!): Component
  user(id: ID!): User
  agentExecution(id: ID!): AgentExecution
  
  # ëª©ë¡ ì¡°íšŒ
  projects(
    options: QueryOptions
    status: ProjectStatus
    ownerId: ID
  ): ProjectConnection!
  
  components(
    projectId: ID!
    options: QueryOptions
    type: ComponentType
  ): ComponentConnection!
  
  agentExecutions(
    projectId: ID
    agentType: AgentType
    status: ExecutionStatus
    options: QueryOptions
  ): AgentExecutionConnection!
  
  # ê²€ìƒ‰
  search(
    query: String!
    types: [String!]
    limit: Int = 10
  ): [SearchResult!]!
  
  # í†µê³„
  projectStatistics(projectId: ID!): ProjectStatistics!
  userStatistics(userId: ID!): UserStatistics!
  systemStatistics: SystemStatistics!
  
  # í˜„ì¬ ì‚¬ìš©ì
  me: User
  myProjects(options: QueryOptions): ProjectConnection!
  
  # ì»´í¬ë„ŒíŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
  componentLibrary(
    category: String
    framework: String
    options: QueryOptions
  ): ComponentConnection!
  
  # ì—ì´ì „íŠ¸ ì •ë³´
  availableAgents: [AgentInfo!]!
  agentStatus(agentType: AgentType!): AgentStatus!
}

type Mutation {
  # í”„ë¡œì íŠ¸ ê´€ë¦¬
  createProject(input: CreateProjectInput!): ProjectPayload!
  updateProject(id: ID!, input: UpdateProjectInput!): ProjectPayload!
  deleteProject(id: ID!): DeletePayload!
  archiveProject(id: ID!): ProjectPayload!
  
  # ì»´í¬ë„ŒíŠ¸ ê´€ë¦¬
  createComponent(input: CreateComponentInput!): ComponentPayload!
  updateComponent(id: ID!, input: UpdateComponentInput!): ComponentPayload!
  deleteComponent(id: ID!): DeletePayload!
  duplicateComponent(id: ID!): ComponentPayload!
  
  # ì—ì´ì „íŠ¸ ì‹¤í–‰
  executeAgent(input: ExecuteAgentInput!): AgentExecutionPayload!
  cancelAgentExecution(id: ID!): AgentExecutionPayload!
  retryAgentExecution(id: ID!): AgentExecutionPayload!
  
  # ì½”ë“œ ìƒì„±
  generateCode(projectId: ID!, options: GenerateOptions): GenerateCodePayload!
  generateComponent(input: GenerateComponentInput!): ComponentPayload!
  optimizeStyles(componentId: ID!): OptimizeStylesPayload!
  
  # ë°°í¬
  deployProject(projectId: ID!, environment: String!): DeploymentPayload!
  rollbackDeployment(deploymentId: ID!): DeploymentPayload!
  
  # ì‚¬ìš©ì ê´€ë¦¬
  updateProfile(input: UpdateProfileInput!): UserPayload!
  updatePreferences(input: UpdatePreferencesInput!): UserPayload!
  
  # í˜‘ì—…
  shareProject(projectId: ID!, userId: ID!, role: String!): SharePayload!
  removeCollaborator(projectId: ID!, userId: ID!): MutationResponse!
  
  # ë²„ì „ ê´€ë¦¬
  createVersion(projectId: ID!, tag: String!): VersionPayload!
  restoreVersion(versionId: ID!): ProjectPayload!
}

# Input íƒ€ì…ë“¤
input CreateProjectInput {
  name: String!
  description: String
  framework: String!
  template: String
  settings: ProjectSettingsInput
}

input UpdateProjectInput {
  name: String
  description: String
  status: ProjectStatus
  settings: ProjectSettingsInput
}

input CreateComponentInput {
  projectId: ID!
  name: String!
  type: ComponentType!
  category: String
  parentId: ID
  code: ComponentCode
  styles: String
}

input UpdateComponentInput {
  name: String
  category: String
  code: ComponentCode
  styles: String
  props: [PropDefinitionInput!]
}

input ExecuteAgentInput {
  projectId: ID!
  agentType: AgentType!
  input: JSON!
  options: AgentOptions
}

input AgentOptions {
  timeout: Int
  priority: Int
  parallel: Boolean
}

# Payload íƒ€ì…ë“¤
type ProjectPayload {
  project: Project
  success: Boolean!
  message: String
  errors: [ValidationError!]
}

type ComponentPayload {
  component: Component
  success: Boolean!
  message: String
  errors: [ValidationError!]
}

type AgentExecutionPayload {
  execution: AgentExecution
  success: Boolean!
  message: String
  errors: [ValidationError!]
}

type GenerateCodePayload {
  code: String!
  files: [GeneratedFile!]!
  success: Boolean!
  message: String
}

type GeneratedFile {
  path: String!
  content: String!
  type: String!
}
```

```typescript
// backend/src/graphql/schema/schema-builder.ts
import { makeExecutableSchema } from '@graphql-tools/schema';
import { mergeTypeDefs, mergeResolvers } from '@graphql-tools/merge';

export class SchemaBuilder {
  private typeDefs: string[] = [];
  private resolvers: any[] = [];
  
  constructor() {
    this.loadTypeDefs();
    this.loadResolvers();
  }
  
  private loadTypeDefs(): void {
    // ê¸°ë³¸ íƒ€ì… ì •ì˜
    this.typeDefs.push(ScalarDefinitions);
    this.typeDefs.push(EnumDefinitions);
    this.typeDefs.push(InterfaceDefinitions);
    this.typeDefs.push(TypeDefinitions);
    this.typeDefs.push(QueryDefinitions);
    this.typeDefs.push(MutationDefinitions);
    this.typeDefs.push(SubscriptionDefinitions);
  }
  
  private loadResolvers(): void {
    // ë¦¬ì¡¸ë²„ ë¡œë“œ
    this.resolvers.push(ScalarResolvers);
    this.resolvers.push(QueryResolvers);
    this.resolvers.push(MutationResolvers);
    this.resolvers.push(SubscriptionResolvers);
    this.resolvers.push(TypeResolvers);
  }
  
  build(): GraphQLSchema {
    const mergedTypeDefs = mergeTypeDefs(this.typeDefs);
    const mergedResolvers = mergeResolvers(this.resolvers);
    
    return makeExecutableSchema({
      typeDefs: mergedTypeDefs,
      resolvers: mergedResolvers,
      inheritResolversFromInterfaces: true
    });
  }
  
  addPlugin(plugin: GraphQLPlugin): void {
    if (plugin.typeDefs) {
      this.typeDefs.push(plugin.typeDefs);
    }
    if (plugin.resolvers) {
      this.resolvers.push(plugin.resolvers);
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì™„ì „í•œ Query ì •ì˜
- [ ] ì™„ì „í•œ Mutation ì •ì˜
- [ ] Input/Payload íƒ€ì…
- [ ] ìŠ¤í‚¤ë§ˆ ì¡°í•© ë¡œì§

#### SubTask 6.11.4: ìŠ¤í‚¤ë§ˆ ìœ íš¨ì„± ê²€ì¦ ë° ìµœì í™”

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/graphql/schema/validator.py
from graphql import validate, parse, build_schema
from typing import List, Dict, Any

class SchemaValidator:
    """GraphQL ìŠ¤í‚¤ë§ˆ ê²€ì¦ê¸°"""
    
    def __init__(self):
        self.rules = self.load_validation_rules()
        self.warnings = []
        self.errors = []
    
    def validate_schema(self, schema_string: str) -> ValidationResult:
        """ìŠ¤í‚¤ë§ˆ ìœ íš¨ì„± ê²€ì¦"""
        
        try:
            # ìŠ¤í‚¤ë§ˆ íŒŒì‹±
            schema = build_schema(schema_string)
            
            # êµ¬ì¡°ì  ê²€ì¦
            self.validate_structure(schema)
            
            # ë„¤ì´ë° ê·œì¹™ ê²€ì¦
            self.validate_naming_conventions(schema)
            
            # ìˆœí™˜ ì°¸ì¡° ê²€ì¦
            self.validate_circular_references(schema)
            
            # ë³µì¡ë„ ê²€ì¦
            self.validate_complexity(schema)
            
            # ë³´ì•ˆ ê²€ì¦
            self.validate_security(schema)
            
            return ValidationResult(
                valid=len(self.errors) == 0,
                errors=self.errors,
                warnings=self.warnings
            )
            
        except Exception as e:
            self.errors.append(f"Schema parsing error: {str(e)}")
            return ValidationResult(valid=False, errors=self.errors)
    
    def validate_structure(self, schema):
        """êµ¬ì¡°ì  ìœ íš¨ì„± ê²€ì¦"""
        
        # Query íƒ€ì… ì¡´ì¬ í™•ì¸
        if not schema.query_type:
            self.errors.append("Query type is required")
        
        # ëª¨ë“  íƒ€ì…ì˜ í•„ë“œ ê²€ì¦
        for type_name, type_def in schema.type_map.items():
            if type_name.startswith("__"):
                continue
                
            # ë¹ˆ íƒ€ì… ì²´í¬
            if hasattr(type_def, 'fields') and not type_def.fields:
                self.warnings.append(f"Type {type_name} has no fields")
            
            # í•„ë“œ íƒ€ì… ê²€ì¦
            if hasattr(type_def, 'fields'):
                for field_name, field in type_def.fields.items():
                    self.validate_field(type_name, field_name, field)
    
    def validate_naming_conventions(self, schema):
        """ë„¤ì´ë° ê·œì¹™ ê²€ì¦"""
        
        for type_name in schema.type_map:
            if type_name.startswith("__"):
                continue
            
            # íƒ€ì… ì´ë¦„ì€ PascalCase
            if not self.is_pascal_case(type_name):
                self.warnings.append(
                    f"Type {type_name} should be in PascalCase"
                )
            
            type_def = schema.type_map[type_name]
            
            # í•„ë“œ ì´ë¦„ì€ camelCase
            if hasattr(type_def, 'fields'):
                for field_name in type_def.fields:
                    if not self.is_camel_case(field_name):
                        self.warnings.append(
                            f"Field {type_name}.{field_name} should be in camelCase"
                        )
    
    def validate_circular_references(self, schema):
        """ìˆœí™˜ ì°¸ì¡° ê²€ì¦"""
        
        visited = set()
        rec_stack = set()
        
        def has_cycle(type_name: str) -> bool:
            visited.add(type_name)
            rec_stack.add(type_name)
            
            type_def = schema.type_map.get(type_name)
            if not type_def or not hasattr(type_def, 'fields'):
                rec_stack.remove(type_name)
                return False
            
            for field_name, field in type_def.fields.items():
                field_type = self.get_base_type(field.type)
                
                if field_type not in visited:
                    if has_cycle(field_type):
                        return True
                elif field_type in rec_stack:
                    self.warnings.append(
                        f"Circular reference detected: {type_name} -> {field_type}"
                    )
            
            rec_stack.remove(type_name)
            return False
        
        for type_name in schema.type_map:
            if type_name not in visited and not type_name.startswith("__"):
                has_cycle(type_name)

class SchemaOptimizer:
    """ìŠ¤í‚¤ë§ˆ ìµœì í™”"""
    
    def optimize(self, schema: str) -> str:
        """ìŠ¤í‚¤ë§ˆ ìµœì í™”"""
        
        # ì¤‘ë³µ íƒ€ì… ì œê±°
        schema = self.remove_duplicate_types(schema)
        
        # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” íƒ€ì… ì œê±°
        schema = self.remove_unused_types(schema)
        
        # í•„ë“œ ìµœì í™”
        schema = self.optimize_fields(schema)
        
        # ì¿¼ë¦¬ ë³µì¡ë„ ìµœì í™”
        schema = self.optimize_query_complexity(schema)
        
        return schema
    
    def analyze_complexity(self, query: str, schema) -> ComplexityAnalysis:
        """ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„"""
        
        ast = parse(query)
        
        complexity = 0
        depth = 0
        
        def visit_field(node, current_depth=0):
            nonlocal complexity, depth
            
            complexity += self.calculate_field_complexity(node)
            depth = max(depth, current_depth)
            
            if hasattr(node, 'selection_set') and node.selection_set:
                for selection in node.selection_set.selections:
                    visit_field(selection, current_depth + 1)
        
        for definition in ast.definitions:
            if hasattr(definition, 'selection_set'):
                for selection in definition.selection_set.selections:
                    visit_field(selection)
        
        return ComplexityAnalysis(
            complexity=complexity,
            depth=depth,
            exceeds_limit=complexity > 1000 or depth > 10
        )

class DeprecationManager:
    """ìŠ¤í‚¤ë§ˆ deprecation ê´€ë¦¬"""
    
    def mark_deprecated(
        self,
        schema,
        type_name: str,
        field_name: str,
        reason: str,
        removal_date: str
    ):
        """í•„ë“œ deprecation ë§ˆí‚¹"""
        
        directive = f'@deprecated(reason: "{reason}", removalDate: "{removal_date}")'
        
        # ìŠ¤í‚¤ë§ˆì— deprecation ë””ë ‰í‹°ë¸Œ ì¶”ê°€
        return self.add_directive(schema, type_name, field_name, directive)
    
    def get_deprecated_fields(self, schema) -> List[DeprecatedField]:
        """Deprecated í•„ë“œ ëª©ë¡ ì¡°íšŒ"""
        
        deprecated = []
        
        for type_name, type_def in schema.type_map.items():
            if hasattr(type_def, 'fields'):
                for field_name, field in type_def.fields.items():
                    if field.is_deprecated:
                        deprecated.append(DeprecatedField(
                            type=type_name,
                            field=field_name,
                            reason=field.deprecation_reason
                        ))
        
        return deprecated
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ê²€ì¦
- [ ] ë„¤ì´ë° ê·œì¹™ ê²€ì¦
- [ ] ìˆœí™˜ ì°¸ì¡° ê°ì§€
- [ ] ë³µì¡ë„ ë¶„ì„

---

### Task 6.12: Resolver êµ¬í˜„

#### SubTask 6.12.1: ì¿¼ë¦¬ ë¦¬ì¡¸ë²„ êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/graphql/resolvers/query-resolvers.ts
import { IResolvers } from '@graphql-tools/utils';
import { Context } from '../context';

export const QueryResolvers: IResolvers = {
  Query: {
    // ë‹¨ì¼ ì¡°íšŒ ë¦¬ì¡¸ë²„
    project: async (parent, { id }, context: Context) => {
      // ê¶Œí•œ í™•ì¸
      await context.authorize('project:read', id);
      
      // ë°ì´í„° ë¡œë“œ
      const project = await context.dataSources.projectAPI.getProject(id);
      
      if (!project) {
        throw new NotFoundError(`Project ${id} not found`);
      }
      
      return project;
    },
    
    component: async (parent, { id }, context: Context) => {
      const component = await context.dataSources.componentAPI.getComponent(id);
      
      // í”„ë¡œì íŠ¸ ê¶Œí•œ í™•ì¸
      await context.authorize('project:read', component.projectId);
      
      return component;
    },
    
    // ëª©ë¡ ì¡°íšŒ ë¦¬ì¡¸ë²„
    projects: async (parent, args, context: Context) => {
      const { options, status, ownerId } = args;
      
      // í•„í„° êµ¬ì„±
      const filters: any = {};
      if (status) filters.status = status;
      if (ownerId) filters.ownerId = ownerId;
      
      // í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬
      const connection = await context.dataSources.projectAPI.getProjects({
        filters,
        ...options
      });
      
      return connection;
    },
    
    components: async (parent, { projectId, options, type }, context: Context) => {
      // í”„ë¡œì íŠ¸ ê¶Œí•œ í™•ì¸
      await context.authorize('project:read', projectId);
      
      const filters: any = { projectId };
      if (type) filters.type = type;
      
      return await context.dataSources.componentAPI.getComponents({
        filters,
        ...options
      });
    },
    
    // ê²€ìƒ‰ ë¦¬ì¡¸ë²„
    search: async (parent, { query, types, limit }, context: Context) => {
      const searchService = context.services.searchService;
      
      const results = await searchService.search({
        query,
        types: types || ['Project', 'Component', 'User'],
        limit,
        userId: context.user.id
      });
      
      // Union íƒ€ì… ë¦¬ì¡¸ë²„ë¥¼ ìœ„í•œ __typename ì¶”ê°€
      return results.map(result => ({
        ...result,
        __typename: result.type
      }));
    },
    
    // í†µê³„ ë¦¬ì¡¸ë²„
    projectStatistics: async (parent, { projectId }, context: Context) => {
      await context.authorize('project:read', projectId);
      
      const stats = await context.services.analyticsService.getProjectStats(projectId);
      
      return {
        componentCount: stats.components,
        linesOfCode: stats.loc,
        lastBuildTime: stats.lastBuild,
        buildStatus: stats.buildStatus,
        testCoverage: stats.coverage
      };
    },
    
    // í˜„ì¬ ì‚¬ìš©ì
    me: async (parent, args, context: Context) => {
      if (!context.user) {
        return null;
      }
      
      return await context.dataSources.userAPI.getUser(context.user.id);
    },
    
    myProjects: async (parent, { options }, context: Context) => {
      if (!context.user) {
        throw new AuthenticationError('Not authenticated');
      }
      
      return await context.dataSources.projectAPI.getProjects({
        filters: { ownerId: context.user.id },
        ...options
      });
    },
    
    // ì»´í¬ë„ŒíŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
    componentLibrary: async (parent, { category, framework, options }, context: Context) => {
      const filters: any = { isLibrary: true };
      if (category) filters.category = category;
      if (framework) filters.framework = framework;
      
      return await context.dataSources.componentAPI.getLibraryComponents({
        filters,
        ...options
      });
    },
    
    // ì—ì´ì „íŠ¸ ì •ë³´
    availableAgents: async (parent, args, context: Context) => {
      const agents = await context.services.agentService.getAvailableAgents();
      
      return agents.map(agent => ({
        type: agent.type,
        name: agent.name,
        description: agent.description,
        status: agent.status,
        capabilities: agent.capabilities
      }));
    },
    
    agentStatus: async (parent, { agentType }, context: Context) => {
      const status = await context.services.agentService.getAgentStatus(agentType);
      
      return {
        type: agentType,
        available: status.available,
        queueLength: status.queueLength,
        averageExecutionTime: status.avgTime,
        successRate: status.successRate
      };
    }
  }
};

// íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ DataLoader ì‚¬ìš©
export class QueryOptimizer {
  constructor(private context: Context) {}
  
  createLoaders() {
    return {
      projectLoader: new DataLoader(async (ids: string[]) => {
        const projects = await this.context.dataSources.projectAPI.getProjectsByIds(ids);
        return ids.map(id => projects.find(p => p.id === id));
      }),
      
      componentLoader: new DataLoader(async (ids: string[]) => {
        const components = await this.context.dataSources.componentAPI.getComponentsByIds(ids);
        return ids.map(id => components.find(c => c.id === id));
      }),
      
      userLoader: new DataLoader(async (ids: string[]) => {
        const users = await this.context.dataSources.userAPI.getUsersByIds(ids);
        return ids.map(id => users.find(u => u.id === id));
      })
    };
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ëª¨ë“  Query ë¦¬ì¡¸ë²„ êµ¬í˜„
- [ ] ê¶Œí•œ í™•ì¸ ë¡œì§
- [ ] DataLoader í†µí•©
- [ ] ì—ëŸ¬ ì²˜ë¦¬

#### SubTask 6.12.2: ë®¤í…Œì´ì…˜ ë¦¬ì¡¸ë²„ êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/graphql/resolvers/mutation_resolvers.py
from typing import Dict, Any
from graphql import GraphQLError

class MutationResolvers:
    """ë®¤í…Œì´ì…˜ ë¦¬ì¡¸ë²„"""
    
    @staticmethod
    async def create_project(parent, args, context):
        """í”„ë¡œì íŠ¸ ìƒì„±"""
        
        input_data = args['input']
        
        # ê¶Œí•œ í™•ì¸
        if not context.user:
            raise GraphQLError("Authentication required")
        
        # ì…ë ¥ ê²€ì¦
        validation_errors = await validate_project_input(input_data)
        if validation_errors:
            return {
                'project': None,
                'success': False,
                'errors': validation_errors
            }
        
        try:
            # í”„ë¡œì íŠ¸ ìƒì„±
            project = await context.services.project_service.create_project({
                **input_data,
                'owner_id': context.user.id
            })
            
            # ì´ˆê¸° ì„¤ì • ìƒì„±
            if input_data.get('settings'):
                await context.services.project_service.update_settings(
                    project.id,
                    input_data['settings']
                )
            
            # í…œí”Œë¦¿ ì ìš©
            if input_data.get('template'):
                await context.services.template_service.apply_template(
                    project.id,
                    input_data['template']
                )
            
            # ì´ë²¤íŠ¸ ë°œìƒ
            await context.pubsub.publish('project_created', {
                'projectCreated': project
            })
            
            return {
                'project': project,
                'success': True,
                'message': 'Project created successfully'
            }
            
        except Exception as e:
            return {
                'project': None,
                'success': False,
                'message': str(e)
            }
    
    @staticmethod
    async def execute_agent(parent, args, context):
        """ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        
        input_data = args['input']
        
        # í”„ë¡œì íŠ¸ ê¶Œí•œ í™•ì¸
        await context.authorize('project:write', input_data['project_id'])
        
        # ì—ì´ì „íŠ¸ ì‹¤í–‰ ìƒì„±
        execution = await context.services.agent_service.create_execution({
            'project_id': input_data['project_id'],
            'agent_type': input_data['agent_type'],
            'input': input_data['input'],
            'triggered_by': context.user.id,
            'options': input_data.get('options', {})
        })
        
        # ë¹„ë™ê¸° ì‹¤í–‰ ì‹œì‘
        asyncio.create_task(
            self._execute_agent_async(execution.id, context)
        )
        
        # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ êµ¬ë… íŠ¸ë¦¬ê±°
        await context.pubsub.publish(f'agent_execution_{execution.id}', {
            'agentExecutionUpdated': execution
        })
        
        return {
            'execution': execution,
            'success': True,
            'message': 'Agent execution started'
        }
    
    @staticmethod
    async def _execute_agent_async(execution_id: str, context):
        """ë¹„ë™ê¸° ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        
        try:
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            result = await context.services.agent_service.execute(execution_id)
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            await context.services.agent_service.update_execution(
                execution_id,
                {
                    'status': 'completed',
                    'output': result,
                    'completed_at': datetime.now()
                }
            )
            
        except Exception as e:
            # ì‹¤íŒ¨ ì²˜ë¦¬
            await context.services.agent_service.update_execution(
                execution_id,
                {
                    'status': 'failed',
                    'error': {
                        'code': 'EXECUTION_ERROR',
                        'message': str(e)
                    }
                }
            )
        
        finally:
            # ì™„ë£Œ ì´ë²¤íŠ¸ ë°œìƒ
            execution = await context.services.agent_service.get_execution(execution_id)
            await context.pubsub.publish(f'agent_execution_{execution_id}', {
                'agentExecutionUpdated': execution
            })
    
    @staticmethod
    async def generate_code(parent, args, context):
        """ì½”ë“œ ìƒì„±"""
        
        project_id = args['project_id']
        options = args.get('options', {})
        
        # ê¶Œí•œ í™•ì¸
        await context.authorize('project:write', project_id)
        
        # í”„ë¡œì íŠ¸ ë¡œë“œ
        project = await context.services.project_service.get_project(project_id)
        
        # ì½”ë“œ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline = CodeGenerationPipeline(project, options)
        
        # ê° ì—ì´ì „íŠ¸ ìˆœì°¨ ì‹¤í–‰
        agents = [
            'requirements_analyzer',
            'ui_generator',
            'component_designer',
            'api_integrator',
            'state_manager',
            'route_configurator',
            'style_optimizer',
            'test_generator',
            'deployment_preparer'
        ]
        
        generated_files = []
        
        for agent_type in agents:
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            result = await context.services.agent_service.execute_sync(
                project_id,
                agent_type,
                pipeline.get_input_for_agent(agent_type)
            )
            
            # ê²°ê³¼ ì²˜ë¦¬
            pipeline.process_agent_result(agent_type, result)
            
            # íŒŒì¼ ìƒì„±
            files = pipeline.generate_files_from_result(agent_type, result)
            generated_files.extend(files)
        
        # ìµœì¢… ì½”ë“œ ì¡°í•©
        final_code = pipeline.combine_results()
        
        return {
            'code': final_code,
            'files': generated_files,
            'success': True,
            'message': f'Generated {len(generated_files)} files'
        }
    
    @staticmethod
    async def deploy_project(parent, args, context):
        """í”„ë¡œì íŠ¸ ë°°í¬"""
        
        project_id = args['project_id']
        environment = args['environment']
        
        # ê¶Œí•œ í™•ì¸
        await context.authorize('project:deploy', project_id)
        
        # ë°°í¬ ì „ ê²€ì¦
        validation = await context.services.deployment_service.validate_deployment(
            project_id,
            environment
        )
        
        if not validation['valid']:
            return {
                'deployment': None,
                'success': False,
                'message': 'Deployment validation failed',
                'errors': validation['errors']
            }
        
        # ë°°í¬ ìƒì„±
        deployment = await context.services.deployment_service.create_deployment({
            'project_id': project_id,
            'environment': environment,
            'initiated_by': context.user.id
        })
        
        # ë¹„ë™ê¸° ë°°í¬ ì‹œì‘
        asyncio.create_task(
            context.services.deployment_service.execute_deployment(deployment.id)
        )
        
        return {
            'deployment': deployment,
            'success': True,
            'message': 'Deployment initiated'
        }
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ëª¨ë“  Mutation ë¦¬ì¡¸ë²„
- [ ] íŠ¸ëœì­ì…˜ ì²˜ë¦¬
- [ ] ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬
- [ ] ì—ëŸ¬ í•¸ë“¤ë§

#### SubTask 6.12.3: í•„ë“œ ë¦¬ì¡¸ë²„ ë° ê´€ê³„ ì²˜ë¦¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/graphql/resolvers/field-resolvers.ts
export const FieldResolvers = {
  Project: {
    owner: async (project, args, context) => {
      // DataLoaderë¥¼ ì‚¬ìš©í•œ ë°°ì¹˜ ë¡œë”©
      return context.loaders.userLoader.load(project.ownerId);
    },
    
    components: async (project, { limit, offset }, context) => {
      return await context.dataSources.componentAPI.getComponentsByProject(
        project.id,
        { limit, offset }
      );
    },
    
    agents: async (project, args, context) => {
      return await context.dataSources.agentAPI.getExecutionsByProject(project.id);
    },
    
    settings: async (project, args, context) => {
      // ìºì‹±ëœ ì„¤ì • ë°˜í™˜
      const cacheKey = `project_settings_${project.id}`;
      const cached = await context.cache.get(cacheKey);
      
      if (cached) {
        return cached;
      }
      
      const settings = await context.dataSources.projectAPI.getSettings(project.id);
      await context.cache.set(cacheKey, settings, 300); // 5ë¶„ ìºì‹±
      
      return settings;
    },
    
    statistics: async (project, args, context) => {
      // í†µê³„ëŠ” ì‹¤ì‹œê°„ ê³„ì‚°
      return await context.services.analyticsService.calculateProjectStats(project.id);
    }
  },
  
  Component: {
    project: async (component, args, context) => {
      return context.loaders.projectLoader.load(component.projectId);
    },
    
    parent: async (component, args, context) => {
      if (!component.parentId) return null;
      return context.loaders.componentLoader.load(component.parentId);
    },
    
    children: async (component, args, context) => {
      return await context.dataSources.componentAPI.getChildComponents(component.id);
    },
    
    dependencies: async (component, args, context) => {
      // ì˜ì¡´ì„± ë¶„ì„
      const deps = await context.services.dependencyService.analyze(component.code);
      return deps.map(dep => ({
        name: dep.name,
        version: dep.version,
        type: dep.type
      }));
    }
  },
  
  AgentExecution: {
    project: async (execution, args, context) => {
      return context.loaders.projectLoader.load(execution.projectId);
    },
    
    triggeredBy: async (execution, args, context) => {
      return context.loaders.userLoader.load(execution.triggeredById);
    },
    
    logs: async (execution, { level, limit }, context) => {
      const filters: any = {};
      if (level) filters.level = level;
      
      return await context.dataSources.logsAPI.getExecutionLogs(
        execution.id,
        { filters, limit }
      );
    },
    
    duration: (execution) => {
      if (!execution.startedAt || !execution.completedAt) {
        return null;
      }
      return execution.completedAt.getTime() - execution.startedAt.getTime();
    }
  },
  
  User: {
    projects: async (user, { limit, offset }, context) => {
      // ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ë§Œ ì¡°íšŒ ê°€ëŠ¥
      if (context.user.id !== user.id && !context.user.isAdmin) {
        throw new ForbiddenError('Cannot access other user projects');
      }
      
      return await context.dataSources.projectAPI.getUserProjects(
        user.id,
        { limit, offset }
      );
    },
    
    executions: async (user, args, context) => {
      if (context.user.id !== user.id && !context.user.isAdmin) {
        return [];
      }
      
      return await context.dataSources.agentAPI.getUserExecutions(user.id);
    },
    
    preferences: async (user, args, context) => {
      // ìì‹ ì˜ ì„¤ì •ë§Œ ì¡°íšŒ ê°€ëŠ¥
      if (context.user.id !== user.id) {
        return null;
      }
      
      return await context.dataSources.userAPI.getPreferences(user.id);
    }
  },
  
  // Union íƒ€ì… ë¦¬ì¡¸ë²„
  SearchResult: {
    __resolveType(obj) {
      if (obj.framework) return 'Project';
      if (obj.code) return 'Component';
      if (obj.email) return 'User';
      return null;
    }
  },
  
  // Interface ë¦¬ì¡¸ë²„
  Node: {
    __resolveType(obj) {
      return obj.__typename;
    }
  }
};

// ê´€ê³„ ìµœì í™”
export class RelationshipOptimizer {
  optimizeQuery(info: GraphQLResolveInfo): QueryPlan {
    const fields = this.parseSelectionSet(info);
    
    // í•„ìš”í•œ ê´€ê³„ íŒŒì•…
    const requiredJoins = this.identifyRequiredJoins(fields);
    
    // ì¿¼ë¦¬ ê³„íš ìƒì„±
    return {
      joins: requiredJoins,
      projections: this.getProjections(fields),
      batchKeys: this.getBatchKeys(fields)
    };
  }
  
  private parseSelectionSet(info: GraphQLResolveInfo): FieldNode[] {
    const selections = info.fieldNodes[0].selectionSet?.selections || [];
    return this.flattenSelections(selections);
  }
  
  private identifyRequiredJoins(fields: FieldNode[]): string[] {
    const joins = new Set<string>();
    
    for (const field of fields) {
      if (this.isRelationField(field)) {
        joins.add(field.name.value);
      }
    }
    
    return Array.from(joins);
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ëª¨ë“  íƒ€ì… í•„ë“œ ë¦¬ì¡¸ë²„
- [ ] DataLoader í™œìš©
- [ ] ìºì‹± ì „ëµ
- [ ] Union/Interface ë¦¬ì¡¸ë²„

#### SubTask 6.12.4: DataLoader ë° ë°°ì¹˜ ì²˜ë¦¬

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/graphql/resolvers/dataloaders.py
from aiodataloader import DataLoader
from typing import List, Dict, Any
import asyncio

class ProjectLoader(DataLoader):
    """í”„ë¡œì íŠ¸ DataLoader"""
    
    def __init__(self, project_service):
        super().__init__()
        self.project_service = project_service
    
    async def batch_load_fn(self, project_ids: List[str]) -> List[Any]:
        """ë°°ì¹˜ ë¡œë“œ í•¨ìˆ˜"""
        
        # í•œ ë²ˆì˜ ì¿¼ë¦¬ë¡œ ëª¨ë“  í”„ë¡œì íŠ¸ ì¡°íšŒ
        projects = await self.project_service.get_projects_by_ids(project_ids)
        
        # ID ìˆœì„œëŒ€ë¡œ ì •ë ¬
        project_map = {p.id: p for p in projects}
        return [project_map.get(pid) for pid in project_ids]

class ComponentLoader(DataLoader):
    """ì»´í¬ë„ŒíŠ¸ DataLoader"""
    
    def __init__(self, component_service):
        super().__init__()
        self.component_service = component_service
        self.max_batch_size = 100
    
    async def batch_load_fn(self, component_ids: List[str]) -> List[Any]:
        # ëŒ€ëŸ‰ ìš”ì²­ ë¶„í•  ì²˜ë¦¬
        if len(component_ids) > self.max_batch_size:
            return await self._load_in_chunks(component_ids)
        
        components = await self.component_service.get_components_by_ids(component_ids)
        component_map = {c.id: c for c in components}
        return [component_map.get(cid) for cid in component_ids]
    
    async def _load_in_chunks(self, ids: List[str]) -> List[Any]:
        """ì²­í¬ ë‹¨ìœ„ ë¡œë“œ"""
        
        chunks = [
            ids[i:i + self.max_batch_size]
            for i in range(0, len(ids), self.max_batch_size)
        ]
        
        results = await asyncio.gather(*[
            self.component_service.get_components_by_ids(chunk)
            for chunk in chunks
        ])
        
        # ê²°ê³¼ ë³‘í•©
        all_components = []
        for chunk_result in results:
            all_components.extend(chunk_result)
        
        component_map = {c.id: c for c in all_components}
        return [component_map.get(cid) for cid in ids]

class RelationshipLoader(DataLoader):
    """ê´€ê³„ DataLoader"""
    
    def __init__(self, relationship_service):
        super().__init__()
        self.relationship_service = relationship_service
        self.cache_enabled = True
    
    async def batch_load_fn(self, keys: List[tuple]) -> List[Any]:
        """ê´€ê³„ ë°°ì¹˜ ë¡œë“œ
        
        keys: [(parent_type, parent_id, relation_name), ...]
        """
        
        # íƒ€ì…ë³„ë¡œ ê·¸ë£¹í™”
        grouped = {}
        for parent_type, parent_id, relation in keys:
            key = (parent_type, relation)
            if key not in grouped:
                grouped[key] = []
            grouped[key].append(parent_id)
        
        # ê° ê·¸ë£¹ë³„ë¡œ ì¿¼ë¦¬
        results = {}
        for (parent_type, relation), parent_ids in grouped.items():
            relation_data = await self.relationship_service.get_relations(
                parent_type,
                parent_ids,
                relation
            )
            
            for parent_id, data in relation_data.items():
                results[(parent_type, parent_id, relation)] = data
        
        # ì›ë˜ ìˆœì„œëŒ€ë¡œ ë°˜í™˜
        return [results.get(key, None) for key in keys]

class DataLoaderRegistry:
    """DataLoader ë ˆì§€ìŠ¤íŠ¸ë¦¬"""
    
    def __init__(self, services):
        self.services = services
        self.loaders = {}
        self.initialize_loaders()
    
    def initialize_loaders(self):
        """ë¡œë” ì´ˆê¸°í™”"""
        
        self.loaders['project'] = ProjectLoader(
            self.services.project_service
        )
        
        self.loaders['component'] = ComponentLoader(
            self.services.component_service
        )
        
        self.loaders['user'] = UserLoader(
            self.services.user_service
        )
        
        self.loaders['relationship'] = RelationshipLoader(
            self.services.relationship_service
        )
        
        # ìºì‹± ë¡œë”
        self.loaders['cached_stats'] = CachedStatsLoader(
            self.services.analytics_service
        )
    
    def get_loader(self, name: str) -> DataLoader:
        """ë¡œë” ì¡°íšŒ"""
        
        if name not in self.loaders:
            raise ValueError(f"Loader {name} not found")
        
        return self.loaders[name]
    
    def create_context_loaders(self) -> Dict[str, DataLoader]:
        """ì»¨í…ìŠ¤íŠ¸ìš© ë¡œë” ìƒì„±"""
        
        # ê° ìš”ì²­ë§ˆë‹¤ ìƒˆë¡œìš´ ë¡œë” ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        return {
            'projectLoader': ProjectLoader(self.services.project_service),
            'componentLoader': ComponentLoader(self.services.component_service),
            'userLoader': UserLoader(self.services.user_service),
            'relationshipLoader': RelationshipLoader(self.services.relationship_service)
        }

class BatchProcessor:
    """ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”"""
    
    def __init__(self):
        self.batch_size = 50
        self.batch_delay = 10  # ms
    
    async def process_batch(
        self,
        items: List[Any],
        processor: callable
    ) -> List[Any]:
        """ë°°ì¹˜ ì²˜ë¦¬"""
        
        # ì§€ì—° ì‹œê°„ ëŒ€ê¸° (ë” ë§ì€ ìš”ì²­ ìˆ˜ì§‘)
        await asyncio.sleep(self.batch_delay / 1000)
        
        # ë°°ì¹˜ ì‹¤í–‰
        return await processor(items)
    
    def optimize_query(self, query: str, batch_size: int) -> str:
        """ì¿¼ë¦¬ ìµœì í™”"""
        
        # IN ì ˆ ì‚¬ìš©
        if batch_size > 1:
            return query.replace('= ?', 'IN (?)')
        
        return query
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] DataLoader êµ¬í˜„
- [ ] ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
- [ ] ìºì‹± í†µí•©
- [ ] N+1 ë¬¸ì œ í•´ê²°

---

### Task 6.13: Subscription ë° ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸

#### SubTask 6.13.1: Subscription ìŠ¤í‚¤ë§ˆ ì •ì˜

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```graphql
# backend/src/graphql/schema/subscriptions.graphql

type Subscription {
  # í”„ë¡œì íŠ¸ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
  projectUpdated(projectId: ID!): Project!
  projectDeleted(projectId: ID!): ID!
  
  # ì»´í¬ë„ŒíŠ¸ ë³€ê²½ ì•Œë¦¼
  componentChanged(projectId: ID!): ComponentChangeEvent!
  
  # ì—ì´ì „íŠ¸ ì‹¤í–‰ ìƒíƒœ
  agentExecutionUpdated(executionId: ID!): AgentExecution!
  agentExecutionLog(executionId: ID!): ExecutionLog!
  
  # ì½”ë“œ ìƒì„± ì§„í–‰ ìƒí™©
  codeGenerationProgress(projectId: ID!): GenerationProgress!
  
  # ë°°í¬ ìƒíƒœ
  deploymentStatusChanged(deploymentId: ID!): DeploymentStatus!
  
  # í˜‘ì—… ì´ë²¤íŠ¸
  collaboratorJoined(projectId: ID!): CollaboratorEvent!
  collaboratorLeft(projectId: ID!): CollaboratorEvent!
  
  # ì‹¤ì‹œê°„ ì½”ë“œ í¸ì§‘
  codeEdited(componentId: ID!): CodeEditEvent!
  cursorMoved(componentId: ID!): CursorEvent!
  
  # ì‹œìŠ¤í…œ ì•Œë¦¼
  systemNotification(userId: ID!): SystemNotification!
  
  # ì„±ëŠ¥ ë©”íŠ¸ë¦­
  performanceMetrics(projectId: ID!): PerformanceMetric!
}

# ì´ë²¤íŠ¸ íƒ€ì…ë“¤
type ComponentChangeEvent {
  type: ChangeType!
  component: Component!
  changedBy: User!
  timestamp: DateTime!
  changes: [FieldChange!]!
}

type FieldChange {
  field: String!
  oldValue: JSON
  newValue: JSON
}

enum ChangeType {
  CREATED
  UPDATED
  DELETED
  MOVED
  RENAMED
}

type GenerationProgress {
  projectId: ID!
  currentAgent: AgentType!
  progress: Float!
  message: String!
  estimatedTimeRemaining: Int
  completedAgents: [AgentType!]!
  pendingAgents: [AgentType!]!
}

type DeploymentStatus {
  deploymentId: ID!
  status: String!
  stage: String!
  progress: Float!
  logs: [String!]!
  error: String
  url: String
}

type CollaboratorEvent {
  projectId: ID!
  user: User!
  action: String!
  timestamp: DateTime!
}

type CodeEditEvent {
  componentId: ID!
  userId: ID!
  changes: [CodeChange!]!
  timestamp: DateTime!
}

type CodeChange {
  line: Int!
  column: Int!
  action: String! # insert, delete, replace
  text: String
}

type CursorEvent {
  componentId: ID!
  userId: ID!
  line: Int!
  column: Int!
  selection: Selection
}

type Selection {
  startLine: Int!
  startColumn: Int!
  endLine: Int!
  endColumn: Int!
}

type SystemNotification {
  id: ID!
  type: NotificationType!
  title: String!
  message: String!
  severity: NotificationSeverity!
  timestamp: DateTime!
  data: JSON
}

enum NotificationType {
  INFO
  WARNING
  ERROR
  SUCCESS
  AGENT_COMPLETED
  DEPLOYMENT_READY
  COLLABORATION_REQUEST
}

enum NotificationSeverity {
  LOW
  MEDIUM
  HIGH
  CRITICAL
}

type PerformanceMetric {
  projectId: ID!
  timestamp: DateTime!
  buildTime: Float
  bundleSize: Int
  memoryUsage: Float
  cpuUsage: Float
  responseTime: Float
}
```

```typescript
// backend/src/graphql/subscriptions/subscription-manager.ts
export class SubscriptionManager {
  private pubsub: PubSub;
  private connections: Map<string, Set<string>> = new Map();
  
  constructor() {
    this.pubsub = new PubSub();
    this.setupEventListeners();
  }
  
  private setupEventListeners(): void {
    // ë„ë©”ì¸ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
    eventBus.on('project:updated', (data) => {
      this.pubsub.publish(`project_${data.projectId}`, {
        projectUpdated: data.project
      });
    });
    
    eventBus.on('component:changed', (data) => {
      this.pubsub.publish(`component_changes_${data.projectId}`, {
        componentChanged: data
      });
    });
    
    eventBus.on('agent:execution:updated', (data) => {
      this.pubsub.publish(`agent_execution_${data.executionId}`, {
        agentExecutionUpdated: data.execution
      });
    });
  }
  
  async subscribe(
    topic: string,
    connectionId: string,
    filter?: any
  ): AsyncIterator {
    // ì—°ê²° ì¶”ì 
    if (!this.connections.has(connectionId)) {
      this.connections.set(connectionId, new Set());
    }
    this.connections.get(connectionId)!.add(topic);
    
    // í•„í„°ë§ëœ êµ¬ë…
    if (filter) {
      return this.pubsub.asyncIterator(topic, {
        filter: (payload) => this.applyFilter(payload, filter)
      });
    }
    
    return this.pubsub.asyncIterator(topic);
  }
  
  private applyFilter(payload: any, filter: any): boolean {
    // í•„í„° ë¡œì§ êµ¬í˜„
    for (const [key, value] of Object.entries(filter)) {
      if (payload[key] !== value) {
        return false;
      }
    }
    return true;
  }
  
  unsubscribe(connectionId: string, topic?: string): void {
    if (topic) {
      this.connections.get(connectionId)?.delete(topic);
    } else {
      this.connections.delete(connectionId);
    }
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì™„ì „í•œ Subscription ìŠ¤í‚¤ë§ˆ
- [ ] ì´ë²¤íŠ¸ íƒ€ì… ì •ì˜
- [ ] êµ¬ë… ê´€ë¦¬ ì‹œìŠ¤í…œ
- [ ] í•„í„°ë§ ì§€ì›

---

### Task 6.13: Subscription ë° ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ (ê³„ì†)

#### SubTask 6.13.2: PubSub ì‹œìŠ¤í…œ êµ¬í˜„

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/graphql/subscriptions/pubsub_system.py
import asyncio
from typing import Dict, List, Any, Set, Optional
from dataclasses import dataclass
import redis.asyncio as redis

@dataclass
class Subscription:
    """êµ¬ë… ì •ë³´"""
    id: str
    topic: str
    filter: Optional[Dict] = None
    connection_id: str = None
    created_at: datetime = field(default_factory=datetime.now)

class PubSubSystem:
    """ë°œí–‰-êµ¬ë… ì‹œìŠ¤í…œ"""
    
    def __init__(self, redis_url: Optional[str] = None):
        self.subscriptions: Dict[str, Set[Subscription]] = {}
        self.connections: Dict[str, Set[str]] = {}
        self.event_queue: asyncio.Queue = asyncio.Queue()
        
        # Redisë¥¼ ì‚¬ìš©í•œ ë¶„ì‚° PubSub
        if redis_url:
            self.redis_client = redis.from_url(redis_url)
            self.redis_pubsub = self.redis_client.pubsub()
            self.use_redis = True
        else:
            self.use_redis = False
    
    async def publish(self, topic: str, payload: Any) -> None:
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        
        event = {
            'topic': topic,
            'payload': payload,
            'timestamp': datetime.now().isoformat()
        }
        
        if self.use_redis:
            # Redisë¥¼ í†µí•œ ë¶„ì‚° ë°œí–‰
            await self.redis_client.publish(
                topic,
                json.dumps(event, default=str)
            )
        else:
            # ë¡œì»¬ ë°œí–‰
            await self.event_queue.put(event)
            await self._notify_subscribers(topic, payload)
    
    async def subscribe(
        self,
        topic: str,
        connection_id: str,
        filter_fn: Optional[callable] = None
    ) -> AsyncIterator:
        """í† í”½ êµ¬ë…"""
        
        subscription = Subscription(
            id=generate_id(),
            topic=topic,
            filter=filter_fn,
            connection_id=connection_id
        )
        
        # êµ¬ë… ë“±ë¡
        if topic not in self.subscriptions:
            self.subscriptions[topic] = set()
        self.subscriptions[topic].add(subscription)
        
        # ì—°ê²°ë³„ êµ¬ë… ì¶”ì 
        if connection_id not in self.connections:
            self.connections[connection_id] = set()
        self.connections[connection_id].add(subscription.id)
        
        # Redis êµ¬ë…
        if self.use_redis:
            await self.redis_pubsub.subscribe(topic)
        
        # ë¹„ë™ê¸° ì´í„°ë ˆì´í„° ë°˜í™˜
        return self._create_async_iterator(subscription)
    
    async def _create_async_iterator(
        self,
        subscription: Subscription
    ) -> AsyncIterator:
        """ë¹„ë™ê¸° ì´í„°ë ˆì´í„° ìƒì„±"""
        
        queue = asyncio.Queue()
        
        async def message_handler():
            while True:
                try:
                    if self.use_redis:
                        # Redisì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹ 
                        message = await self.redis_pubsub.get_message(
                            ignore_subscribe_messages=True,
                            timeout=1.0
                        )
                        
                        if message:
                            data = json.loads(message['data'])
                            if self._should_deliver(data['payload'], subscription):
                                await queue.put(data['payload'])
                    else:
                        # ë¡œì»¬ íì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹ 
                        event = await self.event_queue.get()
                        if event['topic'] == subscription.topic:
                            if self._should_deliver(event['payload'], subscription):
                                await queue.put(event['payload'])
                                
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    await self.handle_error(e, subscription)
        
        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œì‘
        task = asyncio.create_task(message_handler())
        
        try:
            while True:
                yield await queue.get()
        finally:
            task.cancel()
    
    def _should_deliver(
        self,
        payload: Any,
        subscription: Subscription
    ) -> bool:
        """ë©”ì‹œì§€ ì „ë‹¬ ì—¬ë¶€ ê²°ì •"""
        
        if not subscription.filter:
            return True
        
        return subscription.filter(payload)
    
    async def unsubscribe(
        self,
        subscription_id: str,
        connection_id: str
    ) -> None:
        """êµ¬ë… í•´ì œ"""
        
        # êµ¬ë… ì°¾ê¸°
        subscription = None
        for topic_subs in self.subscriptions.values():
            for sub in topic_subs:
                if sub.id == subscription_id:
                    subscription = sub
                    break
        
        if not subscription:
            return
        
        # êµ¬ë… ì œê±°
        self.subscriptions[subscription.topic].discard(subscription)
        
        # ì—°ê²° ì¶”ì  ì œê±°
        if connection_id in self.connections:
            self.connections[connection_id].discard(subscription_id)
        
        # Redis êµ¬ë… í•´ì œ
        if self.use_redis:
            # í•´ë‹¹ í† í”½ì˜ ë‹¤ë¥¸ êµ¬ë…ì´ ì—†ìœ¼ë©´ unsubscribe
            if not self.subscriptions.get(subscription.topic):
                await self.redis_pubsub.unsubscribe(subscription.topic)
    
    async def disconnect(self, connection_id: str) -> None:
        """ì—°ê²° ì¢…ë£Œ ì‹œ ëª¨ë“  êµ¬ë… í•´ì œ"""
        
        if connection_id not in self.connections:
            return
        
        subscription_ids = self.connections[connection_id].copy()
        
        for sub_id in subscription_ids:
            await self.unsubscribe(sub_id, connection_id)
        
        del self.connections[connection_id]

class EventAggregator:
    """ì´ë²¤íŠ¸ ì§‘ê³„ê¸°"""
    
    def __init__(self, pubsub: PubSubSystem):
        self.pubsub = pubsub
        self.buffers: Dict[str, List[Any]] = {}
        self.timers: Dict[str, asyncio.Task] = {}
        
    async def aggregate(
        self,
        topic: str,
        event: Any,
        window: float = 1.0,
        max_size: int = 100
    ) -> None:
        """ì´ë²¤íŠ¸ ì§‘ê³„ ë° ë°°ì¹˜ ë°œí–‰"""
        
        # ë²„í¼ì— ì¶”ê°€
        if topic not in self.buffers:
            self.buffers[topic] = []
        
        self.buffers[topic].append(event)
        
        # í¬ê¸° ì œí•œ í™•ì¸
        if len(self.buffers[topic]) >= max_size:
            await self.flush(topic)
            return
        
        # íƒ€ì´ë¨¸ ì„¤ì •
        if topic not in self.timers or self.timers[topic].done():
            self.timers[topic] = asyncio.create_task(
                self._flush_after_delay(topic, window)
            )
    
    async def _flush_after_delay(self, topic: str, delay: float) -> None:
        """ì§€ì—° í›„ í”ŒëŸ¬ì‹œ"""
        
        await asyncio.sleep(delay)
        await self.flush(topic)
    
    async def flush(self, topic: str) -> None:
        """ë²„í¼ í”ŒëŸ¬ì‹œ"""
        
        if topic not in self.buffers or not self.buffers[topic]:
            return
        
        # ë°°ì¹˜ ì´ë²¤íŠ¸ ë°œí–‰
        batch = self.buffers[topic].copy()
        self.buffers[topic].clear()
        
        await self.pubsub.publish(topic, {
            'type': 'batch',
            'events': batch,
            'count': len(batch)
        })
        
        # íƒ€ì´ë¨¸ ì·¨ì†Œ
        if topic in self.timers:
            self.timers[topic].cancel()
            del self.timers[topic]

class SubscriptionResolvers:
    """Subscription ë¦¬ì¡¸ë²„"""
    
    def __init__(self, pubsub: PubSubSystem):
        self.pubsub = pubsub
        self.aggregator = EventAggregator(pubsub)
    
    async def project_updated(self, parent, args, context, info):
        """í”„ë¡œì íŠ¸ ì—…ë°ì´íŠ¸ êµ¬ë…"""
        
        project_id = args['project_id']
        
        # ê¶Œí•œ í™•ì¸
        await context.authorize('project:read', project_id)
        
        # êµ¬ë…
        return self.pubsub.subscribe(
            f'project_{project_id}',
            context.connection_id
        )
    
    async def agent_execution_updated(self, parent, args, context, info):
        """ì—ì´ì „íŠ¸ ì‹¤í–‰ ìƒíƒœ êµ¬ë…"""
        
        execution_id = args['execution_id']
        
        # ì‹¤í–‰ ì •ë³´ ì¡°íšŒ ë° ê¶Œí•œ í™•ì¸
        execution = await context.services.agent_service.get_execution(execution_id)
        await context.authorize('project:read', execution.project_id)
        
        return self.pubsub.subscribe(
            f'agent_execution_{execution_id}',
            context.connection_id
        )
    
    async def code_generation_progress(self, parent, args, context, info):
        """ì½”ë“œ ìƒì„± ì§„í–‰ ìƒí™© êµ¬ë…"""
        
        project_id = args['project_id']
        await context.authorize('project:read', project_id)
        
        # ì§‘ê³„ëœ ì´ë²¤íŠ¸ êµ¬ë…
        return self.pubsub.subscribe(
            f'generation_progress_{project_id}',
            context.connection_id,
            filter_fn=lambda payload: payload.get('type') == 'progress'
        )
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] PubSub ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] Redis í†µí•© (ë¶„ì‚°)
- [ ] ì´ë²¤íŠ¸ ì§‘ê³„
- [ ] êµ¬ë… ê´€ë¦¬

#### SubTask 6.13.3: ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ í•„í„°ë§

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/graphql/subscriptions/event-filtering.ts
export interface EventFilter {
  field: string;
  operator: FilterOperator;
  value: any;
}

export class EventFilteringSystem {
  private filters: Map<string, EventFilter[]> = new Map();
  private compiledFilters: Map<string, CompiledFilter> = new Map();
  
  addFilter(subscriptionId: string, filter: EventFilter): void {
    if (!this.filters.has(subscriptionId)) {
      this.filters.set(subscriptionId, []);
    }
    
    this.filters.get(subscriptionId)!.push(filter);
    this.compileFilter(subscriptionId);
  }
  
  private compileFilter(subscriptionId: string): void {
    const filters = this.filters.get(subscriptionId);
    if (!filters) return;
    
    // í•„í„°ë¥¼ ìµœì í™”ëœ í•¨ìˆ˜ë¡œ ì»´íŒŒì¼
    const compiled = new CompiledFilter(filters);
    this.compiledFilters.set(subscriptionId, compiled);
  }
  
  shouldDeliver(subscriptionId: string, event: any): boolean {
    const compiled = this.compiledFilters.get(subscriptionId);
    if (!compiled) return true;
    
    return compiled.evaluate(event);
  }
}

class CompiledFilter {
  private filterFn: (event: any) => boolean;
  
  constructor(filters: EventFilter[]) {
    this.filterFn = this.compile(filters);
  }
  
  private compile(filters: EventFilter[]): (event: any) => boolean {
    // í•„í„°ë¥¼ JavaScript í•¨ìˆ˜ë¡œ ì»´íŒŒì¼
    const conditions: string[] = [];
    
    for (const filter of filters) {
      const condition = this.compileCondition(filter);
      conditions.push(condition);
    }
    
    const fnBody = `return ${conditions.join(' && ')};`;
    return new Function('event', fnBody) as (event: any) => boolean;
  }
  
  private compileCondition(filter: EventFilter): string {
    const field = `event.${filter.field}`;
    const value = JSON.stringify(filter.value);
    
    switch (filter.operator) {
      case FilterOperator.EQUALS:
        return `${field} === ${value}`;
      case FilterOperator.NOT_EQUALS:
        return `${field} !== ${value}`;
      case FilterOperator.GREATER_THAN:
        return `${field} > ${value}`;
      case FilterOperator.LESS_THAN:
        return `${field} < ${value}`;
      case FilterOperator.IN:
        return `${value}.includes(${field})`;
      case FilterOperator.CONTAINS:
        return `${field}.includes(${value})`;
      default:
        return 'true';
    }
  }
  
  evaluate(event: any): boolean {
    try {
      return this.filterFn(event);
    } catch (error) {
      console.error('Filter evaluation error:', error);
      return false;
    }
  }
}

// ê¶Œí•œ ê¸°ë°˜ í•„í„°ë§
export class PermissionBasedFilter {
  constructor(private authService: AuthService) {}
  
  async createFilter(userId: string, resourceType: string): Promise<EventFilter[]> {
    const permissions = await this.authService.getUserPermissions(userId);
    const filters: EventFilter[] = [];
    
    // ë¦¬ì†ŒìŠ¤ íƒ€ì…ë³„ í•„í„° ìƒì„±
    switch (resourceType) {
      case 'Project':
        // ì‚¬ìš©ìê°€ ì ‘ê·¼ ê°€ëŠ¥í•œ í”„ë¡œì íŠ¸ë§Œ
        const projectIds = await this.authService.getAccessibleProjects(userId);
        filters.push({
          field: 'projectId',
          operator: FilterOperator.IN,
          value: projectIds
        });
        break;
        
      case 'Component':
        // ì»´í¬ë„ŒíŠ¸ëŠ” í”„ë¡œì íŠ¸ ê¶Œí•œì„ ìƒì†
        const componentProjectIds = await this.authService.getAccessibleProjects(userId);
        filters.push({
          field: 'project.id',
          operator: FilterOperator.IN,
          value: componentProjectIds
        });
        break;
    }
    
    return filters;
  }
}

// ì´ë²¤íŠ¸ ë³€í™˜ ë° í•„í„°ë§ íŒŒì´í”„ë¼ì¸
export class EventPipeline {
  private transformers: Array<(event: any) => any> = [];
  private filters: Array<(event: any) => boolean> = [];
  
  addTransformer(transformer: (event: any) => any): void {
    this.transformers.push(transformer);
  }
  
  addFilter(filter: (event: any) => boolean): void {
    this.filters.push(filter);
  }
  
  async process(event: any): Promise<any | null> {
    // ë³€í™˜ ì ìš©
    let transformed = event;
    for (const transformer of this.transformers) {
      transformed = await transformer(transformed);
    }
    
    // í•„í„° ì ìš©
    for (const filter of this.filters) {
      if (!await filter(transformed)) {
        return null; // í•„í„°ë§ë¨
      }
    }
    
    return transformed;
  }
}

// ì´ë²¤íŠ¸ ìƒ˜í”Œë§
export class EventSampler {
  private sampleRates: Map<string, number> = new Map();
  private counters: Map<string, number> = new Map();
  
  setSampleRate(eventType: string, rate: number): void {
    this.sampleRates.set(eventType, rate);
  }
  
  shouldSample(eventType: string): boolean {
    const rate = this.sampleRates.get(eventType);
    if (!rate || rate >= 1) return true;
    if (rate <= 0) return false;
    
    // ì¹´ìš´í„° ê¸°ë°˜ ìƒ˜í”Œë§
    const counter = this.counters.get(eventType) || 0;
    this.counters.set(eventType, counter + 1);
    
    return (counter % Math.floor(1 / rate)) === 0;
  }
}

// ì´ë²¤íŠ¸ ìœˆë„ìš° í•„í„°
export class WindowFilter {
  private windows: Map<string, TimeWindow> = new Map();
  
  createWindow(
    id: string,
    duration: number,
    maxEvents: number
  ): void {
    this.windows.set(id, new TimeWindow(duration, maxEvents));
  }
  
  shouldAccept(windowId: string, event: any): boolean {
    const window = this.windows.get(windowId);
    if (!window) return true;
    
    return window.accept(event);
  }
}

class TimeWindow {
  private events: Array<{ timestamp: number; event: any }> = [];
  
  constructor(
    private duration: number, // seconds
    private maxEvents: number
  ) {}
  
  accept(event: any): boolean {
    const now = Date.now();
    
    // ì˜¤ë˜ëœ ì´ë²¤íŠ¸ ì œê±°
    this.events = this.events.filter(
      e => (now - e.timestamp) < this.duration * 1000
    );
    
    // ìµœëŒ€ ì´ë²¤íŠ¸ ìˆ˜ í™•ì¸
    if (this.events.length >= this.maxEvents) {
      return false;
    }
    
    this.events.push({ timestamp: now, event });
    return true;
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì´ë²¤íŠ¸ í•„í„°ë§ ì‹œìŠ¤í…œ
- [ ] ê¶Œí•œ ê¸°ë°˜ í•„í„°
- [ ] ìƒ˜í”Œë§ ì§€ì›
- [ ] ìœˆë„ìš° ê¸°ë°˜ í•„í„°

#### SubTask 6.13.4: ì—°ê²° ê´€ë¦¬ ë° í™•ì¥ì„±

**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/graphql/subscriptions/connection_manager.py
from typing import Dict, Set, Optional
import asyncio
from dataclasses import dataclass

@dataclass
class ConnectionInfo:
    """ì—°ê²° ì •ë³´"""
    id: str
    user_id: Optional[str]
    ip_address: str
    user_agent: str
    connected_at: datetime
    last_ping: datetime
    subscriptions: Set[str] = field(default_factory=set)
    metadata: Dict = field(default_factory=dict)

class ConnectionManager:
    """WebSocket ì—°ê²° ê´€ë¦¬"""
    
    def __init__(self):
        self.connections: Dict[str, ConnectionInfo] = {}
        self.user_connections: Dict[str, Set[str]] = {}
        self.health_checker = ConnectionHealthChecker()
        self.rate_limiter = ConnectionRateLimiter()
        
    async def add_connection(
        self,
        connection_id: str,
        websocket,
        request_info: Dict
    ) -> ConnectionInfo:
        """ì—°ê²° ì¶”ê°€"""
        
        # Rate limiting
        if not await self.rate_limiter.check_limit(request_info['ip']):
            raise RateLimitExceededError("Too many connections")
        
        # ì—°ê²° ì •ë³´ ìƒì„±
        conn_info = ConnectionInfo(
            id=connection_id,
            user_id=request_info.get('user_id'),
            ip_address=request_info['ip'],
            user_agent=request_info.get('user_agent', ''),
            connected_at=datetime.now(),
            last_ping=datetime.now()
        )
        
        # ì €ì¥
        self.connections[connection_id] = conn_info
        
        # ì‚¬ìš©ìë³„ ì—°ê²° ì¶”ì 
        if conn_info.user_id:
            if conn_info.user_id not in self.user_connections:
                self.user_connections[conn_info.user_id] = set()
            self.user_connections[conn_info.user_id].add(connection_id)
        
        # Health check ì‹œì‘
        asyncio.create_task(
            self.health_checker.start_monitoring(connection_id, websocket)
        )
        
        return conn_info
    
    async def remove_connection(self, connection_id: str) -> None:
        """ì—°ê²° ì œê±°"""
        
        if connection_id not in self.connections:
            return
        
        conn_info = self.connections[connection_id]
        
        # ì‚¬ìš©ì ì—°ê²° ì¶”ì  ì œê±°
        if conn_info.user_id:
            self.user_connections[conn_info.user_id].discard(connection_id)
            if not self.user_connections[conn_info.user_id]:
                del self.user_connections[conn_info.user_id]
        
        # Health check ì¤‘ì§€
        await self.health_checker.stop_monitoring(connection_id)
        
        # ì—°ê²° ì •ë³´ ì œê±°
        del self.connections[connection_id]
        
        # ì •ë¦¬ ì´ë²¤íŠ¸ ë°œìƒ
        await self.emit_disconnection_event(conn_info)
    
    def get_connection(self, connection_id: str) -> Optional[ConnectionInfo]:
        """ì—°ê²° ì •ë³´ ì¡°íšŒ"""
        return self.connections.get(connection_id)
    
    def get_user_connections(self, user_id: str) -> List[ConnectionInfo]:
        """ì‚¬ìš©ìì˜ ëª¨ë“  ì—°ê²° ì¡°íšŒ"""
        
        connection_ids = self.user_connections.get(user_id, set())
        return [
            self.connections[cid]
            for cid in connection_ids
            if cid in self.connections
        ]
    
    async def broadcast_to_user(
        self,
        user_id: str,
        message: Any
    ) -> None:
        """ì‚¬ìš©ìì˜ ëª¨ë“  ì—°ê²°ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        
        connections = self.get_user_connections(user_id)
        
        await asyncio.gather(*[
            self.send_to_connection(conn.id, message)
            for conn in connections
        ])
    
    def get_statistics(self) -> Dict:
        """ì—°ê²° í†µê³„"""
        
        return {
            'total_connections': len(self.connections),
            'unique_users': len(self.user_connections),
            'connections_by_user': {
                user_id: len(conns)
                for user_id, conns in self.user_connections.items()
            },
            'average_connection_duration': self.calculate_avg_duration(),
            'peak_connections': self.get_peak_connections()
        }

class ConnectionHealthChecker:
    """ì—°ê²° ìƒíƒœ ì²´í¬"""
    
    def __init__(self):
        self.ping_interval = 30  # seconds
        self.pong_timeout = 10   # seconds
        self.monitors: Dict[str, asyncio.Task] = {}
    
    async def start_monitoring(
        self,
        connection_id: str,
        websocket
    ) -> None:
        """ì—°ê²° ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        
        async def monitor():
            while True:
                try:
                    # Ping ì „ì†¡
                    pong_waiter = await websocket.ping()
                    
                    # Pong ëŒ€ê¸°
                    await asyncio.wait_for(
                        pong_waiter,
                        timeout=self.pong_timeout
                    )
                    
                    # ìƒíƒœ ì—…ë°ì´íŠ¸
                    await self.update_health_status(connection_id, True)
                    
                    await asyncio.sleep(self.ping_interval)
                    
                except asyncio.TimeoutError:
                    # Pong íƒ€ì„ì•„ì›ƒ
                    await self.handle_unhealthy_connection(connection_id)
                    break
                    
                except Exception as e:
                    # ì—°ê²° ì˜¤ë¥˜
                    await self.handle_connection_error(connection_id, e)
                    break
        
        self.monitors[connection_id] = asyncio.create_task(monitor())
    
    async def stop_monitoring(self, connection_id: str) -> None:
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        
        if connection_id in self.monitors:
            self.monitors[connection_id].cancel()
            del self.monitors[connection_id]

class ScalableSubscriptionManager:
    """í™•ì¥ ê°€ëŠ¥í•œ êµ¬ë… ê´€ë¦¬"""
    
    def __init__(self, redis_cluster: RedisCluster):
        self.redis = redis_cluster
        self.local_cache = TTLCache(maxsize=10000, ttl=60)
        self.shard_manager = ShardManager()
    
    async def distribute_subscription(
        self,
        subscription_id: str,
        topic: str,
        connection_id: str
    ) -> str:
        """êµ¬ë… ë¶„ì‚°"""
        
        # ìƒ¤ë“œ ê²°ì •
        shard = self.shard_manager.get_shard(topic)
        
        # Redisì— êµ¬ë… ì •ë³´ ì €ì¥
        key = f"subscription:{shard}:{subscription_id}"
        value = {
            'topic': topic,
            'connection_id': connection_id,
            'shard': shard,
            'created_at': datetime.now().isoformat()
        }
        
        await self.redis.hset(key, mapping=value)
        
        # ë¡œì»¬ ìºì‹œ ì—…ë°ì´íŠ¸
        self.local_cache[subscription_id] = value
        
        # ìƒ¤ë“œë³„ êµ¬ë… ì¹´ìš´íŠ¸ ì¦ê°€
        await self.redis.hincrby(f"shard:stats:{shard}", "subscriptions", 1)
        
        return shard
    
    async def rebalance_shards(self) -> None:
        """ìƒ¤ë“œ ì¬ê· í˜•"""
        
        # ê° ìƒ¤ë“œì˜ ë¶€í•˜ ì¸¡ì •
        shard_loads = await self.measure_shard_loads()
        
        # ë¶ˆê· í˜• ê°ì§€
        if self.is_imbalanced(shard_loads):
            # ì¬ê· í˜• ê³„íš ìˆ˜ë¦½
            plan = self.create_rebalancing_plan(shard_loads)
            
            # êµ¬ë… ë§ˆì´ê·¸ë ˆì´ì…˜
            await self.migrate_subscriptions(plan)
            
            # ìƒ¤ë“œ ë§µ ì—…ë°ì´íŠ¸
            await self.shard_manager.update_shard_map(plan)

class ConnectionRateLimiter:
    """ì—°ê²° ì†ë„ ì œí•œ"""
    
    def __init__(self):
        self.limits = {
            'connections_per_ip': 10,
            'connections_per_user': 5,
            'new_connections_per_minute': 20
        }
        self.counters = {}
    
    async def check_limit(self, identifier: str) -> bool:
        """ì œí•œ í™•ì¸"""
        
        current = self.counters.get(identifier, 0)
        
        if current >= self.limits['connections_per_ip']:
            return False
        
        self.counters[identifier] = current + 1
        
        # ì‹œê°„ ê¸°ë°˜ ì œí•œ
        return await self.check_time_based_limit(identifier)
    
    async def check_time_based_limit(self, identifier: str) -> bool:
        """ì‹œê°„ ê¸°ë°˜ ì œí•œ í™•ì¸"""
        
        key = f"rate_limit:{identifier}:{int(time.time() / 60)}"
        
        count = await redis_client.incr(key)
        
        if count == 1:
            await redis_client.expire(key, 60)
        
        return count <= self.limits['new_connections_per_minute']

class AutoScalingManager:
    """ìë™ ìŠ¤ì¼€ì¼ë§ ê´€ë¦¬"""
    
    def __init__(self):
        self.metrics = MetricsCollector()
        self.scaler = K8sScaler()
        self.thresholds = {
            'cpu_high': 80,
            'cpu_low': 20,
            'memory_high': 85,
            'memory_low': 30,
            'connections_per_pod': 1000
        }
    
    async def monitor_and_scale(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ë° ìŠ¤ì¼€ì¼ë§"""
        
        while True:
            metrics = await self.metrics.collect()
            
            # ìŠ¤ì¼€ì¼ ì•„ì›ƒ í•„ìš” ì—¬ë¶€
            if self.should_scale_out(metrics):
                await self.scale_out()
            
            # ìŠ¤ì¼€ì¼ ì¸ í•„ìš” ì—¬ë¶€
            elif self.should_scale_in(metrics):
                await self.scale_in()
            
            await asyncio.sleep(30)
    
    def should_scale_out(self, metrics: Dict) -> bool:
        """ìŠ¤ì¼€ì¼ ì•„ì›ƒ í•„ìš” ì—¬ë¶€"""
        
        return (
            metrics['cpu'] > self.thresholds['cpu_high'] or
            metrics['memory'] > self.thresholds['memory_high'] or
            metrics['connections_per_pod'] > self.thresholds['connections_per_pod']
        )
    
    async def scale_out(self) -> None:
        """ìŠ¤ì¼€ì¼ ì•„ì›ƒ"""
        
        current_replicas = await self.scaler.get_replicas()
        new_replicas = min(current_replicas + 1, 10)  # ìµœëŒ€ 10ê°œ
        
        await self.scaler.set_replicas(new_replicas)
        
        # ì´ë²¤íŠ¸ ë¡œê¹…
        await self.log_scaling_event('scale_out', current_replicas, new_replicas)
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì—°ê²° ê´€ë¦¬ ì‹œìŠ¤í…œ
- [ ] Health Check
- [ ] ë¶„ì‚° êµ¬ë… ê´€ë¦¬
- [ ] ìë™ ìŠ¤ì¼€ì¼ë§

---

### Task 6.14: WebSocket ì„œë²„ êµ¬í˜„

#### SubTask 6.14.1: WebSocket ì„œë²„ ì´ˆê¸°í™”

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/websocket/server.ts
import { Server } from 'ws';
import { createServer } from 'http';
import { parse } from 'url';

export class WebSocketServer {
  private wss: Server;
  private httpServer: any;
  private connections: Map<string, WebSocket> = new Map();
  private handlers: Map<string, MessageHandler> = new Map();
  
  constructor(private config: WebSocketConfig) {
    this.initialize();
  }
  
  private initialize(): void {
    // HTTP ì„œë²„ ìƒì„±
    this.httpServer = createServer();
    
    // WebSocket ì„œë²„ ìƒì„±
    this.wss = new Server({
      server: this.httpServer,
      path: this.config.path || '/ws',
      maxPayload: this.config.maxPayload || 100 * 1024 * 1024, // 100MB
      perMessageDeflate: {
        zlibDeflateOptions: {
          chunkSize: 1024,
          memLevel: 7,
          level: 3
        },
        zlibInflateOptions: {
          chunkSize: 10 * 1024
        },
        clientNoContextTakeover: true,
        serverNoContextTakeover: true,
        serverMaxWindowBits: 10,
        concurrencyLimit: 10,
        threshold: 1024
      }
    });
    
    this.setupEventHandlers();
    this.registerDefaultHandlers();
  }
  
  private setupEventHandlers(): void {
    // ì—°ê²° ì´ë²¤íŠ¸
    this.wss.on('connection', async (ws, request) => {
      const connectionId = generateConnectionId();
      const clientInfo = this.extractClientInfo(request);
      
      try {
        // ì—°ê²° ì²˜ë¦¬
        await this.handleConnection(ws, connectionId, clientInfo);
      } catch (error) {
        console.error('Connection handling error:', error);
        ws.close(1002, 'Connection error');
      }
    });
    
    // ì„œë²„ ì—ëŸ¬
    this.wss.on('error', (error) => {
      console.error('WebSocket server error:', error);
      this.handleServerError(error);
    });
    
    // ì„œë²„ ì¢…ë£Œ
    this.wss.on('close', () => {
      console.log('WebSocket server closed');
      this.cleanup();
    });
  }
  
  private async handleConnection(
    ws: WebSocket,
    connectionId: string,
    clientInfo: ClientInfo
  ): Promise<void> {
    console.log(`New connection: ${connectionId}`);
    
    // ì—°ê²° ì €ì¥
    this.connections.set(connectionId, ws);
    
    // ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    const context = new ConnectionContext(connectionId, clientInfo);
    ws['context'] = context;
    
    // í™˜ì˜ ë©”ì‹œì§€
    await this.sendMessage(ws, {
      type: 'connection',
      payload: {
        connectionId,
        version: this.config.version,
        features: this.config.features
      }
    });
    
    // ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ ì„¤ì •
    ws.on('message', async (data) => {
      await this.handleMessage(ws, data, context);
    });
    
    // ì—ëŸ¬ í•¸ë“¤ëŸ¬
    ws.on('error', (error) => {
      console.error(`Connection ${connectionId} error:`, error);
      this.handleConnectionError(connectionId, error);
    });
    
    // ì—°ê²° ì¢…ë£Œ í•¸ë“¤ëŸ¬
    ws.on('close', (code, reason) => {
      console.log(`Connection ${connectionId} closed: ${code} ${reason}`);
      this.handleDisconnection(connectionId, code, reason);
    });
    
    // Ping/Pong ì„¤ì •
    this.setupHeartbeat(ws, connectionId);
  }
  
  private setupHeartbeat(ws: WebSocket, connectionId: string): void {
    const interval = this.config.heartbeatInterval || 30000;
    let isAlive = true;
    
    ws.on('pong', () => {
      isAlive = true;
    });
    
    const heartbeat = setInterval(() => {
      if (!isAlive) {
        // ì—°ê²° ì¢…ë£Œ
        this.terminateConnection(connectionId);
        return;
      }
      
      isAlive = false;
      ws.ping();
    }, interval);
    
    ws['heartbeat'] = heartbeat;
  }
  
  private extractClientInfo(request: any): ClientInfo {
    const url = parse(request.url || '', true);
    
    return {
      ip: request.socket.remoteAddress,
      userAgent: request.headers['user-agent'],
      origin: request.headers['origin'],
      query: url.query,
      headers: request.headers
    };
  }
  
  async start(port: number = 8080): Promise<void> {
    return new Promise((resolve, reject) => {
      this.httpServer.listen(port, () => {
        console.log(`WebSocket server listening on port ${port}`);
        resolve();
      });
      
      this.httpServer.on('error', reject);
    });
  }
  
  async stop(): Promise<void> {
    // ëª¨ë“  ì—°ê²° ì¢…ë£Œ
    for (const [connectionId, ws] of this.connections) {
      ws.close(1001, 'Server shutting down');
    }
    
    // ì„œë²„ ì¢…ë£Œ
    return new Promise((resolve) => {
      this.wss.close(() => {
        this.httpServer.close(() => {
          resolve();
        });
      });
    });
  }
}

// WebSocket ì„¤ì •
export interface WebSocketConfig {
  path?: string;
  maxPayload?: number;
  heartbeatInterval?: number;
  version: string;
  features: string[];
  ssl?: {
    cert: string;
    key: string;
  };
  cors?: {
    origin: string | string[];
    credentials: boolean;
  };
}

// ì—°ê²° ì»¨í…ìŠ¤íŠ¸
export class ConnectionContext {
  public authenticated: boolean = false;
  public user?: User;
  public subscriptions: Set<string> = new Set();
  public metadata: Map<string, any> = new Map();
  
  constructor(
    public connectionId: string,
    public clientInfo: ClientInfo
  ) {
    this.metadata.set('connectedAt', new Date());
  }
  
  authenticate(user: User): void {
    this.authenticated = true;
    this.user = user;
    this.metadata.set('authenticatedAt', new Date());
  }
  
  addSubscription(subscriptionId: string): void {
    this.subscriptions.add(subscriptionId);
  }
  
  removeSubscription(subscriptionId: string): void {
    this.subscriptions.delete(subscriptionId);
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] WebSocket ì„œë²„ ì„¤ì •
- [ ] ì—°ê²° ì²˜ë¦¬
- [ ] Heartbeat ë©”ì»¤ë‹ˆì¦˜
- [ ] ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬

#### SubTask 6.14.2: ì—°ê²° í•¸ë“¤ë§ ë° ì¸ì¦

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/websocket/connection_handler.py
import jwt
from typing import Optional, Dict, Any
import asyncio

class ConnectionHandler:
    """WebSocket ì—°ê²° í•¸ë“¤ëŸ¬"""
    
    def __init__(self, auth_service, connection_manager):
        self.auth_service = auth_service
        self.connection_manager = connection_manager
        self.pending_auth: Dict[str, asyncio.Task] = {}
    
    async def handle_new_connection(
        self,
        websocket,
        connection_id: str,
        request_info: Dict
    ) -> Optional[ConnectionContext]:
        """ìƒˆ ì—°ê²° ì²˜ë¦¬"""
        
        try:
            # 1. ì´ˆê¸° ê²€ì¦
            if not await self.validate_origin(request_info):
                await websocket.close(1008, "Invalid origin")
                return None
            
            # 2. Rate limiting ì²´í¬
            if not await self.check_rate_limit(request_info['ip']):
                await websocket.close(1008, "Rate limit exceeded")
                return None
            
            # 3. ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = ConnectionContext(
                connection_id=connection_id,
                websocket=websocket,
                ip_address=request_info['ip'],
                user_agent=request_info.get('user_agent')
            )
            
            # 4. ì¸ì¦ ì²˜ë¦¬
            auth_token = self.extract_auth_token(request_info)
            if auth_token:
                # ì¦‰ì‹œ ì¸ì¦
                auth_result = await self.authenticate_connection(
                    context,
                    auth_token
                )
                if not auth_result:
                    await websocket.close(1008, "Authentication failed")
                    return None
            else:
                # ì¸ì¦ ëŒ€ê¸° (grace period)
                self.schedule_auth_timeout(context)
            
            # 5. ì—°ê²° ë“±ë¡
            await self.connection_manager.add_connection(
                connection_id,
                websocket,
                context
            )
            
            # 6. í™˜ì˜ ë©”ì‹œì§€
            await self.send_welcome_message(context)
            
            return context
            
        except Exception as e:
            await websocket.close(1011, "Server error")
            raise e
    
    async def authenticate_connection(
        self,
        context: ConnectionContext,
        token: str
    ) -> bool:
        """ì—°ê²° ì¸ì¦"""
        
        try:
            # JWT í† í° ê²€ì¦
            payload = jwt.decode(
                token,
                self.auth_service.secret_key,
                algorithms=['HS256']
            )
            
            # ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
            user = await self.auth_service.get_user(payload['user_id'])
            if not user:
                return False
            
            # ê¶Œí•œ í™•ì¸
            permissions = await self.auth_service.get_permissions(user.id)
            
            # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            context.authenticate(user, permissions)
            
            # ì¸ì¦ ì„±ê³µ ë©”ì‹œì§€
            await context.send({
                'type': 'auth_success',
                'payload': {
                    'user_id': user.id,
                    'permissions': permissions
                }
            })
            
            return True
            
        except jwt.ExpiredSignatureError:
            await context.send({
                'type': 'auth_error',
                'payload': {'error': 'Token expired'}
            })
            return False
            
        except jwt.InvalidTokenError:
            await context.send({
                'type': 'auth_error',
                'payload': {'error': 'Invalid token'}
            })
            return False
    
    def extract_auth_token(self, request_info: Dict) -> Optional[str]:
        """ì¸ì¦ í† í° ì¶”ì¶œ"""
        
        # 1. Query parameter
        if 'token' in request_info.get('query', {}):
            return request_info['query']['token']
        
        # 2. Cookie
        cookies = request_info.get('cookies', {})
        if 'auth_token' in cookies:
            return cookies['auth_token']
        
        # 3. Authorization header
        auth_header = request_info.get('headers', {}).get('authorization')
        if auth_header and auth_header.startswith('Bearer '):
            return auth_header[7:]
        
        return None
    
    def schedule_auth_timeout(self, context: ConnectionContext):
        """ì¸ì¦ íƒ€ì„ì•„ì›ƒ ìŠ¤ì¼€ì¤„ë§"""
        
        async def auth_timeout():
            await asyncio.sleep(30)  # 30ì´ˆ ëŒ€ê¸°
            
            if not context.authenticated:
                await context.send({
                    'type': 'auth_required',
                    'payload': {
                        'message': 'Authentication required',
                        'timeout': 30
                    }
                })
                
                await asyncio.sleep(10)  # ì¶”ê°€ 10ì´ˆ ëŒ€ê¸°
                
                if not context.authenticated:
                    await context.websocket.close(
                        1008,
                        "Authentication timeout"
                    )
        
        task = asyncio.create_task(auth_timeout())
        self.pending_auth[context.connection_id] = task
    
    async def handle_auth_message(
        self,
        context: ConnectionContext,
        message: Dict
    ):
        """ì¸ì¦ ë©”ì‹œì§€ ì²˜ë¦¬"""
        
        token = message.get('token')
        if not token:
            await context.send({
                'type': 'auth_error',
                'payload': {'error': 'Token required'}
            })
            return
        
        # ì¸ì¦ ì‹œë„
        success = await self.authenticate_connection(context, token)
        
        if success:
            # íƒ€ì„ì•„ì›ƒ íƒœìŠ¤í¬ ì·¨ì†Œ
            if context.connection_id in self.pending_auth:
                self.pending_auth[context.connection_id].cancel()
                del self.pending_auth[context.connection_id]
        else:
            # ì¸ì¦ ì‹¤íŒ¨ ì¹´ìš´í„°
            context.auth_attempts += 1
            
            if context.auth_attempts >= 3:
                await context.websocket.close(
                    1008,
                    "Too many authentication attempts"
                )

class PermissionChecker:
    """ê¶Œí•œ ì²´í¬"""
    
    def __init__(self):
        self.permission_cache = TTLCache(maxsize=1000, ttl=300)
    
    async def check_permission(
        self,
        context: ConnectionContext,
        resource: str,
        action: str
    ) -> bool:
        """ê¶Œí•œ í™•ì¸"""
        
        if not context.authenticated:
            return False
        
        # ìºì‹œ í™•ì¸
        cache_key = f"{context.user.id}:{resource}:{action}"
        if cache_key in self.permission_cache:
            return self.permission_cache[cache_key]
        
        # ê¶Œí•œ ì²´í¬
        has_permission = await self.evaluate_permission(
            context.permissions,
            resource,
            action
        )
        
        # ìºì‹œ ì €ì¥
        self.permission_cache[cache_key] = has_permission
        
        return has_permission
    
    async def evaluate_permission(
        self,
        permissions: List[str],
        resource: str,
        action: str
    ) -> bool:
        """ê¶Œí•œ í‰ê°€"""
        
        required = f"{resource}:{action}"
        
        # ì§ì ‘ ê¶Œí•œ
        if required in permissions:
            return True
        
        # ì™€ì¼ë“œì¹´ë“œ ê¶Œí•œ
        if f"{resource}:*" in permissions:
            return True
        
        if "*:*" in permissions:  # ê´€ë¦¬ì
            return True
        
        return False

class SecureConnectionUpgrade:
    """ë³´ì•ˆ ì—°ê²° ì—…ê·¸ë ˆì´ë“œ"""
    
    async def upgrade_to_secure(
        self,
        context: ConnectionContext
    ) -> bool:
        """TLS ì—…ê·¸ë ˆì´ë“œ"""
        
        # TLS í•¸ë“œì…°ì´í¬
        await context.send({
            'type': 'security_upgrade',
            'payload': {
                'method': 'TLS',
                'version': '1.3'
            }
        })
        
        # í´ë¼ì´ì–¸íŠ¸ ì‘ë‹µ ëŒ€ê¸°
        response = await context.receive()
        
        if response.get('type') == 'security_upgrade_accept':
            # TLS ì—°ê²° ì„¤ì •
            context.secure = True
            context.tls_version = '1.3'
            return True
        
        return False
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì—°ê²° ì¸ì¦ ì‹œìŠ¤í…œ
- [ ] JWT í† í° ì²˜ë¦¬
- [ ] ê¶Œí•œ ê´€ë¦¬
- [ ] ë³´ì•ˆ ì—…ê·¸ë ˆì´ë“œ

#### SubTask 6.14.3: ë©”ì‹œì§€ í”„ë¡œí† ì½œ ì •ì˜

**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```typescript
// backend/src/websocket/protocol.ts
export interface Message {
  id: string;
  type: MessageType;
  payload: any;
  timestamp: number;
  metadata?: MessageMetadata;
}

export interface MessageMetadata {
  correlationId?: string;
  replyTo?: string;
  ttl?: number;
  priority?: number;
  compression?: string;
}

export enum MessageType {
  // ì—°ê²° ê´€ë¦¬
  CONNECTION = 'connection',
  PING = 'ping',
  PONG = 'pong',
  CLOSE = 'close',
  
  // ì¸ì¦
  AUTH_REQUEST = 'auth_request',
  AUTH_RESPONSE = 'auth_response',
  AUTH_ERROR = 'auth_error',
  
  // êµ¬ë…
  SUBSCRIBE = 'subscribe',
  UNSUBSCRIBE = 'unsubscribe',
  SUBSCRIPTION_DATA = 'subscription_data',
  
  // RPC
  RPC_REQUEST = 'rpc_request',
  RPC_RESPONSE = 'rpc_response',
  RPC_ERROR = 'rpc_error',
  
  // ì´ë²¤íŠ¸
  EVENT = 'event',
  BROADCAST = 'broadcast',
  
  // ì—ëŸ¬
  ERROR = 'error'
}

export class MessageProtocol {
  private version: string = '1.0';
  private encoders: Map<string, MessageEncoder> = new Map();
  private decoders: Map<string, MessageDecoder> = new Map();
  
  constructor() {
    this.registerEncoders();
    this.registerDecoders();
  }
  
  private registerEncoders(): void {
    // JSON ì¸ì½”ë”
    this.encoders.set('json', {
      encode: (message: Message) => JSON.stringify(message),
      contentType: 'application/json'
    });
    
    // MessagePack ì¸ì½”ë”
    this.encoders.set('msgpack', {
      encode: (message: Message) => msgpack.encode(message),
      contentType: 'application/msgpack'
    });
    
    // Protocol Buffers ì¸ì½”ë”
    this.encoders.set('protobuf', {
      encode: (message: Message) => this.encodeProtobuf(message),
      contentType: 'application/protobuf'
    });
  }
  
  encode(
    message: Message,
    format: string = 'json'
  ): Buffer | string {
    const encoder = this.encoders.get(format);
    if (!encoder) {
      throw new Error(`Unknown encoding format: ${format}`);
    }
    
    // ë©”ì‹œì§€ ìœ íš¨ì„± ê²€ì¦
    this.validateMessage(message);
    
    // ë©”íƒ€ë°ì´í„° ì¶”ê°€
    message.timestamp = message.timestamp || Date.now();
    message.id = message.id || generateMessageId();
    
    return encoder.encode(message);
  }
  
  decode(data: Buffer | string, format: string = 'json'): Message {
    const decoder = this.decoders.get(format);
    if (!decoder) {
      throw new Error(`Unknown decoding format: ${format}`);
    }
    
    const message = decoder.decode(data);
    
    // ë©”ì‹œì§€ ìœ íš¨ì„± ê²€ì¦
    this.validateMessage(message);
    
    return message;
  }
  
  private validateMessage(message: Message): void {
    if (!message.type) {
      throw new Error('Message type is required');
    }
    
    if (!message.id) {
      message.id = generateMessageId();
    }
    
    // íƒ€ì…ë³„ í˜ì´ë¡œë“œ ê²€ì¦
    this.validatePayload(message.type, message.payload);
  }
  
  private validatePayload(type: MessageType, payload: any): void {
    const schema = this.getPayloadSchema(type);
    if (!schema) return;
    
    const validator = new Ajv();
    const valid = validator.validate(schema, payload);
    
    if (!valid) {
      throw new Error(`Invalid payload: ${validator.errors}`);
    }
  }
}

// ë©”ì‹œì§€ ë¹Œë”
export class MessageBuilder {
  private message: Partial<Message> = {};
  
  static create(type: MessageType): MessageBuilder {
    const builder = new MessageBuilder();
    builder.message.type = type;
    return builder;
  }
  
  withPayload(payload: any): MessageBuilder {
    this.message.payload = payload;
    return this;
  }
  
  withCorrelationId(id: string): MessageBuilder {
    if (!this.message.metadata) {
      this.message.metadata = {};
    }
    this.message.metadata.correlationId = id;
    return this;
  }
  
  withReplyTo(replyTo: string): MessageBuilder {
    if (!this.message.metadata) {
      this.message.metadata = {};
    }
    this.message.metadata.replyTo = replyTo;
    return this;
  }
  
  withPriority(priority: number): MessageBuilder {
    if (!this.message.metadata) {
      this.message.metadata = {};
    }
    this.message.metadata.priority = priority;
    return this;
  }
  
  build(): Message {
    return {
      id: generateMessageId(),
      type: this.message.type!,
      payload: this.message.payload,
      timestamp: Date.now(),
      metadata: this.message.metadata
    } as Message;
  }
}

// ë©”ì‹œì§€ ë¼ìš°í„°
export class MessageRouter {
  private routes: Map<MessageType, MessageHandler[]> = new Map();
  private middleware: MessageMiddleware[] = [];
  
  use(middleware: MessageMiddleware): void {
    this.middleware.push(middleware);
  }
  
  on(type: MessageType, handler: MessageHandler): void {
    if (!this.routes.has(type)) {
      this.routes.set(type, []);
    }
    this.routes.get(type)!.push(handler);
  }
  
  async route(
    message: Message,
    context: ConnectionContext
  ): Promise<void> {
    // ë¯¸ë“¤ì›¨ì–´ ì‹¤í–‰
    for (const mw of this.middleware) {
      const shouldContinue = await mw(message, context);
      if (!shouldContinue) return;
    }
    
    // í•¸ë“¤ëŸ¬ ì‹¤í–‰
    const handlers = this.routes.get(message.type) || [];
    
    for (const handler of handlers) {
      try {
        await handler(message, context);
      } catch (error) {
        await this.handleError(error, message, context);
      }
    }
  }
  
  private async handleError(
    error: Error,
    message: Message,
    context: ConnectionContext
  ): Promise<void> {
    const errorMessage = MessageBuilder
      .create(MessageType.ERROR)
      .withPayload({
        error: error.message,
        originalMessage: message.id,
        code: 'HANDLER_ERROR'
      })
      .withCorrelationId(message.id)
      .build();
    
    await context.send(errorMessage);
  }
}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ë©”ì‹œì§€ í”„ë¡œí† ì½œ ì •ì˜
- [ ] ì¸ì½”ë”©/ë””ì½”ë”©
- [ ] ë©”ì‹œì§€ ê²€ì¦
- [ ] ë¼ìš°íŒ… ì‹œìŠ¤í…œ

#### SubTask 6.14.4: ì—°ê²° í’€ ê´€ë¦¬

**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:

```python
# backend/src/websocket/connection_pool.py
from typing import Dict, List, Optional, Set
import asyncio
from dataclasses import dataclass

@dataclass
class PoolConfig:
    """ì—°ê²° í’€ ì„¤ì •"""
    min_size: int = 10
    max_size: int = 1000
    max_idle_time: int = 300  # seconds
    max_lifetime: int = 3600  # seconds
    health_check_interval: int = 30
    overflow_policy: str = 'reject'  # reject, queue, scale

class ConnectionPool:
    """WebSocket ì—°ê²° í’€"""
    
    def __init__(self, config: PoolConfig):
        self.config = config
        self.connections: Dict[str, PooledConnection] = {}
        self.available: asyncio.Queue = asyncio.Queue()
        self.in_use: Set[str] = set()
        self.waiting: asyncio.Queue = asyncio.Queue()
        self.stats = PoolStatistics()
        
    async def initialize(self):
        """í’€ ì´ˆê¸°í™”"""
        
        # ìµœì†Œ ì—°ê²° ìƒì„±
        for _ in range(self.config.min_size):
            conn = await self.create_connection()
            await self.available.put(conn)
        
        # í—¬ìŠ¤ ì²´í¬ ì‹œì‘
        asyncio.create_task(self.health_check_loop())
        
        # ì •ë¦¬ ì‘ì—… ì‹œì‘
        asyncio.create_task(self.cleanup_loop())
    
    async def acquire(
        self,
        timeout: Optional[float] = None
    ) -> PooledConnection:
        """ì—°ê²° íšë“"""
        
        self.stats.acquire_attempts += 1
        
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ê²° í™•ì¸
            if not self.available.empty():
                conn = await self.available.get()
                
                # ì—°ê²° ìƒíƒœ í™•ì¸
                if await self.validate_connection(conn):
                    self.in_use.add(conn.id)
                    self.stats.active_connections += 1
                    return conn
                else:
                    # ì—°ê²° ì¬ìƒì„±
                    await self.destroy_connection(conn)
                    return await self.acquire(timeout)
            
            # í’€ í¬ê¸° í™•ì¸
            current_size = len(self.connections)
            
            if current_size < self.config.max_size:
                # ìƒˆ ì—°ê²° ìƒì„±
                conn = await self.create_connection()
                self.in_use.add(conn.id)
                self.stats.active_connections += 1
                return conn
            
            # ì˜¤ë²„í”Œë¡œìš° ì •ì±… ì ìš©
            return await self.handle_overflow(timeout)
            
        except asyncio.TimeoutError:
            self.stats.acquire_timeouts += 1
            raise PoolExhaustedError("Connection pool exhausted")
    
    async def release(self, connection: PooledConnection):
        """ì—°ê²° ë°˜í™˜"""
        
        if connection.id not in self.in_use:
            return
        
        self.in_use.remove(connection.id)
        self.stats.active_connections -= 1
        
        # ì—°ê²° ìƒíƒœ í™•ì¸
        if await self.validate_connection(connection):
            # ì¬ì‚¬ìš© ê°€ëŠ¥
            connection.last_used = datetime.now()
            await self.available.put(connection)
            
            # ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì²˜ë¦¬
            if not self.waiting.empty():
                waiter = await self.waiting.get()
                waiter.set_result(connection)
        else:
            # ì—°ê²° íê¸°
            await self.destroy_connection(connection)
            
            # ìƒˆ ì—°ê²° ìƒì„±
            if len(self.connections) < self.config.min_size:
                new_conn = await self.create_connection()
                await self.available.put(new_conn)
    
    async def handle_overflow(
        self,
        timeout: Optional[float]
    ) -> PooledConnection:
        """ì˜¤ë²„í”Œë¡œìš° ì²˜ë¦¬"""
        
        if self.config.overflow_policy == 'reject':
            raise PoolExhaustedError("Connection pool at maximum capacity")
            
        elif self.config.overflow_policy == 'queue':
            # ëŒ€ê¸° íì— ì¶”ê°€
            future = asyncio.Future()
            await self.waiting.put(future)
            
            if timeout:
                return await asyncio.wait_for(future, timeout)
            else:
                return await future
                
        elif self.config.overflow_policy == 'scale':
            # ë™ì  ìŠ¤ì¼€ì¼ë§
            await self.scale_up()
            return await self.acquire(timeout)
    
    async def health_check_loop(self):
        """í—¬ìŠ¤ ì²´í¬ ë£¨í”„"""
        
        while True:
            await asyncio.sleep(self.config.health_check_interval)
            
            # ëª¨ë“  ì—°ê²° ì²´í¬
            for conn in list(self.connections.values()):
                if not await self.ping_connection(conn):
                    await self.handle_unhealthy_connection(conn)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats.update()
    
    async def cleanup_loop(self):
        """ì •ë¦¬ ì‘ì—… ë£¨í”„"""
        
        while True:
            await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤
            
            now = datetime.now()
            
            # ìœ íœ´ ì—°ê²° ì •ë¦¬
            while not self.available.empty():
                conn = await self.available.get()
                
                idle_time = (now - conn.last_used).total_seconds()
                lifetime = (now - conn.created_at).total_seconds()
                
                if (idle_time > self.config.max_idle_time or
                    lifetime > self.config.max_lifetime):
                    await self.destroy_connection(conn)
                else:
                    await self.available.put(conn)
                    break
            
            # ìµœì†Œ í¬ê¸° ìœ ì§€
            await self.maintain_min_size()

@dataclass
class PooledConnection:
    """í’€ë§ëœ ì—°ê²°"""
    id: str
    websocket: Any
    created_at: datetime
    last_used: datetime
    metadata: Dict = field(default_factory=dict)

class ConnectionPoolManager:
    """ì—°ê²° í’€ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.pools: Dict[str, ConnectionPool] = {}
        self.default_config = PoolConfig()
    
    def create_pool(
        self,
        name: str,
        config: Optional[PoolConfig] = None
    ) -> ConnectionPool:
        """í’€ ìƒì„±"""
        
        if name in self.pools:
            raise ValueError(f"Pool {name} already exists")
        
        config = config or self.default_config
        pool = ConnectionPool(config)
        self.pools[name] = pool
        
        return pool
    
    def get_pool(self, name: str) -> Optional[ConnectionPool]:
        """í’€ ì¡°íšŒ"""
        return self.pools.get(name)
    
    async def get_connection(
        self,
        pool_name: str = 'default'
    ) -> PooledConnection:
        """ì—°ê²° íšë“"""
        
        pool = self.get_pool(pool_name)
        if not pool:
            pool = self.create_pool(pool_name)
            await pool.initialize()
        
        return await pool.acquire()
    
    def get_statistics(self) -> Dict[str, PoolStatistics]:
        """í†µê³„ ì¡°íšŒ"""
        
        return {
            name: pool.stats
            for name, pool in self.pools.items()
        }

class PoolStatistics:
    """í’€ í†µê³„"""
    
    def __init__(self):
        self.total_connections = 0
        self.active_connections = 0
        self.idle_connections = 0
        self.acquire_attempts = 0
        self.acquire_timeouts = 0
        self.connection_errors = 0
        self.created_connections = 0
        self.destroyed_connections = 0
    
    def update(self):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        
        self.idle_connections = self.total_connections - self.active_connections
    
    def to_dict(self) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ ë³€í™˜"""
        
        return {
            'total': self.total_connections,
            'active': self.active_connections,
            'idle': self.idle_connections,
            'acquire_attempts': self.acquire_attempts,
            'acquire_timeouts': self.acquire_timeouts,
            'errors': self.connection_errors,
            'created': self.created_connections,
            'destroyed': self.destroyed_connections,
            'utilization': (
                self.active_connections / self.total_connections * 100
                if self.total_connections > 0 else 0
            )
        }
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì—°ê²° í’€ë§
- [ ] ì˜¤ë²„í”Œë¡œìš° ì •ì±…
- [ ] í—¬ìŠ¤ ì²´í¬
- [ ] í†µê³„ ìˆ˜ì§‘

---

## Task 6.15: ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°

### Task 6.15.1: SSE Server Implementation

```python
# src/api/streaming/sse_server.py
from typing import AsyncIterator, Dict, Any, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime
import asyncio
import json
import uuid

@dataclass
class SSEClient:
    """SSE í´ë¼ì´ì–¸íŠ¸"""
    id: str
    subscriptions: Set[str] = field(default_factory=set)
    created_at: datetime = field(default_factory=datetime.utcnow)
    last_ping: datetime = field(default_factory=datetime.utcnow)

class SSEBroadcaster:
    """SSE ë¸Œë¡œë“œìºìŠ¤í„°"""
    
    def __init__(self):
        self.clients: Dict[str, SSEClient] = {}
        self.channels: Dict[str, Set[str]] = {}
        
    async def connect(self, client_id: Optional[str] = None) -> str:
        """í´ë¼ì´ì–¸íŠ¸ ì—°ê²°"""
        client_id = client_id or str(uuid.uuid4())
        self.clients[client_id] = SSEClient(id=client_id)
        return client_id
    
    async def subscribe(self, client_id: str, channel: str):
        """ì±„ë„ êµ¬ë…"""
        if client_id in self.clients:
            self.clients[client_id].subscriptions.add(channel)
            if channel not in self.channels:
                self.channels[channel] = set()
            self.channels[channel].add(client_id)
    
    async def publish(self, channel: str, event: str, data: Any):
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        if channel in self.channels:
            for client_id in self.channels[channel]:
                yield self._format_sse(event, data)
    
    def _format_sse(self, event: str, data: Any) -> str:
        """SSE í¬ë§·"""
        return f"event: {event}\ndata: {json.dumps(data)}\n\n"
```

### Task 6.15.2: WebSocket Streaming

```python
# src/api/streaming/websocket_stream.py
from fastapi import WebSocket
from typing import Dict, Any, Optional
import asyncio
import json

class WebSocketStreamer:
    """WebSocket ìŠ¤íŠ¸ë¦¬ë¨¸"""
    
    def __init__(self):
        self.connections: Dict[str, WebSocket] = {}
        self.streams: Dict[str, asyncio.Task] = {}
        
    async def connect(self, websocket: WebSocket, client_id: str):
        """ì—°ê²° ìˆ˜ë¦½"""
        await websocket.accept()
        self.connections[client_id] = websocket
        
    async def stream_data(
        self,
        client_id: str,
        data_source: AsyncIterator[Any],
        chunk_size: int = 1024
    ):
        """ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°"""
        websocket = self.connections.get(client_id)
        if not websocket:
            return
            
        try:
            async for chunk in data_source:
                await websocket.send_json({
                    "type": "data",
                    "chunk": chunk,
                    "timestamp": datetime.utcnow().isoformat()
                })
        except Exception as e:
            await websocket.send_json({
                "type": "error",
                "message": str(e)
            })
```

### Task 6.15.3: Event Stream Processor

```python
# src/api/streaming/event_processor.py
from typing import AsyncIterator, Optional, List, Callable
from dataclasses import dataclass
import asyncio

@dataclass
class StreamEvent:
    """ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸"""
    type: str
    data: Any
    timestamp: float

class EventStreamPipeline:
    """ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.processors: List[Callable] = []
        self.filters: List[Callable] = []
        
    async def process_stream(
        self,
        input_stream: AsyncIterator[StreamEvent]
    ) -> AsyncIterator[StreamEvent]:
        """ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬"""
        async for event in input_stream:
            if await self._apply_filters(event):
                event = await self._apply_processors(event)
                if event:
                    yield event
    
    async def _apply_filters(self, event: StreamEvent) -> bool:
        """í•„í„° ì ìš©"""
        for filter_func in self.filters:
            if not await filter_func(event):
                return False
        return True
    
    async def _apply_processors(self, event: StreamEvent) -> Optional[StreamEvent]:
        """í”„ë¡œì„¸ì„œ ì ìš©"""
        for processor in self.processors:
            event = await processor(event)
            if event is None:
                break
        return event
```

### Task 6.15.4: Stream Monitoring & Metrics

```python
# src/api/streaming/stream_metrics.py
from dataclasses import dataclass, field
from typing import Dict
import time

@dataclass
class StreamMetrics:
    """ìŠ¤íŠ¸ë¦¼ ë©”íŠ¸ë¦­"""
    events_sent: int = 0
    events_received: int = 0
    bytes_sent: int = 0
    bytes_received: int = 0
    errors: int = 0
    latency_ms: float = 0
    
class StreamMonitor:
    """ìŠ¤íŠ¸ë¦¼ ëª¨ë‹ˆí„°"""
    
    def __init__(self):
        self.metrics: Dict[str, StreamMetrics] = {}
        
    def record_event(self, stream_id: str, event_type: str, size: int):
        """ì´ë²¤íŠ¸ ê¸°ë¡"""
        if stream_id not in self.metrics:
            self.metrics[stream_id] = StreamMetrics()
            
        metrics = self.metrics[stream_id]
        if event_type == "sent":
            metrics.events_sent += 1
            metrics.bytes_sent += size
        elif event_type == "received":
            metrics.events_received += 1
            metrics.bytes_received += size
            
    def get_metrics(self, stream_id: str) -> StreamMetrics:
        """ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        return self.metrics.get(stream_id, StreamMetrics())
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] SSE ì„œë²„ êµ¬í˜„
- [ ] WebSocket ìŠ¤íŠ¸ë¦¬ë°
- [ ] ì´ë²¤íŠ¸ í”„ë¡œì„¸ì‹±
- [ ] ë©”íŠ¸ë¦­ ìˆ˜ì§‘

---

## Task 6.16: ì–‘ë°©í–¥ í†µì‹  í”„ë¡œí† ì½œ

### Task 6.16.1: Protocol Design

```python
# src/api/protocol/protocol_design.py
from enum import Enum
from typing import Dict, Any, Optional
from dataclasses import dataclass
import uuid

class MessageType(Enum):
    """ë©”ì‹œì§€ íƒ€ì…"""
    REQUEST = "request"
    RESPONSE = "response"
    NOTIFICATION = "notification"
    ERROR = "error"
    
@dataclass
class ProtocolMessage:
    """í”„ë¡œí† ì½œ ë©”ì‹œì§€"""
    id: str
    type: MessageType
    method: Optional[str]
    params: Optional[Dict[str, Any]]
    result: Optional[Any]
    error: Optional[Dict[str, Any]]
    
    @classmethod
    def create_request(cls, method: str, params: Dict = None):
        """ìš”ì²­ ìƒì„±"""
        return cls(
            id=str(uuid.uuid4()),
            type=MessageType.REQUEST,
            method=method,
            params=params,
            result=None,
            error=None
        )
    
    @classmethod
    def create_response(cls, request_id: str, result: Any):
        """ì‘ë‹µ ìƒì„±"""
        return cls(
            id=request_id,
            type=MessageType.RESPONSE,
            method=None,
            params=None,
            result=result,
            error=None
        )
```

### Task 6.16.2: Message Router

```python
# src/api/protocol/message_router.py
from typing import Dict, Callable, Any
import asyncio

class MessageRouter:
    """ë©”ì‹œì§€ ë¼ìš°í„°"""
    
    def __init__(self):
        self.handlers: Dict[str, Callable] = {}
        self.pending_requests: Dict[str, asyncio.Future] = {}
        
    def register_handler(self, method: str, handler: Callable):
        """í•¸ë“¤ëŸ¬ ë“±ë¡"""
        self.handlers[method] = handler
        
    async def route_message(self, message: ProtocolMessage) -> Optional[ProtocolMessage]:
        """ë©”ì‹œì§€ ë¼ìš°íŒ…"""
        if message.type == MessageType.REQUEST:
            return await self._handle_request(message)
        elif message.type == MessageType.RESPONSE:
            return await self._handle_response(message)
        elif message.type == MessageType.NOTIFICATION:
            return await self._handle_notification(message)
            
    async def _handle_request(self, message: ProtocolMessage) -> ProtocolMessage:
        """ìš”ì²­ ì²˜ë¦¬"""
        handler = self.handlers.get(message.method)
        if not handler:
            return ProtocolMessage.create_error(
                message.id,
                code=-32601,
                message="Method not found"
            )
            
        try:
            result = await handler(message.params)
            return ProtocolMessage.create_response(message.id, result)
        except Exception as e:
            return ProtocolMessage.create_error(
                message.id,
                code=-32603,
                message=str(e)
            )
```

### Task 6.16.3: RPC Implementation

```python
# src/api/protocol/rpc_impl.py
from typing import Any, Dict, Optional
import asyncio

class RPCClient:
    """RPC í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, transport):
        self.transport = transport
        self.pending: Dict[str, asyncio.Future] = {}
        
    async def call(
        self,
        method: str,
        params: Dict = None,
        timeout: float = 30.0
    ) -> Any:
        """ì›ê²© í”„ë¡œì‹œì € í˜¸ì¶œ"""
        request = ProtocolMessage.create_request(method, params)
        future = asyncio.Future()
        self.pending[request.id] = future
        
        await self.transport.send(request)
        
        try:
            result = await asyncio.wait_for(future, timeout)
            return result
        except asyncio.TimeoutError:
            del self.pending[request.id]
            raise TimeoutError(f"RPC call {method} timed out")
            
    async def handle_response(self, response: ProtocolMessage):
        """ì‘ë‹µ ì²˜ë¦¬"""
        if response.id in self.pending:
            future = self.pending.pop(response.id)
            if response.error:
                future.set_exception(Exception(response.error))
            else:
                future.set_result(response.result)

class RPCServer:
    """RPC ì„œë²„"""
    
    def __init__(self):
        self.methods: Dict[str, Callable] = {}
        
    def register(self, name: str = None):
        """ë©”ì†Œë“œ ë“±ë¡ ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            method_name = name or func.__name__
            self.methods[method_name] = func
            return func
        return decorator
        
    async def handle_request(self, request: ProtocolMessage) -> ProtocolMessage:
        """ìš”ì²­ ì²˜ë¦¬"""
        method = self.methods.get(request.method)
        if not method:
            return ProtocolMessage.create_error(
                request.id,
                code=-32601,
                message=f"Method {request.method} not found"
            )
            
        try:
            result = await method(**request.params)
            return ProtocolMessage.create_response(request.id, result)
        except Exception as e:
            return ProtocolMessage.create_error(
                request.id,
                code=-32000,
                message=str(e)
            )
```

### Task 6.16.4: Protocol Negotiation

```python
# src/api/protocol/negotiation.py
from typing import List, Dict, Optional
from dataclasses import dataclass

@dataclass
class ProtocolCapability:
    """í”„ë¡œí† ì½œ ê¸°ëŠ¥"""
    name: str
    version: str
    features: List[str]
    
class ProtocolNegotiator:
    """í”„ë¡œí† ì½œ í˜‘ìƒ"""
    
    def __init__(self):
        self.supported_protocols = {
            "jsonrpc": ProtocolCapability("jsonrpc", "2.0", ["batch", "notification"]),
            "websocket": ProtocolCapability("websocket", "13", ["binary", "text"]),
            "sse": ProtocolCapability("sse", "1.0", ["retry", "id"])
        }
        
    async def negotiate(
        self,
        client_capabilities: List[str]
    ) -> Optional[ProtocolCapability]:
        """í”„ë¡œí† ì½œ í˜‘ìƒ"""
        for cap in client_capabilities:
            if cap in self.supported_protocols:
                return self.supported_protocols[cap]
        return None
        
    def get_capabilities(self) -> Dict[str, ProtocolCapability]:
        """ì§€ì› ê¸°ëŠ¥ ì¡°íšŒ"""
        return self.supported_protocols
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] í”„ë¡œí† ì½œ ì„¤ê³„
- [ ] ë©”ì‹œì§€ ë¼ìš°íŒ…
- [ ] RPC êµ¬í˜„
- [ ] í”„ë¡œí† ì½œ í˜‘ìƒ

---

## Task 6.17: ì¸ì¦/ì¸ê°€ ì‹œìŠ¤í…œ

### Task 6.17.1: Authentication Service

```python
# src/api/auth/authentication.py
from typing import Optional, Dict, Any
from dataclasses import dataclass
import hashlib
import secrets

@dataclass
class User:
    """ì‚¬ìš©ì"""
    id: str
    username: str
    email: str
    password_hash: str
    
class AuthenticationService:
    """ì¸ì¦ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.users: Dict[str, User] = {}
        self.sessions: Dict[str, str] = {}
        
    def hash_password(self, password: str, salt: bytes = None) -> str:
        """ë¹„ë°€ë²ˆí˜¸ í•´ì‹±"""
        if salt is None:
            salt = secrets.token_bytes(32)
        return hashlib.pbkdf2_hmac('sha256', password.encode(), salt, 100000).hex()
        
    async def register(self, username: str, email: str, password: str) -> User:
        """ì‚¬ìš©ì ë“±ë¡"""
        user = User(
            id=str(uuid.uuid4()),
            username=username,
            email=email,
            password_hash=self.hash_password(password)
        )
        self.users[user.id] = user
        return user
        
    async def authenticate(self, username: str, password: str) -> Optional[str]:
        """ì‚¬ìš©ì ì¸ì¦"""
        for user in self.users.values():
            if user.username == username:
                if self.verify_password(password, user.password_hash):
                    session_id = secrets.token_urlsafe(32)
                    self.sessions[session_id] = user.id
                    return session_id
        return None
```

### Task 6.17.2: Authorization Engine

```python
# src/api/auth/authorization.py
from typing import List, Dict, Set
from dataclasses import dataclass
from enum import Enum

class Permission(Enum):
    """ê¶Œí•œ"""
    READ = "read"
    WRITE = "write"
    DELETE = "delete"
    ADMIN = "admin"
    
@dataclass
class Role:
    """ì—­í• """
    name: str
    permissions: Set[Permission]
    
class AuthorizationEngine:
    """ì¸ê°€ ì—”ì§„"""
    
    def __init__(self):
        self.roles: Dict[str, Role] = {}
        self.user_roles: Dict[str, Set[str]] = {}
        self._init_default_roles()
        
    def _init_default_roles(self):
        """ê¸°ë³¸ ì—­í•  ì´ˆê¸°í™”"""
        self.roles["viewer"] = Role("viewer", {Permission.READ})
        self.roles["editor"] = Role("editor", {Permission.READ, Permission.WRITE})
        self.roles["admin"] = Role("admin", {Permission.READ, Permission.WRITE, Permission.DELETE, Permission.ADMIN})
        
    def assign_role(self, user_id: str, role_name: str):
        """ì—­í•  í• ë‹¹"""
        if user_id not in self.user_roles:
            self.user_roles[user_id] = set()
        self.user_roles[user_id].add(role_name)
        
    def check_permission(self, user_id: str, permission: Permission) -> bool:
        """ê¶Œí•œ í™•ì¸"""
        if user_id not in self.user_roles:
            return False
            
        for role_name in self.user_roles[user_id]:
            role = self.roles.get(role_name)
            if role and permission in role.permissions:
                return True
        return False
```

### Task 6.17.3: Session Management

```python
# src/api/auth/session.py
from typing import Optional, Dict, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, field
import secrets

@dataclass
class Session:
    """ì„¸ì…˜"""
    id: str
    user_id: str
    created_at: datetime
    expires_at: datetime
    data: Dict[str, Any] = field(default_factory=dict)
    
class SessionManager:
    """ì„¸ì…˜ ê´€ë¦¬ì"""
    
    def __init__(self, ttl_seconds: int = 3600):
        self.sessions: Dict[str, Session] = {}
        self.ttl = timedelta(seconds=ttl_seconds)
        
    def create_session(self, user_id: str, data: Dict = None) -> str:
        """ì„¸ì…˜ ìƒì„±"""
        session_id = secrets.token_urlsafe(32)
        now = datetime.utcnow()
        
        session = Session(
            id=session_id,
            user_id=user_id,
            created_at=now,
            expires_at=now + self.ttl,
            data=data or {}
        )
        
        self.sessions[session_id] = session
        return session_id
        
    def get_session(self, session_id: str) -> Optional[Session]:
        """ì„¸ì…˜ ì¡°íšŒ"""
        session = self.sessions.get(session_id)
        if session and session.expires_at > datetime.utcnow():
            return session
        elif session:
            del self.sessions[session_id]
        return None
        
    def refresh_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ ê°±ì‹ """
        session = self.get_session(session_id)
        if session:
            session.expires_at = datetime.utcnow() + self.ttl
            return True
        return False
```

### Task 6.17.4: MFA Implementation

```python
# src/api/auth/mfa.py
import pyotp
import qrcode
from io import BytesIO
from typing import Optional

class MFAService:
    """ë‹¤ì¤‘ ì¸ì¦ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.user_secrets: Dict[str, str] = {}
        
    def generate_secret(self, user_id: str) -> str:
        """ë¹„ë°€í‚¤ ìƒì„±"""
        secret = pyotp.random_base32()
        self.user_secrets[user_id] = secret
        return secret
        
    def generate_qr_code(self, user_id: str, issuer: str = "MyApp") -> bytes:
        """QR ì½”ë“œ ìƒì„±"""
        secret = self.user_secrets.get(user_id)
        if not secret:
            secret = self.generate_secret(user_id)
            
        totp = pyotp.TOTP(secret)
        provisioning_uri = totp.provisioning_uri(
            name=user_id,
            issuer_name=issuer
        )
        
        qr = qrcode.QRCode(version=1, box_size=10, border=5)
        qr.add_data(provisioning_uri)
        qr.make(fit=True)
        
        img = qr.make_image(fill_color="black", back_color="white")
        buf = BytesIO()
        img.save(buf, format='PNG')
        return buf.getvalue()
        
    def verify_token(self, user_id: str, token: str) -> bool:
        """í† í° ê²€ì¦"""
        secret = self.user_secrets.get(user_id)
        if not secret:
            return False
            
        totp = pyotp.TOTP(secret)
        return totp.verify(token, valid_window=1)
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì¸ì¦ ì„œë¹„ìŠ¤
- [ ] ì¸ê°€ ì—”ì§„
- [ ] ì„¸ì…˜ ê´€ë¦¬
- [ ] MFA êµ¬í˜„

---

## Task 6.18: OAuth 2.0/JWT êµ¬í˜„

### Task 6.18.1: OAuth Provider

```python
# src/api/oauth/provider.py
from typing import Dict, Optional, List
from dataclasses import dataclass
import secrets
from datetime import datetime, timedelta

@dataclass
class OAuthClient:
    """OAuth í´ë¼ì´ì–¸íŠ¸"""
    client_id: str
    client_secret: str
    redirect_uris: List[str]
    scopes: List[str]
    
@dataclass
class AuthorizationCode:
    """ì¸ê°€ ì½”ë“œ"""
    code: str
    client_id: str
    user_id: str
    scopes: List[str]
    expires_at: datetime
    
class OAuthProvider:
    """OAuth 2.0 ì œê³µì"""
    
    def __init__(self):
        self.clients: Dict[str, OAuthClient] = {}
        self.auth_codes: Dict[str, AuthorizationCode] = {}
        self.access_tokens: Dict[str, Dict] = {}
        
    def register_client(
        self,
        redirect_uris: List[str],
        scopes: List[str]
    ) -> OAuthClient:
        """í´ë¼ì´ì–¸íŠ¸ ë“±ë¡"""
        client = OAuthClient(
            client_id=secrets.token_urlsafe(32),
            client_secret=secrets.token_urlsafe(64),
            redirect_uris=redirect_uris,
            scopes=scopes
        )
        self.clients[client.client_id] = client
        return client
        
    def authorize(
        self,
        client_id: str,
        user_id: str,
        scopes: List[str],
        redirect_uri: str
    ) -> str:
        """ì¸ê°€ ì½”ë“œ ë°œê¸‰"""
        client = self.clients.get(client_id)
        if not client or redirect_uri not in client.redirect_uris:
            raise ValueError("Invalid client or redirect URI")
            
        code = secrets.token_urlsafe(32)
        auth_code = AuthorizationCode(
            code=code,
            client_id=client_id,
            user_id=user_id,
            scopes=scopes,
            expires_at=datetime.utcnow() + timedelta(minutes=10)
        )
        self.auth_codes[code] = auth_code
        return code
```

### Task 6.18.2: JWT Token Service

```python
# src/api/oauth/jwt_service.py
import jwt
from datetime import datetime, timedelta
from typing import Dict, Any, Optional

class JWTService:
    """JWT í† í° ì„œë¹„ìŠ¤"""
    
    def __init__(self, secret_key: str, algorithm: str = "HS256"):
        self.secret_key = secret_key
        self.algorithm = algorithm
        
    def create_access_token(
        self,
        subject: str,
        scopes: List[str] = None,
        expires_delta: timedelta = None
    ) -> str:
        """ì•¡ì„¸ìŠ¤ í† í° ìƒì„±"""
        if expires_delta:
            expire = datetime.utcnow() + expires_delta
        else:
            expire = datetime.utcnow() + timedelta(minutes=15)
            
        payload = {
            "sub": subject,
            "scopes": scopes or [],
            "exp": expire,
            "iat": datetime.utcnow(),
            "type": "access"
        }
        
        return jwt.encode(payload, self.secret_key, algorithm=self.algorithm)
        
    def create_refresh_token(
        self,
        subject: str,
        expires_delta: timedelta = None
    ) -> str:
        """ë¦¬í”„ë ˆì‹œ í† í° ìƒì„±"""
        if expires_delta:
            expire = datetime.utcnow() + expires_delta
        else:
            expire = datetime.utcnow() + timedelta(days=30)
            
        payload = {
            "sub": subject,
            "exp": expire,
            "iat": datetime.utcnow(),
            "type": "refresh"
        }
        
        return jwt.encode(payload, self.secret_key, algorithm=self.algorithm)
        
    def verify_token(self, token: str) -> Optional[Dict[str, Any]]:
        """í† í° ê²€ì¦"""
        try:
            payload = jwt.decode(
                token,
                self.secret_key,
                algorithms=[self.algorithm]
            )
            return payload
        except jwt.ExpiredSignatureError:
            return None
        except jwt.InvalidTokenError:
            return None
```

### Task 6.18.3: Token Refresh Logic

```python
# src/api/oauth/token_refresh.py
from typing import Optional, Tuple
from datetime import datetime, timedelta

class TokenRefreshService:
    """í† í° ê°±ì‹  ì„œë¹„ìŠ¤"""
    
    def __init__(self, jwt_service: JWTService):
        self.jwt_service = jwt_service
        self.refresh_tokens: Dict[str, str] = {}
        
    def issue_token_pair(
        self,
        user_id: str,
        scopes: List[str] = None
    ) -> Tuple[str, str]:
        """í† í° ìŒ ë°œê¸‰"""
        access_token = self.jwt_service.create_access_token(
            subject=user_id,
            scopes=scopes,
            expires_delta=timedelta(minutes=15)
        )
        
        refresh_token = self.jwt_service.create_refresh_token(
            subject=user_id,
            expires_delta=timedelta(days=30)
        )
        
        self.refresh_tokens[refresh_token] = user_id
        
        return access_token, refresh_token
        
    def refresh_access_token(self, refresh_token: str) -> Optional[str]:
        """ì•¡ì„¸ìŠ¤ í† í° ê°±ì‹ """
        payload = self.jwt_service.verify_token(refresh_token)
        
        if not payload or payload.get("type") != "refresh":
            return None
            
        if refresh_token not in self.refresh_tokens:
            return None
            
        user_id = payload["sub"]
        
        new_access_token = self.jwt_service.create_access_token(
            subject=user_id,
            expires_delta=timedelta(minutes=15)
        )
        
        return new_access_token
        
    def revoke_refresh_token(self, refresh_token: str) -> bool:
        """ë¦¬í”„ë ˆì‹œ í† í° ì·¨ì†Œ"""
        if refresh_token in self.refresh_tokens:
            del self.refresh_tokens[refresh_token]
            return True
        return False
```

### Task 6.18.4: JWKS Management

```python
# src/api/oauth/jwks.py
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.primitives.asymmetric import rsa
from typing import Dict, List
import base64
import json

class JWKSManager:
    """JWKS ê´€ë¦¬ì"""
    
    def __init__(self):
        self.keys: Dict[str, Dict] = {}
        
    def generate_key_pair(self, kid: str) -> Dict:
        """í‚¤ ìŒ ìƒì„±"""
        private_key = rsa.generate_private_key(
            public_exponent=65537,
            key_size=2048
        )
        
        public_key = private_key.public_key()
        
        # JWK í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        public_numbers = public_key.public_numbers()
        
        jwk = {
            "kty": "RSA",
            "use": "sig",
            "kid": kid,
            "n": base64.urlsafe_b64encode(
                public_numbers.n.to_bytes(256, 'big')
            ).rstrip(b'=').decode('utf-8'),
            "e": base64.urlsafe_b64encode(
                public_numbers.e.to_bytes(3, 'big')
            ).rstrip(b'=').decode('utf-8')
        }
        
        self.keys[kid] = {
            "private_key": private_key,
            "public_key": public_key,
            "jwk": jwk
        }
        
        return jwk
        
    def get_jwks(self) -> Dict:
        """JWKS ì¡°íšŒ"""
        return {
            "keys": [key_data["jwk"] for key_data in self.keys.values()]
        }
        
    def rotate_keys(self) -> str:
        """í‚¤ ìˆœí™˜"""
        new_kid = f"key-{datetime.utcnow().timestamp()}"
        self.generate_key_pair(new_kid)
        
        # ì´ì „ í‚¤ ë³´ê´€ (ì¼ì • ê¸°ê°„)
        cutoff = datetime.utcnow() - timedelta(hours=24)
        for kid in list(self.keys.keys()):
            if self._parse_kid_timestamp(kid) < cutoff:
                del self.keys[kid]
                
        return new_kid
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] OAuth ì œê³µì
- [ ] JWT í† í° ì„œë¹„ìŠ¤
- [ ] í† í° ê°±ì‹  ë¡œì§
- [ ] JWKS ê´€ë¦¬

---

## Task 6.19: API í‚¤ ê´€ë¦¬

### Task 6.19.1: API Key Generation

```python
# src/api/keys/key_generation.py
from typing import Optional, Dict, List
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import secrets
import hashlib

@dataclass
class APIKey:
    """API í‚¤"""
    id: str
    name: str
    key_hash: str
    prefix: str
    created_at: datetime
    expires_at: Optional[datetime]
    scopes: List[str] = field(default_factory=list)
    metadata: Dict = field(default_factory=dict)
    
class APIKeyGenerator:
    """API í‚¤ ìƒì„±ê¸°"""
    
    def __init__(self, prefix: str = "sk"):
        self.prefix = prefix
        self.keys: Dict[str, APIKey] = {}
        
    def generate_key(
        self,
        name: str,
        scopes: List[str] = None,
        expires_in: Optional[timedelta] = None
    ) -> tuple[str, APIKey]:
        """API í‚¤ ìƒì„±"""
        # í‚¤ ìƒì„±
        raw_key = secrets.token_urlsafe(32)
        full_key = f"{self.prefix}_{raw_key}"
        
        # í‚¤ í•´ì‹œ
        key_hash = self._hash_key(full_key)
        
        # í‚¤ ê°ì²´ ìƒì„±
        api_key = APIKey(
            id=secrets.token_hex(16),
            name=name,
            key_hash=key_hash,
            prefix=full_key[:8],  # í‚¤ í”„ë¦¬í”½ìŠ¤ ì €ì¥
            created_at=datetime.utcnow(),
            expires_at=datetime.utcnow() + expires_in if expires_in else None,
            scopes=scopes or [],
            metadata={}
        )
        
        self.keys[api_key.id] = api_key
        
        return full_key, api_key
        
    def _hash_key(self, key: str) -> str:
        """í‚¤ í•´ì‹±"""
        return hashlib.sha256(key.encode()).hexdigest()
        
    def validate_key(self, key: str) -> Optional[APIKey]:
        """í‚¤ ê²€ì¦"""
        key_hash = self._hash_key(key)
        
        for api_key in self.keys.values():
            if api_key.key_hash == key_hash:
                if api_key.expires_at and api_key.expires_at < datetime.utcnow():
                    return None
                return api_key
                
        return None
```

### Task 6.19.2: Key Rotation System

```python
# src/api/keys/key_rotation.py
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import asyncio

@dataclass
class KeyRotationPolicy:
    """í‚¤ ìˆœí™˜ ì •ì±…"""
    rotation_interval: timedelta
    grace_period: timedelta
    auto_rotate: bool = True
    notify_before: timedelta = timedelta(days=7)
    
class KeyRotationService:
    """í‚¤ ìˆœí™˜ ì„œë¹„ìŠ¤"""
    
    def __init__(self, generator: APIKeyGenerator):
        self.generator = generator
        self.policies: Dict[str, KeyRotationPolicy] = {}
        self.rotation_schedule: Dict[str, datetime] = {}
        
    def set_rotation_policy(
        self,
        key_id: str,
        policy: KeyRotationPolicy
    ):
        """ìˆœí™˜ ì •ì±… ì„¤ì •"""
        self.policies[key_id] = policy
        
        # ë‹¤ìŒ ìˆœí™˜ ì¼ì • ì„¤ì •
        api_key = self.generator.keys.get(key_id)
        if api_key:
            next_rotation = api_key.created_at + policy.rotation_interval
            self.rotation_schedule[key_id] = next_rotation
            
    async def rotate_key(
        self,
        key_id: str
    ) -> Optional[tuple[str, APIKey]]:
        """í‚¤ ìˆœí™˜"""
        old_key = self.generator.keys.get(key_id)
        if not old_key:
            return None
            
        policy = self.policies.get(key_id)
        
        # ìƒˆ í‚¤ ìƒì„±
        new_full_key, new_api_key = self.generator.generate_key(
            name=f"{old_key.name}_rotated",
            scopes=old_key.scopes,
            expires_in=policy.rotation_interval if policy else None
        )
        
        # ì´ì „ í‚¤ì— ìœ ì˜ˆ ê¸°ê°„ ì„¤ì •
        if policy:
            old_key.expires_at = datetime.utcnow() + policy.grace_period
            
        # ìˆœí™˜ ì¼ì • ì—…ë°ì´íŠ¸
        if policy:
            self.rotation_schedule[new_api_key.id] = datetime.utcnow() + policy.rotation_interval
            
        return new_full_key, new_api_key
        
    async def check_rotation_schedule(self):
        """ìˆœí™˜ ì¼ì • í™•ì¸"""
        now = datetime.utcnow()
        
        for key_id, next_rotation in list(self.rotation_schedule.items()):
            if now >= next_rotation:
                policy = self.policies.get(key_id)
                if policy and policy.auto_rotate:
                    await self.rotate_key(key_id)
```

### Task 6.19.3: Key Validation

```python
# src/api/keys/key_validation.py
from typing import Optional, List, Dict
from dataclasses import dataclass
from datetime import datetime
import re

@dataclass
class ValidationResult:
    """ê²€ì¦ ê²°ê³¼"""
    valid: bool
    key_id: Optional[str] = None
    scopes: List[str] = field(default_factory=list)
    error: Optional[str] = None
    
class KeyValidator:
    """í‚¤ ê²€ì¦ê¸°"""
    
    def __init__(self, generator: APIKeyGenerator):
        self.generator = generator
        self.blacklist: Set[str] = set()
        self.rate_limits: Dict[str, List[datetime]] = {}
        
    def validate(
        self,
        key: str,
        required_scopes: List[str] = None
    ) -> ValidationResult:
        """í‚¤ ê²€ì¦"""
        # í˜•ì‹ ê²€ì¦
        if not self._validate_format(key):
            return ValidationResult(
                valid=False,
                error="Invalid key format"
            )
            
        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ í™•ì¸
        if key in self.blacklist:
            return ValidationResult(
                valid=False,
                error="Key is blacklisted"
            )
            
        # í‚¤ ì¡´ì¬ ë° ë§Œë£Œ í™•ì¸
        api_key = self.generator.validate_key(key)
        if not api_key:
            return ValidationResult(
                valid=False,
                error="Invalid or expired key"
            )
            
        # ìŠ¤ì½”í”„ í™•ì¸
        if required_scopes:
            if not all(scope in api_key.scopes for scope in required_scopes):
                return ValidationResult(
                    valid=False,
                    key_id=api_key.id,
                    error="Insufficient scopes"
                )
                
        # ë ˆì´íŠ¸ ë¦¬ë°‹ í™•ì¸
        if not self._check_rate_limit(api_key.id):
            return ValidationResult(
                valid=False,
                key_id=api_key.id,
                error="Rate limit exceeded"
            )
            
        return ValidationResult(
            valid=True,
            key_id=api_key.id,
            scopes=api_key.scopes
        )
        
    def _validate_format(self, key: str) -> bool:
        """í˜•ì‹ ê²€ì¦"""
        pattern = r'^[a-zA-Z]+_[a-zA-Z0-9_-]+$'
        return bool(re.match(pattern, key))
        
    def _check_rate_limit(
        self,
        key_id: str,
        limit: int = 100,
        window: timedelta = timedelta(minutes=1)
    ) -> bool:
        """ë ˆì´íŠ¸ ë¦¬ë°‹ í™•ì¸"""
        now = datetime.utcnow()
        
        if key_id not in self.rate_limits:
            self.rate_limits[key_id] = []
            
        # ìœˆë„ìš° ë°– ìš”ì²­ ì œê±°
        self.rate_limits[key_id] = [
            ts for ts in self.rate_limits[key_id]
            if now - ts < window
        ]
        
        # ë¦¬ë°‹ í™•ì¸
        if len(self.rate_limits[key_id]) >= limit:
            return False
            
        self.rate_limits[key_id].append(now)
        return True
        
    def revoke_key(self, key_id: str):
        """í‚¤ ì·¨ì†Œ"""
        if key_id in self.generator.keys:
            api_key = self.generator.keys[key_id]
            self.blacklist.add(api_key.key_hash)
```

### Task 6.19.4: Key Analytics

```python
# src/api/keys/key_analytics.py
from typing import Dict, List, Optional
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict

@dataclass
class KeyUsageMetrics:
    """í‚¤ ì‚¬ìš© ë©”íŠ¸ë¦­"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    last_used: Optional[datetime] = None
    endpoints_accessed: Dict[str, int] = field(default_factory=dict)
    
class KeyAnalytics:
    """í‚¤ ë¶„ì„"""
    
    def __init__(self):
        self.metrics: Dict[str, KeyUsageMetrics] = {}
        self.hourly_stats: Dict[str, Dict[int, int]] = defaultdict(lambda: defaultdict(int))
        
    def record_usage(
        self,
        key_id: str,
        endpoint: str,
        success: bool,
        response_time: float
    ):
        """ì‚¬ìš© ê¸°ë¡"""
        if key_id not in self.metrics:
            self.metrics[key_id] = KeyUsageMetrics()
            
        metrics = self.metrics[key_id]
        metrics.total_requests += 1
        
        if success:
            metrics.successful_requests += 1
        else:
            metrics.failed_requests += 1
            
        metrics.last_used = datetime.utcnow()
        
        if endpoint not in metrics.endpoints_accessed:
            metrics.endpoints_accessed[endpoint] = 0
        metrics.endpoints_accessed[endpoint] += 1
        
        # ì‹œê°„ë³„ í†µê³„
        hour = datetime.utcnow().hour
        self.hourly_stats[key_id][hour] += 1
        
    def get_metrics(self, key_id: str) -> KeyUsageMetrics:
        """ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        return self.metrics.get(key_id, KeyUsageMetrics())
        
    def get_usage_report(
        self,
        key_id: str,
        period: timedelta = timedelta(days=30)
    ) -> Dict:
        """ì‚¬ìš© ë¦¬í¬íŠ¸ ìƒì„±"""
        metrics = self.get_metrics(key_id)
        
        return {
            "key_id": key_id,
            "period": period.days,
            "total_requests": metrics.total_requests,
            "success_rate": (
                metrics.successful_requests / metrics.total_requests * 100
                if metrics.total_requests > 0 else 0
            ),
            "last_used": metrics.last_used.isoformat() if metrics.last_used else None,
            "top_endpoints": sorted(
                metrics.endpoints_accessed.items(),
                key=lambda x: x[1],
                reverse=True
            )[:10],
            "hourly_distribution": dict(self.hourly_stats[key_id])
        }
        
    def detect_anomalies(self, key_id: str) -> List[str]:
        """ì´ìƒ íƒì§€"""
        anomalies = []
        metrics = self.get_metrics(key_id)
        
        # ë†’ì€ ì‹¤íŒ¨ìœ¨
        if metrics.total_requests > 100:
            failure_rate = metrics.failed_requests / metrics.total_requests
            if failure_rate > 0.1:
                anomalies.append(f"High failure rate: {failure_rate:.2%}")
                
        # ë¹„ì •ìƒì ì¸ ì‚¬ìš© íŒ¨í„´
        hourly = self.hourly_stats[key_id]
        if hourly:
            avg_hourly = sum(hourly.values()) / len(hourly)
            for hour, count in hourly.items():
                if count > avg_hourly * 3:
                    anomalies.append(f"Spike at hour {hour}: {count} requests")
                    
        return anomalies
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] API í‚¤ ìƒì„±
- [ ] í‚¤ ìˆœí™˜ ì‹œìŠ¤í…œ
- [ ] í‚¤ ê²€ì¦
- [ ] í‚¤ ë¶„ì„

---

## Task 6.20: Rate Limiting ë° Throttling

### Task 6.20.1: Token Bucket Algorithm

```python
# src/api/ratelimit/token_bucket.py
from typing import Dict, Optional
from dataclasses import dataclass
from datetime import datetime
import asyncio
import time

@dataclass
class TokenBucket:
    """í† í° ë²„í‚·"""
    capacity: int
    refill_rate: float  # tokens per second
    tokens: float
    last_refill: float
    
class TokenBucketRateLimiter:
    """í† í° ë²„í‚· ë ˆì´íŠ¸ ë¦¬ë¯¸í„°"""
    
    def __init__(self, capacity: int = 100, refill_rate: float = 10):
        self.capacity = capacity
        self.refill_rate = refill_rate
        self.buckets: Dict[str, TokenBucket] = {}
        
    def _get_bucket(self, key: str) -> TokenBucket:
        """ë²„í‚· ê°€ì ¸ì˜¤ê¸°"""
        if key not in self.buckets:
            self.buckets[key] = TokenBucket(
                capacity=self.capacity,
                refill_rate=self.refill_rate,
                tokens=self.capacity,
                last_refill=time.time()
            )
        return self.buckets[key]
        
    def _refill(self, bucket: TokenBucket):
        """í† í° ë¦¬í•„"""
        now = time.time()
        time_passed = now - bucket.last_refill
        tokens_to_add = time_passed * bucket.refill_rate
        
        bucket.tokens = min(bucket.capacity, bucket.tokens + tokens_to_add)
        bucket.last_refill = now
        
    async def consume(
        self,
        key: str,
        tokens: int = 1
    ) -> tuple[bool, float]:
        """í† í° ì†Œë¹„"""
        bucket = self._get_bucket(key)
        self._refill(bucket)
        
        if bucket.tokens >= tokens:
            bucket.tokens -= tokens
            return True, bucket.tokens
        
        # ëŒ€ê¸° ì‹œê°„ ê³„ì‚°
        tokens_needed = tokens - bucket.tokens
        wait_time = tokens_needed / bucket.refill_rate
        
        return False, wait_time
        
    def get_status(self, key: str) -> Dict:
        """ìƒíƒœ ì¡°íšŒ"""
        bucket = self._get_bucket(key)
        self._refill(bucket)
        
        return {
            "available_tokens": bucket.tokens,
            "capacity": bucket.capacity,
            "refill_rate": bucket.refill_rate
        }
```

### Task 6.20.2: Sliding Window Counter

```python
# src/api/ratelimit/sliding_window.py
from typing import Dict, List
from datetime import datetime, timedelta
from collections import deque
import time

class SlidingWindowRateLimiter:
    """ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë ˆì´íŠ¸ ë¦¬ë¯¸í„°"""
    
    def __init__(
        self,
        window_size: timedelta = timedelta(minutes=1),
        max_requests: int = 60
    ):
        self.window_size = window_size
        self.max_requests = max_requests
        self.requests: Dict[str, deque] = {}
        
    def _cleanup_old_requests(self, key: str):
        """ì˜¤ë˜ëœ ìš”ì²­ ì •ë¦¬"""
        if key not in self.requests:
            self.requests[key] = deque()
            return
            
        cutoff = time.time() - self.window_size.total_seconds()
        
        while self.requests[key] and self.requests[key][0] < cutoff:
            self.requests[key].popleft()
            
    async def check_limit(self, key: str) -> tuple[bool, Dict]:
        """ë¦¬ë°‹ í™•ì¸"""
        self._cleanup_old_requests(key)
        
        current_count = len(self.requests[key])
        
        if current_count < self.max_requests:
            self.requests[key].append(time.time())
            return True, {
                "allowed": True,
                "current": current_count + 1,
                "limit": self.max_requests,
                "remaining": self.max_requests - current_count - 1,
                "reset_at": datetime.utcnow() + self.window_size
            }
        
        # ë‹¤ìŒ ìŠ¬ë¡¯ê¹Œì§€ ëŒ€ê¸° ì‹œê°„
        oldest_request = self.requests[key][0]
        reset_time = oldest_request + self.window_size.total_seconds()
        wait_time = reset_time - time.time()
        
        return False, {
            "allowed": False,
            "current": current_count,
            "limit": self.max_requests,
            "remaining": 0,
            "retry_after": wait_time,
            "reset_at": datetime.fromtimestamp(reset_time)
        }
        
    def get_usage(self, key: str) -> Dict:
        """ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        self._cleanup_old_requests(key)
        
        current_count = len(self.requests.get(key, []))
        
        return {
            "current": current_count,
            "limit": self.max_requests,
            "remaining": max(0, self.max_requests - current_count),
            "window_size": self.window_size.total_seconds()
        }
```

### Task 6.20.3: Distributed Rate Limiting

```python
# src/api/ratelimit/distributed.py
import redis
from typing import Optional, Dict
import time
import json

class DistributedRateLimiter:
    """ë¶„ì‚° ë ˆì´íŠ¸ ë¦¬ë¯¸í„°"""
    
    def __init__(
        self,
        redis_client: redis.Redis,
        prefix: str = "ratelimit"
    ):
        self.redis = redis_client
        self.prefix = prefix
        
    async def check_limit(
        self,
        key: str,
        limit: int,
        window: int  # seconds
    ) -> tuple[bool, Dict]:
        """ë¶„ì‚° ë¦¬ë°‹ í™•ì¸"""
        redis_key = f"{self.prefix}:{key}"
        
        # Lua ìŠ¤í¬ë¦½íŠ¸ë¡œ ì›ìì  ì‹¤í–‰
        lua_script = """
        local key = KEYS[1]
        local limit = tonumber(ARGV[1])
        local window = tonumber(ARGV[2])
        local current_time = tonumber(ARGV[3])
        
        local current = redis.call('GET', key)
        if current == false then
            redis.call('SET', key, 1)
            redis.call('EXPIRE', key, window)
            return {1, 1, limit - 1}
        end
        
        current = tonumber(current)
        if current < limit then
            local new_value = redis.call('INCR', key)
            local ttl = redis.call('TTL', key)
            return {1, new_value, limit - new_value}
        else
            local ttl = redis.call('TTL', key)
            return {0, current, ttl}
        end
        """
        
        result = self.redis.eval(
            lua_script,
            1,
            redis_key,
            limit,
            window,
            int(time.time())
        )
        
        allowed, current, remaining_or_ttl = result
        
        if allowed:
            return True, {
                "allowed": True,
                "current": current,
                "limit": limit,
                "remaining": remaining_or_ttl
            }
        else:
            return False, {
                "allowed": False,
                "current": current,
                "limit": limit,
                "retry_after": remaining_or_ttl
            }
            
    async def reset(self, key: str):
        """ì¹´ìš´í„° ë¦¬ì…‹"""
        redis_key = f"{self.prefix}:{key}"
        self.redis.delete(redis_key)
        
    async def get_usage(self, pattern: str = "*") -> Dict[str, int]:
        """ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        keys = self.redis.keys(f"{self.prefix}:{pattern}")
        usage = {}
        
        for key in keys:
            value = self.redis.get(key)
            if value:
                clean_key = key.decode().replace(f"{self.prefix}:", "")
                usage[clean_key] = int(value)
                
        return usage
```

### Task 6.20.4: Adaptive Throttling

```python
# src/api/ratelimit/adaptive.py
from typing import Dict, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import statistics

@dataclass
class SystemMetrics:
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­"""
    cpu_usage: float
    memory_usage: float
    response_time: float
    error_rate: float
    
class AdaptiveThrottler:
    """ì ì‘í˜• ìŠ¤ë¡œí‹€ëŸ¬"""
    
    def __init__(self):
        self.base_limits: Dict[str, int] = {}
        self.current_limits: Dict[str, int] = {}
        self.metrics_history: List[SystemMetrics] = []
        self.adjustment_factor = 1.0
        
    def set_base_limit(self, key: str, limit: int):
        """ê¸°ë³¸ ë¦¬ë°‹ ì„¤ì •"""
        self.base_limits[key] = limit
        self.current_limits[key] = limit
        
    def update_metrics(self, metrics: SystemMetrics):
        """ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        self.metrics_history.append(metrics)
        
        # ìµœê·¼ ë©”íŠ¸ë¦­ë§Œ ìœ ì§€
        if len(self.metrics_history) > 100:
            self.metrics_history.pop(0)
            
        # ì¡°ì • ê³„ìˆ˜ ê³„ì‚°
        self._calculate_adjustment_factor()
        
        # ë¦¬ë°‹ ì¡°ì •
        self._adjust_limits()
        
    def _calculate_adjustment_factor(self):
        """ì¡°ì • ê³„ìˆ˜ ê³„ì‚°"""
        if len(self.metrics_history) < 10:
            return
            
        recent_metrics = self.metrics_history[-10:]
        
        avg_cpu = statistics.mean(m.cpu_usage for m in recent_metrics)
        avg_memory = statistics.mean(m.memory_usage for m in recent_metrics)
        avg_response_time = statistics.mean(m.response_time for m in recent_metrics)
        avg_error_rate = statistics.mean(m.error_rate for m in recent_metrics)
        
        # ì‹œìŠ¤í…œ ë¶€í•˜ ì ìˆ˜ ê³„ì‚°
        load_score = (
            avg_cpu * 0.3 +
            avg_memory * 0.2 +
            min(avg_response_time / 1000, 1.0) * 0.3 +
            avg_error_rate * 0.2
        )
        
        # ì¡°ì • ê³„ìˆ˜ ì„¤ì •
        if load_score > 0.8:
            self.adjustment_factor = max(0.5, self.adjustment_factor - 0.1)
        elif load_score < 0.4:
            self.adjustment_factor = min(1.5, self.adjustment_factor + 0.1)
        else:
            self.adjustment_factor = 1.0
            
    def _adjust_limits(self):
        """ë¦¬ë°‹ ì¡°ì •"""
        for key, base_limit in self.base_limits.items():
            adjusted_limit = int(base_limit * self.adjustment_factor)
            self.current_limits[key] = max(1, adjusted_limit)
            
    def get_current_limit(self, key: str) -> int:
        """í˜„ì¬ ë¦¬ë°‹ ì¡°íšŒ"""
        return self.current_limits.get(key, self.base_limits.get(key, 100))
        
    def get_status(self) -> Dict:
        """ìƒíƒœ ì¡°íšŒ"""
        return {
            "adjustment_factor": self.adjustment_factor,
            "base_limits": self.base_limits,
            "current_limits": self.current_limits,
            "metrics_count": len(self.metrics_history)
        }
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] í† í° ë²„í‚· ì•Œê³ ë¦¬ì¦˜
- [ ] ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì¹´ìš´í„°
- [ ] ë¶„ì‚° ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ…
- [ ] ì ì‘í˜• ìŠ¤ë¡œí‹€ë§

---

## Task 6.21: API ìºì‹± ì „ëµ

### Task 6.21.1: Response Cache

```python
# src/api/cache/response_cache.py
from typing import Optional, Dict, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
import hashlib
import json

@dataclass
class CacheEntry:
    """ìºì‹œ ì—”íŠ¸ë¦¬"""
    key: str
    value: Any
    created_at: datetime
    expires_at: datetime
    hit_count: int = 0
    
class ResponseCache:
    """ì‘ë‹µ ìºì‹œ"""
    
    def __init__(self, default_ttl: timedelta = timedelta(minutes=5)):
        self.cache: Dict[str, CacheEntry] = {}
        self.default_ttl = default_ttl
        
    def generate_key(
        self,
        method: str,
        path: str,
        params: Dict = None,
        headers: Dict = None
    ) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = {
            "method": method,
            "path": path,
            "params": params or {},
            "headers": headers or {}
        }
        
        key_str = json.dumps(key_data, sort_keys=True)
        return hashlib.md5(key_str.encode()).hexdigest()
        
    async def get(
        self,
        key: str
    ) -> Optional[Any]:
        """ìºì‹œ ì¡°íšŒ"""
        entry = self.cache.get(key)
        
        if not entry:
            return None
            
        # ë§Œë£Œ í™•ì¸
        if datetime.utcnow() > entry.expires_at:
            del self.cache[key]
            return None
            
        # íˆíŠ¸ ì¹´ìš´íŠ¸ ì¦ê°€
        entry.hit_count += 1
        
        return entry.value
        
    async def set(
        self,
        key: str,
        value: Any,
        ttl: Optional[timedelta] = None
    ):
        """ìºì‹œ ì €ì¥"""
        ttl = ttl or self.default_ttl
        now = datetime.utcnow()
        
        self.cache[key] = CacheEntry(
            key=key,
            value=value,
            created_at=now,
            expires_at=now + ttl,
            hit_count=0
        )
        
    async def invalidate(self, pattern: str = "*"):
        """ìºì‹œ ë¬´íš¨í™”"""
        if pattern == "*":
            self.cache.clear()
        else:
            keys_to_delete = [
                key for key in self.cache.keys()
                if self._match_pattern(key, pattern)
            ]
            for key in keys_to_delete:
                del self.cache[key]
```

### Task 6.21.2: CDN Integration

```python
# src/api/cache/cdn_integration.py
from typing import Dict, Optional, List
from dataclasses import dataclass
import aiohttp

@dataclass
class CDNConfig:
    """CDN ì„¤ì •"""
    provider: str
    api_key: str
    zone_id: str
    base_url: str
    
class CDNManager:
    """CDN ê´€ë¦¬ì"""
    
    def __init__(self, config: CDNConfig):
        self.config = config
        self.session = None
        
    async def initialize(self):
        """ì´ˆê¸°í™”"""
        self.session = aiohttp.ClientSession(
            headers={
                "Authorization": f"Bearer {self.config.api_key}"
            }
        )
        
    async def purge_cache(
        self,
        urls: List[str] = None,
        tags: List[str] = None
    ):
        """CDN ìºì‹œ í¼ì§€"""
        if self.config.provider == "cloudflare":
            return await self._purge_cloudflare(urls, tags)
        elif self.config.provider == "fastly":
            return await self._purge_fastly(urls, tags)
            
    async def _purge_cloudflare(
        self,
        urls: List[str] = None,
        tags: List[str] = None
    ):
        """Cloudflare ìºì‹œ í¼ì§€"""
        endpoint = f"https://api.cloudflare.com/client/v4/zones/{self.config.zone_id}/purge_cache"
        
        data = {}
        if urls:
            data["files"] = urls
        if tags:
            data["tags"] = tags
        if not data:
            data["purge_everything"] = True
            
        async with self.session.post(endpoint, json=data) as response:
            return await response.json()
            
    async def set_cache_headers(
        self,
        path: str,
        max_age: int,
        s_maxage: int = None
    ) -> Dict:
        """ìºì‹œ í—¤ë” ì„¤ì •"""
        headers = {
            "Cache-Control": f"public, max-age={max_age}"
        }
        
        if s_maxage:
            headers["Cache-Control"] += f", s-maxage={s_maxage}"
            
        headers["CDN-Cache-Control"] = f"max-age={s_maxage or max_age}"
        
        return headers
```

### Task 6.21.3: Cache Invalidation

```python
# src/api/cache/invalidation.py
from typing import List, Dict, Set, Callable
from dataclasses import dataclass
from datetime import datetime
import asyncio

@dataclass
class InvalidationRule:
    """ë¬´íš¨í™” ê·œì¹™"""
    name: str
    pattern: str
    dependencies: List[str]
    cascade: bool = False
    
class CacheInvalidator:
    """ìºì‹œ ë¬´íš¨í™”ê¸°"""
    
    def __init__(self):
        self.rules: Dict[str, InvalidationRule] = {}
        self.dependencies: Dict[str, Set[str]] = {}
        self.invalidation_queue: asyncio.Queue = asyncio.Queue()
        
    def add_rule(self, rule: InvalidationRule):
        """ë¬´íš¨í™” ê·œì¹™ ì¶”ê°€"""
        self.rules[rule.name] = rule
        
        # ì˜ì¡´ì„± ë§µí•‘
        for dep in rule.dependencies:
            if dep not in self.dependencies:
                self.dependencies[dep] = set()
            self.dependencies[dep].add(rule.name)
            
    async def invalidate(
        self,
        key: str,
        cascade: bool = True
    ):
        """ìºì‹œ ë¬´íš¨í™”"""
        await self.invalidation_queue.put({
            "key": key,
            "cascade": cascade,
            "timestamp": datetime.utcnow()
        })
        
        if cascade:
            await self._cascade_invalidation(key)
            
    async def _cascade_invalidation(self, key: str):
        """ê³„ë‹¨ì‹ ë¬´íš¨í™”"""
        if key in self.dependencies:
            for dependent in self.dependencies[key]:
                await self.invalidation_queue.put({
                    "key": dependent,
                    "cascade": True,
                    "timestamp": datetime.utcnow()
                })
                
    async def process_invalidations(self):
        """ë¬´íš¨í™” ì²˜ë¦¬"""
        while True:
            item = await self.invalidation_queue.get()
            
            # ì‹¤ì œ ë¬´íš¨í™” ìˆ˜í–‰
            await self._perform_invalidation(item)
            
    async def _perform_invalidation(self, item: Dict):
        """ì‹¤ì œ ë¬´íš¨í™” ìˆ˜í–‰"""
        # ë¡œì»¬ ìºì‹œ ë¬´íš¨í™”
        # CDN ìºì‹œ ë¬´íš¨í™”
        # ë°ì´í„°ë² ì´ìŠ¤ ìºì‹œ ë¬´íš¨í™”
        pass
```

### Task 6.21.4: Edge Caching

```python
# src/api/cache/edge_cache.py
from typing import Dict, Optional, List
from dataclasses import dataclass
import asyncio

@dataclass
class EdgeLocation:
    """ì—£ì§€ ìœ„ì¹˜"""
    id: str
    region: str
    endpoint: str
    latency: float
    
class EdgeCacheManager:
    """ì—£ì§€ ìºì‹œ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.locations: Dict[str, EdgeLocation] = {}
        self.cache_policies: Dict[str, Dict] = {}
        
    def add_location(self, location: EdgeLocation):
        """ì—£ì§€ ìœ„ì¹˜ ì¶”ê°€"""
        self.locations[location.id] = location
        
    async def distribute_cache(
        self,
        key: str,
        value: Any,
        locations: List[str] = None
    ):
        """ìºì‹œ ë¶„ì‚°"""
        target_locations = locations or list(self.locations.keys())
        
        tasks = [
            self._push_to_edge(loc_id, key, value)
            for loc_id in target_locations
        ]
        
        await asyncio.gather(*tasks)
        
    async def _push_to_edge(
        self,
        location_id: str,
        key: str,
        value: Any
    ):
        """ì—£ì§€ë¡œ í‘¸ì‹œ"""
        location = self.locations.get(location_id)
        if not location:
            return
            
        # ì—£ì§€ ìºì‹œ ì—…ë°ì´íŠ¸
        async with aiohttp.ClientSession() as session:
            await session.post(
                f"{location.endpoint}/cache",
                json={"key": key, "value": value}
            )
            
    def get_optimal_location(self, client_region: str) -> Optional[EdgeLocation]:
        """ìµœì  ìœ„ì¹˜ ì„ íƒ"""
        best_location = None
        min_latency = float('inf')
        
        for location in self.locations.values():
            if location.region == client_region:
                return location
                
            if location.latency < min_latency:
                min_latency = location.latency
                best_location = location
                
        return best_location
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì‘ë‹µ ìºì‹œ
- [ ] CDN í†µí•©
- [ ] ìºì‹œ ë¬´íš¨í™”
- [ ] ì—£ì§€ ìºì‹±

---

## Task 6.22: ì‘ë‹µ ì••ì¶• ë° ìµœì í™”

### Task 6.22.1: Compression Algorithms

```python
# src/api/compression/algorithms.py
import gzip
import brotli
import zlib
from typing import bytes, Optional, Dict
from enum import Enum

class CompressionType(Enum):
    """ì••ì¶• íƒ€ì…"""
    GZIP = "gzip"
    BROTLI = "br"
    DEFLATE = "deflate"
    NONE = "identity"
    
class CompressionHandler:
    """ì••ì¶• í•¸ë“¤ëŸ¬"""
    
    def __init__(self):
        self.algorithms = {
            CompressionType.GZIP: self._gzip_compress,
            CompressionType.BROTLI: self._brotli_compress,
            CompressionType.DEFLATE: self._deflate_compress
        }
        
    def compress(
        self,
        data: bytes,
        algorithm: CompressionType,
        level: int = 6
    ) -> bytes:
        """ë°ì´í„° ì••ì¶•"""
        if algorithm == CompressionType.NONE:
            return data
            
        compressor = self.algorithms.get(algorithm)
        if not compressor:
            raise ValueError(f"Unsupported algorithm: {algorithm}")
            
        return compressor(data, level)
        
    def _gzip_compress(self, data: bytes, level: int) -> bytes:
        """GZIP ì••ì¶•"""
        return gzip.compress(data, compresslevel=level)
        
    def _brotli_compress(self, data: bytes, level: int) -> bytes:
        """Brotli ì••ì¶•"""
        return brotli.compress(data, quality=level)
        
    def _deflate_compress(self, data: bytes, level: int) -> bytes:
        """Deflate ì••ì¶•"""
        return zlib.compress(data, level)
        
    def decompress(
        self,
        data: bytes,
        algorithm: CompressionType
    ) -> bytes:
        """ë°ì´í„° ì••ì¶• í•´ì œ"""
        if algorithm == CompressionType.GZIP:
            return gzip.decompress(data)
        elif algorithm == CompressionType.BROTLI:
            return brotli.decompress(data)
        elif algorithm == CompressionType.DEFLATE:
            return zlib.decompress(data)
        else:
            return data
            
    def get_compression_ratio(self, original: bytes, compressed: bytes) -> float:
        """ì••ì¶•ë¥  ê³„ì‚°"""
        return 1 - (len(compressed) / len(original))
```

### Task 6.22.2: Payload Optimization

```python
# src/api/compression/payload_optimizer.py
from typing import Dict, Any, List, Optional
import json

class PayloadOptimizer:
    """í˜ì´ë¡œë“œ ìµœì í™”ê¸°"""
    
    def __init__(self):
        self.field_mappings: Dict[str, str] = {}
        self.excluded_fields: Set[str] = set()
        
    def optimize_json(
        self,
        data: Dict,
        minify: bool = True,
        exclude_nulls: bool = True
    ) -> str:
        """JSON ìµœì í™”"""
        optimized = self._optimize_dict(data, exclude_nulls)
        
        if minify:
            return json.dumps(optimized, separators=(',', ':'))
        else:
            return json.dumps(optimized)
            
    def _optimize_dict(
        self,
        data: Dict,
        exclude_nulls: bool
    ) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ ìµœì í™”"""
        result = {}
        
        for key, value in data.items():
            # ì œì™¸ í•„ë“œ í™•ì¸
            if key in self.excluded_fields:
                continue
                
            # null ì œì™¸
            if exclude_nulls and value is None:
                continue
                
            # í•„ë“œ ë§¤í•‘
            mapped_key = self.field_mappings.get(key, key)
            
            # ì¬ê·€ì  ìµœì í™”
            if isinstance(value, dict):
                result[mapped_key] = self._optimize_dict(value, exclude_nulls)
            elif isinstance(value, list):
                result[mapped_key] = [
                    self._optimize_dict(item, exclude_nulls) if isinstance(item, dict) else item
                    for item in value
                ]
            else:
                result[mapped_key] = value
                
        return result
        
    def create_field_mapping(self, verbose_to_short: Dict[str, str]):
        """í•„ë“œ ë§¤í•‘ ìƒì„±"""
        self.field_mappings = verbose_to_short
        
    def batch_optimize(
        self,
        items: List[Dict],
        dedup: bool = True
    ) -> List[Dict]:
        """ë°°ì¹˜ ìµœì í™”"""
        if dedup:
            # ì¤‘ë³µ ì œê±°
            seen = set()
            unique_items = []
            
            for item in items:
                item_hash = hash(json.dumps(item, sort_keys=True))
                if item_hash not in seen:
                    seen.add(item_hash)
                    unique_items.append(item)
                    
            items = unique_items
            
        return [self._optimize_dict(item, True) for item in items]
```

### Task 6.22.3: Image Optimization

```python
# src/api/compression/image_optimizer.py
from PIL import Image
from typing import Tuple, Optional
import io

class ImageOptimizer:
    """ì´ë¯¸ì§€ ìµœì í™”ê¸°"""
    
    def __init__(self):
        self.quality_presets = {
            "high": 95,
            "medium": 85,
            "low": 75,
            "thumbnail": 60
        }
        
    def optimize_image(
        self,
        image_data: bytes,
        format: str = "JPEG",
        quality: str = "medium",
        max_size: Optional[Tuple[int, int]] = None
    ) -> bytes:
        """ì´ë¯¸ì§€ ìµœì í™”"""
        # ì´ë¯¸ì§€ ì—´ê¸°
        img = Image.open(io.BytesIO(image_data))
        
        # í¬ê¸° ì¡°ì •
        if max_size:
            img.thumbnail(max_size, Image.LANCZOS)
            
        # ìµœì í™” ì˜µì…˜
        save_kwargs = {
            "format": format,
            "optimize": True
        }
        
        if format in ["JPEG", "WEBP"]:
            save_kwargs["quality"] = self.quality_presets.get(quality, 85)
            save_kwargs["progressive"] = True
            
        # ì €ì¥
        output = io.BytesIO()
        img.save(output, **save_kwargs)
        
        return output.getvalue()
        
    def convert_format(
        self,
        image_data: bytes,
        target_format: str
    ) -> bytes:
        """í¬ë§· ë³€í™˜"""
        img = Image.open(io.BytesIO(image_data))
        
        output = io.BytesIO()
        img.save(output, format=target_format)
        
        return output.getvalue()
        
    def generate_responsive_images(
        self,
        image_data: bytes,
        sizes: List[Tuple[int, int]]
    ) -> Dict[str, bytes]:
        """ë°˜ì‘í˜• ì´ë¯¸ì§€ ìƒì„±"""
        img = Image.open(io.BytesIO(image_data))
        result = {}
        
        for width, height in sizes:
            resized = img.copy()
            resized.thumbnail((width, height), Image.LANCZOS)
            
            output = io.BytesIO()
            resized.save(output, format="WEBP", optimize=True, quality=85)
            
            result[f"{width}x{height}"] = output.getvalue()
            
        return result
```

### Task 6.22.4: Streaming Compression

```python
# src/api/compression/streaming.py
import asyncio
from typing import AsyncIterator, Optional
import gzip

class StreamingCompressor:
    """ìŠ¤íŠ¸ë¦¬ë° ì••ì¶•ê¸°"""
    
    def __init__(self, chunk_size: int = 8192):
        self.chunk_size = chunk_size
        
    async def compress_stream(
        self,
        input_stream: AsyncIterator[bytes],
        algorithm: str = "gzip"
    ) -> AsyncIterator[bytes]:
        """ìŠ¤íŠ¸ë¦¼ ì••ì¶•"""
        if algorithm == "gzip":
            compressor = gzip.GzipFile(mode='wb')
            
            async for chunk in input_stream:
                compressed = compressor.compress(chunk)
                if compressed:
                    yield compressed
                    
            # ë‚¨ì€ ë°ì´í„° í”ŒëŸ¬ì‹œ
            final = compressor.flush()
            if final:
                yield final
                
    async def decompress_stream(
        self,
        input_stream: AsyncIterator[bytes],
        algorithm: str = "gzip"
    ) -> AsyncIterator[bytes]:
        """ìŠ¤íŠ¸ë¦¼ ì••ì¶• í•´ì œ"""
        if algorithm == "gzip":
            decompressor = gzip.GzipFile(mode='rb')
            
            async for chunk in input_stream:
                decompressed = decompressor.decompress(chunk)
                if decompressed:
                    yield decompressed
                    
    async def adaptive_compression(
        self,
        input_stream: AsyncIterator[bytes],
        threshold: int = 1024
    ) -> AsyncIterator[bytes]:
        """ì ì‘í˜• ì••ì¶•"""
        buffer = b""
        
        async for chunk in input_stream:
            buffer += chunk
            
            if len(buffer) >= threshold:
                # ì••ì¶• íš¨ìœ¨ í™•ì¸
                compressed = gzip.compress(buffer)
                
                if len(compressed) < len(buffer) * 0.9:
                    # ì••ì¶• íš¨ê³¼ê°€ ìˆìœ¼ë©´ ì••ì¶•
                    yield compressed
                else:
                    # ì••ì¶• íš¨ê³¼ê°€ ì—†ìœ¼ë©´ ì›ë³¸
                    yield buffer
                    
                buffer = b""
                
        # ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
        if buffer:
            yield gzip.compress(buffer)
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì••ì¶• ì•Œê³ ë¦¬ì¦˜
- [ ] í˜ì´ë¡œë“œ ìµœì í™”
- [ ] ì´ë¯¸ì§€ ìµœì í™”
- [ ] ìŠ¤íŠ¸ë¦¬ë° ì••ì¶•

---

## Task 6.23: ë¹„ë™ê¸° ì²˜ë¦¬ ë° íì‰

### Task 6.23.1: Job Queue System

```python
# src/api/queue/job_queue.py
from typing import Dict, Any, Optional, Callable, List
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import asyncio
import uuid

class JobStatus(Enum):
    """ì‘ì—… ìƒíƒœ"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class Job:
    """ì‘ì—…"""
    id: str
    type: str
    payload: Dict[str, Any]
    status: JobStatus = JobStatus.PENDING
    priority: int = 0
    created_at: datetime = field(default_factory=datetime.utcnow)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    result: Optional[Any] = None
    error: Optional[str] = None
    retries: int = 0
    max_retries: int = 3

class JobQueue:
    """ì‘ì—… í"""
    
    def __init__(self):
        self.queues: Dict[str, asyncio.PriorityQueue] = {}
        self.jobs: Dict[str, Job] = {}
        self.handlers: Dict[str, Callable] = {}
        
    def create_queue(self, name: str, max_size: int = 0):
        """í ìƒì„±"""
        self.queues[name] = asyncio.PriorityQueue(maxsize=max_size)
        
    async def enqueue(
        self,
        queue_name: str,
        job_type: str,
        payload: Dict[str, Any],
        priority: int = 0
    ) -> str:
        """ì‘ì—… ì¶”ê°€"""
        job = Job(
            id=str(uuid.uuid4()),
            type=job_type,
            payload=payload,
            priority=priority
        )
        
        self.jobs[job.id] = job
        
        queue = self.queues.get(queue_name)
        if not queue:
            self.create_queue(queue_name)
            queue = self.queues[queue_name]
            
        await queue.put((-priority, job.created_at, job.id))
        
        return job.id
        
    async def dequeue(self, queue_name: str) -> Optional[Job]:
        """ì‘ì—… ê°€ì ¸ì˜¤ê¸°"""
        queue = self.queues.get(queue_name)
        if not queue:
            return None
            
        try:
            _, _, job_id = await queue.get()
            return self.jobs.get(job_id)
        except asyncio.QueueEmpty:
            return None
            
    def register_handler(self, job_type: str, handler: Callable):
        """í•¸ë“¤ëŸ¬ ë“±ë¡"""
        self.handlers[job_type] = handler
        
    async def process_job(self, job: Job):
        """ì‘ì—… ì²˜ë¦¬"""
        handler = self.handlers.get(job.type)
        if not handler:
            job.status = JobStatus.FAILED
            job.error = f"No handler for job type: {job.type}"
            return
            
        job.status = JobStatus.RUNNING
        job.started_at = datetime.utcnow()
        
        try:
            result = await handler(job.payload)
            job.result = result
            job.status = JobStatus.COMPLETED
            job.completed_at = datetime.utcnow()
        except Exception as e:
            job.status = JobStatus.FAILED
            job.error = str(e)
            job.retries += 1
            
            if job.retries < job.max_retries:
                # ì¬ì‹œë„
                job.status = JobStatus.PENDING
```

### Task 6.23.2: Background Workers

```python
# src/api/queue/workers.py
from typing import List, Dict, Optional
import asyncio
from dataclasses import dataclass

@dataclass
class WorkerConfig:
    """ì›Œì»¤ ì„¤ì •"""
    name: str
    queue_name: str
    concurrency: int = 1
    poll_interval: float = 1.0
    
class Worker:
    """ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤"""
    
    def __init__(self, config: WorkerConfig, job_queue: JobQueue):
        self.config = config
        self.job_queue = job_queue
        self.running = False
        self.tasks: List[asyncio.Task] = []
        
    async def start(self):
        """ì›Œì»¤ ì‹œì‘"""
        self.running = True
        
        for i in range(self.config.concurrency):
            task = asyncio.create_task(
                self._worker_loop(f"{self.config.name}-{i}")
            )
            self.tasks.append(task)
            
    async def stop(self):
        """ì›Œì»¤ ì¤‘ì§€"""
        self.running = False
        
        for task in self.tasks:
            task.cancel()
            
        await asyncio.gather(*self.tasks, return_exceptions=True)
        self.tasks.clear()
        
    async def _worker_loop(self, worker_id: str):
        """ì›Œì»¤ ë£¨í”„"""
        while self.running:
            try:
                job = await self.job_queue.dequeue(self.config.queue_name)
                
                if job:
                    await self.job_queue.process_job(job)
                else:
                    await asyncio.sleep(self.config.poll_interval)
                    
            except Exception as e:
                # ì—ëŸ¬ ë¡œê¹…
                await asyncio.sleep(self.config.poll_interval)

class WorkerPool:
    """ì›Œì»¤ í’€"""
    
    def __init__(self):
        self.workers: Dict[str, Worker] = {}
        
    def add_worker(self, worker: Worker):
        """ì›Œì»¤ ì¶”ê°€"""
        self.workers[worker.config.name] = worker
        
    async def start_all(self):
        """ëª¨ë“  ì›Œì»¤ ì‹œì‘"""
        for worker in self.workers.values():
            await worker.start()
            
    async def stop_all(self):
        """ëª¨ë“  ì›Œì»¤ ì¤‘ì§€"""
        for worker in self.workers.values():
            await worker.stop()
            
    def scale_worker(self, name: str, concurrency: int):
        """ì›Œì»¤ ìŠ¤ì¼€ì¼ë§"""
        worker = self.workers.get(name)
        if worker:
            worker.config.concurrency = concurrency
```

### Task 6.23.3: Event Bus

```python
# src/api/queue/event_bus.py
from typing import Dict, List, Callable, Any
from dataclasses import dataclass
import asyncio

@dataclass
class Event:
    """ì´ë²¤íŠ¸"""
    type: str
    data: Any
    source: str
    timestamp: datetime
    
class EventBus:
    """ì´ë²¤íŠ¸ ë²„ìŠ¤"""
    
    def __init__(self):
        self.subscribers: Dict[str, List[Callable]] = {}
        self.event_queue: asyncio.Queue = asyncio.Queue()
        self.filters: Dict[str, Callable] = {}
        
    def subscribe(
        self,
        event_type: str,
        handler: Callable,
        filter_func: Optional[Callable] = None
    ):
        """ì´ë²¤íŠ¸ êµ¬ë…"""
        if event_type not in self.subscribers:
            self.subscribers[event_type] = []
            
        self.subscribers[event_type].append(handler)
        
        if filter_func:
            handler_id = id(handler)
            self.filters[handler_id] = filter_func
            
    def unsubscribe(self, event_type: str, handler: Callable):
        """êµ¬ë… í•´ì œ"""
        if event_type in self.subscribers:
            self.subscribers[event_type].remove(handler)
            
        handler_id = id(handler)
        if handler_id in self.filters:
            del self.filters[handler_id]
            
    async def publish(
        self,
        event_type: str,
        data: Any,
        source: str = "system"
    ):
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        event = Event(
            type=event_type,
            data=data,
            source=source,
            timestamp=datetime.utcnow()
        )
        
        await self.event_queue.put(event)
        
    async def process_events(self):
        """ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        while True:
            event = await self.event_queue.get()
            
            handlers = self.subscribers.get(event.type, [])
            
            for handler in handlers:
                # í•„í„° í™•ì¸
                handler_id = id(handler)
                filter_func = self.filters.get(handler_id)
                
                if filter_func and not filter_func(event):
                    continue
                    
                # ë¹„ë™ê¸° ì²˜ë¦¬
                asyncio.create_task(self._handle_event(handler, event))
                
    async def _handle_event(self, handler: Callable, event: Event):
        """ì´ë²¤íŠ¸ í•¸ë“¤ë§"""
        try:
            await handler(event)
        except Exception as e:
            # ì—ëŸ¬ ì²˜ë¦¬
            await self.publish(
                "event.error",
                {"event": event, "error": str(e)},
                "event_bus"
            )
```

### Task 6.23.4: Dead Letter Queue

```python
# src/api/queue/dead_letter.py
from typing import Dict, List, Optional
from dataclasses import dataclass, field
from datetime import datetime

@dataclass
class DeadLetter:
    """ë°ë“œ ë ˆí„°"""
    id: str
    original_queue: str
    job: Job
    error: str
    attempts: int
    created_at: datetime = field(default_factory=datetime.utcnow)
    
class DeadLetterQueue:
    """ë°ë“œ ë ˆí„° í"""
    
    def __init__(self, max_size: int = 10000):
        self.queue: asyncio.Queue = asyncio.Queue(maxsize=max_size)
        self.letters: Dict[str, DeadLetter] = {}
        self.retry_policies: Dict[str, Dict] = {}
        
    async def add(
        self,
        job: Job,
        queue_name: str,
        error: str
    ):
        """ë°ë“œ ë ˆí„° ì¶”ê°€"""
        letter = DeadLetter(
            id=str(uuid.uuid4()),
            original_queue=queue_name,
            job=job,
            error=error,
            attempts=job.retries
        )
        
        self.letters[letter.id] = letter
        await self.queue.put(letter)
        
    async def retry(
        self,
        letter_id: str,
        job_queue: JobQueue
    ) -> bool:
        """ì¬ì‹œë„"""
        letter = self.letters.get(letter_id)
        if not letter:
            return False
            
        # ì¬ì‹œë„ ì •ì±… í™•ì¸
        policy = self.retry_policies.get(letter.job.type, {})
        max_retries = policy.get("max_retries", 3)
        
        if letter.attempts >= max_retries:
            return False
            
        # ì‘ì—… ì¬ì¶”ê°€
        await job_queue.enqueue(
            letter.original_queue,
            letter.job.type,
            letter.job.payload,
            letter.job.priority
        )
        
        # DLQì—ì„œ ì œê±°
        del self.letters[letter_id]
        
        return True
        
    async def process_dlq(self, job_queue: JobQueue):
        """DLQ ì²˜ë¦¬"""
        while True:
            try:
                letter = await asyncio.wait_for(
                    self.queue.get(),
                    timeout=10.0
                )
                
                # ì¬ì‹œë„ ì •ì±…ì— ë”°ë¼ ì²˜ë¦¬
                policy = self.retry_policies.get(letter.job.type, {})
                
                if policy.get("auto_retry", False):
                    delay = policy.get("retry_delay", 60)
                    await asyncio.sleep(delay)
                    await self.retry(letter.id, job_queue)
                    
            except asyncio.TimeoutError:
                continue
                
    def get_statistics(self) -> Dict:
        """í†µê³„ ì¡°íšŒ"""
        stats = {
            "total": len(self.letters),
            "by_queue": {},
            "by_type": {},
            "by_error": {}
        }
        
        for letter in self.letters.values():
            # íë³„ í†µê³„
            queue = letter.original_queue
            stats["by_queue"][queue] = stats["by_queue"].get(queue, 0) + 1
            
            # íƒ€ì…ë³„ í†µê³„
            job_type = letter.job.type
            stats["by_type"][job_type] = stats["by_type"].get(job_type, 0) + 1
            
            # ì—ëŸ¬ë³„ í†µê³„
            error = letter.error[:50]  # ì—ëŸ¬ ë©”ì‹œì§€ ì¶•ì•½
            stats["by_error"][error] = stats["by_error"].get(error, 0) + 1
            
        return stats
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ì‘ì—… í ì‹œìŠ¤í…œ
- [ ] ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤
- [ ] ì´ë²¤íŠ¸ ë²„ìŠ¤
- [ ] ë°ë“œ ë ˆí„° í

---

## Task 6.24: API ë¬¸ì„œ ìë™ ìƒì„± (OpenAPI/Swagger)

### Task 6.24.1: OpenAPI Schema Generation

```python
# src/api/docs/openapi_generator.py
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import inspect

@dataclass
class OpenAPIInfo:
    """OpenAPI ì •ë³´"""
    title: str
    version: str
    description: str
    contact: Dict = None
    license: Dict = None
    
class OpenAPIGenerator:
    """OpenAPI ìŠ¤í‚¤ë§ˆ ìƒì„±ê¸°"""
    
    def __init__(self, info: OpenAPIInfo):
        self.info = info
        self.paths: Dict[str, Dict] = {}
        self.components: Dict[str, Any] = {
            "schemas": {},
            "securitySchemes": {},
            "parameters": {}
        }
        
    def generate_schema(self) -> Dict:
        """OpenAPI ìŠ¤í‚¤ë§ˆ ìƒì„±"""
        return {
            "openapi": "3.0.0",
            "info": {
                "title": self.info.title,
                "version": self.info.version,
                "description": self.info.description,
                "contact": self.info.contact,
                "license": self.info.license
            },
            "paths": self.paths,
            "components": self.components
        }
        
    def add_path(
        self,
        path: str,
        method: str,
        operation: Dict
    ):
        """ê²½ë¡œ ì¶”ê°€"""
        if path not in self.paths:
            self.paths[path] = {}
            
        self.paths[path][method.lower()] = operation
        
    def add_schema(self, name: str, schema: Dict):
        """ìŠ¤í‚¤ë§ˆ ì¶”ê°€"""
        self.components["schemas"][name] = schema
        
    def generate_from_function(self, func: Callable) -> Dict:
        """í•¨ìˆ˜ì—ì„œ ìƒì„±"""
        signature = inspect.signature(func)
        doc = inspect.getdoc(func) or ""
        
        operation = {
            "summary": doc.split("\n")[0] if doc else func.__name__,
            "description": doc,
            "parameters": [],
            "responses": {}
        }
        
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        for param_name, param in signature.parameters.items():
            if param_name in ["self", "cls"]:
                continue
                
            param_schema = self._get_param_schema(param)
            operation["parameters"].append({
                "name": param_name,
                "in": "query",
                "schema": param_schema,
                "required": param.default == inspect.Parameter.empty
            })
            
        # ì‘ë‹µ ìŠ¤í‚¤ë§ˆ
        return_annotation = signature.return_annotation
        if return_annotation != inspect.Signature.empty:
            operation["responses"]["200"] = {
                "description": "Successful response",
                "content": {
                    "application/json": {
                        "schema": self._get_type_schema(return_annotation)
                    }
                }
            }
            
        return operation
        
    def _get_param_schema(self, param: inspect.Parameter) -> Dict:
        """íŒŒë¼ë¯¸í„° ìŠ¤í‚¤ë§ˆ ê°€ì ¸ì˜¤ê¸°"""
        if param.annotation != inspect.Parameter.empty:
            return self._get_type_schema(param.annotation)
        return {"type": "string"}
        
    def _get_type_schema(self, type_hint: Any) -> Dict:
        """íƒ€ì… ìŠ¤í‚¤ë§ˆ ê°€ì ¸ì˜¤ê¸°"""
        if type_hint == str:
            return {"type": "string"}
        elif type_hint == int:
            return {"type": "integer"}
        elif type_hint == float:
            return {"type": "number"}
        elif type_hint == bool:
            return {"type": "boolean"}
        elif hasattr(type_hint, "__origin__"):
            # Generic types
            if type_hint.__origin__ == list:
                return {
                    "type": "array",
                    "items": self._get_type_schema(type_hint.__args__[0])
                }
            elif type_hint.__origin__ == dict:
                return {"type": "object"}
        return {"type": "object"}
```

### Task 6.24.2: Swagger UI Integration

```python
# src/api/docs/swagger_ui.py
from fastapi import FastAPI
from fastapi.openapi.utils import get_openapi
from fastapi.openapi.docs import get_swagger_ui_html

class SwaggerUI:
    """Swagger UI í†µí•©"""
    
    def __init__(self, app: FastAPI):
        self.app = app
        self.setup_routes()
        
    def setup_routes(self):
        """ë¼ìš°íŠ¸ ì„¤ì •"""
        
        @self.app.get("/docs", include_in_schema=False)
        async def swagger_ui():
            return get_swagger_ui_html(
                openapi_url="/openapi.json",
                title=f"{self.app.title} - Swagger UI",
                oauth2_redirect_url="/docs/oauth2-redirect",
                swagger_js_url="/static/swagger-ui-bundle.js",
                swagger_css_url="/static/swagger-ui.css"
            )
            
        @self.app.get("/openapi.json", include_in_schema=False)
        async def openapi_schema():
            return self.get_openapi_schema()
            
    def get_openapi_schema(self) -> Dict:
        """OpenAPI ìŠ¤í‚¤ë§ˆ ê°€ì ¸ì˜¤ê¸°"""
        if not self.app.openapi_schema:
            self.app.openapi_schema = get_openapi(
                title=self.app.title,
                version=self.app.version,
                description=self.app.description,
                routes=self.app.routes
            )
        return self.app.openapi_schema
        
    def customize_swagger_ui(
        self,
        theme: str = "default",
        custom_css: str = None
    ):
        """Swagger UI ì»¤ìŠ¤í„°ë§ˆì´ì§•"""
        
        @self.app.get("/static/custom.css")
        async def custom_css_endpoint():
            css = custom_css or self._get_theme_css(theme)
            return Response(content=css, media_type="text/css")
            
    def _get_theme_css(self, theme: str) -> str:
        """í…Œë§ˆ CSS ê°€ì ¸ì˜¤ê¸°"""
        themes = {
            "dark": """
                .swagger-ui { background: #1a1a1a; }
                .swagger-ui .topbar { background: #2a2a2a; }
            """,
            "blue": """
                .swagger-ui .topbar { background: #0066cc; }
            """
        }
        return themes.get(theme, "")
```

### Task 6.24.3: Example Generation

```python
# src/api/docs/example_generator.py
from typing import Dict, Any, List
import random
import string
from datetime import datetime

class ExampleGenerator:
    """ì˜ˆì œ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.type_generators = {
            "string": self._generate_string,
            "integer": self._generate_integer,
            "number": self._generate_number,
            "boolean": self._generate_boolean,
            "array": self._generate_array,
            "object": self._generate_object
        }
        
    def generate_example(self, schema: Dict) -> Any:
        """ì˜ˆì œ ìƒì„±"""
        if "example" in schema:
            return schema["example"]
            
        if "enum" in schema:
            return random.choice(schema["enum"])
            
        schema_type = schema.get("type", "string")
        generator = self.type_generators.get(schema_type)
        
        if generator:
            return generator(schema)
            
        return None
        
    def _generate_string(self, schema: Dict) -> str:
        """ë¬¸ìì—´ ìƒì„±"""
        if schema.get("format") == "date":
            return datetime.utcnow().date().isoformat()
        elif schema.get("format") == "date-time":
            return datetime.utcnow().isoformat()
        elif schema.get("format") == "email":
            return "user@example.com"
        elif schema.get("format") == "uuid":
            return str(uuid.uuid4())
            
        min_length = schema.get("minLength", 5)
        max_length = schema.get("maxLength", 20)
        length = random.randint(min_length, max_length)
        
        return ''.join(random.choices(string.ascii_letters, k=length))
        
    def _generate_integer(self, schema: Dict) -> int:
        """ì •ìˆ˜ ìƒì„±"""
        minimum = schema.get("minimum", 0)
        maximum = schema.get("maximum", 100)
        return random.randint(minimum, maximum)
        
    def _generate_number(self, schema: Dict) -> float:
        """ìˆ«ì ìƒì„±"""
        minimum = schema.get("minimum", 0.0)
        maximum = schema.get("maximum", 100.0)
        return random.uniform(minimum, maximum)
        
    def _generate_boolean(self, schema: Dict) -> bool:
        """ë¶ˆë¦° ìƒì„±"""
        return random.choice([True, False])
        
    def _generate_array(self, schema: Dict) -> List:
        """ë°°ì—´ ìƒì„±"""
        items_schema = schema.get("items", {})
        min_items = schema.get("minItems", 1)
        max_items = schema.get("maxItems", 5)
        count = random.randint(min_items, max_items)
        
        return [
            self.generate_example(items_schema)
            for _ in range(count)
        ]
        
    def _generate_object(self, schema: Dict) -> Dict:
        """ê°ì²´ ìƒì„±"""
        properties = schema.get("properties", {})
        required = schema.get("required", [])
        
        result = {}
        
        for prop_name, prop_schema in properties.items():
            if prop_name in required or random.random() > 0.5:
                result[prop_name] = self.generate_example(prop_schema)
                
        return result
```

### Task 6.24.4: API Versioning Docs

```python
# src/api/docs/versioning.py
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class APIVersion:
    """API ë²„ì „"""
    version: str
    status: str  # current, deprecated, sunset
    released_at: datetime
    deprecated_at: Optional[datetime] = None
    sunset_at: Optional[datetime] = None
    changes: List[str] = None
    
class VersioningDocumentation:
    """ë²„ì „ ë¬¸ì„œí™”"""
    
    def __init__(self):
        self.versions: Dict[str, APIVersion] = {}
        self.current_version: str = None
        
    def add_version(self, version: APIVersion):
        """ë²„ì „ ì¶”ê°€"""
        self.versions[version.version] = version
        
        if version.status == "current":
            self.current_version = version.version
            
    def generate_version_docs(self) -> Dict:
        """ë²„ì „ ë¬¸ì„œ ìƒì„±"""
        return {
            "current": self.current_version,
            "versions": [
                {
                    "version": v.version,
                    "status": v.status,
                    "released": v.released_at.isoformat(),
                    "deprecated": v.deprecated_at.isoformat() if v.deprecated_at else None,
                    "sunset": v.sunset_at.isoformat() if v.sunset_at else None,
                    "changes": v.changes or []
                }
                for v in self.versions.values()
            ]
        }
        
    def generate_migration_guide(
        self,
        from_version: str,
        to_version: str
    ) -> Dict:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ ìƒì„±"""
        guide = {
            "from": from_version,
            "to": to_version,
            "breaking_changes": [],
            "deprecations": [],
            "new_features": []
        }
        
        # ë³€ê²½ ì‚¬í•­ ìˆ˜ì§‘
        from_v = self.versions.get(from_version)
        to_v = self.versions.get(to_version)
        
        if from_v and to_v:
            # ë²„ì „ ê°„ ë³€ê²½ ì‚¬í•­ ë¶„ì„
            guide["changes"] = to_v.changes or []
            
        return guide
        
    def check_version_compatibility(
        self,
        client_version: str,
        api_version: str
    ) -> Dict:
        """ë²„ì „ í˜¸í™˜ì„± í™•ì¸"""
        client_v = self.versions.get(client_version)
        api_v = self.versions.get(api_version)
        
        if not client_v or not api_v:
            return {"compatible": False, "reason": "Unknown version"}
            
        if client_v.status == "sunset":
            return {"compatible": False, "reason": "Client version is sunset"}
            
        # í˜¸í™˜ì„± ê·œì¹™ í™•ì¸
        major_client = int(client_version.split(".")[0])
        major_api = int(api_version.split(".")[0])
        
        if major_client != major_api:
            return {"compatible": False, "reason": "Major version mismatch"}
            
        return {"compatible": True}
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] OpenAPI ìŠ¤í‚¤ë§ˆ ìƒì„±
- [ ] Swagger UI í†µí•©
- [ ] ì˜ˆì œ ìƒì„±
- [ ] API ë²„ì „ ë¬¸ì„œ

---

## Task 6.25: API í…ŒìŠ¤íŠ¸ ìë™í™”

### Task 6.25.1: Contract Testing

```python
# src/api/testing/contract_testing.py
from typing import Dict, List, Any
from dataclasses import dataclass
import jsonschema

@dataclass
class Contract:
    """API ê³„ì•½"""
    name: str
    request_schema: Dict
    response_schema: Dict
    headers: Dict = None
    
class ContractTester:
    """ê³„ì•½ í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.contracts: Dict[str, Contract] = {}
        self.test_results: List[Dict] = []
        
    def add_contract(self, contract: Contract):
        """ê³„ì•½ ì¶”ê°€"""
        self.contracts[contract.name] = contract
        
    async def test_contract(
        self,
        contract_name: str,
        request_data: Dict,
        response_data: Dict
    ) -> Dict:
        """ê³„ì•½ í…ŒìŠ¤íŠ¸"""
        contract = self.contracts.get(contract_name)
        if not contract:
            return {"passed": False, "error": "Contract not found"}
            
        result = {
            "contract": contract_name,
            "passed": True,
            "errors": []
        }
        
        # ìš”ì²­ ê²€ì¦
        try:
            jsonschema.validate(request_data, contract.request_schema)
        except jsonschema.ValidationError as e:
            result["passed"] = False
            result["errors"].append(f"Request validation failed: {e.message}")
            
        # ì‘ë‹µ ê²€ì¦
        try:
            jsonschema.validate(response_data, contract.response_schema)
        except jsonschema.ValidationError as e:
            result["passed"] = False
            result["errors"].append(f"Response validation failed: {e.message}")
            
        self.test_results.append(result)
        return result
        
    def generate_contract_from_openapi(self, openapi_spec: Dict) -> List[Contract]:
        """OpenAPIì—ì„œ ê³„ì•½ ìƒì„±"""
        contracts = []
        
        for path, methods in openapi_spec.get("paths", {}).items():
            for method, operation in methods.items():
                contract = Contract(
                    name=f"{method.upper()} {path}",
                    request_schema=self._extract_request_schema(operation),
                    response_schema=self._extract_response_schema(operation)
                )
                contracts.append(contract)
                
        return contracts
```

### Task 6.25.2: Load Testing

```python
# src/api/testing/load_testing.py
from typing import Dict, List, Callable
from dataclasses import dataclass
import asyncio
import time
import statistics

@dataclass
class LoadTestConfig:
    """ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì„¤ì •"""
    url: str
    duration: int  # seconds
    users: int
    ramp_up: int  # seconds
    
class LoadTester:
    """ë¶€í•˜ í…ŒìŠ¤í„°"""
    
    def __init__(self, config: LoadTestConfig):
        self.config = config
        self.results: List[Dict] = []
        self.errors: List[str] = []
        
    async def run_test(self, test_func: Callable) -> Dict:
        """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        start_time = time.time()
        end_time = start_time + self.config.duration
        
        # ì‚¬ìš©ì ë¨í”„ì—…
        tasks = []
        for i in range(self.config.users):
            delay = (self.config.ramp_up / self.config.users) * i
            task = asyncio.create_task(
                self._user_simulation(test_func, start_time + delay, end_time)
            )
            tasks.append(task)
            
        await asyncio.gather(*tasks)
        
        return self._analyze_results()
        
    async def _user_simulation(
        self,
        test_func: Callable,
        start_time: float,
        end_time: float
    ):
        """ì‚¬ìš©ì ì‹œë®¬ë ˆì´ì…˜"""
        await asyncio.sleep(max(0, start_time - time.time()))
        
        while time.time() < end_time:
            request_start = time.time()
            
            try:
                await test_func()
                response_time = time.time() - request_start
                
                self.results.append({
                    "timestamp": request_start,
                    "response_time": response_time,
                    "success": True
                })
            except Exception as e:
                self.errors.append(str(e))
                self.results.append({
                    "timestamp": request_start,
                    "response_time": time.time() - request_start,
                    "success": False
                })
                
    def _analyze_results(self) -> Dict:
        """ê²°ê³¼ ë¶„ì„"""
        if not self.results:
            return {"error": "No results"}
            
        response_times = [r["response_time"] for r in self.results if r["success"]]
        success_count = sum(1 for r in self.results if r["success"])
        
        return {
            "total_requests": len(self.results),
            "successful_requests": success_count,
            "failed_requests": len(self.results) - success_count,
            "error_rate": (len(self.results) - success_count) / len(self.results) * 100,
            "avg_response_time": statistics.mean(response_times) if response_times else 0,
            "min_response_time": min(response_times) if response_times else 0,
            "max_response_time": max(response_times) if response_times else 0,
            "percentiles": {
                "p50": statistics.median(response_times) if response_times else 0,
                "p95": self._percentile(response_times, 95) if response_times else 0,
                "p99": self._percentile(response_times, 99) if response_times else 0
            },
            "requests_per_second": len(self.results) / self.config.duration
        }
        
    def _percentile(self, data: List[float], percentile: int) -> float:
        """ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°"""
        size = len(data)
        if size == 0:
            return 0
        sorted_data = sorted(data)
        index = int(size * (percentile / 100))
        return sorted_data[min(index, size - 1)]
```

### Task 6.25.3: Security Testing

```python
# src/api/testing/security_testing.py
from typing import Dict, List, Optional
import re

class SecurityTester:
    """ë³´ì•ˆ í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.vulnerability_checks = {
            "sql_injection": self._check_sql_injection,
            "xss": self._check_xss,
            "csrf": self._check_csrf,
            "auth": self._check_authentication,
            "rate_limiting": self._check_rate_limiting
        }
        
    async def run_security_tests(self, endpoint: str) -> Dict:
        """ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        results = {
            "endpoint": endpoint,
            "vulnerabilities": [],
            "passed": True
        }
        
        for check_name, check_func in self.vulnerability_checks.items():
            result = await check_func(endpoint)
            
            if not result["passed"]:
                results["passed"] = False
                results["vulnerabilities"].append({
                    "type": check_name,
                    "details": result["details"]
                })
                
        return results
        
    async def _check_sql_injection(self, endpoint: str) -> Dict:
        """SQL ì¸ì ì…˜ í™•ì¸"""
        payloads = [
            "' OR '1'='1",
            "1; DROP TABLE users--",
            "' UNION SELECT * FROM users--"
        ]
        
        for payload in payloads:
            # í…ŒìŠ¤íŠ¸ ìš”ì²­ ì „ì†¡
            # ì‘ë‹µ ë¶„ì„
            pass
            
        return {"passed": True, "details": None}
        
    async def _check_xss(self, endpoint: str) -> Dict:
        """XSS í™•ì¸"""
        payloads = [
            "<script>alert('XSS')</script>",
            "<img src=x onerror=alert('XSS')>",
            "javascript:alert('XSS')"
        ]
        
        for payload in payloads:
            # í…ŒìŠ¤íŠ¸ ìš”ì²­ ì „ì†¡
            # ì‘ë‹µì—ì„œ í˜ì´ë¡œë“œ í™•ì¸
            pass
            
        return {"passed": True, "details": None}
        
    async def _check_csrf(self, endpoint: str) -> Dict:
        """CSRF í™•ì¸"""
        # CSRF í† í° í™•ì¸
        # Referer í—¤ë” í™•ì¸
        return {"passed": True, "details": None}
        
    async def _check_authentication(self, endpoint: str) -> Dict:
        """ì¸ì¦ í™•ì¸"""
        # ì¸ì¦ ì—†ì´ ì ‘ê·¼ ì‹œë„
        # ì˜ëª»ëœ í† í°ìœ¼ë¡œ ì ‘ê·¼ ì‹œë„
        return {"passed": True, "details": None}
        
    async def _check_rate_limiting(self, endpoint: str) -> Dict:
        """ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… í™•ì¸"""
        # ë‹¤ìˆ˜ì˜ ìš”ì²­ ì „ì†¡
        # ì‘ë‹µ í™•ì¸
        return {"passed": True, "details": None}
```

### Task 6.25.4: Smoke Testing

```python
# src/api/testing/smoke_testing.py
from typing import Dict, List, Optional
import asyncio
import aiohttp

@dataclass
class SmokeTest:
    """ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸"""
    name: str
    endpoint: str
    method: str = "GET"
    expected_status: int = 200
    timeout: float = 5.0
    
class SmokeTester:
    """ìŠ¤ëª¨í¬ í…ŒìŠ¤í„°"""
    
    def __init__(self, base_url: str):
        self.base_url = base_url
        self.tests: List[SmokeTest] = []
        self.results: List[Dict] = []
        
    def add_test(self, test: SmokeTest):
        """í…ŒìŠ¤íŠ¸ ì¶”ê°€"""
        self.tests.append(test)
        
    async def run_all_tests(self) -> Dict:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        tasks = [self._run_test(test) for test in self.tests]
        results = await asyncio.gather(*tasks)
        
        passed = sum(1 for r in results if r["passed"])
        failed = len(results) - passed
        
        return {
            "total": len(results),
            "passed": passed,
            "failed": failed,
            "success_rate": (passed / len(results) * 100) if results else 0,
            "results": results
        }
        
    async def _run_test(self, test: SmokeTest) -> Dict:
        """ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        result = {
            "test": test.name,
            "passed": False,
            "response_time": None,
            "error": None
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                start_time = time.time()
                
                async with session.request(
                    test.method,
                    f"{self.base_url}{test.endpoint}",
                    timeout=aiohttp.ClientTimeout(total=test.timeout)
                ) as response:
                    result["response_time"] = time.time() - start_time
                    
                    if response.status == test.expected_status:
                        result["passed"] = True
                    else:
                        result["error"] = f"Expected {test.expected_status}, got {response.status}"
                        
        except asyncio.TimeoutError:
            result["error"] = "Request timeout"
        except Exception as e:
            result["error"] = str(e)
            
        self.results.append(result)
        return result
        
    def generate_report(self) -> str:
        """í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = ["Smoke Test Report", "=" * 50]
        
        for result in self.results:
            status = "âœ“" if result["passed"] else "âœ—"
            report.append(f"{status} {result['test']}")
            
            if result["response_time"]:
                report.append(f"  Response time: {result['response_time']:.3f}s")
                
            if result["error"]:
                report.append(f"  Error: {result['error']}")
                
        return "\n".join(report)
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] ê³„ì•½ í…ŒìŠ¤íŠ¸
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸
- [ ] ë³´ì•ˆ í…ŒìŠ¤íŠ¸
- [ ] ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸

---

