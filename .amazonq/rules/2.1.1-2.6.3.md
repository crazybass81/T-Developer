# Phase 2: ë°ì´í„° ë ˆì´ì–´ êµ¬í˜„ - ì „ì²´ SubTask ì‘ì—…ì§€ì‹œ ë¬¸ì„œ

## ğŸ“‹ Phase 2 ê°œìš”
- **ëª©í‘œ**: T-Developerì˜ ë°ì´í„° ì €ì¥, ê²€ìƒ‰, ìºì‹±, ë™ê¸°í™”ë¥¼ ìœ„í•œ í¬ê´„ì ì¸ ë°ì´í„° ë ˆì´ì–´ êµ¬ì¶•
- **ë²”ìœ„**: 15ê°œ Tasks Ã— 4 SubTasks = 60ê°œ ì‘ì—… ë‹¨ìœ„
- **ê¸°ê°„**: ì˜ˆìƒ 6-8ì£¼
- **ì „ì œì¡°ê±´**: Phase 1 ì½”ì–´ ì¸í”„ë¼ ì™„ë£Œ

---

## ğŸ—ï¸ Phase 2 ì „ì²´ Task êµ¬ì¡°

### ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë° êµ¬í˜„ (Tasks 2.1-2.3)
- Task 2.1: DynamoDB í…Œì´ë¸” ì„¤ê³„ ë° êµ¬í˜„
- Task 2.2: ì¸ë±ì‹± ì „ëµ ë° ì¿¼ë¦¬ ìµœì í™”
- Task 2.3: ë°ì´í„° íŒŒí‹°ì…”ë‹ ë° ìƒ¤ë”© ì „ëµ

### ë°ì´í„° ëª¨ë¸ë§ (Tasks 2.4-2.6)
- Task 2.4: ë„ë©”ì¸ ëª¨ë¸ ì •ì˜
- Task 2.5: ë°ì´í„° ê²€ì¦ ë° ìŠ¤í‚¤ë§ˆ ê´€ë¦¬
- Task 2.6: ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ

### ìºì‹± ë ˆì´ì–´ (Tasks 2.7-2.9)
- Task 2.7: Redis ìºì‹± ì‹œìŠ¤í…œ êµ¬ì¶•
- Task 2.8: ìºì‹œ ë¬´íš¨í™” ì „ëµ
- Task 2.9: ë¶„ì‚° ìºì‹± ë° ë™ê¸°í™”

### ë°ì´í„° ì ‘ê·¼ ë ˆì´ì–´ (Tasks 2.10-2.12)
- Task 2.10: Repository íŒ¨í„´ êµ¬í˜„
- Task 2.11: ë°ì´í„° ì ‘ê·¼ ì¶”ìƒí™”
- Task 2.12: íŠ¸ëœì­ì…˜ ê´€ë¦¬

### ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ (Tasks 2.13-2.15)
- Task 2.13: ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ
- Task 2.14: ë³€ê²½ ë°ì´í„° ìº¡ì²˜ (CDC)
- Task 2.15: ë°ì´í„° ë™ê¸°í™” ë©”ì»¤ë‹ˆì¦˜

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 2.1: DynamoDB í…Œì´ë¸” ì„¤ê³„ ë° êµ¬í˜„

#### SubTask 2.1.1: ë‹¨ì¼ í…Œì´ë¸” ì„¤ê³„ (Single Table Design)
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/schemas/single-table-design.ts
export interface TableDesign {
  tableName: string;
  partitionKey: AttributeDefinition;
  sortKey?: AttributeDefinition;
  globalSecondaryIndexes: GSI[];
  localSecondaryIndexes?: LSI[];
  attributes: AttributeDefinition[];
}

export const T_DEVELOPER_TABLE: TableDesign = {
  tableName: 'T-Developer-Main',
  partitionKey: {
    name: 'PK',
    type: 'S',
    description: 'Partition Key - Format: {EntityType}#{EntityId}'
  },
  sortKey: {
    name: 'SK',
    type: 'S', 
    description: 'Sort Key - Format: {RelationType}#{Timestamp}#{Id}'
  },
  globalSecondaryIndexes: [
    {
      indexName: 'GSI1',
      partitionKey: { name: 'GSI1PK', type: 'S' },
      sortKey: { name: 'GSI1SK', type: 'S' },
      projection: 'ALL',
      purpose: 'Query by User/Project relationships'
    },
    {
      indexName: 'GSI2',
      partitionKey: { name: 'GSI2PK', type: 'S' },
      sortKey: { name: 'GSI2SK', type: 'S' },
      projection: 'ALL',
      purpose: 'Query by Agent/Task relationships'
    },
    {
      indexName: 'GSI3',
      partitionKey: { name: 'GSI3PK', type: 'S' },
      sortKey: { name: 'CreatedAt', type: 'S' },
      projection: 'ALL',
      purpose: 'Time-based queries'
    }
  ],
  attributes: [
    { name: 'EntityType', type: 'S', required: true },
    { name: 'EntityId', type: 'S', required: true },
    { name: 'Status', type: 'S', required: true },
    { name: 'CreatedAt', type: 'S', required: true },
    { name: 'UpdatedAt', type: 'S', required: true },
    { name: 'TTL', type: 'N', required: false }
  ]
};

// Access Patterns ì •ì˜
export const ACCESS_PATTERNS = {
  // User ê´€ë ¨
  getUserById: {
    index: 'Primary',
    PK: 'USER#{userId}',
    SK: 'METADATA'
  },
  getUserProjects: {
    index: 'Primary',
    PK: 'USER#{userId}',
    SK: 'PROJECT#'
  },
  
  // Project ê´€ë ¨
  getProjectById: {
    index: 'Primary',
    PK: 'PROJECT#{projectId}',
    SK: 'METADATA'
  },
  getProjectAgents: {
    index: 'Primary',
    PK: 'PROJECT#{projectId}',
    SK: 'AGENT#'
  },
  
  // Agent ê´€ë ¨
  getAgentTasks: {
    index: 'GSI2',
    GSI2PK: 'AGENT#{agentId}',
    GSI2SK: 'TASK#'
  },
  getAgentsByProject: {
    index: 'GSI1',
    GSI1PK: 'PROJECT#{projectId}',
    GSI1SK: 'AGENT#'
  }
};
```

#### SubTask 2.1.2: í…Œì´ë¸” ìƒì„± ìë™í™” ìŠ¤í¬ë¦½íŠ¸
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/scripts/create-tables.ts
import { DynamoDBClient, CreateTableCommand } from '@aws-sdk/client-dynamodb';
import { T_DEVELOPER_TABLE } from '../schemas/single-table-design';

export class TableCreator {
  private dynamoDB: DynamoDBClient;
  
  constructor(region: string = process.env.AWS_REGION || 'us-east-1') {
    this.dynamoDB = new DynamoDBClient({ region });
  }
  
  async createMainTable(): Promise<void> {
    const params = {
      TableName: T_DEVELOPER_TABLE.tableName,
      KeySchema: [
        { AttributeName: 'PK', KeyType: 'HASH' },
        { AttributeName: 'SK', KeyType: 'RANGE' }
      ],
      AttributeDefinitions: [
        { AttributeName: 'PK', AttributeType: 'S' },
        { AttributeName: 'SK', AttributeType: 'S' },
        { AttributeName: 'GSI1PK', AttributeType: 'S' },
        { AttributeName: 'GSI1SK', AttributeType: 'S' },
        { AttributeName: 'GSI2PK', AttributeType: 'S' },
        { AttributeName: 'GSI2SK', AttributeType: 'S' },
        { AttributeName: 'GSI3PK', AttributeType: 'S' },
        { AttributeName: 'CreatedAt', AttributeType: 'S' }
      ],
      GlobalSecondaryIndexes: T_DEVELOPER_TABLE.globalSecondaryIndexes.map(gsi => ({
        IndexName: gsi.indexName,
        KeySchema: [
          { AttributeName: gsi.partitionKey.name, KeyType: 'HASH' },
          { AttributeName: gsi.sortKey!.name, KeyType: 'RANGE' }
        ],
        Projection: { ProjectionType: gsi.projection },
        ProvisionedThroughput: {
          ReadCapacityUnits: 5,
          WriteCapacityUnits: 5
        }
      })),
      BillingMode: 'PAY_PER_REQUEST',
      StreamSpecification: {
        StreamEnabled: true,
        StreamViewType: 'NEW_AND_OLD_IMAGES'
      },
      Tags: [
        { Key: 'Project', Value: 'T-Developer' },
        { Key: 'Environment', Value: process.env.NODE_ENV || 'development' }
      ]
    };
    
    try {
      await this.dynamoDB.send(new CreateTableCommand(params));
      console.log(`âœ… Table ${T_DEVELOPER_TABLE.tableName} created successfully`);
      
      // í…Œì´ë¸”ì´ ACTIVE ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸°
      await this.waitForTableActive(T_DEVELOPER_TABLE.tableName);
      
    } catch (error) {
      if (error.name === 'ResourceInUseException') {
        console.log(`â„¹ï¸ Table ${T_DEVELOPER_TABLE.tableName} already exists`);
      } else {
        throw error;
      }
    }
  }
  
  private async waitForTableActive(tableName: string): Promise<void> {
    // í…Œì´ë¸” ìƒíƒœ í™•ì¸ ë¡œì§
    let isActive = false;
    let attempts = 0;
    
    while (!isActive && attempts < 30) {
      const status = await this.getTableStatus(tableName);
      if (status === 'ACTIVE') {
        isActive = true;
      } else {
        await new Promise(resolve => setTimeout(resolve, 2000));
        attempts++;
      }
    }
  }
}

// ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
if (require.main === module) {
  const creator = new TableCreator();
  creator.createMainTable()
    .then(() => console.log('âœ… All tables created successfully'))
    .catch(console.error);
}
```

#### SubTask 2.1.3: ë°ì´í„° ëª¨ë¸ ì—”í‹°í‹° ì •ì˜
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/entities/base.entity.ts
export abstract class BaseEntity {
  PK: string;
  SK: string;
  EntityType: string;
  EntityId: string;
  CreatedAt: string;
  UpdatedAt: string;
  Version: number;
  
  constructor() {
    this.CreatedAt = new Date().toISOString();
    this.UpdatedAt = new Date().toISOString();
    this.Version = 1;
  }
  
  abstract toDynamoDBItem(): Record<string, any>;
  abstract fromDynamoDBItem(item: Record<string, any>): void;
}

// backend/src/data/entities/user.entity.ts
export class UserEntity extends BaseEntity {
  UserId: string;
  Email: string;
  Username: string;
  Role: 'admin' | 'developer' | 'viewer';
  Preferences: UserPreferences;
  LastLoginAt?: string;
  
  constructor(userId: string) {
    super();
    this.EntityType = 'USER';
    this.EntityId = userId;
    this.UserId = userId;
    this.PK = `USER#${userId}`;
    this.SK = 'METADATA';
  }
  
  toDynamoDBItem(): Record<string, any> {
    return {
      PK: this.PK,
      SK: this.SK,
      EntityType: this.EntityType,
      EntityId: this.EntityId,
      UserId: this.UserId,
      Email: this.Email,
      Username: this.Username,
      Role: this.Role,
      Preferences: this.Preferences,
      LastLoginAt: this.LastLoginAt,
      CreatedAt: this.CreatedAt,
      UpdatedAt: this.UpdatedAt,
      Version: this.Version,
      GSI1PK: `EMAIL#${this.Email}`,
      GSI1SK: this.UserId
    };
  }
  
  fromDynamoDBItem(item: Record<string, any>): void {
    Object.assign(this, item);
  }
}

// backend/src/data/entities/project.entity.ts
export class ProjectEntity extends BaseEntity {
  ProjectId: string;
  ProjectName: string;
  Description: string;
  OwnerId: string;
  Status: 'active' | 'archived' | 'deleted';
  Settings: ProjectSettings;
  Metadata: Record<string, any>;
  
  constructor(projectId: string, ownerId: string) {
    super();
    this.EntityType = 'PROJECT';
    this.EntityId = projectId;
    this.ProjectId = projectId;
    this.OwnerId = ownerId;
    this.PK = `PROJECT#${projectId}`;
    this.SK = 'METADATA';
  }
  
  toDynamoDBItem(): Record<string, any> {
    return {
      PK: this.PK,
      SK: this.SK,
      EntityType: this.EntityType,
      EntityId: this.EntityId,
      ProjectId: this.ProjectId,
      ProjectName: this.ProjectName,
      Description: this.Description,
      OwnerId: this.OwnerId,
      Status: this.Status,
      Settings: this.Settings,
      Metadata: this.Metadata,
      CreatedAt: this.CreatedAt,
      UpdatedAt: this.UpdatedAt,
      Version: this.Version,
      GSI1PK: `USER#${this.OwnerId}`,
      GSI1SK: `PROJECT#${this.CreatedAt}#${this.ProjectId}`,
      GSI3PK: `PROJECTS#${this.Status}`,
      GSI3SK: this.CreatedAt
    };
  }
}

// backend/src/data/entities/agent.entity.ts
export class AgentEntity extends BaseEntity {
  AgentId: string;
  AgentType: string;
  ProjectId: string;
  Name: string;
  Status: 'idle' | 'running' | 'completed' | 'failed';
  Configuration: AgentConfiguration;
  LastExecutionAt?: string;
  Metrics: AgentMetrics;
  
  constructor(agentId: string, projectId: string, agentType: string) {
    super();
    this.EntityType = 'AGENT';
    this.EntityId = agentId;
    this.AgentId = agentId;
    this.ProjectId = projectId;
    this.AgentType = agentType;
    this.PK = `PROJECT#${projectId}`;
    this.SK = `AGENT#${agentId}`;
  }
  
  toDynamoDBItem(): Record<string, any> {
    return {
      PK: this.PK,
      SK: this.SK,
      EntityType: this.EntityType,
      EntityId: this.EntityId,
      AgentId: this.AgentId,
      AgentType: this.AgentType,
      ProjectId: this.ProjectId,
      Name: this.Name,
      Status: this.Status,
      Configuration: this.Configuration,
      LastExecutionAt: this.LastExecutionAt,
      Metrics: this.Metrics,
      CreatedAt: this.CreatedAt,
      UpdatedAt: this.UpdatedAt,
      Version: this.Version,
      GSI2PK: `AGENT#${this.AgentId}`,
      GSI2SK: `STATUS#${this.Status}`,
      GSI3PK: `AGENTS#${this.AgentType}`,
      GSI3SK: this.CreatedAt
    };
  }
}
```

#### SubTask 2.1.4: ë°°ì¹˜ ì‘ì—… ë° íŠ¸ëœì­ì…˜ ì§€ì›
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/services/batch-operations.ts
import { 
  DynamoDBDocumentClient, 
  TransactWriteCommand,
  BatchWriteCommand,
  BatchGetCommand 
} from '@aws-sdk/lib-dynamodb';

export class BatchOperationService {
  constructor(private docClient: DynamoDBDocumentClient) {}
  
  // íŠ¸ëœì­ì…˜ ì“°ê¸°
  async transactWrite(operations: TransactOperation[]): Promise<void> {
    const transactItems = operations.map(op => {
      switch (op.type) {
        case 'Put':
          return { Put: { TableName: op.tableName, Item: op.item } };
        case 'Update':
          return { 
            Update: { 
              TableName: op.tableName,
              Key: op.key,
              UpdateExpression: op.updateExpression,
              ExpressionAttributeValues: op.expressionAttributeValues 
            } 
          };
        case 'Delete':
          return { Delete: { TableName: op.tableName, Key: op.key } };
        default:
          throw new Error(`Unknown operation type: ${op.type}`);
      }
    });
    
    try {
      await this.docClient.send(new TransactWriteCommand({
        TransactItems: transactItems
      }));
    } catch (error) {
      if (error.name === 'TransactionCanceledException') {
        // íŠ¸ëœì­ì…˜ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
        const reasons = error.CancellationReasons || [];
        throw new TransactionFailedError('Transaction failed', reasons);
      }
      throw error;
    }
  }
  
  // ë°°ì¹˜ ì“°ê¸° (ìµœëŒ€ 25ê°œ í•­ëª©)
  async batchWrite(
    tableName: string, 
    items: any[], 
    deleteKeys?: any[]
  ): Promise<void> {
    const chunks = this.chunkArray([...items, ...(deleteKeys || [])], 25);
    
    for (const chunk of chunks) {
      const requests = chunk.map(item => {
        if (deleteKeys?.includes(item)) {
          return { DeleteRequest: { Key: item } };
        }
        return { PutRequest: { Item: item } };
      });
      
      await this.executeBatchWrite(tableName, requests);
    }
  }
  
  private async executeBatchWrite(
    tableName: string, 
    requests: any[]
  ): Promise<void> {
    let unprocessedItems = requests;
    let retryCount = 0;
    
    while (unprocessedItems.length > 0 && retryCount < 5) {
      const result = await this.docClient.send(new BatchWriteCommand({
        RequestItems: { [tableName]: unprocessedItems }
      }));
      
      if (result.UnprocessedItems?.[tableName]) {
        unprocessedItems = result.UnprocessedItems[tableName];
        retryCount++;
        // Exponential backoff
        await new Promise(resolve => 
          setTimeout(resolve, Math.pow(2, retryCount) * 100)
        );
      } else {
        unprocessedItems = [];
      }
    }
    
    if (unprocessedItems.length > 0) {
      throw new Error(`Failed to process ${unprocessedItems.length} items after retries`);
    }
  }
  
  // ë°°ì¹˜ ì½ê¸°
  async batchGet(
    tableName: string, 
    keys: any[], 
    projectionExpression?: string
  ): Promise<any[]> {
    const chunks = this.chunkArray(keys, 100);
    const results: any[] = [];
    
    for (const chunk of chunks) {
      const response = await this.docClient.send(new BatchGetCommand({
        RequestItems: {
          [tableName]: {
            Keys: chunk,
            ProjectionExpression: projectionExpression
          }
        }
      }));
      
      if (response.Responses?.[tableName]) {
        results.push(...response.Responses[tableName]);
      }
    }
    
    return results;
  }
  
  private chunkArray<T>(array: T[], size: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
}

// ì‚¬ìš© ì˜ˆì‹œ
export class ProjectService {
  constructor(
    private batchOps: BatchOperationService,
    private tableName: string
  ) {}
  
  async createProjectWithAgents(
    project: ProjectEntity,
    agents: AgentEntity[]
  ): Promise<void> {
    const operations: TransactOperation[] = [
      {
        type: 'Put',
        tableName: this.tableName,
        item: project.toDynamoDBItem()
      },
      ...agents.map(agent => ({
        type: 'Put' as const,
        tableName: this.tableName,
        item: agent.toDynamoDBItem()
      }))
    ];
    
    await this.batchOps.transactWrite(operations);
  }
}
```

---

### Task 2.2: ì¸ë±ì‹± ì „ëµ ë° ì¿¼ë¦¬ ìµœì í™”

#### SubTask 2.2.1: ë³µí•© ì¿¼ë¦¬ íŒ¨í„´ êµ¬í˜„
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/queries/query-builder.ts
export class DynamoQueryBuilder {
  private params: any = {
    TableName: '',
    KeyConditionExpression: '',
    ExpressionAttributeNames: {},
    ExpressionAttributeValues: {}
  };
  
  constructor(tableName: string) {
    this.params.TableName = tableName;
  }
  
  // íŒŒí‹°ì…˜ í‚¤ ì¡°ê±´
  wherePartitionKey(key: string, value: string): this {
    this.params.KeyConditionExpression = '#pk = :pk';
    this.params.ExpressionAttributeNames['#pk'] = key;
    this.params.ExpressionAttributeValues[':pk'] = value;
    return this;
  }
  
  // ì†ŒíŠ¸ í‚¤ ì¡°ê±´
  andSortKey(key: string, operator: string, value: string | string[]): this {
    const skCondition = this.buildSortKeyCondition(key, operator, value);
    this.params.KeyConditionExpression += ` AND ${skCondition}`;
    return this;
  }
  
  private buildSortKeyCondition(
    key: string, 
    operator: string, 
    value: string | string[]
  ): string {
    this.params.ExpressionAttributeNames['#sk'] = key;
    
    switch (operator) {
      case '=':
        this.params.ExpressionAttributeValues[':sk'] = value;
        return '#sk = :sk';
        
      case 'begins_with':
        this.params.ExpressionAttributeValues[':sk'] = value;
        return 'begins_with(#sk, :sk)';
        
      case 'between':
        if (!Array.isArray(value) || value.length !== 2) {
          throw new Error('Between operator requires array of 2 values');
        }
        this.params.ExpressionAttributeValues[':sk1'] = value[0];
        this.params.ExpressionAttributeValues[':sk2'] = value[1];
        return '#sk BETWEEN :sk1 AND :sk2';
        
      case '>':
        this.params.ExpressionAttributeValues[':sk'] = value;
        return '#sk > :sk';
        
      case '<':
        this.params.ExpressionAttributeValues[':sk'] = value;
        return '#sk < :sk';
        
      default:
        throw new Error(`Unsupported operator: ${operator}`);
    }
  }
  
  // í•„í„° í‘œí˜„ì‹
  filter(expression: string, values: Record<string, any>): this {
    this.params.FilterExpression = expression;
    Object.assign(this.params.ExpressionAttributeValues, values);
    return this;
  }
  
  // GSI ì‚¬ìš©
  useIndex(indexName: string): this {
    this.params.IndexName = indexName;
    return this;
  }
  
  // í˜ì´ì§€ë„¤ì´ì…˜
  limit(count: number): this {
    this.params.Limit = count;
    return this;
  }
  
  startFrom(lastEvaluatedKey: any): this {
    if (lastEvaluatedKey) {
      this.params.ExclusiveStartKey = lastEvaluatedKey;
    }
    return this;
  }
  
  // ì •ë ¬
  scanForward(forward: boolean = true): this {
    this.params.ScanIndexForward = forward;
    return this;
  }
  
  // í”„ë¡œì ì…˜
  select(attributes: string[]): this {
    this.params.ProjectionExpression = attributes.join(', ');
    return this;
  }
  
  build(): any {
    return this.params;
  }
}

// ì¿¼ë¦¬ ì‹¤í–‰ ì„œë¹„ìŠ¤
export class QueryExecutor {
  constructor(private docClient: DynamoDBDocumentClient) {}
  
  async query<T>(params: any): Promise<QueryResult<T>> {
    const result = await this.docClient.send(new QueryCommand(params));
    
    return {
      items: (result.Items || []) as T[],
      lastEvaluatedKey: result.LastEvaluatedKey,
      count: result.Count || 0,
      scannedCount: result.ScannedCount || 0
    };
  }
  
  async queryAll<T>(params: any): Promise<T[]> {
    const items: T[] = [];
    let lastEvaluatedKey: any;
    
    do {
      if (lastEvaluatedKey) {
        params.ExclusiveStartKey = lastEvaluatedKey;
      }
      
      const result = await this.query<T>(params);
      items.push(...result.items);
      lastEvaluatedKey = result.lastEvaluatedKey;
      
    } while (lastEvaluatedKey);
    
    return items;
  }
  
  // ë³‘ë ¬ ì¿¼ë¦¬ ì‹¤í–‰
  async parallelQuery<T>(
    queries: any[]
  ): Promise<T[]> {
    const results = await Promise.all(
      queries.map(query => this.queryAll<T>(query))
    );
    
    return results.flat();
  }
}

// ì‚¬ìš© ì˜ˆì‹œ
export class ProjectQueryService {
  constructor(
    private queryExecutor: QueryExecutor,
    private tableName: string
  ) {}
  
  async getProjectsByUser(
    userId: string, 
    status?: string
  ): Promise<ProjectEntity[]> {
    const query = new DynamoQueryBuilder(this.tableName)
      .useIndex('GSI1')
      .wherePartitionKey('GSI1PK', `USER#${userId}`)
      .andSortKey('GSI1SK', 'begins_with', 'PROJECT#')
      .scanForward(false); // ìµœì‹ ìˆœ
    
    if (status) {
      query.filter('#status = :status', { ':status': status });
    }
    
    const params = query.build();
    return this.queryExecutor.queryAll<ProjectEntity>(params);
  }
}
```

#### SubTask 2.2.2: ì¿¼ë¦¬ ì„±ëŠ¥ ìµœì í™”
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/optimization/query-optimizer.ts
export class QueryOptimizer {
  private queryMetrics: Map<string, QueryMetrics> = new Map();
  
  // ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„
  async analyzeQueryPlan(
    query: any
  ): Promise<QueryAnalysis> {
    const analysis: QueryAnalysis = {
      estimatedRCU: this.estimateReadCapacityUnits(query),
      indexEfficiency: this.calculateIndexEfficiency(query),
      projectionEfficiency: this.calculateProjectionEfficiency(query),
      recommendations: []
    };
    
    // ê¶Œì¥ì‚¬í•­ ìƒì„±
    if (analysis.indexEfficiency < 0.8) {
      analysis.recommendations.push({
        type: 'INDEX',
        message: 'Consider using a more selective index',
        impact: 'HIGH'
      });
    }
    
    if (!query.ProjectionExpression) {
      analysis.recommendations.push({
        type: 'PROJECTION',
        message: 'Add ProjectionExpression to reduce data transfer',
        impact: 'MEDIUM'
      });
    }
    
    return analysis;
  }
  
  // ì ì‘í˜• ì¿¼ë¦¬ ìµœì í™”
  async optimizeQuery(
    originalQuery: any,
    historicalMetrics?: QueryMetrics[]
  ): Promise<any> {
    const optimized = { ...originalQuery };
    
    // 1. ìë™ í”„ë¡œì ì…˜ ì¶”ê°€
    if (!optimized.ProjectionExpression && historicalMetrics) {
      const usedAttributes = this.analyzeAttributeUsage(historicalMetrics);
      if (usedAttributes.length > 0) {
        optimized.ProjectionExpression = usedAttributes.join(', ');
      }
    }
    
    // 2. í˜ì´ì§€ í¬ê¸° ìµœì í™”
    if (!optimized.Limit) {
      optimized.Limit = this.calculateOptimalPageSize(historicalMetrics);
    }
    
    // 3. ì¸ë±ìŠ¤ ì„ íƒ ìµœì í™”
    const betterIndex = this.suggestBetterIndex(originalQuery, historicalMetrics);
    if (betterIndex) {
      optimized.IndexName = betterIndex;
    }
    
    return optimized;
  }
  
  // ì¿¼ë¦¬ ìºì‹± ì „ëµ
  getCacheKey(query: any): string {
    const normalized = {
      table: query.TableName,
      index: query.IndexName || 'primary',
      pk: query.ExpressionAttributeValues[':pk'],
      sk: query.ExpressionAttributeValues[':sk'] || '',
      filter: query.FilterExpression || ''
    };
    
    return crypto
      .createHash('sha256')
      .update(JSON.stringify(normalized))
      .digest('hex');
  }
  
  shouldCache(query: any, result: QueryResult<any>): boolean {
    // ìºì‹± ê¸°ì¤€
    const criteria = {
      minItems: 10,
      maxItems: 1000,
      minExecutionTime: 100, // ms
      frequencyThreshold: 5
    };
    
    const metrics = this.queryMetrics.get(this.getCacheKey(query));
    
    return (
      result.items.length >= criteria.minItems &&
      result.items.length <= criteria.maxItems &&
      metrics?.averageExecutionTime >= criteria.minExecutionTime &&
      metrics?.frequency >= criteria.frequencyThreshold
    );
  }
}

// ì¿¼ë¦¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
export class QueryPerformanceMonitor {
  private metrics: Map<string, QueryMetrics> = new Map();
  
  async trackQuery(
    queryKey: string,
    executionTime: number,
    itemCount: number,
    consumedRCU?: number
  ): Promise<void> {
    const existing = this.metrics.get(queryKey) || {
      queryKey,
      executionCount: 0,
      totalExecutionTime: 0,
      averageExecutionTime: 0,
      totalItemsReturned: 0,
      totalRCUConsumed: 0,
      lastExecuted: new Date()
    };
    
    existing.executionCount++;
    existing.totalExecutionTime += executionTime;
    existing.averageExecutionTime = 
      existing.totalExecutionTime / existing.executionCount;
    existing.totalItemsReturned += itemCount;
    existing.totalRCUConsumed += consumedRCU || 0;
    existing.lastExecuted = new Date();
    
    this.metrics.set(queryKey, existing);
    
    // ì„±ëŠ¥ ì €í•˜ ê°ì§€
    if (existing.averageExecutionTime > 1000) {
      await this.alertSlowQuery(queryKey, existing);
    }
  }
  
  async generatePerformanceReport(): Promise<PerformanceReport> {
    const sortedQueries = Array.from(this.metrics.values())
      .sort((a, b) => b.totalExecutionTime - a.totalExecutionTime);
    
    return {
      totalQueries: this.metrics.size,
      slowestQueries: sortedQueries.slice(0, 10),
      mostFrequentQueries: sortedQueries
        .sort((a, b) => b.executionCount - a.executionCount)
        .slice(0, 10),
      totalRCUConsumed: sortedQueries
        .reduce((sum, m) => sum + m.totalRCUConsumed, 0),
      recommendations: this.generateOptimizationRecommendations(sortedQueries)
    };
  }
}
```

#### SubTask 2.2.3: ì¸ë±ìŠ¤ ê´€ë¦¬ ìë™í™”
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/management/index-manager.ts
export class IndexManager {
  constructor(
    private dynamoDB: DynamoDBClient,
    private cloudWatch: CloudWatchClient
  ) {}
  
  // GSI ì‚¬ìš©ë¥  ë¶„ì„
  async analyzeIndexUsage(
    tableName: string,
    period: number = 7 // days
  ): Promise<IndexUsageReport> {
    const indexes = await this.listTableIndexes(tableName);
    const usage: IndexUsageMetrics[] = [];
    
    for (const index of indexes) {
      const metrics = await this.getIndexMetrics(
        tableName,
        index.IndexName,
        period
      );
      
      usage.push({
        indexName: index.IndexName,
        readUtilization: metrics.readUtilization,
        writeUtilization: metrics.writeUtilization,
        itemCount: metrics.itemCount,
        sizeBytes: metrics.sizeBytes,
        costEstimate: this.estimateIndexCost(metrics)
      });
    }
    
    return {
      tableName,
      period,
      indexes: usage,
      recommendations: this.generateIndexRecommendations(usage)
    };
  }
  
  // ì¸ë±ìŠ¤ ìë™ ìŠ¤ì¼€ì¼ë§
  async configureAutoScaling(
    tableName: string,
    indexName: string,
    config: AutoScalingConfig
  ): Promise<void> {
    const scalingClient = new ApplicationAutoScalingClient({});
    
    // ì½ê¸° ìš©ëŸ‰ ìë™ ìŠ¤ì¼€ì¼ë§
    await scalingClient.send(new PutScalingPolicyCommand({
      ServiceNamespace: 'dynamodb',
      ResourceId: `table/${tableName}/index/${indexName}`,
      ScalableDimension: 'dynamodb:index:ReadCapacityUnits',
      PolicyName: `${indexName}-read-scaling`,
      PolicyType: 'TargetTrackingScaling',
      TargetTrackingScalingPolicyConfiguration: {
        TargetValue: config.targetReadUtilization,
        PredefinedMetricSpecification: {
          PredefinedMetricType: 'DynamoDBReadCapacityUtilization'
        },
        ScaleInCooldown: config.scaleInCooldown || 60,
        ScaleOutCooldown: config.scaleOutCooldown || 60
      }
    }));
    
    // ì“°ê¸° ìš©ëŸ‰ ìë™ ìŠ¤ì¼€ì¼ë§
    await scalingClient.send(new PutScalingPolicyCommand({
      ServiceNamespace: 'dynamodb',
      ResourceId: `table/${tableName}/index/${indexName}`,
      ScalableDimension: 'dynamodb:index:WriteCapacityUnits',
      PolicyName: `${indexName}-write-scaling`,
      PolicyType: 'TargetTrackingScaling',
      TargetTrackingScalingPolicyConfiguration: {
        TargetValue: config.targetWriteUtilization,
        PredefinedMetricSpecification: {
          PredefinedMetricType: 'DynamoDBWriteCapacityUtilization'
        }
      }
    }));
  }
  
  // ë¯¸ì‚¬ìš© ì¸ë±ìŠ¤ ê°ì§€
  async detectUnusedIndexes(
    tableName: string,
    threshold: number = 30 // days
  ): Promise<UnusedIndex[]> {
    const unusedIndexes: UnusedIndex[] = [];
    const indexes = await this.listTableIndexes(tableName);
    
    for (const index of indexes) {
      const lastUsed = await this.getLastIndexUsageTime(
        tableName,
        index.IndexName
      );
      
      if (!lastUsed || 
          (Date.now() - lastUsed.getTime()) > threshold * 24 * 60 * 60 * 1000) {
        unusedIndexes.push({
          indexName: index.IndexName,
          lastUsed,
          estimatedMonthlyCost: await this.estimateIndexMonthlyCost(
            tableName,
            index.IndexName
          ),
          recommendation: 'Consider removing this unused index'
        });
      }
    }
    
    return unusedIndexes;
  }
  
  // ì¸ë±ìŠ¤ ì¬êµ¬ì„± ì œì•ˆ
  async suggestIndexReorganization(
    tableName: string,
    queryPatterns: QueryPattern[]
  ): Promise<IndexReorganizationPlan> {
    const currentIndexes = await this.listTableIndexes(tableName);
    const analysis = this.analyzeQueryPatterns(queryPatterns);
    
    const suggestions: IndexSuggestion[] = [];
    
    // ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ì œì•ˆ
    for (const pattern of analysis.uncoveredPatterns) {
      suggestions.push({
        type: 'CREATE',
        indexName: this.generateIndexName(pattern),
        keys: pattern.keys,
        projection: pattern.projection,
        estimatedImprovement: pattern.estimatedImprovement,
        reason: `Cover query pattern: ${pattern.description}`
      });
    }
    
    // ì¸ë±ìŠ¤ ë³‘í•© ì œì•ˆ
    const mergeCandidates = this.findMergeCandidates(currentIndexes);
    for (const candidate of mergeCandidates) {
      suggestions.push({
        type: 'MERGE',
        indexes: candidate.indexes,
        newIndex: candidate.mergedIndex,
        reason: 'Reduce index overhead by merging similar indexes'
      });
    }
    
    return {
      tableName,
      currentIndexCount: currentIndexes.length,
      suggestions,
      estimatedCostSavings: this.calculateCostSavings(suggestions),
      implementationSteps: this.generateImplementationSteps(suggestions)
    };
  }
}
```

#### SubTask 2.2.4: ì¿¼ë¦¬ íŒ¨í„´ í•™ìŠµ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ML ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/ml/query-pattern-learner.ts
export class QueryPatternLearner {
  private patterns: Map<string, QueryPattern> = new Map();
  private model: QueryPredictionModel;
  
  constructor() {
    this.model = new QueryPredictionModel();
  }
  
  // ì¿¼ë¦¬ íŒ¨í„´ í•™ìŠµ
  async learnFromQuery(
    query: ExecutedQuery
  ): Promise<void> {
    const pattern = this.extractPattern(query);
    const existing = this.patterns.get(pattern.id) || pattern;
    
    // íŒ¨í„´ í†µê³„ ì—…ë°ì´íŠ¸
    existing.frequency++;
    existing.lastSeen = new Date();
    existing.averageResponseTime = 
      (existing.averageResponseTime * (existing.frequency - 1) + 
       query.executionTime) / existing.frequency;
    
    this.patterns.set(pattern.id, existing);
    
    // ëª¨ë¸ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
    if (this.patterns.size % 100 === 0) {
      await this.retrainModel();
    }
  }
  
  // ì¿¼ë¦¬ ì˜ˆì¸¡
  async predictNextQueries(
    context: QueryContext
  ): Promise<PredictedQuery[]> {
    const predictions = await this.model.predict(context);
    
    return predictions.map(pred => ({
      query: this.buildQueryFromPattern(pred.pattern),
      probability: pred.probability,
      expectedResponseTime: pred.expectedTime,
      suggestedCache: pred.shouldCache
    }));
  }
  
  // ì¿¼ë¦¬ íŒ¨í„´ ì¶”ì¶œ
  private extractPattern(query: ExecutedQuery): QueryPattern {
    return {
      id: this.generatePatternId(query),
      entityType: this.extractEntityType(query),
      accessPattern: this.extractAccessPattern(query),
      timePattern: this.extractTimePattern(query),
      userPattern: this.extractUserPattern(query),
      frequency: 1,
      averageResponseTime: query.executionTime,
      lastSeen: new Date()
    };
  }
  
  // ì ì‘í˜• ì¸ë±ì‹± ì œì•ˆ
  async suggestAdaptiveIndexing(): Promise<AdaptiveIndexingSuggestion[]> {
    const suggestions: AdaptiveIndexingSuggestion[] = [];
    
    // ê³ ë¹ˆë„ íŒ¨í„´ ë¶„ì„
    const hotPatterns = Array.from(this.patterns.values())
      .filter(p => p.frequency > 100)
      .sort((a, b) => b.frequency - a.frequency);
    
    for (const pattern of hotPatterns) {
      const indexExists = await this.checkIndexCoverage(pattern);
      
      if (!indexExists) {
        suggestions.push({
          pattern,
          indexDefinition: this.generateOptimalIndex(pattern),
          expectedImprovement: this.estimateImprovement(pattern),
          priority: this.calculatePriority(pattern)
        });
      }
    }
    
    return suggestions.sort((a, b) => b.priority - a.priority);
  }
  
  // ì¿¼ë¦¬ ìµœì í™” í•™ìŠµ
  async learnOptimization(
    originalQuery: any,
    optimizedQuery: any,
    improvement: number
  ): Promise<void> {
    const optimization = {
      pattern: this.extractPattern(originalQuery),
      optimization: this.extractOptimization(originalQuery, optimizedQuery),
      improvement,
      timestamp: new Date()
    };
    
    await this.model.addOptimizationExample(optimization);
  }
}

// ì¿¼ë¦¬ ì˜ˆì¸¡ ëª¨ë¸
class QueryPredictionModel {
  private network: NeuralNetwork;
  
  constructor() {
    this.network = new NeuralNetwork({
      inputSize: 50, // íŠ¹ì„± ë²¡í„° í¬ê¸°
      hiddenLayers: [100, 50, 25],
      outputSize: 20, // ì˜ˆì¸¡ ê°€ëŠ¥í•œ íŒ¨í„´ ìˆ˜
      activation: 'relu',
      optimizer: 'adam'
    });
  }
  
  async predict(context: QueryContext): Promise<Prediction[]> {
    const features = this.extractFeatures(context);
    const predictions = await this.network.forward(features);
    
    return this.decodePredictions(predictions)
      .filter(p => p.probability > 0.3)
      .sort((a, b) => b.probability - a.probability)
      .slice(0, 5);
  }
  
  async train(examples: TrainingExample[]): Promise<void> {
    const dataset = examples.map(ex => ({
      input: this.extractFeatures(ex.context),
      output: this.encodePattern(ex.actualPattern)
    }));
    
    await this.network.train(dataset, {
      epochs: 100,
      batchSize: 32,
      validationSplit: 0.2,
      earlyStoppingPatience: 10
    });
  }
}
```

---

### Task 2.3: ë°ì´í„° íŒŒí‹°ì…”ë‹ ë° ìƒ¤ë”© ì „ëµ

#### SubTask 2.3.1: ì‹œê°„ ê¸°ë°˜ íŒŒí‹°ì…”ë‹
**ë‹´ë‹¹ì**: ë°ì´í„° ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/partitioning/time-based-partitioner.ts
export class TimeBasedPartitioner {
  private partitionStrategy: PartitionStrategy;
  
  constructor(strategy: PartitionStrategy = 'monthly') {
    this.partitionStrategy = strategy;
  }
  
  // íŒŒí‹°ì…˜ í‚¤ ìƒì„±
  generatePartitionKey(
    baseKey: string,
    timestamp: Date
  ): string {
    const suffix = this.getPartitionSuffix(timestamp);
    return `${baseKey}#${suffix}`;
  }
  
  private getPartitionSuffix(date: Date): string {
    switch (this.partitionStrategy) {
      case 'daily':
        return date.toISOString().split('T')[0];
      case 'weekly':
        return this.getWeekIdentifier(date);
      case 'monthly':
        return `${date.getFullYear()}-${String(date.getMonth() + 1).padStart(2, '0')}`;
      case 'yearly':
        return String(date.getFullYear());
      default:
        throw new Error(`Unknown partition strategy: ${this.partitionStrategy}`);
    }
  }
  
  // ì¿¼ë¦¬ ë²”ìœ„ì— ë”°ë¥¸ íŒŒí‹°ì…˜ ëª©ë¡ ìƒì„±
  getPartitionsForRange(
    startDate: Date,
    endDate: Date
  ): string[] {
    const partitions: string[] = [];
    const current = new Date(startDate);
    
    while (current <= endDate) {
      partitions.push(this.getPartitionSuffix(current));
      current.setDate(current.getDate() + 1);
    }
    
    return [...new Set(partitions)];
  }
  
  // Hot íŒŒí‹°ì…˜ ê°ì§€
  async detectHotPartitions(
    tableName: string,
    metrics: PartitionMetrics[]
  ): Promise<HotPartition[]> {
    const threshold = this.calculateDynamicThreshold(metrics);
    
    return metrics
      .filter(m => m.consumedRCU > threshold.rcu || 
                   m.consumedWCU > threshold.wcu)
      .map(m => ({
        partitionKey: m.partitionKey,
        consumedRCU: m.consumedRCU,
        consumedWCU: m.consumedWCU,
        itemCount: m.itemCount,
        recommendation: this.generateRebalancingRecommendation(m)
      }));
  }
  
  // ìë™ ì•„ì¹´ì´ë¹™
  async archiveOldPartitions(
    tableName: string,
    retentionDays: number
  ): Promise<ArchiveResult> {
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays);
    
    const partitionsToArchive = await this.identifyArchivablePartitions(
      tableName,
      cutoffDate
    );
    
    const archived: string[] = [];
    const failed: string[] = [];
    
    for (const partition of partitionsToArchive) {
      try {
        await this.archivePartition(tableName, partition);
        archived.push(partition);
      } catch (error) {
        failed.push(partition);
        console.error(`Failed to archive partition ${partition}:`, error);
      }
    }
    
    return {
      totalPartitions: partitionsToArchive.length,
      archived,
      failed,
      bytesArchived: await this.calculateArchivedSize(archived)
    };
  }
}

// íŒŒí‹°ì…˜ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬
export class PartitionLifecycleManager {
  constructor(
    private partitioner: TimeBasedPartitioner,
    private s3Client: S3Client
  ) {}
  
  // íŒŒí‹°ì…˜ ìƒì„± ìë™í™”
  async createUpcomingPartitions(
    tableName: string,
    daysAhead: number = 7
  ): Promise<void> {
    const futureDate = new Date();
    futureDate.setDate(futureDate.getDate() + daysAhead);
    
    const partitionsNeeded = this.partitioner.getPartitionsForRange(
      new Date(),
      futureDate
    );
    
    for (const partition of partitionsNeeded) {
      await this.ensurePartitionExists(tableName, partition);
    }
  }
  
  // íŒŒí‹°ì…˜ ë³‘í•©
  async mergePartitions(
    sourcePartitions: string[],
    targetPartition: string
  ): Promise<MergeResult> {
    const items: any[] = [];
    
    // ëª¨ë“  ì†ŒìŠ¤ íŒŒí‹°ì…˜ì—ì„œ ë°ì´í„° ì½ê¸°
    for (const partition of sourcePartitions) {
      const partitionItems = await this.readPartition(partition);
      items.push(...partitionItems);
    }
    
    // ëŒ€ìƒ íŒŒí‹°ì…˜ì— ì“°ê¸°
    await this.writeToPartition(targetPartition, items);
    
    // ì†ŒìŠ¤ íŒŒí‹°ì…˜ ì •ë¦¬
    for (const partition of sourcePartitions) {
      await this.deletePartition(partition);
    }
    
    return {
      sourcePartitions,
      targetPartition,
      itemsMerged: items.length,
      success: true
    };
  }
}
```

#### SubTask 2.3.2: í•« íŒŒí‹°ì…˜ ê´€ë¦¬ ë° ì¬ë¶„ë°°
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/partitioning/hot-partition-manager.ts
export class HotPartitionManager {
  private monitoringInterval: NodeJS.Timer;
  private rebalancingQueue: Queue<RebalancingJob>;
  
  constructor(
    private cloudWatch: CloudWatchClient,
    private dynamoDB: DynamoDBClient
  ) {
    this.rebalancingQueue = new Queue('partition-rebalancing');
  }
  
  // ì‹¤ì‹œê°„ íŒŒí‹°ì…˜ ëª¨ë‹ˆí„°ë§
  startMonitoring(tableName: string): void {
    this.monitoringInterval = setInterval(async () => {
      try {
        const metrics = await this.collectPartitionMetrics(tableName);
        const hotPartitions = await this.identifyHotPartitions(metrics);
        
        if (hotPartitions.length > 0) {
          await this.handleHotPartitions(tableName, hotPartitions);
        }
      } catch (error) {
        console.error('Partition monitoring error:', error);
      }
    }, 60000); // 1ë¶„ë§ˆë‹¤
  }
  
  // íŒŒí‹°ì…˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  private async collectPartitionMetrics(
    tableName: string
  ): Promise<PartitionMetrics[]> {
    const params = {
      MetricName: 'ConsumedReadCapacityUnits',
      Namespace: 'AWS/DynamoDB',
      Dimensions: [
        { Name: 'TableName', Value: tableName }
      ],
      StartTime: new Date(Date.now() - 5 * 60 * 1000), // 5ë¶„ ì „
      EndTime: new Date(),
      Period: 60,
      Statistics: ['Sum', 'Average', 'Maximum']
    };
    
    const response = await this.cloudWatch.send(
      new GetMetricStatisticsCommand(params)
    );
    
    // íŒŒí‹°ì…˜ë³„ ë©”íŠ¸ë¦­ ë¶„ì„
    return this.analyzePartitionMetrics(response.Datapoints || []);
  }
  
  // ìë™ ì¬ë¶„ë°° ì „ëµ
  async rebalanceHotPartition(
    tableName: string,
    partition: HotPartition
  ): Promise<RebalancingResult> {
    const strategy = this.selectRebalancingStrategy(partition);
    
    switch (strategy) {
      case 'SPLIT':
        return await this.splitPartition(tableName, partition);
        
      case 'REDISTRIBUTE':
        return await this.redistributeItems(tableName, partition);
        
      case 'CACHE':
        return await this.enablePartitionCaching(tableName, partition);
        
      case 'THROTTLE':
        return await this.applyThrottling(tableName, partition);
        
      default:
        throw new Error(`Unknown rebalancing strategy: ${strategy}`);
    }
  }
  
  // íŒŒí‹°ì…˜ ë¶„í• 
  private async splitPartition(
    tableName: string,
    partition: HotPartition
  ): Promise<RebalancingResult> {
    // 1. ìƒˆë¡œìš´ íŒŒí‹°ì…˜ í‚¤ ìƒì„±
    const newPartitions = this.generateSplitPartitions(partition);
    
    // 2. ê¸°ì¡´ í•­ëª© ì½ê¸°
    const items = await this.readPartitionItems(tableName, partition.partitionKey);
    
    // 3. í•­ëª© ì¬ë¶„ë°°
    const distribution = this.distributeItems(items, newPartitions);
    
    // 4. ë³‘ë ¬ë¡œ ìƒˆ íŒŒí‹°ì…˜ì— ì“°ê¸°
    const writePromises = newPartitions.map((newPartition, index) =>
      this.batchWriteItems(tableName, distribution[index], newPartition)
    );
    
    await Promise.all(writePromises);
    
    // 5. ê¸°ì¡´ íŒŒí‹°ì…˜ ì •ë¦¬
    await this.cleanupOldPartition(tableName, partition.partitionKey);
    
    return {
      strategy: 'SPLIT',
      originalPartition: partition.partitionKey,
      newPartitions,
      itemsRebalanced: items.length,
      success: true
    };
  }
  
  // ì§€ëŠ¥í˜• í•­ëª© ì¬ë¶„ë°°
  private distributeItems(
    items: any[],
    partitions: string[]
  ): any[][] {
    const distributed: any[][] = partitions.map(() => []);
    
    // í•´ì‹œ ê¸°ë°˜ ê· ë“± ë¶„ë°°
    items.forEach(item => {
      const hash = this.hashItem(item);
      const targetIndex = hash % partitions.length;
      distributed[targetIndex].push(item);
    });
    
    // ë¶„ë°° ê· í˜• ê²€ì¦
    const sizes = distributed.map(d => d.length);
    const avg = items.length / partitions.length;
    const maxDeviation = Math.max(...sizes.map(s => Math.abs(s - avg)));
    
    if (maxDeviation > avg * 0.2) {
      // ì¬ê· í˜• í•„ìš”
      return this.rebalanceDistribution(distributed);
    }
    
    return distributed;
  }
  
  // ì ì‘í˜• íŒŒí‹°ì…”ë‹
  async enableAdaptivePartitioning(
    tableName: string
  ): Promise<void> {
    const config: AdaptivePartitioningConfig = {
      enabled: true,
      minPartitionSize: 1000,
      maxPartitionSize: 100000,
      hotPartitionThreshold: {
        rcu: 3000,
        wcu: 1000
      },
      cooldownPeriod: 300, // 5ë¶„
      strategies: ['SPLIT', 'REDISTRIBUTE', 'CACHE']
    };
    
    await this.savePartitioningConfig(tableName, config);
    
    // ëª¨ë‹ˆí„°ë§ ì‹œì‘
    this.startMonitoring(tableName);
  }
}

// íŒŒí‹°ì…˜ ì˜ˆì¸¡ ëª¨ë¸
export class PartitionPredictionModel {
  async predictFutureHotspots(
    historicalData: PartitionMetrics[],
    timeframe: number
  ): Promise<PredictedHotspot[]> {
    // ì‹œê³„ì—´ ë¶„ì„
    const trends = this.analyzeTimeSeries(historicalData);
    
    // ê³„ì ˆì„± íŒ¨í„´ ê°ì§€
    const seasonality = this.detectSeasonality(historicalData);
    
    // ì˜ˆì¸¡ ëª¨ë¸ ì‹¤í–‰
    const predictions = await this.runPredictionModel({
      trends,
      seasonality,
      timeframe
    });
    
    return predictions.map(pred => ({
      partitionKey: pred.partition,
      predictedTime: pred.timestamp,
      expectedLoad: pred.load,
      confidence: pred.confidence,
      recommendation: this.generateProactiveAction(pred)
    }));
  }
}
```

#### SubTask 2.3.3: ê¸€ë¡œë²Œ í…Œì´ë¸” ë° í¬ë¡œìŠ¤ ë¦¬ì „ ë³µì œ
**ë‹´ë‹¹ì**: ì¸í”„ë¼ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/replication/global-table-manager.ts
export class GlobalTableManager {
  private regions: string[];
  private replicationMonitor: ReplicationMonitor;
  
  constructor(regions: string[]) {
    this.regions = regions;
    this.replicationMonitor = new ReplicationMonitor();
  }
  
  // ê¸€ë¡œë²Œ í…Œì´ë¸” ìƒì„±
  async createGlobalTable(
    tableName: string,
    schema: TableSchema
  ): Promise<GlobalTableCreationResult> {
    const results: RegionResult[] = [];
    
    // 1. ê° ë¦¬ì „ì— í…Œì´ë¸” ìƒì„±
    for (const region of this.regions) {
      const client = new DynamoDBClient({ region });
      
      try {
        await this.createRegionalTable(client, tableName, schema);
        results.push({ region, status: 'CREATED' });
      } catch (error) {
        results.push({ region, status: 'FAILED', error });
      }
    }
    
    // 2. ê¸€ë¡œë²Œ í…Œì´ë¸” ì„¤ì •
    if (results.every(r => r.status === 'CREATED')) {
      await this.enableGlobalTableReplication(tableName);
    }
    
    return {
      tableName,
      regions: results,
      replicationEnabled: results.every(r => r.status === 'CREATED'),
      timestamp: new Date()
    };
  }
  
  // ë³µì œ ì§€ì—° ëª¨ë‹ˆí„°ë§
  async monitorReplicationLag(): Promise<ReplicationMetrics> {
    const metrics: RegionMetrics[] = [];
    
    for (const region of this.regions) {
      const lag = await this.measureReplicationLag(region);
      const health = await this.checkRegionHealth(region);
      
      metrics.push({
        region,
        replicationLag: lag,
        health,
        lastSync: new Date()
      });
    }
    
    return {
      globalHealth: this.calculateGlobalHealth(metrics),
      regionMetrics: metrics,
      alerts: this.generateReplicationAlerts(metrics)
    };
  }
  
  // ì¶©ëŒ í•´ê²° ì „ëµ
  async resolveConflicts(
    conflicts: ReplicationConflict[]
  ): Promise<ConflictResolutionResult[]> {
    const results: ConflictResolutionResult[] = [];
    
    for (const conflict of conflicts) {
      const resolution = await this.applyConflictResolution(conflict);
      results.push(resolution);
      
      // í•´ê²° ë‚´ì—­ ê¸°ë¡
      await this.logConflictResolution(resolution);
    }
    
    return results;
  }
  
  private async applyConflictResolution(
    conflict: ReplicationConflict
  ): Promise<ConflictResolutionResult> {
    switch (conflict.type) {
      case 'CONCURRENT_UPDATE':
        return this.resolveByLastWriterWins(conflict);
        
      case 'DELETE_UPDATE':
        return this.resolveDeleteUpdate(conflict);
        
      case 'SCHEMA_MISMATCH':
        return this.resolveSchemaMismatch(conflict);
        
      default:
        return this.customConflictResolution(conflict);
    }
  }
  
  // ë¦¬ì „ ì¥ì•  ëŒ€ì‘
  async handleRegionFailure(
    failedRegion: string
  ): Promise<FailoverResult> {
    // 1. ì¥ì•  ë¦¬ì „ ê²©ë¦¬
    await this.isolateFailedRegion(failedRegion);
    
    // 2. íŠ¸ë˜í”½ ì¬ë¼ìš°íŒ…
    const newPrimary = await this.selectNewPrimaryRegion();
    await this.rerouteTraffic(failedRegion, newPrimary);
    
    // 3. ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
    await this.verifyDataConsistency(newPrimary);
    
    // 4. ì•Œë¦¼ ë°œì†¡
    await this.notifyFailover(failedRegion, newPrimary);
    
    return {
      failedRegion,
      newPrimary,
      dataLoss: false,
      recoveryTime: Date.now(),
      status: 'COMPLETED'
    };
  }
}

// í¬ë¡œìŠ¤ ë¦¬ì „ ë°ì´í„° ë™ê¸°í™”
export class CrossRegionSync {
  private syncQueue: Queue<SyncJob>;
  private syncStatus: Map<string, SyncStatus>;
  
  // ì„ íƒì  ë™ê¸°í™”
  async syncSelectedData(
    sourceRegion: string,
    targetRegions: string[],
    filter: SyncFilter
  ): Promise<SyncResult> {
    const syncJobs: SyncJob[] = [];
    
    // ë™ê¸°í™”í•  ë°ì´í„° ì‹ë³„
    const dataToSync = await this.identifyDataToSync(
      sourceRegion,
      filter
    );
    
    // ê° ëŒ€ìƒ ë¦¬ì „ì— ëŒ€í•œ ë™ê¸°í™” ì‘ì—… ìƒì„±
    for (const targetRegion of targetRegions) {
      const job: SyncJob = {
        id: uuidv4(),
        sourceRegion,
        targetRegion,
        dataSet: dataToSync,
        priority: filter.priority || 'NORMAL',
        createdAt: new Date()
      };
      
      syncJobs.push(job);
      await this.syncQueue.add(job);
    }
    
    // ë™ê¸°í™” ì§„í–‰ ìƒíƒœ ì¶”ì 
    return this.trackSyncProgress(syncJobs);
  }
  
  // ì¦ë¶„ ë™ê¸°í™”
  async performIncrementalSync(
    region: string,
    lastSyncTimestamp: Date
  ): Promise<IncrementalSyncResult> {
    // DynamoDB Streamsì—ì„œ ë³€ê²½ì‚¬í•­ ì½ê¸°
    const changes = await this.readChangesSince(
      region,
      lastSyncTimestamp
    );
    
    // ë³€ê²½ì‚¬í•­ ë¶„ë¥˜
    const classified = this.classifyChanges(changes);
    
    // ë³‘ë ¬ ë™ê¸°í™” ì‹¤í–‰
    const results = await Promise.all([
      this.syncInserts(classified.inserts),
      this.syncUpdates(classified.updates),
      this.syncDeletes(classified.deletes)
    ]);
    
    return {
      itemsSynced: results.reduce((sum, r) => sum + r.count, 0),
      duration: Date.now() - lastSyncTimestamp.getTime(),
      errors: results.filter(r => r.errors > 0),
      nextSyncTimestamp: new Date()
    };
  }
}
```

#### SubTask 2.3.4: ìƒ¤ë”© í‚¤ ì„¤ê³„ ë° ìµœì í™”
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/sharding/sharding-strategy.ts
export class ShardingStrategy {
  private shardCount: number;
  private hashFunction: HashFunction;
  
  constructor(
    shardCount: number = 10,
    hashFunction: HashFunction = 'xxhash'
  ) {
    this.shardCount = shardCount;
    this.hashFunction = this.initializeHashFunction(hashFunction);
  }
  
  // ìƒ¤ë“œ í‚¤ ìƒì„±
  generateShardKey(
    entityId: string,
    timestamp?: Date
  ): string {
    const shardId = this.calculateShardId(entityId);
    const timeComponent = timestamp ? 
      `#${timestamp.getTime()}` : '';
    
    return `SHARD#${shardId}${timeComponent}`;
  }
  
  // ì¼ê´€ëœ í•´ì‹±
  private calculateShardId(key: string): number {
    const hash = this.hashFunction(key);
    return hash % this.shardCount;
  }
  
  // ìƒ¤ë“œ ì¬ë¶„ë°°
  async reshardData(
    currentShards: number,
    targetShards: number
  ): Promise<ReshardingPlan> {
    const plan: ReshardingPlan = {
      currentShards,
      targetShards,
      migrations: [],
      estimatedDuration: 0
    };
    
    // ë§ˆì´ê·¸ë ˆì´ì…˜ ë§¤í•‘ ìƒì„±
    for (let i = 0; i < currentShards; i++) {
      const targetShard = this.mapToNewShard(
        i,
        currentShards,
        targetShards
      );
      
      if (targetShard !== i) {
        plan.migrations.push({
          fromShard: i,
          toShard: targetShard,
          estimatedItems: await this.estimateShardSize(i)
        });
      }
    }
    
    plan.estimatedDuration = this.estimateMigrationTime(plan.migrations);
    
    return plan;
  }
  
  // í•« ìƒ¤ë“œ ê°ì§€ ë° ë¶„í• 
  async detectAndSplitHotShards(
    metrics: ShardMetrics[]
  ): Promise<ShardSplitResult[]> {
    const results: ShardSplitResult[] = [];
    const threshold = this.calculateDynamicThreshold(metrics);
    
    for (const metric of metrics) {
      if (metric.load > threshold) {
        const splitResult = await this.splitShard(metric.shardId);
        results.push(splitResult);
      }
    }
    
    return results;
  }
  
  private async splitShard(
    shardId: number
  ): Promise<ShardSplitResult> {
    // ê°€ìƒ ìƒ¤ë“œ ìƒì„±
    const virtualShards = this.createVirtualShards(shardId, 2);
    
    // ë°ì´í„° ì¬ë¶„ë°°
    const items = await this.readShardItems(shardId);
    const distribution = this.distributeToVirtualShards(
      items,
      virtualShards
    );
    
    // ìƒˆ ìƒ¤ë“œì— ì“°ê¸°
    await Promise.all(
      virtualShards.map((vShard, index) =>
        this.writeToShard(vShard, distribution[index])
      )
    );
    
    return {
      originalShard: shardId,
      newShards: virtualShards,
      itemsRedistributed: items.length,
      timestamp: new Date()
    };
  }
}

// ì§€ëŠ¥í˜• ìƒ¤ë”© ìµœì í™”
export class IntelligentShardingOptimizer {
  private ml: ShardingMLModel;
  
  constructor() {
    this.ml = new ShardingMLModel();
  }
  
  // ìµœì  ìƒ¤ë“œ ìˆ˜ ì˜ˆì¸¡
  async predictOptimalShardCount(
    workload: WorkloadProfile
  ): Promise<ShardingRecommendation> {
    const features = this.extractWorkloadFeatures(workload);
    const prediction = await this.ml.predict(features);
    
    return {
      recommendedShards: prediction.shardCount,
      confidence: prediction.confidence,
      reasoning: prediction.explanation,
      expectedImprovement: {
        throughput: prediction.throughputGain,
        latency: prediction.latencyReduction,
        cost: prediction.costOptimization
      }
    };
  }
  
  // ìƒ¤ë”© ì „ëµ í•™ìŠµ
  async learnFromPerformance(
    strategy: ShardingStrategy,
    performance: PerformanceMetrics
  ): Promise<void> {
    const example = {
      strategy: this.encodeStrategy(strategy),
      performance: this.normalizeMetrics(performance),
      timestamp: new Date()
    };
    
    await this.ml.addTrainingExample(example);
    
    // ì£¼ê¸°ì  ëª¨ë¸ ì¬í•™ìŠµ
    if (this.shouldRetrain()) {
      await this.ml.retrain();
    }
  }
  
  // ë™ì  ìƒ¤ë”© ì¡°ì •
  async adjustShardingDynamically(
    currentMetrics: ShardMetrics[]
  ): Promise<ShardingAdjustment> {
    const analysis = this.analyzeCurrentPerformance(currentMetrics);
    
    if (analysis.needsAdjustment) {
      const adjustment = await this.calculateAdjustment(analysis);
      
      // ì ì§„ì  ì¡°ì • ì‹¤í–‰
      return await this.executeGradualAdjustment(adjustment);
    }
    
    return { adjusted: false };
  }
}
```
### Task 2.4: ë„ë©”ì¸ ëª¨ë¸ ì •ì˜

#### SubTask 2.4.1: í•µì‹¬ ë„ë©”ì¸ ì—”í‹°í‹° ëª¨ë¸ë§
**ë‹´ë‹¹ì**: ë„ë©”ì¸ ì „ë¬¸ê°€ & ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/domain/models/core-entities.ts
import { z } from 'zod';

// ê¸°ë³¸ ë„ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
export interface DomainEntity {
  id: string;
  version: number;
  createdAt: Date;
  updatedAt: Date;
  createdBy: string;
  updatedBy?: string;
}

// User ë„ë©”ì¸ ëª¨ë¸
export const UserSchema = z.object({
  id: z.string().uuid(),
  email: z.string().email(),
  username: z.string().min(3).max(30),
  displayName: z.string().max(100),
  role: z.enum(['admin', 'developer', 'viewer', 'guest']),
  status: z.enum(['active', 'inactive', 'suspended', 'deleted']),
  preferences: z.object({
    theme: z.enum(['light', 'dark', 'auto']),
    language: z.string().default('en'),
    timezone: z.string().default('UTC'),
    notifications: z.object({
      email: z.boolean().default(true),
      push: z.boolean().default(false),
      inApp: z.boolean().default(true)
    })
  }),
  metadata: z.record(z.any()).optional(),
  lastLoginAt: z.date().optional(),
  emailVerifiedAt: z.date().optional(),
  version: z.number().default(1),
  createdAt: z.date(),
  updatedAt: z.date()
});

export type User = z.infer<typeof UserSchema>;

// Project ë„ë©”ì¸ ëª¨ë¸
export const ProjectSchema = z.object({
  id: z.string().uuid(),
  name: z.string().min(1).max(100),
  description: z.string().max(1000).optional(),
  ownerId: z.string().uuid(),
  organizationId: z.string().uuid().optional(),
  type: z.enum(['web', 'mobile', 'api', 'ml', 'data']),
  status: z.enum(['planning', 'active', 'paused', 'completed', 'archived']),
  visibility: z.enum(['private', 'team', 'organization', 'public']),
  settings: z.object({
    autoDeployEnabled: z.boolean().default(false),
    branchProtection: z.boolean().default(true),
    requireCodeReview: z.boolean().default(true),
    testCoverage: z.number().min(0).max(100).default(80),
    maxAgents: z.number().default(10),
    resourceLimits: z.object({
      cpu: z.number().default(2),
      memory: z.number().default(4096),
      storage: z.number().default(10240)
    })
  }),
  repository: z.object({
    provider: z.enum(['github', 'gitlab', 'bitbucket', 'internal']),
    url: z.string().url(),
    defaultBranch: z.string().default('main'),
    accessToken: z.string().optional()
  }).optional(),
  tags: z.array(z.string()).default([]),
  collaborators: z.array(z.object({
    userId: z.string().uuid(),
    role: z.enum(['owner', 'admin', 'contributor', 'viewer']),
    addedAt: z.date()
  })).default([]),
  metrics: z.object({
    totalTasks: z.number().default(0),
    completedTasks: z.number().default(0),
    activeAgents: z.number().default(0),
    lastActivityAt: z.date().optional()
  }),
  version: z.number().default(1),
  createdAt: z.date(),
  updatedAt: z.date()
});

export type Project = z.infer<typeof ProjectSchema>;

// Agent ë„ë©”ì¸ ëª¨ë¸
export const AgentSchema = z.object({
  id: z.string().uuid(),
  projectId: z.string().uuid(),
  type: z.enum([
    'ProjectManagerAgent',
    'RequirementsAgent', 
    'ArchitectAgent',
    'BackendAgent',
    'FrontendAgent',
    'DatabaseAgent',
    'DevOpsAgent',
    'TestingAgent',
    'DocumentationAgent'
  ]),
  name: z.string().min(1).max(100),
  description: z.string().max(500).optional(),
  status: z.enum(['idle', 'initializing', 'running', 'paused', 'completed', 'failed', 'terminated']),
  configuration: z.object({
    model: z.string().default('claude-3-opus'),
    temperature: z.number().min(0).max(1).default(0.7),
    maxTokens: z.number().default(4096),
    systemPrompt: z.string().optional(),
    tools: z.array(z.string()).default([]),
    permissions: z.object({
      canCreateFiles: z.boolean().default(true),
      canModifyFiles: z.boolean().default(true),
      canDeleteFiles: z.boolean().default(false),
      canExecuteCommands: z.boolean().default(false),
      canAccessNetwork: z.boolean().default(true)
    }),
    resourceLimits: z.object({
      maxExecutionTime: z.number().default(300000), // 5 minutes
      maxMemoryUsage: z.number().default(512), // MB
      maxApiCalls: z.number().default(1000)
    })
  }),
  state: z.object({
    currentTask: z.string().uuid().optional(),
    workingMemory: z.record(z.any()).default({}),
    conversationHistory: z.array(z.object({
      role: z.enum(['user', 'assistant', 'system']),
      content: z.string(),
      timestamp: z.date()
    })).default([]),
    checkpoints: z.array(z.object({
      id: z.string().uuid(),
      timestamp: z.date(),
      state: z.record(z.any())
    })).default([])
  }),
  metrics: z.object({
    tasksCompleted: z.number().default(0),
    tasksFailed: z.number().default(0),
    averageExecutionTime: z.number().default(0),
    totalExecutionTime: z.number().default(0),
    apiCallsUsed: z.number().default(0),
    errorRate: z.number().default(0),
    lastExecutionAt: z.date().optional()
  }),
  dependencies: z.array(z.string().uuid()).default([]),
  version: z.number().default(1),
  createdAt: z.date(),
  updatedAt: z.date()
});

export type Agent = z.infer<typeof AgentSchema>;

// Task ë„ë©”ì¸ ëª¨ë¸
export const TaskSchema = z.object({
  id: z.string().uuid(),
  projectId: z.string().uuid(),
  parentTaskId: z.string().uuid().optional(),
  agentId: z.string().uuid().optional(),
  type: z.enum(['epic', 'story', 'task', 'subtask', 'bug', 'spike']),
  title: z.string().min(1).max(200),
  description: z.string().max(5000).optional(),
  status: z.enum(['todo', 'in_progress', 'review', 'testing', 'done', 'cancelled']),
  priority: z.enum(['critical', 'high', 'medium', 'low']),
  complexity: z.enum(['XS', 'S', 'M', 'L', 'XL', 'XXL']),
  assignee: z.object({
    type: z.enum(['user', 'agent']),
    id: z.string().uuid()
  }).optional(),
  requirements: z.array(z.object({
    id: z.string().uuid(),
    description: z.string(),
    type: z.enum(['functional', 'technical', 'constraint']),
    status: z.enum(['pending', 'approved', 'implemented'])
  })).default([]),
  acceptance_criteria: z.array(z.string()).default([]),
  dependencies: z.array(z.object({
    taskId: z.string().uuid(),
    type: z.enum(['blocks', 'relates_to', 'duplicates'])
  })).default([]),
  artifacts: z.array(z.object({
    id: z.string().uuid(),
    type: z.enum(['code', 'document', 'diagram', 'test', 'config']),
    path: z.string(),
    url: z.string().url().optional(),
    createdAt: z.date()
  })).default([]),
  timeline: z.object({
    estimatedHours: z.number().optional(),
    actualHours: z.number().default(0),
    startDate: z.date().optional(),
    dueDate: z.date().optional(),
    completedAt: z.date().optional()
  }),
  metadata: z.record(z.any()).default({}),
  version: z.number().default(1),
  createdAt: z.date(),
  updatedAt: z.date()
});

export type Task = z.infer<typeof TaskSchema>;

// Conversation ë„ë©”ì¸ ëª¨ë¸
export const ConversationSchema = z.object({
  id: z.string().uuid(),
  projectId: z.string().uuid(),
  participants: z.array(z.object({
    type: z.enum(['user', 'agent']),
    id: z.string().uuid(),
    name: z.string()
  })),
  type: z.enum(['direct', 'group', 'broadcast']),
  status: z.enum(['active', 'archived', 'deleted']),
  messages: z.array(z.object({
    id: z.string().uuid(),
    senderId: z.string().uuid(),
    senderType: z.enum(['user', 'agent']),
    content: z.string(),
    attachments: z.array(z.object({
      type: z.enum(['file', 'code', 'image', 'link']),
      url: z.string().url(),
      metadata: z.record(z.any())
    })).default([]),
    mentions: z.array(z.string().uuid()).default([]),
    reactions: z.array(z.object({
      userId: z.string().uuid(),
      emoji: z.string(),
      timestamp: z.date()
    })).default([]),
    editedAt: z.date().optional(),
    deletedAt: z.date().optional(),
    timestamp: z.date()
  })).default([]),
  metadata: z.record(z.any()).default({}),
  version: z.number().default(1),
  createdAt: z.date(),
  updatedAt: z.date()
});

export type Conversation = z.infer<typeof ConversationSchema>;
```

#### SubTask 2.4.2: ë„ë©”ì¸ ì´ë²¤íŠ¸ ëª¨ë¸ë§
**ë‹´ë‹¹ì**: ì´ë²¤íŠ¸ ì£¼ë„ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/domain/events/domain-events.ts
export abstract class DomainEvent {
  public readonly occurredAt: Date;
  public readonly eventId: string;
  public readonly eventType: string;
  public readonly aggregateId: string;
  public readonly aggregateType: string;
  public readonly causationId?: string;
  public readonly correlationId?: string;
  public readonly metadata: Record<string, any>;

  constructor(params: {
    aggregateId: string;
    aggregateType: string;
    causationId?: string;
    correlationId?: string;
    metadata?: Record<string, any>;
  }) {
    this.eventId = uuidv4();
    this.occurredAt = new Date();
    this.eventType = this.constructor.name;
    this.aggregateId = params.aggregateId;
    this.aggregateType = params.aggregateType;
    this.causationId = params.causationId;
    this.correlationId = params.correlationId || uuidv4();
    this.metadata = params.metadata || {};
  }

  abstract toJSON(): Record<string, any>;
}

// User ì´ë²¤íŠ¸
export class UserCreatedEvent extends DomainEvent {
  constructor(
    public readonly userId: string,
    public readonly email: string,
    public readonly username: string,
    public readonly role: string
  ) {
    super({
      aggregateId: userId,
      aggregateType: 'User'
    });
  }

  toJSON() {
    return {
      userId: this.userId,
      email: this.email,
      username: this.username,
      role: this.role
    };
  }
}

export class UserRoleChangedEvent extends DomainEvent {
  constructor(
    public readonly userId: string,
    public readonly oldRole: string,
    public readonly newRole: string,
    public readonly changedBy: string
  ) {
    super({
      aggregateId: userId,
      aggregateType: 'User'
    });
  }

  toJSON() {
    return {
      userId: this.userId,
      oldRole: this.oldRole,
      newRole: this.newRole,
      changedBy: this.changedBy
    };
  }
}

// Project ì´ë²¤íŠ¸
export class ProjectCreatedEvent extends DomainEvent {
  constructor(
    public readonly projectId: string,
    public readonly name: string,
    public readonly ownerId: string,
    public readonly type: string
  ) {
    super({
      aggregateId: projectId,
      aggregateType: 'Project'
    });
  }

  toJSON() {
    return {
      projectId: this.projectId,
      name: this.name,
      ownerId: this.ownerId,
      type: this.type
    };
  }
}

export class ProjectStatusChangedEvent extends DomainEvent {
  constructor(
    public readonly projectId: string,
    public readonly oldStatus: string,
    public readonly newStatus: string,
    public readonly reason?: string
  ) {
    super({
      aggregateId: projectId,
      aggregateType: 'Project'
    });
  }

  toJSON() {
    return {
      projectId: this.projectId,
      oldStatus: this.oldStatus,
      newStatus: this.newStatus,
      reason: this.reason
    };
  }
}

// Agent ì´ë²¤íŠ¸
export class AgentStartedEvent extends DomainEvent {
  constructor(
    public readonly agentId: string,
    public readonly projectId: string,
    public readonly agentType: string,
    public readonly taskId?: string
  ) {
    super({
      aggregateId: agentId,
      aggregateType: 'Agent'
    });
  }

  toJSON() {
    return {
      agentId: this.agentId,
      projectId: this.projectId,
      agentType: this.agentType,
      taskId: this.taskId
    };
  }
}

export class AgentCompletedTaskEvent extends DomainEvent {
  constructor(
    public readonly agentId: string,
    public readonly taskId: string,
    public readonly executionTime: number,
    public readonly result: any
  ) {
    super({
      aggregateId: agentId,
      aggregateType: 'Agent'
    });
  }

  toJSON() {
    return {
      agentId: this.agentId,
      taskId: this.taskId,
      executionTime: this.executionTime,
      result: this.result
    };
  }
}

export class AgentFailedEvent extends DomainEvent {
  constructor(
    public readonly agentId: string,
    public readonly error: string,
    public readonly stackTrace?: string,
    public readonly retryable: boolean = false
  ) {
    super({
      aggregateId: agentId,
      aggregateType: 'Agent'
    });
  }

  toJSON() {
    return {
      agentId: this.agentId,
      error: this.error,
      stackTrace: this.stackTrace,
      retryable: this.retryable
    };
  }
}

// Task ì´ë²¤íŠ¸  
export class TaskCreatedEvent extends DomainEvent {
  constructor(
    public readonly taskId: string,
    public readonly projectId: string,
    public readonly title: string,
    public readonly type: string,
    public readonly createdBy: string
  ) {
    super({
      aggregateId: taskId,
      aggregateType: 'Task'
    });
  }

  toJSON() {
    return {
      taskId: this.taskId,
      projectId: this.projectId,
      title: this.title,
      type: this.type,
      createdBy: this.createdBy
    };
  }
}

export class TaskAssignedEvent extends DomainEvent {
  constructor(
    public readonly taskId: string,
    public readonly assigneeType: 'user' | 'agent',
    public readonly assigneeId: string,
    public readonly previousAssigneeId?: string
  ) {
    super({
      aggregateId: taskId,
      aggregateType: 'Task'
    });
  }

  toJSON() {
    return {
      taskId: this.taskId,
      assigneeType: this.assigneeType,
      assigneeId: this.assigneeId,
      previousAssigneeId: this.previousAssigneeId
    };
  }
}

// ì´ë²¤íŠ¸ ìŠ¤í† ì–´
export class EventStore {
  constructor(
    private dynamoDB: DynamoDBDocumentClient,
    private tableName: string
  ) {}

  async saveEvent(event: DomainEvent): Promise<void> {
    const item = {
      PK: `EVENT#${event.aggregateType}#${event.aggregateId}`,
      SK: `${event.occurredAt.toISOString()}#${event.eventId}`,
      EventId: event.eventId,
      EventType: event.eventType,
      AggregateId: event.aggregateId,
      AggregateType: event.aggregateType,
      OccurredAt: event.occurredAt.toISOString(),
      CausationId: event.causationId,
      CorrelationId: event.correlationId,
      Metadata: event.metadata,
      Data: event.toJSON(),
      TTL: Math.floor(Date.now() / 1000) + (365 * 24 * 60 * 60) // 1ë…„
    };

    await this.dynamoDB.send(new PutCommand({
      TableName: this.tableName,
      Item: item
    }));
  }

  async getEvents(
    aggregateId: string,
    aggregateType: string,
    fromDate?: Date,
    toDate?: Date
  ): Promise<DomainEvent[]> {
    const params: QueryCommandInput = {
      TableName: this.tableName,
      KeyConditionExpression: 'PK = :pk',
      ExpressionAttributeValues: {
        ':pk': `EVENT#${aggregateType}#${aggregateId}`
      }
    };

    if (fromDate || toDate) {
      params.KeyConditionExpression += ' AND SK BETWEEN :from AND :to';
      params.ExpressionAttributeValues![':from'] = fromDate?.toISOString() || '0';
      params.ExpressionAttributeValues![':to'] = toDate?.toISOString() || '9999';
    }

    const result = await this.dynamoDB.send(new QueryCommand(params));
    return result.Items?.map(item => this.deserializeEvent(item)) || [];
  }

  private deserializeEvent(item: any): DomainEvent {
    // ì´ë²¤íŠ¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ í´ë˜ìŠ¤ë¡œ ì—­ì§ë ¬í™”
    const eventClass = this.getEventClass(item.EventType);
    return new eventClass(item.Data);
  }
}
```

#### SubTask 2.4.3: ê°’ ê°ì²´ ë° ì§‘ê³„ ì •ì˜
**ë‹´ë‹¹ì**: DDD ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/domain/value-objects/index.ts

// Email ê°’ ê°ì²´
export class Email {
  private readonly value: string;

  constructor(email: string) {
    if (!this.isValid(email)) {
      throw new Error(`Invalid email format: ${email}`);
    }
    this.value = email.toLowerCase();
  }

  private isValid(email: string): boolean {
    const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
    return emailRegex.test(email);
  }

  toString(): string {
    return this.value;
  }

  equals(other: Email): boolean {
    return this.value === other.value;
  }

  getDomain(): string {
    return this.value.split('@')[1];
  }
}

// ProjectName ê°’ ê°ì²´
export class ProjectName {
  private readonly value: string;

  constructor(name: string) {
    const trimmed = name.trim();
    if (trimmed.length < 1 || trimmed.length > 100) {
      throw new Error('Project name must be between 1 and 100 characters');
    }
    if (!/^[a-zA-Z0-9\s\-_]+$/.test(trimmed)) {
      throw new Error('Project name contains invalid characters');
    }
    this.value = trimmed;
  }

  toString(): string {
    return this.value;
  }

  toSlug(): string {
    return this.value
      .toLowerCase()
      .replace(/\s+/g, '-')
      .replace(/[^a-z0-9\-]/g, '');
  }
}

// TimeRange ê°’ ê°ì²´
export class TimeRange {
  constructor(
    public readonly start: Date,
    public readonly end: Date
  ) {
    if (start >= end) {
      throw new Error('Start time must be before end time');
    }
  }

  getDuration(): number {
    return this.end.getTime() - this.start.getTime();
  }

  contains(date: Date): boolean {
    return date >= this.start && date <= this.end;
  }

  overlaps(other: TimeRange): boolean {
    return this.start < other.end && this.end > other.start;
  }
}

// ResourceLimits ê°’ ê°ì²´
export class ResourceLimits {
  constructor(
    public readonly cpu: number,
    public readonly memory: number,
    public readonly storage: number
  ) {
    if (cpu <= 0 || memory <= 0 || storage <= 0) {
      throw new Error('Resource limits must be positive');
    }
  }

  exceedsLimits(usage: ResourceUsage): boolean {
    return usage.cpu > this.cpu || 
           usage.memory > this.memory || 
           usage.storage > this.storage;
  }
}

// backend/src/domain/aggregates/project-aggregate.ts
export class ProjectAggregate {
  private events: DomainEvent[] = [];
  
  constructor(
    private state: Project,
    private eventStore: EventStore
  ) {}

  // Commands
  async create(params: CreateProjectParams): Promise<void> {
    if (this.state.id) {
      throw new Error('Project already exists');
    }

    const project: Project = {
      id: uuidv4(),
      name: params.name,
      description: params.description,
      ownerId: params.ownerId,
      type: params.type,
      status: 'planning',
      visibility: params.visibility || 'private',
      settings: this.getDefaultSettings(),
      tags: params.tags || [],
      collaborators: [{
        userId: params.ownerId,
        role: 'owner',
        addedAt: new Date()
      }],
      metrics: {
        totalTasks: 0,
        completedTasks: 0,
        activeAgents: 0
      },
      version: 1,
      createdAt: new Date(),
      updatedAt: new Date()
    };

    this.state = project;
    this.addEvent(new ProjectCreatedEvent(
      project.id,
      project.name,
      project.ownerId,
      project.type
    ));
  }

  async updateStatus(
    newStatus: Project['status'],
    reason?: string
  ): Promise<void> {
    const validTransitions: Record<string, string[]> = {
      planning: ['active', 'archived'],
      active: ['paused', 'completed', 'archived'],
      paused: ['active', 'archived'],
      completed: ['archived'],
      archived: []
    };

    if (!validTransitions[this.state.status].includes(newStatus)) {
      throw new Error(
        `Invalid status transition from ${this.state.status} to ${newStatus}`
      );
    }

    const oldStatus = this.state.status;
    this.state.status = newStatus;
    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new ProjectStatusChangedEvent(
      this.state.id,
      oldStatus,
      newStatus,
      reason
    ));
  }

  async addCollaborator(
    userId: string,
    role: 'admin' | 'contributor' | 'viewer',
    addedBy: string
  ): Promise<void> {
    if (this.state.collaborators.some(c => c.userId === userId)) {
      throw new Error('User is already a collaborator');
    }

    this.state.collaborators.push({
      userId,
      role,
      addedAt: new Date()
    });

    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new ProjectCollaboratorAddedEvent(
      this.state.id,
      userId,
      role,
      addedBy
    ));
  }

  async removeCollaborator(
    userId: string,
    removedBy: string
  ): Promise<void> {
    const collaborator = this.state.collaborators.find(
      c => c.userId === userId
    );

    if (!collaborator) {
      throw new Error('User is not a collaborator');
    }

    if (collaborator.role === 'owner') {
      throw new Error('Cannot remove project owner');
    }

    this.state.collaborators = this.state.collaborators.filter(
      c => c.userId !== userId
    );

    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new ProjectCollaboratorRemovedEvent(
      this.state.id,
      userId,
      removedBy
    ));
  }

  // Event handling
  private addEvent(event: DomainEvent): void {
    this.events.push(event);
  }

  async commit(): Promise<void> {
    // Save state to database
    await this.saveState();

    // Save events
    for (const event of this.events) {
      await this.eventStore.saveEvent(event);
    }

    // Publish events
    await this.publishEvents();

    // Clear events
    this.events = [];
  }

  private async saveState(): Promise<void> {
    // Implementation to save aggregate state to DynamoDB
  }

  private async publishEvents(): Promise<void> {
    // Implementation to publish events to event bus
  }

  // Queries
  hasPermission(userId: string, permission: string): boolean {
    const collaborator = this.state.collaborators.find(
      c => c.userId === userId
    );

    if (!collaborator) {
      return false;
    }

    const permissions: Record<string, string[]> = {
      owner: ['read', 'write', 'delete', 'admin'],
      admin: ['read', 'write', 'admin'],
      contributor: ['read', 'write'],
      viewer: ['read']
    };

    return permissions[collaborator.role].includes(permission);
  }

  getState(): Readonly<Project> {
    return Object.freeze({ ...this.state });
  }
}

// backend/src/domain/aggregates/agent-aggregate.ts
export class AgentAggregate {
  private events: DomainEvent[] = [];
  private stateHistory: AgentState[] = [];

  constructor(
    private state: Agent,
    private eventStore: EventStore
  ) {}

  async start(taskId?: string): Promise<void> {
    if (this.state.status !== 'idle') {
      throw new Error(`Cannot start agent in ${this.state.status} state`);
    }

    this.state.status = 'initializing';
    this.state.state.currentTask = taskId;
    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new AgentStartedEvent(
      this.state.id,
      this.state.projectId,
      this.state.type,
      taskId
    ));

    // Initialize agent runtime
    await this.initializeRuntime();
    
    this.state.status = 'running';
    this.state.metrics.lastExecutionAt = new Date();
  }

  async completeTask(
    taskId: string,
    result: any,
    executionTime: number
  ): Promise<void> {
    if (this.state.state.currentTask !== taskId) {
      throw new Error('Task mismatch');
    }

    this.state.metrics.tasksCompleted++;
    this.state.metrics.totalExecutionTime += executionTime;
    this.state.metrics.averageExecutionTime = 
      this.state.metrics.totalExecutionTime / this.state.metrics.tasksCompleted;

    this.state.state.currentTask = undefined;
    this.state.status = 'idle';
    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new AgentCompletedTaskEvent(
      this.state.id,
      taskId,
      executionTime,
      result
    ));
  }

  async fail(error: Error, retryable: boolean = false): Promise<void> {
    this.state.status = 'failed';
    this.state.metrics.tasksFailed++;
    this.state.metrics.errorRate = 
      this.state.metrics.tasksFailed / 
      (this.state.metrics.tasksCompleted + this.state.metrics.tasksFailed);

    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new AgentFailedEvent(
      this.state.id,
      error.message,
      error.stack,
      retryable
    ));
  }

  async checkpoint(): Promise<string> {
    const checkpointId = uuidv4();
    const checkpoint = {
      id: checkpointId,
      timestamp: new Date(),
      state: {
        ...this.state.state,
        workingMemory: { ...this.state.state.workingMemory }
      }
    };

    this.state.state.checkpoints.push(checkpoint);
    
    // Keep only last 10 checkpoints
    if (this.state.state.checkpoints.length > 10) {
      this.state.state.checkpoints.shift();
    }

    this.state.updatedAt = new Date();
    this.state.version++;

    return checkpointId;
  }

  async restore(checkpointId: string): Promise<void> {
    const checkpoint = this.state.state.checkpoints.find(
      c => c.id === checkpointId
    );

    if (!checkpoint) {
      throw new Error(`Checkpoint ${checkpointId} not found`);
    }

    // Save current state to history
    this.stateHistory.push({ ...this.state.state });

    // Restore from checkpoint
    this.state.state = {
      ...checkpoint.state,
      checkpoints: this.state.state.checkpoints
    };

    this.state.updatedAt = new Date();
    this.state.version++;

    this.addEvent(new AgentRestoredEvent(
      this.state.id,
      checkpointId
    ));
  }

  private async initializeRuntime(): Promise<void> {
    // Implementation to initialize agent runtime environment
  }

  private addEvent(event: DomainEvent): void {
    this.events.push(event);
  }

  async commit(): Promise<void> {
    // Similar to ProjectAggregate commit
  }
}
```

#### SubTask 2.4.4: ë„ë©”ì¸ ì„œë¹„ìŠ¤ êµ¬í˜„
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/domain/services/project-orchestration.service.ts
export class ProjectOrchestrationService {
  constructor(
    private projectRepo: ProjectRepository,
    private agentRepo: AgentRepository,
    private taskRepo: TaskRepository,
    private eventBus: EventBus
  ) {}

  async createProjectWithAgents(
    params: CreateProjectWithAgentsParams
  ): Promise<ProjectCreationResult> {
    const transaction = new DomainTransaction();

    try {
      // 1. Create project
      const project = await this.createProject(params.project, transaction);

      // 2. Create initial agents based on project type
      const agents = await this.createInitialAgents(
        project.id,
        project.type,
        transaction
      );

      // 3. Create initial task structure
      const tasks = await this.createInitialTasks(
        project.id,
        params.initialRequirements,
        transaction
      );

      // 4. Assign tasks to agents
      await this.assignTasksToAgents(tasks, agents, transaction);

      // 5. Commit transaction
      await transaction.commit();

      // 6. Publish project creation event
      await this.eventBus.publish(new ProjectInitializedEvent(
        project.id,
        agents.map(a => a.id),
        tasks.map(t => t.id)
      ));

      return {
        project,
        agents,
        tasks,
        success: true
      };
    } catch (error) {
      await transaction.rollback();
      throw error;
    }
  }

  private async createInitialAgents(
    projectId: string,
    projectType: string,
    transaction: DomainTransaction
  ): Promise<Agent[]> {
    const agentTypes = this.getRequiredAgentTypes(projectType);
    const agents: Agent[] = [];

    for (const agentType of agentTypes) {
      const agent = await this.agentRepo.create({
        projectId,
        type: agentType,
        name: `${agentType} for ${projectId}`,
        status: 'idle',
        configuration: this.getAgentConfiguration(agentType)
      }, transaction);

      agents.push(agent);
    }

    return agents;
  }

  private getRequiredAgentTypes(projectType: string): string[] {
    const agentTypeMap: Record<string, string[]> = {
      web: [
        'ProjectManagerAgent',
        'RequirementsAgent',
        'ArchitectAgent',
        'BackendAgent',
        'FrontendAgent',
        'DatabaseAgent',
        'TestingAgent',
        'DevOpsAgent'
      ],
      api: [
        'ProjectManagerAgent',
        'RequirementsAgent',
        'ArchitectAgent',
        'BackendAgent',
        'DatabaseAgent',
        'TestingAgent',
        'DocumentationAgent'
      ],
      mobile: [
        'ProjectManagerAgent',
        'RequirementsAgent',
        'ArchitectAgent',
        'FrontendAgent',
        'BackendAgent',
        'TestingAgent'
      ]
    };

    return agentTypeMap[projectType] || agentTypeMap.web;
  }
}

// backend/src/domain/services/agent-coordination.service.ts
export class AgentCoordinationService {
  private coordinationRules: CoordinationRule[] = [];

  constructor(
    private agentManager: AgentManager,
    private messageQueue: MessageQueue,
    private stateManager: StateManager
  ) {
    this.initializeCoordinationRules();
  }

  async coordinateAgents(
    context: CoordinationContext
  ): Promise<CoordinationResult> {
    // 1. Analyze current state
    const currentState = await this.analyzeCurrentState(context);

    // 2. Determine coordination strategy
    const strategy = this.selectCoordinationStrategy(currentState);

    // 3. Execute coordination
    const result = await this.executeCoordination(strategy, context);

    // 4. Update agent states
    await this.updateAgentStates(result);

    return result;
  }

  private async analyzeCurrentState(
    context: CoordinationContext
  ): Promise<SystemState> {
    const agentStates = await Promise.all(
      context.agentIds.map(id => this.agentManager.getAgentState(id))
    );

    const taskProgress = await this.calculateTaskProgress(context.taskIds);
    const dependencies = await this.analyzeDependencies(context);

    return {
      agents: agentStates,
      taskProgress,
      dependencies,
      bottlenecks: this.identifyBottlenecks(agentStates, dependencies)
    };
  }

  private selectCoordinationStrategy(
    state: SystemState
  ): CoordinationStrategy {
    // Rule-based strategy selection
    for (const rule of this.coordinationRules) {
      if (rule.matches(state)) {
        return rule.strategy;
      }
    }

    // Default strategy
    return new ParallelCoordinationStrategy();
  }

  private async executeCoordination(
    strategy: CoordinationStrategy,
    context: CoordinationContext
  ): Promise<CoordinationResult> {
    const plan = strategy.createPlan(context);
    const results: AgentExecutionResult[] = [];

    for (const step of plan.steps) {
      if (step.parallel) {
        const parallelResults = await this.executeParallelStep(step);
        results.push(...parallelResults);
      } else {
        const sequentialResult = await this.executeSequentialStep(step);
        results.push(sequentialResult);
      }
    }

    return {
      plan,
      results,
      success: results.every(r => r.success),
      duration: this.calculateTotalDuration(results)
    };
  }

  private initializeCoordinationRules(): void {
    this.coordinationRules = [
      {
        name: 'Sequential Dependencies',
        matches: (state) => state.dependencies.some(d => d.type === 'sequential'),
        strategy: new SequentialCoordinationStrategy()
      },
      {
        name: 'Resource Constraints',
        matches: (state) => state.bottlenecks.length > 0,
        strategy: new ResourceOptimizedStrategy()
      },
      {
        name: 'High Parallelism',
        matches: (state) => state.dependencies.every(d => d.type === 'parallel'),
        strategy: new ParallelCoordinationStrategy()
      }
    ];
  }
}

// backend/src/domain/services/task-assignment.service.ts
export class TaskAssignmentService {
  constructor(
    private agentCapabilities: AgentCapabilityRegistry,
    private workloadAnalyzer: WorkloadAnalyzer,
    private performanceTracker: PerformanceTracker
  ) {}

  async assignTaskToOptimalAgent(
    task: Task,
    availableAgents: Agent[]
  ): Promise<TaskAssignment> {
    // 1. Filter capable agents
    const capableAgents = await this.filterCapableAgents(
      task,
      availableAgents
    );

    if (capableAgents.length === 0) {
      throw new Error(`No capable agents found for task ${task.id}`);
    }

    // 2. Score agents
    const scores = await this.scoreAgents(task, capableAgents);

    // 3. Select optimal agent
    const optimalAgent = this.selectOptimalAgent(scores);

    // 4. Create assignment
    const assignment = await this.createAssignment(
      task,
      optimalAgent,
      scores.get(optimalAgent.id)!
    );

    // 5. Update workload
    await this.workloadAnalyzer.updateAgentWorkload(
      optimalAgent.id,
      task
    );

    return assignment;
  }

  private async filterCapableAgents(
    task: Task,
    agents: Agent[]
  ): Promise<Agent[]> {
    const capable: Agent[] = [];

    for (const agent of agents) {
      const capabilities = await this.agentCapabilities.getCapabilities(
        agent.type
      );

      if (this.taskMatchesCapabilities(task, capabilities)) {
        capable.push(agent);
      }
    }

    return capable;
  }

  private async scoreAgents(
    task: Task,
    agents: Agent[]
  ): Promise<Map<string, AgentScore>> {
    const scores = new Map<string, AgentScore>();

    for (const agent of agents) {
      const workload = await this.workloadAnalyzer.getAgentWorkload(
        agent.id
      );
      const performance = await this.performanceTracker.getAgentPerformance(
        agent.id,
        task.type
      );

      const score = this.calculateAgentScore({
        agent,
        task,
        workload,
        performance
      });

      scores.set(agent.id, score);
    }

    return scores;
  }

  private calculateAgentScore(params: {
    agent: Agent;
    task: Task;
    workload: AgentWorkload;
    performance: AgentPerformance;
  }): AgentScore {
    const weights = {
      availability: 0.3,
      expertise: 0.3,
      performance: 0.2,
      workload: 0.2
    };

    const availabilityScore = this.calculateAvailabilityScore(
      params.workload
    );
    const expertiseScore = this.calculateExpertiseScore(
      params.agent,
      params.task
    );
    const performanceScore = this.calculatePerformanceScore(
      params.performance
    );
    const workloadScore = this.calculateWorkloadScore(
      params.workload
    );

    const totalScore = 
      availabilityScore * weights.availability +
      expertiseScore * weights.expertise +
      performanceScore * weights.performance +
      workloadScore * weights.workload;

    return {
      agentId: params.agent.id,
      totalScore,
      breakdown: {
        availability: availabilityScore,
        expertise: expertiseScore,
        performance: performanceScore,
        workload: workloadScore
      }
    };
  }
}
```

---

### Task 2.5: ë°ì´í„° ê²€ì¦ ë° ìŠ¤í‚¤ë§ˆ ê´€ë¦¬

#### SubTask 2.5.1: ëŸ°íƒ€ì„ ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/validation/runtime-validator.ts
import { z, ZodError, ZodSchema } from 'zod';

export class RuntimeValidator {
  private schemas: Map<string, ZodSchema> = new Map();
  private validationStats: Map<string, ValidationStats> = new Map();

  // ìŠ¤í‚¤ë§ˆ ë“±ë¡
  registerSchema(name: string, schema: ZodSchema): void {
    this.schemas.set(name, schema);
    this.validationStats.set(name, {
      totalValidations: 0,
      successfulValidations: 0,
      failedValidations: 0,
      commonErrors: new Map()
    });
  }

  // ë°ì´í„° ê²€ì¦
  validate<T>(
    schemaName: string,
    data: unknown,
    options?: ValidationOptions
  ): ValidationResult<T> {
    const schema = this.schemas.get(schemaName);
    if (!schema) {
      throw new Error(`Schema '${schemaName}' not found`);
    }

    const stats = this.validationStats.get(schemaName)!;
    stats.totalValidations++;

    try {
      const validated = schema.parse(data) as T;
      stats.successfulValidations++;

      return {
        success: true,
        data: validated,
        errors: []
      };
    } catch (error) {
      stats.failedValidations++;

      if (error instanceof ZodError) {
        const errors = this.formatZodErrors(error);
        this.updateErrorStats(schemaName, errors);

        if (options?.throwOnError) {
          throw new ValidationError(schemaName, errors);
        }

        return {
          success: false,
          data: null,
          errors
        };
      }

      throw error;
    }
  }

  // ë°°ì¹˜ ê²€ì¦
  async validateBatch<T>(
    schemaName: string,
    items: unknown[],
    options?: BatchValidationOptions
  ): Promise<BatchValidationResult<T>> {
    const results: ValidationResult<T>[] = [];
    const validItems: T[] = [];
    const invalidItems: InvalidItem[] = [];

    const batchSize = options?.batchSize || 100;
    const chunks = this.chunkArray(items, batchSize);

    for (const chunk of chunks) {
      const chunkResults = await Promise.all(
        chunk.map((item, index) => {
          const result = this.validate<T>(schemaName, item);
          if (result.success) {
            validItems.push(result.data!);
          } else {
            invalidItems.push({
              index,
              item,
              errors: result.errors
            });
          }
          return result;
        })
      );

      results.push(...chunkResults);

      // ì¡°ê¸° ì¢…ë£Œ ì˜µì…˜
      if (options?.stopOnFirstError && invalidItems.length > 0) {
        break;
      }
    }

    return {
      totalItems: items.length,
      validItems,
      invalidItems,
      successRate: validItems.length / items.length,
      validationTime: Date.now()
    };
  }

  // ë™ì  ìŠ¤í‚¤ë§ˆ ìƒì„±
  createDynamicSchema(
    definition: SchemaDefinition
  ): ZodSchema {
    const shape: Record<string, any> = {};

    for (const [field, config] of Object.entries(definition.fields)) {
      let fieldSchema = this.createFieldSchema(config);

      if (config.required === false) {
        fieldSchema = fieldSchema.optional();
      }

      if (config.nullable) {
        fieldSchema = fieldSchema.nullable();
      }

      if (config.default !== undefined) {
        fieldSchema = fieldSchema.default(config.default);
      }

      shape[field] = fieldSchema;
    }

    return z.object(shape);
  }

  private createFieldSchema(config: FieldConfig): ZodSchema {
    switch (config.type) {
      case 'string':
        let stringSchema = z.string();
        if (config.min) stringSchema = stringSchema.min(config.min);
        if (config.max) stringSchema = stringSchema.max(config.max);
        if (config.pattern) stringSchema = stringSchema.regex(config.pattern);
        if (config.format === 'email') stringSchema = stringSchema.email();
        if (config.format === 'url') stringSchema = stringSchema.url();
        if (config.format === 'uuid') stringSchema = stringSchema.uuid();
        return stringSchema;

      case 'number':
        let numberSchema = z.number();
        if (config.min !== undefined) numberSchema = numberSchema.min(config.min);
        if (config.max !== undefined) numberSchema = numberSchema.max(config.max);
        if (config.integer) numberSchema = numberSchema.int();
        return numberSchema;

      case 'boolean':
        return z.boolean();

      case 'date':
        let dateSchema = z.date();
        if (config.min) dateSchema = dateSchema.min(new Date(config.min));
        if (config.max) dateSchema = dateSchema.max(new Date(config.max));
        return dateSchema;

      case 'array':
        const itemSchema = this.createFieldSchema(config.items!);
        let arraySchema = z.array(itemSchema);
        if (config.min !== undefined) arraySchema = arraySchema.min(config.min);
        if (config.max !== undefined) arraySchema = arraySchema.max(config.max);
        return arraySchema;

      case 'object':
        if (config.properties) {
          const shape: Record<string, ZodSchema> = {};
          for (const [key, value] of Object.entries(config.properties)) {
            shape[key] = this.createFieldSchema(value);
          }
          return z.object(shape);
        }
        return z.record(z.any());

      case 'enum':
        return z.enum(config.values as [string, ...string[]]);

      default:
        return z.any();
    }
  }

  // ê²€ì¦ í†µê³„
  getValidationStats(schemaName?: string): ValidationStats | Map<string, ValidationStats> {
    if (schemaName) {
      return this.validationStats.get(schemaName) || {
        totalValidations: 0,
        successfulValidations: 0,
        failedValidations: 0,
        commonErrors: new Map()
      };
    }
    return this.validationStats;
  }

  private formatZodErrors(error: ZodError): ValidationError[] {
    return error.errors.map(err => ({
      path: err.path.join('.'),
      message: err.message,
      code: err.code,
      expected: (err as any).expected,
      received: (err as any).received
    }));
  }

  private updateErrorStats(schemaName: string, errors: ValidationError[]): void {
    const stats = this.validationStats.get(schemaName)!;
    
    for (const error of errors) {
      const errorKey = `${error.path}:${error.code}`;
      const count = stats.commonErrors.get(errorKey) || 0;
      stats.commonErrors.set(errorKey, count + 1);
    }
  }

  private chunkArray<T>(array: T[], size: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
}

// ì»¤ìŠ¤í…€ ê²€ì¦ ê·œì¹™
export class CustomValidationRules {
  static readonly rules = new Map<string, ValidationRule>();

  static register(name: string, rule: ValidationRule): void {
    this.rules.set(name, rule);
  }

  static validate(ruleName: string, value: any, context?: any): boolean {
    const rule = this.rules.get(ruleName);
    if (!rule) {
      throw new Error(`Validation rule '${ruleName}' not found`);
    }
    return rule.validate(value, context);
  }
}

// ë„ë©”ì¸ë³„ ê²€ì¦ê¸°
export class DomainValidator extends RuntimeValidator {
  constructor() {
    super();
    this.registerDomainSchemas();
    this.registerCustomRules();
  }

  private registerDomainSchemas(): void {
    // User ë„ë©”ì¸
    this.registerSchema('User', UserSchema);
    this.registerSchema('UserUpdate', UserSchema.partial());
    
    // Project ë„ë©”ì¸
    this.registerSchema('Project', ProjectSchema);
    this.registerSchema('ProjectCreate', ProjectSchema.omit({ 
      id: true, 
      createdAt: true, 
      updatedAt: true 
    }));
    
    // Agent ë„ë©”ì¸
    this.registerSchema('Agent', AgentSchema);
    this.registerSchema('AgentConfiguration', AgentSchema.shape.configuration);
    
    // Task ë„ë©”ì¸
    this.registerSchema('Task', TaskSchema);
    this.registerSchema('TaskCreate', TaskSchema.omit({ 
      id: true, 
      version: true,
      createdAt: true,
      updatedAt: true 
    }));
  }

  private registerCustomRules(): void {
    // í”„ë¡œì íŠ¸ ì´ë¦„ ìœ ì¼ì„±
    CustomValidationRules.register('uniqueProjectName', {
      validate: async (name: string, context: { userId: string }) => {
        const exists = await this.checkProjectNameExists(name, context.userId);
        return !exists;
      },
      message: 'Project name already exists'
    });

    // ì—ì´ì „íŠ¸ íƒ€ì…ë³„ ì„¤ì • ê²€ì¦
    CustomValidationRules.register('validAgentConfig', {
      validate: (config: any, context: { agentType: string }) => {
        const requiredTools = this.getRequiredToolsForAgent(context.agentType);
        return requiredTools.every(tool => config.tools.includes(tool));
      },
      message: 'Agent configuration missing required tools'
    });

    // íƒœìŠ¤í¬ ì˜ì¡´ì„± ìˆœí™˜ ì°¸ì¡° ê²€ì¦
    CustomValidationRules.register('noCyclicDependencies', {
      validate: async (dependencies: any[], context: { taskId: string }) => {
        return !await this.hasCyclicDependency(context.taskId, dependencies);
      },
      message: 'Cyclic dependency detected'
    });
  }

  private async checkProjectNameExists(name: string, userId: string): Promise<boolean> {
    // Implementation
    return false;
  }

  private getRequiredToolsForAgent(agentType: string): string[] {
    const toolMap: Record<string, string[]> = {
      'BackendAgent': ['code-generator', 'test-runner', 'git'],
      'FrontendAgent': ['ui-builder', 'style-generator', 'bundler'],
      'DatabaseAgent': ['schema-designer', 'query-optimizer', 'migrator']
    };
    return toolMap[agentType] || [];
  }

  private async hasCyclicDependency(taskId: string, dependencies: any[]): Promise<boolean> {
    // Implementation
    return false;
  }
}
```

#### SubTask 2.5.2: ìŠ¤í‚¤ë§ˆ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/schema/version-manager.ts
export class SchemaVersionManager {
  private versions: Map<string, SchemaVersion[]> = new Map();
  private migrations: Map<string, Migration[]> = new Map();
  
  constructor(
    private storage: SchemaStorage,
    private validator: RuntimeValidator
  ) {}

  // ìŠ¤í‚¤ë§ˆ ë²„ì „ ë“±ë¡
  async registerVersion(
    entityName: string,
    version: SchemaVersion
  ): Promise<void> {
    const versions = this.versions.get(entityName) || [];
    
    // ë²„ì „ ì¤‘ë³µ í™•ì¸
    if (versions.some(v => v.version === version.version)) {
      throw new Error(
        `Schema version ${version.version} already exists for ${entityName}`
      );
    }

    // ë²„ì „ ê²€ì¦
    await this.validateSchemaVersion(version);

    // ì´ì „ ë²„ì „ê³¼ì˜ í˜¸í™˜ì„± í™•ì¸
    if (versions.length > 0) {
      const previousVersion = versions[versions.length - 1];
      await this.checkCompatibility(previousVersion, version);
    }

    versions.push(version);
    versions.sort((a, b) => this.compareVersions(a.version, b.version));
    this.versions.set(entityName, versions);

    // ìŠ¤í† ë¦¬ì§€ì— ì €ì¥
    await this.storage.saveSchemaVersion(entityName, version);
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±
  async createMigration(
    entityName: string,
    fromVersion: string,
    toVersion: string
  ): Promise<Migration> {
    const fromSchema = await this.getSchema(entityName, fromVersion);
    const toSchema = await this.getSchema(entityName, toVersion);

    const changes = this.detectSchemaChanges(fromSchema, toSchema);
    
    const migration: Migration = {
      id: uuidv4(),
      entityName,
      fromVersion,
      toVersion,
      changes,
      up: this.generateUpMigration(changes),
      down: this.generateDownMigration(changes),
      createdAt: new Date()
    };

    // ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦
    await this.validateMigration(migration);

    // ë§ˆì´ê·¸ë ˆì´ì…˜ ì €ì¥
    const migrations = this.migrations.get(entityName) || [];
    migrations.push(migration);
    this.migrations.set(entityName, migrations);

    return migration;
  }

  // ìŠ¤í‚¤ë§ˆ ë³€ê²½ ê°ì§€
  private detectSchemaChanges(
    fromSchema: SchemaDefinition,
    toSchema: SchemaDefinition
  ): SchemaChange[] {
    const changes: SchemaChange[] = [];

    // í•„ë“œ ì¶”ê°€ ê°ì§€
    for (const [field, config] of Object.entries(toSchema.fields)) {
      if (!fromSchema.fields[field]) {
        changes.push({
          type: 'ADD_FIELD',
          field,
          config
        });
      }
    }

    // í•„ë“œ ì œê±° ê°ì§€
    for (const field of Object.keys(fromSchema.fields)) {
      if (!toSchema.fields[field]) {
        changes.push({
          type: 'REMOVE_FIELD',
          field
        });
      }
    }

    // í•„ë“œ ë³€ê²½ ê°ì§€
    for (const [field, newConfig] of Object.entries(toSchema.fields)) {
      const oldConfig = fromSchema.fields[field];
      if (oldConfig && !this.isFieldConfigEqual(oldConfig, newConfig)) {
        changes.push({
          type: 'MODIFY_FIELD',
          field,
          oldConfig,
          newConfig
        });
      }
    }

    // ì¸ë±ìŠ¤ ë³€ê²½ ê°ì§€
    const indexChanges = this.detectIndexChanges(
      fromSchema.indexes || [],
      toSchema.indexes || []
    );
    changes.push(...indexChanges);

    return changes;
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
  async executeMigration(
    entityName: string,
    targetVersion: string,
    options?: MigrationOptions
  ): Promise<MigrationResult> {
    const currentVersion = await this.getCurrentVersion(entityName);
    const migrations = await this.getMigrationPath(
      entityName,
      currentVersion,
      targetVersion
    );

    const result: MigrationResult = {
      entityName,
      fromVersion: currentVersion,
      toVersion: targetVersion,
      migrationsApplied: [],
      success: true,
      errors: []
    };

    // ë“œë¼ì´ëŸ° ëª¨ë“œ
    if (options?.dryRun) {
      return this.simulateMigration(migrations, options);
    }

    // íŠ¸ëœì­ì…˜ ì‹œì‘
    const transaction = await this.storage.beginTransaction();

    try {
      for (const migration of migrations) {
        await this.applyMigration(migration, transaction, options);
        result.migrationsApplied.push(migration.id);
      }

      // ë²„ì „ ì—…ë°ì´íŠ¸
      await this.updateCurrentVersion(entityName, targetVersion, transaction);

      await transaction.commit();
    } catch (error) {
      await transaction.rollback();
      result.success = false;
      result.errors.push({
        migration: migrations[result.migrationsApplied.length]?.id,
        error: error.message
      });
    }

    return result;
  }

  // ìŠ¤í‚¤ë§ˆ ì§„í™” ì¶”ì 
  async trackSchemaEvolution(
    entityName: string
  ): Promise<SchemaEvolution> {
    const versions = this.versions.get(entityName) || [];
    const migrations = this.migrations.get(entityName) || [];

    const evolution: SchemaEvolution = {
      entityName,
      versions: versions.map(v => ({
        version: v.version,
        releaseDate: v.releaseDate,
        changes: v.changes,
        breaking: v.breaking
      })),
      totalVersions: versions.length,
      totalMigrations: migrations.length,
      timeline: this.createEvolutionTimeline(versions, migrations)
    };

    return evolution;
  }

  // ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± í™•ì¸
  private async checkCompatibility(
    oldVersion: SchemaVersion,
    newVersion: SchemaVersion
  ): Promise<CompatibilityResult> {
    const result: CompatibilityResult = {
      compatible: true,
      breaking: [],
      warnings: []
    };

    const changes = this.detectSchemaChanges(
      oldVersion.schema,
      newVersion.schema
    );

    for (const change of changes) {
      switch (change.type) {
        case 'REMOVE_FIELD':
          if (!change.config?.deprecated) {
            result.breaking.push({
              type: 'FIELD_REMOVED',
              field: change.field,
              message: `Field '${change.field}' was removed without deprecation`
            });
            result.compatible = false;
          }
          break;

        case 'MODIFY_FIELD':
          if (this.isBreakingFieldChange(change)) {
            result.breaking.push({
              type: 'FIELD_TYPE_CHANGED',
              field: change.field,
              message: `Field '${change.field}' type changed incompatibly`
            });
            result.compatible = false;
          }
          break;

        case 'ADD_FIELD':
          if (change.config?.required && !change.config?.default) {
            result.warnings.push({
              type: 'REQUIRED_FIELD_ADDED',
              field: change.field,
              message: `Required field '${change.field}' added without default`
            });
          }
          break;
      }
    }

    return result;
  }

  // ë²„ì „ ë¹„êµ
  private compareVersions(v1: string, v2: string): number {
    const parts1 = v1.split('.').map(Number);
    const parts2 = v2.split('.').map(Number);

    for (let i = 0; i < Math.max(parts1.length, parts2.length); i++) {
      const p1 = parts1[i] || 0;
      const p2 = parts2[i] || 0;
      
      if (p1 > p2) return 1;
      if (p1 < p2) return -1;
    }

    return 0;
  }
}

// ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ê¸°
export class MigrationExecutor {
  constructor(
    private dynamoDB: DynamoDBDocumentClient,
    private logger: Logger
  ) {}

  async applyMigration(
    migration: Migration,
    options?: ExecutionOptions
  ): Promise<void> {
    this.logger.info(`Applying migration ${migration.id}`, {
      entity: migration.entityName,
      from: migration.fromVersion,
      to: migration.toVersion
    });

    const batchSize = options?.batchSize || 1000;
    let lastEvaluatedKey: any;
    let processedCount = 0;

    do {
      // ë°ì´í„° ì½ê¸°
      const items = await this.scanItems(
        migration.entityName,
        batchSize,
        lastEvaluatedKey
      );

      if (items.length === 0) break;

      // ë³€í™˜ ì ìš©
      const transformedItems = await this.transformItems(
        items,
        migration
      );

      // ë°°ì¹˜ ì“°ê¸°
      await this.batchWriteItems(transformedItems);

      processedCount += items.length;
      lastEvaluatedKey = items[items.length - 1]?.SK;

      // ì§„í–‰ ìƒí™© ë¦¬í¬íŠ¸
      if (options?.onProgress) {
        options.onProgress({
          processed: processedCount,
          current: items.length,
          migration: migration.id
        });
      }

    } while (lastEvaluatedKey);

    this.logger.info(`Migration ${migration.id} completed`, {
      processedItems: processedCount
    });
  }

  private async transformItems(
    items: any[],
    migration: Migration
  ): Promise<any[]> {
    const transformed: any[] = [];

    for (const item of items) {
      try {
        const newItem = { ...item };

        for (const change of migration.changes) {
          switch (change.type) {
            case 'ADD_FIELD':
              newItem[change.field] = change.config.default ?? null;
              break;

            case 'REMOVE_FIELD':
              delete newItem[change.field];
              break;

            case 'MODIFY_FIELD':
              newItem[change.field] = await this.transformField(
                item[change.field],
                change.oldConfig,
                change.newConfig
              );
              break;

            case 'RENAME_FIELD':
              newItem[change.newField] = item[change.oldField];
              delete newItem[change.oldField];
              break;
          }
        }

        // ë²„ì „ ì—…ë°ì´íŠ¸
        newItem.SchemaVersion = migration.toVersion;
        newItem.UpdatedAt = new Date().toISOString();

        transformed.push(newItem);
      } catch (error) {
        this.logger.error(`Failed to transform item`, {
          item,
          migration: migration.id,
          error
        });
        throw error;
      }
    }

    return transformed;
  }
}
```

#### SubTask 2.5.3: ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
**ë‹´ë‹¹ì**: ë°ì´í„° í’ˆì§ˆ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/quality/data-quality-monitor.ts
export class DataQualityMonitor {
  private rules: Map<string, QualityRule[]> = new Map();
  private metrics: Map<string, QualityMetrics> = new Map();
  private alerts: AlertManager;

  constructor(
    private dataSource: DataSource,
    private notificationService: NotificationService
  ) {
    this.alerts = new AlertManager(notificationService);
    this.initializeDefaultRules();
  }

  // ë°ì´í„° í’ˆì§ˆ ê·œì¹™ ë“±ë¡
  registerRule(
    entityType: string,
    rule: QualityRule
  ): void {
    const rules = this.rules.get(entityType) || [];
    rules.push(rule);
    this.rules.set(entityType, rules);
  }

  // ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì‚¬
  async checkDataQuality(
    entityType: string,
    data: any
  ): Promise<QualityCheckResult> {
    const rules = this.rules.get(entityType) || [];
    const violations: QualityViolation[] = [];

    for (const rule of rules) {
      try {
        const passed = await rule.check(data);
        
        if (!passed) {
          violations.push({
            rule: rule.name,
            severity: rule.severity,
            message: rule.message,
            field: rule.field,
            value: data[rule.field]
          });
        }
      } catch (error) {
        violations.push({
          rule: rule.name,
          severity: 'error',
          message: `Rule execution failed: ${error.message}`,
          field: rule.field
        });
      }
    }

    const result: QualityCheckResult = {
      entityType,
      passed: violations.length === 0,
      violations,
      score: this.calculateQualityScore(violations),
      timestamp: new Date()
    };

    // ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    await this.updateMetrics(entityType, result);

    // ì‹¬ê°í•œ ìœ„ë°˜ ì‹œ ì•Œë¦¼
    if (violations.some(v => v.severity === 'critical')) {
      await this.alerts.sendCriticalAlert(entityType, violations);
    }

    return result;
  }

  // ë°°ì¹˜ í’ˆì§ˆ ë¶„ì„
  async analyzeBatchQuality(
    entityType: string,
    timeRange: TimeRange
  ): Promise<BatchQualityReport> {
    const items = await this.dataSource.queryByTimeRange(
      entityType,
      timeRange
    );

    const results: QualityCheckResult[] = [];
    const fieldStats: Map<string, FieldStatistics> = new Map();

    // ê° í•­ëª© ê²€ì‚¬
    for (const item of items) {
      const result = await this.checkDataQuality(entityType, item);
      results.push(result);
      
      // í•„ë“œë³„ í†µê³„ ìˆ˜ì§‘
      this.collectFieldStatistics(item, fieldStats);
    }

    // ì´ìƒì¹˜ ê°ì§€
    const anomalies = await this.detectAnomalies(fieldStats);

    // í’ˆì§ˆ íŠ¸ë Œë“œ ë¶„ì„
    const trends = await this.analyzeQualityTrends(
      entityType,
      results,
      timeRange
    );

    return {
      entityType,
      timeRange,
      totalItems: items.length,
      qualityScore: this.calculateAverageScore(results),
      violations: this.aggregateViolations(results),
      fieldStatistics: Array.from(fieldStats.values()),
      anomalies,
      trends,
      recommendations: this.generateRecommendations(results, anomalies)
    };
  }

  // ë°ì´í„° í”„ë¡œíŒŒì¼ë§
  async profileData(
    entityType: string,
    sampleSize?: number
  ): Promise<DataProfile> {
    const sample = await this.dataSource.getSample(
      entityType,
      sampleSize || 10000
    );

    const profile: DataProfile = {
      entityType,
      sampleSize: sample.length,
      fields: new Map(),
      relationships: [],
      patterns: []
    };

    // ê° í•„ë“œ ë¶„ì„
    for (const field of this.getFields(sample)) {
      const fieldProfile = await this.profileField(field, sample);
      profile.fields.set(field, fieldProfile);
    }

    // ê´€ê³„ ë¶„ì„
    profile.relationships = await this.analyzeRelationships(sample);

    // íŒ¨í„´ ê°ì§€
    profile.patterns = await this.detectPatterns(sample);

    return profile;
  }

  private async profileField(
    fieldName: string,
    data: any[]
  ): Promise<FieldProfile> {
    const values = data.map(item => item[fieldName]);
    const nonNullValues = values.filter(v => v != null);

    const profile: FieldProfile = {
      name: fieldName,
      type: this.inferFieldType(nonNullValues),
      nullable: values.length > nonNullValues.length,
      uniqueCount: new Set(nonNullValues).size,
      nullCount: values.length - nonNullValues.length,
      statistics: {}
    };

    // íƒ€ì…ë³„ í†µê³„
    switch (profile.type) {
      case 'number':
        profile.statistics = this.calculateNumericStats(nonNullValues);
        break;
      case 'string':
        profile.statistics = this.calculateStringStats(nonNullValues);
        break;
      case 'date':
        profile.statistics = this.calculateDateStats(nonNullValues);
        break;
    }

    // ë¶„í¬ ë¶„ì„
    profile.distribution = this.analyzeDistribution(nonNullValues);

    return profile;
  }

  // ì´ìƒì¹˜ ê°ì§€
  private async detectAnomalies(
    fieldStats: Map<string, FieldStatistics>
  ): Promise<Anomaly[]> {
    const anomalies: Anomaly[] = [];

    for (const [field, stats] of fieldStats) {
      // IQR ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ ê°ì§€
      if (stats.type === 'numeric') {
        const iqr = stats.q3 - stats.q1;
        const lowerBound = stats.q1 - 1.5 * iqr;
        const upperBound = stats.q3 + 1.5 * iqr;

        const outliers = stats.values.filter(
          v => v < lowerBound || v > upperBound
        );

        if (outliers.length > 0) {
          anomalies.push({
            field,
            type: 'outlier',
            values: outliers,
            threshold: { lower: lowerBound, upper: upperBound },
            severity: outliers.length / stats.values.length > 0.1 ? 
              'high' : 'medium'
          });
        }
      }

      // íŒ¨í„´ ì´ìƒ ê°ì§€
      if (stats.type === 'string') {
        const patterns = this.detectStringPatterns(stats.values);
        const violations = stats.values.filter(
          v => !patterns.some(p => p.test(v))
        );

        if (violations.length > 0) {
          anomalies.push({
            field,
            type: 'pattern_violation',
            values: violations.slice(0, 10), // ìƒ˜í”Œë§Œ
            severity: 'medium'
          });
        }
      }
    }

    return anomalies;
  }

  // í’ˆì§ˆ íŠ¸ë Œë“œ ë¶„ì„
  private async analyzeQualityTrends(
    entityType: string,
    results: QualityCheckResult[],
    timeRange: TimeRange
  ): Promise<QualityTrend[]> {
    const trends: QualityTrend[] = [];

    // ì‹œê°„ë³„ ê·¸ë£¹í™”
    const hourlyGroups = this.groupByHour(results);

    for (const [hour, group] of hourlyGroups) {
      const score = this.calculateAverageScore(group);
      const previousScore = await this.getPreviousScore(
        entityType,
        hour
      );

      trends.push({
        timestamp: hour,
        score,
        change: score - previousScore,
        violationCount: group.reduce(
          (sum, r) => sum + r.violations.length,
          0
        ),
        trend: this.calculateTrend(score, previousScore)
      });
    }

    return trends;
  }

  // ê¸°ë³¸ í’ˆì§ˆ ê·œì¹™ ì´ˆê¸°í™”
  private initializeDefaultRules(): void {
    // ê³µí†µ ê·œì¹™
    const commonRules: QualityRule[] = [
      {
        name: 'not_null_id',
        field: 'id',
        severity: 'critical',
        message: 'ID cannot be null',
        check: async (data) => data.id != null
      },
      {
        name: 'valid_timestamps',
        field: 'createdAt',
        severity: 'high',
        message: 'Invalid timestamp',
        check: async (data) => {
          if (!data.createdAt) return false;
          const date = new Date(data.createdAt);
          return !isNaN(date.getTime()) && date <= new Date();
        }
      },
      {
        name: 'version_consistency',
        field: 'version',
        severity: 'medium',
        message: 'Version must be positive',
        check: async (data) => data.version > 0
      }
    ];

    // ëª¨ë“  ì—”í‹°í‹°ì— ê³µí†µ ê·œì¹™ ì ìš©
    for (const entityType of ['User', 'Project', 'Agent', 'Task']) {
      this.rules.set(entityType, [...commonRules]);
    }

    // ì—”í‹°í‹°ë³„ íŠ¹í™” ê·œì¹™
    this.registerRule('User', {
      name: 'valid_email',
      field: 'email',
      severity: 'high',
      message: 'Invalid email format',
      check: async (data) => /^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(data.email)
    });

    this.registerRule('Project', {
      name: 'valid_status',
      field: 'status',
      severity: 'high',
      message: 'Invalid project status',
      check: async (data) => 
        ['planning', 'active', 'paused', 'completed', 'archived']
          .includes(data.status)
    });

    this.registerRule('Agent', {
      name: 'valid_agent_type',
      field: 'type',
      severity: 'critical',
      message: 'Invalid agent type',
      check: async (data) => 
        data.type && data.type.endsWith('Agent')
    });
  }

  // í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
  private calculateQualityScore(violations: QualityViolation[]): number {
    if (violations.length === 0) return 100;

    const weights = {
      critical: 10,
      high: 5,
      medium: 2,
      low: 1
    };

    const totalPenalty = violations.reduce(
      (sum, v) => sum + (weights[v.severity] || 0),
      0
    );

    return Math.max(0, 100 - totalPenalty);
  }

  // ê¶Œì¥ì‚¬í•­ ìƒì„±
  private generateRecommendations(
    results: QualityCheckResult[],
    anomalies: Anomaly[]
  ): Recommendation[] {
    const recommendations: Recommendation[] = [];

    // ë¹ˆë²ˆí•œ ìœ„ë°˜ ë¶„ì„
    const violationCounts = new Map<string, number>();
    for (const result of results) {
      for (const violation of result.violations) {
        const count = violationCounts.get(violation.rule) || 0;
        violationCounts.set(violation.rule, count + 1);
      }
    }

    // ìƒìœ„ ìœ„ë°˜ì— ëŒ€í•œ ê¶Œì¥ì‚¬í•­
    for (const [rule, count] of violationCounts) {
      if (count > results.length * 0.1) { // 10% ì´ìƒ
        recommendations.push({
          type: 'validation',
          priority: 'high',
          title: `Frequent ${rule} violations`,
          description: `${count} items failed ${rule} validation`,
          action: `Review and update ${rule} validation logic or data source`
        });
      }
    }

    // ì´ìƒì¹˜ì— ëŒ€í•œ ê¶Œì¥ì‚¬í•­
    for (const anomaly of anomalies) {
      if (anomaly.severity === 'high') {
        recommendations.push({
          type: 'anomaly',
          priority: 'high',
          title: `High number of outliers in ${anomaly.field}`,
          description: `${anomaly.values.length} outliers detected`,
          action: 'Investigate data source for potential issues'
        });
      }
    }

    return recommendations;
  }
}

// ë°ì´í„° í’ˆì§ˆ ëŒ€ì‹œë³´ë“œ
export class DataQualityDashboard {
  constructor(
    private monitor: DataQualityMonitor,
    private storage: MetricsStorage
  ) {}

  async generateDashboard(
    timeRange: TimeRange
  ): Promise<DashboardData> {
    const entities = ['User', 'Project', 'Agent', 'Task'];
    const entityMetrics: EntityMetrics[] = [];

    for (const entity of entities) {
      const report = await this.monitor.analyzeBatchQuality(
        entity,
        timeRange
      );

      entityMetrics.push({
        entity,
        score: report.qualityScore,
        violations: report.violations.length,
        anomalies: report.anomalies.length,
        trend: report.trends[report.trends.length - 1]?.trend || 'stable'
      });
    }

    return {
      timeRange,
      overallScore: this.calculateOverallScore(entityMetrics),
      entityMetrics,
      alerts: await this.getRecentAlerts(timeRange),
      trends: await this.getQualityTrends(timeRange),
      recommendations: await this.getTopRecommendations()
    };
  }
}
```

#### SubTask 2.5.4: ìë™ ìŠ¤í‚¤ë§ˆ ë¬¸ì„œí™”
**ë‹´ë‹¹ì**: ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±ì & ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/documentation/schema-documenter.ts
export class SchemaDocumenter {
  private templates: Map<string, DocumentTemplate> = new Map();
  
  constructor(
    private schemaRegistry: SchemaRegistry,
    private outputPath: string
  ) {
    this.initializeTemplates();
  }

  // ìŠ¤í‚¤ë§ˆ ë¬¸ì„œ ìë™ ìƒì„±
  async generateDocumentation(
    options?: DocumentationOptions
  ): Promise<void> {
    const schemas = await this.schemaRegistry.getAllSchemas();
    
    // ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„±
    if (options?.formats?.includes('markdown') !== false) {
      await this.generateMarkdownDocs(schemas);
    }

    // HTML ë¬¸ì„œ ìƒì„±
    if (options?.formats?.includes('html')) {
      await this.generateHtmlDocs(schemas);
    }

    // OpenAPI ìŠ¤í™ ìƒì„±
    if (options?.formats?.includes('openapi')) {
      await this.generateOpenApiSpec(schemas);
    }

    // GraphQL ìŠ¤í‚¤ë§ˆ ìƒì„±
    if (options?.formats?.includes('graphql')) {
      await this.generateGraphQLSchema(schemas);
    }

    // ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
    if (options?.includeDiagrams) {
      await this.generateDiagrams(schemas);
    }
  }

  // ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„±
  private async generateMarkdownDocs(
    schemas: SchemaDefinition[]
  ): Promise<void> {
    const toc: string[] = ['# Data Model Documentation\n'];
    const content: string[] = [];

    // ê°œìš” ì„¹ì…˜
    content.push(await this.generateOverview(schemas));

    // ê° ìŠ¤í‚¤ë§ˆë³„ ë¬¸ì„œ
    for (const schema of schemas) {
      const doc = await this.generateSchemaMarkdown(schema);
      content.push(doc);
      toc.push(`- [${schema.name}](#${schema.name.toLowerCase()})`);
    }

    // ê´€ê³„ ë‹¤ì´ì–´ê·¸ë¨
    content.push('\n## Entity Relationships\n');
    content.push(await this.generateRelationshipDiagram(schemas));

    // íŒŒì¼ ì €ì¥
    const fullContent = [...toc, '\n---\n', ...content].join('\n');
    await fs.writeFile(
      path.join(this.outputPath, 'data-model.md'),
      fullContent
    );
  }

  // ê°œë³„ ìŠ¤í‚¤ë§ˆ ë§ˆí¬ë‹¤ìš´ ìƒì„±
  private async generateSchemaMarkdown(
    schema: SchemaDefinition
  ): Promise<string> {
    const sections: string[] = [];

    // í—¤ë”
    sections.push(`## ${schema.name}`);
    sections.push(`\n${schema.description || 'No description provided.'}\n`);

    // ë©”íƒ€ë°ì´í„°
    if (schema.metadata) {
      sections.push('### Metadata');
      sections.push(`- **Version**: ${schema.metadata.version}`);
      sections.push(`- **Last Updated**: ${schema.metadata.lastUpdated}`);
      if (schema.metadata.author) {
        sections.push(`- **Author**: ${schema.metadata.author}`);
      }
      sections.push('');
    }

    // í•„ë“œ í…Œì´ë¸”
    sections.push('### Fields\n');
    sections.push(this.generateFieldTable(schema.fields));

    // ì¸ë±ìŠ¤
    if (schema.indexes && schema.indexes.length > 0) {
      sections.push('\n### Indexes\n');
      sections.push(this.generateIndexTable(schema.indexes));
    }

    // ê²€ì¦ ê·œì¹™
    if (schema.validations && schema.validations.length > 0) {
      sections.push('\n### Validation Rules\n');
      for (const validation of schema.validations) {
        sections.push(`- **${validation.rule}**: ${validation.description}`);
      }
    }

    // ì˜ˆì œ
    if (schema.examples && schema.examples.length > 0) {
      sections.push('\n### Examples\n');
      for (const example of schema.examples) {
        sections.push('```json');
        sections.push(JSON.stringify(example, null, 2));
        sections.push('```\n');
      }
    }

    // ê´€ë ¨ ì—”í‹°í‹°
    const relationships = this.findRelationships(schema);
    if (relationships.length > 0) {
      sections.push('\n### Relationships\n');
      for (const rel of relationships) {
        sections.push(`- **${rel.type}** ${rel.target} via \`${rel.field}\``);
      }
    }

    return sections.join('\n');
  }

  // í•„ë“œ í…Œì´ë¸” ìƒì„±
  private generateFieldTable(fields: Record<string, FieldConfig>): string {
    const rows: string[] = [
      '| Field | Type | Required | Description | Constraints |',
      '|-------|------|----------|-------------|-------------|'
    ];

    for (const [name, config] of Object.entries(fields)) {
      const required = config.required !== false ? 'âœ“' : '';
      const constraints = this.formatConstraints(config);
      const description = config.description || '-';
      
      rows.push(
        `| \`${name}\` | ${config.type} | ${required} | ${description} | ${constraints} |`
      );
    }

    return rows.join('\n');
  }

  // OpenAPI ìŠ¤í™ ìƒì„±
  private async generateOpenApiSpec(
    schemas: SchemaDefinition[]
  ): Promise<void> {
    const spec: any = {
      openapi: '3.0.0',
      info: {
        title: 'T-Developer Data Models',
        version: '1.0.0',
        description: 'Data model definitions for T-Developer'
      },
      components: {
        schemas: {}
      }
    };

    for (const schema of schemas) {
      spec.components.schemas[schema.name] = 
        this.convertToOpenApiSchema(schema);
    }

    await fs.writeFile(
      path.join(this.outputPath, 'openapi-schemas.json'),
      JSON.stringify(spec, null, 2)
    );
  }

  // GraphQL ìŠ¤í‚¤ë§ˆ ìƒì„±
  private async generateGraphQLSchema(
    schemas: SchemaDefinition[]
  ): Promise<void> {
    const types: string[] = [];

    for (const schema of schemas) {
      types.push(this.convertToGraphQLType(schema));
    }

    // ì¿¼ë¦¬ íƒ€ì… ì¶”ê°€
    types.push(this.generateGraphQLQueries(schemas));

    // ë®¤í…Œì´ì…˜ íƒ€ì… ì¶”ê°€
    types.push(this.generateGraphQLMutations(schemas));

    const fullSchema = types.join('\n\n');
    await fs.writeFile(
      path.join(this.outputPath, 'schema.graphql'),
      fullSchema
    );
  }

  // GraphQL íƒ€ì… ë³€í™˜
  private convertToGraphQLType(schema: SchemaDefinition): string {
    const fields: string[] = [];

    for (const [name, config] of Object.entries(schema.fields)) {
      const type = this.mapToGraphQLType(config);
      const required = config.required !== false ? '!' : '';
      const description = config.description ? 
        `  "${config.description}"` : '';
      
      if (description) {
        fields.push(description);
      }
      fields.push(`  ${name}: ${type}${required}`);
    }

    return `type ${schema.name} {
${fields.join('\n')}
}`;
  }

  // ER ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
  private async generateRelationshipDiagram(
    schemas: SchemaDefinition[]
  ): Promise<string> {
    const mermaid: string[] = ['```mermaid', 'erDiagram'];

    // ì—”í‹°í‹° ì •ì˜
    for (const schema of schemas) {
      const fields = Object.entries(schema.fields)
        .map(([name, config]) => 
          `    ${config.type} ${name}${config.required !== false ? '' : '?'}`
        )
        .join('\n');
      
      mermaid.push(`  ${schema.name} {`);
      mermaid.push(fields);
      mermaid.push('  }');
    }

    // ê´€ê³„ ì •ì˜
    for (const schema of schemas) {
      const relationships = this.findRelationships(schema);
      for (const rel of relationships) {
        const cardinality = this.determineCardinality(rel);
        mermaid.push(`  ${schema.name} ${cardinality} ${rel.target} : "${rel.field}"`);
      }
    }

    mermaid.push('```');
    return mermaid.join('\n');
  }

  // ëŒ€í™”í˜• ë¬¸ì„œ ìƒì„±
  private async generateInteractiveDocs(
    schemas: SchemaDefinition[]
  ): Promise<void> {
    const html = `
<!DOCTYPE html>
<html>
<head>
  <title>T-Developer Data Model Explorer</title>
  <style>
    ${await this.loadStyles()}
  </style>
</head>
<body>
  <div id="app">
    <nav class="sidebar">
      ${this.generateNavigation(schemas)}
    </nav>
    <main class="content">
      ${schemas.map(s => this.generateInteractiveSchema(s)).join('')}
    </main>
  </div>
  <script>
    ${await this.loadInteractiveScript()}
  </script>
</body>
</html>`;

    await fs.writeFile(
      path.join(this.outputPath, 'interactive-docs.html'),
      html
    );
  }

  // ìŠ¤í‚¤ë§ˆ ë³€ê²½ ë¡œê·¸ ìƒì„±
  async generateChangeLog(
    fromVersion: string,
    toVersion: string
  ): Promise<string> {
    const changes = await this.schemaRegistry.getChangesBetweenVersions(
      fromVersion,
      toVersion
    );

    const sections: string[] = [
      `# Schema Change Log (${fromVersion} â†’ ${toVersion})`,
      `\n## Summary`,
      `- **Breaking Changes**: ${changes.breaking.length}`,
      `- **New Features**: ${changes.additions.length}`,
      `- **Modifications**: ${changes.modifications.length}`,
      `- **Deprecations**: ${changes.deprecations.length}`,
      `\n---\n`
    ];

    if (changes.breaking.length > 0) {
      sections.push('## âš ï¸ Breaking Changes\n');
      for (const change of changes.breaking) {
        sections.push(`- **${change.entity}.${change.field}**: ${change.description}`);
        if (change.migration) {
          sections.push(`  - Migration: \`${change.migration}\``);
        }
      }
      sections.push('');
    }

    if (changes.additions.length > 0) {
      sections.push('## âœ¨ New Features\n');
      for (const addition of changes.additions) {
        sections.push(`- Added \`${addition.entity}.${addition.field}\` (${addition.type})`);
        if (addition.description) {
          sections.push(`  - ${addition.description}`);
        }
      }
      sections.push('');
    }

    return sections.join('\n');
  }

  // API ì‚¬ìš© ì˜ˆì œ ìƒì„±
  private generateApiExamples(schema: SchemaDefinition): string {
    const examples: string[] = [
      `### API Usage Examples for ${schema.name}\n`
    ];

    // Create ì˜ˆì œ
    examples.push('#### Create');
    examples.push('```typescript');
    examples.push(`const new${schema.name} = await create${schema.name}({`);
    for (const [field, config] of Object.entries(schema.fields)) {
      if (config.required !== false && !config.computed) {
        const value = this.generateExampleValue(config);
        examples.push(`  ${field}: ${value},`);
      }
    }
    examples.push('});');
    examples.push('```\n');

    // Query ì˜ˆì œ
    examples.push('#### Query');
    examples.push('```typescript');
    examples.push(`const ${schema.name.toLowerCase()}s = await query${schema.name}s({`);
    examples.push(`  filter: { status: 'active' },`);
    examples.push(`  sort: { createdAt: 'desc' },`);
    examples.push(`  limit: 10`);
    examples.push('});');
    examples.push('```\n');

    return examples.join('\n');
  }
}
```

---

### Task 2.6: ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ

#### SubTask 2.6.1: ë§ˆì´ê·¸ë ˆì´ì…˜ í”„ë ˆì„ì›Œí¬ êµ¬ì¶•
**ë‹´ë‹¹ì**: ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ë¬¸ê°€  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/migration/migration-framework.ts
export abstract class Migration {
  abstract readonly id: string;
  abstract readonly name: string;
  abstract readonly version: string;
  abstract readonly description: string;
  
  abstract up(context: MigrationContext): Promise<void>;
  abstract down(context: MigrationContext): Promise<void>;
  
  async validate(context: MigrationContext): Promise<ValidationResult> {
    // ê¸°ë³¸ ê²€ì¦ ë¡œì§
    return { valid: true };
  }
  
  async estimate(context: MigrationContext): Promise<MigrationEstimate> {
    // ì˜ˆìƒ ì‹œê°„ ë° ë¦¬ì†ŒìŠ¤ ê³„ì‚°
    return {
      estimatedTime: 0,
      estimatedItems: 0,
      requiredResources: {}
    };
  }
}

export class MigrationRunner {
  private migrations: Map<string, Migration> = new Map();
  private history: MigrationHistory;
  private lock: DistributedLock;
  
  constructor(
    private context: MigrationContext,
    private options: MigrationOptions
  ) {
    this.history = new MigrationHistory(context.dynamoDB);
    this.lock = new DistributedLock(context.dynamoDB);
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ë“±ë¡
  register(migration: Migration): void {
    if (this.migrations.has(migration.id)) {
      throw new Error(`Migration ${migration.id} already registered`);
    }
    this.migrations.set(migration.id, migration);
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
  async run(targetVersion?: string): Promise<MigrationResult> {
    const lockId = await this.acquireLock();
    
    try {
      // í˜„ì¬ ë²„ì „ í™•ì¸
      const currentVersion = await this.history.getCurrentVersion();
      
      // ì‹¤í–‰í•  ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ì •
      const pendingMigrations = await this.getPendingMigrations(
        currentVersion,
        targetVersion
      );

      if (pendingMigrations.length === 0) {
        return {
          success: true,
          message: 'No migrations to run',
          migrationsRun: []
        };
      }

      // ê²€ì¦
      if (this.options.validate) {
        await this.validateMigrations(pendingMigrations);
      }

      // ë“œë¼ì´ëŸ°
      if (this.options.dryRun) {
        return await this.dryRun(pendingMigrations);
      }

      // ì‹¤ì œ ì‹¤í–‰
      return await this.executeMigrations(pendingMigrations);
      
    } finally {
      await this.releaseLock(lockId);
    }
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
  private async executeMigrations(
    migrations: Migration[]
  ): Promise<MigrationResult> {
    const results: MigrationExecutionResult[] = [];
    
    for (const migration of migrations) {
      const startTime = Date.now();
      
      try {
        // ì‚¬ì „ ê²€ì¦
        const validation = await migration.validate(this.context);
        if (!validation.valid) {
          throw new Error(`Validation failed: ${validation.errors.join(', ')}`);
        }

        // ë°±ì—… ìƒì„±
        if (this.options.backup) {
          await this.createBackup(migration.id);
        }

        // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
        await this.executeWithProgress(migration);

        // íˆìŠ¤í† ë¦¬ ê¸°ë¡
        await this.history.recordMigration({
          id: migration.id,
          version: migration.version,
          executedAt: new Date(),
          duration: Date.now() - startTime,
          status: 'completed'
        });

        results.push({
          migration: migration.id,
          status: 'success',
          duration: Date.now() - startTime
        });

      } catch (error) {
        // ë¡¤ë°±
        if (this.options.rollbackOnError) {
          await this.rollback(migration);
        }

        // ì‹¤íŒ¨ ê¸°ë¡
        await this.history.recordMigration({
          id: migration.id,
          version: migration.version,
          executedAt: new Date(),
          duration: Date.now() - startTime,
          status: 'failed',
          error: error.message
        });

        results.push({
          migration: migration.id,
          status: 'failed',
          error: error.message,
          duration: Date.now() - startTime
        });

        if (!this.options.continueOnError) {
          break;
        }
      }
    }

    return {
      success: results.every(r => r.status === 'success'),
      migrationsRun: results.map(r => r.migration),
      results
    };
  }

  // ì§„í–‰ ìƒí™© ì¶”ì 
  private async executeWithProgress(migration: Migration): Promise<void> {
    const progressTracker = new ProgressTracker();
    
    const contextWithProgress = {
      ...this.context,
      progress: progressTracker
    };

    // ì§„í–‰ ìƒí™© ë¦¬í¬í„° ì‹œì‘
    const reporter = setInterval(() => {
      const progress = progressTracker.getProgress();
      this.options.onProgress?.(migration.id, progress);
    }, 1000);

    try {
      await migration.up(contextWithProgress);
    } finally {
      clearInterval(reporter);
    }
  }

  // ë¡¤ë°±
  async rollback(
    steps: number = 1
  ): Promise<RollbackResult> {
    const lockId = await this.acquireLock();
    
    try {
      const executedMigrations = await this.history.getExecutedMigrations();
      const toRollback = executedMigrations.slice(-steps);

      const results: RollbackExecutionResult[] = [];

      for (const record of toRollback.reverse()) {
        const migration = this.migrations.get(record.id);
        
        if (!migration) {
          results.push({
            migration: record.id,
            status: 'skipped',
            reason: 'Migration not found'
          });
          continue;
        }

        try {
          await migration.down(this.context);
          
          await this.history.removeMigration(record.id);
          
          results.push({
            migration: record.id,
            status: 'success'
          });
        } catch (error) {
          results.push({
            migration: record.id,
            status: 'failed',
            error: error.message
          });
          
          if (!this.options.continueOnError) {
            break;
          }
        }
      }

      return {
        success: results.every(r => r.status === 'success'),
        rollbackCount: results.filter(r => r.status === 'success').length,
        results
      };
      
    } finally {
      await this.releaseLock(lockId);
    }
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸
  async status(): Promise<MigrationStatus> {
    const currentVersion = await this.history.getCurrentVersion();
    const executedMigrations = await this.history.getExecutedMigrations();
    const pendingMigrations = await this.getPendingMigrations(currentVersion);

    return {
      currentVersion,
      executedCount: executedMigrations.length,
      pendingCount: pendingMigrations.length,
      executedMigrations: executedMigrations.map(m => ({
        id: m.id,
        version: m.version,
        executedAt: m.executedAt,
        duration: m.duration
      })),
      pendingMigrations: pendingMigrations.map(m => ({
        id: m.id,
        version: m.version,
        description: m.description
      }))
    };
  }

  // ë¶„ì‚° ì ê¸ˆ íšë“
  private async acquireLock(): Promise<string> {
    const lockId = uuidv4();
    const acquired = await this.lock.acquire(
      'migration-lock',
      lockId,
      this.options.lockTimeout || 300000 // 5ë¶„
    );

    if (!acquired) {
      throw new Error('Failed to acquire migration lock');
    }

    return lockId;
  }

  private async releaseLock(lockId: string): Promise<void> {
    await this.lock.release('migration-lock', lockId);
  }
}

// ë§ˆì´ê·¸ë ˆì´ì…˜ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
export class MigrationHistory {
  constructor(
    private dynamoDB: DynamoDBDocumentClient,
    private tableName: string = 'MigrationHistory'
  ) {}

  async getCurrentVersion(): Promise<string | null> {
    const result = await this.dynamoDB.send(new QueryCommand({
      TableName: this.tableName,
      KeyConditionExpression: 'PK = :pk',
      ExpressionAttributeValues: {
        ':pk': 'MIGRATION#CURRENT'
      },
      ScanIndexForward: false,
      Limit: 1
    }));

    return result.Items?.[0]?.version || null;
  }

  async getExecutedMigrations(): Promise<MigrationRecord[]> {
    const result = await this.dynamoDB.send(new QueryCommand({
      TableName: this.tableName,
      KeyConditionExpression: 'PK = :pk',
      ExpressionAttributeValues: {
        ':pk': 'MIGRATION#HISTORY'
      },
      ScanIndexForward: false
    }));

    return result.Items || [];
  }

  async recordMigration(record: MigrationRecord): Promise<void> {
    await this.dynamoDB.send(new TransactWriteCommand({
      TransactItems: [
        {
          Put: {
            TableName: this.tableName,
            Item: {
              PK: 'MIGRATION#HISTORY',
              SK: `${record.executedAt.toISOString()}#${record.id}`,
              ...record
            }
          }
        },
        {
          Update: {
            TableName: this.tableName,
            Key: {
              PK: 'MIGRATION#CURRENT',
              SK: 'VERSION'
            },
            UpdateExpression: 'SET version = :version, updatedAt = :now',
            ExpressionAttributeValues: {
              ':version': record.version,
              ':now': new Date().toISOString()
            }
          }
        }
      ]
    }));
  }
}
```

#### SubTask 2.6.2: ëŒ€ìš©ëŸ‰ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬
**ë‹´ë‹¹ì**: ë¹…ë°ì´í„° ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 14ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/migration/bulk-migration.ts
export class BulkDataMigration {
  private workers: Worker[] = [];
  private progressTracker: ProgressTracker;
  private errorHandler: ErrorHandler;
  
  constructor(
    private source: DataSource,
    private target: DataSource,
    private options: BulkMigrationOptions
  ) {
    this.progressTracker = new ProgressTracker();
    this.errorHandler = new ErrorHandler(options.errorHandling);
    this.initializeWorkers();
  }

  // ì›Œì»¤ ì´ˆê¸°í™”
  private initializeWorkers(): void {
    const workerCount = this.options.parallelism || os.cpus().length;
    
    for (let i = 0; i < workerCount; i++) {
      const worker = new Worker(
        path.join(__dirname, 'migration-worker.js'),
        { workerData: { workerId: i } }
      );
      
      worker.on('message', this.handleWorkerMessage.bind(this));
      worker.on('error', this.handleWorkerError.bind(this));
      
      this.workers.push(worker);
    }
  }

  // ëŒ€ìš©ëŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
  async migrate(
    transformation?: DataTransformation
  ): Promise<BulkMigrationResult> {
    const startTime = Date.now();
    
    try {
      // 1. ë°ì´í„° í¬ê¸° ì¶”ì •
      const estimate = await this.estimateDataSize();
      this.progressTracker.initialize(estimate);

      // 2. ë°ì´í„° íŒŒí‹°ì…”ë‹
      const partitions = await this.partitionData(estimate);

      // 3. ë³‘ë ¬ ë§ˆì´ê·¸ë ˆì´ì…˜
      const results = await this.migratePartitions(
        partitions,
        transformation
      );

      // 4. ê²€ì¦
      if (this.options.validate) {
        await this.validateMigration(results);
      }

      return {
        success: true,
        totalItems: estimate.itemCount,
        migratedItems: results.reduce((sum, r) => sum + r.itemCount, 0),
        duration: Date.now() - startTime,
        partitionResults: results
      };

    } catch (error) {
      return {
        success: false,
        error: error.message,
        duration: Date.now() - startTime,
        partitionResults: []
      };
    } finally {
      this.cleanup();
    }
  }

  // ë°ì´í„° íŒŒí‹°ì…”ë‹
  private async partitionData(
    estimate: DataEstimate
  ): Promise<DataPartition[]> {
    const partitions: DataPartition[] = [];
    const partitionSize = Math.ceil(
      estimate.itemCount / this.workers.length
    );

    // ë²”ìœ„ ê¸°ë°˜ íŒŒí‹°ì…”ë‹
    if (this.options.partitionStrategy === 'range') {
      const ranges = await this.calculateRanges(partitionSize);
      
      for (const range of ranges) {
        partitions.push({
          id: uuidv4(),
          startKey: range.start,
          endKey: range.end,
          estimatedSize: partitionSize
        });
      }
    }
    // í•´ì‹œ ê¸°ë°˜ íŒŒí‹°ì…”ë‹
    else if (this.options.partitionStrategy === 'hash') {
      for (let i = 0; i < this.workers.length; i++) {
        partitions.push({
          id: uuidv4(),
          hashBucket: i,
          totalBuckets: this.workers.length,
          estimatedSize: partitionSize
        });
      }
    }

    return partitions;
  }

  // íŒŒí‹°ì…˜ ë§ˆì´ê·¸ë ˆì´ì…˜
  private async migratePartitions(
    partitions: DataPartition[],
    transformation?: DataTransformation
  ): Promise<PartitionResult[]> {
    const queue = new PQueue({ 
      concurrency: this.workers.length 
    });
    
    const results: PartitionResult[] = [];

    for (const partition of partitions) {
      queue.add(async () => {
        const result = await this.migratePartition(
          partition,
          transformation
        );
        results.push(result);
        
        // ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        this.progressTracker.updatePartition(
          partition.id,
          result.itemCount
        );
      });
    }

    await queue.onIdle();
    return results;
  }

  // ë‹¨ì¼ íŒŒí‹°ì…˜ ë§ˆì´ê·¸ë ˆì´ì…˜
  private async migratePartition(
    partition: DataPartition,
    transformation?: DataTransformation
  ): Promise<PartitionResult> {
    const worker = this.getAvailableWorker();
    const startTime = Date.now();
    
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error(`Partition ${partition.id} timeout`));
      }, this.options.partitionTimeout || 3600000); // 1ì‹œê°„

      worker.postMessage({
        type: 'MIGRATE_PARTITION',
        partition,
        transformation: transformation?.toString(),
        options: {
          batchSize: this.options.batchSize,
          retryPolicy: this.options.retryPolicy
        }
      });

      worker.once('message', (message) => {
        clearTimeout(timeout);
        
        if (message.type === 'PARTITION_COMPLETE') {
          resolve({
            partitionId: partition.id,
            itemCount: message.itemCount,
            duration: Date.now() - startTime,
            errors: message.errors || []
          });
        } else if (message.type === 'PARTITION_ERROR') {
          reject(new Error(message.error));
        }
      });
    });
  }

  // ìŠ¤íŠ¸ë¦¬ë° ë§ˆì´ê·¸ë ˆì´ì…˜
  async streamMigrate(
    filter?: DataFilter
  ): Promise<AsyncGenerator<MigrationChunk>> {
    const stream = this.source.createReadStream(filter);
    const transformer = new TransformStream();

    return async function* () {
      for await (const chunk of stream) {
        const transformed = await transformer.transform(chunk);
        
        // ëŒ€ìƒì— ì“°ê¸°
        await this.target.writeBatch(transformed);
        
        yield {
          items: transformed,
          timestamp: new Date(),
          sequenceNumber: chunk.sequenceNumber
        };
      }
    }.call(this);
  }

  // ì¦ë¶„ ë§ˆì´ê·¸ë ˆì´ì…˜
  async incrementalMigrate(
    lastCheckpoint?: string
  ): Promise<IncrementalMigrationResult> {
    // DynamoDB Streams ë˜ëŠ” ë³€ê²½ ë¡œê·¸ ì‚¬ìš©
    const changes = await this.source.getChangesSince(lastCheckpoint);
    const results: ChangeResult[] = [];

    for (const change of changes) {
      try {
        const result = await this.applyChange(change);
        results.push(result);
      } catch (error) {
        this.errorHandler.handle(error, change);
      }
    }

    return {
      checkpoint: changes[changes.length - 1]?.sequenceNumber,
      changesProcessed: results.length,
      results
    };
  }

  // ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„
  private async handleFailedItems(
    failures: FailedItem[]
  ): Promise<RetryResult> {
    const retryPolicy = this.options.retryPolicy || {
      maxAttempts: 3,
      backoffMultiplier: 2,
      initialDelay: 1000
    };

    const retryResults: RetryItemResult[] = [];

    for (const failure of failures) {
      let attempt = 0;
      let success = false;
      let lastError: Error | null = null;

      while (attempt < retryPolicy.maxAttempts && !success) {
        try {
          await this.retrySingleItem(failure);
          success = true;
        } catch (error) {
          lastError = error;
          attempt++;
          
          if (attempt < retryPolicy.maxAttempts) {
            const delay = retryPolicy.initialDelay * 
              Math.pow(retryPolicy.backoffMultiplier, attempt - 1);
            await new Promise(resolve => setTimeout(resolve, delay));
          }
        }
      }

      retryResults.push({
        item: failure.item,
        success,
        attempts: attempt,
        error: success ? null : lastError
      });
    }

    return {
      totalItems: failures.length,
      successCount: retryResults.filter(r => r.success).length,
      failureCount: retryResults.filter(r => !r.success).length,
      results: retryResults
    };
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦
  private async validateMigration(
    results: PartitionResult[]
  ): Promise<ValidationResult> {
    const validator = new MigrationValidator(
      this.source,
      this.target
    );

    // ë ˆì½”ë“œ ìˆ˜ ê²€ì¦
    const countValidation = await validator.validateCounts();

    // ìƒ˜í”Œ ë°ì´í„° ê²€ì¦
    const sampleValidation = await validator.validateSampleData(
      this.options.validationSampleSize || 1000
    );

    // ì²´í¬ì„¬ ê²€ì¦
    const checksumValidation = await validator.validateChecksums(
      results.map(r => r.partitionId)
    );

    return {
      valid: countValidation.valid && 
             sampleValidation.valid && 
             checksumValidation.valid,
      validations: {
        count: countValidation,
        sample: sampleValidation,
        checksum: checksumValidation
      }
    };
  }

  // ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
  getProgress(): MigrationProgress {
    return this.progressTracker.getOverallProgress();
  }

  // ì •ë¦¬
  private cleanup(): void {
    for (const worker of this.workers) {
      worker.terminate();
    }
    this.workers = [];
  }
}

// ë§ˆì´ê·¸ë ˆì´ì…˜ ì›Œì»¤
// migration-worker.js
const { parentPort, workerData } = require('worker_threads');

parentPort.on('message', async (message) => {
  if (message.type === 'MIGRATE_PARTITION') {
    try {
      const result = await migratePartitionData(
        message.partition,
        message.transformation,
        message.options
      );
      
      parentPort.postMessage({
        type: 'PARTITION_COMPLETE',
        itemCount: result.itemCount,
        errors: result.errors
      });
    } catch (error) {
      parentPort.postMessage({
        type: 'PARTITION_ERROR',
        error: error.message
      });
    }
  }
});

async function migratePartitionData(partition, transformation, options) {
  let itemCount = 0;
  const errors = [];
  const batchSize = options.batchSize || 100;

  // íŒŒí‹°ì…˜ ë°ì´í„° ì½ê¸°
  const reader = createPartitionReader(partition);
  const writer = createBatchWriter();

  let batch = [];
  
  for await (const item of reader) {
    try {
      // ë³€í™˜ ì ìš©
      const transformed = transformation ? 
        await applyTransformation(item, transformation) : item;
      
      batch.push(transformed);
      
      if (batch.length >= batchSize) {
        await writer.write(batch);
        itemCount += batch.length;
        batch = [];
      }
    } catch (error) {
      errors.push({
        item: item.id,
        error: error.message
      });
    }
  }

  // ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬
  if (batch.length > 0) {
    await writer.write(batch);
    itemCount += batch.length;
  }

  return { itemCount, errors };
}
```

#### SubTask 2.6.3: ë¬´ì¤‘ë‹¨ ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/data/migration/zero-downtime-migration.ts
export class ZeroDowntimeMigration {
  private dualWriteManager: DualWriteManager;
  private backfillManager: BackfillManager;
  private cutoverManager: CutoverManager;
  
  constructor(
    private oldSystem: DataSystem,
    private newSystem: DataSystem,
    private options: ZeroDowntimeOptions
  ) {
    this.dualWriteManager = new DualWriteManager(oldSystem, newSystem);
    this.backfillManager = new BackfillManager(oldSystem, newSystem);
    this.cutoverManager = new CutoverManager();
  }

  // ë¬´ì¤‘ë‹¨ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
  async execute(): Promise<MigrationExecutionResult> {
    const phases: Phase[] = [
      this.phaseDualWrite.bind(this),
      this.phaseBackfill.bind(this),
      this.phaseValidation.bind(this),
      this.phaseCutover.bind(this),
      this.phaseCleanup.bind(this)
    ];

    const results: PhaseResult[] = [];

    for (const [index, phase] of phases.entries()) {
      try {
        const result = await phase();
        results.push(result);

        if (!result.success) {
          // ë¡¤ë°±
          await this.rollback(index, results);
          break;
        }
      } catch (error) {
        await this.handlePhaseError(index, error);
        break;
      }
    }

    return {
      success: results.every(r => r.success),
      phases: results,
      totalDuration: results.reduce((sum, r) => sum + r.duration, 0)
    };
  }

  // Phase 1: ì´ì¤‘ ì“°ê¸° í™œì„±í™”
  private async phaseDualWrite(): Promise<PhaseResult> {
    const startTime = Date.now();
    
    // ì´ì¤‘ ì“°ê¸° ì„¤ì •
    await this.dualWriteManager.enable({
      primaryTarget: 'old',
      secondaryTarget: 'new',
      asyncWrite: true,
      errorHandling: 'log_and_continue'
    });

    // ì“°ê¸° í”„ë¡ì‹œ ì„¤ì •
    await this.setupWriteProxy();

    // ëª¨ë‹ˆí„°ë§ ì‹œì‘
    await this.startDualWriteMonitoring();

    return {
      phase: 'dual_write',
      success: true,
      duration: Date.now() - startTime,
      metrics: await this.dualWriteManager.getMetrics()
    };
  }

  // Phase 2: ê¸°ì¡´ ë°ì´í„° ë°±í•„
  private async phaseBackfill(): Promise<PhaseResult> {
    const startTime = Date.now();
    
    // ë°±í•„ ì‘ì—… ìƒì„±
    const backfillJob = await this.backfillManager.createJob({
      source: this.oldSystem,
      target: this.newSystem,
      strategy: 'incremental',
      batchSize: this.options.backfillBatchSize || 1000,
      parallelism: this.options.backfillParallelism || 10
    });

    // ë°±í•„ ì‹¤í–‰
    const backfillResult = await this.backfillManager.execute(
      backfillJob,
      {
        onProgress: (progress) => {
          this.options.onProgress?.('backfill', progress);
        }
      }
    );

    return {
      phase: 'backfill',
      success: backfillResult.success,
      duration: Date.now() - startTime,
      metrics: {
        totalItems: backfillResult.totalItems,
        migratedItems: backfillResult.migratedItems,
        errorCount: backfillResult.errors.length
      }
    };
  }

  // Phase 3: ë°ì´í„° ê²€ì¦
  private async phaseValidation(): Promise<PhaseResult> {
    const startTime = Date.now();
    
    const validator = new DataValidator(
      this.oldSystem,
      this.newSystem
    );

    // ì „ì²´ ê²€ì¦
    const validationResult = await validator.validate({
      strategies: ['count', 'checksum', 'sample'],
      sampleSize: this.options.validationSampleSize || 10000,
      parallelism: 5
    });

    // ë¶ˆì¼ì¹˜ ì²˜ë¦¬
    if (!validationResult.valid) {
      await this.handleValidationDiscrepancies(
        validationResult.discrepancies
      );
    }

    return {
      phase: 'validation',
      success: validationResult.valid,
      duration: Date.now() - startTime,
      metrics: validationResult
    };
  }

  // Phase 4: ì‹œìŠ¤í…œ ì „í™˜
  private async phaseCutover(): Promise<PhaseResult> {
    const startTime = Date.now();
    
    // 1. ì½ê¸° íŠ¸ë˜í”½ ì ì§„ì  ì´ë™
    await this.cutoverManager.startGradualCutover({
      trafficPercentages: [10, 25, 50, 75, 100],
      intervalMinutes: this.options.cutoverInterval || 5,
      rollbackThreshold: {
        errorRate: 0.01,
        latencyP99: 100
      }
    });

    // 2. ê±´ê°• ìƒíƒœ ëª¨ë‹ˆí„°ë§
    const healthChecker = new HealthChecker(this.newSystem);
    const healthCheckResult = await healthChecker.continuousCheck({
      duration: 300000, // 5ë¶„
      interval: 5000
    });

    if (!healthCheckResult.healthy) {
      throw new Error('New system health check failed');
    }

    // 3. ì´ì¤‘ ì“°ê¸° ë°©í–¥ ì „í™˜
    await this.dualWriteManager.switchPrimary('new');

    // 4. ìµœì¢… ë™ê¸°í™”
    await this.performFinalSync();

    return {
      phase: 'cutover',
      success: true,
      duration: Date.now() - startTime,
      metrics: {
        trafficMigrated: true,
        healthStatus: healthCheckResult.status,
        errorRate: healthCheckResult.errorRate
      }
    };
  }

  // Phase 5: ì •ë¦¬ ì‘ì—…
  private async phaseCleanup(): Promise<PhaseResult> {
    const startTime = Date.now();
    
    // 1. ì´ì¤‘ ì“°ê¸° ë¹„í™œì„±í™”
    await this.dualWriteManager.disable();

    // 2. ì„ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    await this.cleanupTemporaryResources();

    // 3. êµ¬ ì‹œìŠ¤í…œ ì•„ì¹´ì´ë¸Œ
    if (this.options.archiveOldData) {
      await this.archiveOldSystem();
    }

    return {
      phase: 'cleanup',
      success: true,
      duration: Date.now() - startTime,
      metrics: {
        resourcesCleaned: true,
        oldSystemArchived: this.options.archiveOldData || false
      }
    };
  }

  // ì“°ê¸° í”„ë¡ì‹œ ì„¤ì •
  private async setupWriteProxy(): Promise<void> {
    const proxy = new WriteProxy({
      interceptor: async (operation) => {
        // ì›ë³¸ ì‹œìŠ¤í…œì— ì“°ê¸°
        const oldResult = await this.oldSystem.write(operation);
        
        // ìƒˆ ì‹œìŠ¤í…œì— ë¹„ë™ê¸° ì“°ê¸°
        this.newSystem.writeAsync(operation).catch(error => {
          this.options.onDualWriteError?.(error, operation);
        });

        return oldResult;
      }
    });

    await proxy.install();
  }

  // ìµœì¢… ë™ê¸°í™”
  private async performFinalSync(): Promise<void> {
    // ë§ˆì§€ë§‰ ë³€ê²½ì‚¬í•­ í™•ì¸
    const lastChanges = await this.oldSystem.getChangesSince(
      this.backfillManager.getLastSyncTimestamp()
    );

    if (lastChanges.length > 0) {
      // ë™ê¸°í™” ìˆ˜í–‰
      await this.backfillManager.syncChanges(lastChanges);
    }
  }

  // ë¡¤ë°± ì²˜ë¦¬
  private async rollback(
    failedPhase: number,
    completedPhases: PhaseResult[]
  ): Promise<void> {
    // ì—­ìˆœìœ¼ë¡œ ë¡¤ë°±
    for (let i = failedPhase - 1; i >= 0; i--) {
      const phase = completedPhases[i];
      
      switch (phase.phase) {
        case 'cutover':
          await this.cutoverManager.rollback();
          break;
        case 'dual_write':
          await this.dualWriteManager.disable();
          break;
        // ë‹¤ë¥¸ phaseë“¤ì˜ ë¡¤ë°± ë¡œì§
      }
    }
  }
}

// ì´ì¤‘ ì“°ê¸° ê´€ë¦¬ì
export class DualWriteManager {
  private writeMetrics: WriteMetrics;
  private errorHandler: ErrorHandler;
  
  constructor(
    private primarySystem: DataSystem,
    private secondarySystem: DataSystem
  ) {
    this.writeMetrics = new WriteMetrics();
    this.errorHandler = new ErrorHandler();
  }

  async enable(config: DualWriteConfig): Promise<void> {
    // ì“°ê¸° ì¸í„°ì…‰í„° ì„¤ì •
    this.primarySystem.addWriteInterceptor(async (operation) => {
      const primaryResult = await this.primarySystem.executeWrite(operation);
      
      // ë³´ì¡° ì‹œìŠ¤í…œì— ì“°ê¸°
      if (config.asyncWrite) {
        this.writeToSecondaryAsync(operation);
      } else {
        await this.writeToSecondarySync(operation);
      }
      
      return primaryResult;
    });
  }

  private async writeToSecondaryAsync(operation: WriteOperation): Promise<void> {
    try {
      await this.secondarySystem.executeWrite(operation);
      this.writeMetrics.recordSuccess('secondary');
    } catch (error) {
      this.writeMetrics.recordFailure('secondary');
      await this.errorHandler.handle(error, operation);
    }
  }

  async switchPrimary(newPrimary: 'old' | 'new'): Promise<void> {
    // íŠ¸ë˜í”½ ì¼ì‹œ ì •ì§€
    await this.pauseWrites();
    
    // ì‹œìŠ¤í…œ ì „í™˜
    if (newPrimary === 'new') {
      [this.primarySystem, this.secondarySystem] = 
        [this.secondarySystem, this.primarySystem];
    }
    
    // íŠ¸ë˜í”½ ì¬ê°œ
    await this.resumeWrites();
  }

  getMetrics(): DualWriteMetrics {
    return {
      primaryWrites: this.writeMetrics.getPrimaryMetrics(),
      secondaryWrites: this.writeMetrics.getSecondaryMetrics(),
      errorRate: this.writeMetrics.getErrorRate(),
      latencyDiff: this.writeMetrics.getLatencyDifference()
    };
  }
}

// ì ì§„ì  ì „í™˜ ê´€ë¦¬ì
export class CutoverManager {
  private trafficRouter: TrafficRouter;
  private healthMonitor: HealthMonitor;
  
  async startGradualCutover(config: CutoverConfig): Promise<void> {
    for (const percentage of config.trafficPercentages) {
      // íŠ¸ë˜í”½ ë¹„ìœ¨ ì¡°ì •
      await this.trafficRouter.setDistribution({
        old: 100 - percentage,
        new: percentage
      });

      // ëŒ€ê¸° ë° ëª¨ë‹ˆí„°ë§
      await this.waitAndMonitor(
        config.intervalMinutes * 60 * 1000,
        config.rollbackThreshold
      );

      // ì„ê³„ê°’ í™•ì¸
      const metrics = await this.healthMonitor.getCurrentMetrics();
      if (this.shouldRollback(metrics, config.rollbackThreshold)) {
        throw new Error('Cutover rollback triggered');
      }
    }
  }

  private async waitAndMonitor(
    duration: number,
    threshold: RollbackThreshold
  ): Promise<void> {
    const endTime = Date.now() + duration;
    
    while (Date.now() < endTime) {
      const metrics = await this.healthMonitor.getCurrentMetrics();
      
      if (this.shouldRollback(metrics, threshold)) {
        throw new Error('Health check failed during cutover');
      }
      
      await new Promise(resolve => setTimeout(resolve, 5000));
    }
  }

  private shouldRollback(
    metrics: SystemMetrics,
    threshold: RollbackThreshold
  ): boolean {
    return metrics.errorRate > threshold.errorRate ||
           metrics.latencyP99 > threshold.latencyP99;
  }

  async rollback(): Promise<void> {
    // ëª¨ë“  íŠ¸ë˜í”½ì„ êµ¬ ì‹œìŠ¤í…œìœ¼ë¡œ
    await this.trafficRouter.setDistribution({
      old: 100,
      new: 0
    });
  }
}