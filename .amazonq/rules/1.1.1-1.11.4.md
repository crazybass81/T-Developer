# Phase 1: ì½”ì–´ ì¸í”„ë¼ êµ¬ì¶• - ì „ì²´ SubTask ì‘ì—…ì§€ì‹œ ë¬¸ì„œ

## ğŸ“‹ Phase 1 ê°œìš”
- **ëª©í‘œ**: AWS Agent Squad + Agno Framework ê¸°ë°˜ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì½”ì–´ êµ¬ì¶•
- **ë²”ìœ„**: 20ê°œ Tasks Ã— 4 SubTasks = 80ê°œ ì‘ì—… ë‹¨ìœ„
- **ê¸°ê°„**: ì˜ˆìƒ 8-10ì£¼

---

## ğŸ—ï¸ Phase 1 ì „ì²´ Task êµ¬ì¡°

### ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ (Tasks 1.1-1.4)
- Task 1.1: Agent Squad ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì„¤ì •
- Task 1.2: SupervisorAgent ì‹œìŠ¤í…œ êµ¬í˜„
- Task 1.3: íƒœìŠ¤í¬ ë¼ìš°íŒ… ì—”ì§„
- Task 1.4: ì›Œí¬í”Œë¡œìš° ì¡°ì • ì‹œìŠ¤í…œ

### Agno Framework í†µí•© (Tasks 1.5-1.8)
- Task 1.5: Agno ì½”ì–´ ì„¤ì¹˜ ë° ì„¤ì •
- Task 1.6: ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ
- Task 1.7: LLM ëª¨ë¸ í†µí•© ë ˆì´ì–´
- Task 1.8: ë©”ëª¨ë¦¬ ë° ìƒíƒœ ê´€ë¦¬

### Bedrock ëŸ°íƒ€ì„ í™˜ê²½ (Tasks 1.9-1.11)
- Task 1.9: AgentCore ëŸ°íƒ€ì„ êµ¬ì„±
- Task 1.10: ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ
- Task 1.11: ë³´ì•ˆ ë° ì¸ì¦ ë ˆì´ì–´

### ë°ì´í„° ì¸í”„ë¼ (Tasks 1.12-1.14)
- Task 1.12: DynamoDB ì—°ê²° ì„¤ì •
- Task 1.13: ìºì‹± ì‹œìŠ¤í…œ êµ¬ì¶•
- Task 1.14: ë©”ì‹œì§• í ì‹œìŠ¤í…œ

### ì‹œìŠ¤í…œ ì¸í”„ë¼ (Tasks 1.15-1.17)
- Task 1.15: ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
- Task 1.16: ì—ëŸ¬ ì²˜ë¦¬ í”„ë ˆì„ì›Œí¬
- Task 1.17: ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ

### í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (Tasks 1.18-1.20)
- Task 1.18: ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë„êµ¬
- Task 1.19: í†µí•© í…ŒìŠ¤íŠ¸ í™˜ê²½
- Task 1.20: CI/CD íŒŒì´í”„ë¼ì¸ ê¸°ì´ˆ

---

## ğŸ“ ì„¸ë¶€ ì‘ì—…ì§€ì‹œì„œ

### Task 1.1: Agent Squad ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì„¤ì •

#### SubTask 1.1.1: Agent Squad ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì´ˆê¸° ì„¤ì •
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```bash
# Python í™˜ê²½
pip install agent-squad[aws]
pip install agent-squad[monitoring]

# TypeScript/JavaScript í™˜ê²½
npm install agent-squad
npm install @types/agent-squad --save-dev
```

**ì„¤ì • íŒŒì¼ ìƒì„±**:
```typescript
// backend/src/config/agent-squad.config.ts
export const agentSquadConfig = {
  orchestrator: {
    maxConcurrentAgents: 50,
    timeout: 300000, // 5ë¶„
    retryPolicy: {
      maxAttempts: 3,
      backoffMultiplier: 2
    }
  },
  monitoring: {
    enabled: true,
    metricsEndpoint: '/metrics',
    healthCheckInterval: 30000
  },
  storage: {
    type: 'dynamodb',
    region: process.env.AWS_REGION,
    tableName: 't-developer-agents'
  }
};
```

**ê²€ì¦ ê¸°ì¤€**:
- [ ] Agent Squad íŒ¨í‚¤ì§€ ì •ìƒ ì„¤ì¹˜
- [ ] ì„¤ì • íŒŒì¼ ë¡œë“œ í™•ì¸
- [ ] ê¸°ë³¸ orchestrator ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ

#### SubTask 1.1.2: ê¸°ë³¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° êµ¬í˜„
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/orchestration/base_orchestrator.py
from agent_squad import AgentSquad, Agent
from typing import Dict, List, Any
import asyncio

class BaseOrchestrator:
    def __init__(self):
        self.squad = AgentSquad()
        self.agent_registry: Dict[str, Agent] = {}
        self.active_sessions: Dict[str, Any] = {}
        
    async def initialize(self):
        """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”"""
        await self.squad.initialize()
        await self.register_default_agents()
        
    async def register_agent(self, name: str, agent: Agent):
        """ì—ì´ì „íŠ¸ ë“±ë¡"""
        self.agent_registry[name] = agent
        await self.squad.add_agent(agent)
        
    async def route_task(self, task: Dict[str, Any]) -> Any:
        """íƒœìŠ¤í¬ ë¼ìš°íŒ…"""
        agent_name = self.determine_agent(task)
        if agent_name in self.agent_registry:
            return await self.agent_registry[agent_name].execute(task)
        raise ValueError(f"No agent found for task: {task}")
```

#### SubTask 1.1.3: ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/orchestration/agent-registry.ts
interface AgentMetadata {
  name: string;
  version: string;
  capabilities: string[];
  maxConcurrent: number;
  timeout: number;
}

class AgentRegistry {
  private agents: Map<string, AgentMetadata> = new Map();
  private instances: Map<string, any> = new Map();
  
  async register(metadata: AgentMetadata): Promise<void> {
    this.agents.set(metadata.name, metadata);
    await this.persistToDatabase(metadata);
  }
  
  async getAgent(name: string): Promise<any> {
    if (!this.instances.has(name)) {
      await this.instantiateAgent(name);
    }
    return this.instances.get(name);
  }
  
  private async instantiateAgent(name: string): Promise<void> {
    const metadata = this.agents.get(name);
    if (!metadata) throw new Error(`Agent ${name} not found`);
    
    // Dynamic import and instantiation
    const AgentClass = await import(`../agents/${name}`);
    this.instances.set(name, new AgentClass.default(metadata));
  }
}
```

#### SubTask 1.1.4: í—¬ìŠ¤ì²´í¬ ë° ëª¨ë‹ˆí„°ë§ í†µí•©
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/monitoring/health_check.py
class OrchestratorHealthCheck:
    def __init__(self, orchestrator):
        self.orchestrator = orchestrator
        self.metrics = {
            'active_agents': 0,
            'queued_tasks': 0,
            'completed_tasks': 0,
            'failed_tasks': 0,
            'avg_response_time': 0
        }
    
    async def check_health(self) -> Dict[str, Any]:
        return {
            'status': 'healthy' if self.is_healthy() else 'unhealthy',
            'timestamp': datetime.utcnow().isoformat(),
            'metrics': await self.collect_metrics(),
            'agents': await self.check_agent_health()
        }
    
    async def collect_metrics(self):
        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë¡œì§
        pass
```

---

### Task 1.2: SupervisorAgent ì‹œìŠ¤í…œ êµ¬í˜„

#### SubTask 1.2.1: SupervisorAgent ì•„í‚¤í…ì²˜ ì„¤ê³„
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/agents/supervisor/supervisor_agent.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any
import asyncio

class SupervisorAgent(ABC):
    """ëª¨ë“  ì‘ì—…ì„ ê°ë…í•˜ê³  ì¡°ì •í•˜ëŠ” ìµœìƒìœ„ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.sub_agents: Dict[str, Agent] = {}
        self.workflow_engine = WorkflowEngine()
        self.decision_engine = DecisionEngine()
        
    async def analyze_request(self, request: Dict[str, Any]) -> WorkflowPlan:
        """ìš”ì²­ ë¶„ì„ ë° ì›Œí¬í”Œë¡œìš° ê³„íš ìˆ˜ë¦½"""
        # NLPë¥¼ ì‚¬ìš©í•œ ìš”ì²­ ë¶„ì„
        intent = await self.extract_intent(request)
        
        # í•„ìš”í•œ ì—ì´ì „íŠ¸ ê²°ì •
        required_agents = await self.decision_engine.determine_agents(intent)
        
        # ì›Œí¬í”Œë¡œìš° ìƒì„±
        workflow = await self.workflow_engine.create_workflow(
            intent, required_agents
        )
        
        return workflow
        
    async def execute_workflow(self, workflow: WorkflowPlan) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ë° ì¡°ì •"""
        results = {}
        
        for step in workflow.steps:
            if step.parallel:
                # ë³‘ë ¬ ì‹¤í–‰
                tasks = [
                    self.execute_agent_task(agent, step.task)
                    for agent in step.agents
                ]
                step_results = await asyncio.gather(*tasks)
            else:
                # ìˆœì°¨ ì‹¤í–‰
                step_results = []
                for agent in step.agents:
                    result = await self.execute_agent_task(agent, step.task)
                    step_results.append(result)
            
            results[step.name] = step_results
            
        return results
```

#### SubTask 1.2.2: ì˜ì‚¬ê²°ì • ì—”ì§„ êµ¬í˜„
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/agents/supervisor/decision-engine.ts
interface Decision {
  agentName: string;
  confidence: number;
  reasoning: string;
  alternativeAgents?: string[];
}

class DecisionEngine {
  private modelEndpoint: string;
  private decisionHistory: Map<string, Decision[]> = new Map();
  
  async determineAgents(intent: Intent): Promise<Decision[]> {
    // 1. ê·œì¹™ ê¸°ë°˜ ë§¤ì¹­
    const ruleBasedAgents = this.matchByRules(intent);
    
    // 2. ML ê¸°ë°˜ ì˜ˆì¸¡
    const mlPredictions = await this.predictAgents(intent);
    
    // 3. íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ìµœì í™”
    const historicalPatterns = this.analyzeHistory(intent);
    
    // 4. ìµœì¢… ê²°ì •
    return this.combineDecisions(
      ruleBasedAgents,
      mlPredictions,
      historicalPatterns
    );
  }
  
  private matchByRules(intent: Intent): Decision[] {
    const rules = [
      { pattern: /code|implement|develop/, agents: ['CodeAgent'] },
      { pattern: /test|verify|validate/, agents: ['TestAgent'] },
      { pattern: /design|architect/, agents: ['DesignAgent'] },
      { pattern: /security|vulnerabilit/, agents: ['SecurityAgent'] }
    ];
    
    return rules
      .filter(rule => rule.pattern.test(intent.description))
      .map(rule => ({
        agentName: rule.agents[0],
        confidence: 0.8,
        reasoning: `Rule-based match: ${rule.pattern}`
      }));
  }
}
```

#### SubTask 1.2.3: ì›Œí¬í”Œë¡œìš° ì—”ì§„ ê°œë°œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 20ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/workflow/workflow_engine.py
from dataclasses import dataclass
from typing import List, Optional
from enum import Enum

class StepType(Enum):
    SEQUENTIAL = "sequential"
    PARALLEL = "parallel"
    CONDITIONAL = "conditional"

@dataclass
class WorkflowStep:
    id: str
    name: str
    type: StepType
    agents: List[str]
    dependencies: List[str]
    condition: Optional[str] = None
    timeout: int = 300

class WorkflowEngine:
    def __init__(self):
        self.templates = self.load_workflow_templates()
        self.validator = WorkflowValidator()
        
    async def create_workflow(
        self, 
        intent: Intent, 
        agents: List[str]
    ) -> Workflow:
        # 1. í…œí”Œë¦¿ ì„ íƒ
        template = self.select_template(intent)
        
        # 2. ì›Œí¬í”Œë¡œìš° ìƒì„±
        workflow = Workflow()
        
        if template:
            workflow = self.apply_template(template, agents)
        else:
            workflow = self.create_dynamic_workflow(intent, agents)
        
        # 3. ê²€ì¦
        await self.validator.validate(workflow)
        
        # 4. ìµœì í™”
        workflow = self.optimize_workflow(workflow)
        
        return workflow
    
    def create_dynamic_workflow(
        self, 
        intent: Intent, 
        agents: List[str]
    ) -> Workflow:
        """ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        steps = []
        
        # ì˜ì¡´ì„± ë¶„ì„
        dependencies = self.analyze_dependencies(agents)
        
        # ë³‘ë ¬í™” ê°€ëŠ¥í•œ ì‘ì—… ì‹ë³„
        parallel_groups = self.identify_parallel_tasks(dependencies)
        
        # ì›Œí¬í”Œë¡œìš° ìŠ¤í… ìƒì„±
        for group in parallel_groups:
            if len(group) > 1:
                step = WorkflowStep(
                    id=f"step_{len(steps)}",
                    name=f"Parallel execution: {', '.join(group)}",
                    type=StepType.PARALLEL,
                    agents=group,
                    dependencies=[]
                )
            else:
                step = WorkflowStep(
                    id=f"step_{len(steps)}",
                    name=f"Execute: {group[0]}",
                    type=StepType.SEQUENTIAL,
                    agents=group,
                    dependencies=[]
                )
            steps.append(step)
        
        return Workflow(steps=steps)
```

#### SubTask 1.2.4: ì‹¤í–‰ ìƒíƒœ ì¶”ì  ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/workflow/execution-tracker.ts
interface ExecutionState {
  workflowId: string;
  status: 'pending' | 'running' | 'completed' | 'failed';
  currentStep: string;
  startTime: Date;
  endTime?: Date;
  results: Map<string, any>;
  errors: Error[];
}

class ExecutionTracker {
  private states: Map<string, ExecutionState> = new Map();
  private eventEmitter: EventEmitter;
  
  async trackExecution(
    workflowId: string, 
    workflow: Workflow
  ): Promise<void> {
    const state: ExecutionState = {
      workflowId,
      status: 'pending',
      currentStep: workflow.steps[0].id,
      startTime: new Date(),
      results: new Map(),
      errors: []
    };
    
    this.states.set(workflowId, state);
    this.emitUpdate(workflowId, state);
    
    // ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ WebSocket ì—°ê²°
    this.setupRealtimeUpdates(workflowId);
  }
  
  async updateStepProgress(
    workflowId: string,
    stepId: string,
    progress: number
  ): Promise<void> {
    const state = this.states.get(workflowId);
    if (!state) return;
    
    state.currentStep = stepId;
    this.emitUpdate(workflowId, {
      ...state,
      progress
    });
  }
  
  private setupRealtimeUpdates(workflowId: string): void {
    // WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
    this.eventEmitter.on(`progress:${workflowId}`, (data) => {
      this.broadcast(workflowId, {
        type: 'progress',
        data
      });
    });
  }
}
```

---

### Task 1.3: íƒœìŠ¤í¬ ë¼ìš°íŒ… ì—”ì§„

#### SubTask 1.3.1: ì§€ëŠ¥í˜• ë¼ìš°íŒ… ì•Œê³ ë¦¬ì¦˜
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/routing/intelligent_router.py
import numpy as np
from sklearn.preprocessing import StandardScaler
from typing import List, Tuple

class IntelligentRouter:
    def __init__(self):
        self.routing_model = self.load_routing_model()
        self.feature_extractor = FeatureExtractor()
        self.load_balancer = LoadBalancer()
        
    async def route_task(self, task: Task) -> Agent:
        """íƒœìŠ¤í¬ë¥¼ ê°€ì¥ ì ì ˆí•œ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…"""
        
        # 1. íŠ¹ì§• ì¶”ì¶œ
        features = await self.feature_extractor.extract(task)
        
        # 2. ì—ì´ì „íŠ¸ ì ìˆ˜ ê³„ì‚°
        agent_scores = await self.calculate_agent_scores(features)
        
        # 3. ë¡œë“œ ë°¸ëŸ°ì‹± ê³ ë ¤
        available_agents = await self.load_balancer.get_available_agents()
        
        # 4. ìµœì¢… ì„ íƒ
        selected_agent = self.select_best_agent(
            agent_scores, 
            available_agents
        )
        
        # 5. ë¼ìš°íŒ… ê¸°ë¡
        await self.record_routing_decision(task, selected_agent)
        
        return selected_agent
    
    async def calculate_agent_scores(
        self, 
        features: np.ndarray
    ) -> List[Tuple[str, float]]:
        """ê° ì—ì´ì „íŠ¸ì˜ ì í•©ë„ ì ìˆ˜ ê³„ì‚°"""
        
        # ML ëª¨ë¸ ì˜ˆì¸¡
        predictions = self.routing_model.predict_proba(features)
        
        # ì—ì´ì „íŠ¸ë³„ ì ìˆ˜
        agent_scores = []
        for idx, agent_name in enumerate(self.agent_names):
            score = predictions[0][idx]
            
            # ê³¼ê±° ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ì ìš©
            historical_weight = await self.get_historical_performance(
                agent_name
            )
            adjusted_score = score * historical_weight
            
            agent_scores.append((agent_name, adjusted_score))
        
        return sorted(agent_scores, key=lambda x: x[1], reverse=True)
```

#### SubTask 1.3.2: ë¡œë“œ ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/routing/load-balancer.ts
interface AgentLoad {
  agentId: string;
  currentTasks: number;
  cpuUsage: number;
  memoryUsage: number;
  avgResponseTime: number;
  capacity: number;
}

class LoadBalancer {
  private agentLoads: Map<string, AgentLoad> = new Map();
  private strategy: BalancingStrategy;
  
  constructor(strategy: BalancingStrategy = 'weighted-round-robin') {
    this.strategy = strategy;
    this.startMonitoring();
  }
  
  async getAvailableAgents(): Promise<string[]> {
    const agents = Array.from(this.agentLoads.entries());
    
    // ìš©ëŸ‰ì´ ë‚¨ì€ ì—ì´ì „íŠ¸ í•„í„°ë§
    const available = agents.filter(([_, load]) => 
      load.currentTasks < load.capacity * 0.8
    );
    
    // ì „ëµì— ë”°ë¼ ì •ë ¬
    switch (this.strategy) {
      case 'least-connections':
        return this.sortByLeastConnections(available);
      case 'weighted-round-robin':
        return this.weightedRoundRobin(available);
      case 'resource-based':
        return this.sortByResourceUsage(available);
      default:
        return available.map(([id]) => id);
    }
  }
  
  private sortByResourceUsage(
    agents: [string, AgentLoad][]
  ): string[] {
    return agents
      .sort((a, b) => {
        const scoreA = this.calculateResourceScore(a[1]);
        const scoreB = this.calculateResourceScore(b[1]);
        return scoreA - scoreB;
      })
      .map(([id]) => id);
  }
  
  private calculateResourceScore(load: AgentLoad): number {
    // ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¢…í•© ì ìˆ˜
    return (
      load.cpuUsage * 0.4 +
      load.memoryUsage * 0.3 +
      (load.currentTasks / load.capacity) * 0.3
    );
  }
}
```

#### SubTask 1.3.3: íƒœìŠ¤í¬ ìš°ì„ ìˆœìœ„ ê´€ë¦¬
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/routing/priority_manager.py
from enum import Enum
from heapq import heappush, heappop
import time

class Priority(Enum):
    CRITICAL = 1
    HIGH = 2
    NORMAL = 3
    LOW = 4

class PriorityQueue:
    def __init__(self):
        self.queue = []
        self.task_map = {}
        
    def add_task(self, task: Task, priority: Priority):
        """ìš°ì„ ìˆœìœ„ íì— íƒœìŠ¤í¬ ì¶”ê°€"""
        # ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°
        priority_score = self.calculate_priority_score(task, priority)
        
        # í™ì— ì¶”ê°€
        heappush(self.queue, (priority_score, time.time(), task))
        self.task_map[task.id] = priority_score
        
    def get_next_task(self) -> Optional[Task]:
        """ë‹¤ìŒ ì‹¤í–‰í•  íƒœìŠ¤í¬ ë°˜í™˜"""
        while self.queue:
            _, _, task = heappop(self.queue)
            if task.id in self.task_map:
                del self.task_map[task.id]
                return task
        return None
    
    def calculate_priority_score(
        self, 
        task: Task, 
        priority: Priority
    ) -> float:
        """ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°"""
        base_score = priority.value
        
        # ëŒ€ê¸° ì‹œê°„ ê°€ì¤‘ì¹˜
        wait_time = time.time() - task.created_at
        wait_weight = min(wait_time / 300, 1.0)  # 5ë¶„ ì´ìƒ ëŒ€ê¸° ì‹œ ìµœëŒ€ ê°€ì¤‘ì¹˜
        
        # SLA ê°€ì¤‘ì¹˜
        sla_weight = 0
        if hasattr(task, 'sla_deadline'):
            time_to_deadline = task.sla_deadline - time.time()
            if time_to_deadline < 300:  # 5ë¶„ ì´ë‚´
                sla_weight = 2.0
        
        return base_score - (wait_weight + sla_weight)
```

#### SubTask 1.3.4: ë¼ìš°íŒ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/routing/routing-metrics.ts
interface RoutingMetrics {
  totalRequests: number;
  routingLatency: number[];
  agentUtilization: Map<string, number>;
  queueDepth: number;
  errorRate: number;
}

class RoutingMonitor {
  private metrics: RoutingMetrics;
  private metricsHistory: RoutingMetrics[] = [];
  
  async collectMetrics(): Promise<void> {
    this.metrics = {
      totalRequests: await this.getTotalRequests(),
      routingLatency: await this.getLatencyPercentiles(),
      agentUtilization: await this.getAgentUtilization(),
      queueDepth: await this.getQueueDepth(),
      errorRate: await this.getErrorRate()
    };
    
    // CloudWatchì— ë©”íŠ¸ë¦­ ì „ì†¡
    await this.publishToCloudWatch(this.metrics);
    
    // ì´ìƒ ê°ì§€
    await this.detectAnomalies(this.metrics);
  }
  
  private async detectAnomalies(
    metrics: RoutingMetrics
  ): Promise<void> {
    // ì§€ì—° ì‹œê°„ ì´ìƒ
    const p99Latency = metrics.routingLatency[99];
    if (p99Latency > 1000) {  // 1ì´ˆ ì´ˆê³¼
      await this.alert('High routing latency detected', {
        p99Latency,
        threshold: 1000
      });
    }
    
    // ì—ëŸ¬ìœ¨ ì´ìƒ
    if (metrics.errorRate > 0.05) {  // 5% ì´ˆê³¼
      await this.alert('High error rate in routing', {
        errorRate: metrics.errorRate,
        threshold: 0.05
      });
    }
  }
}
```

---

### Task 1.4: ì›Œí¬í”Œë¡œìš° ì¡°ì • ì‹œìŠ¤í…œ

#### SubTask 1.4.1: ë³‘ë ¬ ì‹¤í–‰ ì—”ì§„
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/workflow/parallel_executor.py
import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any

class ParallelExecutor:
    def __init__(self, max_workers: int = 50):
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.semaphore = asyncio.Semaphore(max_workers)
        self.task_tracker = TaskTracker()
        
    async def execute_parallel(
        self, 
        tasks: List[Task]
    ) -> List[Dict[str, Any]]:
        """ë³‘ë ¬ íƒœìŠ¤í¬ ì‹¤í–‰"""
        
        # ì˜ì¡´ì„± ê·¸ë˜í”„ ìƒì„±
        dependency_graph = self.build_dependency_graph(tasks)
        
        # ì‹¤í–‰ ìˆœì„œ ê²°ì •
        execution_order = self.topological_sort(dependency_graph)
        
        # ë³‘ë ¬ ì‹¤í–‰ ê·¸ë£¹ ìƒì„±
        parallel_groups = self.create_parallel_groups(
            execution_order, 
            dependency_graph
        )
        
        results = []
        for group in parallel_groups:
            # ê·¸ë£¹ ë‚´ íƒœìŠ¤í¬ ë³‘ë ¬ ì‹¤í–‰
            group_results = await self.execute_group(group)
            results.extend(group_results)
        
        return results
    
    async def execute_group(
        self, 
        group: List[Task]
    ) -> List[Dict[str, Any]]:
        """ê·¸ë£¹ ë‚´ íƒœìŠ¤í¬ ë³‘ë ¬ ì‹¤í–‰"""
        async with self.semaphore:
            tasks = []
            for task in group:
                # ê° íƒœìŠ¤í¬ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
                task_future = asyncio.create_task(
                    self.execute_single_task(task)
                )
                tasks.append(task_future)
            
            # ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì—ëŸ¬ ì²˜ë¦¬
            processed_results = []
            for idx, result in enumerate(results):
                if isinstance(result, Exception):
                    await self.handle_task_error(group[idx], result)
                    processed_results.append({
                        'task_id': group[idx].id,
                        'status': 'failed',
                        'error': str(result)
                    })
                else:
                    processed_results.append(result)
            
            return processed_results
```

#### SubTask 1.4.2: ì˜ì¡´ì„± ê´€ë¦¬ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/workflow/dependency-manager.ts
interface Dependency {
  taskId: string;
  dependsOn: string[];
  type: 'hard' | 'soft';
  condition?: string;
}

class DependencyManager {
  private dependencies: Map<string, Dependency> = new Map();
  private graph: DirectedGraph<string>;
  
  constructor() {
    this.graph = new DirectedGraph();
  }
  
  addDependency(dependency: Dependency): void {
    this.dependencies.set(dependency.taskId, dependency);
    
    // ê·¸ë˜í”„ì— ë…¸ë“œ ì¶”ê°€
    this.graph.addNode(dependency.taskId);
    
    // ì˜ì¡´ì„± ì—£ì§€ ì¶”ê°€
    for (const dep of dependency.dependsOn) {
      this.graph.addEdge(dep, dependency.taskId);
    }
    
    // ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
    if (this.graph.hasCycle()) {
      throw new Error(
        `Circular dependency detected for task: ${dependency.taskId}`
      );
    }
  }
  
  async canExecute(taskId: string): Promise<boolean> {
    const dependency = this.dependencies.get(taskId);
    if (!dependency) return true;
    
    // ëª¨ë“  ì˜ì¡´ì„± í™•ì¸
    for (const depId of dependency.dependsOn) {
      const depStatus = await this.getTaskStatus(depId);
      
      if (dependency.type === 'hard' && depStatus !== 'completed') {
        return false;
      }
      
      if (dependency.type === 'soft' && depStatus === 'failed') {
        // Soft ì˜ì¡´ì„±ì€ ì‹¤íŒ¨í•´ë„ ì§„í–‰ ê°€ëŠ¥
        console.warn(`Soft dependency ${depId} failed for ${taskId}`);
      }
    }
    
    // ì¡°ê±´ë¶€ ì˜ì¡´ì„± í‰ê°€
    if (dependency.condition) {
      return await this.evaluateCondition(dependency.condition);
    }
    
    return true;
  }
  
  getExecutionOrder(): string[] {
    // ìœ„ìƒ ì •ë ¬ë¡œ ì‹¤í–‰ ìˆœì„œ ê²°ì •
    return this.graph.topologicalSort();
  }
}
```

#### SubTask 1.4.3: ìƒíƒœ ë™ê¸°í™” ë©”ì»¤ë‹ˆì¦˜
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/workflow/state_synchronizer.py
import redis
import json
from typing import Dict, Any
import asyncio

class StateSynchronizer:
    def __init__(self):
        self.redis_client = redis.Redis(
            host=os.getenv('REDIS_HOST'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            decode_responses=True
        )
        self.state_locks = {}
        self.pubsub = self.redis_client.pubsub()
        
    async def sync_state(
        self, 
        workflow_id: str, 
        state: Dict[str, Any]
    ) -> None:
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë™ê¸°í™”"""
        
        # ë¶„ì‚° ë½ íšë“
        lock_key = f"lock:workflow:{workflow_id}"
        async with self.acquire_lock(lock_key):
            # í˜„ì¬ ìƒíƒœ ì½ê¸°
            current_state = await self.get_state(workflow_id)
            
            # ìƒíƒœ ë³‘í•©
            merged_state = self.merge_states(current_state, state)
            
            # ìƒíƒœ ì €ì¥
            await self.save_state(workflow_id, merged_state)
            
            # ë³€ê²½ ì‚¬í•­ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            await self.broadcast_state_change(workflow_id, merged_state)
    
    async def acquire_lock(
        self, 
        lock_key: str, 
        timeout: int = 30
    ) -> AsyncContextManager:
        """ë¶„ì‚° ë½ íšë“"""
        lock = self.redis_client.lock(
            lock_key,
            timeout=timeout,
            blocking_timeout=5
        )
        return lock
    
    def merge_states(
        self, 
        current: Dict[str, Any], 
        new: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ìƒíƒœ ë³‘í•© ë¡œì§"""
        merged = current.copy()
        
        for key, value in new.items():
            if key in merged and isinstance(merged[key], dict):
                # ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ ì¬ê·€ì  ë³‘í•©
                merged[key] = self.merge_states(merged[key], value)
            else:
                merged[key] = value
        
        merged['last_updated'] = datetime.utcnow().isoformat()
        return merged
```

#### SubTask 1.4.4: ì¥ì•  ë³µêµ¬ ë° ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/workflow/recovery-manager.ts
interface RecoveryStrategy {
  maxRetries: number;
  backoffMultiplier: number;
  maxBackoffSeconds: number;
  retryableErrors: string[];
}

class RecoveryManager {
  private strategies: Map<string, RecoveryStrategy> = new Map();
  private recoveryHistory: Map<string, any[]> = new Map();
  
  async handleFailure(
    task: Task,
    error: Error
  ): Promise<RecoveryAction> {
    const strategy = this.getStrategy(task.type);
    const history = this.getHistory(task.id);
    
    // ì¬ì‹œë„ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if (!this.isRetryable(error, strategy)) {
      return { action: 'fail', reason: 'Non-retryable error' };
    }
    
    // ì¬ì‹œë„ íšŸìˆ˜ í™•ì¸
    if (history.length >= strategy.maxRetries) {
      return { action: 'fail', reason: 'Max retries exceeded' };
    }
    
    // ë°±ì˜¤í”„ ê³„ì‚°
    const backoffTime = this.calculateBackoff(
      history.length,
      strategy
    );
    
    // ë³µêµ¬ ì•¡ì…˜ ê²°ì •
    return {
      action: 'retry',
      delaySeconds: backoffTime,
      attemptNumber: history.length + 1
    };
  }
  
  async executeRecovery(
    task: Task,
    action: RecoveryAction
  ): Promise<void> {
    switch (action.action) {
      case 'retry':
        await this.scheduleRetry(task, action.delaySeconds);
        break;
      case 'compensate':
        await this.executeCompensation(task);
        break;
      case 'fail':
        await this.handlePermanentFailure(task);
        break;
    }
  }
  
  private calculateBackoff(
    attemptNumber: number,
    strategy: RecoveryStrategy
  ): number {
    const backoff = Math.min(
      strategy.backoffMultiplier ** attemptNumber,
      strategy.maxBackoffSeconds
    );
    
    // Jitter ì¶”ê°€ë¡œ ì¬ì‹œë„ í­ì£¼ ë°©ì§€
    const jitter = Math.random() * 0.3 * backoff;
    return Math.floor(backoff + jitter);
  }
}
```

---

### Task 1.5: Agno ì½”ì–´ ì„¤ì¹˜ ë° ì„¤ì •

#### SubTask 1.5.1: Agno Framework ì„¤ì¹˜
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```bash
# Agno ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash

# Python í™˜ê²½
pip install agno
pip install agno[all]  # ëª¨ë“  í™•ì¥ ê¸°ëŠ¥ í¬í•¨
pip install agno[monitoring]
pip install agno[tracing]

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install pydantic>=2.0
pip install httpx>=0.24
pip install rich>=13.0
```

**ì„¤ì • íŒŒì¼**:
```python
# backend/src/config/agno_config.py
from agno import AgnoConfig
from agno.monitoring import MonitoringConfig
from agno.tracing import TracingConfig

AGNO_CONFIG = AgnoConfig(
    # ì„±ëŠ¥ ì„¤ì •
    performance={
        "instantiation_target_us": 3,  # 3Î¼s ëª©í‘œ
        "memory_target_kb": 6.5,        # 6.5KB ëª©í‘œ
        "enable_optimizations": True,
        "use_native_extensions": True
    },
    
    # ëª¨ë‹ˆí„°ë§ ì„¤ì •
    monitoring=MonitoringConfig(
        enabled=True,
        endpoint="https://agno.com/metrics",
        api_key=os.getenv("AGNO_API_KEY"),
        metrics_interval=30,
        custom_metrics=[
            "agent_instantiation_time",
            "memory_usage_per_agent",
            "total_active_agents"
        ]
    ),
    
    # íŠ¸ë ˆì´ì‹± ì„¤ì •
    tracing=TracingConfig(
        enabled=True,
        sample_rate=0.1,  # 10% ìƒ˜í”Œë§
        export_endpoint="https://agno.com/traces"
    ),
    
    # ë¦¬ì†ŒìŠ¤ ì œí•œ
    resources={
        "max_agents": 10000,
        "max_memory_per_agent_kb": 10,
        "agent_timeout_seconds": 300
    }
)
```

#### SubTask 1.5.2: ì„±ëŠ¥ ìµœì í™” ì„¤ì •
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/agno/performance_optimizer.py
import agno
from agno.optimizers import (
    MemoryOptimizer,
    InstantiationOptimizer,
    CacheOptimizer
)

class AgnoPerformanceOptimizer:
    def __init__(self):
        self.memory_optimizer = MemoryOptimizer()
        self.instantiation_optimizer = InstantiationOptimizer()
        self.cache_optimizer = CacheOptimizer()
        
    async def optimize_agent_creation(self):
        """ì—ì´ì „íŠ¸ ìƒì„± ìµœì í™”"""
        
        # 1. í”„ë¦¬ë¡œë“œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ëª¨ë“ˆ
        await self.preload_common_modules()
        
        # 2. ì—ì´ì „íŠ¸ í’€ ì´ˆê¸°í™”
        await self.initialize_agent_pool()
        
        # 3. JIT ì»´íŒŒì¼ í™œì„±í™”
        self.enable_jit_compilation()
        
        # 4. ë©”ëª¨ë¦¬ ì‚¬ì „ í• ë‹¹
        await self.preallocate_memory()
    
    def enable_jit_compilation(self):
        """JIT ì»´íŒŒì¼ í™œì„±í™”"""
        import numba
        
        # í•µì‹¬ í•¨ìˆ˜ë“¤ JIT ì»´íŒŒì¼
        @numba.jit(nopython=True, cache=True)
        def fast_agent_init(config):
            # ìµœì í™”ëœ ì´ˆê¸°í™” ë¡œì§
            pass
        
        agno.set_init_function(fast_agent_init)
    
    async def benchmark_performance(self):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        import time
        
        # ì¸ìŠ¤í„´ìŠ¤í™” ì‹œê°„ ì¸¡ì •
        start = time.perf_counter_ns()
        agent = agno.Agent()
        end = time.perf_counter_ns()
        
        instantiation_time_us = (end - start) / 1000
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        memory_before = process.memory_info().rss
        
        agents = [agno.Agent() for _ in range(1000)]
        
        memory_after = process.memory_info().rss
        memory_per_agent_kb = (memory_after - memory_before) / 1000 / 1024
        
        return {
            "instantiation_time_us": instantiation_time_us,
            "memory_per_agent_kb": memory_per_agent_kb,
            "target_met": (
                instantiation_time_us <= 3 and 
                memory_per_agent_kb <= 6.5
            )
        }
```

#### SubTask 1.5.3: Agno ì—ì´ì „íŠ¸ í’€ êµ¬í˜„
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/agno/agent-pool.ts
import { Agent as AgnoAgent } from 'agno';

interface PoolConfig {
  minSize: number;
  maxSize: number;
  idleTimeout: number;
  preWarm: boolean;
}

class AgentPool {
  private available: AgnoAgent[] = [];
  private inUse: Map<string, AgnoAgent> = new Map();
  private config: PoolConfig;
  
  constructor(config: PoolConfig) {
    this.config = config;
    if (config.preWarm) {
      this.warmUp();
    }
  }
  
  private async warmUp(): Promise<void> {
    // ë¯¸ë¦¬ ì—ì´ì „íŠ¸ ìƒì„±
    const promises = [];
    for (let i = 0; i < this.config.minSize; i++) {
      promises.push(this.createAgent());
    }
    
    const agents = await Promise.all(promises);
    this.available.push(...agents);
  }
  
  async getAgent(): Promise<AgnoAgent> {
    // ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ê°€ ìˆìœ¼ë©´ ë°˜í™˜
    if (this.available.length > 0) {
      const agent = this.available.pop()!;
      const id = this.generateId();
      this.inUse.set(id, agent);
      return agent;
    }
    
    // í’€ í¬ê¸° ì œí•œ í™•ì¸
    if (this.inUse.size >= this.config.maxSize) {
      throw new Error('Agent pool exhausted');
    }
    
    // ìƒˆ ì—ì´ì „íŠ¸ ìƒì„±
    const agent = await this.createAgent();
    const id = this.generateId();
    this.inUse.set(id, agent);
    
    return agent;
  }
  
  async releaseAgent(agentId: string): Promise<void> {
    const agent = this.inUse.get(agentId);
    if (!agent) return;
    
    this.inUse.delete(agentId);
    
    // ì—ì´ì „íŠ¸ ìƒíƒœ ì´ˆê¸°í™”
    await this.resetAgent(agent);
    
    // í’€ì— ë°˜í™˜
    if (this.available.length < this.config.maxSize) {
      this.available.push(agent);
    } else {
      // í’€ì´ ê°€ë“ ì°¨ë©´ ì—ì´ì „íŠ¸ ì œê±°
      await this.destroyAgent(agent);
    }
  }
  
  private async createAgent(): Promise<AgnoAgent> {
    // 3Î¼s ëª©í‘œë¡œ ìµœì í™”ëœ ìƒì„±
    const start = performance.now();
    const agent = new AgnoAgent({
      lightweight: true,
      skipValidation: true,
      useCache: true
    });
    const duration = performance.now() - start;
    
    // ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    if (duration > 0.003) {  // 3Î¼s
      console.warn(`Agent creation took ${duration}ms`);
    }
    
    return agent;
  }
}
```

#### SubTask 1.5.4: Agno ëª¨ë‹ˆí„°ë§ í†µí•©
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/agno/monitoring_integration.py
from agno.monitoring import AgnoMonitor
import prometheus_client
from typing import Dict, Any

class AgnoMonitoringIntegration:
    def __init__(self):
        self.agno_monitor = AgnoMonitor()
        self.setup_prometheus_metrics()
        
    def setup_prometheus_metrics(self):
        """Prometheus ë©”íŠ¸ë¦­ ì„¤ì •"""
        
        # ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤í™” ì‹œê°„
        self.instantiation_time = prometheus_client.Histogram(
            'agno_agent_instantiation_seconds',
            'Time to instantiate an Agno agent',
            buckets=(0.000001, 0.000003, 0.00001, 0.0001, 0.001)
        )
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        self.memory_usage = prometheus_client.Gauge(
            'agno_agent_memory_bytes',
            'Memory usage per agent in bytes'
        )
        
        # í™œì„± ì—ì´ì „íŠ¸ ìˆ˜
        self.active_agents = prometheus_client.Gauge(
            'agno_active_agents_total',
            'Total number of active agents'
        )
        
        # ì—ëŸ¬ìœ¨
        self.error_rate = prometheus_client.Counter(
            'agno_errors_total',
            'Total number of errors',
            ['error_type']
        )
    
    async def collect_metrics(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        metrics = await self.agno_monitor.get_metrics()
        
        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self.instantiation_time.observe(
            metrics.get('instantiation_time_us', 0) / 1_000_000
        )
        self.memory_usage.set(
            metrics.get('memory_per_agent_kb', 0) * 1024
        )
        self.active_agents.set(
            metrics.get('active_agents', 0)
        )
        
        # Agno ëŒ€ì‹œë³´ë“œë¡œ ì „ì†¡
        await self.send_to_agno_dashboard(metrics)
        
        return metrics
    
    async def send_to_agno_dashboard(
        self, 
        metrics: Dict[str, Any]
    ) -> None:
        """Agno ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œë¡œ ë©”íŠ¸ë¦­ ì „ì†¡"""
        
        # agno.com ìœ¼ë¡œ ë©”íŠ¸ë¦­ ì „ì†¡
        await self.agno_monitor.send_metrics({
            'timestamp': datetime.utcnow().isoformat(),
            'project_id': os.getenv('AGNO_PROJECT_ID'),
            'metrics': metrics,
            'metadata': {
                'environment': os.getenv('ENVIRONMENT', 'development'),
                'version': os.getenv('APP_VERSION', '1.0.0')
            }
        })
```

ì´ë ‡ê²Œ Phase 1ì˜ ì²˜ìŒ 5ê°œ Tasks (20ê°œ SubTasks)ì— ëŒ€í•œ ìƒì„¸í•œ ì‘ì—…ì§€ì‹œì„œë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. 

ë‚˜ë¨¸ì§€ 15ê°œ Tasks (Task 1.6 ~ Task 1.20)ë„ ê³„ì† ì‘ì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? ê° TaskëŠ” 4ê°œì˜ SubTasksë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ë‹¤ìŒê³¼ ê°™ì€ ì˜ì—­ì„ ë‹¤ë£¹ë‹ˆë‹¤:

- **Task 1.6-1.8**: ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬, LLM í†µí•©, ë©”ëª¨ë¦¬ ê´€ë¦¬
- **Task 1.9-1.11**: Bedrock ëŸ°íƒ€ì„, ì„¸ì…˜ ê´€ë¦¬, ë³´ì•ˆ
- **Task 1.12-1.14**: ë°ì´í„°ë² ì´ìŠ¤, ìºì‹±, ë©”ì‹œì§•
- **Task 1.15-1.17**: ë¡œê¹…, ì—ëŸ¬ ì²˜ë¦¬, ì„¤ì • ê´€ë¦¬
- **Task 1.18-1.20**: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸, í†µí•© í…ŒìŠ¤íŠ¸, CI/CD

### Task 1.6: ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ

#### SubTask 1.6.1: í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì—”ì§„
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/multimodal/text_processor.py
from agno.io import TextProcessor
from typing import Dict, List, Any
import tiktoken

class MultiModalTextProcessor:
    def __init__(self):
        self.processor = TextProcessor()
        self.tokenizers = self.load_tokenizers()
        self.preprocessors = self.load_preprocessors()
        
    async def process_text(
        self, 
        text: str, 
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        
        # 1. ì „ì²˜ë¦¬
        cleaned_text = await self.preprocess(text, options)
        
        # 2. í† í¬ë‚˜ì´ì§•
        tokens = await self.tokenize(cleaned_text, options.get('model'))
        
        # 3. ì²­í‚¹ (ê¸´ í…ìŠ¤íŠ¸ ë¶„í• )
        chunks = await self.chunk_text(
            cleaned_text, 
            tokens,
            options.get('max_tokens', 4096)
        )
        
        # 4. ì„ë² ë”© (ì„ íƒì )
        embeddings = None
        if options.get('generate_embeddings'):
            embeddings = await self.generate_embeddings(chunks)
        
        return {
            'original': text,
            'processed': cleaned_text,
            'tokens': tokens,
            'token_count': len(tokens),
            'chunks': chunks,
            'embeddings': embeddings
        }
    
    async def preprocess(
        self, 
        text: str, 
        options: Dict[str, Any]
    ) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        processed = text
        
        # ì •ê·œí™”
        if options.get('normalize'):
            processed = self.normalize_text(processed)
        
        # ë¯¼ê°ì •ë³´ ë§ˆìŠ¤í‚¹
        if options.get('mask_pii'):
            processed = await self.mask_sensitive_info(processed)
        
        # ì–¸ì–´ ê°ì§€ ë° ë²ˆì—­
        if options.get('translate'):
            language = await self.detect_language(processed)
            if language != options.get('target_language', 'en'):
                processed = await self.translate_text(
                    processed, 
                    language, 
                    options.get('target_language', 'en')
                )
        
        return processed
    
    async def chunk_text(
        self, 
        text: str, 
        tokens: List[int], 
        max_tokens: int
    ) -> List[str]:
        """ìŠ¤ë§ˆíŠ¸ í…ìŠ¤íŠ¸ ì²­í‚¹"""
        if len(tokens) <= max_tokens:
            return [text]
        
        chunks = []
        
        # ë¬¸ì¥ ê²½ê³„ ê¸°ë°˜ ì²­í‚¹
        sentences = self.split_sentences(text)
        current_chunk = []
        current_tokens = 0
        
        for sentence in sentences:
            sentence_tokens = self.count_tokens(sentence)
            
            if current_tokens + sentence_tokens > max_tokens:
                if current_chunk:
                    chunks.append(' '.join(current_chunk))
                current_chunk = [sentence]
                current_tokens = sentence_tokens
            else:
                current_chunk.append(sentence)
                current_tokens += sentence_tokens
        
        if current_chunk:
            chunks.append(' '.join(current_chunk))
        
        return chunks
```

#### SubTask 1.6.2: ì´ë¯¸ì§€ ì²˜ë¦¬ ì—”ì§„
**ë‹´ë‹¹ì**: ML ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/multimodal/image-processor.ts
import { ImageProcessor } from 'agno';
import sharp from 'sharp';
import * as tf from '@tensorflow/tfjs-node';

interface ImageProcessingOptions {
  resize?: { width: number; height: number };
  format?: 'jpeg' | 'png' | 'webp';
  quality?: number;
  extractText?: boolean;
  generateCaption?: boolean;
  detectObjects?: boolean;
}

class MultiModalImageProcessor {
  private processor: ImageProcessor;
  private ocrModel: any;
  private captionModel: any;
  private objectDetectionModel: any;
  
  constructor() {
    this.processor = new ImageProcessor();
    this.loadModels();
  }
  
  private async loadModels(): Promise<void> {
    // OCR ëª¨ë¸ ë¡œë“œ
    if (process.env.ENABLE_OCR === 'true') {
      this.ocrModel = await this.loadOCRModel();
    }
    
    // ìº¡ì…˜ ìƒì„± ëª¨ë¸ ë¡œë“œ
    if (process.env.ENABLE_CAPTION === 'true') {
      this.captionModel = await this.loadCaptionModel();
    }
    
    // ê°ì²´ ê²€ì¶œ ëª¨ë¸ ë¡œë“œ
    if (process.env.ENABLE_OBJECT_DETECTION === 'true') {
      this.objectDetectionModel = await tf.loadGraphModel(
        'https://tfhub.dev/tensorflow/tfjs-model/ssd_mobilenet_v2/1/default/1'
      );
    }
  }
  
  async processImage(
    imageBuffer: Buffer,
    options: ImageProcessingOptions
  ): Promise<any> {
    const results: any = {
      metadata: await this.extractMetadata(imageBuffer),
      processed: null
    };
    
    // ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•
    let processedBuffer = imageBuffer;
    if (options.resize) {
      processedBuffer = await sharp(imageBuffer)
        .resize(options.resize.width, options.resize.height)
        .toBuffer();
    }
    
    // í¬ë§· ë³€í™˜
    if (options.format) {
      processedBuffer = await sharp(processedBuffer)
        .toFormat(options.format, { quality: options.quality || 85 })
        .toBuffer();
    }
    
    results.processed = processedBuffer;
    
    // OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
    if (options.extractText && this.ocrModel) {
      results.extractedText = await this.extractText(processedBuffer);
    }
    
    // ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±
    if (options.generateCaption && this.captionModel) {
      results.caption = await this.generateCaption(processedBuffer);
    }
    
    // ê°ì²´ ê²€ì¶œ
    if (options.detectObjects && this.objectDetectionModel) {
      results.detectedObjects = await this.detectObjects(processedBuffer);
    }
    
    return results;
  }
  
  private async extractText(imageBuffer: Buffer): Promise<string> {
    // Tesseract.js ë˜ëŠ” ë‹¤ë¥¸ OCR ì—”ì§„ ì‚¬ìš©
    const Tesseract = require('tesseract.js');
    
    const { data: { text } } = await Tesseract.recognize(
      imageBuffer,
      'eng',
      {
        logger: m => console.log(m)
      }
    );
    
    return text;
  }
  
  private async generateCaption(imageBuffer: Buffer): Promise<string> {
    // ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
    const imageTensor = await this.imageToTensor(imageBuffer);
    
    // ìº¡ì…˜ ëª¨ë¸ ì‹¤í–‰
    const caption = await this.captionModel.generate(imageTensor);
    
    return caption;
  }
}
```

#### SubTask 1.6.3: ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ì²˜ë¦¬ ì—”ì§„
**ë‹´ë‹¹ì**: ë©€í‹°ë¯¸ë””ì–´ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 20ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/multimodal/audio_video_processor.py
import ffmpeg
import whisper
from typing import Dict, Any, Optional
import numpy as np

class AudioVideoProcessor:
    def __init__(self):
        self.whisper_model = whisper.load_model("base")
        self.ffmpeg_path = self.verify_ffmpeg()
        
    async def process_audio(
        self, 
        audio_path: str, 
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì˜¤ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        
        results = {
            'duration': None,
            'format': None,
            'transcript': None,
            'summary': None
        }
        
        # ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = await self.extract_audio_metadata(audio_path)
        results['duration'] = metadata['duration']
        results['format'] = metadata['format']
        
        # ìŒì„± ì¸ì‹ (STT)
        if options.get('transcribe', True):
            transcript = await self.transcribe_audio(audio_path)
            results['transcript'] = transcript
            
            # ìš”ì•½ ìƒì„±
            if options.get('summarize') and transcript:
                results['summary'] = await self.summarize_transcript(
                    transcript
                )
        
        # ì˜¤ë””ì˜¤ ë¶„ì„
        if options.get('analyze'):
            results['analysis'] = await self.analyze_audio(audio_path)
        
        return results
    
    async def transcribe_audio(self, audio_path: str) -> Dict[str, Any]:
        """Whisperë¥¼ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹"""
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = whisper.load_audio(audio_path)
        audio = whisper.pad_or_trim(audio)
        
        # ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒì„±
        mel = whisper.log_mel_spectrogram(audio).to(
            self.whisper_model.device
        )
        
        # ì–¸ì–´ ê°ì§€
        _, probs = self.whisper_model.detect_language(mel)
        detected_language = max(probs, key=probs.get)
        
        # ì „ì‚¬
        options = whisper.DecodingOptions(
            language=detected_language,
            fp16=False
        )
        result = whisper.decode(self.whisper_model, mel, options)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ì „ì‚¬
        full_result = self.whisper_model.transcribe(
            audio_path,
            language=detected_language,
            task='transcribe',
            verbose=False
        )
        
        return {
            'text': full_result['text'],
            'segments': full_result['segments'],
            'language': detected_language
        }
    
    async def process_video(
        self, 
        video_path: str, 
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        
        results = {
            'metadata': await self.extract_video_metadata(video_path),
            'frames': None,
            'audio_track': None,
            'scenes': None
        }
        
        # í‚¤ í”„ë ˆì„ ì¶”ì¶œ
        if options.get('extract_frames'):
            results['frames'] = await self.extract_key_frames(
                video_path,
                options.get('frame_count', 10)
            )
        
        # ì˜¤ë””ì˜¤ íŠ¸ë™ ì¶”ì¶œ ë° ì²˜ë¦¬
        if options.get('process_audio'):
            audio_path = await self.extract_audio_track(video_path)
            results['audio_track'] = await self.process_audio(
                audio_path,
                options.get('audio_options', {})
            )
        
        # ì”¬ ê°ì§€
        if options.get('detect_scenes'):
            results['scenes'] = await self.detect_scenes(video_path)
        
        return results
    
    async def extract_key_frames(
        self, 
        video_path: str, 
        frame_count: int
    ) -> List[np.ndarray]:
        """ë¹„ë””ì˜¤ì—ì„œ í‚¤ í”„ë ˆì„ ì¶”ì¶œ"""
        
        # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        probe = ffmpeg.probe(video_path)
        video_info = next(
            s for s in probe['streams'] 
            if s['codec_type'] == 'video'
        )
        
        duration = float(probe['format']['duration'])
        
        # ê· ë“± ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ ì¶”ì¶œ
        frames = []
        for i in range(frame_count):
            time = (duration / frame_count) * i
            
            out, _ = (
                ffmpeg
                .input(video_path, ss=time)
                .output('pipe:', vframes=1, format='rawvideo', pix_fmt='rgb24')
                .run(capture_stdout=True, quiet=True)
            )
            
            frame = np.frombuffer(out, np.uint8).reshape([
                int(video_info['height']),
                int(video_info['width']),
                3
            ])
            
            frames.append(frame)
        
        return frames
```

#### SubTask 1.6.4: í†µí•© ë©€í‹°ëª¨ë‹¬ API
**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/multimodal/unified-api.ts
interface MultiModalInput {
  type: 'text' | 'image' | 'audio' | 'video' | 'mixed';
  data: any;
  metadata?: any;
  options?: any;
}

interface MultiModalOutput {
  processed: any;
  insights: any[];
  recommendations?: any[];
  confidence: number;
}

class UnifiedMultiModalAPI {
  private textProcessor: MultiModalTextProcessor;
  private imageProcessor: MultiModalImageProcessor;
  private audioVideoProcessor: AudioVideoProcessor;
  
  constructor() {
    this.textProcessor = new MultiModalTextProcessor();
    this.imageProcessor = new MultiModalImageProcessor();
    this.audioVideoProcessor = new AudioVideoProcessor();
  }
  
  async process(input: MultiModalInput): Promise<MultiModalOutput> {
    switch (input.type) {
      case 'text':
        return await this.processText(input);
      case 'image':
        return await this.processImage(input);
      case 'audio':
        return await this.processAudio(input);
      case 'video':
        return await this.processVideo(input);
      case 'mixed':
        return await this.processMixed(input);
      default:
        throw new Error(`Unsupported input type: ${input.type}`);
    }
  }
  
  private async processMixed(
    input: MultiModalInput
  ): Promise<MultiModalOutput> {
    // ë³µí•© ëª¨ë‹¬ ì²˜ë¦¬
    const results = await Promise.all(
      input.data.map(async (item: any) => {
        return await this.process({
          type: item.type,
          data: item.data,
          options: item.options
        });
      })
    );
    
    // ê²°ê³¼ í†µí•©
    const insights = this.combineInsights(results);
    const recommendations = this.generateRecommendations(insights);
    
    return {
      processed: results,
      insights,
      recommendations,
      confidence: this.calculateConfidence(results)
    };
  }
  
  private combineInsights(results: MultiModalOutput[]): any[] {
    // ê° ëª¨ë‹¬ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ í†µí•©
    const insights = [];
    
    for (const result of results) {
      insights.push(...result.insights);
    }
    
    // ì¤‘ë³µ ì œê±° ë° ìš°ì„ ìˆœìœ„ ì •ë ¬
    return this.deduplicateAndPrioritize(insights);
  }
}
```

---

### Task 1.7: LLM ëª¨ë¸ í†µí•© ë ˆì´ì–´

#### SubTask 1.7.1: ëª¨ë¸ í”„ë¡œë°”ì´ë” ì¶”ìƒí™”
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/llm/model_provider_abstract.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional, AsyncIterator
from dataclasses import dataclass

@dataclass
class ModelConfig:
    name: str
    provider: str
    max_tokens: int
    temperature: float
    top_p: float
    frequency_penalty: float
    presence_penalty: float
    stop_sequences: List[str]

@dataclass
class ModelResponse:
    text: str
    tokens_used: int
    finish_reason: str
    metadata: Dict[str, Any]

class ModelProvider(ABC):
    """ëª¨ë“  LLM í”„ë¡œë°”ì´ë”ì˜ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config: ModelConfig):
        self.config = config
        self.client = None
        
    @abstractmethod
    async def initialize(self) -> None:
        """í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”"""
        pass
    
    @abstractmethod
    async def generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> ModelResponse:
        """í…ìŠ¤íŠ¸ ìƒì„±"""
        pass
    
    @abstractmethod
    async def stream_generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> AsyncIterator[str]:
        """ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ìƒì„±"""
        pass
    
    @abstractmethod
    async def embed(
        self, 
        texts: List[str]
    ) -> List[List[float]]:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        pass
    
    @abstractmethod
    def estimate_tokens(self, text: str) -> int:
        """í† í° ìˆ˜ ì¶”ì •"""
        pass
    
    @abstractmethod
    def get_cost_estimate(
        self, 
        input_tokens: int, 
        output_tokens: int
    ) -> float:
        """ë¹„ìš© ì¶”ì •"""
        pass

class ModelProviderFactory:
    """ëª¨ë¸ í”„ë¡œë°”ì´ë” íŒ©í† ë¦¬"""
    
    _providers: Dict[str, type] = {}
    
    @classmethod
    def register(cls, name: str, provider_class: type) -> None:
        """í”„ë¡œë°”ì´ë” ë“±ë¡"""
        cls._providers[name] = provider_class
    
    @classmethod
    def create(
        cls, 
        provider_name: str, 
        config: ModelConfig
    ) -> ModelProvider:
        """í”„ë¡œë°”ì´ë” ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        if provider_name not in cls._providers:
            raise ValueError(f"Unknown provider: {provider_name}")
        
        provider_class = cls._providers[provider_name]
        return provider_class(config)
```

#### SubTask 1.7.2: 25+ ëª¨ë¸ í”„ë¡œë°”ì´ë” êµ¬í˜„
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 24ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/llm/providers/openai_provider.py
import openai
from typing import AsyncIterator

class OpenAIProvider(ModelProvider):
    """OpenAI ëª¨ë¸ í”„ë¡œë°”ì´ë”"""
    
    async def initialize(self) -> None:
        self.client = openai.AsyncOpenAI(
            api_key=os.getenv("OPENAI_API_KEY")
        )
    
    async def generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> ModelResponse:
        options = options or {}
        
        response = await self.client.chat.completions.create(
            model=self.config.name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=options.get('max_tokens', self.config.max_tokens),
            temperature=options.get('temperature', self.config.temperature),
            top_p=options.get('top_p', self.config.top_p),
            frequency_penalty=options.get(
                'frequency_penalty', 
                self.config.frequency_penalty
            ),
            presence_penalty=options.get(
                'presence_penalty', 
                self.config.presence_penalty
            ),
            stop=options.get('stop', self.config.stop_sequences)
        )
        
        choice = response.choices[0]
        return ModelResponse(
            text=choice.message.content,
            tokens_used=response.usage.total_tokens,
            finish_reason=choice.finish_reason,
            metadata={
                'model': response.model,
                'created': response.created
            }
        )
    
    async def stream_generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> AsyncIterator[str]:
        options = options or {}
        
        stream = await self.client.chat.completions.create(
            model=self.config.name,
            messages=[{"role": "user", "content": prompt}],
            stream=True,
            **options
        )
        
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content

# backend/src/llm/providers/anthropic_provider.py
import anthropic

class AnthropicProvider(ModelProvider):
    """Anthropic Claude í”„ë¡œë°”ì´ë”"""
    
    async def initialize(self) -> None:
        self.client = anthropic.AsyncAnthropic(
            api_key=os.getenv("ANTHROPIC_API_KEY")
        )
    
    async def generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> ModelResponse:
        response = await self.client.messages.create(
            model=self.config.name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=self.config.max_tokens
        )
        
        return ModelResponse(
            text=response.content[0].text,
            tokens_used=response.usage.input_tokens + response.usage.output_tokens,
            finish_reason=response.stop_reason,
            metadata={'model': response.model}
        )

# backend/src/llm/providers/bedrock_provider.py
import boto3
import json

class BedrockProvider(ModelProvider):
    """AWS Bedrock í”„ë¡œë°”ì´ë”"""
    
    async def initialize(self) -> None:
        self.client = boto3.client(
            'bedrock-runtime',
            region_name=os.getenv('AWS_REGION')
        )
    
    async def generate(
        self, 
        prompt: str, 
        options: Optional[Dict[str, Any]] = None
    ) -> ModelResponse:
        # Bedrock API í˜¸ì¶œ
        body = json.dumps({
            "prompt": prompt,
            "max_tokens": self.config.max_tokens,
            "temperature": self.config.temperature,
            "top_p": self.config.top_p
        })
        
        response = self.client.invoke_model(
            modelId=self.config.name,
            body=body,
            accept='application/json',
            contentType='application/json'
        )
        
        result = json.loads(response['body'].read())
        
        return ModelResponse(
            text=result['completion'],
            tokens_used=result.get('token_count', 0),
            finish_reason=result.get('stop_reason', 'stop'),
            metadata={'model_id': self.config.name}
        )

# ì¶”ê°€ í”„ë¡œë°”ì´ë”ë“¤...
# - HuggingFaceProvider
# - CohereProvider
# - AI21Provider
# - GooglePaLMProvider
# - AlephAlphaProvider
# ... ì´ 25+ í”„ë¡œë°”ì´ë”
```

**í”„ë¡œë°”ì´ë” ë“±ë¡**:
```python
# backend/src/llm/providers/__init__.py

# ëª¨ë“  í”„ë¡œë°”ì´ë” ë“±ë¡
ModelProviderFactory.register('openai', OpenAIProvider)
ModelProviderFactory.register('anthropic', AnthropicProvider)
ModelProviderFactory.register('bedrock', BedrockProvider)
ModelProviderFactory.register('huggingface', HuggingFaceProvider)
ModelProviderFactory.register('cohere', CohereProvider)
ModelProviderFactory.register('ai21', AI21Provider)
ModelProviderFactory.register('google', GooglePaLMProvider)
# ... 25+ í”„ë¡œë°”ì´ë” ë“±ë¡
```

#### SubTask 1.7.3: ëª¨ë¸ ì„ íƒ ë° ë¼ìš°íŒ… ì—”ì§„
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/llm/model-router.ts
interface ModelCapabilities {
  contextLength: number;
  supportedLanguages: string[];
  specialties: string[];
  costPerToken: number;
  latency: 'low' | 'medium' | 'high';
  availability: number;  // 0-1
}

interface RoutingCriteria {
  taskType: string;
  requiredContext: number;
  targetLanguage?: string;
  maxCost?: number;
  maxLatency?: 'low' | 'medium' | 'high';
  requiredCapabilities?: string[];
}

class ModelRouter {
  private modelRegistry: Map<string, ModelCapabilities> = new Map();
  private performanceHistory: Map<string, any[]> = new Map();
  
  constructor() {
    this.initializeModelRegistry();
  }
  
  private initializeModelRegistry(): void {
    // ëª¨ë¸ ëŠ¥ë ¥ ë“±ë¡
    this.modelRegistry.set('gpt-4', {
      contextLength: 128000,
      supportedLanguages: ['all'],
      specialties: ['reasoning', 'coding', 'analysis'],
      costPerToken: 0.00003,
      latency: 'medium',
      availability: 0.99
    });
    
    this.modelRegistry.set('claude-3-opus', {
      contextLength: 200000,
      supportedLanguages: ['all'],
      specialties: ['long-context', 'analysis', 'creative'],
      costPerToken: 0.000015,
      latency: 'low',
      availability: 0.98
    });
    
    // ... 25+ ëª¨ë¸ ë“±ë¡
  }
  
  async selectModel(criteria: RoutingCriteria): Promise<string> {
    const candidates = this.filterCandidates(criteria);
    
    if (candidates.length === 0) {
      throw new Error('No suitable model found for criteria');
    }
    
    // ì ìˆ˜ ê³„ì‚°
    const scores = await this.scoreModels(candidates, criteria);
    
    // ìµœì  ëª¨ë¸ ì„ íƒ
    const bestModel = this.selectBestModel(scores);
    
    // ì„ íƒ ê¸°ë¡
    await this.recordSelection(bestModel, criteria);
    
    return bestModel;
  }
  
  private filterCandidates(criteria: RoutingCriteria): string[] {
    const candidates = [];
    
    for (const [model, capabilities] of this.modelRegistry) {
      // ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸
      if (capabilities.contextLength < criteria.requiredContext) {
        continue;
      }
      
      // ì–¸ì–´ ì§€ì› í™•ì¸
      if (criteria.targetLanguage && 
          !capabilities.supportedLanguages.includes('all') &&
          !capabilities.supportedLanguages.includes(criteria.targetLanguage)) {
        continue;
      }
      
      // ì§€ì—°ì‹œê°„ ìš”êµ¬ì‚¬í•­ í™•ì¸
      if (criteria.maxLatency) {
        const latencyOrder = ['low', 'medium', 'high'];
        if (latencyOrder.indexOf(capabilities.latency) > 
            latencyOrder.indexOf(criteria.maxLatency)) {
          continue;
        }
      }
      
      candidates.push(model);
    }
    
    return candidates;
  }
  
  private async scoreModels(
    candidates: string[], 
    criteria: RoutingCriteria
  ): Promise<Map<string, number>> {
    const scores = new Map<string, number>();
    
    for (const model of candidates) {
      const capabilities = this.modelRegistry.get(model)!;
      let score = 0;
      
      // ì „ë¬¸ì„± ì ìˆ˜
      const specialtyScore = this.calculateSpecialtyScore(
        capabilities.specialties,
        criteria.taskType
      );
      score += specialtyScore * 0.3;
      
      // ë¹„ìš© ì ìˆ˜
      if (criteria.maxCost) {
        const costScore = 1 - (capabilities.costPerToken / criteria.maxCost);
        score += Math.max(0, costScore) * 0.2;
      }
      
      // ì„±ëŠ¥ ì´ë ¥ ì ìˆ˜
      const performanceScore = await this.getPerformanceScore(model);
      score += performanceScore * 0.3;
      
      // ê°€ìš©ì„± ì ìˆ˜
      score += capabilities.availability * 0.2;
      
      scores.set(model, score);
    }
    
    return scores;
  }
}
```

#### SubTask 1.7.4: ëª¨ë¸ í´ë°± ë° ë¶€í•˜ ë¶„ì‚°
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/llm/fallback_manager.py
from typing import List, Dict, Any
import asyncio
from datetime import datetime, timedelta

class ModelFallbackManager:
    def __init__(self):
        self.health_checker = ModelHealthChecker()
        self.load_balancer = ModelLoadBalancer()
        self.fallback_chains = self.define_fallback_chains()
        
    def define_fallback_chains(self) -> Dict[str, List[str]]:
        """ëª¨ë¸ë³„ í´ë°± ì²´ì¸ ì •ì˜"""
        return {
            'gpt-4': ['gpt-4-turbo', 'claude-3-opus', 'gpt-3.5-turbo'],
            'claude-3-opus': ['claude-3-sonnet', 'gpt-4', 'claude-2.1'],
            'bedrock-claude': ['bedrock-titan', 'claude-3-opus', 'gpt-4'],
            # ... ëª¨ë“  ëª¨ë¸ì— ëŒ€í•œ í´ë°± ì²´ì¸
        }
    
    async def execute_with_fallback(
        self,
        primary_model: str,
        prompt: str,
        options: Dict[str, Any]
    ) -> ModelResponse:
        """í´ë°± ë¡œì§ì„ í¬í•¨í•œ ëª¨ë¸ ì‹¤í–‰"""
        
        # í´ë°± ì²´ì¸ ê°€ì ¸ì˜¤ê¸°
        fallback_chain = [primary_model] + self.fallback_chains.get(
            primary_model, 
            []
        )
        
        last_error = None
        
        for model in fallback_chain:
            try:
                # ëª¨ë¸ í—¬ìŠ¤ ì²´í¬
                if not await self.health_checker.is_healthy(model):
                    continue
                
                # ë¡œë“œ ë°¸ëŸ°ì‹± í™•ì¸
                if not await self.load_balancer.can_handle_request(model):
                    continue
                
                # ëª¨ë¸ ì‹¤í–‰
                provider = ModelProviderFactory.create(
                    model.split('-')[0],  # í”„ë¡œë°”ì´ë” ì¶”ì¶œ
                    ModelConfig(name=model, **options)
                )
                
                await provider.initialize()
                response = await provider.generate(prompt, options)
                
                # ì„±ê³µ ê¸°ë¡
                await self.record_success(model)
                
                return response
                
            except Exception as e:
                last_error = e
                await self.record_failure(model, e)
                
                # ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ì¸ì§€ í™•ì¸
                if not self.is_retryable_error(e):
                    raise
                
                continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨
        raise Exception(
            f"All models in fallback chain failed. Last error: {last_error}"
        )
    
    def is_retryable_error(self, error: Exception) -> bool:
        """ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ì¸ì§€ í™•ì¸"""
        retryable_errors = [
            'rate_limit',
            'timeout',
            'service_unavailable',
            'internal_server_error'
        ]
        
        error_message = str(error).lower()
        return any(err in error_message for err in retryable_errors)

class ModelLoadBalancer:
    def __init__(self):
        self.request_counts = defaultdict(int)
        self.rate_limits = self.load_rate_limits()
        
    async def can_handle_request(self, model: str) -> bool:
        """ëª¨ë¸ì´ ì¶”ê°€ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸"""
        
        current_count = self.request_counts[model]
        rate_limit = self.rate_limits.get(model, float('inf'))
        
        # í˜„ì¬ ë¶€í•˜ í™•ì¸
        if current_count >= rate_limit * 0.8:  # 80% ì„ê³„ê°’
            return False
        
        # ë¶„ì‚° ë¶€í•˜ í™•ì¸ (Redis ì‚¬ìš©)
        distributed_count = await self.get_distributed_count(model)
        if distributed_count >= rate_limit:
            return False
        
        return True
    
    async def get_distributed_count(self, model: str) -> int:
        """ë¶„ì‚° í™˜ê²½ì—ì„œì˜ ì „ì²´ ìš”ì²­ ìˆ˜ í™•ì¸"""
        # Redisë¥¼ ì‚¬ìš©í•œ ë¶„ì‚° ì¹´ìš´í„°
        key = f"model_request_count:{model}"
        count = await redis_client.get(key)
        return int(count) if count else 0
```

---

### Task 1.8: ë©”ëª¨ë¦¬ ë° ìƒíƒœ ê´€ë¦¬

#### SubTask 1.8.1: ê³„ì¸µì  ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/memory/hierarchical_memory.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List
import redis
import sqlite3
import json

class MemoryLayer(ABC):
    """ë©”ëª¨ë¦¬ ë ˆì´ì–´ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def get(self, key: str) -> Optional[Any]:
        pass
    
    @abstractmethod
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        pass
    
    @abstractmethod
    async def delete(self, key: str) -> None:
        pass
    
    @abstractmethod
    async def clear(self) -> None:
        pass

class WorkingMemory(MemoryLayer):
    """ë‹¨ê¸° ì‘ì—… ë©”ëª¨ë¦¬ (In-Memory)"""
    
    def __init__(self, max_size: int = 1000):
        self.memory: Dict[str, Any] = {}
        self.max_size = max_size
        self.access_count: Dict[str, int] = {}
        
    async def get(self, key: str) -> Optional[Any]:
        if key in self.memory:
            self.access_count[key] = self.access_count.get(key, 0) + 1
            return self.memory[key]
        return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        # LRU ì •ì±…ìœ¼ë¡œ ë©”ëª¨ë¦¬ ê´€ë¦¬
        if len(self.memory) >= self.max_size:
            await self.evict_lru()
        
        self.memory[key] = value
        self.access_count[key] = 1
        
        if ttl:
            # TTL êµ¬í˜„
            asyncio.create_task(self.expire_key(key, ttl))
    
    async def evict_lru(self) -> None:
        """LRU ì •ì±…ìœ¼ë¡œ í•­ëª© ì œê±°"""
        if not self.access_count:
            return
        
        lru_key = min(self.access_count, key=self.access_count.get)
        del self.memory[lru_key]
        del self.access_count[lru_key]

class ShortTermMemory(MemoryLayer):
    """ë‹¨ê¸° ë©”ëª¨ë¦¬ (Redis)"""
    
    def __init__(self):
        self.redis_client = redis.Redis(
            host=os.getenv('REDIS_HOST'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            decode_responses=True
        )
        
    async def get(self, key: str) -> Optional[Any]:
        value = self.redis_client.get(key)
        if value:
            return json.loads(value)
        return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        serialized = json.dumps(value)
        if ttl:
            self.redis_client.setex(key, ttl, serialized)
        else:
            self.redis_client.set(key, serialized)

class LongTermMemory(MemoryLayer):
    """ì¥ê¸° ë©”ëª¨ë¦¬ (SQLite/DynamoDB)"""
    
    def __init__(self, db_path: str = "memory.db"):
        self.db_path = db_path
        self.init_db()
        
    def init_db(self):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS memory (
                key TEXT PRIMARY KEY,
                value TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                access_count INTEGER DEFAULT 0
            )
        ''')
        conn.commit()
        conn.close()
    
    async def get(self, key: str) -> Optional[Any]:
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute(
            'SELECT value FROM memory WHERE key = ?',
            (key,)
        )
        result = cursor.fetchone()
        
        if result:
            # ì ‘ê·¼ íšŸìˆ˜ ì—…ë°ì´íŠ¸
            cursor.execute(
                'UPDATE memory SET access_count = access_count + 1 WHERE key = ?',
                (key,)
            )
            conn.commit()
            
            value = json.loads(result[0])
            conn.close()
            return value
        
        conn.close()
        return None

class HierarchicalMemorySystem:
    """ê³„ì¸µì  ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.working_memory = WorkingMemory()
        self.short_term_memory = ShortTermMemory()
        self.long_term_memory = LongTermMemory()
        
        # ë©”ëª¨ë¦¬ ì •ì±…
        self.promotion_threshold = 5  # ìŠ¹ê²© ì„ê³„ê°’
        self.demotion_threshold = 30  # ê°•ë“± ì„ê³„ê°’ (ì¼)
    
    async def remember(
        self, 
        key: str, 
        value: Any, 
        importance: str = 'normal'
    ) -> None:
        """ì¤‘ìš”ë„ì— ë”°ë¼ ì ì ˆí•œ ë©”ëª¨ë¦¬ ë ˆì´ì–´ì— ì €ì¥"""
        
        if importance == 'critical':
            # ëª¨ë“  ë ˆì´ì–´ì— ì €ì¥
            await self.working_memory.set(key, value)
            await self.short_term_memory.set(key, value, ttl=86400)  # 1ì¼
            await self.long_term_memory.set(key, value)
        elif importance == 'high':
            # ë‹¨ê¸° ë° ì¥ê¸° ë©”ëª¨ë¦¬ì— ì €ì¥
            await self.short_term_memory.set(key, value, ttl=3600)  # 1ì‹œê°„
            await self.long_term_memory.set(key, value)
        else:
            # ì‘ì—… ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥
            await self.working_memory.set(key, value)
    
    async def recall(self, key: str) -> Optional[Any]:
        """ê³„ì¸µì ìœ¼ë¡œ ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        
        # 1. ì‘ì—… ë©”ëª¨ë¦¬ í™•ì¸
        value = await self.working_memory.get(key)
        if value is not None:
            return value
        
        # 2. ë‹¨ê¸° ë©”ëª¨ë¦¬ í™•ì¸
        value = await self.short_term_memory.get(key)
        if value is not None:
            # ì‘ì—… ë©”ëª¨ë¦¬ë¡œ ìŠ¹ê²©
            await self.working_memory.set(key, value)
            return value
        
        # 3. ì¥ê¸° ë©”ëª¨ë¦¬ í™•ì¸
        value = await self.long_term_memory.get(key)
        if value is not None:
            # ë‹¨ê¸° ë©”ëª¨ë¦¬ë¡œ ìŠ¹ê²©
            await self.short_term_memory.set(key, value, ttl=3600)
            await self.working_memory.set(key, value)
            return value
        
        return None
```

#### SubTask 1.8.2: ì—ì´ì „íŠ¸ ìƒíƒœ ì§€ì†ì„± ê´€ë¦¬
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/memory/agent-state-manager.ts
interface AgentState {
  agentId: string;
  sessionId: string;
  context: Map<string, any>;
  memory: any;
  lastActivity: Date;
  checkpoints: Checkpoint[];
}

interface Checkpoint {
  id: string;
  timestamp: Date;
  state: any;
  metadata: any;
}

class AgentStateManager {
  private stateStore: StateStore;
  private compressionEngine: CompressionEngine;
  private encryptionService: EncryptionService;
  
  constructor() {
    this.stateStore = new DynamoDBStateStore();
    this.compressionEngine = new CompressionEngine();
    this.encryptionService = new EncryptionService();
  }
  
  async saveState(
    agentId: string,
    state: AgentState
  ): Promise<void> {
    // ìƒíƒœ ì§ë ¬í™”
    const serialized = this.serializeState(state);
    
    // ì••ì¶•
    const compressed = await this.compressionEngine.compress(serialized);
    
    // ì•”í˜¸í™” (ë¯¼ê°í•œ ë°ì´í„° ë³´í˜¸)
    const encrypted = await this.encryptionService.encrypt(compressed);
    
    // ì €ì¥
    await this.stateStore.save({
      agentId,
      sessionId: state.sessionId,
      data: encrypted,
      timestamp: new Date(),
      ttl: this.calculateTTL(state)
    });
    
    // ì²´í¬í¬ì¸íŠ¸ ìƒì„±
    if (this.shouldCreateCheckpoint(state)) {
      await this.createCheckpoint(agentId, state);
    }
  }
  
  async loadState(
    agentId: string,
    sessionId?: string
  ): Promise<AgentState | null> {
    // ìƒíƒœ ì¡°íšŒ
    const encryptedState = await this.stateStore.load(agentId, sessionId);
    if (!encryptedState) return null;
    
    // ë³µí˜¸í™”
    const compressed = await this.encryptionService.decrypt(
      encryptedState.data
    );
    
    // ì••ì¶• í•´ì œ
    const serialized = await this.compressionEngine.decompress(compressed);
    
    // ì—­ì§ë ¬í™”
    const state = this.deserializeState(serialized);
    
    // ìƒíƒœ ê²€ì¦
    if (!this.validateState(state)) {
      throw new Error('Invalid agent state');
    }
    
    return state;
  }
  
  private shouldCreateCheckpoint(state: AgentState): boolean {
    // ì²´í¬í¬ì¸íŠ¸ ìƒì„± ì¡°ê±´
    const lastCheckpoint = state.checkpoints[state.checkpoints.length - 1];
    if (!lastCheckpoint) return true;
    
    const timeSinceLastCheckpoint = 
      Date.now() - lastCheckpoint.timestamp.getTime();
    
    // 5ë¶„ë§ˆë‹¤ ë˜ëŠ” ì¤‘ìš” ë³€ê²½ì‚¬í•­ ì‹œ
    return timeSinceLastCheckpoint > 5 * 60 * 1000 ||
           this.hasSignificantChanges(state, lastCheckpoint.state);
  }
  
  async createCheckpoint(
    agentId: string,
    state: AgentState
  ): Promise<void> {
    const checkpoint: Checkpoint = {
      id: generateId(),
      timestamp: new Date(),
      state: this.cloneState(state),
      metadata: {
        memorySize: JSON.stringify(state.memory).length,
        contextKeys: Array.from(state.context.keys())
      }
    };
    
    state.checkpoints.push(checkpoint);
    
    // ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬
    if (state.checkpoints.length > 10) {
      state.checkpoints = this.pruneCheckpoints(state.checkpoints);
    }
  }
  
  private pruneCheckpoints(checkpoints: Checkpoint[]): Checkpoint[] {
    // ìµœê·¼ 5ê°œ + ì‹œê°„ë³„ ëŒ€í‘œ ì²´í¬í¬ì¸íŠ¸ ìœ ì§€
    const recent = checkpoints.slice(-5);
    const hourly = this.selectHourlyCheckpoints(checkpoints.slice(0, -5));
    
    return [...hourly, ...recent];
  }
}
```

#### SubTask 1.8.3: ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: AI ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/memory/context_manager.py
from typing import Dict, List, Any, Optional
import numpy as np
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ContextEntry:
    key: str
    value: Any
    timestamp: datetime
    relevance_score: float
    access_count: int
    source: str
    metadata: Dict[str, Any]

class ContextManager:
    def __init__(self, max_context_size: int = 10000):
        self.context: Dict[str, ContextEntry] = {}
        self.max_context_size = max_context_size
        self.relevance_calculator = RelevanceCalculator()
        self.context_compressor = ContextCompressor()
        
    async def add_context(
        self,
        key: str,
        value: Any,
        source: str = 'user',
        metadata: Optional[Dict[str, Any]] = None
    ) -> None:
        """ì»¨í…ìŠ¤íŠ¸ì— ì •ë³´ ì¶”ê°€"""
        
        # ì¤‘ë³µ í‚¤ ì²˜ë¦¬
        if key in self.context:
            await self.merge_context(key, value, metadata)
            return
        
        # ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ê´€ë¦¬
        if len(self.context) >= self.max_context_size:
            await self.compress_context()
        
        # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
        relevance_score = await self.relevance_calculator.calculate(
            key, value, self.context
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ì—”íŠ¸ë¦¬ ìƒì„±
        entry = ContextEntry(
            key=key,
            value=value,
            timestamp=datetime.utcnow(),
            relevance_score=relevance_score,
            access_count=0,
            source=source,
            metadata=metadata or {}
        )
        
        self.context[key] = entry
    
    async def get_relevant_context(
        self,
        query: str,
        max_items: int = 10
    ) -> List[ContextEntry]:
        """ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ì»¨í…ìŠ¤íŠ¸ í•­ëª© ë°˜í™˜"""
        
        # ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ í•­ëª©ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
        scores = []
        for key, entry in self.context.items():
            score = await self.relevance_calculator.calculate_query_relevance(
                query, entry
            )
            scores.append((score, entry))
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        scores.sort(key=lambda x: x[0], reverse=True)
        
        # ìƒìœ„ í•­ëª© ë°˜í™˜
        relevant_entries = [entry for _, entry in scores[:max_items]]
        
        # ì ‘ê·¼ íšŸìˆ˜ ì—…ë°ì´íŠ¸
        for entry in relevant_entries:
            entry.access_count += 1
        
        return relevant_entries
    
    async def compress_context(self) -> None:
        """ì»¨í…ìŠ¤íŠ¸ ì••ì¶•"""
        
        # 1. ë‚®ì€ ê´€ë ¨ì„± í•­ëª© ì œê±°
        relevance_threshold = np.percentile(
            [e.relevance_score for e in self.context.values()],
            25  # í•˜ìœ„ 25% ì œê±°
        )
        
        # 2. ì˜¤ë˜ëœ í•­ëª© ì œê±°
        current_time = datetime.utcnow()
        age_threshold = timedelta(hours=24)
        
        # 3. ì ‘ê·¼í•˜ì§€ ì•Šì€ í•­ëª© ì œê±°
        access_threshold = 2
        
        items_to_remove = []
        for key, entry in self.context.items():
            if (entry.relevance_score < relevance_threshold and
                entry.access_count < access_threshold and
                current_time - entry.timestamp > age_threshold):
                items_to_remove.append(key)
        
        # ì œê±°
        for key in items_to_remove:
            del self.context[key]
        
        # 4. ìœ ì‚¬í•œ í•­ëª© ë³‘í•©
        await self.merge_similar_entries()
    
    async def merge_similar_entries(self) -> None:
        """ìœ ì‚¬í•œ ì»¨í…ìŠ¤íŠ¸ í•­ëª© ë³‘í•©"""
        
        # ì„ë² ë”© ìƒì„±
        embeddings = {}
        for key, entry in self.context.items():
            embeddings[key] = await self.generate_embedding(entry.value)
        
        # í´ëŸ¬ìŠ¤í„°ë§
        clusters = self.cluster_embeddings(embeddings)
        
        # ê° í´ëŸ¬ìŠ¤í„° ë³‘í•©
        for cluster in clusters:
            if len(cluster) > 1:
                merged_entry = await self.merge_entries(
                    [self.context[key] for key in cluster]
                )
                
                # ì²« ë²ˆì§¸ í‚¤ë¡œ ë³‘í•©ëœ ì—”íŠ¸ë¦¬ ì €ì¥
                self.context[cluster[0]] = merged_entry
                
                # ë‚˜ë¨¸ì§€ ì œê±°
                for key in cluster[1:]:
                    del self.context[key]

class RelevanceCalculator:
    """ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°ê¸°"""
    
    def __init__(self):
        self.embedding_model = self.load_embedding_model()
        
    async def calculate(
        self,
        key: str,
        value: Any,
        existing_context: Dict[str, ContextEntry]
    ) -> float:
        """ìƒˆ í•­ëª©ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        
        # ê¸°ë³¸ ì ìˆ˜
        base_score = 0.5
        
        # ìµœê·¼ì„± ê°€ì¤‘ì¹˜
        recency_weight = 1.0  # ìƒˆ í•­ëª©ì€ ìµœëŒ€ ê°€ì¤‘ì¹˜
        
        # ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ì™€ì˜ ì—°ê´€ì„±
        if existing_context:
            similarities = await self.calculate_similarities(
                value, existing_context
            )
            coherence_score = np.mean(similarities) if similarities else 0
        else:
            coherence_score = 0.5
        
        # ìµœì¢… ì ìˆ˜
        relevance_score = (
            base_score * 0.3 +
            recency_weight * 0.3 +
            coherence_score * 0.4
        )
        
        return min(1.0, relevance_score)
```

#### SubTask 1.8.4: ë©”ëª¨ë¦¬ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 8ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/memory/garbage-collector.ts
interface GCPolicy {
  maxMemoryMB: number;
  maxAge: number;  // ì¼
  minRelevance: number;
  gcInterval: number;  // ì´ˆ
}

class MemoryGarbageCollector {
  private policy: GCPolicy;
  private isRunning: boolean = false;
  private gcTimer: NodeJS.Timer | null = null;
  
  constructor(policy: GCPolicy) {
    this.policy = policy;
  }
  
  start(): void {
    if (this.isRunning) return;
    
    this.isRunning = true;
    this.gcTimer = setInterval(
      () => this.runGarbageCollection(),
      this.policy.gcInterval * 1000
    );
    
    console.log('Memory garbage collector started');
  }
  
  stop(): void {
    if (this.gcTimer) {
      clearInterval(this.gcTimer);
      this.gcTimer = null;
    }
    this.isRunning = false;
    console.log('Memory garbage collector stopped');
  }
  
  private async runGarbageCollection(): Promise<void> {
    console.log('Starting garbage collection...');
    
    const startTime = Date.now();
    const stats = {
      itemsChecked: 0,
      itemsRemoved: 0,
      memoryFreed: 0
    };
    
    try {
      // 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
      const memoryUsage = await this.getMemoryUsage();
      if (memoryUsage < this.policy.maxMemoryMB * 0.8) {
        // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì„ê³„ê°’ ì´í•˜ë©´ ìŠ¤í‚µ
        return;
      }
      
      // 2. ê° ë©”ëª¨ë¦¬ ë ˆì´ì–´ ì •ë¦¬
      await this.cleanWorkingMemory(stats);
      await this.cleanShortTermMemory(stats);
      await this.cleanLongTermMemory(stats);
      
      // 3. ì••ì¶• ì‹¤í–‰
      await this.compactMemory();
      
      // 4. í†µê³„ ê¸°ë¡
      const duration = Date.now() - startTime;
      await this.recordGCStats({
        ...stats,
        duration,
        timestamp: new Date()
      });
      
      console.log(`GC completed: removed ${stats.itemsRemoved} items, ` +
                  `freed ${stats.memoryFreed}MB in ${duration}ms`);
      
    } catch (error) {
      console.error('Garbage collection failed:', error);
    }
  }
  
  private async cleanWorkingMemory(stats: any): Promise<void> {
    const workingMemory = MemoryManager.getWorkingMemory();
    const items = await workingMemory.getAllItems();
    
    for (const [key, item] of items) {
      stats.itemsChecked++;
      
      // ì œê±° ì¡°ê±´ í™•ì¸
      if (this.shouldRemove(item)) {
        const size = this.calculateItemSize(item);
        await workingMemory.delete(key);
        
        stats.itemsRemoved++;
        stats.memoryFreed += size;
      }
    }
  }
  
  private shouldRemove(item: any): boolean {
    // ë‚˜ì´ í™•ì¸
    const age = Date.now() - item.timestamp;
    if (age > this.policy.maxAge * 24 * 60 * 60 * 1000) {
      return true;
    }
    
    // ê´€ë ¨ì„± í™•ì¸
    if (item.relevance < this.policy.minRelevance) {
      return true;
    }
    
    // ì ‘ê·¼ ë¹ˆë„ í™•ì¸
    const accessRate = item.accessCount / (age / 1000 / 60);  // ë¶„ë‹¹ ì ‘ê·¼
    if (accessRate < 0.01) {  // ë¶„ë‹¹ 0.01íšŒ ë¯¸ë§Œ
      return true;
    }
    
    return false;
  }
  
  private async compactMemory(): Promise<void> {
    // ë©”ëª¨ë¦¬ ì¡°ê°í™” ì •ë¦¬
    if (global.gc) {
      global.gc();
    }
    
    // ìºì‹œ ì¬êµ¬ì„±
    await this.reorganizeCaches();
  }
}
```

---

### Task 1.9: AgentCore ëŸ°íƒ€ì„ êµ¬ì„±

#### SubTask 1.9.1: AWS Bedrock AgentCore í”„ë¡œë¹„ì €ë‹
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```yaml
# infrastructure/cloudformation/agentcore-runtime.yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: 'AWS Bedrock AgentCore Runtime Infrastructure'

Parameters:
  EnvironmentName:
    Type: String
    Default: production
    AllowedValues:
      - development
      - staging
      - production
  
  RuntimeInstanceType:
    Type: String
    Default: ml.g5.2xlarge
    Description: Instance type for AgentCore runtime

Resources:
  # AgentCore ëŸ°íƒ€ì„ ì—­í• 
  AgentCoreRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${EnvironmentName}-agentcore-runtime-role
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - bedrock.amazonaws.com
                - lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: AgentCorePolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - bedrock:*
                  - s3:GetObject
                  - s3:PutObject
                  - dynamodb:GetItem
                  - dynamodb:PutItem
                  - dynamodb:Query
                  - dynamodb:Scan
                Resource: '*'

  # AgentCore ëŸ°íƒ€ì„ ì„¤ì •
  AgentCoreRuntime:
    Type: AWS::Bedrock::AgentCoreRuntime
    Properties:
      RuntimeName: !Sub ${EnvironmentName}-t-developer-runtime
      RuntimeConfiguration:
        InstanceType: !Ref RuntimeInstanceType
        MaxConcurrentSessions: 1000
        SessionTimeout: 28800  # 8ì‹œê°„
        MemoryConfiguration:
          MaxMemoryPerAgent: 512  # MB
          TotalRuntimeMemory: 32768  # 32GB
        NetworkConfiguration:
          SubnetIds: !Ref PrivateSubnets
          SecurityGroupIds:
            - !Ref AgentCoreSecurityGroup
      RoleArn: !GetAtt AgentCoreRole.Arn
      Tags:
        - Key: Environment
          Value: !Ref EnvironmentName
        - Key: Application
          Value: T-Developer

  # ë³´ì•ˆ ê·¸ë£¹
  AgentCoreSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub ${EnvironmentName}-agentcore-sg
      GroupDescription: Security group for AgentCore runtime
      VpcId: !Ref VPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          SourceSecurityGroupId: !Ref ApplicationSecurityGroup
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0

  # Auto Scaling ì„¤ì •
  AgentCoreAutoScaling:
    Type: AWS::ApplicationAutoScaling::ScalableTarget
    Properties:
      MaxCapacity: 10
      MinCapacity: 2
      ResourceId: !Sub runtime/${AgentCoreRuntime}
      RoleARN: !GetAtt AgentCoreRole.Arn
      ScalableDimension: bedrock:runtime:InstanceCount
      ServiceNamespace: bedrock

  # ìŠ¤ì¼€ì¼ë§ ì •ì±…
  AgentCoreScalingPolicy:
    Type: AWS::ApplicationAutoScaling::ScalingPolicy
    Properties:
      PolicyName: !Sub ${EnvironmentName}-agentcore-scaling-policy
      PolicyType: TargetTrackingScaling
      ScalingTargetId: !Ref AgentCoreAutoScaling
      TargetTrackingScalingPolicyConfiguration:
        PredefinedMetricSpecification:
          PredefinedMetricType: BedrockRuntimeCPUUtilization
        TargetValue: 70.0
        ScaleInCooldown: 300
        ScaleOutCooldown: 60

Outputs:
  AgentCoreRuntimeId:
    Description: AgentCore Runtime ID
    Value: !Ref AgentCoreRuntime
    Export:
      Name: !Sub ${EnvironmentName}-agentcore-runtime-id
  
  AgentCoreEndpoint:
    Description: AgentCore Runtime Endpoint
    Value: !GetAtt AgentCoreRuntime.Endpoint
    Export:
      Name: !Sub ${EnvironmentName}-agentcore-endpoint
```

**Terraform ë²„ì „**:
```hcl
# infrastructure/terraform/agentcore-runtime.tf
resource "aws_bedrock_agent_core_runtime" "main" {
  name = "${var.environment}-t-developer-runtime"
  
  runtime_configuration {
    instance_type           = var.runtime_instance_type
    max_concurrent_sessions = 1000
    session_timeout_seconds = 28800  # 8ì‹œê°„
    
    memory_configuration {
      max_memory_per_agent_mb = 512
      total_runtime_memory_gb = 32
    }
    
    network_configuration {
      subnet_ids         = var.private_subnet_ids
      security_group_ids = [aws_security_group.agentcore.id]
    }
  }
  
  role_arn = aws_iam_role.agentcore.arn
  
  tags = {
    Environment = var.environment
    Application = "T-Developer"
  }
}
```

#### SubTask 1.9.2: ëŸ°íƒ€ì„ í™˜ê²½ ìµœì í™”
**ë‹´ë‹¹ì**: ì„±ëŠ¥ ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/runtime/agentcore_optimizer.py
import boto3
from typing import Dict, Any
import json

class AgentCoreOptimizer:
    def __init__(self):
        self.bedrock_client = boto3.client('bedrock-agent-runtime')
        self.cloudwatch = boto3.client('cloudwatch')
        self.optimization_rules = self.load_optimization_rules()
        
    async def optimize_runtime(
        self, 
        runtime_id: str
    ) -> Dict[str, Any]:
        """AgentCore ëŸ°íƒ€ì„ ìµœì í™”"""
        
        # í˜„ì¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        metrics = await self.collect_runtime_metrics(runtime_id)
        
        # ìµœì í™” í•„ìš” ì—¬ë¶€ íŒë‹¨
        optimizations_needed = self.analyze_metrics(metrics)
        
        if not optimizations_needed:
            return {"status": "optimal", "metrics": metrics}
        
        # ìµœì í™” ì‹¤í–‰
        optimization_results = []
        
        for optimization in optimizations_needed:
            result = await self.apply_optimization(
                runtime_id, 
                optimization
            )
            optimization_results.append(result)
        
        return {
            "status": "optimized",
            "optimizations": optimization_results,
            "metrics": metrics
        }
    
    async def collect_runtime_metrics(
        self, 
        runtime_id: str
    ) -> Dict[str, Any]:
        """ëŸ°íƒ€ì„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        # CloudWatch ë©”íŠ¸ë¦­ ì¡°íšŒ
        response = self.cloudwatch.get_metric_statistics(
            Namespace='AWS/Bedrock',
            MetricName='RuntimeUtilization',
            Dimensions=[
                {
                    'Name': 'RuntimeId',
                    'Value': runtime_id
                }
            ],
            StartTime=datetime.utcnow() - timedelta(hours=1),
            EndTime=datetime.utcnow(),
            Period=300,
            Statistics=['Average', 'Maximum']
        )
        
        # ì¶”ê°€ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        metrics = {
            'cpu_utilization': self.get_metric_value(response, 'Average'),
            'memory_utilization': await self.get_memory_utilization(runtime_id),
            'session_count': await self.get_active_sessions(runtime_id),
            'average_latency': await self.get_average_latency(runtime_id),
            'error_rate': await self.get_error_rate(runtime_id)
        }
        
        return metrics
    
    def analyze_metrics(
        self, 
        metrics: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ë©”íŠ¸ë¦­ ë¶„ì„ ë° ìµœì í™” ì œì•ˆ"""
        
        optimizations = []
        
        # CPU ìµœì í™”
        if metrics['cpu_utilization'] > 80:
            optimizations.append({
                'type': 'scale_out',
                'reason': 'High CPU utilization',
                'target_value': 70
            })
        elif metrics['cpu_utilization'] < 20:
            optimizations.append({
                'type': 'scale_in',
                'reason': 'Low CPU utilization',
                'target_value': 40
            })
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        if metrics['memory_utilization'] > 85:
            optimizations.append({
                'type': 'increase_memory',
                'reason': 'High memory utilization',
                'recommended_increase': '25%'
            })
        
        # ë ˆì´í„´ì‹œ ìµœì í™”
        if metrics['average_latency'] > 500:  # 500ms
            optimizations.append({
                'type': 'optimize_caching',
                'reason': 'High latency detected',
                'target_latency': 200
            })
        
        return optimizations
    
    async def apply_optimization(
        self,
        runtime_id: str,
        optimization: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ìµœì í™” ì ìš©"""
        
        if optimization['type'] == 'scale_out':
            return await self.scale_runtime(runtime_id, 'out')
        elif optimization['type'] == 'scale_in':
            return await self.scale_runtime(runtime_id, 'in')
        elif optimization['type'] == 'increase_memory':
            return await self.adjust_memory(runtime_id, optimization)
        elif optimization['type'] == 'optimize_caching':
            return await self.optimize_caching(runtime_id)
        
        return {"status": "unknown_optimization_type"}
```

#### SubTask 1.9.3: ëŸ°íƒ€ì„ ëª¨ë‹ˆí„°ë§ ì„¤ì •
**ë‹´ë‹¹ì**: DevOps ì—”ì§€ë‹ˆì–´  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```typescript
// backend/src/runtime/monitoring-setup.ts
interface MonitoringConfig {
  runtimeId: string;
  metrics: MetricConfig[];
  alarms: AlarmConfig[];
  dashboards: DashboardConfig[];
}

interface MetricConfig {
  name: string;
  namespace: string;
  dimensions: Record<string, string>;
  statistic: 'Average' | 'Sum' | 'Maximum' | 'Minimum';
  period: number;
}

class RuntimeMonitoringSetup {
  private cloudWatch: CloudWatch;
  private sns: SNS;
  
  constructor() {
    this.cloudWatch = new CloudWatch();
    this.sns = new SNS();
  }
  
  async setupMonitoring(config: MonitoringConfig): Promise<void> {
    // 1. ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ìƒì„±
    await this.createCustomMetrics(config.metrics);
    
    // 2. CloudWatch ì•ŒëŒ ì„¤ì •
    await this.createAlarms(config.alarms);
    
    // 3. ëŒ€ì‹œë³´ë“œ ìƒì„±
    await this.createDashboard(config.dashboards);
    
    // 4. ë¡œê·¸ ê·¸ë£¹ ì„¤ì •
    await this.setupLogging(config.runtimeId);
    
    // 5. X-Ray íŠ¸ë ˆì´ì‹± í™œì„±í™”
    await this.enableXRayTracing(config.runtimeId);
  }
  
  private async createCustomMetrics(
    metrics: MetricConfig[]
  ): Promise<void> {
    for (const metric of metrics) {
      const putMetricParams = {
        Namespace: metric.namespace,
        MetricData: [
          {
            MetricName: metric.name,
            Dimensions: Object.entries(metric.dimensions).map(
              ([name, value]) => ({ Name: name, Value: value })
            ),
            Timestamp: new Date(),
            Unit: 'None'
          }
        ]
      };
      
      await this.cloudWatch.putMetricData(putMetricParams).promise();
    }
  }
  
  private async createAlarms(alarms: AlarmConfig[]): Promise<void> {
    for (const alarm of alarms) {
      const alarmParams = {
        AlarmName: alarm.name,
        ComparisonOperator: alarm.comparisonOperator,
        EvaluationPeriods: alarm.evaluationPeriods,
        MetricName: alarm.metricName,
        Namespace: alarm.namespace,
        Period: alarm.period,
        Statistic: alarm.statistic,
        Threshold: alarm.threshold,
        ActionsEnabled: true,
        AlarmActions: [alarm.snsTopicArn],
        AlarmDescription: alarm.description,
        Dimensions: alarm.dimensions
      };
      
      await this.cloudWatch.putMetricAlarm(alarmParams).promise();
    }
  }
  
  private async createDashboard(
    dashboards: DashboardConfig[]
  ): Promise<void> {
    for (const dashboard of dashboards) {
      const widgets = this.createDashboardWidgets(dashboard);
      
      const dashboardBody = {
        widgets: widgets
      };
      
      await this.cloudWatch.putDashboard({
        DashboardName: dashboard.name,
        DashboardBody: JSON.stringify(dashboardBody)
      }).promise();
    }
  }
  
  private createDashboardWidgets(
    dashboard: DashboardConfig
  ): any[] {
    return [
      // CPU ì‚¬ìš©ë¥  ìœ„ì ¯
      {
        type: 'metric',
        properties: {
          metrics: [
            ['AWS/Bedrock', 'CPUUtilization', 'RuntimeId', dashboard.runtimeId]
          ],
          period: 300,
          stat: 'Average',
          region: process.env.AWS_REGION,
          title: 'CPU Utilization'
        }
      },
      // ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ìœ„ì ¯
      {
        type: 'metric',
        properties: {
          metrics: [
            ['AWS/Bedrock', 'MemoryUtilization', 'RuntimeId', dashboard.runtimeId]
          ],
          period: 300,
          stat: 'Average',
          region: process.env.AWS_REGION,
          title: 'Memory Utilization'
        }
      },
      // í™œì„± ì„¸ì…˜ ìˆ˜
      {
        type: 'metric',
        properties: {
          metrics: [
            ['AWS/Bedrock', 'ActiveSessions', 'RuntimeId', dashboard.runtimeId]
          ],
          period: 60,
          stat: 'Sum',
          region: process.env.AWS_REGION,
          title: 'Active Sessions'
        }
      },
      // ì—ëŸ¬ìœ¨
      {
        type: 'metric',
        properties: {
          metrics: [
            ['AWS/Bedrock', 'Errors', 'RuntimeId', dashboard.runtimeId],
            ['AWS/Bedrock', 'Invocations', 'RuntimeId', dashboard.runtimeId]
          ],
          period: 300,
          stat: 'Sum',
          region: process.env.AWS_REGION,
          title: 'Error Rate',
          yAxis: {
            left: {
              label: 'Count'
            }
          }
        }
      }
    ];
  }
}
```

#### SubTask 1.9.4: ê³ ê°€ìš©ì„± ë° ì¬í•´ë³µêµ¬ ì„¤ì •
**ë‹´ë‹¹ì**: ì¸í”„ë¼ ì•„í‚¤í…íŠ¸  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 16ì‹œê°„

**ì‘ì—… ë‚´ìš©**:
```python
# backend/src/runtime/high_availability.py
from typing import Dict, List, Any
import asyncio

class HighAvailabilityManager:
    def __init__(self):
        self.primary_region = os.getenv('AWS_PRIMARY_REGION', 'us-east-1')
        self.dr_regions = os.getenv('AWS_DR_REGIONS', 'us-west-2,eu-west-1').split(',')
        self.health_checker = HealthChecker()
        self.failover_manager = FailoverManager()
        
    async def setup_multi_region_deployment(self) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ë¦¬ì „ ë°°í¬ ì„¤ì •"""
        
        deployment_results = {
            'primary': None,
            'dr_regions': []
        }
        
        # 1. ê¸°ë³¸ ë¦¬ì „ ì„¤ì •
        primary_result = await self.deploy_runtime(
            self.primary_region,
            is_primary=True
        )
        deployment_results['primary'] = primary_result
        
        # 2. DR ë¦¬ì „ ì„¤ì •
        for region in self.dr_regions:
            dr_result = await self.deploy_runtime(
                region,
                is_primary=False
            )
            deployment_results['dr_regions'].append({
                'region': region,
                'result': dr_result
            })
        
        # 3. í¬ë¡œìŠ¤ ë¦¬ì „ ë³µì œ ì„¤ì •
        await self.setup_cross_region_replication()
        
        # 4. ê¸€ë¡œë²Œ ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì •
        await self.setup_global_load_balancer()
        
        return deployment_results
    
    async def deploy_runtime(
        self,
        region: str,
        is_primary: bool
    ) -> Dict[str, Any]:
        """ë¦¬ì „ë³„ ëŸ°íƒ€ì„ ë°°í¬"""
        
        bedrock_client = boto3.client(
            'bedrock-agent-runtime',
            region_name=region
        )
        
        # CloudFormation ìŠ¤íƒ ë°°í¬
        cf_client = boto3.client('cloudformation', region_name=region)
        
        stack_name = f"agentcore-runtime-{region}"
        template_body = self.get_runtime_template(is_primary)
        
        try:
            response = cf_client.create_stack(
                StackName=stack_name,
                TemplateBody=template_body,
                Parameters=[
                    {
                        'ParameterKey': 'IsPrimaryRegion',
                        'ParameterValue': str(is_primary)
                    },
                    {
                        'ParameterKey': 'ReplicationRegions',
                        'ParameterValue': ','.join(self.dr_regions)
                    }
                ],
                Capabilities=['CAPABILITY_IAM']
            )
            
            # ìŠ¤íƒ ìƒì„± ëŒ€ê¸°
            waiter = cf_client.get_waiter('stack_create_complete')
            waiter.wait(StackName=stack_name)
            
            # ëŸ°íƒ€ì„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            stack_outputs = self.get_stack_outputs(cf_client, stack_name)
            
            return {
                'status': 'success',
                'region': region,
                'runtime_id': stack_outputs['RuntimeId'],
                'endpoint': stack_outputs['RuntimeEndpoint']
            }
            
        except Exception as e:
            return {
                'status': 'failed',
                'region': region,
                'error': str(e)
            }
    
    async def setup_cross_region_replication(self) -> None:
        """í¬ë¡œìŠ¤ ë¦¬ì „ ë°ì´í„° ë³µì œ ì„¤ì •"""
        
        # DynamoDB ê¸€ë¡œë²Œ í…Œì´ë¸” ì„¤ì •
        dynamodb = boto3.client('dynamodb')
        
        tables = [
            'agent-states',
            'agent-sessions',
            'agent-checkpoints'
        ]
        
        for table_name in tables:
            try:
                response = dynamodb.update_table(
                    TableName=table_name,
                    ReplicaUpdates=[
                        {
                            'Create': {
                                'RegionName': region,
                                'GlobalSecondaryIndexes': []
                            }
                        } for region in self.dr_regions
                    ]
                )
            except Exception as e:
                print(f"Failed to setup replication for {table_name}: {e}")
    
    async def implement_health_checks(self) -> None:
        """í—¬ìŠ¤ì²´í¬ êµ¬í˜„"""
        
        while True:
            try:
                # ëª¨ë“  ë¦¬ì „ í—¬ìŠ¤ì²´í¬
                health_status = {}
                
                # Primary ë¦¬ì „ ì²´í¬
                primary_health = await self.health_checker.check_runtime(
                    self.primary_region
                )
                health_status['primary'] = primary_health
                
                # DR ë¦¬ì „ ì²´í¬
                for region in self.dr_regions:
                    dr_health = await self.health_checker.check_runtime(region)
                    health_status[region] = dr_health
                
                # ì¥ì•  ê°ì§€ ì‹œ í˜ì¼ì˜¤ë²„
                if not primary_health['healthy']:
                    await self.initiate_failover()
                
                # ë©”íŠ¸ë¦­ ê¸°ë¡
                await self.record_health_metrics(health_status)
                
            except Exception as e:
                print(f"Health check error: {e}")
            
            await asyncio.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬
    
    async def initiate_failover(self) -> None:
        """í˜ì¼ì˜¤ë²„ ì‹¤í–‰"""
        
        print("Initiating failover process...")
        
        # 1. ê°€ì¥ ê±´ê°•í•œ DR ë¦¬ì „ ì„ íƒ
        healthiest_region = await self.select_healthiest_dr_region()
        
        if not healthiest_region:
            raise Exception("No healthy DR region available")
        
        # 2. DNS ì—…ë°ì´íŠ¸
        await self.update_dns_routing(healthiest_region)
        
        # 3. ìƒˆ Primary ìŠ¹ê²©
        await self.promote_to_primary(healthiest_region)
        
        # 4. ì•Œë¦¼ ë°œì†¡
        await self.send_failover_notification(healthiest_region)
        
        print(f"Failover completed to {healthiest_region}")
```

---

ê³„ì†í•´ì„œ ë‚˜ë¨¸ì§€ Tasksë¥¼ ì‘ì„±í• ê¹Œìš”? ë‹¤ìŒì€:

- **Task 1.10**: ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ
- **Task 1.11**: ë³´ì•ˆ ë° ì¸ì¦ ë ˆì´ì–´
- **Task 1.12-1.14**: ë°ì´í„°ë² ì´ìŠ¤, ìºì‹±, ë©”ì‹œì§•
- **Task 1.15-1.17**: ë¡œê¹…, ì—ëŸ¬ì²˜ë¦¬, ì„¤ì •ê´€ë¦¬
- **Task 1.18-1.20**: ì„±ëŠ¥í…ŒìŠ¤íŠ¸, í†µí•©í…ŒìŠ¤íŠ¸, CI/CD

í”„ë¡œì íŠ¸ ì§€ì‹ì„ í™•ì¸í•˜ì—¬ Task 1.10ë¶€í„° ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.í”„ë¡œì íŠ¸ ì§€ì‹ì„ í™•ì¸í•œ ê²°ê³¼, Phase 1ì˜ ì „ì²´ Task êµ¬ì¡°ë¥¼ íŒŒì•…í–ˆìŠµë‹ˆë‹¤. ì´ì œ Task 1.10 (ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ)ì˜ SubTask 1.10.1ë¶€í„° ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.

# Phase 1: ì½”ì–´ ì¸í”„ë¼ êµ¬ì¶• - SubTask Documentation (Task 1.10ë¶€í„°)

## Task 1.10: ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ

### SubTask 1.10.1: ì¥ê¸° ì‹¤í–‰ ì„¸ì…˜ ì•„í‚¤í…ì²˜ ì„¤ê³„
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: Bedrock AgentCoreì˜ 8ì‹œê°„ ì„¸ì…˜ ì§€ì›ì„ ìœ„í•œ ì•ˆì •ì ì¸ ì„¸ì…˜ ê´€ë¦¬ ì•„í‚¤í…ì²˜ ì„¤ê³„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/session/architecture/session-manager.ts
import { DynamoDBClient } from '@aws-sdk/client-dynamodb';
import { DynamoDBDocumentClient } from '@aws-sdk/lib-dynamodb';
import { Redis } from 'ioredis';
import { EventEmitter } from 'events';

export interface SessionConfig {
  maxDuration: number; // ìµœëŒ€ 8ì‹œê°„ (28800ì´ˆ)
  heartbeatInterval: number; // 30ì´ˆ
  persistenceInterval: number; // 5ë¶„
  maxConcurrentSessions: number;
  sessionTimeout: number;
}

export interface Session {
  sessionId: string;
  userId: string;
  projectId: string;
  agentInstances: Map<string, AgentInstance>;
  startTime: Date;
  lastActivity: Date;
  state: SessionState;
  metadata: SessionMetadata;
  checkpoints: Checkpoint[];
}

export interface SessionState {
  status: 'active' | 'paused' | 'resuming' | 'terminating' | 'completed';
  currentPhase: string;
  progress: number;
  context: Record<string, any>;
  memorySnapshot: MemorySnapshot;
}

export interface MemorySnapshot {
  workingMemory: Record<string, any>;
  longTermMemory: Record<string, any>;
  agentStates: Map<string, any>;
  timestamp: Date;
}

export class SessionManager extends EventEmitter {
  private dynamoClient: DynamoDBDocumentClient;
  private redis: Redis;
  private sessions: Map<string, Session>;
  private heartbeatTimers: Map<string, NodeJS.Timer>;
  
  constructor(
    private config: SessionConfig,
    dynamoClient: DynamoDBClient,
    redis: Redis
  ) {
    super();
    this.dynamoClient = DynamoDBDocumentClient.from(dynamoClient);
    this.redis = redis;
    this.sessions = new Map();
    this.heartbeatTimers = new Map();
    
    this.initializeSessionRecovery();
  }
  
  async createSession(params: CreateSessionParams): Promise<Session> {
    // ì„¸ì…˜ ìˆ˜ ì œí•œ í™•ì¸
    if (this.sessions.size >= this.config.maxConcurrentSessions) {
      throw new Error('Maximum concurrent sessions reached');
    }
    
    const session: Session = {
      sessionId: this.generateSessionId(),
      userId: params.userId,
      projectId: params.projectId,
      agentInstances: new Map(),
      startTime: new Date(),
      lastActivity: new Date(),
      state: {
        status: 'active',
        currentPhase: 'initialization',
        progress: 0,
        context: {},
        memorySnapshot: {
          workingMemory: {},
          longTermMemory: {},
          agentStates: new Map(),
          timestamp: new Date()
        }
      },
      metadata: {
        clientInfo: params.clientInfo,
        sessionType: params.sessionType,
        features: params.enabledFeatures
      },
      checkpoints: []
    };
    
    // DynamoDBì— ì„¸ì…˜ ì €ì¥
    await this.persistSession(session);
    
    // Redisì— í™œì„± ì„¸ì…˜ ìºì‹±
    await this.cacheSession(session);
    
    // ë©”ëª¨ë¦¬ì— ì €ì¥
    this.sessions.set(session.sessionId, session);
    
    // í•˜íŠ¸ë¹„íŠ¸ ì‹œì‘
    this.startHeartbeat(session.sessionId);
    
    // ìë™ ì²´í¬í¬ì¸íŠ¸ ì‹œì‘
    this.startAutoCheckpoint(session.sessionId);
    
    this.emit('session:created', session);
    
    return session;
  }
  
  private startHeartbeat(sessionId: string): void {
    const timer = setInterval(async () => {
      try {
        await this.updateHeartbeat(sessionId);
      } catch (error) {
        console.error(`Heartbeat failed for session ${sessionId}:`, error);
        await this.handleSessionFailure(sessionId);
      }
    }, this.config.heartbeatInterval * 1000);
    
    this.heartbeatTimers.set(sessionId, timer);
  }
  
  private async updateHeartbeat(sessionId: string): Promise<void> {
    const session = this.sessions.get(sessionId);
    if (!session) return;
    
    session.lastActivity = new Date();
    
    // Redis ì—…ë°ì´íŠ¸
    await this.redis.setex(
      `session:heartbeat:${sessionId}`,
      this.config.sessionTimeout,
      JSON.stringify({
        timestamp: session.lastActivity,
        status: session.state.status
      })
    );
    
    // ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ì²´í¬
    const duration = Date.now() - session.startTime.getTime();
    if (duration > this.config.maxDuration * 1000) {
      await this.gracefulTerminate(sessionId);
    }
  }
}
```

**ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨**:
```mermaid
graph TB
    Client[Client Application]
    
    subgraph "Session Layer"
        SM[Session Manager]
        SQ[Session Queue]
        SC[Session Cache]
    end
    
    subgraph "Persistence"
        DDB[(DynamoDB)]
        Redis[(Redis)]
        S3[(S3 Checkpoints)]
    end
    
    subgraph "Agent Runtime"
        AR[Agent Runtime]
        AM[Agent Memory]
        AS[Agent State]
    end
    
    Client --> SM
    SM --> SQ
    SM --> SC
    SC --> Redis
    SM --> DDB
    SM --> AR
    AR --> AM
    AR --> AS
    AS --> S3
```

### SubTask 1.10.2: ì„¸ì…˜ ìƒíƒœ ì§€ì†ì„± ë©”ì»¤ë‹ˆì¦˜
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì„¸ì…˜ ìƒíƒœë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ë³µêµ¬í•  ìˆ˜ ìˆëŠ” ì§€ì†ì„± ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/session/persistence/session-persistence.ts
import { S3Client, PutObjectCommand, GetObjectCommand } from '@aws-sdk/client-s3';
import { compress, decompress } from 'lz4js';
import crypto from 'crypto';

export class SessionPersistenceManager {
  private s3Client: S3Client;
  private checkpointBucket: string;
  
  constructor(
    s3Client: S3Client,
    checkpointBucket: string
  ) {
    this.s3Client = s3Client;
    this.checkpointBucket = checkpointBucket;
  }
  
  async createCheckpoint(
    session: Session,
    checkpointType: 'auto' | 'manual' | 'recovery'
  ): Promise<Checkpoint> {
    const checkpoint: Checkpoint = {
      id: this.generateCheckpointId(),
      sessionId: session.sessionId,
      timestamp: new Date(),
      type: checkpointType,
      state: await this.captureSessionState(session),
      metadata: {
        size: 0,
        compressed: true,
        encryption: 'AES-256-GCM'
      }
    };
    
    // ìƒíƒœ ì§ë ¬í™” ë° ì••ì¶•
    const serialized = JSON.stringify(checkpoint.state);
    const compressed = await this.compressData(serialized);
    
    // ì•”í˜¸í™”
    const encrypted = await this.encryptData(compressed);
    
    // S3ì— ì €ì¥
    const key = `checkpoints/${session.sessionId}/${checkpoint.id}.checkpoint`;
    await this.s3Client.send(new PutObjectCommand({
      Bucket: this.checkpointBucket,
      Key: key,
      Body: encrypted,
      Metadata: {
        sessionId: session.sessionId,
        checkpointId: checkpoint.id,
        timestamp: checkpoint.timestamp.toISOString(),
        type: checkpointType
      }
    }));
    
    checkpoint.metadata.size = encrypted.length;
    
    // DynamoDBì— ì²´í¬í¬ì¸íŠ¸ ë©”íƒ€ë°ì´í„° ì €ì¥
    await this.saveCheckpointMetadata(checkpoint);
    
    return checkpoint;
  }
  
  async restoreFromCheckpoint(
    checkpointId: string,
    sessionId: string
  ): Promise<SessionState> {
    // S3ì—ì„œ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    const key = `checkpoints/${sessionId}/${checkpointId}.checkpoint`;
    const response = await this.s3Client.send(new GetObjectCommand({
      Bucket: this.checkpointBucket,
      Key: key
    }));
    
    const encrypted = await response.Body.transformToByteArray();
    
    // ë³µí˜¸í™”
    const compressed = await this.decryptData(encrypted);
    
    // ì••ì¶• í•´ì œ
    const decompressed = await this.decompressData(compressed);
    
    // ì—­ì§ë ¬í™”
    const state = JSON.parse(decompressed);
    
    // ìƒíƒœ ê²€ì¦
    await this.validateSessionState(state);
    
    return state;
  }
  
  private async captureSessionState(session: Session): Promise<SessionState> {
    // ì—ì´ì „íŠ¸ ìƒíƒœ ìˆ˜ì§‘
    const agentStates = new Map();
    for (const [agentId, instance] of session.agentInstances) {
      agentStates.set(agentId, await instance.captureState());
    }
    
    // ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ· ìƒì„±
    const memorySnapshot: MemorySnapshot = {
      workingMemory: await this.captureWorkingMemory(session),
      longTermMemory: await this.captureLongTermMemory(session),
      agentStates: agentStates,
      timestamp: new Date()
    };
    
    return {
      status: session.state.status,
      currentPhase: session.state.currentPhase,
      progress: session.state.progress,
      context: { ...session.state.context },
      memorySnapshot: memorySnapshot
    };
  }
  
  async cleanupOldCheckpoints(
    sessionId: string,
    retentionDays: number = 7
  ): Promise<void> {
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays);
    
    // ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì¡°íšŒ
    const oldCheckpoints = await this.queryOldCheckpoints(
      sessionId,
      cutoffDate
    );
    
    // S3ì—ì„œ ì‚­ì œ
    for (const checkpoint of oldCheckpoints) {
      const key = `checkpoints/${sessionId}/${checkpoint.id}.checkpoint`;
      await this.s3Client.send(new DeleteObjectCommand({
        Bucket: this.checkpointBucket,
        Key: key
      }));
    }
    
    // ë©”íƒ€ë°ì´í„° ì‚­ì œ
    await this.deleteCheckpointMetadata(oldCheckpoints);
  }
}
```

### SubTask 1.10.3: ì„¸ì…˜ ë³µêµ¬ ë° ì¬ê°œ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: ì¤‘ë‹¨ëœ ì„¸ì…˜ì„ ì•ˆì „í•˜ê²Œ ë³µêµ¬í•˜ê³  ì¬ê°œí•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/session/recovery/session-recovery.ts
export class SessionRecoveryService {
  private sessionManager: SessionManager;
  private persistenceManager: SessionPersistenceManager;
  private recoveryQueue: PriorityQueue<RecoveryTask>;
  
  constructor(
    sessionManager: SessionManager,
    persistenceManager: SessionPersistenceManager
  ) {
    this.sessionManager = sessionManager;
    this.persistenceManager = persistenceManager;
    this.recoveryQueue = new PriorityQueue();
    
    this.startRecoveryWorker();
  }
  
  async recoverSession(
    sessionId: string,
    recoveryOptions?: RecoveryOptions
  ): Promise<Session> {
    try {
      // 1. ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
      const checkpoint = await this.findLatestValidCheckpoint(sessionId);
      if (!checkpoint) {
        throw new Error(`No valid checkpoint found for session ${sessionId}`);
      }
      
      // 2. ì„¸ì…˜ ìƒíƒœ ë³µì›
      const sessionState = await this.persistenceManager.restoreFromCheckpoint(
        checkpoint.id,
        sessionId
      );
      
      // 3. ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ì¬ìƒì„±
      const agentInstances = await this.recreateAgentInstances(
        sessionState.memorySnapshot.agentStates
      );
      
      // 4. ì„¸ì…˜ ì¬êµ¬ì„±
      const recoveredSession = await this.reconstructSession(
        sessionId,
        sessionState,
        agentInstances
      );
      
      // 5. ìƒíƒœ ê²€ì¦
      await this.validateRecoveredSession(recoveredSession);
      
      // 6. ì„¸ì…˜ ì¬ê°œ
      await this.resumeSession(recoveredSession);
      
      this.emit('session:recovered', {
        sessionId,
        checkpointId: checkpoint.id,
        recoveryTime: Date.now()
      });
      
      return recoveredSession;
      
    } catch (error) {
      this.emit('session:recovery:failed', {
        sessionId,
        error: error.message
      });
      throw error;
    }
  }
  
  private async recreateAgentInstances(
    agentStates: Map<string, any>
  ): Promise<Map<string, AgentInstance>> {
    const instances = new Map();
    
    for (const [agentId, state] of agentStates) {
      try {
        const instance = await this.recreateAgent(agentId, state);
        instances.set(agentId, instance);
      } catch (error) {
        console.error(`Failed to recreate agent ${agentId}:`, error);
        // ì—ì´ì „íŠ¸ ì¬ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìƒíƒœë¡œ ìƒì„±
        const fallbackInstance = await this.createFallbackAgent(agentId);
        instances.set(agentId, fallbackInstance);
      }
    }
    
    return instances;
  }
  
  private async resumeSession(session: Session): Promise<void> {
    // 1. ì„¸ì…˜ ìƒíƒœë¥¼ 'resuming'ìœ¼ë¡œ ë³€ê²½
    session.state.status = 'resuming';
    
    // 2. ì—ì´ì „íŠ¸ ì›Œë°ì—…
    await this.warmupAgents(session.agentInstances);
    
    // 3. ì»¨í…ìŠ¤íŠ¸ ë³µì›
    await this.restoreContext(session);
    
    // 4. ì§„í–‰ ìƒí™© ë™ê¸°í™”
    await this.syncProgress(session);
    
    // 5. ì„¸ì…˜ í™œì„±í™”
    session.state.status = 'active';
    session.lastActivity = new Date();
    
    // 6. í•˜íŠ¸ë¹„íŠ¸ ì¬ì‹œì‘
    this.sessionManager.startHeartbeat(session.sessionId);
  }
  
  async handleCrashRecovery(): Promise<void> {
    // ì‹œìŠ¤í…œ ì¬ì‹œì‘ ì‹œ í˜¸ì¶œë˜ëŠ” ë©”ì„œë“œ
    // ëª¨ë“  ë¯¸ì™„ë£Œ ì„¸ì…˜ ë³µêµ¬ ì‹œë„
    
    const incompleteSessions = await this.findIncompleteSessions();
    
    for (const sessionInfo of incompleteSessions) {
      const recoveryTask: RecoveryTask = {
        sessionId: sessionInfo.sessionId,
        priority: this.calculateRecoveryPriority(sessionInfo),
        attempts: 0,
        maxAttempts: 3,
        nextAttempt: new Date()
      };
      
      this.recoveryQueue.enqueue(recoveryTask);
    }
  }
  
  private startRecoveryWorker(): void {
    setInterval(async () => {
      if (this.recoveryQueue.isEmpty()) return;
      
      const task = this.recoveryQueue.dequeue();
      if (!task) return;
      
      try {
        await this.recoverSession(task.sessionId);
      } catch (error) {
        task.attempts++;
        
        if (task.attempts < task.maxAttempts) {
          // ì¬ì‹œë„ ìŠ¤ì¼€ì¤„ë§ (ì§€ìˆ˜ ë°±ì˜¤í”„)
          task.nextAttempt = new Date(
            Date.now() + Math.pow(2, task.attempts) * 60000
          );
          this.recoveryQueue.enqueue(task);
        } else {
          // ë³µêµ¬ ì‹¤íŒ¨ ì²˜ë¦¬
          await this.handleRecoveryFailure(task.sessionId);
        }
      }
    }, 10000); // 10ì´ˆë§ˆë‹¤ ì‹¤í–‰
  }
}
```

### SubTask 1.10.4: ì„¸ì…˜ ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„
**ë‹´ë‹¹ì**: í’€ìŠ¤íƒ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì„¸ì…˜ ìƒíƒœì™€ ì„±ëŠ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/session/monitoring/session-monitor.ts
import { MetricsCollector } from '../../metrics/collector';
import { AlertManager } from '../../alerts/manager';

export interface SessionMetrics {
  sessionId: string;
  duration: number;
  memoryUsage: number;
  cpuUsage: number;
  agentCount: number;
  checkpointCount: number;
  errorRate: number;
  throughput: number;
}

export class SessionMonitor {
  private metricsCollector: MetricsCollector;
  private alertManager: AlertManager;
  private metricsInterval: NodeJS.Timer;
  
  constructor(
    metricsCollector: MetricsCollector,
    alertManager: AlertManager
  ) {
    this.metricsCollector = metricsCollector;
    this.alertManager = alertManager;
  }
  
  startMonitoring(session: Session): void {
    const intervalId = setInterval(async () => {
      try {
        const metrics = await this.collectSessionMetrics(session);
        await this.analyzeMetrics(metrics);
        await this.checkThresholds(metrics);
      } catch (error) {
        console.error(`Monitoring error for session ${session.sessionId}:`, error);
      }
    }, 30000); // 30ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
    
    this.metricsInterval = intervalId;
  }
  
  private async collectSessionMetrics(session: Session): Promise<SessionMetrics> {
    const metrics: SessionMetrics = {
      sessionId: session.sessionId,
      duration: Date.now() - session.startTime.getTime(),
      memoryUsage: await this.getMemoryUsage(session),
      cpuUsage: await this.getCPUUsage(session),
      agentCount: session.agentInstances.size,
      checkpointCount: session.checkpoints.length,
      errorRate: await this.calculateErrorRate(session),
      throughput: await this.calculateThroughput(session)
    };
    
    // Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    this.metricsCollector.gauge('session_duration_seconds', 
      metrics.duration / 1000, 
      { sessionId: session.sessionId }
    );
    
    this.metricsCollector.gauge('session_memory_bytes',
      metrics.memoryUsage,
      { sessionId: session.sessionId }
    );
    
    this.metricsCollector.gauge('session_agent_count',
      metrics.agentCount,
      { sessionId: session.sessionId }
    );
    
    return metrics;
  }
  
  private async checkThresholds(metrics: SessionMetrics): Promise<void> {
    // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì„ê³„ê°’ ì²´í¬
    if (metrics.memoryUsage > 2 * 1024 * 1024 * 1024) { // 2GB
      await this.alertManager.sendAlert({
        severity: 'warning',
        title: 'High Memory Usage in Session',
        message: `Session ${metrics.sessionId} is using ${Math.round(metrics.memoryUsage / 1024 / 1024)}MB of memory`,
        metadata: metrics
      });
    }
    
    // ì„¸ì…˜ ì§€ì† ì‹œê°„ ì²´í¬
    if (metrics.duration > 7 * 60 * 60 * 1000) { // 7ì‹œê°„
      await this.alertManager.sendAlert({
        severity: 'info',
        title: 'Long Running Session',
        message: `Session ${metrics.sessionId} has been running for ${Math.round(metrics.duration / 1000 / 60 / 60)} hours`,
        metadata: metrics
      });
    }
    
    // ì—ëŸ¬ìœ¨ ì²´í¬
    if (metrics.errorRate > 0.05) { // 5%
      await this.alertManager.sendAlert({
        severity: 'warning',
        title: 'High Error Rate',
        message: `Session ${metrics.sessionId} has ${Math.round(metrics.errorRate * 100)}% error rate`,
        metadata: metrics
      });
    }
  }
  
  async generateSessionReport(sessionId: string): Promise<SessionReport> {
    const historicalMetrics = await this.metricsCollector.queryRange(
      'session_*',
      { sessionId },
      '-24h',
      'now'
    );
    
    return {
      sessionId,
      summary: {
        totalDuration: this.calculateTotalDuration(historicalMetrics),
        averageMemoryUsage: this.calculateAverageMemory(historicalMetrics),
        peakMemoryUsage: this.calculatePeakMemory(historicalMetrics),
        totalAgentsCreated: this.countTotalAgents(historicalMetrics),
        checkpointStats: this.analyzeCheckpoints(historicalMetrics),
        performanceScore: this.calculatePerformanceScore(historicalMetrics)
      },
      timeline: this.generateTimeline(historicalMetrics),
      recommendations: this.generateRecommendations(historicalMetrics)
    };
  }
}

// ì„¸ì…˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ API
export class SessionAnalyticsDashboard {
  async getActiveSessions(): Promise<SessionSummary[]> {
    const sessions = await this.sessionManager.getActiveSessions();
    
    return Promise.all(sessions.map(async session => ({
      sessionId: session.sessionId,
      userId: session.userId,
      projectId: session.projectId,
      startTime: session.startTime,
      duration: Date.now() - session.startTime.getTime(),
      status: session.state.status,
      progress: session.state.progress,
      agentCount: session.agentInstances.size,
      lastActivity: session.lastActivity,
      healthStatus: await this.calculateHealthStatus(session)
    })));
  }
  
  async getSessionTrends(timeRange: string): Promise<TrendData> {
    const metrics = await this.metricsCollector.queryRange(
      'session_*',
      {},
      timeRange,
      'now'
    );
    
    return {
      sessionCount: this.extractTrend(metrics, 'session_count'),
      averageDuration: this.extractTrend(metrics, 'session_duration_seconds'),
      memoryUsage: this.extractTrend(metrics, 'session_memory_bytes'),
      errorRate: this.extractTrend(metrics, 'session_error_rate'),
      throughput: this.extractTrend(metrics, 'session_throughput')
    };
  }
}
```

## Task 1.11: ë³´ì•ˆ ë° ì¸ì¦ ë ˆì´ì–´

### SubTask 1.11.1: JWT ê¸°ë°˜ ì¸ì¦ ì‹œìŠ¤í…œ
**ë‹´ë‹¹ì**: ë³´ì•ˆ ì „ë¬¸ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ì•ˆì „í•œ JWT ê¸°ë°˜ ì¸ì¦ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/auth/jwt-auth.ts
import jwt from 'jsonwebtoken';
import { JWK, JWS } from 'node-jose';
import crypto from 'crypto';

export interface TokenPayload {
  userId: string;
  sessionId: string;
  projectId?: string;
  roles: string[];
  permissions: string[];
  iat: number;
  exp: number;
  jti: string;
}

export class JWTAuthService {
  private keyStore: JWK.KeyStore;
  private activeTokens: Map<string, TokenInfo>;
  private blacklist: Set<string>;
  
  constructor(
    private config: AuthConfig
  ) {
    this.keyStore = JWK.createKeyStore();
    this.activeTokens = new Map();
    this.blacklist = new Set();
    
    this.initializeKeys();
  }
  
  private async initializeKeys(): Promise<void> {
    // RSA í‚¤ ìŒ ìƒì„±
    await this.keyStore.generate('RSA', 2048, {
      alg: 'RS256',
      use: 'sig',
      kid: this.generateKeyId()
    });
    
    // í‚¤ ë¡œí…Œì´ì…˜ ìŠ¤ì¼€ì¤„ ì„¤ì •
    this.scheduleKeyRotation();
  }
  
  async generateToken(
    user: User,
    session: Session,
    options?: TokenOptions
  ): Promise<AuthToken> {
    const tokenId = crypto.randomUUID();
    const now = Math.floor(Date.now() / 1000);
    
    const payload: TokenPayload = {
      userId: user.id,
      sessionId: session.sessionId,
      projectId: session.projectId,
      roles: user.roles,
      permissions: await this.resolvePermissions(user),
      iat: now,
      exp: now + (options?.expiresIn || 3600), // ê¸°ë³¸ 1ì‹œê°„
      jti: tokenId
    };
    
    // JWT ìƒì„±
    const key = this.keyStore.all()[0];
    const token = await JWS.createSign({
      format: 'compact',
      fields: {
        typ: 'JWT',
        kid: key.kid
      }
    }, key)
    .update(JSON.stringify(payload))
    .final();
    
    // ë¦¬í”„ë ˆì‹œ í† í° ìƒì„±
    const refreshToken = await this.generateRefreshToken(user, session);
    
    // í† í° ì •ë³´ ì €ì¥
    this.activeTokens.set(tokenId, {
      userId: user.id,
      sessionId: session.sessionId,
      issuedAt: new Date(),
      expiresAt: new Date(payload.exp * 1000),
      refreshToken: refreshToken.id
    });
    
    return {
      accessToken: token.toString(),
      refreshToken: refreshToken.token,
      tokenType: 'Bearer',
      expiresIn: payload.exp - payload.iat
    };
  }
  
  async verifyToken(token: string): Promise<TokenPayload> {
    try {
      // ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬
      const decoded = jwt.decode(token) as any;
      if (this.blacklist.has(decoded?.jti)) {
        throw new Error('Token has been revoked');
      }
      
      // ì„œëª… ê²€ì¦
      const result = await JWS.createVerify(this.keyStore)
        .verify(token);
      
      const payload = JSON.parse(result.payload.toString());
      
      // ë§Œë£Œ ì‹œê°„ ì²´í¬
      if (payload.exp < Math.floor(Date.now() / 1000)) {
        throw new Error('Token has expired');
      }
      
      // ì¶”ê°€ ê²€ì¦
      await this.performAdditionalValidation(payload);
      
      return payload;
      
    } catch (error) {
      throw new AuthenticationError('Invalid token', error);
    }
  }
  
  async refreshAccessToken(refreshToken: string): Promise<AuthToken> {
    const refreshPayload = await this.verifyRefreshToken(refreshToken);
    
    // ì‚¬ìš©ì ë° ì„¸ì…˜ í™•ì¸
    const user = await this.userService.findById(refreshPayload.userId);
    const session = await this.sessionManager.getSession(refreshPayload.sessionId);
    
    if (!user || !session) {
      throw new Error('Invalid refresh token');
    }
    
    // ìƒˆ ì•¡ì„¸ìŠ¤ í† í° ìƒì„±
    return this.generateToken(user, session);
  }
  
  async revokeToken(tokenId: string): Promise<void> {
    this.blacklist.add(tokenId);
    this.activeTokens.delete(tokenId);
    
    // Redisì— ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë™ê¸°í™”
    await this.redis.sadd('token:blacklist', tokenId);
    await this.redis.expire('token:blacklist', 86400); // 24ì‹œê°„
  }
  
  private async performAdditionalValidation(payload: TokenPayload): Promise<void> {
    // IP ì£¼ì†Œ ê²€ì¦
    if (this.config.validateIP) {
      const tokenIP = await this.redis.get(`token:ip:${payload.jti}`);
      if (tokenIP && tokenIP !== this.getCurrentIP()) {
        throw new Error('IP address mismatch');
      }
    }
    
    // ì„¸ì…˜ ìœ íš¨ì„± ê²€ì¦
    const session = await this.sessionManager.getSession(payload.sessionId);
    if (!session || session.state.status !== 'active') {
      throw new Error('Invalid session');
    }
  }
}
```
### SubTask 1.11.2: ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´ (RBAC)
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 12ì‹œê°„

**ëª©í‘œ**: ì„¸ë°€í•œ ê¶Œí•œ ê´€ë¦¬ë¥¼ ìœ„í•œ RBAC ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/rbac/rbac-system.ts
export interface Role {
  id: string;
  name: string;
  description: string;
  permissions: Permission[];
  inherits?: string[]; // ìƒì†ë°›ëŠ” ë‹¤ë¥¸ ì—­í• ë“¤
  conditions?: RoleCondition[];
  priority: number;
}

export interface Permission {
  id: string;
  resource: string;
  action: string;
  effect: 'allow' | 'deny';
  conditions?: PermissionCondition[];
}

export interface RoleCondition {
  type: 'time' | 'ip' | 'attribute';
  operator: 'equals' | 'contains' | 'between' | 'regex';
  value: any;
}

export class RBACService {
  private roleCache: Map<string, Role>;
  private permissionCache: Map<string, Permission>;
  private userRoleCache: LRUCache<string, string[]>;
  
  constructor(
    private dynamoClient: DynamoDBDocumentClient,
    private redis: Redis
  ) {
    this.roleCache = new Map();
    this.permissionCache = new Map();
    this.userRoleCache = new LRUCache({ max: 10000 });
    
    this.initializeDefaultRoles();
  }
  
  private async initializeDefaultRoles(): Promise<void> {
    const defaultRoles: Role[] = [
      {
        id: 'admin',
        name: 'Administrator',
        description: 'Full system access',
        permissions: [
          {
            id: 'admin-all',
            resource: '*',
            action: '*',
            effect: 'allow'
          }
        ],
        priority: 100
      },
      {
        id: 'developer',
        name: 'Developer',
        description: 'Standard developer access',
        permissions: [
          {
            id: 'project-manage',
            resource: 'project:*',
            action: 'create|read|update|delete',
            effect: 'allow',
            conditions: [{
              type: 'attribute',
              operator: 'equals',
              value: { projectOwner: '${userId}' }
            }]
          },
          {
            id: 'agent-execute',
            resource: 'agent:*',
            action: 'execute|monitor',
            effect: 'allow'
          }
        ],
        priority: 50
      },
      {
        id: 'viewer',
        name: 'Viewer',
        description: 'Read-only access',
        permissions: [
          {
            id: 'read-only',
            resource: '*',
            action: 'read|list',
            effect: 'allow'
          }
        ],
        priority: 10
      }
    ];
    
    for (const role of defaultRoles) {
      await this.createRole(role);
    }
  }
  
  async checkPermission(
    userId: string,
    resource: string,
    action: string,
    context?: PermissionContext
  ): Promise<boolean> {
    // 1. ì‚¬ìš©ì ì—­í•  ì¡°íšŒ
    const userRoles = await this.getUserRoles(userId);
    
    // 2. ì—­í• ë³„ ê¶Œí•œ ìˆ˜ì§‘
    const permissions = await this.collectPermissions(userRoles);
    
    // 3. ê¶Œí•œ í‰ê°€
    return this.evaluatePermissions(
      permissions,
      resource,
      action,
      context
    );
  }
  
  private async collectPermissions(roleIds: string[]): Promise<Permission[]> {
    const allPermissions: Permission[] = [];
    const processedRoles = new Set<string>();
    
    const processRole = async (roleId: string) => {
      if (processedRoles.has(roleId)) return;
      processedRoles.add(roleId);
      
      const role = await this.getRole(roleId);
      if (!role) return;
      
      // ì§ì ‘ ê¶Œí•œ ì¶”ê°€
      allPermissions.push(...role.permissions);
      
      // ìƒì†ëœ ì—­í•  ì²˜ë¦¬
      if (role.inherits) {
        for (const inheritedRoleId of role.inherits) {
          await processRole(inheritedRoleId);
        }
      }
    };
    
    for (const roleId of roleIds) {
      await processRole(roleId);
    }
    
    // ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì •ë ¬
    return allPermissions.sort((a, b) => {
      const roleA = this.roleCache.get(a.id);
      const roleB = this.roleCache.get(b.id);
      return (roleB?.priority || 0) - (roleA?.priority || 0);
    });
  }
  
  private evaluatePermissions(
    permissions: Permission[],
    resource: string,
    action: string,
    context?: PermissionContext
  ): boolean {
    let decision: boolean | null = null;
    
    for (const permission of permissions) {
      // ë¦¬ì†ŒìŠ¤ ë§¤ì¹­
      if (!this.matchResource(permission.resource, resource)) {
        continue;
      }
      
      // ì•¡ì…˜ ë§¤ì¹­
      if (!this.matchAction(permission.action, action)) {
        continue;
      }
      
      // ì¡°ê±´ í‰ê°€
      if (permission.conditions) {
        const conditionsMet = this.evaluateConditions(
          permission.conditions,
          context
        );
        if (!conditionsMet) continue;
      }
      
      // ëª…ì‹œì  ê±°ë¶€ëŠ” í•­ìƒ ìš°ì„ 
      if (permission.effect === 'deny') {
        return false;
      }
      
      // í—ˆìš© ê¶Œí•œ ë°œê²¬
      if (permission.effect === 'allow') {
        decision = true;
      }
    }
    
    return decision === true;
  }
  
  async createPolicy(
    name: string,
    statements: PolicyStatement[]
  ): Promise<Policy> {
    const policy: Policy = {
      id: crypto.randomUUID(),
      name,
      version: '1.0',
      statements,
      createdAt: new Date(),
      updatedAt: new Date()
    };
    
    // DynamoDBì— ì €ì¥
    await this.dynamoClient.send(new PutCommand({
      TableName: 'Policies',
      Item: policy
    }));
    
    return policy;
  }
  
  // ë™ì  ê¶Œí•œ í‰ê°€
  async evaluateDynamicPermission(
    userId: string,
    request: PermissionRequest
  ): Promise<PermissionDecision> {
    const startTime = Date.now();
    
    // ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
    const context = await this.buildContext(userId, request);
    
    // ì ìš© ê°€ëŠ¥í•œ ì •ì±… ì°¾ê¸°
    const applicablePolicies = await this.findApplicablePolicies(
      userId,
      request.resource,
      context
    );
    
    // ì •ì±… í‰ê°€
    const decisions = await Promise.all(
      applicablePolicies.map(policy => 
        this.evaluatePolicy(policy, request, context)
      )
    );
    
    // ìµœì¢… ê²°ì •
    const finalDecision = this.combineDecisions(decisions);
    
    // ê°ì‚¬ ë¡œê·¸
    await this.auditLog.log({
      userId,
      resource: request.resource,
      action: request.action,
      decision: finalDecision,
      evaluationTime: Date.now() - startTime,
      policies: applicablePolicies.map(p => p.id)
    });
    
    return finalDecision;
  }
}

// RBAC ë¯¸ë“¤ì›¨ì–´
export function rbacMiddleware(
  resource: string | ((req: Request) => string),
  action: string | ((req: Request) => string)
) {
  return async (req: Request, res: Response, next: NextFunction) => {
    try {
      const userId = req.user?.id;
      if (!userId) {
        return res.status(401).json({ error: 'Unauthorized' });
      }
      
      const resourceName = typeof resource === 'function' 
        ? resource(req) 
        : resource;
      const actionName = typeof action === 'function' 
        ? action(req) 
        : action;
        
      const hasPermission = await rbacService.checkPermission(
        userId,
        resourceName,
        actionName,
        {
          ip: req.ip,
          userAgent: req.headers['user-agent'],
          requestId: req.id,
          resourceId: req.params.id
        }
      );
      
      if (!hasPermission) {
        return res.status(403).json({ 
          error: 'Forbidden',
          message: `Insufficient permissions for ${actionName} on ${resourceName}`
        });
      }
      
      next();
    } catch (error) {
      next(error);
    }
  };
}
```

### SubTask 1.11.3: API ë³´ì•ˆ ê°•í™”
**ë‹´ë‹¹ì**: ë³´ì•ˆ ì „ë¬¸ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: API ë ˆë²¨ì—ì„œì˜ ì¢…í•©ì ì¸ ë³´ì•ˆ ê°•í™”

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/api/api-security.ts
import rateLimit from 'express-rate-limit';
import helmet from 'helmet';
import { createHash, createHmac } from 'crypto';

export class APISecurityManager {
  private rateLimiters: Map<string, any>;
  private apiKeyStore: Map<string, APIKey>;
  
  constructor(
    private config: SecurityConfig,
    private redis: Redis
  ) {
    this.rateLimiters = new Map();
    this.apiKeyStore = new Map();
    
    this.initializeRateLimiters();
  }
  
  private initializeRateLimiters(): void {
    // ê¸°ë³¸ rate limiter
    this.rateLimiters.set('default', rateLimit({
      windowMs: 15 * 60 * 1000, // 15ë¶„
      max: 100, // ìš”ì²­ ìˆ˜
      standardHeaders: true,
      legacyHeaders: false,
      store: new RedisStore({
        client: this.redis,
        prefix: 'rl:default:'
      }),
      handler: (req, res) => {
        res.status(429).json({
          error: 'Too Many Requests',
          message: 'Rate limit exceeded',
          retryAfter: req.rateLimit.resetTime
        });
      }
    }));
    
    // ì—„ê²©í•œ rate limiter (ë¯¼ê°í•œ ì—”ë“œí¬ì¸íŠ¸ìš©)
    this.rateLimiters.set('strict', rateLimit({
      windowMs: 15 * 60 * 1000,
      max: 10,
      skipSuccessfulRequests: false,
      store: new RedisStore({
        client: this.redis,
        prefix: 'rl:strict:'
      })
    }));
    
    // API í‚¤ë³„ rate limiter
    this.rateLimiters.set('apikey', rateLimit({
      windowMs: 60 * 1000, // 1ë¶„
      max: (req) => {
        const apiKey = this.extractAPIKey(req);
        const keyInfo = this.apiKeyStore.get(apiKey);
        return keyInfo?.rateLimit || 60;
      },
      keyGenerator: (req) => {
        return this.extractAPIKey(req) || req.ip;
      },
      store: new RedisStore({
        client: this.redis,
        prefix: 'rl:apikey:'
      })
    }));
  }
  
  // API í‚¤ ê´€ë¦¬
  async generateAPIKey(
    userId: string,
    name: string,
    permissions: string[]
  ): Promise<APIKeyResponse> {
    const key = this.generateSecureKey();
    const hashedKey = this.hashAPIKey(key);
    
    const apiKeyInfo: APIKey = {
      id: crypto.randomUUID(),
      userId,
      name,
      hashedKey,
      permissions,
      rateLimit: 60, // ë¶„ë‹¹ ìš”ì²­ ìˆ˜
      createdAt: new Date(),
      lastUsed: null,
      expiresAt: new Date(Date.now() + 365 * 24 * 60 * 60 * 1000), // 1ë…„
      metadata: {}
    };
    
    // DynamoDBì— ì €ì¥
    await this.saveAPIKey(apiKeyInfo);
    
    // ìºì‹œì— ì €ì¥
    this.apiKeyStore.set(hashedKey, apiKeyInfo);
    
    return {
      apiKey: key, // ì›ë³¸ í‚¤ëŠ” ì´ë•Œë§Œ ë°˜í™˜
      keyId: apiKeyInfo.id,
      name: apiKeyInfo.name,
      permissions: apiKeyInfo.permissions,
      expiresAt: apiKeyInfo.expiresAt
    };
  }
  
  // ìš”ì²­ ì„œëª… ê²€ì¦
  async verifyRequestSignature(
    req: Request,
    secret: string
  ): Promise<boolean> {
    const signature = req.headers['x-signature'] as string;
    if (!signature) return false;
    
    const timestamp = req.headers['x-timestamp'] as string;
    if (!timestamp) return false;
    
    // íƒ€ì„ìŠ¤íƒ¬í”„ ê²€ì¦ (5ë¶„ ì´ë‚´)
    const requestTime = parseInt(timestamp);
    const currentTime = Date.now();
    if (Math.abs(currentTime - requestTime) > 300000) {
      return false;
    }
    
    // ì„œëª… í˜ì´ë¡œë“œ ìƒì„±
    const payload = this.createSignaturePayload(req, timestamp);
    
    // HMAC ì„œëª… ìƒì„±
    const expectedSignature = createHmac('sha256', secret)
      .update(payload)
      .digest('hex');
      
    // íƒ€ì´ë° ê³µê²© ë°©ì§€ë¥¼ ìœ„í•œ ì•ˆì „í•œ ë¹„êµ
    return this.secureCompare(signature, expectedSignature);
  }
  
  // CORS ì„¤ì •
  getCORSOptions(): cors.CorsOptions {
    return {
      origin: (origin, callback) => {
        // í—ˆìš©ëœ ë„ë©”ì¸ í™•ì¸
        if (!origin || this.isAllowedOrigin(origin)) {
          callback(null, true);
        } else {
          callback(new Error('CORS policy violation'));
        }
      },
      credentials: true,
      methods: ['GET', 'POST', 'PUT', 'DELETE', 'PATCH'],
      allowedHeaders: [
        'Content-Type',
        'Authorization',
        'X-Request-ID',
        'X-API-Key',
        'X-Signature',
        'X-Timestamp'
      ],
      exposedHeaders: [
        'X-Request-ID',
        'X-RateLimit-Limit',
        'X-RateLimit-Remaining',
        'X-RateLimit-Reset'
      ],
      maxAge: 86400 // 24ì‹œê°„
    };
  }
  
  // ë³´ì•ˆ í—¤ë” ì„¤ì •
  getSecurityHeaders(): any {
    return helmet({
      contentSecurityPolicy: {
        directives: {
          defaultSrc: ["'self'"],
          scriptSrc: ["'self'", "'unsafe-inline'"],
          styleSrc: ["'self'", "'unsafe-inline'"],
          imgSrc: ["'self'", "data:", "https:"],
          connectSrc: ["'self'"],
          fontSrc: ["'self'"],
          objectSrc: ["'none'"],
          mediaSrc: ["'self'"],
          frameSrc: ["'none'"]
        }
      },
      crossOriginEmbedderPolicy: true,
      crossOriginOpenerPolicy: true,
      crossOriginResourcePolicy: { policy: "cross-origin" },
      dnsPrefetchControl: true,
      frameguard: { action: 'deny' },
      hidePoweredBy: true,
      hsts: {
        maxAge: 31536000,
        includeSubDomains: true,
        preload: true
      },
      ieNoOpen: true,
      noSniff: true,
      originAgentCluster: true,
      permittedCrossDomainPolicies: false,
      referrerPolicy: { policy: "strict-origin-when-cross-origin" },
      xssFilter: true
    });
  }
  
  // SQL Injection ë°©ì§€
  sanitizeInput(input: any): any {
    if (typeof input === 'string') {
      // SQL ì˜ˆì•½ì–´ ë° ìœ„í—˜í•œ íŒ¨í„´ ì œê±°
      return input
        .replace(/['";\\]/g, '')
        .replace(/--/g, '')
        .replace(/\/\*/g, '')
        .replace(/\*\//g, '')
        .replace(/xp_/gi, '')
        .replace(/sp_/gi, '');
    }
    
    if (Array.isArray(input)) {
      return input.map(item => this.sanitizeInput(item));
    }
    
    if (typeof input === 'object' && input !== null) {
      const sanitized: any = {};
      for (const [key, value] of Object.entries(input)) {
        sanitized[this.sanitizeInput(key)] = this.sanitizeInput(value);
      }
      return sanitized;
    }
    
    return input;
  }
  
  // API ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´ ì²´ì¸
  getSecurityMiddleware(): RequestHandler[] {
    return [
      // 1. ë³´ì•ˆ í—¤ë”
      this.getSecurityHeaders(),
      
      // 2. CORS
      cors(this.getCORSOptions()),
      
      // 3. Body í¬ê¸° ì œí•œ
      express.json({ limit: '10mb' }),
      express.urlencoded({ extended: true, limit: '10mb' }),
      
      // 4. Rate limiting
      this.rateLimiters.get('default'),
      
      // 5. API í‚¤ ê²€ì¦
      this.apiKeyMiddleware.bind(this),
      
      // 6. ìš”ì²­ ì„œëª… ê²€ì¦ (ì„ íƒì )
      this.signatureMiddleware.bind(this),
      
      // 7. ì…ë ¥ ê²€ì¦ ë° ì‚´ê· 
      this.inputValidationMiddleware.bind(this),
      
      // 8. ê°ì‚¬ ë¡œê¹…
      this.auditLoggingMiddleware.bind(this)
    ];
  }
}
```

### SubTask 1.11.4: ë°ì´í„° ì•”í˜¸í™” ë° ë³´ì•ˆ ì €ì¥ì†Œ
**ë‹´ë‹¹ì**: ë°±ì—”ë“œ ê°œë°œì  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 10ì‹œê°„

**ëª©í‘œ**: ë¯¼ê°í•œ ë°ì´í„°ì˜ ì•”í˜¸í™” ë° ì•ˆì „í•œ ì €ì¥ ì‹œìŠ¤í…œ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
```typescript
// backend/src/security/encryption/data-encryption.ts
import { KMSClient, GenerateDataKeyCommand, DecryptCommand } from '@aws-sdk/client-kms';
import crypto from 'crypto';

export class DataEncryptionService {
  private kmsClient: KMSClient;
  private dataKeyCache: LRUCache<string, Buffer>;
  
  constructor(
    private config: EncryptionConfig
  ) {
    this.kmsClient = new KMSClient({
      region: config.awsRegion
    });
    this.dataKeyCache = new LRUCache({
      max: 100,
      ttl: 1000 * 60 * 60 // 1ì‹œê°„
    });
  }
  
  // í•„ë“œ ë ˆë²¨ ì•”í˜¸í™”
  async encryptField(
    plaintext: string,
    context?: EncryptionContext
  ): Promise<EncryptedField> {
    // ë°ì´í„° í‚¤ ìƒì„± ë˜ëŠ” ìºì‹œì—ì„œ ê°€ì ¸ì˜¤ê¸°
    const dataKey = await this.getOrGenerateDataKey(context);
    
    // AES-256-GCMìœ¼ë¡œ ì•”í˜¸í™”
    const iv = crypto.randomBytes(16);
    const cipher = crypto.createCipheriv(
      'aes-256-gcm',
      dataKey.plaintext,
      iv
    );
    
    const encrypted = Buffer.concat([
      cipher.update(plaintext, 'utf8'),
      cipher.final()
    ]);
    
    const authTag = cipher.getAuthTag();
    
    return {
      ciphertext: encrypted.toString('base64'),
      iv: iv.toString('base64'),
      authTag: authTag.toString('base64'),
      keyId: dataKey.keyId,
      algorithm: 'AES-256-GCM',
      context
    };
  }
  
  async decryptField(
    encryptedField: EncryptedField
  ): Promise<string> {
    // ë°ì´í„° í‚¤ ë³µí˜¸í™”
    const dataKey = await this.decryptDataKey(
      encryptedField.keyId,
      encryptedField.context
    );
    
    // AES-256-GCMìœ¼ë¡œ ë³µí˜¸í™”
    const decipher = crypto.createDecipheriv(
      'aes-256-gcm',
      dataKey,
      Buffer.from(encryptedField.iv, 'base64')
    );
    
    decipher.setAuthTag(
      Buffer.from(encryptedField.authTag, 'base64')
    );
    
    const decrypted = Buffer.concat([
      decipher.update(
        Buffer.from(encryptedField.ciphertext, 'base64')
      ),
      decipher.final()
    ]);
    
    return decrypted.toString('utf8');
  }
  
  // íˆ¬ëª…í•œ ì•”í˜¸í™” ë˜í¼
  createEncryptedModel<T extends object>(
    model: T,
    encryptedFields: string[]
  ): EncryptedModel<T> {
    return new Proxy(model, {
      get: async (target, prop) => {
        if (encryptedFields.includes(prop as string)) {
          const encryptedValue = target[prop];
          if (encryptedValue && typeof encryptedValue === 'object') {
            return await this.decryptField(encryptedValue);
          }
        }
        return target[prop];
      },
      
      set: async (target, prop, value) => {
        if (encryptedFields.includes(prop as string)) {
          target[prop] = await this.encryptField(value);
        } else {
          target[prop] = value;
        }
        return true;
      }
    }) as EncryptedModel<T>;
  }
  
  // íŒŒì¼ ì•”í˜¸í™”
  async encryptFile(
    filePath: string,
    outputPath: string
  ): Promise<FileEncryptionResult> {
    const dataKey = await this.getOrGenerateDataKey();
    
    // ìŠ¤íŠ¸ë¦¼ ì•”í˜¸í™”
    const iv = crypto.randomBytes(16);
    const cipher = crypto.createCipheriv(
      'aes-256-gcm',
      dataKey.plaintext,
      iv
    );
    
    const input = fs.createReadStream(filePath);
    const output = fs.createWriteStream(outputPath);
    
    // ë©”íƒ€ë°ì´í„° í—¤ë” ì‘ì„±
    const header = {
      version: 1,
      keyId: dataKey.keyId,
      iv: iv.toString('base64'),
      algorithm: 'AES-256-GCM'
    };
    
    output.write(JSON.stringify(header) + '\n');
    
    // íŒŒì¼ ì•”í˜¸í™”
    return new Promise((resolve, reject) => {
      input
        .pipe(cipher)
        .pipe(output)
        .on('finish', () => {
          const authTag = cipher.getAuthTag();
          
          // ì¸ì¦ íƒœê·¸ ì¶”ê°€
          fs.appendFileSync(outputPath, '\n' + authTag.toString('base64'));
          
          resolve({
            encryptedPath: outputPath,
            keyId: dataKey.keyId,
            size: fs.statSync(outputPath).size,
            checksum: this.calculateChecksum(outputPath)
          });
        })
        .on('error', reject);
    });
  }
  
  // ë³´ì•ˆ í‚¤ ì €ì¥ì†Œ
  async storeSecureSecret(
    name: string,
    value: string,
    options?: SecretOptions
  ): Promise<void> {
    // AWS Secrets Manager ì‚¬ìš©
    const client = new SecretsManagerClient({
      region: this.config.awsRegion
    });
    
    const encrypted = await this.encryptField(value, {
      purpose: 'secret-storage',
      name
    });
    
    await client.send(new CreateSecretCommand({
      Name: `t-developer/${this.config.environment}/${name}`,
      SecretString: JSON.stringify(encrypted),
      Tags: [
        { Key: 'Application', Value: 'T-Developer' },
        { Key: 'Environment', Value: this.config.environment },
        { Key: 'Encrypted', Value: 'true' }
      ],
      KmsKeyId: this.config.kmsKeyId
    }));
  }
  
  // ë³´ì•ˆ ê°ì‚¬ ë¡œê·¸
  async logSecurityEvent(event: SecurityEvent): Promise<void> {
    const encryptedEvent = {
      ...event,
      sensitiveData: event.sensitiveData 
        ? await this.encryptField(
            JSON.stringify(event.sensitiveData),
            { purpose: 'audit-log' }
          )
        : undefined,
      timestamp: new Date().toISOString(),
      environment: this.config.environment
    };
    
    // CloudWatch Logsì— ì•”í˜¸í™”ëœ ë¡œê·¸ ì „ì†¡
    await this.cloudWatchClient.send(new PutLogEventsCommand({
      logGroupName: `/aws/t-developer/security/${this.config.environment}`,
      logStreamName: `security-events-${new Date().toISOString().split('T')[0]}`,
      logEvents: [{
        timestamp: Date.now(),
        message: JSON.stringify(encryptedEvent)
      }]
    }));
  }
}

// ì•”í˜¸í™”ëœ DynamoDB í…Œì´ë¸” ë˜í¼
export class EncryptedDynamoDBTable {
  constructor(
    private tableName: string,
    private encryptionService: DataEncryptionService,
    private encryptedAttributes: string[]
  ) {}
  
  async putItem(item: Record<string, any>): Promise<void> {
    const encryptedItem = { ...item };
    
    // ì§€ì •ëœ ì†ì„± ì•”í˜¸í™”
    for (const attr of this.encryptedAttributes) {
      if (item[attr] !== undefined) {
        encryptedItem[attr] = await this.encryptionService.encryptField(
          typeof item[attr] === 'string' 
            ? item[attr] 
            : JSON.stringify(item[attr])
        );
      }
    }
    
    await this.dynamoClient.send(new PutCommand({
      TableName: this.tableName,
      Item: encryptedItem
    }));
  }
  
  async getItem(key: Record<string, any>): Promise<any> {
    const response = await this.dynamoClient.send(new GetCommand({
      TableName: this.tableName,
      Key: key
    }));
    
    if (!response.Item) return null;
    
    const decryptedItem = { ...response.Item };
    
    // ì•”í˜¸í™”ëœ ì†ì„± ë³µí˜¸í™”
    for (const attr of this.encryptedAttributes) {
      if (decryptedItem[attr] && typeof decryptedItem[attr] === 'object') {
        const decrypted = await this.encryptionService.decryptField(
          decryptedItem[attr]
        );
        
        try {
          decryptedItem[attr] = JSON.parse(decrypted);
        } catch {
          decryptedItem[attr] = decrypted;
        }
      }
    }
    
    return decryptedItem;
  }
}
```