# ğŸ§¬ Evolution Safety Framework

## ê°œìš”

T-Developerì˜ AI ììœ¨ì§„í™” ì‹œìŠ¤í…œì„ ìœ„í•œ ì•ˆì „ì¥ì¹˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì•…ì„± ì§„í™” ë°©ì§€, ì‹œìŠ¤í…œ ì•ˆì •ì„± ë³´ì¥, ì§„í™” ê²°ê³¼ ê²€ì¦ì„ í†µí•´ ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ì§„í™”ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

## ğŸ¯ ì•ˆì „ ëª©í‘œ

### 1. ì•…ì„± ì§„í™” ë°©ì§€ (Malicious Evolution Prevention)
- ì˜ë„ì /ë¹„ì˜ë„ì  ì•…ì„± ì½”ë“œ ìƒì„± ì°¨ë‹¨
- ì‹œìŠ¤í…œ ë³´ì•ˆì„ ìœ„í˜‘í•˜ëŠ” ì§„í™” ë°©ì§€
- ë°ì´í„° ìœ ì¶œì´ë‚˜ ê¶Œí•œ ìƒìŠ¹ì„ ì‹œë„í•˜ëŠ” ì§„í™” ì°¨ë‹¨

### 2. ì‹œìŠ¤í…œ ì•ˆì •ì„± ë³´ì¥ (System Stability)
- ì§„í™” ê³¼ì •ì—ì„œ ì‹œìŠ¤í…œ ì¶©ëŒ ë°©ì§€
- ë¬´í•œ ë£¨í”„ë‚˜ ìì› ê³ ê°ˆ ìƒí™© ì°¨ë‹¨
- ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ì˜ í˜¸í™˜ì„± ìœ ì§€

### 3. í’ˆì§ˆ ì œì–´ (Quality Assurance)
- ì§„í™” ê²°ê³¼ì˜ ê¸°ëŠ¥ì  ì •í™•ì„± ë³´ì¥
- ì„±ëŠ¥ ì €í•˜ ë°©ì§€
- ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë¬´ê²°ì„± ìœ ì§€

## ğŸ›¡ï¸ ë‹¤ì¸µ ì•ˆì „ì¥ì¹˜ ì‹œìŠ¤í…œ

### Layer 1: ì§„í™” ì „ ì‚¬ì „ ê²€ì¦ (Pre-Evolution Validation)

#### 1.1 ì§„í™” ëª©í‘œ ì•ˆì „ì„± ë¶„ì„
```python
# backend/src/security/evolution_safety_validator.py

from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum
import ast
import re
import json

class SafetyRisk(Enum):
    SAFE = "safe"
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class EvolutionSafetyResult:
    is_safe: bool
    risk_level: SafetyRisk
    safety_score: float
    detected_risks: List[str]
    recommended_constraints: Dict[str, Any]
    alternative_approaches: List[str]

class EvolutionSafetyValidator:
    def __init__(self):
        self.dangerous_objectives = [
            "privilege escalation",
            "system infiltration", 
            "data exfiltration",
            "backdoor installation",
            "security bypass",
            "malware creation",
            "ddos attack",
            "unauthorized access",
            "credential harvesting",
            "network scanning"
        ]
        
        self.high_risk_modifications = [
            "authentication systems",
            "authorization mechanisms", 
            "encryption algorithms",
            "security configurations",
            "system administrators",
            "root privileges",
            "kernel modifications",
            "network protocols"
        ]
        
        self.resource_intensive_patterns = [
            "infinite loops",
            "recursive calls without limit",
            "memory allocation bombs",
            "cpu intensive operations",
            "network flooding",
            "disk space exhaustion"
        ]
    
    def validate_evolution_objective(self, objective: str, context: Dict[str, Any]) -> EvolutionSafetyResult:
        """ì§„í™” ëª©í‘œ ì•ˆì „ì„± ê²€ì¦"""
        detected_risks = []
        safety_score = 1.0
        
        # 1. ì•…ì„± ëª©í‘œ ê²€ì‚¬
        malicious_score = self._check_malicious_objectives(objective)
        if malicious_score > 0:
            detected_risks.append(f"Potentially malicious objective detected (score: {malicious_score})")
            safety_score -= malicious_score * 0.4
        
        # 2. ê³ ìœ„í—˜ ìˆ˜ì • ì˜ì—­ ê²€ì‚¬
        high_risk_score = self._check_high_risk_modifications(objective)
        if high_risk_score > 0:
            detected_risks.append(f"High-risk system modification (score: {high_risk_score})")
            safety_score -= high_risk_score * 0.3
        
        # 3. ë¦¬ì†ŒìŠ¤ ì§‘ì•½ì  íŒ¨í„´ ê²€ì‚¬
        resource_risk_score = self._check_resource_risks(objective)
        if resource_risk_score > 0:
            detected_risks.append(f"Resource-intensive pattern detected (score: {resource_risk_score})")
            safety_score -= resource_risk_score * 0.2
        
        # 4. ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        context_risk_score = self._analyze_context_risks(context)
        if context_risk_score > 0:
            detected_risks.append(f"Context-based risk detected (score: {context_risk_score})")
            safety_score -= context_risk_score * 0.1
        
        safety_score = max(safety_score, 0.0)
        
        # ìœ„í—˜ë„ ê²°ì •
        risk_level = self._calculate_risk_level(safety_score)
        is_safe = risk_level in [SafetyRisk.SAFE, SafetyRisk.LOW]
        
        # ê¶Œì¥ ì œì•½ì‚¬í•­ ìƒì„±
        constraints = self._generate_safety_constraints(detected_risks, risk_level)
        
        # ëŒ€ì•ˆ ì ‘ê·¼ë²• ì œì•ˆ
        alternatives = self._suggest_alternatives(objective, detected_risks)
        
        return EvolutionSafetyResult(
            is_safe=is_safe,
            risk_level=risk_level,
            safety_score=safety_score,
            detected_risks=detected_risks,
            recommended_constraints=constraints,
            alternative_approaches=alternatives
        )
    
    def _check_malicious_objectives(self, objective: str) -> float:
        """ì•…ì„± ëª©í‘œ ê²€ì‚¬"""
        objective_lower = objective.lower()
        risk_score = 0.0
        
        for dangerous_term in self.dangerous_objectives:
            if dangerous_term in objective_lower:
                risk_score += 0.8
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ ê²€ì‚¬
        suspicious_patterns = [
            r"bypass\s+security",
            r"exploit\s+vulnerability",
            r"gain\s+(admin|root)\s+access",
            r"steal\s+(data|credentials)",
            r"disable\s+monitoring",
            r"hide\s+activity"
        ]
        
        for pattern in suspicious_patterns:
            if re.search(pattern, objective_lower):
                risk_score += 0.6
        
        return min(risk_score, 1.0)
    
    def _check_high_risk_modifications(self, objective: str) -> float:
        """ê³ ìœ„í—˜ ìˆ˜ì • ì˜ì—­ ê²€ì‚¬"""
        objective_lower = objective.lower()
        risk_score = 0.0
        
        for high_risk_area in self.high_risk_modifications:
            if high_risk_area in objective_lower:
                risk_score += 0.7
        
        # ì‹œìŠ¤í…œ ë ˆë²¨ ìˆ˜ì • íŒ¨í„´
        system_patterns = [
            r"modify\s+(system|kernel|os)",
            r"change\s+(permissions|privileges)",
            r"alter\s+(authentication|authorization)",
            r"update\s+(security|encryption)"
        ]
        
        for pattern in system_patterns:
            if re.search(pattern, objective_lower):
                risk_score += 0.5
        
        return min(risk_score, 1.0)
    
    def _generate_safety_constraints(self, risks: List[str], risk_level: SafetyRisk) -> Dict[str, Any]:
        """ì•ˆì „ ì œì•½ì‚¬í•­ ìƒì„±"""
        constraints = {
            "max_execution_time": 300,  # 5ë¶„
            "max_memory_usage": "1GB",
            "network_access": "restricted",
            "file_system_access": "read_only",
            "system_calls": "prohibited",
            "validation_required": True
        }
        
        if risk_level in [SafetyRisk.HIGH, SafetyRisk.CRITICAL]:
            constraints.update({
                "max_execution_time": 60,  # 1ë¶„
                "max_memory_usage": "256MB",
                "network_access": "none",
                "file_system_access": "none",
                "human_approval_required": True,
                "sandboxed_execution": True
            })
        
        if "malicious" in str(risks):
            constraints.update({
                "automatic_rejection": True,
                "security_team_review": True,
                "enhanced_monitoring": True
            })
        
        return constraints
```

#### 1.2 ì§„í™” íŒŒë¼ë¯¸í„° ì œí•œ
```python
# backend/src/security/evolution_parameter_limiter.py

from typing import Dict, Any, List
from dataclasses import dataclass

@dataclass
class ParameterLimits:
    mutation_rate_max: float = 0.3
    crossover_rate_max: float = 0.8
    population_size_max: int = 100
    generation_limit: int = 50
    fitness_threshold_min: float = 0.1
    convergence_patience: int = 10

class EvolutionParameterLimiter:
    def __init__(self):
        self.safety_limits = {
            "development": ParameterLimits(
                mutation_rate_max=0.5,
                population_size_max=50,
                generation_limit=20
            ),
            "staging": ParameterLimits(
                mutation_rate_max=0.3,
                population_size_max=75,
                generation_limit=35
            ),
            "production": ParameterLimits(
                mutation_rate_max=0.2,
                population_size_max=100,
                generation_limit=50
            )
        }
    
    def validate_and_constrain_parameters(self, 
                                        parameters: Dict[str, Any], 
                                        environment: str = "production") -> Dict[str, Any]:
        """ì§„í™” íŒŒë¼ë¯¸í„° ê²€ì¦ ë° ì œí•œ"""
        limits = self.safety_limits.get(environment, self.safety_limits["production"])
        constrained_params = parameters.copy()
        
        # ë³€ì´ìœ¨ ì œí•œ
        if "mutation_rate" in parameters:
            constrained_params["mutation_rate"] = min(
                parameters["mutation_rate"], 
                limits.mutation_rate_max
            )
        
        # êµì°¨ìœ¨ ì œí•œ
        if "crossover_rate" in parameters:
            constrained_params["crossover_rate"] = min(
                parameters["crossover_rate"],
                limits.crossover_rate_max
            )
        
        # ì¸êµ¬ í¬ê¸° ì œí•œ
        if "population_size" in parameters:
            constrained_params["population_size"] = min(
                parameters["population_size"],
                limits.population_size_max
            )
        
        # ì„¸ëŒ€ ìˆ˜ ì œí•œ
        if "max_generations" in parameters:
            constrained_params["max_generations"] = min(
                parameters["max_generations"],
                limits.generation_limit
            )
        
        # ì•ˆì „ ê²€ì‚¬ì  ì¶”ê°€
        constrained_params.update({
            "safety_checkpoint_interval": 5,
            "automatic_termination_threshold": 0.05,
            "resource_monitoring_enabled": True,
            "rollback_capability_required": True
        })
        
        return constrained_params
```

### Layer 2: ì§„í™” ì¤‘ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (Real-time Monitoring)

#### 2.1 ì§„í™” í”„ë¡œì„¸ìŠ¤ ê°ì‹œ
```python
# backend/src/security/evolution_monitor.py

import asyncio
import time
import psutil
from typing import Dict, List, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class EvolutionMetrics:
    generation: int
    fitness_trend: List[float]
    resource_usage: Dict[str, float]
    safety_violations: int
    convergence_rate: float
    time_elapsed: float

class EvolutionMonitor:
    def __init__(self):
        self.monitoring_active = False
        self.safety_thresholds = {
            "cpu_usage_max": 80.0,  # %
            "memory_usage_max": 75.0,  # %
            "fitness_stagnation_limit": 10,  # generations
            "safety_violation_limit": 3,
            "execution_time_limit": 3600,  # seconds
        }
        
        self.alert_callbacks: List[Callable] = []
        self.metrics_history: List[EvolutionMetrics] = []
        
    async def start_monitoring(self, evolution_id: str, parameters: Dict[str, Any]):
        """ì§„í™” ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.monitoring_active = True
        self.evolution_id = evolution_id
        self.start_time = time.time()
        
        # ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì‹œì‘
        asyncio.create_task(self._monitor_resources())
        asyncio.create_task(self._monitor_fitness_progress())
        asyncio.create_task(self._monitor_safety_violations())
        
    async def _monitor_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§"""
        while self.monitoring_active:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_percent = psutil.virtual_memory().percent
            
            # ì„ê³„ê°’ ì´ˆê³¼ ê²€ì‚¬
            if cpu_percent > self.safety_thresholds["cpu_usage_max"]:
                await self._trigger_alert("RESOURCE_LIMIT", 
                                         f"CPU usage exceeded: {cpu_percent}%")
            
            if memory_percent > self.safety_thresholds["memory_usage_max"]:
                await self._trigger_alert("RESOURCE_LIMIT",
                                         f"Memory usage exceeded: {memory_percent}%")
            
            await asyncio.sleep(5)  # 5ì´ˆë§ˆë‹¤ ì²´í¬
    
    async def _monitor_fitness_progress(self):
        """ì í•©ë„ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§"""
        stagnation_count = 0
        last_best_fitness = 0.0
        
        while self.monitoring_active:
            current_metrics = await self._get_current_metrics()
            
            if current_metrics:
                current_best = max(current_metrics.fitness_trend) if current_metrics.fitness_trend else 0.0
                
                # ì •ì²´ ìƒíƒœ ê°ì§€
                if abs(current_best - last_best_fitness) < 0.001:
                    stagnation_count += 1
                else:
                    stagnation_count = 0
                    last_best_fitness = current_best
                
                # ì •ì²´ í•œê³„ ì´ˆê³¼
                if stagnation_count > self.safety_thresholds["fitness_stagnation_limit"]:
                    await self._trigger_alert("FITNESS_STAGNATION",
                                             f"No improvement for {stagnation_count} generations")
            
            await asyncio.sleep(10)  # 10ì´ˆë§ˆë‹¤ ì²´í¬
    
    async def _trigger_alert(self, alert_type: str, message: str):
        """ì•Œë¦¼ íŠ¸ë¦¬ê±°"""
        alert_data = {
            "type": alert_type,
            "message": message,
            "evolution_id": self.evolution_id,
            "timestamp": datetime.now(),
            "metrics": await self._get_current_metrics()
        }
        
        for callback in self.alert_callbacks:
            await callback(alert_data)
        
        # ì¤‘ìš”í•œ ì•Œë¦¼ì˜ ê²½ìš° ìë™ ëŒ€ì‘
        if alert_type in ["RESOURCE_LIMIT", "SAFETY_VIOLATION"]:
            await self._initiate_emergency_response(alert_type, message)
    
    async def _initiate_emergency_response(self, alert_type: str, message: str):
        """ê¸´ê¸‰ ëŒ€ì‘ ì ˆì°¨"""
        if alert_type == "RESOURCE_LIMIT":
            # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ê°ì†Œ ì¡°ì¹˜
            await self._reduce_population_size()
            await self._throttle_evolution_speed()
        
        elif alert_type == "SAFETY_VIOLATION":
            # ì¦‰ì‹œ ì§„í™” ì¤‘ë‹¨
            await self._pause_evolution()
            await self._create_safety_checkpoint()
```

#### 2.2 ì•…ì„± ì§„í™” íŒ¨í„´ íƒì§€
```python
# backend/src/security/malicious_evolution_detector.py

import numpy as np
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
from sklearn.isolation_forest import IsolationForest
from sklearn.ensemble import RandomForestClassifier

@dataclass
class EvolutionPattern:
    generation: int
    fitness_values: List[float]
    genetic_diversity: float
    mutation_distribution: Dict[str, float]
    behavioral_features: Dict[str, Any]

class MaliciousEvolutionDetector:
    def __init__(self):
        self.anomaly_detector = IsolationForest(contamination=0.1, random_state=42)
        self.pattern_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
        
        # ì•Œë ¤ì§„ ì•…ì„± íŒ¨í„´ ì‹œê·¸ë‹ˆì²˜
        self.malicious_signatures = {
            "exploitation_attempt": {
                "rapid_fitness_spike": True,
                "low_diversity_convergence": True,
                "security_related_mutations": True
            },
            "resource_bombing": {
                "exponential_complexity_growth": True,
                "memory_allocation_pattern": True,
                "infinite_loop_indicators": True
            },
            "backdoor_insertion": {
                "hidden_functionality_injection": True,
                "authentication_bypass_patterns": True,
                "covert_communication_setup": True
            }
        }
    
    def analyze_evolution_pattern(self, 
                                pattern_history: List[EvolutionPattern]) -> Dict[str, Any]:
        """ì§„í™” íŒ¨í„´ ë¶„ì„"""
        if len(pattern_history) < 5:
            return {"threat_detected": False, "reason": "Insufficient data"}
        
        # 1. ì´ìƒì¹˜ íƒì§€
        anomaly_score = self._detect_anomalies(pattern_history)
        
        # 2. ì•Œë ¤ì§„ ì•…ì„± íŒ¨í„´ ë§¤ì¹­
        signature_matches = self._match_malicious_signatures(pattern_history)
        
        # 3. í–‰ë™ íŒ¨í„´ ë¶„ì„
        behavioral_analysis = self._analyze_behavioral_patterns(pattern_history)
        
        # 4. ì¢…í•© ìœ„í—˜ë„ ê³„ì‚°
        threat_score = self._calculate_threat_score(
            anomaly_score, signature_matches, behavioral_analysis
        )
        
        return {
            "threat_detected": threat_score > 0.7,
            "threat_score": threat_score,
            "anomaly_score": anomaly_score,
            "signature_matches": signature_matches,
            "behavioral_analysis": behavioral_analysis,
            "recommended_action": self._recommend_action(threat_score)
        }
    
    def _detect_anomalies(self, patterns: List[EvolutionPattern]) -> float:
        """ì´ìƒì¹˜ íƒì§€"""
        features = []
        
        for pattern in patterns:
            feature_vector = [
                pattern.genetic_diversity,
                np.mean(pattern.fitness_values),
                np.std(pattern.fitness_values),
                len(pattern.mutation_distribution),
                sum(pattern.mutation_distribution.values())
            ]
            features.append(feature_vector)
        
        features_array = np.array(features)
        anomaly_scores = self.anomaly_detector.fit_predict(features_array)
        
        # ì´ìƒì¹˜ ë¹„ìœ¨ ê³„ì‚°
        anomaly_ratio = np.sum(anomaly_scores == -1) / len(anomaly_scores)
        return anomaly_ratio
    
    def _match_malicious_signatures(self, 
                                   patterns: List[EvolutionPattern]) -> Dict[str, float]:
        """ì•…ì„± ì‹œê·¸ë‹ˆì²˜ ë§¤ì¹­"""
        matches = {}
        
        for signature_name, signature in self.malicious_signatures.items():
            match_score = 0.0
            
            # ê¸‰ê²©í•œ ì í•©ë„ ìƒìŠ¹ íŒ¨í„´
            if signature.get("rapid_fitness_spike"):
                fitness_gradients = self._calculate_fitness_gradients(patterns)
                if max(fitness_gradients) > 0.5:  # ì„ê³„ê°’
                    match_score += 0.3
            
            # ë‚®ì€ ë‹¤ì–‘ì„± ìˆ˜ë ´ íŒ¨í„´
            if signature.get("low_diversity_convergence"):
                diversity_trend = [p.genetic_diversity for p in patterns[-5:]]
                if all(d < 0.1 for d in diversity_trend):
                    match_score += 0.3
            
            # ë³´ì•ˆ ê´€ë ¨ ë³€ì´ íŒ¨í„´
            if signature.get("security_related_mutations"):
                security_mutations = self._count_security_mutations(patterns)
                if security_mutations > 0.2:  # 20% ì´ìƒ
                    match_score += 0.4
            
            matches[signature_name] = match_score
        
        return matches
    
    def _calculate_fitness_gradients(self, patterns: List[EvolutionPattern]) -> List[float]:
        """ì í•©ë„ ë³€í™”ìœ¨ ê³„ì‚°"""
        gradients = []
        for i in range(1, len(patterns)):
            prev_fitness = np.mean(patterns[i-1].fitness_values)
            curr_fitness = np.mean(patterns[i].fitness_values)
            gradient = (curr_fitness - prev_fitness) / max(prev_fitness, 0.001)
            gradients.append(gradient)
        return gradients
    
    def _recommend_action(self, threat_score: float) -> str:
        """ê¶Œì¥ ì¡°ì¹˜ ê²°ì •"""
        if threat_score > 0.9:
            return "IMMEDIATE_TERMINATION"
        elif threat_score > 0.7:
            return "ENHANCED_MONITORING"
        elif threat_score > 0.5:
            return "CHECKPOINT_AND_REVIEW"
        else:
            return "CONTINUE_WITH_CAUTION"
```

### Layer 3: ì§„í™” í›„ ê²€ì¦ (Post-Evolution Validation)

#### 3.1 ì§„í™” ê²°ê³¼ ì•ˆì „ì„± ê²€ì¦
```python
# backend/src/security/evolution_result_validator.py

import ast
import subprocess
import tempfile
import os
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class ValidationResult:
    is_safe: bool
    security_score: float
    functionality_score: float
    performance_score: float
    detected_issues: List[str]
    recommended_fixes: List[str]

class EvolutionResultValidator:
    def __init__(self):
        self.security_checkers = [
            self._check_dangerous_imports,
            self._check_system_calls,
            self._check_network_operations,
            self._check_file_operations,
            self._check_eval_usage,
            self._check_subprocess_usage
        ]
        
        self.functionality_checkers = [
            self._check_syntax_validity,
            self._check_api_compatibility,
            self._check_interface_compliance,
            self._check_business_logic_integrity
        ]
        
        self.performance_checkers = [
            self._check_computational_complexity,
            self._check_memory_usage_patterns,
            self._check_infinite_loop_potential,
            self._check_recursive_depth
        ]
    
    def validate_evolution_result(self, 
                                evolved_code: str, 
                                original_spec: Dict[str, Any]) -> ValidationResult:
        """ì§„í™” ê²°ê³¼ ì¢…í•© ê²€ì¦"""
        detected_issues = []
        recommended_fixes = []
        
        # 1. ë³´ì•ˆ ê²€ì¦
        security_score, security_issues, security_fixes = self._run_security_checks(evolved_code)
        detected_issues.extend(security_issues)
        recommended_fixes.extend(security_fixes)
        
        # 2. ê¸°ëŠ¥ì„± ê²€ì¦
        functionality_score, func_issues, func_fixes = self._run_functionality_checks(
            evolved_code, original_spec
        )
        detected_issues.extend(func_issues)
        recommended_fixes.extend(func_fixes)
        
        # 3. ì„±ëŠ¥ ê²€ì¦
        performance_score, perf_issues, perf_fixes = self._run_performance_checks(evolved_code)
        detected_issues.extend(perf_issues)
        recommended_fixes.extend(perf_fixes)
        
        # 4. ì¢…í•© ì•ˆì „ì„± íŒì •
        overall_score = (security_score * 0.5 + 
                        functionality_score * 0.3 + 
                        performance_score * 0.2)
        
        is_safe = (security_score >= 0.8 and 
                  functionality_score >= 0.7 and 
                  performance_score >= 0.6 and
                  overall_score >= 0.75)
        
        return ValidationResult(
            is_safe=is_safe,
            security_score=security_score,
            functionality_score=functionality_score,
            performance_score=performance_score,
            detected_issues=detected_issues,
            recommended_fixes=recommended_fixes
        )
    
    def _run_security_checks(self, code: str) -> Tuple[float, List[str], List[str]]:
        """ë³´ì•ˆ ê²€ì‚¬ ì‹¤í–‰"""
        issues = []
        fixes = []
        score = 1.0
        
        for checker in self.security_checkers:
            check_result = checker(code)
            if check_result["violations"]:
                issues.extend(check_result["violations"])
                fixes.extend(check_result["fixes"])
                score -= check_result["severity"] * 0.2
        
        return max(score, 0.0), issues, fixes
    
    def _check_dangerous_imports(self, code: str) -> Dict[str, Any]:
        """ìœ„í—˜í•œ ì„í¬íŠ¸ ê²€ì‚¬"""
        dangerous_modules = [
            "subprocess", "os", "sys", "ctypes", "importlib", 
            "pickle", "marshal", "exec", "eval"
        ]
        
        violations = []
        fixes = []
        
        try:
            tree = ast.parse(code)
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        if alias.name in dangerous_modules:
                            violations.append(f"Dangerous import detected: {alias.name}")
                            fixes.append(f"Replace {alias.name} with safer alternative")
                
                elif isinstance(node, ast.ImportFrom):
                    if node.module in dangerous_modules:
                        violations.append(f"Dangerous module import: {node.module}")
                        fixes.append(f"Avoid importing from {node.module}")
        
        except SyntaxError:
            violations.append("Code contains syntax errors")
            fixes.append("Fix syntax errors before deployment")
        
        severity = len(violations) * 0.3
        return {"violations": violations, "fixes": fixes, "severity": min(severity, 1.0)}
    
    def _check_system_calls(self, code: str) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ í˜¸ì¶œ ê²€ì‚¬"""
        system_call_patterns = [
            r"os\.system\s*\(",
            r"subprocess\.(call|run|Popen)",
            r"exec\s*\(",
            r"eval\s*\(",
            r"__import__\s*\("
        ]
        
        violations = []
        fixes = []
        
        for pattern in system_call_patterns:
            import re
            matches = re.finditer(pattern, code)
            for match in matches:
                violations.append(f"System call detected: {match.group(0)}")
                fixes.append("Replace with safer alternative or add proper validation")
        
        severity = len(violations) * 0.4
        return {"violations": violations, "fixes": fixes, "severity": min(severity, 1.0)}
```

## ğŸ”„ ìë™ ë¡¤ë°± ë©”ì»¤ë‹ˆì¦˜

### 1. ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ
```python
# backend/src/security/evolution_checkpoint_manager.py

import json
import hashlib
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime

@dataclass
class EvolutionCheckpoint:
    checkpoint_id: str
    generation: int
    population_state: Dict[str, Any]
    fitness_metrics: Dict[str, float]
    system_state: Dict[str, Any]
    timestamp: datetime
    validation_status: str
    security_hash: str

class EvolutionCheckpointManager:
    def __init__(self):
        self.checkpoints: Dict[str, EvolutionCheckpoint] = {}
        self.auto_checkpoint_interval = 5  # 5ì„¸ëŒ€ë§ˆë‹¤
        self.max_checkpoints = 20
        
    def create_checkpoint(self, 
                         generation: int,
                         population: Dict[str, Any],
                         metrics: Dict[str, float]) -> str:
        """ì²´í¬í¬ì¸íŠ¸ ìƒì„±"""
        checkpoint_id = f"evo_cp_{generation}_{int(datetime.now().timestamp())}"
        
        # ì‹œìŠ¤í…œ ìƒíƒœ ìº¡ì²˜
        system_state = self._capture_system_state()
        
        # ë³´ì•ˆ í•´ì‹œ ìƒì„±
        checkpoint_data = {
            "generation": generation,
            "population": population,
            "metrics": metrics,
            "system_state": system_state
        }
        security_hash = self._generate_security_hash(checkpoint_data)
        
        checkpoint = EvolutionCheckpoint(
            checkpoint_id=checkpoint_id,
            generation=generation,
            population_state=population,
            fitness_metrics=metrics,
            system_state=system_state,
            timestamp=datetime.now(),
            validation_status="pending",
            security_hash=security_hash
        )
        
        self.checkpoints[checkpoint_id] = checkpoint
        
        # ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬
        self._cleanup_old_checkpoints()
        
        return checkpoint_id
    
    def validate_and_rollback(self, 
                            target_checkpoint_id: str,
                            reason: str) -> bool:
        """ê²€ì¦ í›„ ë¡¤ë°± ì‹¤í–‰"""
        if target_checkpoint_id not in self.checkpoints:
            return False
        
        checkpoint = self.checkpoints[target_checkpoint_id]
        
        # ì²´í¬í¬ì¸íŠ¸ ë¬´ê²°ì„± ê²€ì¦
        if not self._verify_checkpoint_integrity(checkpoint):
            return False
        
        # ë¡¤ë°± ì‹¤í–‰
        success = self._execute_rollback(checkpoint, reason)
        
        if success:
            # ë¡¤ë°± ì´í›„ ì²´í¬í¬ì¸íŠ¸ë“¤ ì œê±°
            self._cleanup_post_rollback_checkpoints(checkpoint.generation)
        
        return success
    
    def _execute_rollback(self, checkpoint: EvolutionCheckpoint, reason: str) -> bool:
        """ë¡¤ë°± ì‹¤í–‰"""
        try:
            # 1. ì‹œìŠ¤í…œ ìƒíƒœ ë³µì›
            self._restore_system_state(checkpoint.system_state)
            
            # 2. ì§„í™” ìƒíƒœ ë³µì›
            self._restore_evolution_state(checkpoint.population_state)
            
            # 3. ë¡¤ë°± ë¡œê·¸ ê¸°ë¡
            self._log_rollback_event(checkpoint, reason)
            
            return True
            
        except Exception as e:
            self._log_rollback_failure(checkpoint, str(e))
            return False
```

## ğŸ“Š ì•ˆì „ì„± ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

### 1. ì‹¤ì‹œê°„ ì•ˆì „ì„± ì§€í‘œ
```yaml
í•µì‹¬ KPI:
  - ì§„í™” ì•ˆì „ì„± ì ìˆ˜: 0-100
  - ë³´ì•ˆ ìœ„ë°˜ íšŸìˆ˜: ì¼ì¼/ì›”ê°„
  - ìë™ ë¡¤ë°± ì‹¤í–‰ íšŸìˆ˜
  - ì²´í¬í¬ì¸íŠ¸ ìƒì„± ì£¼ê¸°
  - ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶”ì´

ì•Œë¦¼ ì„ê³„ê°’:
  - ë³´ì•ˆ ì ìˆ˜ < 70: ê²½ê³ 
  - ë³´ì•ˆ ì ìˆ˜ < 50: ìœ„í—˜
  - ì—°ì† ë³´ì•ˆ ìœ„ë°˜ > 3: ìë™ ì¤‘ë‹¨
  - ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ > 80%: ìŠ¤ì¼€ì¼ë§ ì•Œë¦¼
```

### 2. ì§„í™” í’ˆì§ˆ íŠ¸ë Œë“œ
```yaml
ì¶”ì  ì§€í‘œ:
  - ì„¸ëŒ€ë³„ ì í•©ë„ í–¥ìƒë¥ 
  - ìœ ì „ì  ë‹¤ì–‘ì„± ì§€ìˆ˜
  - ìˆ˜ë ´ ì†ë„
  - í˜ì‹ ì  ëŒì—°ë³€ì´ ë¹„ìœ¨
  - ì•ˆì •ì„± ì ìˆ˜ ì¶”ì´

ë¶„ì„ ë¦¬í¬íŠ¸:
  - ì£¼ê°„ ì§„í™” í’ˆì§ˆ ë¦¬í¬íŠ¸
  - ì›”ê°„ ì•ˆì „ì„± ì¢…í•© ë¶„ì„
  - ë¶„ê¸°ë³„ ê°œì„  ê¶Œê³ ì‚¬í•­
  - ì—°ê°„ ì§„í™” ì „ëµ í‰ê°€
```

## ğŸ¯ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: í•µì‹¬ ì•ˆì „ì¥ì¹˜ (ì£¼ 1-2)
- ì§„í™” ëª©í‘œ ì•ˆì „ì„± ê²€ì¦
- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
- ê¸°ë³¸ ì²´í¬í¬ì¸íŠ¸ ë©”ì»¤ë‹ˆì¦˜

### Phase 2: ê³ ê¸‰ íƒì§€ ì‹œìŠ¤í…œ (ì£¼ 3)
- ì•…ì„± ì§„í™” íŒ¨í„´ íƒì§€
- ìë™ ë¡¤ë°± ì‹œìŠ¤í…œ
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê°•í™”

### Phase 3: ì™„ì „ ìë™í™” (ì£¼ 4)
- ì•ˆì „ì„± ëŒ€ì‹œë³´ë“œ
- ì˜ˆì¸¡ì  ìœ„í—˜ ë¶„ì„
- ìê°€ í•™ìŠµ ì•ˆì „ ì‹œìŠ¤í…œ

ì´ Evolution Safety Frameworkë¥¼ í†µí•´ T-Developerì˜ AI ììœ¨ì§„í™” ì‹œìŠ¤í…œì´ ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆê²Œ ìš´ì˜ë©ë‹ˆë‹¤.
