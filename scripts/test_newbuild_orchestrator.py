#!/usr/bin/env python3
"""NewBuildOrchestrator í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ì²˜ìŒë¶€í„° ìƒì„±í•˜ëŠ” NewBuildOrchestratorë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
UpgradeOrchestratorì™€ ë‹¬ë¦¬ ê¸°ì¡´ í”„ë¡œì íŠ¸ ë¶„ì„ ì—†ì´ ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import asyncio
import sys
from pathlib import Path
import json
from datetime import datetime

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from backend.packages.orchestrator.newbuild_orchestrator import (
    NewBuildOrchestrator,
    NewBuildConfig
)


async def test_newbuild_orchestrator():
    """NewBuildOrchestrator í…ŒìŠ¤íŠ¸"""
    
    print("=" * 80)
    print("ğŸš€ Testing NewBuildOrchestrator - Building New Project from Scratch")
    print("=" * 80)
    
    # í…ŒìŠ¤íŠ¸ìš© í”„ë¡œì íŠ¸ ì„¤ì •
    project_name = f"test-project-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
    
    # ìš”êµ¬ì‚¬í•­ ì •ì˜
    requirements = """
    T-Developer-TEST í”„ë¡œì íŠ¸ë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    
    ## í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­
    1. Python ê¸°ë°˜ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
    2. Flask í”„ë ˆì„ì›Œí¬ ì‚¬ìš©
    3. ì‚¬ìš©ì ì¸ì¦ ê¸°ëŠ¥
    4. ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ (SQLite)
    5. RESTful API ì—”ë“œí¬ì¸íŠ¸
    6. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í¬í•¨
    7. Docker ì»¨í…Œì´ë„ˆí™”
    8. CI/CD íŒŒì´í”„ë¼ì¸ ì„¤ì •
    
    ## ì£¼ìš” ê¸°ëŠ¥
    - ì‚¬ìš©ì ë“±ë¡/ë¡œê·¸ì¸
    - í”„ë¡œí•„ ê´€ë¦¬
    - ê²Œì‹œê¸€ CRUD
    - ëŒ“ê¸€ ê¸°ëŠ¥
    - ê²€ìƒ‰ ê¸°ëŠ¥
    
    ## ê¸°ìˆ  ìŠ¤íƒ
    - Backend: Python, Flask
    - Database: SQLite (ê°œë°œ), PostgreSQL (í”„ë¡œë•ì…˜)
    - Authentication: JWT
    - Testing: pytest
    - Containerization: Docker
    - CI/CD: GitHub Actions
    """
    
    print(f"ğŸ“ Project Name: {project_name}")
    print(f"ğŸ“‹ Requirements Preview: {requirements[:200]}...")
    
    # NewBuildConfig ìƒì„± (Evolution Loop í™œì„±í™”)
    config = NewBuildConfig(
        project_name=project_name,
        output_dir="/tmp/t-developer/new-projects",
        project_type="web",
        language="python",
        framework="flask",
        include_tests=True,
        include_docs=True,
        include_ci_cd=True,
        include_docker=True,
        include_kubernetes=False,
        # Evolution Loop ì„¤ì •
        enable_evolution_loop=True,  # Evolution Loop í™œì„±í™”
        max_evolution_iterations=3,  # ìµœëŒ€ 3ë²ˆ ë°˜ë³µ
        evolution_convergence_threshold=0.85,  # 85% ìˆ˜ë ´ ì‹œ ì¢…ë£Œ
        auto_improve_code=True,  # ì½”ë“œ ìë™ ê°œì„ 
        ai_driven_design=True,
        auto_generate_all=True,
        use_best_practices=True,
        max_execution_time=900,  # 15ë¶„ (Evolution Loop ê³ ë ¤)
        max_files=50,
        max_code_lines=5000
    )
    
    print("\nâš™ï¸ Configuration:")
    print(f"  - Project Type: {config.project_type}")
    print(f"  - Language: {config.language}")
    print(f"  - Framework: {config.framework}")
    print(f"  - Output Dir: {config.output_dir}")
    print(f"  - Include Tests: {config.include_tests}")
    print(f"  - Include Docker: {config.include_docker}")
    print(f"  - AI-Driven Design: {config.ai_driven_design}")
    print(f"  - Evolution Loop: {config.enable_evolution_loop}")
    print(f"  - Max Iterations: {config.max_evolution_iterations}")
    print(f"  - Convergence Threshold: {config.evolution_convergence_threshold:.0%}")
    
    # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„± ë° ì´ˆê¸°í™”
    print("\nğŸ”§ Initializing NewBuildOrchestrator...")
    orchestrator = NewBuildOrchestrator(config)
    await orchestrator.initialize()
    print("âœ… Orchestrator initialized")
    
    # ë¹Œë“œ ì‹¤í–‰
    print("\nğŸ—ï¸ Starting Project Build...")
    print("-" * 40)
    
    start_time = datetime.now()
    
    try:
        # build ë©”ì„œë“œ ì‹¤í–‰
        report = await orchestrator.build(requirements)
        
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        
        print("\nâœ… Build Process Completed!")
        print("-" * 40)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“Š Build Results:")
        print(f"  - Success: {report.success}")
        print(f"  - Execution Time: {execution_time:.2f}s")
        print(f"  - Project Name: {report.project_name}")
        print(f"  - Output Path: {report.output_path}")
        
        # ë‹¨ê³„ë³„ ê²°ê³¼ í™•ì¸
        print("\nğŸ“‹ Phase Execution Results:")
        
        if report.requirement_analysis:
            print("  âœ… RequirementAnalyzer - Completed")
        else:
            print("  âŒ RequirementAnalyzer - Failed or Skipped")
        
        if report.external_research:
            print("  âœ… ExternalResearcher - Completed")
        else:
            print("  âŒ ExternalResearcher - Failed or Skipped")
        
        if report.architecture_design:
            print("  âœ… SystemArchitect - Completed")
            agents = report.architecture_design.get('agents', [])
            print(f"     - Designed Agents: {len(agents)}")
        else:
            print("  âŒ SystemArchitect - Failed or Skipped")
        
        if report.orchestrator_design:
            print("  âœ… OrchestratorDesigner - Completed")
        else:
            print("  âŒ OrchestratorDesigner - Failed or Skipped")
        
        if report.development_plan:
            print("  âœ… PlannerAgent - Completed")
        else:
            print("  âŒ PlannerAgent - Failed or Skipped")
        
        if report.detailed_tasks:
            print("  âœ… TaskCreatorAgent - Completed")
            print(f"     - Total Tasks: {len(report.detailed_tasks)}")
        else:
            print("  âŒ TaskCreatorAgent - Failed or Skipped")
        
        if report.project_structure:
            print("  âœ… Project Structure - Created")
            print(f"     - Root Dir: {report.project_structure.root_dir}")
            print(f"     - Directories: {len(report.project_structure.directories_to_create)}")
        else:
            print("  âŒ Project Structure - Failed")
        
        if report.code_generated:
            print("  âœ… CodeGenerator - Completed")
            print(f"     - Files Generated: {report.code_generated.get('total_files', 0)}")
            print(f"     - Total Lines: {report.code_generated.get('total_lines', 0)}")
        else:
            print("  âŒ CodeGenerator - Failed or Skipped")
        
        if report.tests_generated:
            print("  âœ… Test Generation - Completed")
            print(f"     - Test Files: {report.tests_generated.get('total_tests', 0)}")
        else:
            print("  âŒ Test Generation - Failed or Skipped")
        
        if report.documentation_generated:
            print("  âœ… Documentation - Completed")
            print(f"     - Docs Generated: {len(report.documentation_generated)}")
        else:
            print("  âŒ Documentation - Failed or Skipped")
        
        if report.quality_metrics:
            print("  âœ… Quality Gate - Completed")
            print(f"     - Quality Score: {report.quality_metrics.get('quality_score', 0):.1f}/100")
        else:
            print("  âŒ Quality Gate - Failed or Skipped")
        
        # Evolution Loop ê²°ê³¼
        if report.evolution_iterations > 0:
            print("\nğŸ”„ Evolution Loop Results:")
            print(f"  - Iterations Completed: {report.evolution_iterations}")
            print(f"  - Convergence Rate: {report.convergence_rate:.2%}")
            print(f"  - Gaps Remaining: {len(report.gaps_remaining) if report.gaps_remaining else 0}")
            
            if report.gap_analysis:
                print(f"  - Gap Score: {report.gap_analysis.get('gap_score', 0):.2%}")
            
            if report.current_state_analysis:
                print("  - Current State Analysis: Completed")
        
        # ìƒì„±ëœ íŒŒì¼ ëª©ë¡
        if report.files_created:
            print("\nğŸ“ Files Created:")
            for file_path in report.files_created[:10]:  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
                print(f"  â€¢ {file_path}")
            if len(report.files_created) > 10:
                print(f"  ... and {len(report.files_created) - 10} more files")
        
        # ì—ëŸ¬ ë° ê²½ê³ 
        if report.errors:
            print("\nâŒ Errors:")
            for error in report.errors:
                print(f"  â€¢ {error}")
        
        if report.warnings:
            print("\nâš ï¸ Warnings:")
            for warning in report.warnings:
                print(f"  â€¢ {warning}")
        
        # ë‹¤ìŒ ë‹¨ê³„
        if report.next_steps:
            print("\nğŸ¯ Next Steps:")
            for step in report.next_steps:
                print(f"  â€¢ {step}")
        
        # ë°°í¬ ì§€ì¹¨ ë¯¸ë¦¬ë³´ê¸°
        if report.deployment_instructions:
            print("\nğŸ“¦ Deployment Instructions (Preview):")
            preview = report.deployment_instructions[:300]
            print(preview + "..." if len(report.deployment_instructions) > 300 else preview)
        
        # ì „ì²´ ë³´ê³ ì„œë¥¼ JSONìœ¼ë¡œ ì €ì¥
        test_output_path = Path("test_outputs")
        test_output_path.mkdir(exist_ok=True)
        
        output_file = test_output_path / f"newbuild_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # ë³´ê³ ì„œë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        report_dict = {
            "timestamp": report.timestamp,
            "project_name": report.project_name,
            "output_path": report.output_path,
            "success": report.success,
            "total_execution_time": report.total_execution_time,
            "files_created": report.files_created,
            "errors": report.errors,
            "warnings": report.warnings,
            "next_steps": report.next_steps,
            "phases_completed": {
                "requirement_analysis": bool(report.requirement_analysis),
                "external_research": bool(report.external_research),
                "architecture_design": bool(report.architecture_design),
                "orchestrator_design": bool(report.orchestrator_design),
                "development_plan": bool(report.development_plan),
                "detailed_tasks": len(report.detailed_tasks) if report.detailed_tasks else 0,
                "code_generated": bool(report.code_generated),
                "tests_generated": bool(report.tests_generated),
                "documentation_generated": bool(report.documentation_generated),
                "quality_metrics": bool(report.quality_metrics)
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report_dict, f, indent=2, default=str, ensure_ascii=False)
        
        print(f"\nğŸ’¾ Full report saved to: {output_file}")
        
        # í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ í™•ì¸
        if report.success and report.output_path:
            project_path = Path(report.output_path)
            if project_path.exists():
                print(f"\nâœ… Project successfully created at: {project_path}")
                print("\nTo explore the project:")
                print(f"  cd {project_path}")
                print("  ls -la")
            else:
                print(f"\nâš ï¸ Project directory not found: {project_path}")
        
        print("\n" + "=" * 80)
        if report.success:
            print("ğŸ‰ NewBuildOrchestrator Test Completed Successfully!")
        else:
            print("âš ï¸ NewBuildOrchestrator Test Completed with Issues")
        print("=" * 80)
        
        return report.success
        
    except Exception as e:
        print(f"\nâŒ Error during build: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Main entry point"""
    success = asyncio.run(test_newbuild_orchestrator())
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()